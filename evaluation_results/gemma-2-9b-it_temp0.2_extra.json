{"raw_generations": {"sample_108": ["    def test_reverse_type_error_propagates(self):\n        @DynamicConverter.register_to_url\n            raise TypeError('This type error propagates.')\n        with self.assertRaisesMessage(TypeError, 'This type error propagates.'):\n            reverse('dynamic', kwargs={'value': object()})\n"], "sample_770": ["def test_silhouette_with_sparse_data():\n    # Tests the Silhouette Coefficient with sparse matrices\n    dataset = datasets.load_iris()\n    X_dense = dataset.data\n    X_csr = csr_matrix(X_dense)\n    X_dok = sp.dok_matrix(X_dense)\n    X_lil = sp.lil_matrix(X_dense)\n    y = dataset.target\n\n    for X in [X_csr, X_dok, X_lil]:\n        D = pairwise_distances(X, metric='euclidean')\n        score_precomputed = silhouette_score(D, y, metric='precomputed')\n        assert_greater(score_precomputed, 0)\n        score_dense_without_sampling = silhouette_score(X_dense, y,\n                                                      metric='euclidean')\n        pytest.approx(score_precomputed, score_dense_without_sampling)\n\n        score_precomputed = silhouette_score(D, y, metric='precomputed',\n                                            sample_size=int(X.shape[0] / 2),\n                                            random_state=0)\n        score_dense_with_sampling = silhouette_score(X_dense, y,\n                                                    metric='euclidean',\n                                                    sample_size=int(X.shape[0] / 2),\n                                                    random_state=0)\n        assert_greater(score_precomputed, 0)\n        assert_greater(score_dense_with_sampling, 0)\n        pytest.approx(score_precomputed, score_dense_with_sampling)\n\n\n\n"], "sample_1011": ["def test_polylog_printing_issue_14820():\n    assert octave_code(polylog(x, y)) == 'polylog(x, y)'\n"], "sample_740": ["compilation error"], "sample_808": ["def test_iforest_sparse_fit_predict():\n    \"\"\"Test fit and predict with sparse input.\"\"\"\n    X_train = np.array([[1, 2], [3, 4], [5, 6]])\n    X_test = np.array([[7, 8], [9, 10]])\n    \n    # Convert to sparse matrices\n    X_train_sparse = csr_matrix(X_train)\n    X_test_sparse = csr_matrix(X_test)\n\n    clf = IsolationForest()\n    clf.fit(X_train_sparse)\n    y_pred = clf.predict(X_test_sparse)\n\n    assert_array_equal(y_pred, clf.predict(X_test))\n"], "sample_156": ["    def test_renderer_with_context(self):\n        class CustomRenderer(DjangoTemplates):\n                return f\"Custom rendered: {context['form']}\"\n\n        custom = CustomRenderer()\n        form = Form(renderer=custom)\n        rendered = form.render()\n        self.assertEqual(rendered, \"Custom rendered: <form>\")\n"], "sample_92": ["    def test_get_user_anonymous(self):\n        self.client.logout()\n        request = HttpRequest()\n        request.session = self.client.session\n        user = get_user(request)\n        self.assertIsNone(user)\n"], "sample_411": ["    def test_normalize_path_patterns_handles_trailing_slashes(self):\n        expected = [os.path.normcase(p) for p in [\"foo/bar/\", \"bar/\"]]\n        self.assertEqual(normalize_path_patterns([\"foo/bar/*\", \"bar/\"]), expected)\n"], "sample_699": ["    def test_is_setup_py_empty(tmp_path: Path) -> None:\n        setup_py = tmp_path.joinpath(\"setup.py\")\n        setup_py.write_text(\"\", \"utf-8\")\n        assert _is_setup_py(setup_py)\n"], "sample_210": ["    def test_template_params_with_kwargs(self):\n        \"\"\"A template view can be customized to return extra context.\"\"\"\n        response = self.client.get('/template/custom/bar1/bar2/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.context['foo1'], 'bar1')\n        self.assertEqual(response.context['foo2'], 'bar2')\n        self.assertEqual(response.context['key'], 'value')\n        self.assertIsInstance(response.context['view'], View)\n"], "sample_498": ["def test_legend_title_fontsize_with_rcparam():\n    mpl.rcParams['legend.title_fontsize'] = 12\n    fig, ax = plt.subplots()\n    ax.plot(range(10), label='test')\n    leg = ax.legend(title=\"Aardvark\")\n    assert leg.get_title().get_fontsize() == 12\n\n\n"], "sample_120": ["    def test_serialize_custom_field(self):\n        class MyCustomField(models.Field):\n                super().__init__(*args, **kwargs)\n\n                return 'MyCustomField'\n\n                return 'MyCustomField'\n\n                return super().formfield(**kwargs)\n\n        class MyModel(models.Model):\n            my_field = MyCustomField()\n\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.CreateModel(\"MyModel\", (\n                    ('id', models.AutoField(primary_key=True)),\n                    ('my_field', MyModel.my_field),\n                ), {})\n            ],\n            \"dependencies\": []\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\"MyCustomField\", output)\n"], "sample_718": ["def test_check_estimators_data_not_an_array():\n    # check that estimators that are not transformers raise an error\n    # if they are given a data type that is not a numpy array\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.ensemble import RandomForestClassifier\n    from sklearn.neighbors import KNeighborsClassifier\n\n    for estimator_class in [LogisticRegression, RandomForestClassifier,\n                            KNeighborsClassifier]:\n        estimator = estimator_class()\n        msg = \"Estimator does not raise an error when given a non-array data type\"\n        with ignore_warnings(category=(DeprecationWarning, FutureWarning)):\n            assert_raises_regex(TypeError, msg,\n                                estimator.fit, [1, 2, 3], [4, 5, 6])\n"], "sample_897": ["def test_partial_dependence_with_categorical_features_and_subsample(\n    pyplot, categorical_features, array_type"], "sample_1185": ["def test_decompogen_nested_functions():\n    assert decompogen(sin(cos(sqrt(x))), x) == [sin(x), cos(x), sqrt(x)]\n    assert decompogen(sqrt(x**2 + 1), x) == [sqrt(x), x**2 + 1]\n    assert decompogen(exp(sin(x)), x) == [exp(x), sin(x)]\n    assert decompogen(log(x**2 + 1), x) == [log(x), x**2 + 1]\n"], "sample_195": ["    def test_bulk_batch_size(self):\n        self.assertEqual(connection.ops.bulk_batch_size(\n            ['id'], [Author()]\n        ), 500)\n        self.assertEqual(connection.ops.bulk_batch_size(\n            ['id', 'name'], [Author()]\n        ), 250)\n\n\n\n"], "sample_641": ["def test_save_and_load_empty_results(path: str) -> None:\n    save_results(LinterStats(), path)\n    loaded = load_results(path)\n    assert loaded is not None\n    assert loaded.bad_names == LinterStats().bad_names\n"], "sample_972": ["compilation error"], "sample_540": ["def test_animation_repr_html_no_writer(writer, anim):\n    with plt.rc_context({'animation.writer': writer}):\n        with pytest.raises(ValueError):\n            anim._repr_html_()\n"], "sample_579": ["    def test_clustermap_with_categorical_data(self):\n        df = pd.DataFrame({'A': ['a', 'b', 'a', 'c', 'b'],\n                           'B': ['x', 'y', 'x', 'y', 'x'],\n                           'C': [1, 2, 3, 4, 5]})\n        df = pd.get_dummies(df, columns=['A', 'B'])\n        g = mat.clustermap(df, cmap='viridis')\n        assert len(g.ax_heatmap.collections) == 1\n        assert len(g.ax_heatmap.texts) == len(df.values.flatten())\n"], "sample_1068": ["def test_polylog():\n    assert octave_code(polylog(n, x)) == 'polylog(n, x)'\n"], "sample_862": ["def test_vectorizer_with_empty_input(vectorizer_class):\n    if issubclass(vectorizer_class, HashingVectorizer):\n        pytest.xfail('HashingVectorizer is not supported on PyPy')\n    for input_data in [ [], [''] , [None]]:\n        vectorizer = vectorizer_class()\n        with pytest.raises(ValueError, match=\"Input data cannot be empty\"):\n            vectorizer.fit_transform(input_data)\n\n\n\n"], "sample_976": ["def test_symbols_with_spaces():\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z')\n\n    assert symbols(' x  y  z ') == (x, y, z)\n    assert symbols(' x, y, z ') == (x, y, z)\n    assert symbols(' x  ,  y  ,  z ') == (x, y, z)\n    assert symbols(' x, y , z ') == (x, y, z)\n    assert symbols(' x , y , z ') == (x, y, z)\n\n\n\n"], "sample_624": ["compilation error"], "sample_445": ["    def test_timeuntil_with_future_date(self):\n        future_date = self.t + self.oneday\n        self.assertEqual(timeuntil(future_date), \"1\\xa0day\")\n"], "sample_995": ["def test_issue_10504():\n    assert Float(1.2345678901234567890123456789012345678901234567890, 100) == Float(1.2345678901234567890123456789012345678901234567890, 100)\n"], "sample_135": ["    def test_format_with_empty_string(self):\n        my_birthday = datetime(1979, 7, 8, 22, 00)\n        self.assertEqual(dateformat.format(my_birthday, ''), my_birthday.strftime('%Y-%m-%d %H:%M:%S'))\n"], "sample_727": ["def test_imputation_sparse_missing_values_not_zero():\n    # Test imputation with sparse matrices and missing_values != 0.\n    rng = np.random.RandomState(0)\n\n    dim = 10\n    dec = 10\n    shape = (dim * dim, dim + dec)\n\n    zeros = np.zeros(shape[0])\n    values = np.arange(1, shape[0] + 1)\n    values[4::2] = - values[4::2]\n\n    for missing_values in [1, 2, 5]:\n        X = np.empty(shape)\n        X_true = np.empty(shape)\n        true_statistics = np.empty(shape[1])\n\n        # Create a matrix X with columns\n        #    - with only zeros,\n        #    - with only missing values\n        #    - with zeros, missing values and values\n        # And a matrix X_true containing all true values\n        for j in range(shape[1]):\n            nb_zeros = (j - dec + 1 > 0) * (j - dec + 1) * (j - dec + 1)\n            nb_missing_values = max(shape[0] + dec * dec\n                                    - (j + dec) * (j + dec), 0)\n            nb_values = shape[0] - nb_zeros - nb_missing_values\n\n            z = zeros[:nb_zeros]\n            p = np.repeat(missing_values, nb_missing_values)\n            v = values[rng.permutation(len(values))[:nb_values]]\n\n            true_statistics[j] = np.mean(v)\n\n            # Create the columns\n            X[:, j] = np.hstack((v, z, p))\n\n            X_true[:, j] = np.hstack((v,\n                                      np.repeat(true_statistics[j],\n                                                nb_missing_values + nb_zeros)))\n\n            # Shuffle them the same way\n            np.random.RandomState(j).shuffle(X[:, j])\n            np.random.RandomState(j).shuffle(X_true[:, j])\n\n        imputer = Imputer(missing_values=missing"], "sample_481": ["    def test_join09(self):\n        output = self.engine.render_to_string(\"join09\", {\"a\": [\"alpha\", \"beta & me\"], \"var\": mark_safe(\" & \")})\n        self.assertEqual(output, \"alpha & beta & me\")\n"], "sample_832": ["def test_ard_with_sparse_data():\n    # Test ARDRegression with sparse input data\n    from scipy.sparse import csr_matrix\n    n_samples = 100\n    n_features = 1000\n    random_state = check_random_state(42)\n    X = random_state.rand(n_samples, n_features)\n    X_sparse = csr_matrix(X)\n    y = np.random.rand(n_samples)\n\n    clf = ARDRegression()\n    clf.fit(X_sparse, y)\n    y_pred = clf.predict(X_sparse)\n    assert_array_almost_equal(y_pred, clf.predict(X), 2)\n"], "sample_753": ["def test_l1_penalty_with_intercept():\n    # Test that the L1 penalty works correctly with fit_intercept=True\n    rng = np.random.RandomState(42)\n    n_samples = 50\n    X, y = make_classification(n_samples=n_samples, n_features=20,\n                               random_state=0)\n    X_noise = rng.normal(scale=0.1, size=(n_samples, 3))\n    X_constant = np.zeros(shape=(n_samples, 2))\n    X = np.concatenate((X, X_noise, X_constant), axis=1)\n    lr = LogisticRegression(penalty=\"l1\", C=1.0, solver='liblinear',\n                           fit_intercept=True)\n    lr.fit(X, y)\n    assert_array_almost_equal(lr.coef_[0, -5:], np.zeros(5))\n"], "sample_1132": ["compilation error"], "sample_1103": ["def test_issue_18507_continued():\n    assert Mul(zoo, zoo, evaluate=False) is nan\n    assert Mul(zoo, zoo, evaluate=True) is nan\n    assert Mul(zoo, zoo, evaluate=False, method='evalf') is nan\n    assert Mul(zoo, zoo, evaluate=True, method='evalf') is nan\n"], "sample_269": ["    def test_i18n_with_plural_forms(self):\n        with override('fr'):\n            response = self.client.get('/jsi18n_plural_forms/')\n            self.assertContains(response, '1 message')\n            self.assertContains(response, '2 messages')\n            self.assertContains(response, '3 messages')\n            self.assertContains(response, '4 messages')\n"], "sample_629": ["    def test_expand_modules_with_duplicate_files(files_or_modules, expected):\n        ignore_list, ignore_list_re, ignore_list_paths_re = [], [], []\n        modules, errors = expand_modules(\n            files_or_modules, ignore_list, ignore_list_re, ignore_list_paths_re\n        )\n        modules.sort(key=lambda d: d[\"name\"])\n        assert modules == expected\n        assert not errors\n"], "sample_581": ["def test_blueprint_url_prefix_inheritance(app, client) -> None:\n    parent = flask.Blueprint(\"parent\", __name__, url_prefix=\"/parent\")\n    child = flask.Blueprint(\"child\", __name__, url_prefix=\"/child\")\n\n    @child.route(\"/\")\n        return \"child\"\n\n    parent.register_blueprint(child)\n    app.register_blueprint(parent)\n\n    response = client.get(\"/parent/child/\")\n    assert response.status_code == 200\n    assert response.data == b\"child\"\n"], "sample_842": ["def test_kernel_is_stationary(kernel):\n    # Test the is_stationary method of kernels.\n    is_stationary = kernel.is_stationary()\n    if isinstance(kernel, (RBF, Matern, ExpSineSquared, RationalQuadratic)):\n        assert is_stationary\n    else:\n        assert not is_stationary\n"], "sample_713": ["def test_ridge_classifier_multi_class():\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5,\n                               n_classes=3, random_state=42)\n    ridge = RidgeClassifier(solver='lbfgs', random_state=42)\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape[0], X.shape[1])\n    assert_equal(ridge.classes_.shape[0], 3)\n"], "sample_715": ["def test_cross_val_predict_with_sparse_data():\n    X, y = make_classification(n_samples=100, n_features=10, random_state=0)\n    X_sparse = csr_matrix(X)\n    y_sparse = csr_matrix(y)\n\n    clf = LogisticRegression()\n    predictions = cross_val_predict(clf, X_sparse, y_sparse, cv=5)\n    assert_array_almost_equal(predictions, cross_val_predict(clf, X, y, cv=5))\n"], "sample_611": ["compilation error"], "sample_686": ["def test_external_plugins_integrated_with_ini(testdir, plugin):\n    testdir.syspathinsert()\n    testdir.makepyfile(**{plugin: \"\"})\n    testdir.makeini(f\"[pytest]\\n{plugin} = true\")\n    with pytest.warns(pytest.PytestConfigWarning):\n        testdir.parseconfig()\n"], "sample_1059": ["compilation error"], "sample_469": ["    def test_alias_with_subquery(self):\n        qs = Book.objects.annotate(\n            top_rating_year=Subquery(\n                Book.objects.filter(pubdate__year=OuterRef(\"pubdate__year\"))\n                .order_by(\"-rating\")\n                .values(\"rating\")[:1]\n            ),\n        ).alias(\n            top_rating_year_alias=F(\"top_rating_year\"),\n        )\n        self.assertIs(hasattr(qs.first(), \"top_rating_year_alias\"), False)\n        self.assertCountEqual(\n            qs.values(\"pubdate__year\", \"top_rating_year_alias\"),\n            [\n                {\"pubdate__year\": 1991, \"top_rating_year_alias\": 5.0},\n                {\"pubdate__year\": 1995, \"top_rating_year_alias\": 4.0},\n                {\"pubdate__year\": 2007, \"top_rating_year_alias\": 4.5},\n                {\"pubdate__year\": 2008, \"top_rating_year_alias\": 4.0},\n                {\"pubdate__year\": 2008, \"top_rating_year_alias\": 4.0},\n                {\"pubdate__year\": 2008, \"top_rating_year_alias\": 4.0},\n            ],\n        )\n\n"], "sample_903": ["def test_early_exaggeration_effect():\n    # Test the effect of early_exaggeration on the embedding\n    random_state = check_random_state(0)\n    X = random_state.randn(100, 2)\n    tsne_ee_1 = TSNE(n_components=2, perplexity=30,\n                     learning_rate=100.0, random_state=0,\n                     early_exaggeration=1.0)\n    tsne_ee_10 = TSNE(n_components=2, perplexity=30,\n                      learning_rate=100.0, random_state=0,\n                      early_exaggeration=10.0)\n\n    Y_ee_1 = tsne_ee_1.fit_transform(X)\n    Y_ee_10 = tsne_ee_10.fit_transform(X)\n\n    # Check that the embeddings are different\n    assert_array_not_equal(Y_ee_1, Y_ee_10)\n\n    # Check that the embedding with higher early_exaggeration\n    # is more spread out\n    assert np.mean(pairwise_distances(Y_ee_10)) > np.mean(\n        pairwise_distances(Y_ee_1))\n\n\n\n"], "sample_73": ["    def test_file_change_after_collectstatic_with_import(self):\n        # Create initial static files.\n        file_contents = (\n            ('foo.png', 'foo'),\n            ('bar.css', 'url(\"foo.png\")\\n@import \"baz.css\";'),\n            ('baz.css', 'url(\"foo.png\")'),\n            ('xyz.png', 'xyz'),\n        )\n        for filename, content in file_contents:\n            with open(self._get_filename_path(filename), 'w') as f:\n                f.write(content)\n\n        with self.modify_settings(STATICFILES_DIRS={'append': self._temp_dir}):\n            finders.get_finder.cache_clear()\n            err = StringIO()\n            # First collectstatic run.\n            call_command('collectstatic', interactive=False, verbosity=0, stderr=err)\n            relpath = self.hashed_file_path('test/bar.css')\n            with storage.staticfiles_storage.open(relpath) as relfile:\n                content = relfile.read()\n                self.assertIn(b'foo.acbd18db4cc2.png', content)\n                self.assertIn(b'baz.d41d8cd98f00.css', content)\n\n            # Change the contents of the png files.\n            for filename in ('foo.png', 'xyz.png'):\n                with open(self._get_filename_path(filename), 'w+b') as f:\n                    f.write(b\"new content of file to change its hash\")\n\n            # The hashes of the png files in the CSS file are updated after\n            # a second collectstatic.\n            call_command('collectstatic', interactive=False, verbosity=0, stderr=err)\n            relpath = self.hashed_file_path('test/bar.css')\n            with storage.staticfiles_storage.open(relpath) as relfile:\n                content = relfile.read()\n                self.assertIn(b'foo.57a5cb9ba68d.png', content)\n                self.assertIn(b'baz.57a5cb9ba68d.css"], "sample_1128": ["def test_point_vel_multiple_velocities():\n    q1, q2, u1, u2 = dynamicsymbols('q1 q2 u1 u2')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    O = Point('O')\n    O.set_vel(N, u1 * N.x)\n    P = Point('P')\n    P.set_pos(O, q1 * N.x)\n    P.set_vel(B, u2 * B.y)\n    assert P.vel(N) == u1 * N.x + u2 * B.y - q1 * u1 * B.x\n    assert P.vel(B) == u2 * B.y\n\n\n\n"], "sample_1083": ["def test_atanh_series_expansion():\n    x = Symbol('x')\n    assert atanh(x).series(x, 0, 10) == \\\n        x + x**3/3 + x**5/5 + x**7/7 + x**9/9 + O(x**10)\n"], "sample_329": ["    def test_serialize_custom_field(self):\n        class CustomField(models.Field):\n                super().__init__(*args, **kwargs)\n\n                return 'CustomField'\n\n                return 'CustomField'\n\n                return super().formfield(**kwargs)\n\n        class MyModel(models.Model):\n            my_field = CustomField()\n\n        with self.subTest(serialize_custom_field=True):\n            writer = MigrationWriter(migrations.Migration('0001_initial', 'myapp'))\n            writer.serialize_field(MyModel._meta.get_field('my_field'))\n            self.assertIn(\"CustomField\", writer.output)\n"], "sample_483": ["    def test_list_filter_works_on_through_field_with_custom_model(self):\n        \"\"\"\n        Ensure list_filter can access reverse fields even when the app registry\n        is not ready; refs #24146.\n        \"\"\"\n\n        class CustomThroughModel(models.Model):\n            book = models.ForeignKey(Book, on_delete=models.CASCADE)\n            author = models.ForeignKey(Author, on_delete=models.CASCADE)\n            featured = models.BooleanField(default=False)\n\n        class BookAdminWithCustomThroughListFilter(admin.ModelAdmin):\n            list_filter = [\"authorsbooks__featured\"]\n\n        # Temporarily pretending apps are not ready yet. This issue can happen\n        # if the value of 'list_filter' refers to a 'through__field'.\n        Book._meta.apps.ready = False\n        try:\n            errors = BookAdminWithCustomThroughListFilter(Book, AdminSite()).check()\n            self.assertEqual(errors, [])\n        finally:\n            Book._meta.apps.ready = True\n"], "sample_1117": ["def test_matrix_element_sets_mat_mul():\n    X = MatrixSymbol('X', 3, 3)\n    Y = MatrixSymbol('Y', 3, 3)\n    assert ask(Q.integer_elements(X*Y), Q.integer_elements(X) & Q.integer_elements(Y))\n    assert ask(Q.real_elements(X*Y), Q.real_elements(X) & Q.real_elements(Y))\n    assert ask(Q.complex_elements(X*Y), Q.complex_elements(X) & Q.complex_elements(Y))\n"], "sample_1129": ["def test_sympy_printing_of_special_functions():\n    from sympy import (\n        erf, erfc, besselj, bessely, besseli, besselk,\n        digamma, loggamma, RisingFactorial,\n        eval_legendre, eval_chebyt, eval_chebyu, eval_gegenbauer,\n        eval_laguerre, eval_hermite,\n    )\n\n    prntr = SymPyPrinter()\n\n    assert prntr.doprint(erf(x)) == 'sympy.erf(x)'\n    assert prntr.doprint(erfc(x)) == 'sympy.erfc(x)'\n    assert prntr.doprint(besselj(x, y)) == 'sympy.special.besselj(x, y)'\n    assert prntr.doprint(bessely(x, y)) == 'sympy.special.bessely(x, y)'\n    assert prntr.doprint(besseli(x, y)) == 'sympy.special.besseli(x, y)'\n    assert prntr.doprint(besselk(x, y)) == 'sympy.special.besselk(x, y)'\n    assert prntr.doprint(digamma(x)) == 'sympy.psi(x)'\n    assert prntr.doprint(loggamma(x)) == 'sympy.loggamma(x)'\n    assert prntr.doprint(RisingFactorial(x, y)) == 'sympy.rising_factorial(x, y)'\n    assert prntr.doprint(eval_legendre(x, y)) == 'sympy.legendre(x, y)'\n    assert prntr.doprint(eval_chebyt(x, y)) == 'sympy.chebyt(x, y)'\n    assert prntr.doprint(eval_chebyu(x, y)) == 'sympy.chebyu(x, y)'\n    assert prntr.doprint(eval_gegenbauer(x, y)) == 'sympy.gegenbauer(x, y)'\n    assert prntr.doprint(eval_laguerre(x, y)) == 'sympy.laguerre(x, y)'\n    assert prntr."], "sample_274": ["    def test_modelchoicefield_empty_label(self):\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(), empty_label=None)\n        self.assertFormErrors(['INVALID CHOICE'], f.clean, '')\n"], "sample_631": ["    def test_unused_variable_in_lambda(self):\n        \"\"\"Ensure unused variables in lambdas are flagged.\"\"\"\n        node = astroid.parse(\n            \"\"\"\n            lambda x: x + 1\n        \"\"\"\n        )\n        with self.assertAddsMessages(\n            Message(\"unused-variable\", node=node.body[0].args[0], args=\"x\")\n        ):\n            self.walk(node)\n"], "sample_925": ["def test_mock_inheritance():\n    with mock(['sphinx.unknown.module']):\n        class SubClass(object):\n            pass\n\n        assert SubClass.__module__ == 'sphinx.unknown.module'\n        assert SubClass.__qualname__ == 'sphinx.unknown.module.SubClass'\n\n        class SubSubClass(SubClass):\n            pass\n\n        assert SubSubClass.__module__ == 'sphinx.unknown.module'\n        assert SubSubClass.__qualname__ == 'sphinx.unknown.module.SubSubClass'\n"], "sample_857": ["def test_prune_tree_with_sparse_data():\n    X = csc_matrix(np.random.RandomState(0).random_sample((100, 11)))\n    y = np.random.RandomState(0).random_sample(100)\n\n    clf = DecisionTreeRegressor(max_leaf_nodes=20, random_state=0)\n    info = clf.cost_complexity_pruning_path(X, y)\n\n    pruning_path = info.ccp_alphas\n    impurities = info.impurities\n    assert np.all(np.diff(pruning_path) >= 0)\n    assert np.all(np.diff(impurities) >= 0)\n\n    assert_pruning_creates_subtree(DecisionTreeRegressor, X, y, pruning_path)\n"], "sample_1005": ["def test_issue_14623():\n    from sympy.physics.quantum import Dagger\n    a = Symbol('a')\n    b = Symbol('b')\n    assert latex(Dagger(a*b)) == r\"\\left(a b\\right)^{\\dagger}\"\n"], "sample_356": ["    def test_operation_with_no_suggested_name_and_initial_true(self):\n        class Migration(migrations.Migration):\n            initial = True\n            operations = [migrations.RunSQL('SELECT 1 FROM person;')]\n\n        migration = Migration('0001_initial', 'test_app')\n        self.assertEqual(migration.suggest_name(), 'initial')\n"], "sample_837": ["def test_show_versions_missing_dep():\n    import unittest\n    from unittest.mock import patch\n    from sklearn.utils._show_versions import _get_deps_info, show_versions\n\n    class MockModule:\n        __version__ = None\n\n    with patch('sklearn.utils._show_versions.importlib.import_module',\n               side_effect=ImportError):\n        with patch('sklearn.utils._show_versions._get_deps_info',\n                   return_value={'pip': '10.0', 'missing_dep': None}):\n            show_versions()\n            deps_info = _get_deps_info()\n\n            assert 'missing_dep' in deps_info\n            assert deps_info['missing_dep'] is None\n"], "sample_1038": ["def test_matrix_subs():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    x = symbols('x')\n\n    assert (A + B).subs(A, C) == C + B\n    assert (A + B).subs({A: C, B: C}) == C + C\n    assert (A*B).subs(A, C) == C*B\n    assert (A*B).subs({A: C, B: C}) == C*C\n    assert (A*B).subs(B, x*C) == A*(x*C)\n    assert (A*B).subs({A: C, B: x*C}) == C*(x*C)\n    assert (A + B).subs(x, 2) == A + B\n    assert (A*B).subs(x, 2) == A*B\n    assert (A + B).subs({A: C, B: x*C}, x=2) == C + 2*C\n    assert (A*B).subs({A: C, B: x*C}, x=2) == C*(2*C)\n    assert (A + B).subs({A: C, B: x*C}, x=2).doit() == C + 2*C\n    assert (A*B).subs({A: C, B: x*C}, x=2).doit() == C*(2*C)\n"], "sample_987": ["def test_issue_10401():\n    from sympy import symbols, sin, cos, pi\n    x, y = symbols('x y')\n    assert (sin(x) + cos(y)).evalf(subs={x: pi/2, y: pi/4}) == 1.7071067811865476\n    assert (sin(x) + cos(y)).evalf(subs={x: pi/4, y: pi/2}) == 1.7071067811865476\n"], "sample_626": ["compilation error"], "sample_297": ["    def test_ticket_24605_distinct_on_related_field(self):\n        \"\"\"\n        Subquery table names should be quoted when using distinct on related fields.\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        qs = Individual.objects.filter(\n            Q(alive=False),\n            Q(related_individual__isnull=True),\n            Q(related_individual__pk__in=RelatedIndividual.objects.distinct('related__pk'))\n        )\n        self.assertSequenceEqual(qs, [i4])\n"], "sample_722": ["def test_k_means_with_empty_data():\n    km = KMeans(n_clusters=2)\n    assert_raises(ValueError, km.fit, [])\n    assert_raises(ValueError, km.fit, np.array([]))\n    assert_raises(ValueError, km.fit, sp.csr_matrix([]))\n\n\n"], "sample_647": ["    def test_warning_classes_have_format_method(warning_class: UserWarning) -> None:\n        if not hasattr(warning_class, \"format\"):\n            pytest.skip(f\"{warning_class} does not have a format method\")\n        instance = warning_class(\"test message\")\n        assert isinstance(instance, warning_class)\n"], "sample_964": ["def test_warn_missing_reference_in_html(app, status, warning):\n    app.build()\n    assert 'index.html: WARNING: undefined label: no-label' in warning.getvalue()\n    assert ('index.html: WARNING: Failed to create a cross reference. A title or caption not found: existing-label'\n            in warning.getvalue())\n"], "sample_823": ["def test_pairwise_distances_with_precomputed():\n    # Test pairwise_distances with precomputed distances\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((10, 5))\n    D = pairwise_distances(X, metric='euclidean')\n    assert_array_almost_equal(pairwise_distances(X, D=D), D)\n    assert_array_almost_equal(pairwise_distances(X, D=D,\n                metric='euclidean'), D)\n    assert_array_almost_equal(pairwise_distances(X, D=D,\n                metric='manhattan'), D)\n\n    # Test with sparse input\n    X_sparse = csr_matrix(X)\n    D_sparse = pairwise_distances(X_sparse, metric='euclidean')\n    assert_array_almost_equal(pairwise_distances(X_sparse, D=D_sparse),\n                             D_sparse)\n\n    # Test with invalid precomputed distances\n    assert_raises(ValueError, pairwise_distances, X, D=np.zeros((10, 10)))\n    assert_raises(ValueError, pairwise_distances, X, D=np.ones((10, 10)))\n    assert_raises(ValueError, pairwise_distances, X, D=np.random.randn(10, 11))\n\n\n\n"], "sample_200": ["    def test_send_messages_with_connection_error(self):\n        \"\"\"\n        send_messages() should handle a connection error gracefully.\n        \"\"\"\n        self.backend.fail_silently = True\n        self.backend.open = lambda: None\n        email = EmailMessage('Subject', 'Content', 'from@example.com', ['to@example.com'])\n        with self.assertRaises(ConnectionError):\n            self.backend.send_messages([email])\n        self.assertEqual(len(self.server.get_sink()), 0)\n\n\n\n"], "sample_346": ["    def test_cache_control_decorator(self):\n        @cache_control(max_age=3600, public=True, must_revalidate=True)\n            return HttpResponse()\n        r = a_view(HttpRequest())\n        self.assertEqual(\n            set(r.headers['Cache-Control'].split(', ')),\n            {'max-age=3600', 'public', 'must-revalidate'},\n        )\n\n"], "sample_648": ["    def test_mark_mro_with_duplicate_marks(self) -> None:\n        xfail = pytest.mark.xfail\n\n        @xfail(\"a\")\n        class A:\n            pass\n\n        @xfail(\"a\")\n        class B:\n            pass\n\n        @xfail(\"b\")\n        class C(A, B):\n            pass\n\n        all_marks = get_unpacked_marks(C)\n\n        assert all_marks == [xfail(\"b\").mark, xfail(\"a\").mark]\n"], "sample_437": ["    def test_multi_database_connection_close(self):\n        for db in self.databases:\n            with self.subTest(database=db):\n                conn = connections[db]\n                conn.connection = MagicMock()\n                conn.close()\n                conn.connection.close.assert_called_once()\n\n\n\n"], "sample_938": ["def test_man_show_urls(app, status, warning):\n    app.build()\n    content = (app.outdir / 'python.1').read_text()\n    assert r'\\fBhttps://www.sphinx-doc.org\\fP' in content \n"], "sample_72": ["    def test_serialize_custom_field(self):\n        class MyCustomField(models.Field):\n                super().__init__(*args, **kwargs)\n\n                return 'MyCustomFieldType'\n\n                return 'MyCustomFieldType'\n\n                return super().formfield(**kwargs)\n\n        class MyModel(models.Model):\n            my_field = MyCustomField()\n\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.CreateModel(\"MyModel\", (\n                    ('id', models.AutoField(primary_key=True)),\n                    ('my_field', MyModel.my_field),\n                ), {})\n            ],\n            \"dependencies\": []\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\"MyCustomFieldType\", output)\n"], "sample_420": ["    def test_related_objects_are_not_included(self):\n        \"\"\"Related objects are not included in the dictionary representation.\"\"\"\n        item = ColourfulItem.objects.create()\n        item.colours.add(Colour.objects.create(name=\"blue\"))\n        data = model_to_dict(item)\n        self.assertNotIn(\"colours\", data)\n        self.assertNotIn(\"colour_set\", data)\n\n\n\n"], "sample_1064": ["def test_tensorflow_Piecewise():\n    if not tf:\n        skip(\"TensorFlow not installed\")\n\n    expr = Piecewise((x > 0, x**2, x <= 0, -x))\n    assert tensorflow_code(expr) == \\\n        \"tensorflow.where(tensorflow.math.greater(x, 0), tensorflow.math.pow(x, 2), -x)\"\n    _compare_tensorflow_scalar((x,), expr)\n"], "sample_27": ["    def test_fitsdiff_with_different_data_types(self):\n        path1 = self.temp(\"test1.fits\")\n        path2 = self.temp(\"test2.fits\")\n        a = np.arange(10).astype(\"int32\")\n        b = np.arange(10).astype(\"float32\")\n        hdu_a = PrimaryHDU(data=a)\n        hdu_b = PrimaryHDU(data=b)\n        hdu_a.writeto(path1)\n        hdu_b.writeto(path2)\n        diff = FITSDiff(path1, path2)\n        assert not diff.identical\n        assert \"Data types differ\" in diff.report()\n"], "sample_1057": ["compilation error"], "sample_573": ["    def test_order(self, df):\n\n        groupby = GroupBy([\"group\"])\n        res_order_1 = PolyFit(order=1)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n        res_order_2 = PolyFit(order=2)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n\n        for _, part in res_order_1.groupby(\"group\"):\n            assert part[\"y\"].diff().diff().dropna().abs().gt(0).all()\n\n        for _, part in res_order_2.groupby(\"group\"):\n            assert part[\"y\"].diff().diff().dropna().abs().gt(0).all()\n\n        assert_array_almost_equal(res_order_1[\"y\"].values.flatten(),\n                                 res_order_2[\"y\"].values.flatten())\n"], "sample_265": ["    def test_invalid_template_library(self):\n        with self.assertRaisesMessage(InvalidTemplateLibrary, \"Invalid template library specified. ImportError raised when trying to load 'nonexistent_library': No module named 'nonexistent_library'\"):\n            DjangoTemplates({\n                'DIRS': [],\n                'APP_DIRS': False,\n                'NAME': 'django',\n                'OPTIONS': {\n                    'libraries': {\n                        'nonexistent_library': 'nonexistent_library',\n                    },\n                },\n            })\n"], "sample_343": ["    def test_get_content_type(self):\n        question = Question.objects.create(text='test')\n        answer = Answer.objects.create(question=question)\n        self.assertEqual(Answer.question.get_content_type(), ContentType.objects.get_for_model(Question))\n"], "sample_147": ["    def test_union_with_subquery_ordering(self):\n        qs1 = Number.objects.filter(num__lte=1).order_by('num')\n        qs2 = Number.objects.filter(num__gte=2, num__lte=3).order_by('-num')\n        self.assertNumbersEqual(qs1.union(qs2).order_by('num'), [3, 2, 1, 0])\n\n"], "sample_1152": ["compilation error"], "sample_183": ["    def test_invalid_output_field_type(self):\n        with self.assertRaisesMessage(TypeError, \"Output field must be a Field or a callable\"):\n            Case(\n                When(Q(pk__gt=0), then=Value('1', output_field=str)),\n            )\n"], "sample_1058": ["def test_NumPyPrinter_print_CodegenArrayTensorProduct():\n    from sympy.codegen.array_utils import CodegenArrayTensorProduct\n    n = NumPyPrinter()\n    a = MatrixSymbol('a', 2, 2)\n    b = MatrixSymbol('b', 2, 2)\n    expr = CodegenArrayTensorProduct(a, b)\n    assert n.doprint(expr) == 'numpy.einsum(\"ij,kl->ikjl\", a, b)'\n"], "sample_465": ["    def test_get_queryset(self):\n        class BandAdmin(ModelAdmin):\n                return Band.objects.filter(name__startswith=\"The\")\n\n        self.site.register(Band, BandAdmin)\n        ma = self.site._registry[Band]\n        queryset = ma.get_queryset(MockRequest())\n        self.assertEqual(queryset.count(), 1)\n        self.assertEqual(queryset.first().name, \"The Doors\")\n"], "sample_406": ["    def test_refresh_from_db_with_related_objects(self):\n        article = Article.objects.create(\n            headline=\"Parrot programs in Python\",\n            pub_date=datetime(2005, 7, 28),\n        )\n        featured = FeaturedArticle.objects.create(article=article)\n        \n        # Check if related objects are fetched correctly\n        self.assertEqual(featured.article.headline, \"Parrot programs in Python\")\n\n        # Update the article headline\n        article.headline = \"Parrot programs in Python 2.0\"\n        article.save()\n\n        # Refresh the featured article to get the updated headline\n        featured.refresh_from_db()\n\n        # Verify the headline is updated in the related object\n        self.assertEqual(featured.article.headline, \"Parrot programs in Python 2.0\")\n"], "sample_759": ["compilation error"], "sample_948": ["compilation error"], "sample_756": ["def test_min_samples_influence(min_samples):\n    # Test that the number of samples required to be considered a core point\n    # influences the clustering results.\n    centers = [[1, 1], [-1, -1], [1, -1]]\n    X, labels_true = make_blobs(n_samples=750, centers=centers,\n                                cluster_std=0.4, random_state=0)\n\n    # Compute optics with varying min_samples\n    op1 = OPTICS(min_samples=min_samples).fit(X)\n    op2 = OPTICS(min_samples=min_samples + 1).fit(X)\n\n    # Check that the number of core points is different\n    assert len(op1.core_sample_indices_) < len(op2.core_sample_indices_)\n\n    # Check that the labels are different\n    assert_array_equal(op1.labels_, op2.labels_)\n\n"], "sample_122": ["    def test_cache_key_with_user_and_language(self):\n        request = self.factory.get(self.path)\n        user = User.objects.create_user(username='testuser', password='testpassword')\n        request.user = user\n        translation.activate('es')\n        template = engines['django'].from_string(\"This is a test\")\n        response = TemplateResponse(request, template)\n        key = get_cache_key(request)\n        self.assertEqual(key, 'views.decorators.cache.cache_page.settingsprefix.GET.user_testuser.lang_es.d41d8cd98f00b204e9800998ecf8427e')\n"], "sample_782": ["def test_column_transformer_sparse_remainder_with_fit_transform():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n    ct = ColumnTransformer([('trans1', StandardScaler(), [0])],\n                           remainder=SparseMatrixTrans(),\n                           sparse_threshold=0.8)\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n\n    #  SparseMatrixTrans creates 3 features for each column, thus:\n    assert X_trans.shape == (3, 3)\n    assert_array_equal(X_trans.toarray(), np.eye(3))\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], SparseMatrixTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n\n\n\n"], "sample_804": ["def test_one_hot_encoder_categorical_feature_names():\n    enc = OneHotEncoder(categories=[['a', 'b', 'c'], [1, 2, 3]],\n                        handle_unknown='ignore')\n    X = np.array([['a', 1], ['b', 2], ['c', 3]], dtype=object).T\n    enc.fit(X)\n    feature_names = enc.get_feature_names()\n    assert_array_equal(['x0_a', 'x0_b', 'x0_c', 'x1_1', 'x1_2', 'x1_3'],\n                        feature_names)\n"], "sample_1010": ["def test_issue_14687():\n    from sympy.tensor.tensor import Tensor\n    A = Tensor('A', (2, 3))\n    B = Tensor('B', (3, 1))\n    assert latex(A * B) == r\"A \\cdot B\"\n"], "sample_1048": ["compilation error"], "sample_1079": ["compilation error"], "sample_1044": ["def test_issue_10302_2():\n    x = Symbol('x')\n    r = Symbol('r', real=True)\n    u = -(3*2**pi)**(1/pi) + 2*3**(1/pi)\n    i = u + u*I\n    assert (u + i).is_zero is None\n    assert (1 + i).is_zero is False\n    a = Dummy('a', zero=True)\n    assert (a + I).is_zero is False\n    assert (a + r*I).is_zero is None\n    assert (a + I).is_imaginary\n    assert (a + x + I).is_imaginary is None\n    assert (a + r*I + I).is_imaginary is None\n"], "sample_805": ["    def test_tweedie_deviance_with_nan():\n        y_true = np.array([1, 2, np.nan, 4])\n        y_pred = np.array([1.5, 2.5, np.nan, 4.5])\n        with pytest.raises(ValueError, match=\"Target values cannot contain NaN\"):\n            mean_tweedie_deviance(y_true, y_pred, p=1)\n"], "sample_504": ["def test_colorbar_fraction():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.arange(100).reshape(10, 10))\n    cb = fig.colorbar(pc, ax=ax, fraction=0.1)\n    assert cb.ax.get_position().height == 0.1\n    cb = fig.colorbar(pc, ax=ax, fraction=0.2)\n    assert cb.ax.get_position().height == 0.2\n    cb = fig.colorbar(pc, ax=ax, fraction=0.5)\n    assert cb.ax.get_position().height == 0.5\n\n\n\n"], "sample_246": ["    def test_makemessages_with_invalid_locale(self):\n        with self.assertRaises(CommandError):\n            self.run_django_admin(['makemessages', '-l', 'invalid_locale', '-v', '0'])\n"], "sample_1102": ["def test_issue_19010():\n    p = Poly(x**2 + 1, x, domain='ZZ')\n    assert p.is_monic() is True\n    p = Poly(2*x**2 + 4*x + 2, x, domain='ZZ')\n    assert p.is_monic() is False\n    p = Poly(x**2 + 1, x, domain='QQ')\n    assert p.is_monic() is True\n    p = Poly(2*x**2 + 4*x + 2, x, domain='QQ')\n    assert p.is_monic() is False\n"], "sample_443": ["    def test_cache_key_with_user_and_language(self):\n        request = self.factory.get(self.path)\n        user = User(username=\"testuser\")\n        request.user = user\n        translation.activate(\"en\")\n        template = engines[\"django\"].from_string(\"This is a test\")\n        response = TemplateResponse(request, template)\n        key = get_cache_key(request)\n        self.assertIn(\"user_testuser\", key)\n        self.assertIn(\"lang_en\", key)\n"], "sample_301": ["    def test_snapshot_files_with_non_existing_files(self):\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.nonexistent_file]):\n            snapshot = dict(self.reloader.snapshot_files())\n            self.assertNotIn(self.nonexistent_file, snapshot)\n"], "sample_868": ["def test_empty_input(metric_name):\n    metric = SUPERVISED_METRICS[metric_name]\n    with pytest.raises(ValueError, match='Input arrays cannot be empty'):\n        metric([], [])\n    with pytest.raises(ValueError, match='Input arrays cannot be empty'):\n        metric([], [0, 1])\n"], "sample_788": ["def test_n_bins_with_constant_feature(strategy, expected_bin_edges):\n    X = np.array([[0, 1], [0, 2], [0, 3], [0, 4]]).reshape(-1, 2)\n    kbd = KBinsDiscretizer(n_bins=4, strategy=strategy, encode='ordinal')\n    kbd.fit(X)\n    assert_array_almost_equal(kbd.bin_edges_[0], expected_bin_edges)\n    assert_array_almost_equal(kbd.bin_edges_[1], [0, 1, 2, 3])\n"], "sample_121": ["    def test_check_constraints_with_custom_error_message(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(\n                        check=models.Q(age__gte=18),\n                        name='is_adult',\n                        error_message='You must be at least 18 years old.'\n                    )\n                ]\n\n        errors = Model.check()\n        self.assertEqual(len(errors), 0)\n\n"], "sample_358": ["    def test_rename_column_references_with_opclasses(self):\n        compiler = Person.objects.all().query.get_compiler(connection.alias)\n        self.expressions = Expressions(\n            table=Person._meta.db_table,\n            expressions=ExpressionList(\n                IndexExpression(F('first_name'), opclass='text_ops'),\n                IndexExpression(F('last_name').desc(), opclass='text_ops'),\n                IndexExpression(Upper('last_name'), opclass='text_ops'),\n            ).resolve_expression(compiler.query),\n            compiler=compiler,\n            quote_value=self.editor.quote_value,\n            col_suffixes=['_first', '_last', '_upper'],\n            opclasses=['text_ops', 'text_ops', 'text_ops'],\n        )\n        table = Person._meta.db_table\n        self.expressions.rename_column_references(table, 'first_name', 'other')\n        self.assertIs(self.expressions.references_column(table, 'other'), True)\n        self.assertIs(self.expressions.references_column(table, 'first_name'), False)\n        expected_str = (\n            '%s.other_first, %s.last_name_last DESC, '\n            '(UPPER(%s.last_name_upper))' % (\n                self.editor.quote_name(table),\n                self.editor.quote_name(table),\n                self.editor.quote_name(table),\n            )\n        )\n        self.assertEqual(str(self.expressions), expected_str)\n"], "sample_171": ["    def test_squashmigrations_empty_app_label(self):\n        with self.assertRaisesMessage(CommandError, \"App label cannot be empty.\"):\n            call_command('squashmigrations', '', '0002')\n"], "sample_435": ["    def test_password_too_short(self):\n        user = User.objects.get(username=\"testclient\")\n        data = {\"password1\": \"a\", \"password2\": \"a\"}\n        form = AdminPasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form.errors[\"password1\"],\n            [\n                \"This password is too short. It must contain at least 12 characters.\"\n            ],\n        )\n        self.assertEqual(form.errors[\"password2\"], [\n            \"This password is too short. It must contain at least 12 characters.\"\n        ])\n        self.assertEqual(form.changed_data, [])\n"], "sample_674": ["def test_prunetraceback_with_fulltrace(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import traceback\n\n            raise ValueError(\"some error\")\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--fulltrace\")\n    result.stdout.fnmatch_lines([str(p) + \":*: ValueError\", \"*1 failed in *\"])\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([str(p) + \":*: ValueError\", \"*1 failed in *\"])\n"], "sample_1141": ["def test_matrix_subs():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    D = MatrixSymbol('D', 2, 2)\n    x = symbols('x')\n    expr = A*B + C*D\n    assert expr.subs({A: x*B, C: x*D}) == x*B*B + x*D*D\n    assert expr.subs({A: x*B, C: x*D}).doit() == x*B*B + x*D*D\n    assert expr.subs({A: x*B, C: x*D}).subs({B: x*C, D: x*C}) == x**2*C*B + x**2*C*C\n    assert expr.subs({A: x*B, C: x*D}).subs({B: x*C, D: x*C}).doit() == x**2*C*B + x**2*C*C\n    assert expr.subs({A: x*B, C: x*D}).subs({B: x*C, D: x*C}).subs({C: x*D}) == x**3*D*B + x**3*D*D\n    assert expr.subs({A: x*B, C: x*D}).subs({B: x*C, D: x*C}).subs({C: x*D}).doit() == x**3*D*B + x**3*D*D\n    assert expr.subs({A: x*B, C: x*D}).subs({B: x*C, D: x*C}).subs({C: x*D}).subs({D: x*E}) == x**3*E*B + x**3*E*E\n    assert expr.subs({A: x*B, C: x*D}).subs({B: x*C, D: x*C}).subs({C: x*D}).subs({D: x*E}).doit() == x**3*E*B + x**3*E*E\n\n\n\n"], "sample_967": ["def test_mathjax_inline_custom(app, status, warning):\n    app.builder.build_all()\n\n    content = (app.outdir / 'index.html').read_text()\n    html = (r'<div class=\"math notranslate nohighlight\">\\s*'\n            r'\\[a\\^2\\+b\\^2=c\\^2\\]</div>')\n    assert re.search(html, content, re.S)\n"], "sample_973": ["compilation error"], "sample_531": ["def test_gridspec_kw_propagation():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1])\n\n    assert ax1.get_gridspec() is gs[0, 0]\n    assert ax2.get_gridspec() is gs[0, 1]\n\n    gs_new = fig.add_gridspec(2, 2)\n    ax3 = fig.add_subplot(gs_new[0, 0])\n\n    assert ax3.get_gridspec() is gs_new[0, 0]\n    assert ax1.get_gridspec() is gs[0, 0]\n    assert ax2.get_gridspec() is gs[0, 1]\n\n\n\n"], "sample_439": ["    def test_form_renderer_deprecation(self):\n        from django.forms.renderers import get_default_renderer\n        from django.forms.utils import DEFAULT_RENDERER_DEPRECATION_MSG\n\n        with isolate_lru_cache(get_default_renderer), self.settings(\n            FORM_RENDERER=\"django.forms.renderers.DjangoTemplates\"\n        ), self.assertRaisesMessage(\n            RemovedInDjango50Warning, DEFAULT_RENDERER_DEPRECATION_MSG\n        ):\n            form = Person()\n            get_default_renderer()\n"], "sample_958": ["def test_domain_cpp_parse_template_param_with_default(app, warning):\n    text = (\".. cpp:function:: void f(T t = 42)\\n\"\n            \"   :cpp:param: t\\n\")\n    restructuredtext.parse(app, text)\n    ws = warning.getvalue().split(\"\\n\")\n    assert len(ws) == 0\n"], "sample_286": ["    def test_refresh_from_db_with_related_objects(self):\n        article = Article.objects.create(headline='Article 1', pub_date=datetime.now())\n        comment = Comment.objects.create(article=article, content='First comment')\n        with self.assertNumQueries(1):\n            article.refresh_from_db(fields=['comments'])\n        self.assertEqual(article.comments.count(), 1)\n        self.assertEqual(article.comments.first().content, 'First comment')\n"], "sample_1053": ["def test_mod_with_zero():\n    assert 5 % 0 == 0\n    assert 0 % 5 == 0\n    assert (-5) % 0 == 0\n    assert 0 % (-5) == 0\n    raises(ZeroDivisionError, lambda: 5 / 0)\n    raises(ZeroDivisionError, lambda: 0 / 5)\n    raises(ZeroDivisionError, lambda: -5 / 0)\n    raises(ZeroDivisionError, lambda: 0 / -5)\n"], "sample_289": ["    def test_update(self):\n        self.dict1.update({'Content-Type': 'text/plain'})\n        self.assertEqual(self.dict1['Content-Type'], 'text/plain')\n        self.assertEqual(self.dict1['content-type'], 'text/plain')\n        self.assertEqual(self.dict1['CONTENT-TYPE'], 'text/plain')\n"], "sample_950": ["def test_warn_missing_reference_with_explicit_label(app, status, warning):\n    app.build()\n    assert 'index.rst:6: WARNING: undefined label: no-label' in warning.getvalue()\n    assert ('index.rst:6: WARNING: Failed to create a cross reference. A title or caption not found: existing-label'\n            in warning.getvalue())\n"], "sample_417": ["    def test_invalid_input(self):\n        self.assertEqual(floatformat(None), \"\")\n        self.assertEqual(floatformat(True), \"\")\n        self.assertEqual(floatformat(False), \"\")\n        self.assertEqual(floatformat([]), \"\")\n        self.assertEqual(floatformat({}), \"\")\n        self.assertEqual(floatformat(object()), \"\")\n"], "sample_399": ["    def test_aggregation_subquery_annotation_with_extra_where(self):\n        subquery_qs = Author.objects.extra(where=[\"age > 100\"])\n        authors = Author.objects.annotate(\n            count=Count(\"book\"),\n            exists=Exists(subquery_qs),\n        )\n        self.assertEqual(len(authors), 6)\n"], "sample_981": ["def test_inversion_vector():\n    p = Permutation([1, 5, 2, 0, 3, 6, 4])\n    assert p.inversion_vector() == [2, 4, 1, 3, 1, 0]\n    assert Permutation([0, 1, 2, 3]).inversion_vector() == [0, 0, 0, 0]\n    assert Permutation([3, 2, 1, 0]).inversion_vector() == [0, 1, 2, 3]\n    assert Permutation([0, 4, 1, 3, 2]).inversion_vector() == [1, 2, 0, 0, 0]\n    assert Permutation([0, 1, 2, 3, 4, 5]).inversion_vector() == [0, 0, 0, 0, 0, 0]\n    assert Permutation([5, 4, 3, 2, 1, 0]).inversion_vector() == [5, 4, 3, 2, 1, 0]\n    assert Permutation([]).inversion_vector() == []\n    assert Permutation([0]).inversion_vector() == []\n    assert Permutation([0, 1]).inversion_vector() == [0]\n    assert Permutation([0, 1, 2]).inversion_vector() == [1, 1]\n    assert Permutation([0, 1, 2, 3]).inversion_vector() == [3, 2, 1, 0]\n\n\n\n"], "sample_605": ["def test_groupby_multiple_groups():\n    ds = xr.Dataset(\n        {\n            \"foo\": ((\"x\", \"y\"), np.arange(12).reshape((3, 4))),\n            \"bar\": ((\"x\", \"y\"), np.arange(12).reshape((3, 4)) + 10),\n        },\n        coords={\"x\": [1, 2, 3], \"y\": [4, 5, 6, 7]},\n    )\n\n    grouped = ds.groupby([\"x\", \"y\"])\n\n    # Test that multiple groups are returned\n    assert len(grouped) == 12\n\n    # Test that each group has the correct data\n    for i in range(12):\n        x = (i // 4) + 1\n        y = (i % 4) + 4\n        expected_foo = ds.foo[ds.x == x, ds.y == y]\n        expected_bar = ds.bar[ds.x == x, ds.y == y]\n        actual_foo = grouped[f\"({x}, {y})\"][\"foo\"]\n        actual_bar = grouped[f\"({x}, {y})\"][\"bar\"]\n        assert_identical(expected_foo, actual_foo)\n        assert_identical(expected_bar, actual_bar)\n\n    # Test that we can access groups by label\n    grouped_by_label = grouped.get_group((1, 4))\n    assert_identical(grouped_by_label[\"foo\"], ds.foo[ds.x == 1, ds.y == 4])\n\n    grouped_by_label = grouped.get_group((1, 4))\n    assert_identical(grouped_by_label[\"bar\"], ds.bar[ds.x == 1, ds.y == 4])\n\n\n\n"], "sample_600": ["def test_unsigned_integer_coder_roundtrip_with_fill_value(dtype):\n    original = xr.Variable(\n        (\"x\",), np.arange(10, dtype=dtype), encoding={\"dtype\": dtype, \"_FillValue\": 127}\n    )\n    coder = variables.UnsignedIntegerCoder()\n    roundtripped = coder.decode(coder.encode(original))\n    assert_identical(original, roundtripped)\n"], "sample_146": ["    def test_invalid_variant_language_settings(self):\n        msg = (\n            'You have provided a value for the LANGUAGE_CODE setting that is '\n            'not in the LANGUAGES setting.'\n        )\n        for tag in ['fr-US', 'es-418', 'de-at', 'ca-ES-valencia']:\n            with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n                self.assertEqual(check_language_settings_consistent(None), [\n                    Error(msg, id='translation.E004'),\n                ])\n"], "sample_1108": ["compilation error"], "sample_98": ["    def test_redirect_with_query_string(self):\n        with self.urlopen('/redirect_with_query_string/?q=test') as f:\n            self.assertEqual(f.read(), b'Redirected')\n"], "sample_1030": ["def test_intersection_with_circles():\n    c1 = Circle((0, 0), 1)\n    c2 = Circle((2, 0), 1)\n    assert intersection(c1, c2) == [Point2D(1, 0)]\n    assert intersection(c1, c2, pairwise=True) == [Point2D(1, 0), Point2D(1, 0)]\n    c3 = Circle((1, 0), 1)\n    assert intersection(c1, c2, c3) == [Point2D(1, 0)]\n    assert intersection(c1, c2, c3, pairwise=True) == [Point2D(1, 0), Point2D(1, 0)]\n    c4 = Circle((0, 0), 2)\n    assert intersection(c1, c4) == [Point2D(0, 0), Point2D(0, 0)]\n    assert intersection(c1, c4, pairwise=True) == [Point2D(0, 0), Point2D(0, 0)]\n    c5 = Circle((0, 0), 0.5)\n    assert intersection(c1, c5) == []\n    assert intersection(c1, c5, pairwise=True) == []\n    c6 = Circle((0, 0), 1.5)\n    assert intersection(c1, c6) == [Point2D(0, 0), Point2D(0, 0)]\n    assert intersection(c1, c6, pairwise=True) == [Point2D(0, 0), Point2D(0, 0)]\n\n\n\n"], "sample_11": ["compilation error"], "sample_512": ["def test_subplot_projection_reuse_with_kwargs():\n    # test that subplot with projection reuse works with kwargs\n    fig = plt.figure()\n    ax1 = plt.subplot(111, projection='polar')\n    ax2 = plt.subplot(111, projection='polar', theta_offset=45)\n    assert ax1 is ax2\n    ax1.remove()\n    ax3 = plt.subplot(111, projection='polar', theta_offset=45,\n                      label='test')\n    assert ax3 is not ax1\n    assert ax3.name == 'polar'\n    assert ax3.get_label() == 'test'\n"], "sample_708": ["def test_getstatement_with_docstring() -> None:\n    source = \"\"\"\\"], "sample_339": ["    def test_modelformset_factory_with_custom_queryset(self):\n        class CustomAuthorFormSet(modelformset_factory):\n                return Author.objects.filter(name__startswith='C')\n\n        formset = CustomAuthorFormSet()\n        self.assertEqual(len(formset.forms), 1)\n        self.assertEqual(formset.forms[0].instance.name, 'Charles Baudelaire')\n"], "sample_429": ["    def test_validate_integer_with_negative_values(self):\n        for value in [-10, -1, 0, 1, 10]:\n            with self.subTest(value=value):\n                self.assertEqual(validate_integer(value), value)\n"], "sample_1181": ["def test_scipy_log_gamma():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    f = lambdify((a,), scipy.special.gammaln(a), 'numpy')\n    assert abs(f(1.5) - 0.5 * np.log(4) + np.log(np.sqrt(np.pi))) < 1e-16\n"], "sample_840": ["compilation error"], "sample_41": ["def test_unit_with_custom_format():\n    class MyUnit(u.UnitBase):\n            super().__init__(name, format_name=format_name)\n\n    my_unit = MyUnit('my_unit', format_name='custom')\n    assert my_unit.get_format_name() == 'custom'\n"], "sample_238": ["    def test_aggregation_subquery_annotation_with_distinct(self):\n        distinct_books_qs = Book.objects.filter(\n            publisher=OuterRef('pk')\n        ).values('name').annotate(\n            distinct_count=Count('id', distinct=True)\n        )\n        publisher_qs = Publisher.objects.annotate(\n            distinct_book_count=Subquery(distinct_books_qs),\n        ).values('name', 'distinct_book_count').order_by('name')\n        self.assertEqual(list(publisher_qs), [\n            {'name': 'Apress', 'distinct_book_count': 1},\n            {'name': 'Morgan Kaufmann', 'distinct_book_count': 1},\n            {'name': \"Jonno's House of Books\", 'distinct_book_count': 1},\n            {'name': 'Prentice Hall', 'distinct_book_count': 1},\n            {'name': 'Sams', 'distinct_book_count': 1},\n        ])\n"], "sample_7": ["def test_masked_column_copy():\n    mc = table.MaskedColumn([1, 2, 3], mask=[True, False, True])\n    mc2 = mc.copy()\n    assert mc2.data is not mc.data\n    assert mc2.mask is not mc.mask\n    assert np.all(mc2.data == mc.data)\n    assert np.all(mc2.mask == mc.mask)\n\n    mc2[0] = np.ma.masked\n    assert not np.all(mc.mask == mc2.mask)\n"], "sample_679": ["    def test_parametrize_with_invalid_marker_name(testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.invalid_marker\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines(\n            [\n                \"ERROR: Unknown marker 'invalid_marker' in test function 'test_func'\",\n            ]\n        )\n        assert result.ret == ExitCode.ERROR\n"], "sample_24": ["    def test_nanmedian_with_masked_array(self):\n        self.check(np.nanmedian, masked_result=True)\n        a = np.array([1, 2, np.nan, 4, 5])\n        mask = np.array([False, False, True, False, False])\n        ma = Masked(a, mask=mask)\n        expected = np.nanmedian(a)\n        result = np.nanmedian(ma)\n        assert_array_equal(result.unmasked, expected)\n        assert_array_equal(result.mask, np.array([False, False, True, False, False]))\n"], "sample_978": ["def test_bspline_basis_with_non_integer_knots():\n    d = 2\n    knots = [0.5, 1.5, 2.5, 3.5]\n    splines = bspline_basis_set(d, knots, x)\n    b0 = Piecewise((x**2/2 - x + 0.25, Interval(0.5, 1.5).contains(x)),\n                   (Rational(-3, 2) + 3*x - x**2, Interval(1.5, 2.5).contains(x)),\n                   (Rational(9, 2) - 3*x + x**2/2, Interval(2.5, 3.5).contains(x)),\n                   (0, True))\n    assert splines[0] == b0\n"], "sample_226": ["    def test_serialization_with_non_serializable_fields(self):\n        # serialize_db_to_string() handles fields that are not serializable.\n        obj = Object.objects.create(\n            text_field='This is a test',\n            binary_field=b'Some binary data'\n        )\n        with mock.patch('django.db.migrations.loader.MigrationLoader') as loader:\n            # serialize_db_to_string() serializes only migrated apps, so mark\n            # the backends app as migrated.\n            loader_instance = loader.return_value\n            loader_instance.migrated_apps = {'backends'}\n            data = connection.creation.serialize_db_to_string()\n        Object.objects.all().delete()\n        connection.creation.deserialize_db_from_string(data)\n        deserialized_obj = Object.objects.get()\n        self.assertEqual(deserialized_obj.text_field, 'This is a test')\n        self.assertEqual(deserialized_obj.binary_field, b'Some binary data')\n"], "sample_560": ["def test_loc_validation_invalid_string_value():\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError, match=\"'invalid' is not a valid value for\"):\n        ax.legend(loc='invalid')\n"], "sample_625": ["def test_cross_2d(a, b, ae, be, dim: str, axis: int, use_dask: bool) -> None:\n    expected = np.cross(ae, be, axis=axis)\n\n    if use_dask:\n        if not has_dask:\n            pytest.skip(\"test for dask.\")\n        a = a.chunk()\n        b = b.chunk()\n\n    actual = xr.cross(a, b, dim=dim)\n    xr.testing.assert_duckarray_allclose(expected, actual)\n"], "sample_114": ["    def test_mti_inheritance_model_removal_with_fk(self):\n        \"\"\"\n        #23316 - Removing an MTI model with a FK to a non-deleted parent\n        model should work.\n        \"\"\"\n        Owner = ModelState('app', 'Owner', [\n            (\"id\", models.AutoField(primary_key=True)),\n        ])\n        Pet = ModelState('app', 'Pet', [], bases=('app.Owner',))\n        changes = self.get_changes([Owner, Pet], [Owner])\n        self.assertNumberMigrations(changes, 'app', 1)\n        self.assertOperationTypes(changes, 'app', 0, ['DeleteModel'])\n        self.assertOperationAttributes(changes, 'app', 0, 0, name='Pet')\n"], "sample_1046": ["compilation error"], "sample_32": ["    def test_de_density_scale_units(self, cosmo):\n        \"\"\"Test that `de_density_scale` returns a Quantity with the correct units.\"\"\"\n        assert cosmo.de_density_scale(z).unit == u.one\n"], "sample_962": ["def test_stringify_type_hints_TypedDict():\n    from typing import TypedDict  # type: ignore\n    MyTypedDict = TypedDict('MyTypedDict', {'a': int, 'b': str})\n    assert stringify(MyTypedDict) == \"TypedDict['MyTypedDict', {'a': int, 'b': str}]\"\n"], "sample_911": ["compilation error"], "sample_206": ["    def test_file_field_storage_override(self):\n        class CustomStorage(Storage):\n                return open(os.path.join(self.location, name), mode)\n\n        class MyDocument(models.Model):\n            myfile = models.FileField(storage=CustomStorage())\n\n        with TemporaryUploadedFile('foo.txt', 'text/plain', 1, 'utf-8') as tmp_file:\n            MyDocument.objects.create(myfile=tmp_file)\n            self.assertTrue(os.path.exists(os.path.join(temp.gettempdir(), 'foo.txt')))\n"], "sample_205": ["    def test_update_error_dict(self):\n        error_dict = {}\n        exception = ValidationError(error_dict)\n        self.assertEqual(error_dict, {})\n\n        error_dict = {'field1': ['E1', 'E2']}\n        exception = ValidationError(error_dict)\n        self.assertEqual(error_dict, {'field1': ['E1', 'E2']})\n\n        exception.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {'field1': ['E1', 'E2']})\n\n        error_dict = {'field2': ['E3', 'E4']}\n        exception = ValidationError(error_dict)\n        self.assertEqual(error_dict, {'field2': ['E3', 'E4']})\n\n        exception.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {'field1': ['E1', 'E2'], 'field2': ['E3', 'E4']})\n\n        error_dict = {'field1': ['E5', 'E6']}\n        exception = ValidationError(error_dict)\n        self.assertEqual(error_dict, {'field1': ['E5', 'E6']})\n\n        exception.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {'field1': ['E1', 'E2', 'E5', 'E6'], 'field2': ['E3', 'E4']})\n\n        error_dict = {}\n        exception = ValidationError(error_dict)\n        self.assertEqual(error_dict, {})\n\n        exception.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {'field1': ['E1', 'E2', 'E5', 'E6'], 'field2': ['E3', 'E4']})\n\n        exception.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {'field1': ['E1', 'E2', 'E5', 'E6'], 'field2': ['E3', 'E4']})\n\n        error_dict = {'__all__': ['E7', 'E8']}\n        exception = ValidationError(error_dict)\n        self"], "sample_694": ["def test_deprecated_argument_type_str_choice(pytester: Pytester) -> None:\n    with pytest.warns(\n        pytest.PytestRemovedIn8Warning,\n        match=re.escape(\n            \"`type` argument to addoption() is the string {typ!r}, \"\n            \"but when supplied should be a type (for example `str` or `int`). \"\n            \"(options: {names})\"\n        ),\n    ) as record:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n                parser.addoption(\n                    \"--foo\",\n                    type=\"str\",\n                    choices=[\"a\", \"b\", \"c\"],\n                )\n            \"\"\"\n        )\n        pytester.runpytest()\n    assert len(record) == 1\n"], "sample_1071": ["def test_quantity_simplify_with_functions():\n    from sympy.physics.units.util import quantity_simplify\n    from sympy.physics.units import meter, second, kilogram, newton, sin, sqrt\n\n    assert quantity_simplify(sin(meter)) == sin(meter)\n    assert quantity_simplify(sqrt(meter)) == sqrt(meter)\n    assert quantity_simplify(meter * sin(meter)) == meter * sin(meter)\n    assert quantity_simplify(sqrt(meter) * kilogram) == sqrt(meter)*kilogram\n    assert quantity_simplify(newton * sqrt(meter)) == newton * sqrt(meter)\n"], "sample_1182": ["compilation error"], "sample_104": ["    def test_file_change_after_collectstatic_with_import(self):\n        # Create initial static files.\n        file_contents = (\n            ('foo.png', 'foo'),\n            ('bar.css', 'url(\"foo.png\")\\n@import \"baz.css\";'),\n            ('baz.css', 'url(\"foo.png\")'),\n            ('xyz.png', 'xyz'),\n        )\n        for filename, content in file_contents:\n            with open(self._get_filename_path(filename), 'w') as f:\n                f.write(content)\n\n        with self.modify_settings(STATICFILES_DIRS={'append': self._temp_dir}):\n            finders.get_finder.cache_clear()\n            err = StringIO()\n            # First collectstatic run.\n            call_command('collectstatic', interactive=False, verbosity=0, stderr=err)\n            relpath = self.hashed_file_path('test/bar.css')\n            with storage.staticfiles_storage.open(relpath) as relfile:\n                content = relfile.read()\n                self.assertIn(b'foo.acbd18db4cc2.png', content)\n                self.assertIn(b'baz.d16fb36f0911.css', content)\n\n            # Change the contents of the png files.\n            for filename in ('foo.png', 'xyz.png'):\n                with open(self._get_filename_path(filename), 'w+b') as f:\n                    f.write(b\"new content of file to change its hash\")\n\n            # The hashes of the png files in the CSS file are updated after\n            # a second collectstatic.\n            call_command('collectstatic', interactive=False, verbosity=0, stderr=err)\n            relpath = self.hashed_file_path('test/bar.css')\n            with storage.staticfiles_storage.open(relpath) as relfile:\n                content = relfile.read()\n                self.assertIn(b'foo.57a5cb9ba68d.png', content)\n                self.assertIn(b'baz.57a5cb9ba68d.css"], "sample_1023": ["def test_totient_and_reduced_totient():\n    assert totient(1) == 1\n    assert totient(2) == 1\n    assert totient(3) == 2\n    assert totient(4) == 2\n    assert totient(5) == 4\n    assert totient(6) == 2\n    assert totient(7) == 6\n    assert totient(8) == 4\n    assert totient(9) == 6\n    assert totient(10) == 4\n    assert totient(11) == 10\n    assert totient(12) == 4\n    assert totient(13) == 12\n    assert totient(14) == 6\n    assert totient(15) == 8\n    assert totient(16) == 8\n    assert totient(17) == 16\n    assert totient(18) == 6\n    assert totient(19) == 18\n    assert totient(20) == 8\n    assert totient(21) == 12\n    assert totient(22) == 10\n    assert totient(23) == 22\n    assert totient(24) == 8\n    assert totient(25) == 20\n    assert totient(26) == 12\n    assert totient(27) == 18\n    assert totient(28) == 12\n    assert totient(29) == 28\n    assert totient(30) == 8\n    assert totient(31) == 30\n    assert totient(32) == 16\n    assert totient(33) == 20\n    assert totient(34) == 16\n    assert totient(35) == 24\n    assert totient(36) == 12\n    assert totient(37) == 36\n    assert totient(38) == 18\n    assert totient(39) == 24\n    assert totient(40) == 16\n    assert"], "sample_336": ["    def test_lookahead_and_lookbehind_with_other_patterns(self):\n        test_urls = [\n            ('/lookahead-/a-city/other', '/lookahead-/a-city/other'),\n            ('/lookbehind-/a-city/other', '/lookbehind-/a-city/other'),\n            ('/lookahead+/a-city/other', '/lookahead+/a-city/other'),\n            ('/lookbehind+/a-city/other', '/lookbehind+/a-city/other'),\n        ]\n        for test_url in test_urls:\n            with self.subTest(url=test_url):\n                self.assertEqual(resolve(test_url).kwargs, {'city': 'a-city'})\n"], "sample_244": ["    def test_all_valid_with_non_form_errors(self):\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '0',\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': '0',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '1',\n        }\n        ChoiceFormSet = formset_factory(Choice, validate_max=True)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [\n            {'__all__': ['This is a non-form error.']},\n            {'__all__': ['This is a non-form error.']},\n        ]\n        formset1._errors = expected_errors\n        formset2._errors = expected_errors\n        self.assertIs(all_valid((formset1, formset2)), False)\n"], "sample_474": ["    def test_concat_null(self):\n        authors = Author.objects.annotate(\n            name_with_null=Concat(\"name\", Value(None))\n        )\n        self.assertCountEqual(\n            authors.filter(name_with_null__isnull=True),\n            [self.john, self.elena, self.rhonda],\n        )\n"], "sample_655": ["def test_capture_with_encoding_errors(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import sys\n            sys.stdout.encoding = 'ascii'\n            sys.stderr.encoding = 'ascii'\n            sys.stdout.write(b'\\xe9')\n            sys.stderr.write(b'\\xe9')\n    \"\"\"\n    )\n    result = testdir.runpytest_subprocess()\n    result.stdout.fnmatch_lines(\n        \"\"\"\n        *test_encoding_errors*\n        *UnicodeEncodeError*\n        *UnicodeEncodeError*\n    \"\"\"\n    )\n\n\n\n"], "sample_833": ["def test_LogisticRegression_fit_intercept_with_intercept_scaling(penalty):\n    # Test that fit_intercept=False works as expected with intercept scaling\n    # in LogisticRegression.\n    X, y = make_classification(n_samples=100, random_state=0)\n    intercept_scaling = 1.5\n    lr = LogisticRegression(penalty=penalty, solver='saga',\n                            fit_intercept=False,\n                            intercept_scaling=intercept_scaling,\n                            random_state=0)\n    lr.fit(X, y)\n    assert lr.intercept_ is None\n    assert lr.coef_.shape == (1, X.shape[1])  # Assuming binary classification\n\n    # Check that intercept scaling is applied correctly\n    lr_with_intercept = LogisticRegression(penalty=penalty, solver='saga',\n                                          fit_intercept=True,\n                                          intercept_scaling=intercept_scaling,\n                                          random_state=0)\n    lr_with_intercept.fit(X, y)\n    assert lr_with_intercept.intercept_ is not None\n    assert lr_with_intercept.intercept_ == intercept_scaling * lr.coef_[0, 0]\n\n\n\n"], "sample_734": ["def test_fowlkes_mallows_score_empty_arrays():\n    # Test for empty arrays\n    assert_equal(fowlkes_mallows_score([], []), 0.0)\n    assert_equal(fowlkes_mallows_score([0], []), 0.0)\n    assert_equal(fowlkes_mallows_score([], [0]), 0.0)\n"], "sample_320": ["    def test_references_field_by_related_name(self):\n        operation = FieldOperation(\n            \"Model\",\n            \"field\",\n            models.ForeignKey(\"Other\", models.CASCADE, related_name=\"related_name\"),\n        )\n        self.assertIs(\n            operation.references_field(\"Other\", \"related_name\", \"migrations\"), True\n        )\n        self.assertIs(\n            operation.references_field(\"Other\", \"whatever\", \"migrations\"), False\n        )\n\n\n\n"], "sample_692": ["compilation error"], "sample_52": ["    def test_empty_label_with_no_choices(self):\n        f = forms.ModelChoiceField(queryset=Category.objects.none(), empty_label='---------')\n        self.assertEqual(list(f.choices), [('', '---------')])\n        with self.assertRaises(ValidationError):\n            f.clean('')\n"], "sample_772": ["def test_sparse_input_with_oob_score(name):\n    X, y = datasets.make_multilabel_classification(random_state=0,\n                n_samples=50)\n    X_sparse = csr_matrix(X)\n    ForestEstimator = FOREST_ESTIMATORS[name]\n    est = ForestEstimator(n_estimators=1, max_depth=2, random_state=0,\n                          bootstrap=True, oob_score=True)\n    est.fit(X_sparse, y)\n    assert hasattr(est, 'oob_score_')\n\n\n\n"], "sample_1204": ["compilation error"], "sample_196": ["    def test_explain_query_prefix_raise_not_supported_error(self):\n        msg = 'This backend does not support explaining query execution.'\n        with self.assertRaisesMessage(NotSupportedError, msg):\n            connection.ops.explain_query_prefix()\n"], "sample_303": ["    def test_runshell_with_settings(self):\n        with mock.patch('subprocess.run') as run:\n            with mock.patch.object(\n                BaseDatabaseClient,\n                'settings_to_cmd_args_env',\n                return_value=([], {'KEY': 'VALUE'}),\n            ):\n                self.client.runshell(None)\n            run.assert_called_once_with([], env={'KEY': 'VALUE'}, check=True)\n"], "sample_636": ["    def test_duplicate_code_raw_strings_disable_scope_function_double(self) -> None:\n        \"\"\"Tests disabling duplicate-code at an inner scope level with another scope with similarity in two files.\"\"\"\n        path = join(DATA, \"raw_strings_disable_scope_function_double\")\n        self._runtest([path, \"--disable=all\", \"--enable=duplicate-code\"], code=0)\n"], "sample_733": ["def test_vectorizer_with_custom_analyzer():\n        return [word.upper() for word in text.split()]\n\n    vect = CountVectorizer(analyzer=custom_analyzer)\n    X = vect.fit_transform(JUNK_FOOD_DOCS)\n    assert_array_equal(\n        X.toarray(),\n        [[1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n         [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n         [1, 0, 0, 0, 0, 0, 1, 0, 0, 0]]\n    )\n"], "sample_893": ["def test_plot_tree_with_custom_colors():\n    clf = DecisionTreeClassifier(max_depth=2, random_state=0)\n    clf.fit(X, y)\n\n    # Test custom colors for nodes\n    colors = [\"red\", \"green\", \"blue\"]\n    nodes = plot_tree(clf, feature_names=[\"feature\"],\n                      node_colors=colors)\n    assert len(nodes) == 3\n    assert nodes[0].get_facecolor() == colors[0]\n    assert nodes[1].get_facecolor() == colors[1]\n    assert nodes[2].get_facecolor() == colors[2]\n\n\n\n"], "sample_892": ["def test_adaboost_with_sparse_data():\n    from sklearn.datasets import make_classification\n    from sklearn.ensemble import AdaBoostClassifier\n    from scipy.sparse import csr_matrix\n\n    X, y = make_classification(n_samples=100, n_features=10, random_state=42)\n    X_sparse = csr_matrix(X)\n\n    clf = AdaBoostClassifier(n_estimators=10, random_state=42)\n    clf.fit(X_sparse, y)\n    \n    # Check that predict works with sparse data\n    y_pred = clf.predict(X_sparse)\n    assert len(y_pred) == len(y)\n\n    # Check that predict_proba works with sparse data\n    y_proba = clf.predict_proba(X_sparse)\n    assert y_proba.shape == (len(y), 2)\n\n    # Check that decision_function works with sparse data\n    decision_values = clf.decision_function(X_sparse)\n    assert decision_values.shape == (len(y), )\n\n\n\n"], "sample_1061": ["def test_mod_inverse_with_zero():\n    raises(ValueError, lambda: mod_inverse(0, 5))\n    raises(ValueError, lambda: mod_inverse(0, 0))\n"], "sample_471": ["    def test_integerfield_empty_values(self):\n        f = IntegerField()\n        self.assertEqual(None, f.clean(\"\"))\n        self.assertEqual(None, f.clean(None))\n        self.assertEqual(None, f.clean(0))\n        self.assertEqual(None, f.clean(\"0\"))\n        self.assertEqual(None, f.clean(\"0.0\"))\n\n\n\n"], "sample_983": ["compilation error"], "sample_767": ["def test_column_transformer_sparse_threshold_pandas():\n    pd = pytest.importorskip('pandas')\n    X_df = pd.DataFrame({'col1': [0, 1, 2], 'col2': [2, 4, 6]})\n    ct = ColumnTransformer([('trans', StandardScaler(), 'col1')],\n                           sparse_threshold=0.5)\n    X_trans = ct.fit_transform(X_df)\n    assert not sparse.issparse(X_trans)\n    assert_array_equal(X_trans[:, 0], StandardScaler().fit_transform(X_df['col1']))\n    assert_array_equal(X_trans[:, 1], X_df['col2'].values)\n\n    ct = ColumnTransformer([('trans', StandardScaler(), 'col1')],\n                           sparse_threshold=0.9)\n    X_trans = ct.fit_transform(X_df)\n    assert sparse.issparse(X_trans)\n    assert_array_equal(X_trans.toarray()[:, 0], StandardScaler().fit_transform(X_df['col1']))\n    assert_array_equal(X_trans.toarray()[:, 1], X_df['col2'].values)\n\n\n\n"], "sample_673": ["    def test_is_setup_py_empty(tmpdir):\n        setup_py = tmpdir.join(\"setup.py\")\n        setup_py.write('')\n        assert not _is_setup_py(setup_py)\n"], "sample_971": ["def test_log_collector(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    with logging.LogCollector() as collector:\n        logger.info('message1')\n        logger.warning('message2')\n        logger.error('message3')\n\n    assert len(collector.logs) == 3\n    assert 'message1' in collector.logs[0].msg\n    assert 'message2' in collector.logs[1].msg\n    assert 'message3' in collector.logs[2].msg\n"], "sample_1207": ["def test_issue_14080():\n    x = Symbol('x')\n    assert parse_expr('x + 1.234e-10', evaluate=False) == x + 1.234e-10\n"], "sample_482": ["    def test_safe_input(self):\n        output = self.engine.render_to_string(\"escapeseq_safe\", {\"a\": [mark_safe(\"x&y\"), mark_safe(\"<p>\")]})\n        self.assertEqual(output, \"x&amp;y, &lt;p&gt;\")\n"], "sample_812": ["def test_custom_repr_with_key_val_tuples():\n    class MyEstimator(BaseEstimator):\n            self.key_val_tuples = key_val_tuples\n\n            return f\"MyEstimator({self.key_val_tuples})\"\n\n    key_val_tuples = [('a', 1), ('b', 2), ('c', 3)]\n    estimator = MyEstimator(key_val_tuples)\n    expected = \"MyEstimator([('a', 1), ('b', 2), ('c', 3)])\"\n    assert estimator.__repr__() == expected\n"], "sample_1120": ["def test_matrix_element_subs():\n    A = MatrixSymbol('A', 3, 3)\n    B = MatrixSymbol('B', 3, 3)\n    C = MatrixSymbol('C', 3, 3)\n    assert A[0, 1].subs(A, B) == B[0, 1]\n    assert A[1, 2].subs(A, B).subs(B, C) == C[1, 2]\n    assert A[0, 1].subs(A, B).subs(B, C).subs(C, A) == A[0, 1]\n    assert A[0, 1].subs(A, B).subs(B, C).subs(C, A).subs(A, B) == B[0, 1]\n    assert A[0, 1].subs(A, B).subs(B, C).subs(C, A).subs(A, B).subs(B, C) == C[0, 1]\n\n    raises(TypeError, lambda: A[0, 1].subs(A, 1))\n    raises(TypeError, lambda: A[0, 1].subs(A, [1, 2]))\n    raises(TypeError, lambda: A[0, 1].subs(B, 1))\n    raises(TypeError, lambda: A[0, 1].subs(B, [1, 2]))\n"], "sample_683": ["def test_capture_with_encoding_errors(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import sys\n            sys.stdout.write(b\"\u00f6\")\n    \"\"\"\n    )\n    result = testdir.runpytest_subprocess()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines(\n        [\"*test_encoding_errors*\"]\n    )\n    result.stdout.no_fnmatch_line(\"*UnicodeEncodeError*\")\n"], "sample_580": ["def test_variable_type_mixed_dtype():\n    s = pd.Series([1, 2, \"a\", 3.0])\n    assert variable_type(s) == \"categorical\"\n"], "sample_913": ["def test_pyfunction_signature_with_args(app):\n    text = \".. py:function:: hello(a, *, b, c=1)\\n\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameter, desc_sig_name, \"a\"],\n                [desc_parameter, desc_sig_operator, \"*\"],\n                [desc_parameter, desc_sig_name, \"b\"],\n                [desc_parameter, desc_sig_name, \"c\", desc_sig_punctuation, \"=\"],\n                [nodes.inline, \"1\"])\n\n\n\n"], "sample_136": ["    def test_get_header_with_case_insensitive_lookup(self):\n        environ = {\n            'CONTENT_TYPE': 'text/html',\n            'CONTENT_LENGTH': '100',\n            'HTTP_HOST': 'example.com',\n            'HTTP_USER_AGENT': 'python-requests/1.2.0',\n        }\n        headers = HttpHeaders(environ)\n        self.assertEqual(headers.get('content-type'), 'text/html')\n        self.assertEqual(headers.get('user-agent'), 'python-requests/1.2.0')\n"], "sample_366": ["    def test_invalid_iso_8601(self):\n        test_values = (\n            ('P4Y2M', None),\n            ('P4Y2M3D', None),\n            ('P4Y2M3D1H', None),\n            ('P4Y2M3D1H1M', None),\n            ('P4Y2M3D1H1M1S.1', None),\n            ('P4Y2M3D1H1M1S.123456789', None),\n            ('P4Y2M3D1H1M1S.1234567890', None),\n            ('P4Y2M3D1H1M1S.12345678901', None),\n            ('P4Y2M3D1H1M1S.123456789012', None),\n            ('P4Y2M3D1H1M1S.1234567890123', None),\n            ('P4Y2M3D1H1M1S.12345678901234', None),\n            ('P4Y2M3D1H1M1S.123456789012345', None),\n            ('P4Y2M3D1H1M1S.1234567890123456', None),\n            ('P4Y2M3D1H1M1S.12345678901234567', None),\n            ('P4Y2M3D1H1M1S.123456789012345678', None),\n            ('P4Y2M3D1H1M1S.1234567890123456789', None),\n            ('P4Y2M3D1H1M1S.1234567890123456789"], "sample_1169": ["def test_issue_19661_commutator():\n    a = Symbol('0')\n    assert latex(Commutator(Bd(a)**2, B(a))\n                 ) == '- \\\\left[b_{0},{b^\\\\dagger_{0}}^{2}\\\\right]'\n"], "sample_26": ["compilation error"], "sample_706": ["def test_parentheses_precedence(expr: str, matcher: dict) -> None:\n    assert evaluate(expr, matcher)\n"], "sample_887": ["def test_calibration_with_invalid_method(data):\n    X, y = data\n    with pytest.raises(ValueError, match=\"Invalid method\"):\n        CalibratedClassifierCV(estimator=LogisticRegression(), method=\"invalid\").fit(X, y)\n"], "sample_716": ["def test_ridge_classifier_multiclass():\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5,\n                               n_classes=3, random_state=0)\n    ridge = RidgeClassifier()\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape[0], X.shape[1])\n    assert_equal(ridge.classes_.shape[0], 3)\n"], "sample_377": ["    def test_sensitive_post_parameters_method_decorator(self):\n        class MyClass:\n            @method_decorator(sensitive_post_parameters())\n                return HttpResponse()\n\n        instance = MyClass()\n        response = instance.a_view(HttpRequest())\n        self.assertEqual(response.status_code, 200)\n\n\n\n"], "sample_698": ["def test_coloredlogformatter_with_custom_colors() -> None:\n    logfmt = \"%(filename)-25s %(lineno)4d %(levelname)-8s %(message)s\"\n\n    record = logging.LogRecord(\n        name=\"dummy\",\n        level=logging.INFO,\n        pathname=\"dummypath\",\n        lineno=10,\n        msg=\"Test Message\",\n        args=(),\n        exc_info=None,\n    )\n\n    class CustomColorConfig:\n        class option:\n            log_color = \"red\"\n\n    tw = TerminalWriter()\n    tw.hasmarkup = True\n    formatter = ColoredLevelFormatter(tw, logfmt, color_config=CustomColorConfig)\n    output = formatter.format(record)\n    assert output == (\n        \"dummypath                   10 \\x1b[31mINFO    \\x1b[0m Test Message\"\n    )\n\n\n\n"], "sample_1158": ["def test_issue_21811():\n    a = sympify('x + y + z')\n    assert a.free_symbols == {x, y, z}\n    assert a.atoms(Symbol) == {x, y, z}\n    assert a.args == (x, y, z)\n"], "sample_633": ["def test_ignore_signatures_with_docstrings_fail() -> None:\n    output = StringIO()\n    with redirect_stdout(output), pytest.raises(SystemExit) as ex:\n        similar.Run([SIMILAR5, SIMILAR6])\n    assert ex.value.code == 0\n    assert (\n        output.getvalue().strip()\n        == (\n            f'''"], "sample_550": ["def test_toolmanager_set_active_tool():\n    with pytest.warns(UserWarning, match=_EXPECTED_WARNING_TOOLMANAGER):\n        plt.rcParams['toolbar'] = 'toolmanager'\n    fig = plt.gcf()\n    assert fig.canvas.manager.toolmanager.get_active_tool() is None\n    fig.canvas.manager.toolmanager.set_active_tool('pan')\n    assert fig.canvas.manager.toolmanager.get_active_tool() == 'pan'\n    with pytest.raises(ValueError, match=\"Tool 'foo' not found\"):\n        fig.canvas.manager.toolmanager.set_active_tool('foo')\n"], "sample_1040": ["def test_print_matrix_with_entries():\n    A = Matrix([[1, 2], [3, 4]])\n    assert mpp.doprint(A) == '<mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>3</mn></mtd><mtd><mn>4</mn></mtd></mtr></mtable>'\n    assert mp.doprint(A) == '<matrix><row><entry><cn>1</cn></entry><entry><cn>2</cn></entry></row><row><entry><cn>3</cn></entry><entry><cn>4</cn></entry></row></matrix>'\n"], "sample_1025": ["def test_print_matrix_operations():\n    p = NumPyPrinter()\n    A = MatrixSymbol(\"A\", 2, 2)\n    B = MatrixSymbol(\"B\", 2, 2)\n    C = MatrixSymbol(\"C\", 2, 2)\n    assert p.doprint(A + B) == 'A + B'\n    assert p.doprint(A - B) == 'A - B'\n    assert p.doprint(A * B) == 'A @ B'\n    assert p.doprint(A / B) == 'A / B'\n    assert p.doprint(A.T) == 'A.T'\n    assert p.doprint(A.inv()) == 'numpy.linalg.inv(A)'\n    assert p.doprint(A.det()) == 'numpy.linalg.det(A)'\n    assert p.doprint(A.trace()) == 'numpy.trace(A)'\n    assert p.doprint(A.reshape((1, 4))) == 'A.reshape((1, 4))'\n    assert p.doprint(A.dot(C)) == 'A.dot(C)'\n    assert p.doprint(A.transpose()) == 'A.T'\n    assert p.doprint(A.flatten()) == 'A.flatten()'\n    assert p.doprint(A.reshape((2, 2))) == 'A.reshape((2, 2))'\n"], "sample_1042": ["def test_Indexed_subs_with_multiple_indices():\n    A = IndexedBase(\"A\")\n    i, j, k = symbols(\"i,j,k\")\n    x, y, z = symbols(\"x,y,z\")\n    f = Function(\"f\")\n\n    assert Subs(A[i, j], A[i, j], x).diff(A[k, l]) == KroneckerDelta(i, k)*KroneckerDelta(j, l)\n    assert Subs(A[i, j], A[i, j], x).diff(A[k, l]).doit() == KroneckerDelta(i, k)*KroneckerDelta(j, l)\n    assert Subs(A[i, j], A[i, j], x).diff(A[k, l]).doit() == KroneckerDelta(i, k)*KroneckerDelta(j, l)\n    assert Subs(A[i, j], A[i, j], x).diff(A[k, l]).doit() == KroneckerDelta(i, k)*KroneckerDelta(j, l)\n    assert Subs(A[i, j], A[i, j], x).diff(A[k, l]).doit() == KroneckerDelta(i, k)*KroneckerDelta(j, l)\n    assert Subs(A[i, j], A[i, j], x).diff(A[k, l]).doit() == KroneckerDelta(i, k)*KroneckerDelta(j, l)\n    assert Subs(A[i, j], A[i, j], x).diff(A[k, l]).doit() == KroneckerDelta(i, k)*KroneckerDelta(j, l)\n    assert Subs(A[i, j], A[i, j], x).diff(A[k, l]).doit() == KroneckerDelta(i, k)*KroneckerDelta(j, l)\n    assert Subs(A[i, j], A[i, j], x).diff(A[k, l]).doit() == KroneckerDelta(i, k)*KroneckerDelta(j, l)\n    assert Subs(A[i, j], A[i, j], x).diff(A[k, l]).doit() == KroneckerDelta(i"], "sample_109": ["    def test_optgroups(self):\n        beatles = Band.objects.create(name='The Beatles', style='rock')\n        who = Band.objects.create(name='The Who', style='rock')\n        form = AlbumForm(initial={'band': beatles.pk})\n        output = form.as_table()\n        selected_option = '<option value=\"%s\" selected>The Beatles</option>' % beatles.pk\n        option = '<option value=\"%s\">The Who</option>' % who.pk\n        self.assertIn(selected_option, output)\n        self.assertNotIn(option, output)\n"], "sample_924": ["compilation error"], "sample_1018": ["    def test_fcode_If():\n        x = symbols('x')\n        assert fcode(If(x > 0, [x**2], [x**3]), source_format='free') == (\n            '      if (x > 0) then\\n'\n            '         x = x**2\\n'\n            '      else\\n'\n            '         x = x**3\\n'\n            '      end if'\n        )\n"], "sample_213": ["    def test_file_like_object_from_stringio(self):\n        \"\"\"\n        Test the File storage API with a file-like object coming from StringIO.\n        \"\"\"\n        content = \"This is a test file.\"\n        file_like_object = StringIO(content)\n        f = File(file_like_object)\n        stored_filename = self.storage.save(\"stringio_file.txt\", f)\n\n        with self.storage.open(stored_filename) as stored_file:\n            self.assertEqual(stored_file.read(), content)\n"], "sample_956": ["    def test_inventory_not_having_version_fallback(tempdir, app, status, warning):\n        inv_file = tempdir / 'inventory'\n        inv_file.write_bytes(inventory_v2_not_having_version)\n        set_config(app, {\n            'https://docs.python.org/': inv_file,\n            'fallback': ('https://docs.python.org/py3k/', inv_file),\n        })\n\n        # load the inventory and check if it's done correctly\n        normalize_intersphinx_mapping(app, app.config)\n        load_mappings(app)\n\n        rn = reference_check(app, 'py', 'mod', 'module1', 'foo')\n        assert isinstance(rn, nodes.reference)\n        assert rn['refuri'] == 'https://docs.python.org/foo.html#module-module1'\n        assert rn['reftitle'] == '(in foo)'\n        assert rn[0].astext() == 'Long Module desc'\n"], "sample_44": ["    def test_log_quantity_to_string(self):\n        lq1 = u.Magnitude(10.*u.Jy)\n        assert str(lq1) == \"10. Jy\"\n        lq2 = u.Magnitude(10.*u.m)\n        assert str(lq2) == \"10. m\"\n        lq3 = u.Magnitude(10.*u.dex)\n        assert str(lq3) == \"10. dex\"\n        lq4 = u.Magnitude(10.*u.mag(u.Jy))\n        assert str(lq4) == \"10. mag(Jy)\"\n        lq5 = u.Magnitude(10.*u.mag(u.m))\n        assert str(lq5) == \"10. mag(m)\"\n        lq6 = u.Magnitude(10.*u.dex(u.Jy))\n        assert str(lq6) == \"10. dex(Jy)\"\n\n"], "sample_1105": ["def test_matmul_with_inverse():\n    A = MatrixSymbol('A', n, n)\n    assert MatMul(A, Inverse(A)).doit() == Identity(n)\n    assert MatMul(Inverse(A), A).doit() == Identity(n)\n"], "sample_133": ["    def test_i18n_with_plural_forms(self):\n        with override('fr'):\n            response = self.client.get('/jsi18n_plural_forms/')\n            self.assertContains(response, '1 message')\n            self.assertContains(response, '2 messages')\n            self.assertContains(response, '3 messages')\n            self.assertContains(response, '4 messages')\n"], "sample_116": ["    def test_different_aliases(self):\n        \"\"\"\n        Requesting different aliases should yield different instances.\n        \"\"\"\n        cache1 = caches['default']\n        cache2 = caches['other']\n\n        self.assertIsNot(cache1, cache2)\n"], "sample_594": ["compilation error"], "sample_582": ["def test_cli_command_order(app):\n    \"\"\"Test that commands are registered in the order they are defined.\"\"\"\n    custom = Blueprint(\"custom\", __name__, cli_group=\"customized\")\n    nested = Blueprint(\"nested\", __name__)\n\n    @custom.cli.command(\"custom1\")\n        click.echo(\"custom1_result\")\n\n    @custom.cli.command(\"custom2\")\n        click.echo(\"custom2_result\")\n\n    @nested.cli.command(\"nested1\")\n        click.echo(\"nested1_result\")\n\n    app.register_blueprint(custom)\n    app.register_blueprint(nested)\n\n    app_runner = app.test_cli_runner()\n\n    result = app_runner.invoke(args=[\"customized\", \"--help\"])\n    commands = result.output.splitlines()\n    assert commands[2] == \"custom1\"\n    assert commands[3] == \"custom2\"\n    assert commands[5] == \"nested1\"\n\n\n\n"], "sample_480": ["    def test_key_text_transform_from_lookup_with_nested_key(self):\n        qs = NullableJSONModel.objects.annotate(\n            b=KT(\"value__baz__foo\")\n        ).filter(b__contains=\"ar\")\n        self.assertSequenceEqual(qs, [self.objs[7]])\n"], "sample_300": ["    def test_filter_conditional_with_join(self):\n        query = Query(Item)\n        query.add_related_objects(\n            'creator',\n            related_query=Query(Author, alias_cols=False).filter(num__gt=2)\n        )\n        filter_expr = Func('creator__name', output_field=CharField())\n        where = query.build_where(filter_expr)\n        exact = where.children[0]\n        self.assertIsInstance(exact, Exact)\n        self.assertIsInstance(exact.lhs, Func)\n        self.assertIsInstance(exact.rhs, str)\n"], "sample_717": ["def test_lfw_pairs_subset():\n    for subset in ['train', 'test', '10_folds']:\n        lfw_pairs = fetch_lfw_pairs(subset=subset, data_home=SCIKIT_LEARN_DATA,\n                                    download_if_missing=False)\n        assert_equal(lfw_pairs.target.shape[0], 2200)\n        assert_equal(lfw_pairs.pairs.shape[0], 2200)\n        assert_equal(lfw_pairs.data.shape[0], 2200)\n\n\n\n"], "sample_980": ["compilation error"], "sample_1031": ["def test_quantity_creation():\n    # Test creation of Quantity objects with and without units\n    q1 = Quantity(\"mass\", units=kg)\n    assert q1.name == \"mass\"\n    assert q1.units == kg\n    assert q1.dimension == mass\n\n    q2 = Quantity(\"speed\", units=m/s)\n    assert q2.name == \"speed\"\n    assert q2.units == m/s\n    assert q2.dimension == velocity\n\n    q3 = Quantity(\"energy\")\n    assert q3.name == \"energy\"\n    assert q3.units is None\n    assert q3.dimension == energy\n"], "sample_497": ["    def test_locale_aware(self, use_locale):\n        plt.rcParams['backend'] = 'TkAgg'  # locale-aware backends\n        plt.rcParams['axes.unicode_minus'] = False\n        plt.rcParams['locale'] = 'en_US.UTF-8' if use_locale else None\n        fig, ax = plt.subplots()\n        ax.set_xticks([1, 2, 3])\n        ax.set_xticklabels(['one', 'two', 'three'])\n        fig.canvas.draw()\n        # Check that the tick labels are displayed correctly\n        # based on the locale setting.\n        for i, label in enumerate(ax.get_xticklabels()):\n            assert label.get_text() == f'{i+1}' if not use_locale else \\\n                f'{i+1}'\n\n\n\n"], "sample_963": ["def test_stringify_type_hints_origin_and_args():\n    from typing import TypeVar, Generic, List\n\n    T = TypeVar('T')\n    \n    class MyGeneric(Generic[T]):\n        pass\n\n    assert stringify(MyGeneric) == \"tests.test_util_typing.MyGeneric\"\n    assert stringify(MyGeneric[int]) == \"tests.test_util_typing.MyGeneric[int]\"\n    assert stringify(List[MyGeneric[str]]) == \"List[tests.test_util_typing.MyGeneric[str]]\"\n"], "sample_250": ["    def test_weekday_names_in_different_locales(self):\n        for locale in ['en-us', 'fr', 'de']:\n            with translation.override(locale):\n                dt = datetime(2023, 10, 26)\n                self.assertEqual(dateformat.format(dt, 'l'), WEEKDAYS[dt.weekday()])\n"], "sample_1016": ["def test_polylog():\n    assert octave_code(polylog(n, x)) == 'polylog(n, x)'\n"], "sample_678": ["def test_cleanup_numbered_dir_with_keep(tmp_path):\n    \"\"\"Test cleanup_numbered_dir with keep parameter.\"\"\"\n    prefix = \"test_dir\"\n    keep = 2\n    for i in range(5):\n        make_numbered_dir_with_cleanup(tmp_path, prefix, keep, 60)\n    cleanup_numbered_dir(tmp_path, prefix, keep, 60)\n    assert len(list(tmp_path.glob(f\"{prefix}-*\"))) == keep\n"], "sample_71": ["    def test_non_numeric_input(self):\n        with self.assertRaises(TypeError):\n            nformat('abc', '.')\n        with self.assertRaises(TypeError):\n            nformat(True, '.')\n        with self.assertRaises(TypeError):\n            nformat([1, 2, 3], '.')\n"], "sample_182": ["    def test_union_with_distinct_and_order_by(self):\n        qs1 = Number.objects.filter(num__lte=1).values('num')\n        qs2 = Number.objects.filter(num__gte=2, num__lte=3).values('num')\n        self.assertNumbersEqual(qs1.union(qs2, all=True).order_by('num'), [1, 2, 3])\n\n"], "sample_1130": ["def test_auto_vel_multiple_paths_with_different_velocities():\n    q1, q2, u1, u2 = dynamicsymbols('q1 q2 u1 u2')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    O = Point('O')\n    O.set_vel(N, u1 * N.x)\n    P = Point('P')\n    P.set_pos(O, q1 * N.y)\n    P.set_vel(N, u2 * N.y)\n    Q = Point('Q')\n    Q.set_pos(O, q2 * N.z)\n    Q.set_vel(N, u1 * N.z)\n    with warnings.catch_warnings(): #There are two possible paths in this point tree, thus a warning is raised\n        warnings.simplefilter(\"error\")\n        raises(UserWarning, lambda: P.vel(N))\n"], "sample_953": ["def test_quickstart_with_custom_template(tempdir):\n    answers = {\n        'Root path': tempdir,\n        'Project name': 'Custom Template Test',\n        'Author name': 'Custom Template Tester',\n        'Project version': '0.1',\n    }\n    qs.term_input = mock_input(answers)\n    d = {}\n    qs.ask_user(d)\n\n    # Mock the template directory\n    qs.templatedir = tempdir / 'templates'\n    qs.generate(d, templatedir=qs.templatedir)\n\n    # Check if the custom template was used\n    master_file = tempdir / 'source' / 'index.rst'\n    assert master_file.isfile()\n    with open(master_file, 'r') as f:\n        content = f.read()\n    assert 'This is a custom template' in content\n\n\n\n"], "sample_327": ["    def test_custom_encoder_decoder_with_errors(self):\n        class CustomDecoder(json.JSONDecoder):\n                return super().__init__(object_hook=self.as_uuid, *args, **kwargs)\n\n                if 'uuid' in dct:\n                    try:\n                        dct['uuid'] = uuid.UUID(dct['uuid'])\n                    except ValueError:\n                        raise json.JSONDecodeError(\"Invalid UUID format\", dct, 0)\n                return dct\n\n        value = {'uuid': 'invalid_uuid'}\n        encoded_value = '{\"uuid\": \"invalid_uuid\"}'\n        field = JSONField(encoder=DjangoJSONEncoder, decoder=CustomDecoder)\n        with self.assertRaisesMessage(ValidationError, 'Invalid UUID format'):\n            field.clean(encoded_value)\n"], "sample_653": ["compilation error"], "sample_751": ["def test_sparse_sample_weight_classification():\n    # Check classification with sparse input and sample weights.\n\n    class CustomSVC(SVC):\n        \"\"\"SVC variant that records the nature of the training set.\"\"\"\n\n            \"\"\"Modification on fit caries data type for later verification.\"\"\"\n            super(CustomSVC, self).fit(X, y, sample_weight=sample_weight)\n            self.data_type_ = type(X)\n            return self\n\n    X, y = datasets.make_multilabel_classification(n_classes=1, n_samples=15,\n                                                   n_features=5,\n                                                   random_state=42)\n    # Flatten y to a 1d array\n    y = np.ravel(y)\n\n    sample_weight = np.random.rand(len(y))\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\n    for sparse_format in [csc_matrix, csr_matrix, lil_matrix, coo_matrix,\n                          dok_matrix]:\n        X_train_sparse = sparse_format(X_train)\n        X_test_sparse = sparse_format(X_test)\n\n        # Trained on sparse format\n        sparse_classifier = AdaBoostClassifier(\n            base_estimator=CustomSVC(gamma='scale', probability=True),\n            random_state=1,\n            algorithm=\"SAMME\",\n            sample_weight=sample_weight\n        ).fit(X_train_sparse, y_train)\n\n        # Trained on dense format\n        dense_classifier = AdaBoostClassifier(\n            base_estimator=CustomSVC(gamma='scale', probability=True),\n            random_state=1,\n            algorithm=\"SAMME\",\n            sample_weight=sample_weight\n        ).fit(X_train, y_train)\n\n        # predict\n        sparse_results = sparse_classifier.predict(X_test_sparse)\n        dense_results = dense_classifier.predict(X_test)\n        assert_array_equal(sparse_results, dense_results)\n\n        # decision_function\n        sparse_results = sparse"], "sample_974": ["def test_ccode_complex():\n    from sympy import I, symbols\n    x, y = symbols('x y', complex=True)\n    assert ccode(x + I*y) == \"(x + y*I)\"\n    assert ccode(x*y + I*x) == \"(x*y + x*I)\"\n    assert ccode(x**2 + I*y**2) == \"(pow(x, 2) + pow(y, 2)*I)\"\n    assert ccode(sin(x + I*y)) == \"sin(x + y*I)\"\n    assert ccode(cos(x + I*y)) == \"cos(x + y*I)\"\n"], "sample_586": ["    def test_concat_mixed_dims(self):\n        ds1 = Dataset({\"x\": ((\"y\", \"z\"), np.arange(6).reshape((2, 3))), \"y\": [0, 1]})\n        ds2 = Dataset({\"x\": ((\"y\", \"z\"), np.arange(6, 12).reshape((2, 3))), \"y\": [0, 1]})\n        expected = Dataset({\"x\": ((\"y\", \"z\"), np.arange(12).reshape((2, 6))), \"y\": [0, 1]})\n        actual = concat([ds1, ds2], dim=\"y\")\n        assert_identical(expected, actual)\n\n        ds1 = Dataset({\"x\": ((\"y\", \"z\"), np.arange(6).reshape((2, 3))), \"y\": [0, 1]})\n        ds2 = Dataset({\"x\": ((\"z\", \"y\"), np.arange(6, 12).reshape((2, 3))), \"y\": [0, 1]})\n        with raises_regex(ValueError, \"incompatible dimensions\"):\n            concat([ds1, ds2], dim=\"y\")\n\n        ds1 = Dataset({\"x\": ((\"y\", \"z\"), np.arange(6).reshape((2, 3))), \"y\": [0, 1]})\n        ds2 = Dataset({\"x\": ((\"y\", \"z\"), np.arange(6, 12).reshape((3, 2))), \"y\": [0, 1]})\n        with raises_regex(ValueError, \"incompatible dimensions\"):\n            concat([ds1, ds2], dim=\"y\")\n"], "sample_507": ["    def test_plot_mixed_types(self, plotter):\n        ax = plt.figure().subplots()\n        with pytest.raises(TypeError):\n            plotter(ax, ['a', 3.14, 'b'], [1, 2, 3])\n"], "sample_340": ["    def test_loading_squashed_missing_replacements(self):\n        \"\"\"\n        Tests loading a squashed migration that references a nonexistent replacement migration.\n        \"\"\"\n        loader = MigrationLoader(connection)\n        recorder = MigrationRecorder(connection)\n        self.addCleanup(recorder.flush)\n\n        with self.assertRaisesMessage(\n            KeyError,\n            \"Migration 'migrations.0002_second' depends on nonexistent node ('migrations', '0001_initial')\"\n        ):\n            loader.build_graph()\n"], "sample_566": ["def test_savefig_metadata_with_dpi():\n    fig = plt.figure()\n    fig.savefig(io.BytesIO(), format='png', metadata={'dpi': 300})\n    with pytest.raises(ValueError, match=\"metadata not supported\"):\n        fig.savefig(io.BytesIO(), format='png', metadata={'dpi': 300, 'other': 'value'})\n"], "sample_919": ["compilation error"], "sample_784": ["def test_calibration_multiclass_imbalanced():\n    \"\"\"Test calibration for multiclass imbalanced datasets\"\"\"\n    from sklearn.datasets import make_classification\n    X, y = make_classification(n_samples=1000, n_features=20,\n                               n_classes=3,\n                               weights=[0.1, 0.8, 0.1],\n                               random_state=42)\n    X_train, y_train = X[:800], y[:800]\n    X_test, y_test = X[800:], y[800:]\n\n    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n    clf.fit(X_train, y_train)\n\n    for method in ['isotonic', 'sigmoid']:\n        cal_clf = CalibratedClassifierCV(clf, method=method, cv=3)\n        cal_clf.fit(X_train, y_train)\n        cal_probs = cal_clf.predict_proba(X_test)\n        uncal_probs = clf.predict_proba(X_test)\n\n        # Check that calibration decreases log-loss for the imbalanced\n        # dataset\n        cal_loss = log_loss(y_test, cal_probs)\n        uncal_loss = log_loss(y_test, uncal_probs)\n        assert_greater(uncal_loss, cal_loss)\n\n\n\n"], "sample_858": ["def test_voting_classifier_with_custom_classes():\n    class CustomClassifier(BaseEstimator, ClassifierMixin):\n            pass\n\n            return np.zeros(X.shape[0])\n\n    eclf = VotingClassifier(estimators=[\n        ('custom', CustomClassifier()),\n        ('lr', LogisticRegression(random_state=123))\n    ], voting='soft')\n    eclf.fit(X, y)\n    assert_array_equal(eclf.predict(X), np.zeros(len(y)))\n"], "sample_1173": ["def test_issue_19501_nested():\n    x = Symbol('x')\n    eq = parse_expr('E**(x*(1+x))', local_dict={'x': x}, transformations=(\n        standard_transformations +\n        (implicit_multiplication_application,)))\n    assert eq.free_symbols == {x}\n"], "sample_290": ["    def test_operation_with_no_suggested_name_and_initial_true(self):\n        class Migration(migrations.Migration):\n            initial = True\n            operations = [migrations.RunSQL('SELECT 1 FROM person;')]\n\n        migration = Migration('0001_initial', 'test_app')\n        self.assertEqual(migration.suggest_name(), 'initial')\n"], "sample_1161": ["def test_printing_MatrixElement_with_symbols():\n    A = MatrixSymbol(\"A\", 2, 2)\n    x, y = symbols('x y')\n    assert str(A[x, y]) == \"A[x, y]\"\n"], "sample_69": ["    def test_should_stop_returns_false_for_non_watched_files(self):\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file]):\n            self.assertFalse(self.reloader.should_stop(self.nonexistent_file))\n"], "sample_450": ["    def test_get_admin_log_template_tag(self):\n        # Test the get_admin_log template tag functionality\n        with self.subTest(\"No user specified\"):\n            # Test without specifying a user\n            response = self.client.get(reverse(\"admin:index\"))\n            self.assertContains(response, \"Article changed\")\n            self.assertNotContains(response, \"Car created\")\n\n        with self.subTest(\"User specified\"):\n            # Test with a user specified\n            response = self.client.get(reverse(\"admin:index\"))\n            self.assertContains(response, \"Article changed\")\n            self.assertNotContains(response, \"Car created\")\n"], "sample_1096": ["def test_Indexed_subs_with_multiple_indices():\n    A = IndexedBase(\"A\")\n    i, j, k = symbols(\"i,j,k\")\n    x, y, z = symbols(\"x,y,z\")\n    f = Function(\"f\")\n\n    assert Subs(A[i, j], A[i, j], x).diff(A[i, j]) == 0\n    assert Subs(A[i, j], A[i, j], x).diff(A[k, l]) == 0\n    assert Subs(A[i, j], A[i, j], x).diff(x) == 1\n    assert Subs(A[i, j], A[i, j], x).diff(y) == 0\n    assert Subs(A[i, j], A[i, j], A[k, l]).diff(A[m, n]) == KroneckerDelta(i, m)*KroneckerDelta(j, n)\n    assert Subs(A[i, j]*x, x, A[i, j]).diff(A[i, j]) == 2*A[i, j]\n    assert Subs(A[i, j]*x, x, A[i, j]).diff(A[k, l]) == 2*A[i, j]*KroneckerDelta(i, k)*KroneckerDelta(j, l)\n    assert Subs(A[i, j]*x, x, A[k, l]).diff(A[i, j]) == A[k, l] + A[i, j]*KroneckerDelta(i, k)*KroneckerDelta(j, l)\n    assert Subs(A[i, j]*x, x, A[k, l]).diff(A[k, l]) == A[i, j] + A[k, l]*KroneckerDelta(i, k)*KroneckerDelta(j, l)\n    assert Subs(A[i, j]*x, x, A[i, j]).diff(A[m, n]) == 2*A[i, j]*KroneckerDelta(i, m)*KroneckerDelta(j, n)\n    assert Subs(A[i, j]*x, x, A[k, l"], "sample_535": ["def test_table_bbox_with_loc():\n    data = [[2, 3],\n            [4, 5]]\n\n    col_labels = ('Foo', 'Bar')\n    row_labels = ('Ada', 'Bob')\n\n    cell_text = [[f\"{x}\" for x in row] for row in data]\n\n    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(8, 3))\n\n    # Test bbox with loc='best'\n    axs[0].table(cellText=cell_text,\n                  rowLabels=row_labels,\n                  colLabels=col_labels,\n                  loc='best',\n                  bbox=[0.1, 0.2, 0.8, 0.6])\n    axs[0].axis('off')\n\n    # Test bbox with loc='center'\n    axs[1].table(cellText=cell_text,\n                  rowLabels=row_labels,\n                  colLabels=col_labels,\n                  loc='center',\n                  bbox=[0.1, 0.2, 0.8, 0.6])\n    axs[1].axis('off')\n"], "sample_252": ["    def test_contains_contained_by_with_key_transform_nested(self):\n        tests = [\n            ('value__baz__d__contains', 'e'),\n            ('value__baz__d__contains', [{'f': 'g'}]),\n            ('value__baz__contains', KeyTransform('a', KeyTransform('d', 'value'))),\n            ('value__baz__contained_by', KeyTransform('a', {'b': 'c'})),\n        ]\n        for lookup, value in tests:\n            with self.subTest(lookup=lookup, value=value):\n                self.assertIs(NullableJSONModel.objects.filter(\n                    **{lookup: value},\n                ).exists(), True)\n"], "sample_818": ["def test_spectral_clustering_affinity_matrix_shape():\n    X = np.random.rand(10, 5)\n    affinity_matrix = np.random.rand(10, 10)\n    \n    # Test that SpectralClustering raises an error when the affinity matrix\n    # shape is incorrect.\n    with pytest.raises(ValueError):\n        SpectralClustering(affinity='precomputed', random_state=0).fit(X, affinity_matrix)\n\n    # Test that SpectralClustering works correctly when the affinity matrix\n    # shape is correct.\n    with pytest.raises(ValueError):\n        SpectralClustering(affinity='precomputed', random_state=0).fit(X, affinity_matrix)\n"], "sample_30": ["def test_get_infos_by_id():\n    vot = parse(\n        io.BytesIO(\n            b\"\"\"\n        <VOTABLE xmlns=\"http://www.ivoa.net/xml/VOTable/v1.3\"\n          xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" version=\"1.4\">\n          <RESOURCE type=\"results\">\n            <INFO id=\"creator-name-1\" name=\"creator-name\" value=\"Cannon, A.\"/>\n            <INFO id=\"creator-name-2\" name=\"creator-name\" value=\"Fleming, W.\"/>\n          </RESOURCE>\n        </VOTABLE>\"\"\"\n        )\n    )\n    info1 = vot.get_info_by_id(\"creator-name-1\")\n    assert info1.value == \"Cannon, A.\"\n    info2 = vot.get_info_by_id(\"creator-name-2\")\n    assert info2.value == \"Fleming, W.\"\n"], "sample_847": ["def test_enet_multioutput_sparse_input():\n    X, y, _, _ = build_dataset(n_samples=50, n_features=20)\n    y = np.hstack((y[:, np.newaxis], y[:, np.newaxis]))\n    X_sparse = sparse.csr_matrix(X)\n\n    clf = ElasticNet(alpha=0.5, tol=1e-8, fit_intercept=False)\n    clf.fit(X_sparse, y)\n    assert_array_almost_equal(clf.coef_, clf.coef_)\n\n\n\n"], "sample_36": ["def test_biweight_midcovariance_large_arrays():\n    \"\"\"\n    Test biweight_midcovariance with large arrays to ensure performance\n    and correctness.\n    \"\"\"\n    with NumpyRNGContext(12345):\n        n = 10000\n        d = np.random.normal(0, 1, size=(n, n))\n        cov = biweight_midcovariance(d)\n        assert cov.shape == (n, n)\n        assert np.allclose(cov, cov.T)  # Check for symmetry\n\n\n\n"], "sample_720": ["def test_power_transformer_nan_handling():\n    X = np.abs(X_2d)\n    X_with_nan = np.copy(X)\n    X_with_nan[:, 0] = np.nan\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method='box-cox', standardize=standardize)\n\n        # Test that fit handles NaNs\n        assert_raises(ValueError, pt.fit, X_with_nan)\n\n        # Test that transform handles NaNs\n        assert_raises(ValueError, pt.transform, X_with_nan)\n\n        # Test that inverse_transform handles NaNs\n        assert_raises(ValueError, pt.inverse_transform, pt.transform(X))\n\n\n\n"], "sample_1175": ["def test_issue_18414():\n    from sympy.physics.mechanics import Point, ReferenceFrame, dynamicsymbols, inertial\n\n    N = inertial('N')\n    P = Point('P')\n    q = dynamicsymbols('q')\n    v = dynamicsymbols('v')\n    a = dynamicsymbols('a')\n\n    assert pretty(P.pos_from(N)) == 'P'\n    assert pretty(P.pos_from(N).subs(P.pos_from(N), q)) == 'q'\n    assert pretty(P.vel_from(N)) == 'v_P'\n    assert pretty(P.acc_from(N)) == 'a_P'\n\n"], "sample_335": ["    def test_decimalfield_with_empty_string(self):\n        f = DecimalField(required=True)\n        with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):\n            f.clean('')\n        f = DecimalField(required=False)\n        self.assertIsNone(f.clean(''))\n"], "sample_1180": ["compilation error"], "sample_885": ["def test_interval_closed_neither_bounds_are_included():\n    \"\"\"Check that for Interval with closed='neither', neither bound is included.\"\"\"\n    interval = Interval(Real, 1, 3, closed=\"neither\")\n    assert not interval.is_satisfied_by(1)\n    assert not interval.is_satisfied_by(3)\n    assert interval.is_satisfied_by(1.5)\n    assert interval.is_satisfied_by(2.7)\n\n\n\n"], "sample_170": ["    def test_sensitive_variables_decorator_with_kwargs(self):\n        @sensitive_variables\n            return password, kwargs\n\n        with self.settings(DEBUG=True):\n            response = self.client.post('/some_url/', data={'password': 'secret', 'other': 'value'})\n            self.assertEqual(response.status_code, 500)\n            self.assertContains(response, 'secret', status_code=500)\n            self.assertNotContains(response, 'value', status_code=500)\n"], "sample_23": ["def test_angle_from_string_with_units():\n    \"\"\"\n    Test that Angle can be created from strings with units.\n    \"\"\"\n    a = Angle(\"10d\", u.deg)\n    assert a.value == 10.0\n    assert a.unit == u.deg\n\n    a = Angle(\"10h\", u.hourangle)\n    assert a.value == 10.0\n    assert a.unit == u.hourangle\n\n    a = Angle(\"10m\", u.arcminute)\n    assert a.value == 10.0\n    assert a.unit == u.arcminute\n\n    a = Angle(\"10s\", u.arcsecond)\n    assert a.value == 10.0\n    assert a.unit == u.arcsecond\n\n\n"], "sample_209": ["    def test_ordering_with_respect_to_and_ordering(self):\n        \"\"\"\n        Regression test for #18432: Chained foreign keys with to_field produce incorrect query\n        \"\"\"\n        with self.assertRaises(ValueError):\n            Model1.objects.order_by('model2__model3__name')\n            \n        with self.assertRaises(ValueError):\n            Model1.objects.order_by('model2__model3__name').order_by('name')\n"], "sample_1149": ["def test_singleton_redefinition_with_attributes():\n    class TestSingleton(Basic, metaclass=Singleton):\n        x = 1\n\n    assert TestSingleton() is S.TestSingleton\n    assert TestSingleton().x == 1\n\n    class TestSingleton_new(Basic, metaclass=Singleton):\n        x = 2\n\n    assert TestSingleton_new() is S.TestSingleton_new\n    assert TestSingleton_new().x == 2\n"], "sample_216": ["    def test_add_model_with_field_removed_from_base_model(self):\n        \"\"\"\n        Removing a base field takes place before adding a new inherited model\n        that has a field with the same name.\n        \"\"\"\n        before = [\n            ModelState('app', 'readable', [\n                ('id', models.AutoField(primary_key=True)),\n                ('title', models.CharField(max_length=200)),\n            ]),\n        ]\n        after = [\n            ModelState('app', 'readable', [\n                ('id', models.AutoField(primary_key=True)),\n            ]),\n            ModelState('app', 'book', [\n                ('title', models.CharField(max_length=200)),\n            ], bases=('app.readable',)),\n        ]\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'app', 1)\n        self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel'])\n        self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n        self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n"], "sample_1063": ["def test_issue_17197():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    x, y = symbols('x y')\n    f = lambdify((x, y), sin(x) * cos(y), modules='scipy')\n    assert abs(f(1, 1) - (sin(1) * cos(1))) < 1e-10\n"], "sample_637": ["    def test_regex_codetag(self) -> None:\n        code = \"\"\"a = 1\n                # TODO this should trigger\n                # FIXME that should too\n                \"\"\"\n        with self.assertAddsMessages(\n            MessageTest(msg_id=\"fixme\", line=2, args=\"TODO this should trigger\", col_offset=17),\n            MessageTest(msg_id=\"fixme\", line=3, args=\"FIXME that should too\", col_offset=17),\n        ):\n            self.checker.process_tokens(_tokenize_str(code))\n"], "sample_688": ["    def test_collect_import_error_in_fixture(testdir):\n        testdir.makepyfile(\n            \"\"\"\n                pass\n            \"\"\"\n        )\n        result = testdir.runpytest()\n        assert result.ret == ExitCode.INTERRUPTED\n        result.stdout.fnmatch_lines(\n            [\n                \"*ERROR collecting test_collect_import_error_in_fixture.py*\",\n                \"*ImportError: cannot import name 'a' from 'test_collect_import_error_in_fixture'.*\",\n                \"*! Interrupted: 1 error during collection !*\",\n                \"*= 1 error in *\",\n            ]\n        )\n"], "sample_499": ["def test_legend_title_fontsize_with_fontproperties():\n    # test the title_fontsize kwarg with fontproperties\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontproperties=FontProperties(\n                                       family='serif', size=22))\n    assert leg.get_title().get_fontsize() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10"], "sample_1092": ["def test_issue_19057():\n    from sympy.abc import x, y, z\n    expr = (x + y)**2 + (x + z)**2\n    substs, reduced = cse(expr)\n    assert len(substs) > 0\n    assert reduced[0] == expr.subs(reversed(substs))\n"], "sample_793": ["def test_iforest_contamination_auto():\n    # Test that contamination='auto' works as expected\n    rng = check_random_state(0)\n    X = rng.rand(100, 2)\n    y = np.zeros(100)\n    y[20:] = 1\n    clf = IsolationForest(contamination='auto').fit(X, y)\n    assert clf._contamination != 0.1\n    assert clf._contamination > 0.15\n    assert clf._contamination < 0.25\n\n\n\n"], "sample_729": ["def test_enet_multi_output_sparse_data():\n    X, y, _, _ = build_dataset(n_samples=50, n_features=10)\n    y = y[:, np.newaxis]\n    X_sparse = sparse.csr_matrix(X)\n    y_sparse = sparse.csr_matrix(y)\n\n    clf = ElasticNetCV(n_alphas=5, eps=2e-3, l1_ratio=[0.5, 0.7])\n    clf.fit(X_sparse, y_sparse[:, 0])\n    clf1 = MultiTaskElasticNetCV(n_alphas=5, eps=2e-3, l1_ratio=[0.5, 0.7])\n    clf1.fit(X_sparse, y_sparse)\n    assert_almost_equal(clf.l1_ratio_, clf1.l1_ratio_)\n    assert_almost_equal(clf.alpha_, clf1.alpha_)\n    assert_almost_equal(clf.coef_, clf1.coef_[0])\n    assert_almost_equal(clf.intercept_, clf1.intercept_[0])\n"], "sample_47": ["    def test_cleanse_setting_nested_dictionaries(self):\n        initial = {'user': {'name': 'john', 'password': 'doe'}}\n        expected = {'user': {'name': 'john', 'password': CLEANSED_SUBSTITUTE}}\n        self.assertEqual(cleanse_setting('SETTING_NAME', initial), expected)\n"], "sample_777": ["def test_gradient_boosting_with_missing_values():\n    X = [[1, 2, np.nan], [4, 5, 6], [7, 8, np.nan]]\n    y = [0, 1, 0]\n\n    # Test with different missing value strategies\n    for strategy in ['mean', 'median', 'most_frequent']:\n        gb = GradientBoostingClassifier(\n            random_state=42,\n            missing_values_strategy=strategy\n        )\n        gb.fit(X, y)\n        assert_array_almost_equal(gb.predict(X), [0, 1, 0])\n\n\n\n"], "sample_436": ["    def test_suggestions_with_options(self):\n        args = [\"runserver\", \"--port=8000\", \"--settings=test_project.settings\"]\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertNotInOutput(err, \"Did you mean\")\n"], "sample_19": ["def test_wcs_from_header_with_invalid_units():\n    \"\"\"\n    Test handling of WCS headers with invalid units.\n    \"\"\"\n    header = fits.Header.fromstring(\n        \"\"\""], "sample_332": ["    def test_all_valid_with_non_form_errors(self):\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '0',\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': '',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '',\n        }\n        ChoiceFormSet = formset_factory(Choice, validate_max=True)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [{'votes': ['This field is required.']}, {'votes': ['This field is required.']}]\n        self.assertEqual(formset1._errors, expected_errors)\n        self.assertEqual(formset2._errors, expected_errors)\n"], "sample_380": ["    def test_exists_with_subquery_and_aggregate(self):\n        subquery = Author.objects.filter(\n            age__gt=30,\n        ).values('id')\n        qs = Book.objects.annotate(\n            count=Count('id'),\n            exists=Exists(subquery),\n        ).filter(exists=True)\n        self.assertEqual(len(qs), 3)\n"], "sample_1075": ["compilation error"], "sample_583": ["compilation error"], "sample_1171": ["def test_issue_17860():\n    r = Range(1, 5)\n    assert r[1:3] == Range(2, 4)\n    assert r[1:4] == Range(2, 4)\n    assert r[1:5] == r\n    assert r[0:1] == Range(1, 2)\n    assert r[2:5] == Range(3, 5)\n    assert r[0:0] == Range()\n    assert r[1:0] == Range()\n    assert r[-1:5] == Range(4, 5)\n    assert r[-2:5] == Range(3, 5)\n    assert r[-3:5] == Range(2, 5)\n    assert r[-4:5] == Range(1, 5)\n    assert r[-5:5] == r\n    assert r[-6:5] == r\n    assert r[0:-1] == Range(1, 4)\n    assert r[0:-2] == Range(1, 3)\n    assert r[0:-3] == Range(1, 2)\n    assert r[0:-4] == Range(1, 1)\n    assert r[0:-5] == Range()\n    assert r[1:-1] == Range(2, 4)\n    assert r[1:-2] == Range(2, 3)\n    assert r[1:-3] == Range(2, 2)\n    assert r[1:-4] == Range()\n    assert r[1:-5] == Range()\n    assert r[2:-2] == Range(3, 3)\n    assert r[2:-3] == Range(3, 2)\n    assert r[2:-4] == Range()\n    assert r[2:-5] == Range()\n    assert r[3:-3] == Range(4, 4)\n    assert r[3:-4] == Range(4, 3)\n    assert r[3:-5] == Range()\n    assert r[4:-4] == Range(5, 5)\n    assert r[4:-5] == Range()\n\n\n\n"], "sample_448": ["    def test_unique_constraint_with_null_values(self):\n        with self.assertRaises(ValueError):\n            models.UniqueConstraint(\n                fields=[\"name\"],\n                name=\"name_uniq\",\n                null_values=True,\n            )\n"], "sample_456": ["    def test_all_valid_with_non_form_errors(self):\n        class CustomFormSet(BaseFormSet):\n                raise ValidationError(\"This is a non-form error\")\n\n        ChoiceFormSet = formset_factory(Choice, formset=CustomFormSet)\n        formset1 = ChoiceFormSet(data={}, auto_id=False, prefix=\"choices\")\n        formset2 = ChoiceFormSet(data={}, auto_id=False, prefix=\"choices\")\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [{\"__all__\": [\"This is a non-form error\"]}, {\"__all__\": [\"This is a non-form error\"]}]\n        self.assertEqual(formset1._errors, expected_errors)\n        self.assertEqual(formset2._errors, expected_errors)\n"], "sample_3": ["def test_ecsv_with_comments():\n    \"\"\"Test reading ECSV files with comments.\"\"\"\n    txt = \"\"\"\n    # This is a comment\n    # %ECSV 1.0\n    # ---\n    # datatype:\n    # - {name: a, datatype: int64}\n    # schema: astropy-2.0\n    a\n    1\n    2\n    3\n    # Another comment\n    \"\"\"\n    t = Table.read(txt, format='ascii.ecsv')\n    assert t['a'].dtype == np.int64\n    assert len(t) == 3\n\n\n\n"], "sample_888": ["def test_iforest_sparse_data_with_sample_weight(global_random_seed):\n    \"\"\"Test Isolation Forest with sparse data and sample weights.\"\"\"\n    rng = check_random_state(global_random_seed)\n    X = rng.randn(100, 50).astype(float)\n    X_sparse = csc_matrix(X)\n    sample_weight = rng.rand(100)\n\n    # Test with contamination set\n    contamination = 0.2\n    iforest = IsolationForest(contamination=contamination, random_state=rng)\n    iforest.fit(X_sparse, sample_weight=sample_weight)\n\n    # Test with contamination set to 'auto'\n    iforest = IsolationForest(random_state=rng)\n    iforest.fit(X_sparse, sample_weight=sample_weight)\n\n\n\n"], "sample_419": ["    def test_custom_renderer_with_management_form(self):\n        class CustomRenderer(TemplatesSetting):\n            formset_template_name = \"a/custom/formset/template.html\"\n\n        ChoiceFormSet = formset_factory(Choice, renderer=CustomRenderer)\n        formset = ChoiceFormSet()\n        self.assertEqual(formset.management_form.renderer, CustomRenderer)\n        self.assertEqual(formset.management_form.template_name, \"a/custom/formset/template.html\")\n"], "sample_591": ["    def test_merge_with_different_dims(self):\n        ds1 = xr.Dataset({\"a\": (\"x\", [1, 2])})\n        ds2 = xr.Dataset({\"b\": (\"y\", [3, 4])})\n        with pytest.raises(ValueError):\n            ds1.merge(ds2)\n\n        ds1 = xr.Dataset({\"a\": (\"x\", [1, 2])})\n        ds2 = xr.Dataset({\"b\": (\"x\", [3, 4])})\n        expected = xr.Dataset({\"a\": (\"x\", [1, 2]), \"b\": (\"x\", [3, 4])})\n        assert expected.identical(ds1.merge(ds2, compat=\"override\"))\n\n"], "sample_59": ["    def test_ordering_with_related_field(self):\n        \"\"\"\n        Regression test for #13640: ordering by related field with evaluate method\n        \"\"\"\n        dept = Department.objects.create(pk=1, name='abc')\n        dept.evaluate = 'abc'\n        worker1 = Worker.objects.create(department=dept, name='worker1')\n        worker2 = Worker.objects.create(department=dept, name='worker2')\n        worker3 = Worker.objects.create(department=dept, name='worker3')\n\n        # Order by related field\n        workers = Worker.objects.filter(department=dept).order_by('name')\n        self.assertEqual([w.name for w in workers], ['worker1', 'worker2', 'worker3'])\n\n"], "sample_460": ["    def test_non_admin_url_404_if_authenticated(self):\n        superuser = User.objects.create_superuser(\n            username=\"super\",\n            password=\"secret\",\n            email=\"super@example.com\",\n        )\n        self.client.force_login(superuser)\n        unknown_url = \"/unknown/\"\n        response = self.client.get(unknown_url)\n        self.assertEqual(response.status_code, 404)\n"], "sample_830": ["def test_show_versions_missing_deps():\n    import unittest\n    from unittest.mock import patch\n    from sklearn.utils._show_versions import _get_deps_info, show_versions\n\n    class MockModule:\n        __version__ = \"1.2.3\"\n\n    with patch('sklearn.utils._show_versions.importlib.import_module', side_effect=ImportError):\n        with patch('sklearn.utils._show_versions._get_deps_info', return_value={\n            'pip': '10.0.1',\n            'setuptools': '56.0.0',\n            'sklearn': '0.24.2',\n            'numpy': MockModule,\n            'scipy': None,\n            'Cython': None,\n            'pandas': None,\n            'matplotlib': None\n        }):\n            show_versions()\n            \n    \n"], "sample_1041": ["def test_transpose_commutativity():\n    A = MatrixSymbol('A', n, m)\n    assert (A.T).T == A\n    assert (A + B).T == A.T + B.T\n    assert (A * B).T == B.T * A.T\n    assert (A * 2).T == 2 * A.T\n    assert (A**2).T == A.T**2\n    assert (A**-1).T == (A.T)**-1\n    assert (Transpose(A)).T == A\n\n\n\n"], "sample_447": ["    def test_alias_with_subquery(self):\n        qs = (\n            Book.objects.alias(\n                top_rating_alias=Subquery(\n                    Book.objects.filter(pubdate__year=OuterRef(\"pubdate__year\"))\n                    .order_by(\"-rating\")\n                    .values(\"rating\")[:1]\n                )\n            )\n        )\n        self.assertIs(hasattr(qs.first(), \"top_rating_alias\"), False)\n        self.assertCountEqual(\n            qs.values_list(\"pubdate__year\", \"top_rating_alias\"),\n            [\n                (1991, 5.0),\n                (1995, 4.0),\n                (2007, 4.5),\n                (2008, 4.0),\n            ],\n        )\n"], "sample_418": ["    def test_length_is12(self):\n        output = self.engine.render_to_string(\"length_is12\", {})\n        self.assertEqual(output, \"Length not 0\")\n"], "sample_525": ["def test_subplots_with_constrained_layout():\n    fig = plt.figure(constrained_layout=True)\n    gs = fig.add_gridspec(2, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1])\n    ax3 = fig.add_subplot(gs[1, 0])\n    ax4 = fig.add_subplot(gs[1, 1])\n\n    # Check that the subplots are arranged correctly\n    assert ax1.get_position().x0 == 0.1\n    assert ax1.get_position().y0 == 0.1\n    assert ax2.get_position().x0 == 0.3\n    assert ax2.get_position().y0 == 0.1\n    assert ax3.get_position().x0 == 0.1\n    assert ax3.get_position().y0 == 0.3\n    assert ax4.get_position().x0 == 0.3\n    assert ax4.get_position().y0 == 0.3\n\n\n\n"], "sample_650": ["def test_log_format_custom_format(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import logging\n\n        logger = logging.getLogger(__name__)\n\n            logger.warning('text')\n            assert False\n        \"\"\"\n    )\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_format= %(levelname)s: %(message)s\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 1\n    result.stdout.fnmatch_lines(\n        [\"WARNING: text\"]\n    )\n"], "sample_1107": ["def test_is_permutation():\n    assert is_permutation(list(range(3)), list(range(3))) is True\n    assert is_permutation(list(range(3)), list(range(2, 5))) is True\n    assert is_permutation([1, 2, 3], [3, 1, 2]) is True\n    assert is_permutation([1, 2, 3], [1, 3, 2]) is False\n    assert is_permutation([1, 2, 3], [1, 2, 4]) is False\n    assert is_permutation([], []) is True\n    assert is_permutation([1], [1]) is True\n    assert is_permutation([1, 2, 3], [1, 2, 3, 4]) is False\n    assert is_permutation([1, 2, 3], [1, 2, 3, 3]) is False\n"], "sample_603": ["def test_summarize_attrs_empty(dataset):\n    formatted = fh.summarize_attrs({})\n    assert formatted == \"\"\n"], "sample_939": ["    def test_unparse_kw_defaults(self):\n        source = \"\"\""], "sample_29": ["    def test_write_latex_with_metadata(self, write, tmp_path):\n        fp = tmp_path / \"test_write_latex_with_metadata.tex\"\n        cosmo = self.cosmo\n        cosmo.metadata = {\"custom_key\": \"custom_value\"}\n        write(fp, format=\"latex\", cosmology=cosmo)\n        tbl = QTable.read(fp)\n        assert \"custom_key\" in tbl.meta\n        assert tbl.meta[\"custom_key\"] == \"custom_value\"\n"], "sample_227": ["    def test_emptylistfieldfilter_with_related_field(self):\n        class AuthorAdminWithEmptyFieldListFilter(ModelAdmin):\n            list_filter = (\n                ('books__title', EmptyFieldListFilter),\n            )\n\n        modeladmin = AuthorAdminWithEmptyFieldListFilter(Author, site)\n        request = self.request_factory.get('/', {'books__title__isempty': '1'})\n        request.user = self.alfred\n        changelist = modeladmin.get_changelist_instance(request)\n        queryset = changelist.get_queryset(request)\n        self.assertEqual(list(queryset), [self.alfred])\n\n        request = self.request_factory.get('/', {'books__title__isempty': '0'})\n        request.user = self.alfred\n        changelist = modeladmin.get_changelist_instance(request)\n        queryset = changelist.get_queryset(request)\n        self.assertEqual(list(queryset), [self.bob, self.lisa])\n"], "sample_996": ["def test_issue_14036():\n    a, n = symbols('a n')\n    assert product(1 - a**2 / (n*pi)**2, [n, 1, oo]) != 0\n"], "sample_304": ["    def test_domain_allowlist_access(self):\n        validator = EmailValidator()\n        validator.domain_allowlist = ['mydomain']\n        self.assertEqual(validator.domain_allowlist, ['mydomain'])\n"], "sample_67": ["    def test_related_objects_are_not_included(self):\n        \"\"\"\n        Related objects are not included in the dictionary representation.\n        \"\"\"\n        item = ColourfulItem.objects.create()\n        item.colours.add(Colour.objects.create(name='blue'))\n        data = model_to_dict(item)\n        self.assertNotIn('colours', data)\n"], "sample_510": ["def test_subplot_projection_reuse_with_kwargs():\n    # create an Axes\n    ax1 = plt.subplot(111)\n    # check that it is current\n    assert ax1 is plt.gca()\n    # make sure we get it back if we ask again\n    assert ax1 is plt.subplot(111)\n    # remove it\n    ax1.remove()\n    # create a polar plot with kwargs\n    ax2 = plt.subplot(111, projection='polar', theta_offset=0)\n    assert ax2 is plt.gca()\n    # this should have deleted the first axes\n    assert ax1 not in plt.gcf().axes\n    # assert we get it back if no extra parameters passed\n    assert ax2 is plt.subplot(111, projection='polar')\n    ax2.remove()\n    # now check explicitly setting the projection to rectilinear\n    # makes a new axes\n    ax3 = plt.subplot(111, projection='rectilinear',\n                      facecolor='lightblue')\n    assert ax3 is plt.gca()\n    assert ax3 is not ax2\n    assert ax2 not in plt.gcf().axes\n"], "sample_917": ["compilation error"], "sample_307": ["    def test_timezone_aware_datetime_with_naive_timezone(self):\n        tz = get_fixed_timezone(-510)\n        dt = datetime(2009, 5, 16, 5, 30, 30, tzinfo=tz)\n        self.assertEqual(datetime.fromtimestamp(int(format(dt, 'U')), tz), dt)\n        self.assertEqual(datetime.fromtimestamp(int(format(dt, 'U')), tzinfo=None), dt.astimezone(get_default_timezone()).replace(tzinfo=None))\n"], "sample_1153": ["def test_issue_16023():\n    from sympy import Symbol, re, im, Abs, exp, pi\n    x = Symbol('x')\n    y = Symbol('y')\n    assert re(exp(x + I*y)).subs(x, 0) == 1\n    assert im(exp(x + I*y)).subs(x, 0) == y\n    assert Abs(exp(x + I*y)).subs(x, 0) == exp(y)\n"], "sample_318": ["    def test_lookahead_and_lookbehind_together(self):\n        test_urls = [\n            ('/lookahead+/a-city/lookbehind-/b-city/', {'city': 'a-city', 'city2': 'b-city'}),\n            ('/lookbehind-/b-city/lookahead+/a-city/', {'city': 'a-city', 'city2': 'b-city'}),\n        ]\n        for test_url, kwargs in test_urls:\n            with self.subTest(url=test_url):\n                self.assertEqual(resolve(test_url).kwargs, kwargs)\n\n\n\n"], "sample_869": ["def test_multilabel_jaccard_similarity_score_sparse_matrix():\n    from scipy.sparse import csr_matrix\n    y1 = csr_matrix([[0, 1, 1], [1, 0, 1]])\n    y2 = csr_matrix([[0, 0, 1], [1, 0, 1]])\n\n    jss = jaccard_similarity_score(y1, y2)\n    assert jss == 0.75\n    assert jaccard_similarity_score(y1, y1) == 1\n    assert jaccard_similarity_score(y2, y2) == 1\n    assert jaccard_similarity_score(y2, np.zeros(y1.shape)) == 0\n    assert jaccard_similarity_score(y1, np.zeros(y1.shape)) == 0\n"], "sample_743": ["compilation error"], "sample_323": ["    def test_minimize_rollbacks_no_dependencies(self):\n        \"\"\"\n        Minimize rollbacks when target has no dependencies.\n\n        a: 1\n        b: 1\n\n        If a1 is applied already and there are no dependencies, don't unapply b1\n        even if it's applied.\n        \"\"\"\n        a1_impl = FakeMigration('a1')\n        a1 = ('a', '1')\n        b1_impl = FakeMigration('b1')\n        b1 = ('b', '1')\n        graph = MigrationGraph()\n        graph.add_node(a1, a1_impl)\n        graph.add_node(b1, b1_impl)\n\n        executor = MigrationExecutor(None)\n        executor.loader = FakeLoader(graph, {\n            a1: a1_impl,\n            b1: b1_impl,\n        })\n\n        plan = executor.migration_plan({a1})\n\n        self.assertEqual(plan, [])\n"], "sample_952": ["def test_getargspec_with_defaults():\n        pass\n\n    argspec = inspect.getargspec(func)\n    assert argspec.args == ['a', 'b', 'args', 'kwargs']\n    assert argspec.defaults == (1, (), {})\n    assert argspec.varargs == 'args'\n    assert argspec.keywords == 'kwargs'\n"], "sample_558": ["def test_grid_axes_class_custom():\n    class CustomAxes(mpl.axes.Axes):\n            super().__init__(*args, **kwargs)\n            self.set_facecolor('lightblue')\n\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 2), axes_class=CustomAxes)\n    for ax in grid:\n        assert ax.get_facecolor() == 'lightblue'\n"], "sample_691": ["def test_timeout_with_pdb(pytester: Pytester) -> None:\n    \"\"\"Test that timeout works correctly when entering pdb.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n    import os, time\n    import faulthandler\n\n        time.sleep(1 if \"CI\" in os.environ else 0.1)\n        import pdb; pdb.set_trace()\n    \"\"\"\n    )\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        faulthandler_timeout = 0.05\n        \"\"\"\n    )\n    result = pytester.runpytest_subprocess()\n    result.stderr.fnmatch_lines([\"*%s*\" % \"Traceback (most recent call last)\"])\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n    assert result.ret != 0\n"], "sample_632": ["def test_ignore_signatures_empty_functions_pass():\n    output = StringIO()\n    with redirect_stdout(output), pytest.raises(SystemExit) as ex:\n        similar.Run([\"--ignore-signatures\", EMPTY_FUNCTION_1, EMPTY_FUNCTION_2])\n    assert ex.value.code == 0\n    assert (\n        output.getvalue().strip()\n        == \"\"\""], "sample_313": ["    def test_get_template_directories_with_duplicate_dirs(self):\n        self.assertSetEqual(\n            autoreload.get_template_directories(),\n            {\n                Path(__file__).parent / 'templates_extra',\n                Path(__file__).parent / 'templates',\n            }\n        )\n"], "sample_247": ["    def test_alias_with_subquery(self):\n        qs = Book.objects.alias(\n            top_rating_alias=Subquery(\n                Book.objects.filter(pubdate__year=OuterRef('pubdate_year')).order_by('-rating').values('rating')[:1]\n            ),\n        ).annotate(\n            pubdate_year=ExtractYear('pubdate'),\n        ).values('pubdate_year', 'top_rating_alias')\n        self.assertCountEqual(qs, [\n            {'pubdate_year': 1991, 'top_rating_alias': 5.0},\n            {'pubdate_year': 1995, 'top_rating_alias': 4.0},\n            {'pubdate_year': 2007, 'top_rating_alias': 4.5},\n            {'pubdate_year': 2008, 'top_rating_alias': 4.0},\n        ])\n"], "sample_288": ["    def test_key_transform_with_nested_json_field(self):\n        obj = NullableJSONModel.objects.create(\n            value={'a': {'b': {'c': 1}}}\n        )\n        self.assertEqual(\n            NullableJSONModel.objects.filter(\n                value__a__b__c=1\n            ).get(),\n            obj,\n        )\n        self.assertEqual(\n            NullableJSONModel.objects.filter(\n                value__a__b__c=1\n            ).get().value,\n            {'a': {'b': {'c': 1}}},\n        )\n"], "sample_737": ["def test_vectorizer_empty_vocabulary():\n    # Test for empty vocabulary when fitting on empty data\n    vect = CountVectorizer()\n    assert_raises(ValueError, vect.fit, [])\n    vect = TfidfVectorizer()\n    assert_raises(ValueError, vect.fit, [])\n    vect = HashingVectorizer()\n    assert_raises(ValueError, vect.fit, [])\n"], "sample_291": ["    def test_get_context_data_with_object(self):\n        test_view = views.CustomSingleObjectView()\n        test_view.object = {'name': 'John'}\n        context = test_view.get_context_data()\n        self.assertEqual(context['object'], {'name': 'John'})\n"], "sample_1143": ["def test_mod_with_zero():\n    assert S(2).mod(0) == 0\n    assert S(2).mod(0.0) == 0\n    assert S(2).mod(Rational(0, 1)) == 0\n    assert S(2).mod(Float(0)) == 0\n    assert S(2).mod(S(0)) == 0\n    assert (-2).mod(0) == 0\n    assert (-2).mod(0.0) == 0\n    assert (-2).mod(Rational(0, 1)) == 0\n    assert (-2).mod(Float(0)) == 0\n    assert (-2).mod(S(0)) == 0\n"], "sample_191": ["    def test_snapshot_files_with_non_existing_files(self):\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.nonexistent_file]):\n            snapshot = dict(self.reloader.snapshot_files())\n            self.assertNotIn(self.nonexistent_file, snapshot)\n"], "sample_173": ["    def test_explain_query_prefix_raise_not_supported_error(self):\n        msg = 'This backend does not support explaining query execution.'\n        with self.assertRaisesMessage(NotSupportedError, msg):\n            connection.ops.explain_query_prefix()\n"], "sample_431": ["    def test_refresh_with_related_objects(self):\n        a = Article.objects.create(headline=\"Parrot programs in Python\", pub_date=datetime(2005, 7, 28))\n        s1 = SelfRef.objects.create(article=a)\n        s2 = SelfRef.objects.create(article=a)\n        with self.assertNumQueries(1):\n            a.refresh_from_db(fields=[\"selfref_set\"])\n        self.assertEqual(len(a.selfref_set.all()), 2)\n        with self.assertNumQueries(1):\n            a.refresh_from_db(fields=[\"selfref_set\", \"headline\"])\n        self.assertEqual(len(a.selfref_set.all()), 2)\n        self.assertEqual(a.headline, \"Parrot programs in Python\")\n"], "sample_955": ["    def test_unparse_slice(source, expected):\n        module = ast.parse(source)\n        assert ast.unparse(module.body[0].value, source) == expected\n"], "sample_502": ["def test_subplot_projection_reuse_with_kwargs():\n    ax1 = plt.subplot(111, projection='polar')\n    ax2 = plt.subplot(111, projection='polar', theta_offset=45)\n    assert ax1 is not ax2\n    assert ax2.theta_offset == 45\n"], "sample_810": ["def test_pipeline_with_invalid_transformer():\n    with pytest.raises(TypeError, match=\"Transformer 'InvalidTransf' \"\n                        \"does not have a 'fit' method\"):\n        Pipeline([('transf', InvalidTransf())]).fit(X, y)\n\n"], "sample_794": ["def test_ridge_regression_sparse_data_with_sample_weights():\n    rng = np.random.RandomState(42)\n    n_samples, n_features = 1000, 5\n    X = rng.randn(n_samples, n_features)\n    y = rng.randn(n_samples)\n\n    # Create sparse data\n    X_sparse = sp.csr_matrix(X)\n\n    # Create sample weights\n    sample_weights = rng.randn(n_samples)\n\n    # Test with different solvers\n    for solver in ['sag', 'saga', 'sparse_cg']:\n        ridge = Ridge(alpha=1.0, solver=solver, fit_intercept=True)\n        ridge.fit(X_sparse, y, sample_weight=sample_weights)\n        assert_array_almost_equal(ridge.coef_, ridge.coef_)\n        assert_array_almost_equal(ridge.intercept_, ridge.intercept_)\n\n\n\n"], "sample_128": ["    def test_covering_index_with_opclasses(self):\n        index = Index(\n            name='covering_index_with_opclasses',\n            fields=['headline'],\n            include=['pub_date', 'published'],\n            opclasses=['varchar_pattern_ops'],\n        )\n        with connection.schema_editor() as editor:\n            self.assertIn(\n                '(%s varchar_pattern_ops) INCLUDE (%s, %s)' % (\n                    editor.quote_name('headline'),\n                    editor.quote_name('pub_date'),\n                    editor.quote_name('published'),\n                ),\n                str(index.create_sql(Article, editor)),\n            )\n            editor.add_index(Article, index)\n            with connection.cursor() as cursor:\n                constraints = connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                )\n                self.assertIn(index.name, constraints)\n                self.assertEqual(\n                    constraints[index.name]['columns'],\n                    ['headline', 'pub_date', 'published'],\n                )\n            editor.remove_index(Article, index)\n            with connection.cursor() as cursor:\n                self.assertNotIn(index.name, connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                ))\n"], "sample_455": ["    def test_unique_constraint_with_custom_error_message_and_code(self):\n        constraint = models.UniqueConstraint(\n            fields=[\"name\"],\n            name=\"custom_constraint\",\n            violation_error_message=\"Custom error message\",\n            violation_error_code=\"custom_code\",\n        )\n        msg = \"Custom error message\"\n        with self.assertRaisesMessage(ValidationError, msg) as cm:\n            constraint.validate(UniqueConstraintProduct, UniqueConstraintProduct(name=\"existing_name\"))\n        self.assertEqual(cm.exception.code, \"custom_code\")\n"], "sample_461": ["    def test_urlfield_clean_with_invalid_port(self):\n        f = URLField()\n        msg = \"'Enter a valid URL.'\"\n        with self.assertRaisesMessage(ValidationError, msg):\n            f.clean(\"http://example.com:invalid\")\n        with self.assertRaisesMessage(ValidationError, msg):\n            f.clean(\"https://example.com:invalid\")\n\n\n\n"], "sample_270": ["    def test_unique_constraint_include_with_condition(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_include_id',\n                        include=['id'],\n                        condition=models.Q(age__gte=100),\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_partial_indexes else [\n            Warning(\n                '%s does not support unique constraints with conditions and '\n                'non-key columns.',\n                % connection.display_name,\n                hint=(\n                    \"A constraint won't be created. Silence this warning if \"\n                    \"you don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W040',\n            ),\n        ]\n        self.assertEqual(errors, expected)\n"], "sample_646": ["    def test_raising_unittest_skip_during_test(self):\n        with pytest.raises(unittest.SkipTest):\n            class TestIt(unittest.TestCase):\n                    raise unittest.SkipTest()\n"], "sample_1176": ["def test_issue_10705():\n    assert Float('1.23', 10).as_mpf() == mpf('1.2300000000')\n    assert Float('1.234567890123456789', 10).as_mpf() == mpf('1.234567890123456789')\n    assert Float('1.234567890123456789', 10).as_mpf(10) == mpf('1.234567890123456789')\n    assert Float('1.234567890123456789', 10).as_mpf(20) == mpf('1.2345678901234567890000000000000000')\n\n\n\n"], "sample_373": ["    def test_simplify_regex_with_lookarounds(self):\n        tests = (\n            (r'(?<!a)\\w+(?!b)', r'/\\w+'),\n            (r'(?<=a)\\w+(?=\\b)', r'/\\w+'),\n            (r'(?<!\\w)\\d+(?!\\w)', r'/\\d+'),\n            (r'(?<=a)\\d+(?=b)', r'/\\d+'),\n        )\n        for pattern, output in tests:\n            with self.subTest(pattern=pattern):\n                self.assertEqual(simplify_regex(pattern), output)\n"], "sample_296": ["    def test_not_finished_sentinel(self):\n        storage = self.get_storage()\n        response = self.get_response()\n\n        # Add a few messages to the storage.\n        for i in range(5):\n            storage.add(constants.INFO, f'Message {i}')\n\n        # Update the response with the messages.\n        storage.update(response)\n\n        # Retrieve the messages from the cookie.\n        messages = storage._decode(response.cookies['messages'].value)\n\n        # Assert that the messages were retrieved correctly.\n        self.assertEqual(len(messages), 4)\n        self.assertEqual(messages[-1], storage.not_finished)\n\n        # Retrieve the messages again.\n        messages = storage._decode(response.cookies['messages'].value)\n\n        # Assert that the sentinel value is gone and all messages are retrieved.\n        self.assertEqual(len(messages), 5)\n        self.assertNotIn(storage.not_finished, messages)\n\n\n\n"], "sample_656": ["def test_capture_with_unicode_output(capsys):\n    sys.stdout.write(u\"\u4f60\u597d\")\n    (out, err) = capsys.readouterr()\n    assert out == u\"\u4f60\u597d\"\n"], "sample_703": ["def test_multiple_idents(expr: str, expected: bool) -> None:\n    matcher = {\"ident1\": True, \"ident2\": True, \"ident3\": False}.__getitem__\n    assert evaluate(expr, matcher) is expected\n"], "sample_197": ["    def test_reversed_time_strings(self):\n        time_strings = {\n            'year': ngettext_lazy('%d year ago', '%d years ago'),\n            'month': ngettext_lazy('%d month ago', '%d months ago'),\n            'week': ngettext_lazy('%d week ago', '%d weeks ago'),\n            'day': ngettext_lazy('%d day ago', '%d days ago'),\n            'hour': ngettext_lazy('%d hour ago', '%d hours ago'),\n            'minute': ngettext_lazy('%d minute ago', '%d minutes ago'),\n        }\n        with translation.override('cs'):\n            for now in [self.t, self.t - self.onemicrosecond, self.t - self.oneday]:\n                with self.subTest(now):\n                    self.assertEqual(\n                        timeuntil(now, self.t, time_strings=time_strings),\n                        '0\\xa0minut',\n                    )\n"], "sample_161": ["    def test_invalid_field_type(self):\n        \"\"\"\n        Providing a field type that is not a ForeignKey to the\n        ManyToManyField.through_fields kwarg triggers validation errors.\n        \"\"\"\n        class Fan(models.Model):\n            pass\n\n        class Event(models.Model):\n            invitees = models.ManyToManyField(\n                Fan,\n                through='Invitation',\n                through_fields=('invalid_field', 'event'),\n            )\n\n        class Invitation(models.Model):\n            event = models.ForeignKey(Event, models.CASCADE)\n            invitee = models.ForeignKey(Fan, models.CASCADE)\n            inviter = models.ForeignKey(Fan, models.CASCADE, related_name='+')\n\n        field = Event._meta.get_field('invitees')\n        self.assertEqual(field.check(from_model=Event), [\n            Error(\n                \"The intermediary model 'invalid_models_tests.Invitation' has no field 'invalid_field'.\",\n                hint=\"Did you mean one of the following foreign keys to 'Event': event?\",\n                obj=field,\n                id='fields.E338',\n            ),\n        ])\n\n\n\n"], "sample_765": ["def test_balanced_accuracy_score_with_weights():\n    y_true = np.array([0, 0, 1, 1, 0, 1])\n    y_pred = np.array([0, 0, 1, 1, 0, 0])\n    class_weights = {0: 2, 1: 1}\n    balanced = balanced_accuracy_score(y_true, y_pred,\n                                       sample_weight=class_weights)\n    assert_almost_equal(balanced, 0.66666667)\n"], "sample_1032": ["def test_issue_14000_continued():\n    from sympy.abc import x\n    assert root(x, 2, evaluate=False) == Pow(x, Rational(1, 2), evaluate=False)\n    assert real_root(x, 3, evaluate=False) == Pow(x, Rational(1, 3), evaluate=False)\n    assert real_root(x, 4, evaluate=False) == Pow(x, Rational(1, 4), evaluate=False)\n    assert real_root(x, 5, evaluate=False) == Pow(x, Rational(1, 5), evaluate=False)\n    assert real_root(x, 6, evaluate=False) == Pow(x, Rational(1, 6), evaluate=False)\n    assert real_root(x, 7, evaluate=False) == Pow(x, Rational(1, 7), evaluate=False)\n    assert real_root(x, 8, evaluate=False) == Pow(x, Rational(1, 8), evaluate=False)\n    assert real_root(x, 9, evaluate=False) == Pow(x, Rational(1, 9), evaluate=False)\n    assert real_root(x, 10, evaluate=False) == Pow(x, Rational(1, 10), evaluate=False)\n\n\n\n"], "sample_81": ["    def test_resolver_cache_with_namespace(self):\n        self.assertIsNot(get_ns_resolver('^namespace/', get_resolver(), {}), get_ns_resolver('^namespace/', get_resolver('urlpatterns.path_urls'), {}))\n"], "sample_695": ["def test_node_repr_failure_with_fulltrace(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n            raise ValueError(\"this is a test failure\")\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--fulltrace\")\n    result.stdout.fnmatch_lines(\n        [\n            str(pytester.path.joinpath(\"test_failure.py\")),\n            \"*1 passed in *\",\n            \"*1 failed in *\",\n            \"*ValueError: this is a test failure*\",\n            \"*Traceback (most recent call last):*\",\n        ]\n    )\n\n\n"], "sample_1208": ["def test_MatrixGamma_multivariate_pdf():\n    M = MatrixGamma('M', 2, 3, [[1, 0], [0, 1]])\n    X = MatrixSymbol('X', 2, 2)\n    term1 = exp(Trace(Matrix([[-1/2, 0], [0, -1/2]])*X))*Determinant(X)**(1)\n    assert density(M)(X).doit() == term1/(6*pi)\n    assert density(M)([[2, 1], [1, 2]]).doit() == exp(-1)/(6*pi)\n    n = symbols('n', positive=True)\n    d = symbols('d', positive=True, integer=True)\n    Y = MatrixSymbol('Y', d, d)\n    SM = MatrixSymbol('SM', d, d)\n    M = MatrixGamma('M', n, SM)\n    k = Dummy('k')\n    exprd = pi**(-d*(d - 1)/4)*3**(-n*d)*exp(Trace((-1/3)*SM**(-1)*Y)\n        )*Determinant(SM)**(-n)*Determinant(Y)**(n - d/2 - S(1)/2)/Product(\n        gamma(-k/2 + n + S(1)/2), (k, 1, d))\n    assert density(M)(Y).dummy_eq(exprd)\n"], "sample_1095": ["compilation error"], "sample_854": ["def test_kernel_cache_size():\n    # Test that kernel cache size is respected\n    X = np.random.rand(100, 10)\n    y = np.random.randint(0, 2, size=100)\n\n    for cache_size in [None, 10, 100]:\n        clf = svm.SVC(kernel='linear', cache_size=cache_size)\n        clf.fit(X, y)\n        assert clf.cache_size == cache_size\n"], "sample_817": ["def test_threshold_with_sparse_matrix():\n    # Test VarianceThreshold with a sparse matrix and custom threshold.\n    sparse_data = csr_matrix([[1, 0, 0],\n                              [0, 2, 0],\n                              [0, 0, 3]])\n    sel = VarianceThreshold(threshold=1.5).fit(sparse_data)\n    assert_array_equal([True, False, True], sel.get_support())\n"], "sample_62": ["    def test_registration_with_custom_admin_site(self):\n        custom_site = CustomSite()\n        custom_site.register(Person, NameAdmin)\n        self.assertIsInstance(custom_site._registry[Person], NameAdmin)\n        self.assertNotEqual(custom_site._registry[Person], self.default_site._registry.get(Person))\n"], "sample_454": ["    def test_unique_constraint_with_violation_error_message_and_code(self):\n        constraint = models.UniqueConstraint(\n            fields=[\"name\"],\n            name=\"unique_name\",\n            violation_error_message=\"Custom message\",\n            violation_error_code=\"custom_code\",\n        )\n        msg = \"Custom message\"\n        with self.assertRaisesMessage(ValidationError, msg) as cm:\n            constraint.validate(UniqueConstraintProduct, UniqueConstraintProduct(name=\"existing_name\"))\n        self.assertEqual(cm.exception.code, \"custom_code\")\n"], "sample_354": ["    def test_create_permissions_with_custom_permissions(self):\n        \"\"\"\n        create_permissions() should handle custom permissions defined in\n        the app's `permissions` attribute.\n        \"\"\"\n        custom_permissions = [\n            ('my_custom_permission', 'Some custom permission'),\n        ]\n        self.app_config.permissions = custom_permissions\n        permission_content_type = ContentType.objects.get_by_natural_key('auth', 'permission')\n\n        create_permissions(self.app_config, verbosity=0)\n\n        self.assertEqual(Permission.objects.filter(\n            content_type=permission_content_type,\n        ).count(), 1)\n        self.assertEqual(Permission.objects.get(codename='my_custom_permission').name, 'Some custom permission')\n\n\n\n"], "sample_101": ["    def test_limited_stream(self):\n        environ = self.request_factory._base_environ(\n            PATH_INFO=\"/\",\n            CONTENT_TYPE=\"text/html; charset=utf-8\",\n            REQUEST_METHOD=\"POST\",\n            CONTENT_LENGTH=\"10\"\n        )\n        request = WSGIRequest(environ)\n        self.assertEqual(len(request._stream.buffer), 0)\n        self.assertEqual(request._stream.remaining, 10)\n        data = b\"Hello World\"\n        request._stream._read_limited = lambda size=None: data[:size]\n        read_data = request._stream.read(5)\n        self.assertEqual(read_data, data[:5])\n        self.assertEqual(request._stream.remaining, 5)\n        read_data = request._stream.read()\n        self.assertEqual(read_data, data[5:])\n        self.assertEqual(request._stream.remaining, 0)\n"], "sample_1170": ["def test_printing_MatrixElement_with_symbols():\n    A = MatrixSymbol(\"A\", 2, 2)\n    x, y = symbols('x y')\n    assert str(A[x, y]) == \"A[x, y]\"\n"], "sample_909": ["    def test_raises_with_multiple_exceptions(self):\n        docstrings = [(\"\"\""], "sample_1017": ["def test_issue_13607():\n    x, y = symbols('x y')\n    assert (x > 0).as_expr() == x > 0\n    assert (x >= 0).as_expr() == x >= 0\n    assert (x < 0).as_expr() == x < 0\n    assert (x <= 0).as_expr() == x <= 0\n    assert (x != 0).as_expr() == x != 0\n    assert (x == 0).as_expr() == x == 0\n    assert (x != y).as_expr() == x != y\n    assert (x == y).as_expr() == x == y\n    assert (x > y).as_expr() == x > y\n    assert (x < y).as_expr() == x < y\n    assert (x >= y).as_expr() == x >= y\n    assert (x <= y).as_expr() == x <= y\n    assert (x & y).as_expr() == And(x, y)\n    assert (x | y).as_expr() == Or(x, y)\n    assert (x ^ y).as_expr() == Xor(x, y)\n    assert (~x).as_expr() == Not(x)\n    assert (x >> y).as_expr() == Implies(x, y)\n    assert (x << y).as_expr() == Implies(y, x)\n    assert (ITE(x, y, z)).as_expr() == ITE(x, y, z)\n"], "sample_515": ["def test_colorbar_fraction():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cb = fig.colorbar(im, fraction=0.2)\n    assert cb.ax.get_position().height == 0.2\n\n\n\n"], "sample_848": ["def test_multi_output_classifier_chain_with_different_number_of_outputs():\n    # Test if ClassifierChain handles cases where the number of outputs\n    # differs between training and prediction\n    X, y = datasets.make_classification(n_samples=100,\n                                       n_features=10,\n                                       n_classes=2,\n                                       random_state=0)\n    y1 = y[:, 0]\n    y2 = y[:, 1]\n    y3 = np.random.randint(0, 2, size=y.shape[0])\n    chain = ClassifierChain(LogisticRegression())\n    chain.fit(X, np.column_stack((y1, y2)))\n    assert_raises(ValueError, chain.predict, np.column_stack((y1, y3)))\n"], "sample_776": ["def test_lasso_lars_precompute():\n    # Test the precompute option\n    X = diabetes.data\n    y = diabetes.target\n    # Test with precompute=True\n    lars_precompute = linear_model.LassoLars(precompute=True)\n    lars_precompute.fit(X, y)\n    # Test with precompute=False\n    lars_no_precompute = linear_model.LassoLars(precompute=False)\n    lars_no_precompute.fit(X, y)\n    # Assert that the computation time is faster with precompute=True\n    assert lars_precompute.fit_time_ < lars_no_precompute.fit_time_\n\n\n\n"], "sample_852": ["def test_make_classification_multiclass_weights():\n    for n_classes in [2, 3, 4]:\n        X, y = make_classification(n_samples=100, n_features=20,\n                                    n_informative=10, n_redundant=0,\n                                    n_clusters_per_class=1,\n                                    weights=[0.1, 0.2, 0.7],\n                                    random_state=0,\n                                    n_classes=n_classes)\n        assert X.shape == (100, 20), \"X shape mismatch\"\n        assert y.shape == (100,), \"y shape mismatch\"\n        assert np.unique(y).shape == (n_classes,), \"Unexpected number of classes\"\n        assert_array_almost_equal(np.bincount(y) / len(y),\n                                  [0.1, 0.2, 0.7],\n                                  err_msg=\"Weights not reflected in class distribution\")\n\n\n\n"], "sample_386": ["    def test_mark_safe_with_unicode_characters(self):\n        s = mark_safe(\"a&b\\u00e9\")\n        self.assertRenderEqual(\"{{ s }}\", \"a&b\\u00e9\", s=s)\n"], "sample_526": ["def test_DateFormatter_tz_aware_datetime():\n    dt = datetime.datetime(2023, 1, 1, 10, 0, tzinfo=dateutil.tz.tzutc())\n    formatter = mdates.DateFormatter('%Y-%b-%d %H:%M')\n    formatter.set_tzinfo('America/New_York')\n    assert formatter(mdates.date2num(dt)) == '2023-Jan-01 05:00'\n"], "sample_747": ["def test_power_transformer_y_axis_transform():\n    X = np.abs(X_2d)\n    pt = PowerTransformer(method='box-cox', standardize=False)\n    pt.fit(X)\n\n    # Test that y-axis transformation works as expected\n    X_trans = pt.transform(X)\n    assert_array_almost_equal(pt.inverse_transform(X_trans), X)\n\n    # Test that y-axis transformation works with different methods\n    for method in ['yeo-johnson', 'box-cox']:\n        pt = PowerTransformer(method=method, standardize=False)\n        pt.fit(X)\n        X_trans = pt.transform(X)\n        assert_array_almost_equal(pt.inverse_transform(X_trans), X)\n"], "sample_444": ["    def test_file_change_after_collectstatic_with_import(self):\n        # Create initial static files.\n        file_contents = (\n            (\"foo.png\", \"foo\"),\n            (\"bar.css\", 'url(\"foo.png\")\\nimport \"other.css\";'),\n            (\"other.css\", 'url(\"foo.png\")'),\n            (\"xyz.png\", \"xyz\"),\n        )\n        for filename, content in file_contents:\n            with open(self._get_filename_path(filename), \"w\") as f:\n                f.write(content)\n\n        with self.modify_settings(STATICFILES_DIRS={\"append\": self._temp_dir}):\n            finders.get_finder.cache_clear()\n            err = StringIO()\n            # First collectstatic run.\n            call_command(\"collectstatic\", interactive=False, verbosity=0, stderr=err)\n            relpath = self.hashed_file_path(\"test/bar.css\")\n            with storage.staticfiles_storage.open(relpath) as relfile:\n                content = relfile.read()\n                self.assertIn(b\"foo.acbd18db4cc2.png\", content)\n                self.assertIn(b\"other.d16fb36f0911.css\", content)\n\n            # Change the contents of the png files.\n            for filename in (\"foo.png\", \"xyz.png\"):\n                with open(self._get_filename_path(filename), \"w+b\") as f:\n                    f.write(b\"new content of file to change its hash\")\n\n            # The hashes of the png files in the CSS file are updated after\n            # a second collectstatic.\n            call_command(\"collectstatic\", interactive=False, verbosity=0, stderr=err)\n            relpath = self.hashed_file_path(\"test/bar.css\")\n            with storage.staticfiles_storage.open(relpath) as relfile:\n                content = relfile.read()\n                self.assertIn(b\"foo.57a5cb9ba68d.png\", content)\n                self.assertIn(b\"other.57a5cb9ba68d.css\","], "sample_1159": ["def test_issue_18034():\n    x = Symbol('x', real=True, positive=True)\n    y = Symbol('y', real=True, nonnegative=True)\n    assert (x + y).is_positive is True\n    assert (x - y).is_positive is None\n    assert (x*y).is_positive is True\n    assert (x/y).is_positive is True\n"], "sample_414": ["    def test_ManyToMany_using_to_field(self):\n        from selenium.webdriver.common.by import By\n        from selenium.webdriver.support.ui import Select\n\n        self.admin_login(username=\"super\", password=\"secret\", login_url=\"/\")\n        self.selenium.get(\n            self.live_server_url + reverse(\"admin:admin_widgets_event_add\")\n        )\n\n        main_window = self.selenium.current_window_handle\n        # Click the Add User button to add new\n        self.selenium.find_element(By.ID, \"add_id_supporting_bands\").click()\n        self.wait_for_and_switch_to_popup()\n        band_name_field = self.selenium.find_element(By.ID, \"id_name\")\n        band_name_field.send_keys(\"New Band\")\n\n        save_button_css_selector = \".submit-row > input[type=submit]\"\n        self.selenium.find_element(By.CSS_SELECTOR, save_button_css_selector).click()\n        self.selenium.switch_to.window(main_window)\n        # The field now contains the new band\n        self.selenium.find_element(\n            By.CSS_SELECTOR, \"#id_supporting_bands option[value=New Band]\"\n        )\n\n        self.selenium.find_element(By.ID, \"view_id_supporting_bands\").click()\n        self.wait_for_value(\"#id_name\", \"New Band\")\n        self.selenium.back()\n\n        select = Select(self.selenium.find_element(By.ID, \"id_supporting_bands\"))\n        select.select_by_value(\"New Band\")\n        # Click the Change User button to change it\n        self.selenium.find_element(By.ID, \"change_id_supporting_bands\").click()\n        self.wait_for_and_switch_to_popup()\n\n        band_name_field = self.selenium.find_element(By.ID, \"id_name\")\n        band_name_field.clear()\n        band_name_field.send_keys(\"Changed New Band\")\n\n        save_button_css_selector"], "sample_664": ["def test_fixture_positional_arguments_deprecation(testdir, arg_names):\n    testdir.makepyfile(\n        \"\"\"\n        @pytest.fixture\n            return arg1, arg2, args\n    \n            assert my_fixture == (\"value1\", \"value2\", ())\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            f\"*Passing arguments to pytest.fixture() as positional arguments is deprecated - pass them\",\n            \"*as a keyword argument instead.*\",\n        ]\n    )\n"], "sample_39": ["def test_wcs_from_header_with_missing_crval():\n    \"\"\"\n    Test handling of missing CRVAL keywords.\n    \"\"\"\n    header = get_pkg_data_contents('data/missing_crval.hdr')\n    with pytest.raises(wcs.InvalidTransformError):\n        wcs.WCS(header)\n"], "sample_54": ["    def test_file_response_with_custom_content_type(self):\n        with tempfile.NamedTemporaryFile() as tmp:\n            tmp.write(b'binary content')\n            tmp.flush()\n            response = FileResponse(tmp, content_type='application/octet-stream')\n            self.assertEqual(response['Content-Type'], 'application/octet-stream')\n            self.assertEqual(list(response), [b'binary content'])\n"], "sample_46": ["    def test_delete_cascade(self):\n        u1 = PrimaryKeyUUIDModel.objects.create()\n        r1 = RelatedToUUIDModel.objects.create(uuid_fk=u1)\n        u1.delete()\n        with self.assertRaises(RelatedObjectDoesNotExist):\n            RelatedToUUIDModel.objects.get(id=r1.id)\n"], "sample_179": ["    def test_deferrable_unique_constraint_with_condition(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_gte_100_deferrable',\n                        condition=models.Q(age__gte=100),\n                        deferrable=models.Deferrable.DEFERRED,\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_partial_indexes and connection.features.supports_deferrable_unique_constraints else [\n            Warning(\n                '%s does not support deferrable unique constraints with conditions.'\n                % connection.display_name,\n                hint=(\n                    \"A constraint won't be created. Silence this warning if \"\n                    \"you don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W039',\n            ),\n        ]\n        self.assertEqual(errors, expected)\n"], "sample_35": ["def test_resolve_name():\n    assert introspection.resolve_name('astropy.utils.introspection.resolve_name') == introspection.resolve_name\n    assert introspection.resolve_name('astropy', 'utils', 'introspection', 'resolve_name') == introspection.resolve_name\n    with pytest.raises(ImportError):\n        introspection.resolve_name('nonexistent_module.nonexistent_object')\n"], "sample_422": ["    def test_prefetch_related_with_limit_and_ordering(self):\n        authors = Author.objects.order_by(\"name\").values_list(\"id\", flat=True)\n        with self.assertNumQueries(3):\n            books = list(\n                Book.objects.prefetch_related(\n                    Prefetch(\n                        \"first_time_authors\",\n                        authors[:2],\n                        to_attr=\"first_authors_limited\",\n                    )\n                )\n            )\n        for book in books:\n            with self.subTest(book=book):\n                self.assertEqual(\n                    len(book.first_authors_limited), 2\n                )\n                self.assertEqual(\n                    list(book.first_authors_limited.values_list(\"id\", flat=True)),\n                    authors[:2],\n                )\n"], "sample_1067": ["def test_issue_6103():\n    x = Symbol('x')\n    a = Wild('a')\n    assert (-I*x*oo).match(I*a*oo) == {a: -x}\n"], "sample_1140": ["def test_issue_18467():\n    from sympy.physics.quantum import TensorProduct, Dagger\n    a = Symbol('a')\n    b = Symbol('b')\n    A = Dagger(a)\n    B = Dagger(b)\n    C = TensorProduct(A, B)\n    assert pretty(C) == 'a\u2020 \u2297 b\u2020'\n    assert upretty(C) == 'a\u2020 \u2297 b\u2020'\n"], "sample_438": ["    def test_value_from_string(self):\n        question = Question.objects.create(text=\"test\")\n        answer1 = Answer.objects.create(question=question)\n        answer2 = Answer.objects.create(question=question)\n        result = Question.answer_set.field.value_from_string(json.dumps([answer1.pk, answer2.pk]))\n        self.assertEqual(result, answer1.question)\n"], "sample_549": ["compilation error"], "sample_262": ["    def test_keep_lazy(self):\n        @keep_lazy(int)\n            return x + 1\n\n        self.assertEqual(add_one(1), 2)\n        self.assertEqual(add_one(lazy(lambda: 2, int)), 3)\n        self.assertEqual(add_one(lazy(lambda: 2, int) + lazy(lambda: 3, int)), 6)\n"], "sample_912": ["def test_pyfunction_signature_with_args(app):\n    text = \".. py:function:: compile(source, filename: str, symbol: str = None)\\n\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"compile\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"ast object\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                ([desc_parameter, \"source\"],\n                 [desc_parameter, \"filename\", [desc_sig_punctuation, \":\"], \"str\"],\n                 [desc_parameter, \"symbol\", [desc_sig_punctuation, \":\"], \"str\", [desc_sig_operator, \"=\"], \"None\"]))\n\n\n\n"], "sample_902": ["def test_pipeline_memory_with_fit_transform():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        memory = Memory(cachedir=cachedir, verbose=10)\n        # Test with Transformer + SVC\n        clf = SVC(probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', clone(transf)), ('svc', clf)])\n        cached_pipe = Pipeline([('transf', transf), ('svc', clf)],\n                               memory=memory)\n\n        # Memoize the transformer at the first fit_transform\n        cached_pipe.fit_transform(X, y)\n        pipe.fit_transform(X, y)\n        # Get the time stamp of the transformer in the cached pipeline\n        ts = cached_pipe.named_steps['transf'].timestamp_\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert_false(hasattr(transf, 'means_'))\n        # Check that we are reading the cache while fitting\n        # a second time\n        cached_pipe.fit_transform(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        "], "sample_564": ["def test_text3d_rotation():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    txt = art3d.Text3D(0.5, 0.5, 1, 'Hello',\n                       rotation=(30, 45, 0))\n    ax.add_artist(txt)\n    assert txt.get_rotation() == (30, 45, 0)\n"], "sample_1133": ["compilation error"], "sample_1119": ["def test_jordan_form():\n    A = Matrix([[1, 2], [2, 1]])\n    J, P = A.jordan_form()\n    assert J.is_jordan_block_matrix()\n    assert P.is_invertible()\n    assert (P * J * P.inv()).equals(A)\n\n    B = Matrix([[1, 0, 0], [0, 2, 0], [0, 0, 3]])\n    J, P = B.jordan_form()\n    assert J.is_jordan_block_matrix()\n    assert P.is_invertible()\n    assert (P * J * P.inv()).equals(B)\n\n    C = Matrix([[1, 2, 3], [0, 4, 5], [0, 0, 6]])\n    J, P = C.jordan_form()\n    assert J.is_jordan_block_matrix()\n    assert P.is_invertible()\n    assert (P * J * P.inv()).equals(C)\n\n    D = Matrix([[1, 2], [2, 1]])\n    J, P = D.jordan_form(simplify=True)\n    assert J.is_jordan_block_matrix()\n    assert P.is_invertible()\n    assert (P * J * P.inv()).equals(D)\n\n    E = Matrix([[1, 2], [2, 1]])\n    J, P = E.jordan_form(simplify=False)\n    assert J.is_jordan_block_matrix()\n    assert P.is_invertible()\n    assert (P * J * P.inv()).equals(E)\n\n\n\n"], "sample_53": ["    def test_render_options_with_empty_string(self):\n        form = AlbumForm()\n        output = form.as_table()\n        self.assertIn(self.empty_option, output)\n\n\n\n"], "sample_477": ["    def test_random_list(self):\n        output = self.engine.render_to_string(\"random_list\", {\"list\": [\"a\", \"b\", \"c\"]})\n        self.assertIn(\"a\", output)\n        self.assertIn(\"b\", output)\n        self.assertIn(\"c\", output)\n"], "sample_325": ["    def test_renderer_inheritance(self):\n        class CustomForm(Form):\n            default_renderer = CustomRenderer\n\n        class SubForm(CustomForm):\n            pass\n\n        form = SubForm()\n        self.assertIsInstance(form.renderer, CustomRenderer)\n"], "sample_457": ["    def test_unique_constraint_with_null_values(self):\n        with self.assertRaises(ValueError):\n            models.UniqueConstraint(fields=[\"name\"], name=\"name_uniq\", allow_null=True)\n"], "sample_463": ["    def test_operation_with_custom_name(self):\n        class Migration(migrations.Migration):\n            operations = [\n                migrations.CreateModel(\n                    \"Person\", fields=[], name=\"some_custom_name\"\n                )\n            ]\n\n        migration = Migration(\"some_migration\", \"test_app\")\n        self.assertEqual(migration.suggest_name(), \"some_custom_name\")\n"], "sample_1116": ["def test_inverse_derivative():\n    A = MatrixSymbol('A', 2, 2)\n    x = symbols('x')\n    dA_dx = MatrixSymbol('dA_dx', 2, 2)\n    A_inv = A.I\n    assert A_inv._eval_derivative_matrix_lines(x) == dA_dx * A_inv.T - A_inv * dA_dx.T\n"], "sample_644": ["    def test_import_as_rename(capsys: CaptureFixture[str]) -> None:\n        \"\"\"Test import as rename.\"\"\"\n        Run(\n            [\n                f\"{os.path.join(REGR_DATA, 'import_as_rename')}\",\n                \"-d all\",\n                \"-e useless-import-alias\",\n            ],\n            exit=False,\n        )\n        output, errors = capsys.readouterr()\n        assert \"useless-import-alias\" in output\n        assert len(errors) == 0\n"], "sample_190": ["    def test_isnull_non_boolean_value_with_none(self):\n        # These tests will catch ValueError in Django 4.0 when using\n        # non-boolean values for an isnull lookup becomes forbidden.\n        # msg = (\n        #     'The QuerySet value for an isnull lookup must be True or False.'\n        # )\n        msg = (\n            'Using a non-boolean value for an isnull lookup is deprecated, '\n            'use True or False instead.'\n        )\n        tests = [\n            Author.objects.filter(alias__isnull=None),\n            Article.objects.filter(author__isnull=None),\n            Season.objects.filter(games__isnull=None),\n            Freebie.objects.filter(stock__isnull=None),\n        ]\n        for qs in tests:\n            with self.subTest(qs=qs):\n                with self.assertWarnsMessage(RemovedInDjango40Warning, msg):\n                    qs.exists()\n"], "sample_1094": ["def test_rewrite_with_undefined_functions():\n    from sympy.core.function import UndefinedFunction as UndefFunc\n    x = symbols('x')\n    f = UndefFunc('f')\n    g = UndefFunc('g')\n    expr = f(x) + g(x)\n    assert expr.rewrite(f, g) == expr\n    assert expr.rewrite(f, lambda x: x) == g(x) + x\n    assert expr.rewrite(g, lambda x: x) == f(x) + x\n\n\n\n"], "sample_529": ["def test_legend_title_fontsize_with_rcparam():\n    mpl.rcParams['legend.title_fontsize'] = 12\n    fig, ax = plt.subplots()\n    ax.plot(range(10), label='test')\n    leg = ax.legend(title=\"Aardvark\")\n    assert leg.get_title().get_fontsize() == 12\n"], "sample_749": ["def test_column_transformer_sparse_remainder_transformer_with_remainder_weights():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder=SparseMatrixTrans(transformer_weights={'sparse_trans': 0.5}))\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n\n    #  SparseMatrixTrans creates 3 features for each column, thus:\n    assert X_trans.shape == (3, 3)\n    assert_array_equal(X_trans.toarray(), 0.5 * np.eye(3))\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], SparseMatrixTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n\n\n\n"], "sample_687": ["def test_log_format_with_custom_formatter(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n\n            caplog.set_level(logging.INFO)\n            logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s')\n            logging.info(\"This is a test log message\")\n            assert caplog.text == \"2023-10-27 10:00:00,000 - INFO - This is a test log message\\n\"\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 0\n"], "sample_700": ["compilation error"], "sample_430": ["    def test_suggest_name_with_custom_operations(self):\n        class CustomOperation(migrations.MigrationOperation):\n                super().__init__()\n                self.name = name\n\n        class Migration(migrations.Migration):\n            operations = [CustomOperation(\"my_custom_operation\")]\n\n        migration = Migration(\"some_migration\", \"test_app\")\n        self.assertEqual(migration.suggest_name(), \"my_custom_operation\")\n"], "sample_821": ["def test_affinity_propagation_preference_limits():\n    # Test the behavior of affinity propagation with very small and very large\n    # preferences\n    X = np.array([[0, 0], [1, 1], [-2, -2]])\n    S = -euclidean_distances(X, squared=True)\n\n    # Very small preference, should result in all samples as exemplars\n    with assert_warns(UserWarning, \"mutually equal\"):\n        cluster_center_indices, labels = affinity_propagation(S, preference=-100)\n    assert_array_equal(np.arange(X.shape[0]), cluster_center_indices)\n    assert_array_equal(np.arange(X.shape[0]), labels)\n\n    # Very large preference, should result in a single cluster\n    with assert_warns(UserWarning, \"mutually equal\"):\n        cluster_center_indices, labels = affinity_propagation(S, preference=100)\n    assert_array_equal([0], cluster_center_indices)\n    assert_array_equal([0, 0, 0], labels)\n"], "sample_55": ["    def test_get_formsets_with_inlines_obj_is_none_on_add(self):\n        \"\"\"\n        Verify that the 'obj' argument passed to get_formsets_with_inlines()\n        is None during add_view.\n        \"\"\"\n        with self.subTest(model='explicitly_provided_pk'):\n            admin = AdminSite().get_model_admin(ExplicitlyProvidedPk)\n            formsets = admin.get_formsets_with_inlines(None)\n            self.assertIsNone(formsets[0].instance)\n\n        with self.subTest(model='implicitly_generated_pk'):\n            admin = AdminSite().get_model_admin(ImplicitlyGeneratedPk)\n            formsets = admin.get_formsets_with_inlines(None)\n            self.assertIsNone(formsets[0].instance)\n"], "sample_115": ["    def test_sensitive_variables_decorator_with_args(self):\n        @sensitive_variables(exclude=['cooked_eggs'])\n            return password, cooked_eggs, scrambled\n\n        with self.settings(DEBUG=True):\n            response = self.client.post('/sensitive_view/', data={'password': 'secret', 'cooked_eggs': 'sunny side up', 'scrambled': 'yes'})\n            self.assertContains(response, 'secret', status_code=500)\n            self.assertContains(response, 'sunny side up', status_code=500)\n            self.assertContains(response, 'yes', status_code=500)\n"], "sample_970": ["        def __init__(self, value):\n            self.value = value\n"], "sample_211": ["    def test_template_name_as_string(self):\n        \"\"\"\n        Test a template view that renders a template on GET\n        with the template name as a string.\n        \"\"\"\n        view = TemplateView.as_view(template_name='generic_views/about.html')\n        response = view(self.rf.get('/about/'))\n        self._assert_about(response)\n\n\n\n"], "sample_760": ["def test_check_scoring_with_custom_scorer():\n    # Test that check_scoring works with custom scorers.\n        return 1.0\n\n    scorer = make_scorer(custom_scorer)\n    estimator = LinearSVC()\n    scorer_result = check_scoring(estimator, scorer)\n    assert isinstance(scorer_result, _PredictScorer)\n"], "sample_742": ["def test_l1_penalty_with_intercept():\n    # Test that the L1 penalty works correctly when fit_intercept is True\n    X, y = make_classification(n_samples=50, n_features=20, random_state=0)\n    lr_l1 = LogisticRegression(penalty=\"l1\", C=1.0, solver='liblinear',\n                               fit_intercept=True)\n    lr_l1.fit(X, y)\n    assert_array_almost_equal(lr_l1.coef_[0], lr_l1.coef_[0])\n"], "sample_928": ["def test_default_role():\n    with default_role('test.rst', 'myrole'):\n        from docutils.parsers.rst import roles\n        role_fn, _ = roles.role('myrole', english, 0, Reporter('', 4, 4))\n        assert role_fn is not None\n"], "sample_936": ["def test_stringify_generic_types():\n    from typing import Generic, TypeVar\n\n    T = TypeVar('T')\n\n    class MyGeneric(Generic[T]):\n        pass\n\n    assert stringify(MyGeneric) == \"test_util_typing.MyGeneric[T]\"\n    assert stringify(MyGeneric[int]) == \"test_util_typing.MyGeneric[int]\"\n"], "sample_341": ["    def test_all_valid_with_non_form_errors(self):\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '0',\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': '0',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '1',\n        }\n        ChoiceFormSet = formset_factory(Choice, validate_max=True)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [\n            {'__all__': ['This is a non-form error.']},\n            {'__all__': ['This is a non-form error.']}\n        ]\n        formset1._errors = expected_errors\n        formset2._errors = expected_errors\n        self.assertIs(all_valid((formset1, formset2)), False)\n"], "sample_984": ["def test_issue_11821_continued():\n    A = MatrixSymbol(\"A\", 2, 2)\n    B = MatrixSymbol(\"B\", 2, 2)\n    assert str(A[0, 1] + B[1, 0]) == \"A[0, 1] + B[1, 0]\"\n"], "sample_230": ["    def test_custom_encoder_decoder_with_errors(self):\n        class CustomDecoder(json.JSONDecoder):\n                return super().__init__(object_hook=self.as_uuid, *args, **kwargs)\n\n                if 'uuid' in dct:\n                    try:\n                        dct['uuid'] = uuid.UUID(dct['uuid'])\n                    except ValueError:\n                        raise ValidationError('Invalid UUID format')\n                return dct\n\n        value = {'uuid': 'invalid-uuid'}\n        encoded_value = '{\"uuid\": \"invalid-uuid\"}'\n        field = JSONField(encoder=DjangoJSONEncoder, decoder=CustomDecoder)\n        with self.assertRaises(ValidationError):\n            field.clean(encoded_value)\n"], "sample_1002": ["compilation error"], "sample_969": ["def test_stringify_type_hints_typing_Annotated():\n    from typing import Annotated  # type: ignore\n    assert stringify(Annotated[str, \"foo\", \"bar\"], False) == \"Annotated[str, 'foo', 'bar']\"\n    assert stringify(Annotated[str, \"foo\", \"bar\"], True) == \"~typing.Annotated[str, 'foo', 'bar']\"\n"], "sample_240": ["    def test_token_generation_with_custom_email_field(self):\n        \"\"\"\n        Test token generation with a custom email field.\n        \"\"\"\n        class CustomUser(User):\n            email = CustomEmailField()\n\n        CustomUser.objects.create_user('custom_email_user', 'test5@example.com', 'testpw')\n        p0 = PasswordResetTokenGenerator()\n        user = CustomUser.objects.get(username='custom_email_user')\n        tk1 = p0.make_token(user)\n        self.assertIs(p0.check_token(user, tk1), True)\n"], "sample_528": ["def test_reload_library():\n    original_library = style.library.copy()\n    with temp_style('test', DUMMY_SETTINGS):\n        style.reload_library()\n        assert len(style.library) > len(original_library)\n    style.reload_library()\n    assert len(style.library) == len(original_library)\n"], "sample_806": ["def test_gradient_boosting_with_init_estimator_with_sparse_data():\n    # Check that GradientBoostingRegressor works when init is a sklearn\n    # estimator with sparse data.\n    X, y = make_regression(n_samples=100, n_features=10, random_state=0,\n                           sparse_output=True)\n    init_est = LinearRegression()\n    gb = GradientBoostingRegressor(init=init_est)\n    gb.fit(X, y)\n"], "sample_8": ["    def test_masked_array_from_masked_quantity(self):\n        \"\"\"Check that we can initialize a MaskedArray from a MaskedQuantity.\"\"\"\n        np_ma = np.ma.MaskedArray(self.mq)\n        assert type(np_ma) is np.ma.MaskedArray\n        assert type(np_ma.data) is self._data_cls\n        assert type(np_ma.mask) is np.ndarray\n        assert_array_equal(np_ma.data, self.a)\n        assert_array_equal(np_ma.mask, self.mask_a)\n"], "sample_263": ["    def test_loading_with_invalid_data(self):\n        with self.assertRaisesMessage(IntegrityError, \"Cannot add duplicate key\"):\n            management.call_command('loaddata', 'invalid_data.json', verbosity=0)\n"], "sample_916": ["compilation error"], "sample_1188": ["def test_pretty_print_vector_operations():\n    N = CoordSys3D('N')\n    v1 = N.i + N.j\n    v2 = N.i - N.k\n    v3 = 2*N.j\n\n    assert pretty(v1 | v2) == ' (i_N|i_N) + (j_N|i_N) - (i_N|k_N) - (j_N|k_N)'\n    assert pretty(v1 & v2) == ' (i_N|i_N) - (k_N|k_N)'\n    assert pretty(v1 * v2) == '(i_N|i_N) - (k_N|k_N) + (j_N|i_N) - (j_N|k_N)'\n    assert pretty(v1.cross(v2)) == ' (2) k_N'\n    assert pretty(v1.dot(v2)) == ' (1) + (0) - (0) - (0)'\n    assert pretty(v1.cross(v3)) == ' (2) i_N'\n    assert pretty(v1.magnitude()) == 'sqrt(2)'\n    assert pretty(v1.unit_vector()) == ' (1/sqrt(2)) i_N + (1/sqrt(2)) j_N'\n"], "sample_15": ["        def test_fresnel_scalar(self, function):\n            q = function(1.0 * u.m)\n            assert q.unit == u.dimensionless_unscaled\n            assert q.value == function(1.0)\n"], "sample_947": ["def test_intersphinx_references(tempdir, app, status, warning):\n    origSource = \"\"\"\\"], "sample_518": ["def test_default_linewidth():\n    patch = Patch()\n    assert patch.get_linewidth() == rcParams['patch.linewidth']\n\n\n"], "sample_385": ["    def test_render_options_with_empty_values(self):\n        beatles = Band.objects.create(name=\"The Beatles\", style=\"rock\")\n        Album.objects.create(name=\"Rubber Soul\", band=beatles)\n        form = AlbumForm()\n        output = form.as_table()\n        self.assertIn(self.empty_option, output)\n\n\n\n"], "sample_149": ["    def test_custom_permission_name_length_with_spaces(self):\n        custom_permission_name = 'some ridiculously long verbose name that is out of control' * 5\n\n        class Checked(models.Model):\n            class Meta:\n                permissions = [\n                    ('my_custom_permission', custom_permission_name),\n                ]\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The permission named '%s' of model 'auth_tests.Checked' is longer \"\n                \"than 255 characters.\" % custom_permission_name,\n                obj=Checked,\n                id='auth.E008',\n            ),\n        ])\n"], "sample_908": ["def test_unparse_assignment(source, expected):\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0]) == expected\n"], "sample_1035": ["def test_measure_partial():\n    nqubits = 3\n    c = H(0)*H(1)*Qubit('000')\n    q = qapply(c)\n    result = measure_partial(q, (0,))\n    assert len(result) == 2\n    assert result[0][0] == sqrt(2)*|000>/2 + sqrt(2)*|100>/2\n    assert result[1][0] == sqrt(2)*|010>/2 + sqrt(2)*|110>/2\n    \n    result = measure_partial(q, (1,))\n    assert len(result) == 2\n    assert result[0][0] == sqrt(2)*|000>/2 + sqrt(2)*|010>/2\n    assert result[1][0] == sqrt(2)*|100>/2 + sqrt(2)*|110>/2\n    \n    result = measure_partial(q, (0,1))\n    assert len(result) == 2\n    assert result[0][0] == sqrt(2)*|000>/2 + sqrt(2)*|100>/2\n    assert result[1][0] == sqrt(2)*|010>/2 + sqrt(2)*|110>/2\n"], "sample_779": ["def test_check_get_params_invariance():\n    class InvariantEstimator(BaseEstimator):\n            self.a = a\n            self.b = b\n\n            return self\n\n            return {'a': self.a, 'b': self.b}\n\n    check_get_params_invariance('InvariantEstimator', InvariantEstimator())\n"], "sample_365": ["    def test_keep_lazy(self):\n            return x + 1\n\n        @keep_lazy(int)\n            return add_one(x)\n\n        self.assertEqual(lazy_add_one(3), 4)\n        self.assertEqual(lazy_add_one(3) + lazy_add_one(4), 8)\n\n        @keep_lazy(str)\n            return text + \"!\"\n\n        self.assertEqual(lazy_string(\"Hello\")(), \"Hello!\")\n        self.assertEqual(lazy_string(\"Hello\")() + lazy_string(\"World\")(), \"Hello!World!\")\n"], "sample_890": ["def test_scoring_parameter(direction):\n    X, y = make_classification(random_state=0)\n    sfs = SequentialFeatureSelector(\n        KNeighborsClassifier(),\n        n_features_to_select=\"auto\",\n        direction=direction,\n        scoring=\"accuracy\",\n    )\n    sfs.fit(X, y)\n    assert sfs.n_features_to_select_ > 0\n"], "sample_66": ["    def test_get_header_case_insensitive(self):\n        environ = {\n            'CONTENT_TYPE': 'text/html',\n            'CONTENT_LENGTH': '100',\n            'HTTP_HOST': 'example.com',\n            'HTTP_USER_AGENT': 'python-requests/1.2.0',\n        }\n        headers = HttpHeaders(environ)\n        self.assertEqual(headers.get('content-type'), 'text/html')\n        self.assertEqual(headers.get('User-Agent'), 'python-requests/1.2.0')\n        self.assertEqual(headers.get('nonexistent-header'), None)\n\n\n\n"], "sample_402": ["    def test_etag_match_with_gzip(self):\n        \"\"\"\n        GZipMiddleware allows 304 Not Modified responses even when the content\n        is gzipped.\n        \"\"\"\n\n            response = HttpResponse(self.compressible_string)\n            response.headers[\"ETag\"] = '\"eggs\"'\n            return response\n\n            return GZipMiddleware(get_response)(req)\n\n        request = self.rf.get(\"/\", HTTP_ACCEPT_ENCODING=\"gzip, deflate\")\n        response = get_cond_response(request)\n        gzip_etag = response.headers[\"ETag\"]\n        next_request = self.rf.get(\n            \"/\", HTTP_ACCEPT_ENCODING=\"gzip, deflate\", HTTP_IF_NONE_MATCH=gzip_etag\n        )\n        next_response = get_cond_response(next_request)\n        self.assertEqual(next_response.status_code, 304)\n"], "sample_595": ["def test_isnumeric_unicode():\n    values = xr.DataArray([\"123\", \"123\\u00B9\", \"abc\", \"\\u00A7\"])\n    numeric_e = [True, True, False, False]\n    assert_equal(values.str.isnumeric(), xr.DataArray(numeric_e))\n"], "sample_918": ["    def test_pyfunction_signature_with_args(app):\n        text = \".. py:function:: hello(a: int, b: str, *args: int, **kwargs: str)\\n\"\n        domain = app.env.get_domain('py')\n        doctree = restructuredtext.parse(app, text)\n        assert_node(doctree, (addnodes.index,\n                              [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                        [desc_parameterlist,\n                                                         [desc_parameter, desc_sig_name, \"a\"],\n                                                         [desc_sig_punctuation, \":\"],\n                                                         [desc_sig_name, pending_xref, \"int\"],\n                                                         [desc_parameter, desc_sig_name, \"b\"],\n                                                         [desc_sig_punctuation, \":\"],\n                                                         [desc_sig_name, pending_xref, \"str\"],\n                                                         [desc_parameter, desc_sig_operator, \"*\"],\n                                                         [desc_sig_name, \"args\"],\n                                                         [desc_sig_punctuation, \":\"],\n                                                         [desc_sig_name, pending_xref, \"int\"],\n                                                         [desc_parameter, desc_sig_operator, \"**\"],\n                                                         [desc_sig_name, \"kwargs\"],\n                                                         [desc_sig_punctuation, \":\"],\n                                                         [desc_sig_name, pending_xref, \"str\"]]],\n                                                        [desc_content, ()])],\n                              [desc_content, ()]))\n\n\n\n"], "sample_223": ["    def test_ticket_24605_with_related_object(self):\n        \"\"\"\n        Subquery table names should be quoted when related objects are involved.\n        \"\"\"\n        School.objects.create()\n        Student.objects.create(school=School.objects.get(pk=1))\n        qs = Student.objects.filter(Q(pk__in=()) | Q())\n        self.assertQuerysetEqual(qs, [])\n"], "sample_1199": ["def test_tensor_product_combined_printing():\n    combined = True\n    combined_tp = TensorProduct(Qubit('1'), Qubit('2'))\n    assert combined_tp._pretty() == '1\u22972'\n    combined_tp = TensorProduct(Qubit('1'), Qubit('2'), Qubit('3'))\n    assert combined_tp._pretty() == '1\u22972\u22973'\n    combined = False\n    combined_tp = TensorProduct(Qubit('1'), Qubit('2'))\n    assert combined_tp._pretty() == 'Qubit(1)xQubit(2)'\n    combined_tp = TensorProduct(Qubit('1'), Qubit('2'), Qubit('3'))\n    assert combined_tp._pretty() == 'Qubit(1)xQubit(2)xQubit(3)'\n"], "sample_157": ["    def test_deserialize_db_from_string_with_large_data(self):\n        # deserialize_db_from_string() handles large amounts of data.\n        # (This test is simplified, as generating truly large datasets\n        #  is complex and time-consuming.)\n        from django.db import models\n\n        class LargeObject(models.Model):\n            large_text = models.TextField()\n\n        LargeObject.objects.create(large_text=\"A\" * 10000)\n        data = connection.creation.serialize_db_to_string()\n        connection.creation.deserialize_db_from_string(data)\n        large_objects = LargeObject.objects.all()\n        self.assertEqual(len(large_objects), 1)\n        self.assertEqual(large_objects[0].large_text, \"A\" * 10000)\n"], "sample_988": ["def test_issue_14107():\n    x = symbols('x')\n    y = symbols('y')\n    z = symbols('z')\n    assert (x < y) & (y < z) == (x < z)\n    assert (x > y) & (y > z) == (x > z)\n    assert (x <= y) & (y <= z) == (x <= z)\n    assert (x >= y) & (y >= z) == (x >= z)\n"], "sample_142": ["    def test_list_filter_works_on_through_field_with_custom_through_model(self):\n        \"\"\"\n        Ensure list_filter can access reverse fields even when the through model\n        is custom; refs #24146.\n        \"\"\"\n        class CustomThroughModel(models.Model):\n            book = models.ForeignKey(Book, on_delete=models.CASCADE)\n            author = models.ForeignKey(Author, on_delete=models.CASCADE)\n            featured = models.BooleanField(default=False)\n\n        class BookAdminWithCustomThrough(admin.ModelAdmin):\n            list_filter = ['authorsbooks__featured']\n\n        Book.authorsbooks = models.ManyToManyField(\n            Author, through=CustomThroughModel\n        )\n        # Temporarily pretending apps are not ready yet. This issue can happen\n        # if the value of 'list_filter' refers to a 'through__field'.\n        Book._meta.apps.ready = False\n        try:\n            errors = BookAdminWithCustomThrough(Book, AdminSite()).check()\n            self.assertEqual(errors, [])\n        finally:\n            Book._meta.apps.ready = True\n"], "sample_914": ["    def test_unparse_assignment(source, expected):\n        module = ast.parse(source)\n        assert ast.unparse(module.body[0]) == expected\n"], "sample_589": ["def test_interpolate_na_2d_multi_dim_coords():\n    coords = {\"x\": np.arange(4), \"y\": np.arange(11), \"z\": [1, 2, 3, 4]}\n    da = xr.DataArray(\n        [\n            [\n                [1, 2, 3, 4, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n                [1, 2, 3, np.nan, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n                [1, 2, 3, np.nan, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n                [1, 2, 3, 4, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n            ],\n            [\n                [1, 2, 3, 4, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n                [1, 2, 3, np.nan, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n                [1, 2, 3, np.nan, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n                [1, 2, 3, 4, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n            ],\n        ],\n        dims=[\"z\", \"x\", \"y\"],\n        coords=coords,\n    )\n\n    actual = da.interpolate_na(\"y\", max_gap=2)\n    expected_y = xr.DataArray(\n        [\n            [\n                [1, 2, 3, 4, 5, 6, 7, np.nan, np.nan, np.nan, 11],\n                [1,"], "sample_871": ["def test_silhouette_samples_sparse_input_errors():\n    \"\"\"Check for errors when passing invalid sparse matrices to silhouette_samples.\"\"\"\n    X = np.array([[0.2, 0.1, 0.1, 0.2, 0.1, 1.6, 0.2, 0.1]], dtype=np.float32).T\n    y = [0, 0, 0, 0, 1, 1, 1, 1]\n\n    # Test with a non-sparse matrix\n    with pytest.raises(TypeError, match=\"Input X must be a sparse matrix\"):\n        silhouette_samples(X, y)\n\n    # Test with a non-convertible sparse matrix\n    with pytest.raises(TypeError, match=\"Input X must be a sparse matrix\"):\n        silhouette_samples(np.array([[0, 1]]), y)\n\n    # Test with a sparse matrix with wrong shape\n    with pytest.raises(ValueError, match=\"Input X must have shape\"):\n        silhouette_samples(csr_matrix((np.ones(1), (0, 0))), y)\n\n\n\n"], "sample_48": ["    def test_annotate_with_subquery(self):\n        subquery = Book.objects.filter(rating__gt=4).values('id')\n        qs = Book.objects.annotate(\n            related_book_count=Count('id', filter=subquery)\n        ).all()\n        self.assertQuerysetEqual(\n            qs, [\n                {'id': 1, 'related_book_count': 1},\n                {'id': 2, 'related_book_count': 1},\n                {'id': 3, 'related_book_count': 0},\n                {'id': 4, 'related_book_count': 1},\n            ],\n            lambda x: (x['id'], x['related_book_count'])\n        )\n"], "sample_761": ["def test_imputation_add_indicator_sparse_matrix_with_missing_values(arr_type):\n    X_sparse = arr_type([\n        [1, 2, 3],\n        [4, np.nan, 6],\n        [7, 8, np.nan],\n        [9, 10, 11]\n    ])\n    X_true = np.array([\n        [1., 2., 3., 0., 0., 0.],\n        [4., 2., 6., 0., 1., 0.],\n        [7., 8., 6., 0., 0., 1.],\n        [9., 10., 11., 0., 0., 0.],\n    ])\n\n    imputer = SimpleImputer(missing_values=np.nan, add_indicator=True)\n    X_trans = imputer.fit_transform(X_sparse)\n\n    assert sparse.issparse(X_trans)\n    assert X_trans.shape == X_true.shape\n    assert_allclose(X_trans.toarray(), X_true)\n"], "sample_360": ["    def test_cache_key_with_user_and_language(self):\n        request = self.factory.get(self.path)\n        user = User(username='testuser')\n        request.user = user\n        translation.activate('en')\n        template = engines['django'].from_string(\"This is a test\")\n        response = TemplateResponse(request, template)\n        key = get_cache_key(request)\n        self.assertIn('user_testuser', key)\n        self.assertIn('lang_en', key)\n"], "sample_1004": ["def test_CondSet_subs_with_dummy_symbol():\n    c = ConditionSet(x, x < 1, {x, y})\n    assert c.subs(x, y) == ConditionSet(y, y < 1, {y, z})\n    assert c.subs(x, z) == ConditionSet(z, z < 1, {z, y})\n    assert c.subs(x, Symbol('_x')) == ConditionSet('_x', _x < 1, {y, z})\n    assert c.subs(x, Symbol('_x', commutative=False)) == ConditionSet('_x', _x < 1, {y, z})\n"], "sample_640": ["def test_is_overload_stub() -> None:\n    code = astroid.extract_node(\n        \"\"\"\n    from typing import overload\n    @overload\n        pass\n    \"\"\"\n    )\n    assert utils.is_overload_stub(code[0])\n\n    code = astroid.extract_node(\n        \"\"\"\n        pass\n    \"\"\"\n    )\n    assert not utils.is_overload_stub(code[0])\n"], "sample_394": ["    def test_non_admin_url_404_if_authenticated(self):\n        unknown_url = \"/unknown/\"\n        superuser = User.objects.create_superuser(\n            username=\"super\",\n            password=\"secret\",\n            email=\"super@example.com\",\n        )\n        self.client.force_login(superuser)\n        response = self.client.get(unknown_url)\n        self.assertEqual(response.status_code, 404)\n"], "sample_613": ["    def test_resample_with_multiple_coords(self):\n        times = pd.date_range(\"2000-01-01\", freq=\"6H\", periods=10)\n        lat = np.arange(3)\n        lon = np.arange(4)\n        data = np.arange(120).reshape((10, 3, 4))\n        ds = Dataset(\n            {\n                \"data\": ([\"time\", \"lat\", \"lon\"], data),\n                \"time\": times,\n                \"lat\": lat,\n                \"lon\": lon,\n            }\n        )\n\n        actual = ds.resample(time=\"1D\").mean()\n        expected = ds.isel(time=[0, 4, 8]).mean(dim=\"time\")\n        assert_identical(expected, actual)\n\n        actual = ds.resample(time=\"1D\").mean(dim=[\"time\", \"lat\"])\n        expected = ds.groupby(\"lon\").mean(dim=[\"time\", \"lat\"])\n        assert_identical(expected, actual)\n\n        actual = ds.resample(time=\"1D\").mean(dim=[\"time\", \"lon\"])\n        expected = ds.groupby(\"lat\").mean(dim=[\"time\", \"lon\"])\n        assert_identical(expected, actual)\n\n\n\n"], "sample_617": ["    def test_cross_with_different_dims(use_dask: bool) -> None:\n        if use_dask:\n            if not has_dask:\n                pytest.skip(\"requires dask\")\n        a = xr.DataArray(np.arange(3 * 4).reshape(3, 4), dims=[\"x\", \"y\"])\n        b = xr.DataArray(np.arange(2 * 4).reshape(2, 4), dims=[\"y\", \"z\"])\n        with pytest.raises(ValueError):\n            xr.cross(a, b)\n"], "sample_707": ["def test_node_repr_failure_with_fulltrace(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"x\", [1, 2, 3])\n            assert x == 4\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--tb=full\")\n    result.stdout.fnmatch_lines(\n        [\n            str(pytester.pyfile) + \":*: AssertionError\",\n            \"*1 failed in *\",\n            \"*  File *test_node_repr_failure_with_fulltrace.py*:*: AssertionError\",\n            \"*    assert x == 4\",\n            \"*    ^\",\n        ]\n    )\n\n\n\n"], "sample_578": ["    def test_baseline(self, x, y):\n\n        p = Plot(x, y).add(Bars(baseline=2)).plot()\n        ax = p._figure.axes[0]\n        paths = ax.collections[0].get_paths()\n        for i, path in enumerate(paths):\n            verts = path.vertices\n            assert verts[0, 1] == pytest.approx(y[i] - 2)\n            assert verts[3, 1] == pytest.approx(y[i] - 2)\n"], "sample_404": ["    def test_template_debug_info(self):\n        engine = self._engine(debug=True)\n        template = engine.from_string(\"{% if 1 %}{{ 1 + 1 }}{% endif %}\")\n        context = Context()\n        with self.assertRaises(Exception) as e:\n            template.render(context)\n        if self.debug_engine:\n            debug = e.exception.template_debug\n            self.assertEqual(debug[\"start\"], 0)\n            self.assertEqual(debug[\"end\"], 14)\n            self.assertEqual(debug[\"during\"], \"{{ 1 + 1 }}\")\n"], "sample_628": ["    def test_docstring_lines_that_look_like_comments_7(self):\n        stmt = astroid.extract_node(\n            '''def f():"], "sample_532": ["def test_contour_with_masked_array():\n    x = np.arange(10)\n    y = np.arange(10)\n    X, Y = np.meshgrid(x, y)\n    Z = np.exp(-(X**2 + Y**2))\n    mask = np.zeros_like(Z, dtype=bool)\n    mask[5, 5] = True\n    masked_Z = np.ma.array(Z, mask=mask)\n\n    fig, ax = plt.subplots()\n    cs = ax.contour(X, Y, masked_Z)\n    assert isinstance(cs._contour_generator, contourpy.ContourGenerator)\n    assert all(isinstance(c, contourpy.ContourLine) for c in cs.collections)\n    ax.clabel(cs)\n    plt.show()\n"], "sample_979": ["def test_transpose_simplify():\n    A = MatrixSymbol('A', n, m)\n    assert (A.T).T == A\n    assert (A + B).T == A.T + B.T\n    assert (A*B).T == B.T * A.T\n    assert (MatPow(A, 2)).T == MatPow(A.T, 2)\n    assert (Inverse(A)).T == Inverse(A.T)\n    assert (Adjoint(A)).T == Adjoint(A.T)\n"], "sample_275": ["    def test_delete_with_subquery(self):\n        \"\"\"\n        Deleting objects using a subquery should work correctly.\n        \"\"\"\n        h1 = House.objects.create(address='Foo')\n        h2 = House.objects.create(address='Bar')\n        OrderedPerson.objects.create(name='Jack', lives_in=h1)\n        OrderedPerson.objects.create(name='Bob', lives_in=h2)\n        OrderedPerson.objects.filter(\n            lives_in_id__in=House.objects.filter(address='Foo').values_list('id', flat=True)\n        ).delete()\n        self.assertEqual(OrderedPerson.objects.count(), 1)\n"], "sample_951": ["        def __new__(cls, *args, **kwargs):\n            return super().__new__(cls, *args, **kwargs)\n"], "sample_392": ["    def test_key_transform_with_nested_lookup(self):\n        obj = NullableJSONModel.objects.create(\n            value={\"d\": [{\"e\": {\"f\": \"g\"}}]}\n        )\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(\n                value__d__0__e__f=\"g\"\n            ),\n            [obj],\n        )\n"], "sample_795": ["def test_check_get_params_invariance():\n    # check that get_params(deep=False) is a subset of get_params(deep=True)\n    for estimator in [LinearRegression(), SGDClassifier(),\n                      RandomForestClassifier(), GaussianMixture(),\n                      MiniBatchKMeans()]:\n        estimator = clone(estimator)\n        check_get_params_invariance(estimator.__class__.__name__, estimator)\n"], "sample_799": ["def test_score_with_custom_scorer_function():\n        return np.mean(estimator.predict(X) == y)\n    X, y = make_classification(n_samples=30, random_state=0)\n    clf = SVC(kernel=\"linear\", random_state=0)\n    clf.fit(X, y)\n    score = _score(clf, X, y, custom_scorer)\n    assert isinstance(score, float)\n    assert 0.0 <= score <= 1.0\n\n\n\n"], "sample_1109": ["def test_issue_19117():\n    assert floor(sqrt(x)).is_integer is False\n    assert ceiling(sqrt(x)).is_integer is False\n"], "sample_1137": ["def test_issue_16599():\n    from sympy.physics.units import Quantity\n    from sympy.physics.units.prefixes import kilo\n    from sympy.physics.units.definitions import meter\n\n    q = Quantity(\"q\")\n    q.set_global_relative_scale_factor(1000, meter)\n    assert q.name == \"q\"\n    assert q.abbrev == \"q\"\n    assert q.scale_factor == 1000*meter\n    assert q.dimension == meter.dimension\n    assert q.convert_to(meter) == 1000*meter\n    assert q.convert_to(kilo*meter) == 1000*meter\n\n\n\n"], "sample_214": ["    def test_contains_with_nested_key_transform(self):\n        self.assertIs(NullableJSONModel.objects.filter(\n            value__baz__contains=KeyTransform('a', KeyTransform('b', 'value'))\n        ).exists(), True)\n"], "sample_1194": ["def test_indexed_base():\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z')\n    a = IndexedBase('a', shape=(3,))\n    b = IndexedBase('b', shape=(2, 2))\n    c = IndexedBase('c', shape=(3, 2))\n\n    assert julia_code(a[0]) == \"a[1]\"\n    assert julia_code(a[1:3]) == \"a[2:4]\"\n    assert julia_code(a[0:2]) == \"a[1:3]\"\n    assert julia_code(b[0, 0]) == \"b[1, 1]\"\n    assert julia_code(b[1, 1:2]) == \"b[2, 2]\"\n    assert julia_code(c[0:2, 1]) == \"c[1:3, 2]\"\n    assert julia_code(a[x]) == \"a[x + 1]\"\n    assert julia_code(b[y, z]) == \"b[y + 1, z + 1]\"\n    assert julia_code(c[x, y]) == \"c[x + 1, y + 1]\"\n"], "sample_965": ["def test_getfullargspec_with_defaults():\n        pass\n\n    argspec = inspect.getfullargspec(func)\n    assert argspec.args == ['a', 'b']\n    assert argspec.varargs == 'args'\n    assert argspec.varkw == 'kwargs'\n    assert argspec.defaults == (1,)\n\n\n"], "sample_97": ["    def test_snapshot_files_with_non_existent_files(self):\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file, self.nonexistent_file]):\n            snapshot = dict(self.reloader.snapshot_files())\n            self.assertIn(self.existing_file, snapshot)\n            self.assertNotIn(self.nonexistent_file, snapshot)\n"], "sample_543": ["def test_MultiCursor_reset(horizOn, vertOn):\n    (ax1, ax3) = plt.figure().subplots(2, sharex=True)\n    ax2 = plt.figure().subplots()\n\n    multi = widgets.MultiCursor(\n        None, (ax1, ax2), useblit=False, horizOn=horizOn, vertOn=vertOn\n    )\n\n    # move the cursor\n    event = mock_event(ax1, xdata=.5, ydata=.25)\n    multi.onmove(event)\n\n    # reset the cursor\n    multi.reset()\n\n    # check that the cursor is back to its initial state\n    for l in multi.vlines:\n        assert l.get_xdata() == (0, 0)\n    for l in multi.hlines:\n        assert l.get_ydata() == (0, 0)\n"], "sample_1206": ["def test_issue_11103():\n    assert Float('1.0000000000000002').as_mpf() == mpf('1.0000000000000002')\n"], "sample_891": ["def test_roc_curve_with_multiclass_labels():\n    from sklearn.metrics import roc_curve\n\n    y_true = np.array([0, 0, 1, 1, 2, 2, 2])\n    y_score = np.array([[0.1, 0.2, 0.3],\n                        [0.4, 0.5, 0.6],\n                        [0.7, 0.8, 0.9],\n                        [0.1, 0.2, 0.3],\n                        [0.4, 0.5, 0.6],\n                        [0.7, 0.8, 0.9]])\n\n    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=1)\n    assert fpr.shape == (len(thresholds),)\n    assert tpr.shape == (len(thresholds),)\n    assert thresholds.shape == (len(thresholds),)\n\n    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=2)\n    assert fpr.shape == (len(thresholds),)\n    assert tpr.shape == (len(thresholds),)\n    assert thresholds.shape == (len(thresholds),)\n\n\n\n"], "sample_864": ["def test_bin_seeding_with_large_data():\n    # Test bin seeding with a larger dataset\n    X, _ = make_blobs(n_samples=1000, n_features=2, centers=centers,\n                      cluster_std=0.4, shuffle=True, random_state=11)\n    ms = MeanShift(bin_seeding=True, bandwidth=1.2)\n    ms.fit(X)\n    assert len(ms.cluster_centers_) > 0\n\n\n\n"], "sample_408": ["    def test_suggest_name_with_custom_operations(self):\n        class CustomOperation(migrations.MigrationOperation):\n                self.name = name\n\n        class Migration(migrations.Migration):\n            operations = [\n                CustomOperation(\"create_person\"),\n                CustomOperation(\"delete_animal\"),\n            ]\n\n        migration = Migration(\"some_migration\", \"test_app\")\n        self.assertEqual(migration.suggest_name(), \"create_person_delete_animal\")\n"], "sample_616": ["compilation error"], "sample_78": ["    def test_normalize_path_patterns_handles_trailing_slashes(self):\n        expected = [os.path.normcase(p) for p in ['foo/bar/', 'bar/']]\n        self.assertEqual(normalize_path_patterns(['foo/bar/**/', 'bar/']), expected)\n"], "sample_829": ["def test_incremental_pca_batch_size_zero():\n    # Test that IncrementalPCA handles batch_size=0 correctly.\n    rng = np.random.RandomState(1999)\n    n_samples = 100\n    n_features = 3\n    X = rng.randn(n_samples, n_features)\n\n    ipca = IncrementalPCA(n_components=2, batch_size=0)\n    with pytest.raises(ValueError, match=\"batch_size must be positive\"):\n        ipca.fit(X)\n"], "sample_1167": ["def test_latex_printing_of_matrices_with_symbols():\n    from sympy import Matrix, symbols\n\n    x, y, z = symbols('x y z')\n    A = Matrix([[x, y], [z, x]])\n    assert latex(A) == r\"\\begin{bmatrix} x & y \\\\ z & x \\end{bmatrix}\"\n    assert latex(A, use_unicode=False) == r\"\\begin{bmatrix} x & y \\\\ z & x \\end{bmatrix}\"\n"], "sample_462": ["    def test_choicefield_empty_values(self):\n        f = ChoiceField(choices=[(\"1\", \"One\"), (\"2\", \"Two\")], empty_values=[\"\", None])\n        self.assertEqual(\"\", f.clean(\"\"))\n        self.assertEqual(None, f.clean(None))\n        self.assertEqual(\"1\", f.clean(1))\n        self.assertEqual(\"1\", f.clean(\"1\"))\n        msg = \"'Select a valid choice. 3 is not one of the available choices.'\"\n        with self.assertRaisesMessage(ValidationError, msg):\n            f.clean(\"3\")\n"], "sample_1000": ["def test_IndexedBase():\n    x = Symbol('x')\n    y = Symbol('y')\n    i = Idx('i')\n    j = Idx('j')\n    \n    a = IndexedBase('a', shape=(5, 5))\n    b = IndexedBase('b', shape=(3,))\n    \n    assert mcode(a[i, j]) == \"a(i, j)\"\n    assert mcode(a[i, j] + b[i]) == \"a(i, j) + b(i)\"\n    assert mcode(a[i, j] * b[j]) == \"a(i, j) .* b(j)\"\n    assert mcode(a[i, j] / b[i]) == \"a(i, j) ./ b(i)\"\n    assert mcode(a[i, j]**2) == \"a(i, j).^2\"\n    assert mcode(a[i, j] * x) == \"x.*a(i, j)\"\n    assert mcode(a[i, j] * y) == \"y.*a(i, j)\"\n    assert mcode(a[i, j] * x * y) == \"x.*y.*a(i, j)\"\n"], "sample_609": ["def test_polyval_broadcast(use_dask) -> None:\n    if use_dask and not has_dask:\n        pytest.skip(\"requires dask\")\n\n    xcoord = np.arange(10)\n    da = xr.DataArray(\n        np.stack((1.0 + xcoord + 2.0 * xcoord ** 2, 1.0 + 2.0 * xcoord + 3.0 * xcoord ** 2)),\n        dims=(\"d\", \"x\"),\n        coords={\"x\": xcoord, \"d\": [0, 1]},\n    )\n    coeffs = xr.DataArray(\n        [[2, 1, 1], [3, 2, 1]],\n        dims=(\"d\", \"degree\"),\n        coords={\"d\": [0, 1], \"degree\": [2, 1, 0]},\n    )\n    if use_dask:\n        coeffs = coeffs.chunk({\"d\": 2})\n\n    # Broadcast coefficients to have a dimension matching da\n    coeffs_broadcasted = xr.broadcast_like(coeffs, da)\n\n    da_pv = xr.polyval(da.x, coeffs_broadcasted)\n\n    xr.testing.assert_allclose(da, da_pv.T)\n"], "sample_896": ["def test_nmf_sparse_input():\n    # Test that NMF works correctly with sparse input data\n    n_samples = 20\n    n_features = 10\n    n_components = 5\n    alpha = 0.1\n    l1_ratio = 0.5\n    n_iter = 20\n\n    # Create a sparse matrix\n    rng = np.random.mtrand.RandomState(42)\n    X = sp.csr_matrix(rng.randn(n_samples, n_features))\n\n    # Test NMF with sparse input\n    nmf = NMF(\n        n_components=n_components,\n        alpha_W=alpha,\n        l1_ratio=l1_ratio,\n        random_state=42,\n        solver=\"mu\",\n    )\n    W = nmf.fit_transform(X)\n    H = nmf.components_\n\n    # Check that the results are valid\n    assert isinstance(W, sp.csr_matrix)\n    assert isinstance(H, sp.csr_matrix)\n    assert W.shape == (n_samples, n_components)\n    assert H.shape == (n_components, n_features)\n\n    # Test MiniBatchNMF with sparse input\n    mbnmf = MiniBatchNMF(\n        n_components=n_components,\n        alpha_W=alpha,\n        l1_ratio=l1_ratio,\n        random_state=42,\n        solver=\"mu\",\n    )\n    W_mb = mbnmf.fit_transform(X)\n    H_mb = mbnmf.components_\n\n    # Check that the results are valid\n    assert isinstance(W_mb, sp.csr_matrix)\n    assert isinstance(H_mb, sp.csr_matrix)\n    assert W_mb.shape == (n_samples, n_components)\n    assert H_mb.shape == (n_components, n_features)\n\n    # Check that the results are close\n    assert_allclose(W, W_mb)\n    assert_allclose(H, H_mb)\n"], "sample_110": ["    def test_in_lookup_with_related_field(self):\n        \"\"\"\n        Test pickling and unpickling a QuerySet with an __in=inner_qs\n        lookup involving a related field.\n        \"\"\"\n        events = Event.objects.filter(group__in=Group.objects.filter(name__contains='Group 1').values_list('id', flat=True))\n\n        with self.assertNumQueries(0):\n            dumped = pickle.dumps(events.query)\n\n        with self.assertNumQueries(0):\n            reloaded = pickle.loads(dumped)\n            reloaded_events = Event.objects.none()\n            reloaded_events.query = reloaded\n\n        self.assertSequenceEqual(reloaded_events, [self.e1])\n"], "sample_565": ["def test_grid_with_axes_class_not_overriding_axis():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 2), axes_class=mpl.axes.Axes)\n    for ax in grid:\n        ax.plot([1, 2, 3], [4, 5, 6])\n"], "sample_665": ["def test_collect_with_broken_symlink(testdir):\n    sub = testdir.mkdir(\"sub\")\n    sub.ensure(\"test_file.py\").write(\"def test_file(): pass\")\n\n    # Create a broken symlink.\n    sub.join(\"test_broken.py\").mksymlinkto(\"test_doesnotexist.py\")\n\n    result = testdir.runpytest(\"-v\", str(sub))\n    result.stdout.fnmatch_lines(\n        [\n            \"sub/test_file.py::test_file PASSED*\",\n            \"*1 passed in*\",\n        ]\n    )\n"], "sample_139": ["    def test_bulk_actions_with_no_selection(self):\n        \"\"\"\n        Bulk actions should be disabled when no rows are selected (#22038).\n        \"\"\"\n        self.admin_login(username='super', password='secret')\n        self.selenium.get(self.live_server_url + reverse('admin:auth_user_changelist'))\n\n        form_id = '#changelist-form'\n        bulk_actions = self.selenium.find_elements_by_css_selector(\n            '%s .action-select' % form_id)\n        self.assertEqual(len(bulk_actions), 1)\n\n        # Check that the bulk actions dropdown is disabled\n        bulk_actions_dropdown = self.selenium.find_element_by_css_selector(\n            '%s .action-select' % form_id)\n        self.assertTrue(bulk_actions_dropdown.is_enabled())\n\n        # Simulate no rows being selected\n        # This is a bit hacky, but it's the best way to test this scenario\n        # without actually selecting any rows.\n        self.selenium.execute_script(\n            \"document.querySelector('%s .action-select').checked = false\" % form_id)\n\n        # Check that the bulk actions dropdown is disabled\n        bulk_actions_dropdown = self.selenium.find_element_by_css_selector(\n            '%s .action-select' % form_id)\n        self.assertFalse(bulk_actions_dropdown.is_enabled())\n\n\n\n"], "sample_1001": ["def test_issue_15061():\n    from sympy.physics.units import meter, second\n    t = symbols('t')\n    v = 10*meter/second\n    assert latex(v.subs(t, 2*second)) == r'10 \\frac{\\text{meter}}{\\text{second}}'\n"], "sample_202": ["    def test_not_finished_sentinel(self):\n        storage = self.get_storage()\n        response = self.get_response()\n\n        # Store a large number of messages, exceeding the cookie size limit.\n        messages = [Message(constants.INFO, str(i)) for i in range(100)]\n        storage.update(response, messages)\n\n        # Retrieve the messages from the cookie.\n        retrieved_messages = list(storage)\n\n        # Check that the sentinel value was used and removed.\n        self.assertEqual(len(retrieved_messages), 99)\n        self.assertEqual(retrieved_messages[-1].message, '99')\n\n        # Check that the cookie size is now smaller.\n        self.assertEqual(stored_cookie_messages_count(storage, response), 99)\n\n\n\n"], "sample_576": ["    def test_default_object_in_plot(self):\n\n        p = Plot().add(Default())\n        p.plot()\n        assert len(p._figure.axes) == 1\n        assert len(p._figure.legends) == 0\n"], "sample_785": ["def test_repeated_stratified_kfold_determinstic_split():\n    X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n    y = [1, 1, 1, 0, 0]\n    random_state = 1944695409\n    rskf = RepeatedStratifiedKFold(\n        n_splits=2,\n        n_repeats=2,\n        random_state=random_state)\n\n    # split should produce same and deterministic splits on\n    # each call\n    for _ in range(3):\n        splits = rskf.split(X, y)\n        train, test = next(splits)\n        assert_array_equal(train, [1, 2, 3])\n        assert_array_equal(test, [4, 5])\n\n        train, test = next(splits)\n        assert_array_equal(train, [0, 1, 2, 3])\n        assert_array_equal(test, [4, 5])\n\n        assert_raises(StopIteration, next, splits)\n\n\n\n"], "sample_544": ["def test_imshow_masked_array():\n    data = np.ma.masked_array(np.arange(10), mask=[True, False, True, False,\n                                                  True, False, True, False,\n                                                  True, False])\n    fig, ax = plt.subplots()\n    ax.imshow(data)\n    fig.canvas.draw()\n    assert ax.images[0].get_array().shape == (10,)\n"], "sample_934": ["compilation error"], "sample_957": ["def test_stringify_type_hints_Callable_args(annotation, expected):\n    assert stringify(annotation) == expected\n"], "sample_245": ["    def test_makemessages_no_settings_with_locale_path(self):\n        with override_settings(LOCALE_PATHS=['/tmp/locale']):\n            out, err = self.run_django_admin(['makemessages', '-l', 'en', '-v', '0'])\n        self.assertNoOutput(err)\n        self.assertNoOutput(out)\n"], "sample_726": ["compilation error"], "sample_167": ["    def test_naturaltime_with_timezone(self):\n        tz_aware_now = datetime.datetime.now(tz=utc)\n        tz_naive_now = datetime.datetime.now()\n\n        test_list = [\n            tz_aware_now,\n            tz_aware_now - datetime.timedelta(seconds=1),\n            tz_aware_now - datetime.timedelta(days=1),\n            tz_naive_now,\n            tz_naive_now - datetime.timedelta(seconds=1),\n            tz_naive_now - datetime.timedelta(days=1),\n        ]\n        result_list = [\n            'now',\n            'a second ago',\n            '1 day ago',\n            'now',\n            'a second ago',\n            '1 day ago',\n        ]\n\n        orig_humanize_datetime, humanize.datetime = humanize.datetime, MockDateTime\n        try:\n            with override_settings(USE_TZ=True):\n                with translation.override('en'):\n                    self.humanize_tester(test_list, result_list, 'naturaltime')\n        finally:\n            humanize.datetime = orig_humanize_datetime\n"], "sample_827": ["def test_inplace_row_scale_with_large_indices():\n    X = np.array([[0, 3, 0],\n                  [2, -1, 0],\n                  [0, 0, 0],\n                  [9, 8, 7],\n                  [4, 0, 5]], dtype=np.float64)\n    X_csr = sp.csr_matrix(X)\n    X_csr.indices = X_csr.indices.astype('int64')\n    X_csr.indptr = X_csr.indptr.astype('int64')\n\n    scale = np.array([1.0, 2.0, 3.0], dtype=np.float64)\n    inplace_row_scale(X_csr, scale)\n    assert_array_almost_equal(X_csr.toarray(), X * scale[:, None])\n"], "sample_945": ["def test_warn_missing_reference_with_module(app, status, warning):\n    app.build()\n    assert 'index.rst:6: WARNING: undefined label: no-label' in warning.getvalue()\n    assert ('index.rst:6: WARNING: Failed to create a cross reference. A title or caption not found: existing-label'\n            in warning.getvalue())\n"], "sample_702": ["compilation error"], "sample_451": ["    def test_replace_metacharacters(self):\n        pattern = r\"^(?:\\w+)(?:\\w+)?\\?\"\n        self.assertEqual(replace_metacharacters(pattern), r\"^(?:\\w+)(?:\\w+)?\\\\?\")\n        pattern = r\"^(?:\\w+)(?:\\w+)?\\*\"\n        self.assertEqual(replace_metacharacters(pattern), r\"^(?:\\w+)(?:\\w+)?\\\\*\")\n        pattern = r\"^(?:\\w+)(?:\\w+)?\\+\"\n        self.assertEqual(replace_metacharacters(pattern), r\"^(?:\\w+)(?:\\w+)?\\\\+\")\n        pattern = r\"^(?:\\w+)(?:\\w+)?\\$\"\n        self.assertEqual(replace_metacharacters(pattern), r\"^(?:\\w+)(?:\\w+)?\\\\$\")\n"], "sample_787": ["def test_balanced_accuracy_score_with_multilabel_data():\n    y_true = np.array([[0, 1], [1, 0], [0, 1], [1, 1]])\n    y_pred = np.array([[0, 1], [1, 0], [0, 1], [1, 1]])\n    balanced = balanced_accuracy_score(y_true, y_pred)\n    assert_almost_equal(balanced, 1.0)\n    \n    y_true = np.array([[0, 1], [1, 0], [0, 1], [1, 0]])\n    y_pred = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n    balanced = balanced_accuracy_score(y_true, y_pred)\n    assert_almost_equal(balanced, 0.75)\n"], "sample_775": ["def test_changed_only_with_nested_estimators():\n    # Make sure changed_only works correctly with nested estimators\n    set_config(print_changed_only=True)\n    pipeline = Pipeline([\n        ('scaler', StandardScaler()),\n        ('clf', LogisticRegression(C=999, random_state=42))\n    ])\n    pipeline.fit(X, y)\n    expected = \"\"\""], "sample_403": ["    def test_references_field_by_related_name(self):\n        operation = FieldOperation(\n            \"Model\",\n            \"field\",\n            models.ForeignKey(\"Other\", models.CASCADE, related_name=\"related_field\"),\n        )\n        self.assertIs(\n            operation.references_field(\"Other\", \"related_field\", \"migrations\"), True\n        )\n        self.assertIs(\n            operation.references_field(\"Other\", \"whatever\", \"migrations\"), False\n        )\n"], "sample_1155": ["def test_issue_14590():\n    from sympy.polys.domains import QQ_I\n    assert construct_domain([I*x, 2*I*y], extension=True) == (\n        QQ_I.algebraic_field(I*x, 2*I*y),\n        [QQ_I.algebraic_field(I*x, 2*I*y).convert(I*x),\n         QQ_I.algebraic_field(I*x, 2*I*y).convert(2*I*y)]\n    )\n"], "sample_1209": ["def test_latex_repr():\n    assert PREFIXES['m']._latex(None) == r'\\text{m}'\n    assert PREFIXES['k']._latex(None) == r'\\text{k}'\n    assert PREFIXES['m']._latex(None) == r'\\text{m}'\n    assert kibi._latex(None) == r'\\text{kibi}'\n"], "sample_12": ["def test_angle_from_string_with_units():\n    \"\"\"\n    Test that Angle can be created from a string with units\n    \"\"\"\n    a1 = Angle('10d 20m 30s', unit=u.deg)\n    assert a1.value == 10.333333333333333\n    assert a1.unit == u.deg\n\n    a2 = Angle('10h 20m 30s', unit=u.hourangle)\n    assert a2.value == 10.333333333333333\n    assert a2.unit == u.hourangle\n\n    a3 = Angle('10d 20m 30s', unit=u.rad)\n    assert a3.value == 0.17808833333333334\n    assert a3.unit == u.rad\n\n    # Test with mixed units\n    with pytest.raises(ValueError):\n        Angle('10d 20m 30s', unit=u.deg, unit_of_time=u.hour)\n\n\n\n"], "sample_1187": ["def test_polytope_integrate_with_negative_coefficients():\n    polygon = Polygon((0, 0), (1, 0), (1, 1), (0, 1))\n    polys = [-1, -x, -y, -x*y, x**2*y, x*y**2]\n    assert polytope_integrate(polygon, polys) == \\\n        {-1: -1, x: -S.Half, y: -S.Half, x*y: -Rational(1, 4), x**2*y: -Rational(1, 6), x*y**2: -Rational(1, 6)}\n"], "sample_1179": ["def test_issue_23411():\n    from sympy.tensor.array import Array\n    a = Array([1, 2, 3], shape=(3,))\n    assert str(a) == 'Array([1, 2, 3], shape=(3,))'\n"], "sample_203": ["    def test_value_placeholder_with_custom_validator(self):\n        class MyCustomValidator(object):\n                if value == 'invalid':\n                    raise ValidationError('Custom error message.', code='custom_error')\n                return value\n\n        class MyForm(forms.Form):\n            field = forms.CharField(\n                validators=[MyCustomValidator()],\n                error_messages={'custom_error': '%(value)s'},\n            )\n\n        form = MyForm({'field': 'invalid'})\n        self.assertIs(form.is_valid(), False)\n        self.assertEqual(form.errors, {'field': ['Custom error message.']})\n"], "sample_1196": ["def test_contains_with_symbols():\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z')\n    assert Contains(x, FiniteSet(y, z)) == Contains(x, FiniteSet(y, z), evaluate=False)\n    assert Contains(x, FiniteSet(y, z)).as_set() == FiniteSet(y, z)\n"], "sample_423": ["    def test_operation_with_custom_name(self):\n        class Migration(migrations.Migration):\n            operations = [\n                migrations.CreateModel(\n                    \"Person\", fields=[], name=\"my_person_model\"\n                ),\n            ]\n\n        migration = Migration(\"some_migration\", \"test_app\")\n        self.assertEqual(migration.suggest_name(), \"my_person_model\")\n"], "sample_816": ["def test_vectorizer_with_empty_input(Estimator):\n    with pytest.raises(ValueError, match=\"Input array is empty\"):\n        Estimator().fit_transform([])\n"], "sample_663": ["compilation error"], "sample_337": ["    def test_csrf_token_on_500_stays_constant(self):\n        response = self.client.get('/internal_server_error/')\n        # The error handler returns status code 599.\n        self.assertEqual(response.status_code, 599)\n        token1 = response.content\n        response = self.client.get('/internal_server_error/')\n        self.assertEqual(response.status_code, 599)\n        token2 = response.content\n        self.assertTrue(equivalent_tokens(token1.decode('ascii'), token2.decode('ascii')))\n"], "sample_56": ["    def test_list_filter_works_on_through_field_with_custom_through_model(self):\n        class CustomThroughModel(models.Model):\n            book = models.ForeignKey(Book, on_delete=models.CASCADE)\n            author = models.ForeignKey(Author, on_delete=models.CASCADE)\n            is_featured = models.BooleanField(default=False)\n\n        class Book(models.Model):\n            title = models.CharField(max_length=200)\n            authorsbooks = models.ManyToManyField(\n                Author, through=CustomThroughModel\n            )\n\n        class Author(models.Model):\n            name = models.CharField(max_length=200)\n\n        class BookAdminWithListFilter(admin.ModelAdmin):\n            list_filter = ['authorsbooks__is_featured']\n\n        errors = BookAdminWithListFilter(Book, AdminSite()).check()\n        self.assertEqual(errors, [])\n"], "sample_681": ["def test_log_file_cli_with_existing_file(testdir):\n    path = testdir.makepyfile(\"\"\" def test_logger(): pass \"\"\")\n    log_file = os.path.join(os.path.dirname(str(path)), \"foo/bar/logf.log\")\n    with open(log_file, \"w\") as f:\n        f.write(\"Existing content\")\n    result = testdir.runpytest(\"--log-file=foo/bar/logf.log\")\n    assert \"Existing content\" in open(log_file).read()\n    assert result.ret == ExitCode.OK\n"], "sample_285": ["    def test_find_in_filesystem_finder(self):\n        finder = get_finder('django.contrib.staticfiles.finders.FileSystemFinder')\n        path = 'css/style.css'\n        absolute_path = finder.find(path)\n        self.assertEqual(absolute_path, Path(TEST_ROOT, 'project', 'static', 'css', 'style.css'))\n"], "sample_492": ["    def test_serialize_custom_field(self):\n        class MyCustomField(models.Field):\n                super().__init__(**kwargs)\n\n                return 'MyCustomField'\n\n                return 'MyCustomField'\n\n                return value\n\n                return value\n\n        class MyModel(models.Model):\n            my_field = MyCustomField()\n\n        string, imports = MigrationWriter.serialize(MyModel)\n        self.assertIn(\"MyCustomField\", string)\n        self.assertIn(\"from migrations.test_writer import MyCustomField\", imports)\n"], "sample_255": ["    def test_close_connection(self):\n        request = WSGIRequest(self.request_factory.get('/').environ)\n        client_address = ('192.168.2.0', 8080)\n        server = WSGIServer(('localhost', 0), WSGIRequestHandler)\n        handler = WSGIRequestHandler(request, client_address, server)\n        handler.close_connection = True\n        handler.handle_one_request()\n        self.assertTrue(handler.connection.closed)\n        server.server_close()\n"], "sample_824": ["def test_pairwise_distances_with_precomputed():\n    # check that pairwise_distances works with precomputed distances\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((10, 10))\n    D = cdist(X, X)\n    D_chunked = pairwise_distances_chunked(D, metric='precomputed')\n    assert_allclose(D, D_chunked)\n"], "sample_1024": ["def test_issue_10828():\n    assert Float(1.23456789012345678901234567890123, 100) == Float(1.23456789012345678901234567890123, 100)\n    assert Float(1.23456789012345678901234567890123, 100) != Float(1.23456789012345678901234567890124, 100)\n"], "sample_434": ["    def test_redirect_view_handles_missing_url(self):\n        class RedirectViewWithoutUrl(RedirectView):\n            permanent = False\n\n        view = RedirectViewWithoutUrl()\n        response = view.get(RequestFactory().get(\"/\"))\n        self.assertEqual(response.status_code, 410)\n        self.assertEqual(response.content, b\"Gone\")\n"], "sample_219": ["    def test_output_field_from_expression(self):\n        expr = ExpressionWrapper(\n            F('name') + Value(' '),\n            output_field=CharField(),\n        )\n        self.assertEqual(expr.output_field, CharField())\n"], "sample_476": ["    def test_multiple_assignments(self):\n        p = self.PersonModel(name=\"Joe\")\n        p.mugshot = self.file1\n        self.check_dimensions(p, 4, 8, \"mugshot\")\n        p.mugshot = self.file2\n        self.check_dimensions(p, 8, 4, \"mugshot\")\n        p.headshot = self.file1\n        self.check_dimensions(p, 8, 4, \"mugshot\")\n        self.check_dimensions(p, 4, 8, \"headshot\")\n        p.headshot = self.file2\n        self.check_dimensions(p, 8, 4, \"mugshot\")\n        self.check_dimensions(p, 8, 4, \"headshot\")\n"], "sample_606": ["def test_broadcast_like(use_dask) -> None:\n    if use_dask and not has_dask:\n        pytest.skip(\"requires dask\")\n\n    a = np.arange(30).reshape(3, 10)\n    b = np.arange(10).reshape(10)\n\n    da_a = xr.DataArray(a, dims=[\"a\", \"b\"])\n    da_b = xr.DataArray(b, dims=\"b\")\n\n    if use_dask:\n        da_a = da_a.chunk({\"a\": 2})\n        da_b = da_b.chunk({\"b\": 2})\n\n    actual = xr.broadcast_like(da_a, da_b)\n    expected = xr.DataArray(np.broadcast_to(b, a.shape), dims=da_a.dims)\n    assert_identical(expected, actual)\n\n\n"], "sample_883": ["def test_bayesian_ridge_ard_fit_intercept_with_constant_input():\n    # Test BayesianRidge and ARDRegression with fit_intercept=False on\n    # a dataset where the target is a constant\n    n_samples = 10\n    n_features = 5\n    random_state = check_random_state(42)\n    constant_value = random_state.rand()\n    X = random_state.random_sample((n_samples, n_features))\n    y = np.full(n_samples, constant_value, dtype=np.array(constant_value).dtype)\n\n    for clf in [BayesianRidge(fit_intercept=False), ARDRegression(fit_intercept=False)]:\n        clf.fit(X, y)\n        # Check that the intercept is zero\n        assert clf.intercept_ == 0.0\n        # Check that the model predicts the constant value\n        assert_array_almost_equal(clf.predict(X), y)\n"], "sample_693": ["    def test_do_cleanups_on_teardown_failure_with_multiple_cleanups(pytester: Pytester) -> None:\n        testpath = pytester.makepyfile(\n            \"\"\"\n            import unittest\n            class MyTestCase(unittest.TestCase):\n                values = []\n                        self.values.append(1)\n                        self.values.append(2)\n                    self.addCleanup(cleanup1)\n                    self.addCleanup(cleanup2)\n                    assert False\n                    pass\n                    pass\n                assert MyTestCase.values == [1, 2, 1, 2]\n            \"\"\"\n        )\n        reprec = pytester.inline_run(testpath)\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == 2\n        assert passed == 1\n"], "sample_100": ["    def test_snapshot_files_with_non_existing_files(self):\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.nonexistent_file]):\n            snapshot = dict(self.reloader.snapshot_files())\n            self.assertNotIn(self.nonexistent_file, snapshot)\n"], "sample_231": ["    def test_sensitive_variables_decorator_with_args(self):\n        @sensitive_variables\n            return f'Password: {password}, Secret Key: {secret_key}'\n\n        with self.settings(DEBUG=True):\n            response = self.client.post('/test_view/', data={'password': 'secret', 'secret_key': 'super_secret'})\n            self.assertContains(response, 'Password: XXXXXXXXXXXXXXX, Secret Key: XXXXXXXXXXXXXXX', status_code=500)\n"], "sample_266": ["    def test_circular_dependencies(self):\n        with self.assertRaises(AmbiguityError):\n            MigrationLoader(connection)\n"], "sample_111": ["    def test_bulk_edit_with_list_editable_fields(self):\n        \"\"\"\n        Bulk edit functionality works correctly with list_editable fields\n        (#17198).\n        \"\"\"\n        superuser = self._create_superuser('superuser')\n        m = SwallowAdmin(Swallow, custom_site)\n        request = self._mocked_authenticated_request('/swallow/', superuser)\n        data = {\n            'form-TOTAL_FORMS': '2',\n            'form-INITIAL_FORMS': '2',\n            'form-MIN_NUM_FORMS': '0',\n            'form-MAX_NUM_FORMS': '1000',\n            'form-0-uuid': str(Swallow.objects.get(origin='Swallow A').pk),\n            'form-0-load': '10',\n            'form-1-uuid': str(Swallow.objects.get(origin='Swallow B').pk),\n            'form-1-load': '20',\n            '_save': 'Save',\n        }\n        response = self.client.post(reverse('admin:admin_changelist_swallow'), data)\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, 'Swallow A load updated successfully.')\n        self.assertContains(response, 'Swallow B load updated successfully.')\n        self.assertEqual(Swallow.objects.get(origin='Swallow A').load, 10)\n        self.assertEqual(Swallow.objects.get(origin='Swallow B').load, 20)\n\n\n\n"], "sample_530": ["def test_offsetbox_bbox_transform():\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100)\n    ab = AnnotationBbox(da, (0.5, 0.5),\n                        bbox_transform=ax.transAxes)\n    ax.add_artist(ab)\n\n    # Check that the bbox is transformed correctly\n    bbox = ab.get_window_extent(fig.canvas.get_renderer())\n    assert bbox.width == 100 / fig.dpi\n    assert bbox.height == 100 / fig.dpi\n    assert bbox.xmin == 0.45\n    assert bbox.ymin == 0.45\n    assert bbox.xmax == 0.55\n    assert bbox.ymax == 0.55\n\n\n\n"], "sample_314": ["    def test_password_complexity_validation(self):\n        user = User.objects.get(username='testclient')\n        data = {'password1': 'password', 'password2': 'password'}\n        form = AdminPasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertIn(\n            'This password is too short. It must contain at least 8 characters.',\n            form.errors['password1'],\n        )\n        self.assertIn(\n            'This password is too short. It must contain at least 8 characters.',\n            form.errors['password2'],\n        )\n\n\n\n"], "sample_766": ["def test_dict_learning_online_shuffle():\n    n_components = 12\n    rng = np.random.RandomState(0)\n    X_shuffled = rng.permutation(X)\n    dico = MiniBatchDictionaryLearning(n_components, n_iter=20,\n                                       random_state=0, shuffle=True).fit(X_shuffled)\n    dico_no_shuffle = MiniBatchDictionaryLearning(n_components, n_iter=20,\n                                       random_state=0, shuffle=False).fit(X)\n    assert_array_almost_equal(dico.components_, dico_no_shuffle.components_,\n                              decimal=2)\n"], "sample_620": ["def test_concat_different_index_dtypes() -> None:\n    ds1 = Dataset(coords={\"x\": (\"x\", [1, 2], dtype=np.int64)})\n    ds2 = Dataset(coords={\"x\": (\"x\", [3, 4], dtype=np.float64)})\n\n    with pytest.raises(ValueError, match=r\"Index dtypes must be the same\"):\n        concat([ds1, ds2], dim=\"x\")\n"], "sample_932": ["compilation error"], "sample_666": ["def test_capture_with_nested_threads(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import threading\n        import sys\n        import pytest\n\n                print(\"Hello from worker thread\", file=sys.stdout)\n                sys.stdout.flush()\n                print(\"Goodbye from worker thread\", file=sys.stdout)\n                sys.stdout.flush()\n\n            t = threading.Thread(target=worker)\n            t.start()\n            t.join()\n            print(\"Hello from main thread\", file=sys.stdout)\n            sys.stdout.flush()\n            print(\"Goodbye from main thread\", file=sys.stdout)\n            sys.stdout.flush()\n        \"\"\"\n    )\n    result = testdir.runpytest_subprocess()\n    result.stdout.fnmatch_lines(\n        [\n            \"*Hello from worker thread*\",\n            \"*Goodbye from worker thread*\",\n            \"*Hello from main thread*\",\n            \"*Goodbye from main thread*\",\n        ]\n    )\n"], "sample_943": ["    def test_package_file_with_submodules_and_subpackage(tempdir):\n        outdir = path(tempdir)\n        (outdir / 'testpkg').makedirs()\n        (outdir / 'testpkg' / '__init__.py').write_text('')\n        (outdir / 'testpkg' / 'example.py').write_text('')\n        (outdir / 'testpkg' / 'subpkg').makedirs()\n        (outdir / 'testpkg' / 'subpkg' / '__init__.py').write_text('')\n        (outdir / 'testpkg' / 'subpkg' / 'subsubpkg').makedirs()\n        (outdir / 'testpkg' / 'subpkg' / 'subsubpkg' / '__init__.py').write_text('')\n        apidoc_main(['-o', tempdir, tempdir / 'testpkg'])\n        assert (outdir / 'testpkg.rst').exists()\n        assert (outdir / 'testpkg.subpkg.rst').exists()\n        assert (outdir / 'testpkg.subpkg.subsubpkg.rst').exists()\n\n        content = (outdir / 'testpkg.rst').read_text()\n        assert content == (\"testpkg package\\n\"\n                           \"===============\\n\"\n                           \"\\n\"\n                           \"Subpackages\\n\"\n                           \"-----------\\n\"\n                           \"\\n\"\n                           \".. toctree::\\n\"\n                           \"   :maxdepth: 4\\n\"\n                           \"\\n\"\n                           \"   testpkg.subpkg\\n\"\n                           \"\\n\"\n                           \"Submodules\\n\"\n                           \"----------\\n\"\n                           \"\\n\"\n                           \"testpkg.example module\\n\"\n                           \"--------------------\\n\"\n                           \"\\n\"\n                           \".. automodule:: testpkg.example\\n\"\n                           \"   :members:\\n\"\n                           \"   :undoc-members:\\n\"\n                           \"   :show-inheritance:\\n\")\n\n        content = (outdir / 'testpkg.subpkg.rst').read_text()\n        assert content == (\"testpkg.subpkg package\\n\"\n                           \"======================\\n\"\n                           \"\\n\"\n                           \"Subpackages\\n\"\n                           \"-----------\\n\"\n                           \"\\n\"\n                           \".."], "sample_91": ["    def test_custom_template_context(self):\n        \"\"\"\n        Custom templates can access the request object and exception details.\n        \"\"\"\n        request = self.request_factory.get('/permission_denied/')\n        response = permission_denied(request, Exception('Custom Error'))\n        self.assertContains(response, 'Custom Error', status_code=403)\n"], "sample_660": ["compilation error"], "sample_475": ["    def test_actions_with_custom_permissions_has_method(self):\n        @admin.action(permissions=[\"custom\"])\n            pass\n\n        class BandAdmin(ModelAdmin):\n            actions = (custom_permission_action,)\n\n        class BandAdminWithHasMethod(ModelAdmin):\n                return request.user.is_staff\n\n            actions = (custom_permission_action,)\n\n        self.assertIsValid(BandAdminWithHasMethod, Band)\n"], "sample_5": ["def test_models_evaluate_magunits_with_units(model):\n    if not HAS_SCIPY and model['class'] in SCIPY_MODELS:\n        pytest.skip()\n\n    m = model['class'](**model['parameters'])\n    for args in model['evaluation']:\n        if len(args) == 2:\n            kwargs = dict(zip(('x', 'y'), args))\n        else:\n            kwargs = dict(zip(('x', 'y', 'z'), args))\n            if kwargs['x'].unit.is_equivalent(kwargs['y'].unit):\n                kwargs['x'] = kwargs['x'].to(kwargs['y'].unit)\n        assert_quantity_allclose(m.without_units_for_data(**kwargs), args[-1])\n"], "sample_376": ["    def test_not_finished_sentinel(self):\n        storage = self.get_storage()\n        response = self.get_response()\n\n        # Store a few messages, then add the sentinel value.\n        storage.add(constants.INFO, 'message 1')\n        storage.add(constants.INFO, 'message 2')\n        storage.add(constants.INFO, 'message 3')\n        storage.add(constants.INFO, CookieStorage.not_finished)\n\n        # Update the cookie and check that the sentinel value is present.\n        storage.update(response)\n        messages = self.stored_cookie_messages_count(storage, response)\n        self.assertEqual(messages, 3)\n\n        # Remove the sentinel value and check that the cookie now contains\n        # all messages.\n        storage.request.COOKIES[CookieStorage.cookie_name] = storage._decode(\n            response.cookies[CookieStorage.cookie_name].value\n        )\n        storage.update(response)\n        messages = self.stored_cookie_messages_count(storage, response)\n        self.assertEqual(messages, 4)\n"], "sample_599": ["def test_CFScaleOffsetCoder_decode_with_missing_values():\n    original = xr.Variable(\n        (\"x\",),\n        np.array([10.0, 20.0, np.nan, 30.0]),\n        encoding={\"scale_factor\": 10, \"add_offset\": 5},\n    )\n    coder = variables.CFScaleOffsetCoder()\n    encoded = coder.encode(original)\n    roundtripped = coder.decode(encoded)\n    assert_allclose(roundtripped.data, np.array([15.0, 25.0, np.nan, 35.0]))\n"], "sample_682": ["    def test_relpath_rootdir_with_relative_path(testdir):\n        testdir.makepyfile(\n            **{\n                \"tests/sub/test_1.py\": \"\"\"\n        import pytest\n        @pytest.mark.skip()\n            pass\n            \"\"\",\n            }\n        )\n        result = testdir.runpytest(\"-rs\", \"tests/sub/test_1.py\", \"--rootdir=tests\")\n        result.stdout.fnmatch_lines(\n            [\"SKIPPED [[]1[]] tests/sub/test_1.py:2: unconditional skip\"]\n        )\n"], "sample_468": ["    def test_context_processors_order(self):\n            return {\"processor1\": \"value1\"}\n\n            return {\"processor2\": \"value2\"}\n\n        @override_settings(\n            TEMPLATES=[\n                {\n                    \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n                    \"OPTIONS\": {\n                        \"context_processors\": [\n                            processor1,\n                            processor2,\n                            \"django.template.context_processors.request\",\n                        ],\n                    },\n                }\n            ]\n        )\n            request = self.request_factory.get(\"/\")\n            context = RequestContext(request, {})\n            with context.bind_template(Template(\"\")):\n                pass\n            self.assertEqual(context.dicts[-1], {\"processor1\": \"value1\", \"processor2\": \"value2\"})\n\n        test_func()\n"], "sample_503": ["def test_marker_size_scaling():\n    fig, ax = plt.subplots()\n    x = np.linspace(0, 2*np.pi, 10)\n    y = np.sin(x)\n\n    for marker in mlines.Line2D.filled_markers:\n        for size in [1, 5, 10, 20]:\n            ax.plot(x, y, marker=marker, markersize=size,\n                    linestyle='-', color='b')\n    ax.set_xlim([0, 2*np.pi])\n    ax.set_ylim([-1.2, 1.2])\n"], "sample_212": ["    def test_session_middleware_save_every_request(self):\n        # Simulate a request where the session is modified and configured to save on every request.\n        request = HttpRequest()\n        request.session = self.create_mock_session_store()\n        request.session.modified = True\n\n        # Configure settings to save the session on every request.\n        settings.SESSION_SAVE_EVERY_REQUEST = True\n\n        middleware = SessionMiddleware()\n        response = middleware.process_response(request, HttpResponse())\n\n        # Assert that the session was saved.\n        self.assertTrue(request.session.save.called)\n"], "sample_82": ["    def test_invalid_year_values(self):\n        with self.assertRaises(ValueError):\n            SelectDateWidget(years=('abc',))\n        with self.assertRaises(ValueError):\n            SelectDateWidget(years=('2000', 'abc'))\n        with self.assertRaises(ValueError):\n            SelectDateWidget(years=('2000', '2000.5'))\n        with self.assertRaises(ValueError):\n            SelectDateWidget(years=('2000', '2001', 'abc'))\n\n\n\n"], "sample_796": ["def test_huber_with_intercept_and_sparse_data():\n    X, y = make_regression_with_outliers(n_samples=100, n_features=50)\n    X_sparse = sparse.csr_matrix(X)\n    huber = HuberRegressor(fit_intercept=True, alpha=0.01, max_iter=100)\n    huber.fit(X_sparse, y)\n    assert huber.intercept_ is not None\n    assert_array_almost_equal(huber.coef_, huber.coef_)\n"], "sample_1121": ["def test_issue_18507_cont():\n    assert Mul(zoo, zoo, evaluate=False) is nan\n    assert Mul(zoo, zoo, evaluate=True) is nan\n    assert Mul(zoo, zoo, evaluate=False).is_real is None\n    assert Mul(zoo, zoo, evaluate=True).is_real is None\n"], "sample_813": ["def test_ard_threshold_lambda():\n    # Test the effect of threshold_lambda on the number of active features\n    X = np.random.rand(10, 5)\n    y = np.random.rand(10)\n    clf = ARDRegression(threshold_lambda=1e6)\n    clf.fit(X, y)\n    assert_equal(np.sum(clf.lambda_ > 1e-6), X.shape[1])  # All features active\n\n    clf = ARDRegression(threshold_lambda=1e-3)\n    clf.fit(X, y)\n    assert_less(np.sum(clf.lambda_ > 1e-3), X.shape[1])  # Some features pruned\n\n\n\n"], "sample_50": ["    def test_empty_dbinfo(self):\n        self.assertEqual(\n            self._run_it({}), (\n                ['psql'],\n                None,\n            )\n        )\n"], "sample_614": ["    def test_diff_coords_repr_with_attrs(self) -> None:\n        coords_a = {\"x\": np.array([\"a\", \"b\"], dtype=\"U1\"), \"y\": np.array([1, 2, 3], dtype=\"int64\")}\n        coords_b = {\"x\": np.array([\"a\", \"c\"], dtype=\"U1\"), \"y\": np.array([1, 2], dtype=\"int64\")}\n        attrs_a = {\"units\": \"m\"}\n        attrs_b = {\"units\": \"kg\"}\n\n        expected = dedent(\n            \"\"\"\\\n        Left and right Coordinate objects are not identical\n        Differing coordinates:\n        L * x        (x) %cU1 'a' 'b'\n        R * x        (x) %cU1 'a' 'c'\n        L * y        (y) int64 1 2 3\n        R * y        (y) int64 1 2\n        Differing attributes:\n        L   units: m\n        R   units: kg\"\"\"\n            % (byteorder, byteorder)\n        )\n\n        actual = formatting.diff_coords_repr(coords_a, coords_b, attrs_a, attrs_b)\n        assert actual == expected\n"], "sample_750": ["def test_omp_gram_with_precompute_copy_gram():\n    G, Xy = np.dot(X.T, X), np.dot(X.T, y)\n    gamma_gram = orthogonal_mp_gram(G, Xy, n_nonzero_coefs=5,\n                                    copy_Gram=True)\n    gamma_gram_no_copy = orthogonal_mp_gram(G, Xy, n_nonzero_coefs=5,\n                                            copy_Gram=False)\n    assert_array_almost_equal(gamma_gram, gamma_gram_no_copy)\n"], "sample_1122": ["def test_issue_16004():\n    from sympy import Symbol, Abs, re, im\n    x = Symbol('x')\n    y = Symbol('y')\n    assert re(Abs(x + I*y)) == Abs(x)\n    assert im(Abs(x + I*y)) == Abs(y)\n"], "sample_1055": ["def test_encipher_decipher_gm():\n    ps = [131, 137, 139, 149, 151, 157, 163, 167,\n          173, 179, 181, 191, 193, 197, 199]\n    qs = [89, 97, 101, 103, 107, 109, 113, 127,\n          131, 137, 139, 149, 151, 157, 47]\n    messages = [\n        0, 32855, 34303, 14805, 1280, 75859, 38368,\n        724, 60356, 51675, 76697, 61854, 18661,\n    ]\n    for p, q in zip(ps, qs):\n        pri = gm_private_key(p, q)\n        for msg in messages:\n            pub = gm_public_key(p, q)\n            enc = encipher_gm(msg, pub)\n            dec = decipher_gm(enc, pri)\n            assert dec == msg\n"], "sample_1049": ["compilation error"], "sample_391": ["    def test_optimize_through_m2m_with_through_model(self):\n        \"\"\"\n        CreateModel, AddField, and DeleteModel should optimize when dealing with\n        M2M relationships through a separate model.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Employee\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Employer\", [(\"name\", models.CharField(max_length=255))]\n                ),\n                migrations.CreateModel(\n                    \"Employment\",\n                    [\n                        (\n                            \"employee\",\n                            models.ForeignKey(\"migrations.Employee\", models.CASCADE),\n                        ),\n                        (\n                            \"employer\",\n                            models.ForeignKey(\"migrations.Employer\", models.CASCADE),\n                        ),\n                    ],\n                ),\n                migrations.AddField(\n                    \"Employer\",\n                    \"employees\",\n                    models.ManyToManyField(\n                        \"migrations.Employee\",\n                        through=\"migrations.Employment\",\n                    ),\n                ),\n                migrations.AddField(\n                    \"Employee\",\n                    \"employers\",\n                    models.ManyToManyField(\n                        \"migrations.Employer\",\n                        through=\"migrations.Employment\",\n                    ),\n                ),\n                migrations.RemoveField(\"Employment\", \"employee\"),\n                migrations.DeleteModel(\"Employment\"),\n                migrations.RemoveField(\"Employer\", \"employees\"),\n                migrations.DeleteModel(\"Employee\"),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Employer\", [(\"name\", models.CharField(max_length=255))]\n                ),\n            ],\n        )\n\n\n\n"], "sample_867": ["def test_search_cv_with_precomputed_metric_and_n_jobs():\n    n_samples = 50\n    n_splits = 2\n    X, y = make_classification(n_samples=n_samples, random_state=0)\n    grid_params = {'n_neighbors': [10]}\n\n    # precompute euclidean metric\n    X_precomputed = euclidean_distances(X)\n\n    clf = KNeighborsClassifier(metric='precomputed')\n    cv = GridSearchCV(clf, grid_params, cv=n_splits, n_jobs=2)\n    cv.fit(X_precomputed, y)\n\n\n\n"], "sample_898": ["compilation error"], "sample_258": ["    def test_receiver_dispatch_uid(self):\n        @receiver(a_signal, dispatch_uid=\"uid\")\n            self.state.append(val)\n        self.state = []\n        a_signal.connect(f_uid, dispatch_uid=\"uid\")\n        a_signal.connect(f_uid, dispatch_uid=\"uid2\")\n        a_signal.send(sender=self, val='a')\n        self.assertEqual(len(self.state), 1)\n        self.assertEqual(self.state[0], 'a')\n        a_signal.disconnect(dispatch_uid=\"uid\")\n        a_signal.send(sender=self, val='b')\n        self.assertEqual(len(self.state), 2)\n        self.assertEqual(self.state[1], 'b')\n"], "sample_588": ["    def test_auto_combine_with_multiple_concat_dims(self):\n        objs = [\n            Dataset({\"x\": [0, 1], \"y\": [2, 3]}),\n            Dataset({\"x\": [2, 3], \"y\": [4, 5]}),\n        ]\n        with pytest.warns(FutureWarning, match=\"`concat_dim`\"):\n            auto_combine(objs, concat_dim=[\"x\", \"y\"])\n"], "sample_669": ["def test_capture_with_encoding_errors(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import sys\n            sys.stdout.encoding = 'ascii'\n            sys.stderr.encoding = 'ascii'\n            sys.stdout.write(b'\\xe4')\n            sys.stderr.write(b'\\xe4')\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines(\n        \"*UnicodeEncodeError*\"*\n    )\n    result.stderr.fnmatch_lines(\n        \"*UnicodeEncodeError*\"*\n    )\n"], "sample_567": ["def test_text_bbox_clip():\n    fig, ax = plt.subplots()\n    text = ax.text(0.5, 0.5, 'This text is too long to fit in the axes',\n                   bbox=dict(facecolor='red', alpha=0.5))\n    fig.canvas.draw()\n    bbox = text.get_window_extent()\n    assert bbox.width > 0\n    assert bbox.height > 0\n    assert bbox.x0 < 1\n    assert bbox.x1 > 0\n    assert bbox.y0 < 1\n    assert bbox.y1 > 0\n\n\n\n"], "sample_920": ["    def test_custom_sections_with_types(self):\n        docstring = \"\"\"\\"], "sample_401": ["    def test_all_valid_with_non_form_errors(self):\n        class CustomFormSet(BaseFormSet):\n                raise ValidationError(\"This is a non-form error\")\n\n        ChoiceFormSet = formset_factory(Choice, formset=CustomFormSet)\n        formset1 = ChoiceFormSet(data={}, auto_id=False, prefix=\"choices\")\n        formset2 = ChoiceFormSet(data={}, auto_id=False, prefix=\"choices\")\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [{\"\": [\"This is a non-form error\"]}, {\"\": [\"This is a non-form error\"]}]\n        self.assertEqual(formset1._errors, expected_errors)\n        self.assertEqual(formset2._errors, expected_errors)\n"], "sample_863": ["compilation error"], "sample_1198": ["def test_parser_mathematica_complex_expressions():\n    parser = MathematicaParser()\n\n    full_form1 = \"Simplify[Log[x^2 + y^2, e]]\"\n    full_form2 = \"Expand[Sin[x + y]^2]\"\n    full_form3 = \"Integrate[x^2*Sin[x], x]\"\n    full_form4 = \"Solve[x^2 + y^2 == 1, {x, y}]\"\n    full_form5 = \"FindRoot[x^2 - y^2 == 0, {x, 1}, {y, 1}]\"\n\n    assert parser._from_fullform_to_fullformlist(full_form1) == [\"Simplify\", [\"Log\", [\"Power\", \"x\", \"2\"], [\"Plus\", \"y\", \"2\"], \"e\"]]\n    assert parser._from_fullform_to_fullformlist(full_form2) == [\"Expand\", [\"Sin\", [\"Plus\", \"x\", \"y\"], \"2\"]]\n    assert parser._from_fullform_to_fullformlist(full_form3) == [\"Integrate\", [\"Times\", \"x\", \"2\", \"Sin\", \"x\"], \"x\"]\n    assert parser._from_fullform_to_fullformlist(full_form4) == [\"Solve\", [\"Equal\", [\"Plus\", \"x\", \"2\"], [\"Plus\", \"y\", \"2\"]], {\"x\", \"y\"}]\n    assert parser._from_fullform_to_fullformlist(full_form5) == [\"FindRoot\", [\"Equal\", [\"Minus\", \"x\", \"2\"], [\"y\", \"2\"]], {\"x\": 1}, {\"y\": 1}]\n\n\n\n"], "sample_690": ["    def test_relpath_rootdir_with_relative_path(pytester: Pytester) -> None:\n        pytester.makepyfile(\n            **{\n                \"tests/subdir/test_2.py\": \"\"\"\n            import pytest\n            @pytest.mark.skip()\n                pass\n                \"\"\",\n            }\n        )\n        result = pytester.runpytest(\"-rs\", \"tests/subdir/test_2.py\", \"--rootdir=tests\")\n        result.stdout.fnmatch_lines(\n            [\"SKIPPED [[]1[]] tests/subdir/test_2.py:2: unconditional skip\"]\n        )\n"], "sample_10": ["def test_read_write_with_unicode_column_names():\n    \"\"\"Test reading and writing tables with Unicode column names.\"\"\"\n    dat = [[1, 2], [3, 4]]\n    names = ['\u00e4\u00f6\u00fc', '\u00df']\n    t = Table(dat, names=names)\n    with tempfile.NamedTemporaryFile(suffix=\".csv\") as f:\n        t.write(f.name, format='ascii')\n        t2 = Table.read(f.name, format='ascii')\n    assert t.colnames == t2.colnames\n    assert np.all(t['\u00e4\u00f6\u00fc'] == t2['\u00e4\u00f6\u00fc'])\n    assert np.all(t['\u00df'] == t2['\u00df'])\n"], "sample_604": ["    def test_diff_dataset_repr_with_identical_attrs(self):\n        ds_a = xr.Dataset(\n            data_vars={\"var1\": ((\"x\", \"y\"), np.array([[1, 2, 3], [4, 5, 6]], dtype=\"int64\"))},\n            coords={\"x\": np.array([\"a\", \"b\"], dtype=\"U1\"), \"y\": np.array([1, 2, 3], dtype=\"int64\")},\n            attrs={\"units\": \"m\", \"description\": \"desc\"},\n        )\n\n        ds_b = xr.Dataset(\n            data_vars={\"var1\": ((\"x\", \"y\"), np.array([[1, 2, 3], [4, 5, 6]], dtype=\"int64\"))},\n            coords={\"x\": np.array([\"a\", \"b\"], dtype=\"U1\"), \"y\": np.array([1, 2, 3], dtype=\"int64\")},\n            attrs={\"units\": \"m\", \"description\": \"desc\"},\n        )\n\n        expected = dedent(\n            \"\"\"\\\n        Left and right Dataset objects are identical\n        \"\"\"\n        )\n\n        actual = formatting.diff_dataset_repr(ds_a, ds_b, \"identical\")\n        assert actual == expected\n"], "sample_467": ["    def test_empty_label_with_custom_months(self):\n        widget = SelectDateWidget(\n            years=(\"2014\",),\n            empty_label=\"empty_label\",\n            months=MONTHS_AP,\n        )\n        self.assertHTMLEqual(\n            widget.render(\"mydate\", \"\"),\n            \"\"\"\n            <select name=\"mydate_month\" id=\"id_mydate_month\">\n                <option selected value=\"\">empty_label</option>\n                <option value=\"1\">Jan.</option>\n                <option value=\"2\">Feb.</option>\n                <option value=\"3\">Mar.</option>\n                <option value=\"4\">Apr.</option>\n                <option value=\"5\">May</option>\n                <option value=\"6\">Jun.</option>\n                <option value=\"7\">Jul.</option>\n                <option value=\"8\">Aug.</option>\n                <option value=\"9\">Sep.</option>\n                <option value=\"10\">Oct.</option>\n                <option value=\"11\">Nov.</option>\n                <option value=\"12\">Dec.</option>\n            </select>\n\n            <select name=\"mydate_day\" id=\"id_mydate_day\">\n                <option selected value=\"\">---</option>\n                <option value=\"1\">1</option>\n                <option value=\"2\">2</option>\n                <option value=\"3\">3</option>\n                <option value=\"4\">4</option>\n                <option value=\"5\">5</option>\n                <option value=\"6\">6</option>\n                <option value=\"7\">7</option>\n                <option value=\"8\">8</option>\n                <option value=\"9\">9</option>\n                <option value=\"10\">10</option>\n                <option value=\"11\">11</option>\n                <option value=\"12\">12</option>\n                <option value=\"13\">13</option>\n                <option value=\"14\">14</option>\n                <option value=\"15\">15</option>\n                <option value=\"16\">16</option>\n                <option value=\"17\">"], "sample_94": ["    def test_create_permissions_with_custom_permissions(self):\n        \"\"\"\n        Custom permissions defined in the app's `permissions` attribute\n        should be created.\n        \"\"\"\n        custom_permissions = [\n            ('my_custom_permission', 'Some custom permission'),\n        ]\n        self.app_config.permissions = custom_permissions\n        permission_content_type = ContentType.objects.get_by_natural_key('auth', 'permission')\n        create_permissions(self.app_config, verbosity=0)\n\n        self.assertEqual(Permission.objects.filter(\n            content_type=permission_content_type,\n        ).count(), 1)\n        self.assertEqual(Permission.objects.get(codename='my_custom_permission').name, 'Some custom permission')\n\n\n\n"], "sample_838": ["def test_column_transformer_sparse_remainder_with_sparse_threshold():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).astype('float').T\n    ct = ColumnTransformer([('trans1', StandardScaler(), [0])],\n                           remainder=SparseMatrixTrans(),\n                           sparse_threshold=0.5)\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n    assert X_trans.getnnz() > 0\n    assert X_trans.shape[1] == 3 + 1\n\n\n\n"], "sample_87": ["    def test_should_stop_returns_false_if_no_changes(self):\n        with mock.patch.object(self.reloader, 'snapshot_files', return_value={self.existing_file: 123}):\n            self.assertFalse(self.reloader.should_stop())\n"], "sample_555": ["def test_arc_transformation():\n    fig, ax = plt.subplots()\n    arc = Arc((0, 0), 1, 1, theta1=0, theta2=90)\n    ax.add_patch(arc)\n    transform = ax.transData\n    transformed_arc = arc.get_path().transformed(transform)\n    assert transformed_arc.vertices.shape[0] > 0\n"], "sample_1126": ["def test_bra_ket():\n    from sympy.physics.quantum.state import Ket, Bra\n    a = symbols('a')\n    b = symbols('b')\n    assert Dagger(Ket(a)) == Bra(a)\n    assert Dagger(Bra(b)) == Ket(b)\n    assert Dagger(Ket(a)*Bra(b)) == Bra(b)*Ket(a)\n"], "sample_533": ["def test_contour_with_masked_array():\n    x = np.arange(10)\n    y = np.arange(10)\n    X, Y = np.meshgrid(x, y)\n    data = np.sin(np.sqrt(X**2 + Y**2))\n    mask = np.zeros_like(data, dtype=bool)\n    mask[5, 5] = True\n    masked_data = np.ma.masked_array(data, mask=mask)\n\n    fig, ax = plt.subplots()\n    cs = ax.contour(X, Y, masked_data)\n    assert isinstance(cs._contour_generator, contourpy.ContourGenerator)\n    ax.clabel(cs)\n    plt.show()\n"], "sample_1090": ["def test_sympify():\n    from sympy import sympify\n    assert sympify(1) == S.One\n    assert sympify(2.5) == S.Rational(5, 2)\n    assert sympify(3j) == S.ImaginaryUnit * 3\n    assert sympify(\"pi\") == S.Pi\n    assert sympify(\"e\") == S.Exp1\n    assert sympify(\"oo\") == S.Infinity\n    assert sympify(\"nan\") == S.NaN\n    assert sympify(\"sqrt(2)\") == sqrt(2)\n    assert sympify(\"x + 2\") == x + 2\n    assert sympify(\"sin(x)\") == sin(x)\n"], "sample_144": ["    def test_inherited_fields_with_null_values(self):\n        \"\"\"\n        Regression test for #12345: Make sure inherited fields with null\n        values are correctly handled.\n        \"\"\"\n        p = Person.objects.create(name='Alice', age=30)\n        self.assertIsNone(p.congressman)\n        self.assertIsNone(p.politician)\n        self.assertEqual(p.name, 'Alice')\n        self.assertEqual(p.age, 30)\n\n        c = Congressman.objects.create(state='CA', name='Bob', title='Rep', person=p)\n        self.assertIsNotNone(c.congressman)\n        self.assertIsNotNone(c.politician)\n        self.assertEqual(c.state, 'CA')\n        self.assertEqual(c.name, 'Bob')\n        self.assertEqual(c.title, 'Rep')\n\n        # Check that the Person object still has the correct values\n        self.assertEqual(p.name, 'Alice')\n        self.assertEqual(p.age, 30)\n        self.assertIsNotNone(p.congressman)\n        self.assertIsNotNone(p.politician)\n\n        # Update the Congressman object and check that the Person object\n        # reflects the changes\n        c.title = 'Senator'\n        c.save()\n        self.assertEqual(p.congressman.title, 'Senator')\n        self.assertEqual(p.politician.title, 'Senator')\n\n\n\n"], "sample_1088": ["compilation error"], "sample_106": ["    def test_cache_control_headers(self):\n        request = self.factory.get(self.path)\n        template = engines['django'].from_string(\"This is a test\")\n        response = TemplateResponse(HttpRequest(), template)\n\n        # Test with no Cache-Control headers\n        patch_cache_control(response, public=True, max_age=3600)\n        self.assertEqual(response['Cache-Control'], 'public, max-age=3600')\n\n        # Test with existing Cache-Control headers\n        response['Cache-Control'] = 'private, must-revalidate'\n        patch_cache_control(response, public=True, max_age=3600)\n        self.assertEqual(response['Cache-Control'], 'public, max-age=3600, must-revalidate')\n\n        # Test with overriding existing headers\n        response['Cache-Control'] = 'private, max-age=100'\n        patch_cache_control(response, public=True, max_age=3600)\n        self.assertEqual(response['Cache-Control'], 'public, max-age=3600')\n\n\n\n"], "sample_312": ["    def test_add_squash_children(self):\n        node1 = Node([('a', 1), ('b', 2)], connector='AND')\n        node2 = Node([('c', 3), ('d', 4)], connector='AND')\n        result = node1.add(node2, 'AND', squash=True)\n        self.assertEqual(len(node1.children), 1)\n        self.assertEqual(str(node1), \"(AND: (AND: ('a', 1), ('b', 2), ('c', 3), ('d', 4)))\")\n        self.assertIs(result, node2) \n"], "sample_1022": ["def test_repeated_decimals():\n    cases = {\n        '0.2[1]': '0.21111111111111111...',\n        '0.12[34]': '0.12343434343434343...',\n        '0.123[456]': '0.123456456456456456...',\n        '0.1234[5678]': '0.12345678567856785678...',\n        '0.12345[67890]': '0.12345678906789067890...',\n        '0.123456[789012]': '0.1234567890123456789012...',\n        '0.123456789[0123456789]': '0.12345678901234567890...',\n        '0.1234567890[1234567890]': '0.12345678901234567890...',\n    }\n    transformations = standard_transformations + (repeated_decimals,)\n    for case in cases:\n        implicit = parse_expr(case, transformations=transformations)\n        normal = parse_expr(cases[case], transformations=transformations)\n        assert(implicit == normal)\n"], "sample_905": ["compilation error"], "sample_493": ["    def test_window_function_with_aggregate_pruning(self):\n        with CaptureQueriesContext(connection) as ctx:\n            Book.objects.annotate(\n                avg_publisher_pages=Coalesce(\n                    Window(Avg(\"pages\"), partition_by=F(\"publisher\")),\n                    0.0,\n                )\n            ).aggregate(\n                sum_avg_publisher_pages=Sum(\"avg_publisher_pages\"),\n            )\n        sql = ctx.captured_queries[0][\"sql\"].lower()\n        self.assertEqual(sql.count(\"select\"), 1, \"No subquery wrapping required\")\n        self.assertIn(\"avg_publisher_pages\", sql)\n"], "sample_597": ["    def test_merge_compat_broadcast_equals_with_different_dims(self):\n        ds1 = xr.Dataset({\"x\": ((\"y\", \"z\"), [0, 1])})\n        ds2 = xr.Dataset({\"x\": ((\"y\",), [0, 1])})\n        with pytest.raises(xr.MergeError):\n            ds1.merge(ds2, compat=\"broadcast_equals\")\n\n        with pytest.raises(xr.MergeError):\n            ds2.merge(ds1, compat=\"broadcast_equals\")\n"], "sample_1101": ["def test_schur_partition_large_n():\n    for n in range(45, 101):\n        result = schur_partition(n)\n        t = 0\n        numbers = []\n        for item in result:\n            _sum_free_test(item)\n            t += len(item)\n            for l in item:\n                assert (l in numbers) is False\n                numbers.append(l)\n        assert n == t\n"], "sample_338": ["    def test_operation_with_no_suggested_name_and_initial_true(self):\n        class Migration(migrations.Migration):\n            initial = True\n            operations = [migrations.RunSQL('SELECT 1 FROM person;')]\n\n        migration = Migration('0001_initial', 'test_app')\n        self.assertEqual(migration.suggest_name(), 'initial')\n"], "sample_1156": ["compilation error"], "sample_645": ["def test_log_file_level_overrides_global_level(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            logger = logging.getLogger('catchlog')\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_level == logging.WARNING\n\n            logger.info(\"INFO message won't be shown\")\n            logger.warning(\"WARNING message will be shown\")\n\n            assert \"INFO message won't be shown\" not in caplog.text\n            assert \"WARNING message will be shown\" in caplog.text\n    \"\"\"\n    )\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_level=WARNING\n        log_file_level=DEBUG\n    \"\"\"\n    )\n\n    result = pytester.runpytest()\n    assert result.ret == 0\n"], "sample_40": ["def test_equivalency_context_with_custom_equivalencies():\n    with u.set_enabled_equivalencies(u.spectral()):\n        with u.add_enabled_equivalencies(u.custom_equivalency(\n                u.micron, u.cm, 1e-4)):\n            micron = 1 * u.micron\n            assert_allclose(micron.to_value(u.cm), 1e-4)\n            assert_allclose(micron.to_value(u.cm, equivalencies=u.spectral()), 1e-4)\n"], "sample_22": ["def test_matrix_transpose():\n    m1 = rotation_matrix(35 * u.deg, \"x\")\n    m2 = matrix_transpose(m1)\n    assert_allclose(m2, m1.T)\n    # and (M, 3, 3)\n    n1 = np.tile(m1, (2, 1, 1))\n    n2 = matrix_transpose(n1)\n    assert_allclose(n2, n1.transpose(0, 2, 1))\n"], "sample_234": ["    def test_union_with_distinct_and_ordering(self):\n        qs1 = Number.objects.filter(num__lte=1).values('num')\n        qs2 = Number.objects.filter(num__gte=2, num__lte=3).values('num')\n        self.assertCountEqual(list(qs1.union(qs2).distinct().order_by('num')), [0, 1, 2, 3])\n\n"], "sample_1127": ["compilation error"], "sample_744": ["def test_power_transformer_y_axis():\n    X = np.abs(X_2d)\n    pt = PowerTransformer(method='box-cox', standardize=False)\n    pt.fit(X)\n\n    # Test y_axis parameter\n    X_trans_y_axis_0 = pt.transform(X, y_axis=0)\n    X_trans_y_axis_1 = pt.transform(X, y_axis=1)\n\n    assert_array_almost_equal(X_trans_y_axis_0, pt.transform(X))\n    assert_array_almost_equal(X_trans_y_axis_1, pt.transform(X.T).T)\n\n    assert_raises(ValueError, pt.transform, X, y_axis=2)\n"], "sample_508": ["def test_set_alpha_for_array_nan():\n    art = martist.Artist()\n    with pytest.raises(ValueError, match=\"alpha must be between 0 and 1\"):\n        art._set_alpha_for_array([0.5, np.nan])\n"], "sample_220": ["    def test_delete_cookie_path(self):\n        response = HttpResponse()\n        response.set_cookie('c', path='/admin')\n        response.delete_cookie('c', path='/')\n        self.assertEqual(response.cookies['c']['path'], '/')\n"], "sample_561": ["def test_marker_transformed(marker, transform, expected):\n    new_marker = marker.transformed(transform)\n    assert new_marker is not marker\n    assert new_marker.get_user_transform() == expected\n    assert marker._user_transform is not new_marker._user_transform\n\n"], "sample_470": ["    def test_keep_lazy_with_multiple_args(self):\n        @lazy(int, str)\n            return a + b\n\n        lazy_a = lazy(lambda: 1, int)\n        lazy_b = lazy(lambda: \"2\", str)\n\n        self.assertEqual(keep_lazy(int, str)(my_func, lazy_a, lazy_b), 3)\n"], "sample_680": ["compilation error"], "sample_851": ["    def test_tweedie_deviance_with_zero_values():\n        y_true = np.array([1, 0, 2, 0, 3])\n        y_pred = np.array([1.5, 0.5, 2.2, 0.2, 3.5])\n\n        for power in [0, 1, 2, 3]:\n            with pytest.raises(ValueError,\n                               match=\"strictly positive y_pred\"):\n                mean_tweedie_deviance(y_true, y_pred, power=power)\n"], "sample_150": ["    def test_postgresql_search_path(self):\n        with mock.patch(\n            'django.db.backends.utils.CursorWrapper.fetchone', create=True,\n            return_value=('public',),\n        ):\n            self.assertEqual(check_database_backends(databases=self.databases), [])\n\n        with mock.patch(\n            'django.db.backends.utils.CursorWrapper.fetchone', create=True,\n            return_value=(None,),\n        ):\n            result = check_database_backends(databases=self.databases)\n            self.assertEqual(len(result), 2)\n            self.assertEqual([r.id for r in result], ['postgresql.W001', 'postgresql.W001'])\n"], "sample_319": ["    def test_operation_with_custom_name(self):\n        class Migration(migrations.Migration):\n            operations = [\n                migrations.CreateModel(\n                    name=\"Person\", fields=[], custom_name=\"my_person_model\"\n                ),\n            ]\n\n        migration = Migration(\"some_migration\", \"test_app\")\n        self.assertEqual(migration.suggest_name(), \"my_person_model\")\n"], "sample_542": ["def test_text_bbox_with_transform():\n    fig, ax = plt.subplots()\n    text = ax.text(0, 0, 'test', transform=ax.transAxes)\n    bbox = text.get_bbox()\n    assert bbox.width > 0\n    assert bbox.height > 0\n"], "sample_28": ["    def test_header_append_with_duplicate_keyword(self):\n        h = fits.Header()\n        h.append(\"FOO = 1\")\n        h.append(\"FOO = 2\")\n        assert h[\"FOO\"] == 2.0\n"], "sample_1021": ["def test_quaternion_multiplication():\n    q1 = Quaternion(1, 2, 3, 4)\n    q2 = Quaternion(5, 6, 7, 8)\n    q3 = Quaternion(9, 10, 11, 12)\n\n    assert q1 * q2 == Quaternion(-14, 26, 38, 46)\n    assert q2 * q1 == Quaternion(-14, 26, 38, 46)\n    assert (q1 * q2) * q3 == q1 * (q2 * q3)  # Associativity\n\n    assert q1 * Quaternion(1, 0, 0, 0) == Quaternion(1, 2, 3, 4)\n    assert Quaternion(1, 0, 0, 0) * q1 == Quaternion(1, 2, 3, 4)\n\n    assert q1 * Quaternion(0, 1, 0, 0) == Quaternion(0, 2, 3, 4)\n    assert q1 * Quaternion(0, 0, 1, 0) == Quaternion(0, 2, 3, 4)\n    assert q1 * Quaternion(0, 0, 0, 1) == Quaternion(1, 2, 3, 4)\n\n    assert q1 * q1 == Quaternion(-15, 0, 0, 0)\n\n\n\n"], "sample_299": ["    def test_cache_location_with_relative_path_in_setting(self):\n        with self.settings(CACHES={\n            'default': {\n                'BACKEND': 'django.core.cache.backends.filebased.FileBasedCache',\n                'LOCATION': 'cache',\n            },\n            'other': {\n                'BACKEND': 'django.core.cache.backends.filebased.FileBasedCache',\n                'LOCATION': pathlib.Path.cwd() / 'cache',\n            },\n        }):\n            self.assertEqual(check_cache_location_not_exposed(None), [\n                Warning(\n                    \"Your 'default' cache LOCATION path is relative. Use an \"\n                    \"absolute path instead.\",\n                    id='caches.W003',\n                ),\n            ])\n"], "sample_900": ["def test_validation_fraction():\n    # Test validation_fraction parameter.\n    X = X_digits_binary[:100]\n    y = y_digits_binary[:100]\n\n    for fraction in [0.1, 0.2, 0.3]:\n        mlp = MLPClassifier(validation_fraction=fraction, solver='sgd',\n                            random_state=1)\n        with ignore_warnings(category=ConvergenceWarning):\n            mlp.fit(X, y)\n        assert mlp.validation_scores_.shape[0] == mlp.n_iter_\n\n\n\n"], "sample_915": ["        def static_method(self):\n            pass\n"], "sample_710": ["    def test_traceback_pruning_with_custom_init(pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import unittest\n\n            class MyTestCase(unittest.TestCase):\n                    unittest.TestCase.__init__(self, test_method)\n                    self.custom_arg = custom_arg\n\n            class TestIt(MyTestCase):\n                    assert self.custom_arg == \"hello\"\n\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        passed, skipped, failed = reprec.countoutcomes()\n        assert passed == 1\n        assert reprec.ret == 0\n"], "sample_649": ["    def test_log_disabling_works_with_log_file(testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import logging\n            disabled_log = logging.getLogger('disabled')\n            test_log = logging.getLogger('test')\n\n                test_log.info(\"Visible text!\")\n                disabled_log.warning(\"This string will be suppressed.\")\n            \"\"\"\n        )\n        log_file = \"test.log\"\n        testdir.makeini(\n            \"\"\"\n            [pytest]\n            log_file = {}\n            log_file_level = DEBUG\n            log_disable = disabled\n            \"\"\".format(\n                log_file\n            )\n        )\n        result = testdir.runpytest()\n        assert result.ret == ExitCode.OK\n        with open(log_file, \"r\") as f:\n            content = f.read()\n        assert \"Visible text!\" in content\n        assert \"This string will be suppressed.\" not in content\n"], "sample_381": ["    def test_suggest_name_with_custom_operations(self):\n        class CustomOperation(migrations.MigrationOperation):\n                super().__init__(name, **kwargs)\n\n        class Migration(migrations.Migration):\n            operations = [\n                CustomOperation('custom_operation', name='custom_operation'),\n            ]\n\n        migration = Migration('some_migration', 'test_app')\n        self.assertEqual(migration.suggest_name(), 'custom_operation')\n"], "sample_2": ["def test_read_with_invalid_wcs_keywords():\n    # Test that reading a file with invalid WCS keywords does not crash.\n    data_file = get_pkg_data_filename('data/invalid_wcs.fits')\n    with pytest.warns(AstropyWarning, match=r'Invalid WCS keywords'):\n        ccd = CCDData.read(data_file)\n"], "sample_1060": ["def test_NumPyPrinter_print_MatrixBase():\n    n = NumPyPrinter()\n    A = MatrixSymbol(\"A\", 2, 2)\n    assert n.doprint(A) == \"numpy.array([[None, None], [None, None]])\"\n"], "sample_271": ["    def test_snapshot_files_with_different_mtimes(self):\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file, self.existing_file]):\n            self.increment_mtime(self.existing_file)\n            snapshot1 = dict(self.reloader.snapshot_files())\n            self.increment_mtime(self.existing_file)\n            snapshot2 = dict(self.reloader.snapshot_files())\n            self.assertNotEqual(snapshot1[self.existing_file], snapshot2[self.existing_file])\n"], "sample_520": ["def test_scatter_3d_with_colorbar():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    x = np.random.rand(100)\n    y = np.random.rand(100)\n    z = np.random.rand(100)\n    c = np.random.rand(100)\n    sc = ax.scatter(x, y, z, c=c, cmap='viridis')\n    fig.colorbar(sc)\n"], "sample_1028": ["def test_issue_14401():\n    from sympy import oo\n    assert (oo/oo).is_undefined is True\n    assert (oo/0).is_undefined is True\n    assert (0/oo).is_undefined is True\n    assert (oo/1).is_undefined is False\n    assert (1/oo).is_undefined is False\n"], "sample_881": ["def test_label_ranking_average_precision_score_with_ties():\n    # Test that label_ranking_average_precision_score handles ties correctly\n    y_true = np.array([\n        [1, 0, 0],\n        [0, 1, 1],\n        [0, 0, 1],\n    ])\n    y_score = np.array([\n        [0.5, 0.5, 0.5],\n        [0.2, 0.8, 0.8],\n        [0.1, 0.3, 0.9],\n    ])\n    result = label_ranking_average_precision_score(y_true, y_score)\n    assert result == pytest.approx(0.6666666666666666)\n"], "sample_68": ["    def test_cleanse_setting_handles_nested_dictionaries(self):\n        initial = {'user': {'name': 'john', 'password': 'doe'}}\n        expected = {'user': {'name': 'john', 'password': CLEANSED_SUBSTITUTE}}\n        self.assertEqual(cleanse_setting('SETTING_NAME', initial), expected)\n"], "sample_112": ["    def test_date_hierarchy_with_custom_field(self):\n        class CustomModelAdmin(ModelAdmin):\n            date_hierarchy = 'custom_date'\n\n        class CustomModel(models.Model):\n            custom_date = models.DateField()\n\n        custom_admin = CustomModelAdmin(CustomModel, site)\n        request = self.factory.get('/')\n        request.user = self.superuser\n        changelist = custom_admin.get_changelist_instance(request)\n        spec = date_hierarchy(changelist)\n        self.assertEqual(spec['field'], 'custom_date')\n"], "sample_166": ["    def test_get_random_string_length(self):\n        self.assertEqual(len(get_random_string(length=10)), 10)\n        self.assertEqual(len(get_random_string(length=20)), 20)\n"], "sample_93": ["    def test_subquery_with_aggregate_in_group_by(self):\n        avg_rating_qs = Book.objects.filter(publisher=OuterRef('pk')).values('publisher').annotate(avg_rating=Avg('rating'))\n        publisher_qs = Publisher.objects.annotate(\n            avg_rating=Subquery(avg_rating_qs),\n        ).annotate(count=Count('book'))\n        with self.assertNumQueries(1) as ctx:\n            list(publisher_qs)\n        self.assertEqual(ctx[0]['sql'].count('SELECT'), 2)\n"], "sample_284": ["    def test_file_change_after_collectstatic_with_relative_path(self):\n        # Create initial static files.\n        file_contents = (\n            ('foo.png', 'foo'),\n            ('bar.css', 'url(../foo.png)\\nurl(xyz.png)'),\n            ('xyz.png', 'xyz'),\n        )\n        for filename, content in file_contents:\n            with open(self._get_filename_path(filename), 'w') as f:\n                f.write(content)\n\n        with self.modify_settings(STATICFILES_DIRS={'append': self._temp_dir}):\n            finders.get_finder.cache_clear()\n            err = StringIO()\n            # First collectstatic run.\n            call_command('collectstatic', interactive=False, verbosity=0, stderr=err)\n            relpath = self.hashed_file_path('test/bar.css')\n            with storage.staticfiles_storage.open(relpath) as relfile:\n                content = relfile.read()\n                self.assertIn(b'foo.acbd18db4cc2.png', content)\n                self.assertIn(b'xyz.d16fb36f0911.png', content)\n\n            # Change the contents of the png files.\n            for filename in ('foo.png', 'xyz.png'):\n                with open(self._get_filename_path(filename), 'w+b') as f:\n                    f.write(b\"new content of file to change its hash\")\n\n            # The hashes of the png files in the CSS file are updated after\n            # a second collectstatic.\n            call_command('collectstatic', interactive=False, verbosity=0, stderr=err)\n            relpath = self.hashed_file_path('test/bar.css')\n            with storage.staticfiles_storage.open(relpath) as relfile:\n                content = relfile.read()\n                self.assertIn(b'foo.57a5cb9ba68d.png', content)\n                self.assertIn(b'xyz.57a5cb9ba68d.png', content)\n"], "sample_95": ["    def test_cache_control_decorator(self):\n        @cache_control(private=True, max_age=3600, no_cache=True, no_store=True, must_revalidate=True)\n            return HttpResponse()\n        r = a_view(HttpRequest())\n        self.assertEqual(\n            set(r['Cache-Control'].split(', ')),\n            {'private', 'max-age=3600', 'no-cache', 'no-store', 'must-revalidate'},\n        )\n"], "sample_487": ["    def test_actions_with_custom_permissions_has_method(self):\n        @admin.action(permissions=[\"custom\"])\n            pass\n\n        class BandAdmin(ModelAdmin):\n                return request.user.is_staff\n\n            actions = (custom_permission_action,)\n\n        self.assertIsValid(BandAdmin, Band)\n"], "sample_732": ["def test_data_home():\n    try:\n        data_home = '/tmp/sklearn_test'\n        data = fetch_kddcup99(data_home=data_home, download_if_missing=False)\n        assert os.path.exists(os.path.join(data_home, 'kddcup99'))\n    except IOError:\n        raise SkipTest(\"kddcup99 dataset can not be loaded.\")\n    finally:\n        try:\n            shutil.rmtree(data_home)\n        except OSError:\n            pass\n"], "sample_375": ["    def test_proxy_with_fk(self):\n        A = self.create_model(\"A\")\n        B = self.create_model(\"B\", bases=(A,), proxy=True)\n        C = self.create_model(\"C\", foreign_keys=[models.ForeignKey('B', models.CASCADE)])\n        self.assertRelated(A, [B, C])\n        self.assertRelated(B, [C])\n        self.assertRelated(C, [B])\n\n\n\n"], "sample_975": ["def test_nsolve_complex():\n    x = Symbol('x', complex=True)\n    assert nsolve(x**2 + 1, x, 1j) == 1j\n    assert nsolve(x**2 + 1, x, -1j) == -1j\n"], "sample_138": ["    def test_file_change_after_collectstatic_with_relative_paths(self):\n        # Create initial static files.\n        file_contents = (\n            ('foo.png', 'foo'),\n            ('bar.css', 'url(\"../test/foo.png\")\\nurl(\"xyz.png\")'),\n            ('xyz.png', 'xyz'),\n        )\n        for filename, content in file_contents:\n            with open(self._get_filename_path(filename), 'w') as f:\n                f.write(content)\n\n        with self.modify_settings(STATICFILES_DIRS={'append': self._temp_dir}):\n            finders.get_finder.cache_clear()\n            err = StringIO()\n            # First collectstatic run.\n            call_command('collectstatic', interactive=False, verbosity=0, stderr=err)\n            relpath = self.hashed_file_path('test/bar.css')\n            with storage.staticfiles_storage.open(relpath) as relfile:\n                content = relfile.read()\n                self.assertIn(b'foo.acbd18db4cc2.png', content)\n                self.assertIn(b'xyz.d16fb36f0911.png', content)\n\n            # Change the contents of the png files.\n            for filename in ('foo.png', 'xyz.png'):\n                with open(self._get_filename_path(filename), 'w+b') as f:\n                    f.write(b\"new content of file to change its hash\")\n\n            # The hashes of the png files in the CSS file are updated after\n            # a second collectstatic.\n            call_command('collectstatic', interactive=False, verbosity=0, stderr=err)\n            relpath = self.hashed_file_path('test/bar.css')\n            with storage.staticfiles_storage.open(relpath) as relfile:\n                content = relfile.read()\n                self.assertIn(b'foo.57a5cb9ba68d.png', content)\n                self.assertIn(b'xyz.57a5cb9ba68d.png', content)\n"], "sample_1033": ["def test_issue_14392():\n    assert (cos(zoo)**2).as_real_imag() == (nan, nan)\n"], "sample_1190": ["def test_issue_23040():\n    from sympy.physics.units import Quantity, meter, second\n    q1 = Quantity('q1', dimension=meter/second)\n    q2 = Quantity('q2', dimension=meter/second)\n    q1.set_global_relative_scale_factor(1, meter/second)\n    q2.set_global_relative_scale_factor(2, meter/second)\n    expr = q1 + q2\n    assert SI._collect_factor_and_dimension(expr) == (3, meter/second)\n"], "sample_51": ["    def test_invalid_duration_formats(self):\n        invalid_inputs = (\n            '1 day 10:15:30.1 invalid',\n            '10:15:30.1 day',\n            '1 day 10:15:30.1 invalid',\n            '10:15:30.1 invalid day',\n            'invalid 10:15:30.1',\n            '10:15:30.1 invalid',\n            '10:15:30.1 invalid',\n            'invalid',\n        )\n        for source in invalid_inputs:\n            with self.subTest(source=source):\n                self.assertIsNone(parse_duration(source))\n"], "sample_773": ["def test_LogisticRegression_predict_proba_proba_shape(multi_class):\n    # Test that predict_proba returns the correct shape for multi-class\n    # classification\n\n    X, y = make_classification(n_samples=100, n_classes=3, random_state=0)\n    lr = LogisticRegression(multi_class=multi_class, random_state=0)\n    lr.fit(X, y)\n\n    y_pred_proba = lr.predict_proba(X)\n    n_samples = X.shape[0]\n    n_classes = lr.classes_.size\n\n    if multi_class == 'ovr':\n        assert y_pred_proba.shape == (n_samples, n_classes)\n    else:\n        assert y_pred_proba.shape == (n_samples, n_classes)\n\n\n"], "sample_134": ["    def test_serialize_custom_field(self):\n        class MyCustomField(models.Field):\n                super().__init__(*args, **kwargs)\n\n                return 'MyCustomField'\n\n                return 'MyCustomField'\n\n                return super().formfield(**kwargs)\n\n        class MyModel(models.Model):\n            my_field = MyCustomField()\n\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.CreateModel(\"MyModel\", (\n                    ('id', models.AutoField(primary_key=True)),\n                    ('my_field', MyModel.my_field),\n                ), {}, (models.Model,)),\n            ],\n            \"dependencies\": []\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\"MyCustomField\", output)\n"], "sample_584": ["    def test_auto_combine_with_multiple_concat_dims(self):\n        objs = [Dataset({'x': [0, 1], 'y': [2, 3]}),\n                Dataset({'x': [2, 3], 'y': [4, 5]})]\n        with pytest.warns(FutureWarning, match=\"`concat_dim`\"):\n            auto_combine(objs, concat_dim=['x', 'y'])\n"], "sample_575": ["    def test_label_format(self, t):\n\n        fmt = \"%b %Y\"\n        s = Temporal().label(format=fmt)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"Sep 1972\"\n"], "sample_452": ["    def test_references_field_by_related_name(self):\n        operation = FieldOperation(\n            \"Model\",\n            \"field\",\n            models.ForeignKey(\"Other\", models.CASCADE, related_name=\"related_field\"),\n        )\n        self.assertIs(\n            operation.references_field(\"Other\", \"related_field\", \"migrations\"), True\n        )\n        self.assertIs(\n            operation.references_field(\"Other\", \"whatever\", \"migrations\"), False\n        )\n"], "sample_894": ["compilation error"], "sample_1097": ["def test_block_collapse_with_matrices():\n    A = Matrix([[1, 2], [3, 4]])\n    B = Matrix([[5, 6], [7, 8]])\n    C = Matrix([[9, 10], [11, 12]])\n    X = BlockMatrix([[A, B], [C, A]])\n    assert block_collapse(X + X) == BlockMatrix([[2*A, 2*B], [2*C, 2*A]])\n    assert block_collapse(X * X) == BlockMatrix([[A*A + B*C, A*B + B*B], [C*A + A*C, C*B + B*B]])\n"], "sample_137": ["    def test_replace_named_groups(self):\n        self.assertEqual(replace_named_groups('(?P<a>\\w+)/b/(\\w+)$'), '<a>/b/<var>')\n        self.assertEqual(replace_named_groups('(?P<a>\\w+)/b/(?P<c>\\w+)/$'), '<a>/b/<c>')\n        self.assertEqual(replace_named_groups('(?P<a>\\w+)/b/(\\w+)'), '<a>/b/<var>')\n        self.assertEqual(replace_named_groups('(?P<a>\\w+)/b/(?P<c>\\w+)'), '<a>/b/<var>')\n        self.assertEqual(replace_named_groups('(?P<a>\\w+)/b/((x|y)\\w+)$'), '<a>/b/<var>')\n        self.assertEqual(replace_named_groups('(?P<a>\\w+)/b/((x|y)\\w+)'), '<a>/b/<var>')\n        self.assertEqual(replace_named_groups('(?P<a>\\w+)/b/(?P<c>\\w+)/(?P<d>\\w+)$'), '<a>/b/<c>/<d>')\n        self.assertEqual(replace_named_groups('(?P<a>\\w+)/b/((x|y)\\w+)/(?P<d>\\w+)$'), '<a>/b/<var>/<d>')\n"], "sample_998": ["def test_issue_14402():\n    from sympy.physics.quantum import Dagger\n    a = symbols('a')\n    assert latex(Dagger(a)) == r\"{a}^{\\dagger}\"\n"], "sample_1125": ["def test_differential_operator():\n    from sympy.physics.quantum.operator import DifferentialOperator\n    from sympy import Derivative, Function, Symbol, sin\n\n    x = Symbol('x')\n    f = Function('f')\n    d = DifferentialOperator(Derivative(f(x), x), f(x))\n    w = sin(x)\n    assert qapply(d*w) == cos(x)\n"], "sample_315": ["    def test_redirect_with_trailing_slash(self):\n        response = self.client.get('/account/register/', HTTP_ACCEPT_LANGUAGE='en', follow=True)\n        # We only want one redirect, bypassing CommonMiddleware\n        self.assertEqual(response.redirect_chain, [('/en/account/register/', 302)])\n        self.assertRedirects(response, '/en/account/register/', 302)\n"], "sample_949": ["def test_toc(app, status, warning):\n    app.build()\n    content = (app.outdir / 'python.1').read_text()\n    assert r'\\fBTable of Contents\\fP' in content\n"], "sample_1146": ["def test_latex_printing_of_matrices_with_symbols():\n    from sympy import MatrixSymbol, symbols\n\n    x, y = symbols('x y')\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n\n    assert latex(A + B) == r\"\\mathbf{A} + \\mathbf{B}\"\n    assert latex(A - B) == r\"\\mathbf{A} - \\mathbf{B}\"\n    assert latex(A * B) == r\"\\mathbf{A} \\mathbf{B}\"\n    assert latex(A**2) == r\"\\mathbf{A}^{2}\"\n    assert latex(A * x) == r\"\\mathbf{A} x\"\n    assert latex(A * y**2) == r\"\\mathbf{A} y^{2}\"\n    assert latex(A * MatrixSymbol('C', 2, 1)) == r\"\\mathbf{A} \\mathbf{C}\"\n"], "sample_194": ["    def test_opclasses_with_condition(self):\n        msg = 'UniqueConstraint with conditions cannot have opclasses.'\n        with self.assertRaisesMessage(ValueError, msg):\n            models.UniqueConstraint(\n                fields=['name'],\n                name='name_with_condition_opclasses',\n                condition=models.Q(color__isnull=True),\n                opclasses=['text_pattern_ops'],\n            )\n"], "sample_344": ["    def test_related_models_with_through_model_and_proxy(self):\n        A = self.create_model(\"A\")\n        B = self.create_model(\"B\", proxy=True)\n        T = self.create_model(\"T\", foreign_keys=[\n            models.ForeignKey('A', models.CASCADE),\n            models.ForeignKey('B', models.CASCADE),\n        ])\n        self.assertRelated(A, [B, T])\n        self.assertRelated(B, [A, T])\n        self.assertRelated(T, [A, B])\n"], "sample_523": ["def test_legend_title_fontsize_with_None():\n    fig, ax = plt.subplots()\n    ax.plot(range(10), label='test')\n    leg = ax.legend(title=\"Aardvark\", title_fontsize=None)\n    assert leg.get_title().get_fontsize() is None\n\n"], "sample_882": ["def test_mlp_partial_fit_with_validation_fraction(MLPEstimator):\n    \"\"\"Check partial fit works correctly with validation_fraction.\"\"\"\n    mlp = MLPEstimator(\n        early_stopping=True, validation_fraction=0.2, random_state=0\n    )\n    mlp.fit(X_iris, y_iris)\n    mlp.partial_fit(X_iris, y_iris)\n    assert len(mlp.validation_scores_) > 0\n"], "sample_931": ["def test_pyexception_signature_with_args(app):\n    text = (\".. py:exception:: MyException\\n\"\n            \"   :args:\\n\"\n            \"       arg1: int\\n\"\n            \"       arg2: str\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"exception \"],\n                                                    [desc_name, \"MyException\"])],\n                                  [desc_content, (addnodes.index,\n                                                  desc)])]))\n    assert_node(doctree[1][0][1], addnodes.index,\n                entries=[('single', 'MyException (built-in exception)', 'MyException', '', None)])\n    assert_node(doctree[1][0][2], addnodes.index,\n                entries=[('pair', 'arg1: int', 'arg1', '', None),\n                         ('pair', 'arg2: str', 'arg2', '', None)])\n\n\n\n"], "sample_105": ["    def test_redirect_view_with_kwargs(self):\n        \"\"\"\n        Test a RedirectView with keyword arguments.\n        \"\"\"\n        response = RedirectView.as_view(url='/bar/{object_id}/', permanent=True)(self.rf.get('/foo/42/'))\n        self.assertEqual(response.status_code, 301)\n        self.assertEqual(response.url, '/bar/42/')\n"], "sample_162": ["    def test_makemessages_no_settings_with_locale_path(self):\n        with override_settings(LOCALE_PATHS=['/tmp/locale']):\n            out, err = self.run_django_admin(['makemessages', '-l', 'en', '-v', '0'])\n        self.assertNoOutput(err)\n        self.assertNoOutput(out)\n"], "sample_935": ["compilation error"], "sample_1070": ["def test_log_issue_10214():\n    x = Symbol('x', real=True)\n    assert log(x, 2).rewrite(exp) == log(x, 2)\n    assert log(x, 2).rewrite(log) == log(x, 2)\n    assert log(x, 2).rewrite(exp).rewrite(log) == log(x, 2)\n"], "sample_372": ["    def test_lookahead_and_lookbehind_together(self):\n        test_urls = [\n            ('/lookahead-/lookbehind+/a-city/', {'city': 'a-city'}),\n            ('/lookbehind-/lookahead+/a-city/', {'city': 'a-city'}),\n        ]\n        for test_url, kwargs in test_urls:\n            with self.subTest(url=test_url):\n                self.assertEqual(resolve(test_url).kwargs, kwargs)\n"], "sample_174": ["    def test_explain_query_prefix_raise_not_supported_error(self):\n        msg = 'This backend does not support explaining query execution.'\n        with self.assertRaisesMessage(NotSupportedError, msg):\n            connection.ops.explain_query_prefix()\n"], "sample_342": ["    def test_autocomplete_with_related_model_search_fields(self):\n        class RelatedModelSearchAdmin(ManagerAdmin):\n            search_fields = ['employee__name']\n\n        with model_admin(Manager, RelatedModelSearchAdmin):\n            self.selenium.get(self.live_server_url + reverse('autocomplete_admin:admin_views_bonus_add'))\n            elem = self.selenium.find_element_by_css_selector('.select2-selection')\n            elem.click()  # Open the autocomplete dropdown.\n            results = self.selenium.find_element_by_css_selector('.select2-results')\n            self.assertTrue(results.is_displayed())\n            search = self.selenium.find_element_by_css_selector('.select2-search__field')\n            search.send_keys('Frida')\n            with self.select2_ajax_wait():\n                results = results.find_elements_by_css_selector('.select2-results__option')\n                self.assertEqual(len(results), 1)\n            search.send_keys(Keys.RETURN)\n"], "sample_1076": ["def test_sympy_printing_of_matrix_operations():\n    from sympy import Matrix, eye, zeros, MatrixSymbol, simplify\n\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    x = MatrixSymbol('x', 2, 1)\n\n    prntr = SymPyPrinter()\n\n    # Matrix addition\n    assert prntr.doprint(A + B) == 'A + B'\n    # Matrix subtraction\n    assert prntr.doprint(A - B) == 'A - B'\n    # Matrix multiplication\n    assert prntr.doprint(A * B) == 'A * B'\n    # Matrix transpose\n    assert prntr.doprint(A.T) == 'A.T'\n    # Matrix inverse\n    assert prntr.doprint(A**(-1)) == 'A.inv()'\n    # Identity matrix\n    assert prntr.doprint(eye(3)) == 'sympy.eye(3)'\n    # Zero matrix\n    assert prntr.doprint(zeros(2, 3)) == 'sympy.zeros(2, 3)'\n    # Matrix solve\n    assert prntr.doprint(MatrixSolve(A, x)) == 'solve(A*x, x)'\n    # Matrix dot product\n    assert prntr.doprint(A.dot(B)) == 'A.dot(B)'\n    # Matrix power\n    assert prntr.doprint(A**2) == 'A**2'\n    # Matrix determinant\n    assert prntr.doprint(A.det()) == 'A.det()'\n    # Matrix trace\n    assert prntr.doprint(A.trace()) == 'A.trace()'\n    # Matrix rank\n    assert prntr.doprint(A.rank()) == 'A.rank()'\n    # Matrix eigenvalues\n    assert prntr.doprint(A.eigenvals()) == 'A.eigenvals()'\n    # Matrix eigenvectors\n    assert prntr.doprint(A.eigenvects()) == 'A.eigenvects()'\n\n\n\n"], "sample_622": ["    def test_decode_cf_with_invalid_units(self) -> None:\n        with pytest.raises(ValueError, match=\"Invalid units string\"):\n            conventions.decode_cf(Dataset({\"time\": (\"time\", [0, 1], {\"units\": \"invalid\"})}))\n"], "sample_165": ["    def test_modelchoicefield_empty_label(self):\n        # ModelChoiceField\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': 'INVALID CHOICE',\n        }\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e, empty_label=None)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID CHOICE'], f.clean, '4')\n\n"], "sample_853": ["def test_transform_target_regressor_multi_output_with_inverse_func():\n    X = friedman[0]\n    y = np.vstack((friedman[1], friedman[1] ** 2 + 1)).T\n    func = lambda x: np.sqrt(x[:, 0] ** 2 + x[:, 1] ** 2)\n    inverse_func = lambda x: np.array([x[:, 0], x[:, 0] ** 2 + 1])\n    regr = TransformedTargetRegressor(func=func, inverse_func=inverse_func)\n    y_pred = regr.fit(X, y).predict(X)\n    assert y_pred.shape == y.shape\n    assert_allclose(y, regr.inverse_func(y_pred))\n"], "sample_501": ["def test_legend_title_fontsize_with_fontproperties():\n    # test the title_fontsize kwarg with fontproperties\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontproperties=FontProperties(\n                                       family='serif', size=22))\n    assert leg.get_title().get_fontsize() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10"], "sample_961": ["def test_warn_missing_reference_with_explicit_title(app, status, warning):\n    app.build()\n    assert 'index.rst:6: WARNING: undefined label: no-label' in warning.getvalue()\n    assert ('index.rst:7: WARNING: Failed to create a cross reference. A title or caption not found: existing-label'\n            in warning.getvalue())\n"], "sample_1111": ["def test_multiple_variables():\n    x = Symbol('x')\n    y = Symbol('y')\n    lines = [\n        '      1 |                .                .                ',\n        '        |               .                .                ',\n        '        |              .                .                ',\n        '        |             .                .                ',\n        '        |            .                .                ',\n        '        |           .                .                ',\n        '        |          .                .                ',\n        '        |         .                .                ',\n        '        |        .                .                ',\n        '        |       .                .                ',\n        '    0.5 |-------------------------------------------------------',\n        '        |                .                .                ',\n        '        |               .                .                ',\n        '        |              .                .                ',\n        '        |             .                .                ',\n        '        |            .                .                ',\n        '        |           .                .                ',\n        '        |          .                .                ',\n        '        |         .                .                ',\n        '        |        .                .                ',\n        '      0 |_______________________________________________________',\n        '         -1                         0                          1'\n    ]\n    assert list(textplot_str(x*y, -1, 1, -1, 1)) == lines\n"], "sample_357": ["    def test_operation_with_no_suggested_name_and_initial_true(self):\n        class Migration(migrations.Migration):\n            initial = True\n            operations = [\n                migrations.RunSQL('SELECT 1 FROM person;'),\n            ]\n\n        migration = Migration('0001_initial', 'test_app')\n        self.assertEqual(migration.suggest_name(), 'initial')\n"], "sample_1177": ["def test_issue_19627():\n    from sympy.functions.elementary.complexes import polar_lift\n    x = Symbol('x')\n    assert polar_lift(x**2).subs(x, 1 + I) == (1 + I)**2\n"], "sample_635": ["    def test_fail_docstring_min_length(self) -> None:\n        \"\"\"Example of a function that is less than 'docstring-min-length' config option\n\n        An error message is emitted.\n        \"\"\"\n        node = astroid.extract_node(\n            \"\"\"\n            '''function is too short'''\n            pass\n        \"\"\"\n        )\n        with self.assertAddsMessages(\n            MessageTest(msg_id=\"docstring-too-short\", node=node)\n        ):\n            self.checker.visit_functiondef(node)\n"], "sample_1027": ["def test_issue_15167():\n    assert poly(x**2 + y**2, x, y) == Poly(x**2 + y**2, x, y)\n    assert poly(x**2 + y**2, x, y, domain='ZZ') == Poly(x**2 + y**2, x, y, domain='ZZ')\n    assert poly(x**2 + y**2, x, y, domain='RR') == Poly(x**2 + y**2, x, y, domain='RR')\n    assert poly(x**2 + y**2, x, y, domain='QQ') == Poly(x**2 + y**2, x, y, domain='QQ')\n"], "sample_164": ["    def test_server_formatter_custom_format(self):\n        formatter = ServerFormatter(format='%(asctime)s - %(levelname)s - %(message)s')\n        log_msg = 'log message'\n        record = logging.makeLogRecord({'msg': log_msg})\n        self.assertEqual(formatter.format(record), f'{formatter.formatTime(record, \"%Y-%m-%d %H:%M:%S\")} - INFO - log message')\n"], "sample_803": ["compilation error"], "sample_1029": ["def test_Sum2():\n    sT(Sum2(x, (x, 0, 1, 1)), \"Sum2(Symbol('x'), (Symbol('x'), 0, 1, 1))\")\n"], "sample_355": ["    def test_get_user_anonymous(self):\n        self.client.logout()\n        request = HttpRequest()\n        user = get_user(request)\n        self.assertIsNone(user)\n"], "sample_630": ["def test_get_node_type(node_type, expected):\n    node = astroid.extract_node(f\"def {node_type.__name__}(): pass\")\n    assert infer_node(node) == {expected}, f\"got {infer_node(node)} instead of {expected} for node type {node_type}\"\n"], "sample_369": ["    def test_suggest_name_with_custom_operation(self):\n        class CustomOperation(migrations.MigrationOperation):\n                super().__init__(name, **kwargs)\n                self.name = name\n\n        class Migration(migrations.Migration):\n            operations = [\n                CustomOperation('custom_operation'),\n            ]\n\n        migration = Migration('some_migration', 'test_app')\n        self.assertEqual(migration.suggest_name(), 'custom_operation')\n"], "sample_1110": ["def test_sympy_printing():\n    from sympy import symbols, sin, cos, exp, log, sqrt, pi\n\n    x, y = symbols('x y')\n\n    prntr = SymPyPrinter()\n    assert prntr.doprint(sin(x)) == 'sympy.sin(x)'\n    assert prntr.doprint(cos(x)) == 'sympy.cos(x)'\n    assert prntr.doprint(exp(x)) == 'sympy.exp(x)'\n    assert prntr.doprint(log(x)) == 'sympy.log(x)'\n    assert prntr.doprint(sqrt(x)) == 'sympy.sqrt(x)'\n    assert prntr.doprint(pi) == 'sympy.pi'\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(x + y) == 'x + y'\n    assert prntr.doprint(x*y) == 'x*y'\n\n\n\n"], "sample_217": ["    def test_add_empty_order(self):\n        media = Media(css={'screen': ['a.css']}, js=['a'])\n        empty_media = Media()\n        merged = empty_media + media\n        self.assertEqual(merged._css_lists, [{'screen': ['a.css']}])\n        self.assertEqual(merged._js_lists, [['a']])\n"], "sample_585": ["def test_da_groupby_first_last():\n    array = xr.DataArray([1, 2, 3, 4, 5, 6],\n                         [('x', [1, 1, 1, 2, 2, 2])])\n\n    expected_first = xr.DataArray([1, 4], [('x', [1, 2])])\n    actual_first = array.groupby('x').first()\n    assert_identical(expected_first, actual_first)\n\n    expected_last = xr.DataArray([3, 6], [('x', [1, 2])])\n    actual_last = array.groupby('x').last()\n    assert_identical(expected_last, actual_last)\n\n\n\n"], "sample_459": ["    def test_integerfield_cleans_negative_values_with_min_value(self):\n        f = models.IntegerField(min_value=-10)\n        self.assertEqual(f.clean(-5, None), -5)\n"], "sample_432": ["    def test_filter_by_date(self):\n        from datetime import datetime, timedelta\n\n        today = datetime.now()\n        yesterday = today - timedelta(days=1)\n        tomorrow = today + timedelta(days=1)\n\n        Parent.objects.bulk_create(\n            [\n                Parent(name=f\"parent {i}\", created_at=today)\n                for i in range(10)\n            ]\n        )\n        Parent.objects.create(name=\"parent 11\", created_at=yesterday)\n        Parent.objects.create(name=\"parent 12\", created_at=tomorrow)\n\n        self.admin_login(username=\"super\", password=\"secret\")\n        self.selenium.get(\n            self.live_server_url + reverse(\"admin:admin_changelist_parent_changelist\")\n        )\n\n        # Filter by today's date\n        self.selenium.find_element(By.CSS_SELECTOR, \"[data-filter-title='created_at']\").click()\n        self.selenium.find_element(\n            By.CSS_SELECTOR,\n            f\"[data-filter-value='{today.strftime('%Y-%m-%d')}']\",\n        ).click()\n        rows = self.selenium.find_elements(By.CSS_SELECTOR, \"tbody tr\")\n        self.assertEqual(len(rows), 10)\n\n        # Filter by yesterday's date\n        self.selenium.find_element(\n            By.CSS_SELECTOR, f\"[data-filter-value='{yesterday.strftime('%Y-%m-%d')}']\"\n        ).click()\n        rows = self.selenium.find_elements(By.CSS_SELECTOR, \"tbody tr\")\n        self.assertEqual(len(rows), 1)\n\n        # Filter by tomorrow's date\n        self.selenium.find_element(\n            By.CSS_SELECTOR, f\"[data-filter-value='{tomorrow.strftime('%Y-%m-%d')}']\"\n        ).click()\n        rows = self.selenium.find_elements(By.CSS_SELECTOR, \"tbody tr\")\n        self.assertEqual(len(rows), 1)\n\n"], "sample_547": ["def test_offsetbox_clip_children_with_drawingarea():\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100)\n    bg = mpatches.Rectangle((0, 0), 100, 100,\n                            facecolor='#CCCCCC',\n                            edgecolor='None',\n                            linewidth=0)\n    line = mlines.Line2D([-50, 50], [0, 0],\n                         color='black',\n                         linewidth=10)\n    anchored_box = AnchoredOffsetbox(loc='center', child=da)\n    da.add_artist(bg)\n    da.add_artist(line)\n    ax.add_artist(anchored_box)\n    fig.canvas.draw()\n\n\n\n"], "sample_225": ["    def test_register_unregister(self):\n        class MyModel(models.Model):\n            pass\n\n        with self.assertRaises(AlreadyRegistered):\n            site.register(MyModel)\n            site.register(MyModel)\n\n        self.assertIn(MyModel, site._registry)\n        site.unregister(MyModel)\n        self.assertNotIn(MyModel, site._registry)\n"], "sample_1045": ["def test_issue_6133_continued():\n    raises(TypeError, lambda: (None < -oo))\n    raises(TypeError, lambda: (None > -oo))\n    raises(TypeError, lambda: (None < S(-2)))\n    raises(TypeError, lambda: (None > S(-2)))\n    raises(TypeError, lambda: (None < oo))\n    raises(TypeError, lambda: (None > oo))\n    raises(TypeError, lambda: (None < S(2)))\n    raises(TypeError, lambda: (None > S(2)))\n"], "sample_754": ["def test_sparse_pca_with_missing_data(norm_comp):\n    rng = np.random.RandomState(0)\n    n_samples = 100\n    n_features = 10\n    n_components = 3\n    Y = rng.randn(n_samples, n_features)\n    # Introduce some missing data\n    Y[::2, ::2] = np.nan\n    spca = SparsePCA(n_components=n_components,\n                     normalize_components=norm_comp)\n    spca.fit(Y)\n    assert_true(not np.all(spca.components_ == 0))\n"], "sample_907": ["def test_domain_cpp_parse_template_param_in_decl(app):\n    text = (\".. cpp:function:: template<typename T> void f(T t)\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index, desc, addnodes.index, desc))\n    assert_node(doctree[0], addnodes.index, entries=[('single', 'f (C++ function)', '_CPPv4I0E14fvv', '', None)])\n    assert_node(doctree[0][0], 'templateParam', name='T', type='typename')\n"], "sample_322": ["    def test_minimize_rollbacks_circular_dependency(self):\n        \"\"\"\n        Minimize rollbacks when there's a circular dependency.\n\n        a: 1 <--- 2\n        b:    \\- 1\n        c:     \\- 1\n\n        If a1 is applied already and a2 is not, and we're asked to migrate to\n        a1, don't apply or unapply b1 or c1, regardless of their current state.\n        \"\"\"\n        a1_impl = FakeMigration('a1')\n        a1 = ('a', '1')\n        a2_impl = FakeMigration('a2')\n        a2 = ('a', '2')\n        b1_impl = FakeMigration('b1')\n        b1 = ('b', '1')\n        c1_impl = FakeMigration('c1')\n        c1 = ('c', '1')\n        graph = MigrationGraph()\n        graph.add_node(a1, a1_impl)\n        graph.add_node(a2, a2_impl)\n        graph.add_node(b1, b1_impl)\n        graph.add_node(c1, c1_impl)\n        graph.add_dependency(None, a2, a1)\n        graph.add_dependency(None, b1, a1)\n        graph.add_dependency(None, c1, a1)\n        graph.add_dependency(None, a1, a2)  # Circular dependency\n        graph.add_dependency(None, a1, b1)  # Circular dependency\n        graph.add_dependency(None, a1, c1)  # Circular dependency\n\n        executor = MigrationExecutor(None)\n        executor.loader = FakeLoader(graph, {\n            a1: a1_impl,\n            b1: b1_impl,\n        })\n\n        plan = executor.migration_plan({a1})\n\n        self.assertEqual(plan, [])\n"], "sample_233": ["    def test_token_with_different_user(self):\n        user1 = User.objects.create_user('user1', 'user1@example.com', 'testpw')\n        user2 = User.objects.create_user('user2', 'user2@example.com', 'testpw')\n        p0 = PasswordResetTokenGenerator()\n        tk1 = p0.make_token(user1)\n        self.assertIs(p0.check_token(user2, tk1), False)\n"], "sample_187": ["    def test_camel_case_to_spaces(self):\n        self.assertEqual(text.camel_case_to_spaces('ThisIsCamelCase'), 'This Is Camel Case')\n        self.assertEqual(text.camel_case_to_spaces('thisIsCamelCase'), 'this Is Camel Case')\n        self.assertEqual(text.camel_case_to_spaces('this_is_snake_case'), 'this is snake case')\n        self.assertEqual(text.camel_case_to_spaces('PascalCase'), 'Pascal Case')\n        self.assertEqual(text.camel_case_to_spaces('snake_case'), 'snake case')\n        self.assertEqual(text.camel_case_to_spaces('MixedCase'), 'Mixed Case')\n        self.assertEqual(text.camel_case_to_spaces('a'), 'a')\n        self.assertEqual(text.camel_case_to_spaces(''), '')\n"], "sample_239": ["    def test_all_valid_with_non_form_errors(self):\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '0',\n            'choices-MAX_NUM_FORMS': '1',  # should be ignored\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': '0',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '1',\n        }\n        ChoiceFormSet = formset_factory(Choice, extra=1, max_num=1, validate_max=True)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [{}, {'votes': ['This field is required.']}]\n        self.assertEqual(formset1._errors, expected_errors)\n        self.assertEqual(formset2._errors, expected_errors)\n"], "sample_999": ["def test_issue_14367():\n    from sympy.physics.quantum import Dagger\n    a = symbols('a')\n    assert latex(Dagger(a)) == r\"{a}^{\\dagger}\"\n"], "sample_1081": ["compilation error"], "sample_548": ["compilation error"], "sample_388": ["    def test_user_switch_forces_new_login(self):\n        \"\"\"\n        If the username in the header changes between requests\n        that the original user is logged out\n        \"\"\"\n        User.objects.create(username=\"knownuser\")\n        # Known user authenticates\n        response = self.client.get(\"/remote_user/\", **{self.header: self.known_user})\n        self.assertEqual(response.context[\"user\"].username, \"knownuser\")\n        # During the session, the REMOTE_USER changes to a different user.\n        response = self.client.get(\"/remote_user/\", **{self.header: \"newnewuser\"})\n        # The current user is not the prior remote_user.\n        # In backends that create a new user, username is \"newnewuser\"\n        # In backends that do not create new users, it is '' (anonymous user)\n        self.assertNotEqual(response.context[\"user\"].username, \"knownuser\")\n"], "sample_351": ["    def test_modelchoicefield_with_empty_label(self):\n        f = forms.ModelChoiceField(Category.objects.all(), empty_label=None)\n        self.assertEqual(f.choices[0], ('', ''))\n        f = forms.ModelChoiceField(Category.objects.all(), empty_label='---------')\n        self.assertEqual(f.choices[0], ('', '---------'))\n"], "sample_870": ["def test_gpr_predict_with_sparse_data():\n    \"\"\"Check that predict works correctly with sparse input data.\"\"\"\n    from scipy.sparse import csr_matrix\n\n    n_samples, n_features = 10, 5\n    X = csr_matrix(np.random.rand(n_samples, n_features))\n    y = np.random.rand(n_samples)\n\n    gpr = GaussianProcessRegressor().fit(X, y)\n\n    y_pred = gpr.predict(X)\n    assert y_pred.shape == (n_samples,)\n    assert isinstance(y_pred, np.ndarray)\n\n    y_pred_std = gpr.predict(X, return_std=True)\n    assert y_pred_std[0].shape == (2,)  # (mean, std)\n\n\n\n"], "sample_659": ["    def test_raises_with_unicode_exception_message(self):\n        with pytest.raises(ValueError, match=u\"Invalid Unicode\"):\n            raise ValueError(u\"Invalid Unicode\")\n"], "sample_1162": ["def test_nfloat_dict():\n    from sympy.core.symbol import Symbol\n    x = Symbol('x')\n    expr = {'a': x**2, 'b': 2*x + 1, 'c': 3}\n    assert nfloat(expr) == {'a': x**2, 'b': 2*x + 1, 'c': 3}\n    assert nfloat(expr, dkeys=True) == {'a': x**2.0, 'b': 2*x + 1, 'c': 3.0}\n"], "sample_819": ["def test_partial_fit():\n    \"\"\"Check partial_fit functionality of VotingClassifier.\"\"\"\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    clf3 = GaussianNB()\n    eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n                            voting='soft')\n\n    X_train = X[:5]\n    y_train = y[:5]\n    X_test = X[5:]\n    y_test = y[5:]\n\n    eclf.partial_fit(X_train, y_train)\n    assert_array_almost_equal(eclf.predict(X_test),\n                              eclf.predict(X_test))\n\n    eclf.partial_fit(X_train[1:], y_train[1:])\n    assert_array_almost_equal(eclf.predict(X_test),\n                              eclf.predict(X_test))\n\n    eclf.partial_fit(X_train, y_train, classes=[0, 1])\n    assert_array_almost_equal(eclf.predict(X_test),\n                              eclf.predict(X_test))\n\n\n\n"], "sample_992": ["def test_piecewise():\n    p = PythonCodePrinter()\n    expr = Piecewise((x > 0, x, x <= 0, -x))\n    assert p.doprint(expr) == 'if (x > 0):\\n  return x\\nelse:\\n  return -x'\n    p = NumPyPrinter()\n    expr = Piecewise((x > 0, x, x <= 0, -x))\n    assert p.doprint(expr) == 'numpy.select([x > 0, x <= 0], [x, -x], default=numpy.nan)'\n"], "sample_820": ["def test_estimator_weights_validation():\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    with pytest.raises(ValueError,\n                       match=\"Weights should be a list or array-like with \"\n                             \"the same length as the number of estimators\"):\n        VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)],\n                         weights=[1, 2, 3]).fit(X, y)\n    with pytest.raises(ValueError,\n                       match=\"Weights should be a list or array-like with \"\n                             \"the same length as the number of estimators\"):\n        VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)],\n                         weights=[1, 2]).fit(X, y)\n\n\n\n"], "sample_140": ["    def test_sensitive_variables_decorator_with_args(self):\n        @sensitive_variables(exclude=['cooked_eggs'])\n            return password + cooked_eggs\n\n        with self.settings(DEBUG=True):\n            response = self.client.post('/some_url/', data={'password': 'secret', 'cooked_eggs': 'sunny-side-up'})\n            self.assertContains(response, 'secret', status_code=500)\n            self.assertNotContains(response, 'sunny-side-up', status_code=500)\n"], "sample_374": ["    def test_nested_prefetch_with_to_attr(self):\n        queryset = House.objects.only('name').prefetch_related(\n            Prefetch(\n                'rooms',\n                Room.objects.prefetch_related(\n                    Prefetch(\n                        'house',\n                        queryset=House.objects.only('address'),\n                        to_attr='house_address',\n                    ),\n                ),\n                to_attr='rooms_with_address',\n            ),\n        )\n        with self.assertNumQueries(3):\n            house = queryset.first()\n\n        with self.assertNumQueries(0):\n            self.assertIs(Room.house.is_cached(self.room), True)\n            self.assertEqual(house.rooms_with_address[0].house_address.address, '123 Main St')\n"], "sample_88": ["    def test_send_messages_with_connection_error(self):\n        \"\"\"\n        send_messages() should handle connection errors gracefully.\n        \"\"\"\n        self.backend.fail_silently = True\n        self.backend.connection = FakeSMTPChannel()\n        self.backend.connection.collect_incoming_data = lambda self, data: raise ConnectionError(\"Connection error\")\n        email = EmailMessage('Subject', 'Content', 'from@example.com', ['to@example.com'])\n        sent = self.backend.send_messages([email])\n        self.assertEqual(sent, 0)\n"], "sample_441": ["    def test_password_too_short(self):\n        user = User.objects.get(username=\"testclient\")\n        data = {\"password1\": \"a\", \"password2\": \"a\"}\n        form = AdminPasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form.errors[\"password1\"],\n            [\n                \"Password must be at least 8 characters long.\",\n            ],\n        )\n        self.assertEqual(form.errors[\"password2\"], [\n            \"Password must be at least 8 characters long.\",\n        ])\n        self.assertEqual(form.changed_data, [])\n"], "sample_514": ["def test_colorbar_fraction_with_subplots():\n    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n    for i in range(2):\n        for j in range(2):\n            im = axes[i, j].imshow(np.random.rand(10, 10))\n            fig.colorbar(im, ax=axes[i, j], fraction=0.05)\n    fig.draw_without_rendering()\n    # check that the colorbars are all the right size\n    for i in range(2):\n        for j in range(2):\n            cb = fig.colorbar(im, ax=axes[i, j], fraction=0.05)\n            assert cb.ax.get_position().height == 0.05\n\n\n\n"], "sample_168": ["    def test_stale_content_types_with_no_models(self):\n        \"\"\"\n        Stale content types without models are deleted.\n        \"\"\"\n        ContentType.objects.create(app_label='contenttypes_tests', model=None)\n        with captured_stdout() as stdout:\n            call_command('remove_stale_contenttypes', verbosity=2)\n        self.assertIn(\"Deleting stale content type\", stdout.getvalue())\n        self.assertEqual(ContentType.objects.count(), self.before_count)\n"], "sample_306": ["    def test_invalid_iso_8601(self):\n        invalid_inputs = (\n            'P4Y2M',\n            'P4Y2M3D',\n            'P4Y2M3DT1H',\n            'P4Y2M3DT1H1M',\n            'P4Y2M3DT1H1M1S1',\n            'P4Y2M3DT1H1M1S1.1',\n            'P4Y2M3DT1H1M1S1.123',\n            'P4Y2M3DT1H1M1S1.12345',\n            'P4Y2M3DT1H1M1S1.1234567',\n            'P4Y2M3DT1H1M1S1.123456789',\n            'P4Y2M3DT1H1M1S1.1234567890',\n            'P4Y2M3DT1H1M1S1.12345678901',\n            'P4Y2M3DT1H1M1S1.123456789012',\n            'P4Y2M3DT1H1M1S1.1234567890123',\n            'P4Y2M3DT1H1M1S1.12345678901234',\n            'P4Y2M3DT1H1M1S1.123456789012345',\n            'P4Y2M3DT1H1M1S1.1234567890123456',\n            'P4Y2M3DT1H1M1S1.12345678901234567',\n            'P4Y2M3DT1H1M1S1.123456789012345678',\n            'P"], "sample_378": ["    def test_related_object_update_with_prefetch_related(self):\n        parent = RelatedObject.objects.create()\n        child = SingleObject.objects.create(name='child')\n        parent.single = child\n        parent.save()\n        RelatedObject.objects.prefetch_related('single').bulk_update([parent], fields=['single__name'])\n        parent.refresh_from_db()\n        self.assertEqual(parent.single.name, 'child')\n"], "sample_1054": ["def test_issue_12001():\n    a = Interval(0, 1)\n    b = Interval(0, pi)\n    c = ComplexRegion(a * b, polar=True)\n    assert c.measure == 0.5 * pi\n"], "sample_160": ["    def test_empty_string(self):\n        self.assertEqual(nformat(''), '')\n        self.assertEqual(nformat('', '.'), '')\n        self.assertEqual(nformat('', '.', decimal_pos=2), '0.00')\n        self.assertEqual(nformat('', '.', grouping=2, thousand_sep=','), '')\n        self.assertEqual(nformat('', '.', grouping=2, thousand_sep=',', force_grouping=True), '')\n"], "sample_1150": ["def test_issue_18080():\n    assert ImageSet(Lambda(x, x**2), S.Integers).is_subset(S.Naturals0)\n    assert ImageSet(Lambda(x, x**2), S.Naturals).is_subset(S.Naturals)\n    assert ImageSet(Lambda(x, x**2), S.Naturals0).is_subset(S.Naturals0)\n    assert ImageSet(Lambda(x, x**2), S.Reals).is_subset(S.Reals)\n    assert ImageSet(Lambda(x, x**2), S.Complexes).is_subset(S.Complexes)\n"], "sample_84": ["    def test_no_change(self):\n        self.assertEqual(escape_leading_slashes('http://example.com'), 'http://example.com')\n"], "sample_64": ["    def test_cookie_with_unicode_value(self):\n        c = SimpleCookie()\n        c['key'] = '\u4f60\u597d\u4e16\u754c'\n        self.assertEqual(c['key'].value, '\u4f60\u597d\u4e16\u754c')\n        self.assertEqual(c.output(), 'key=\u4f60\u597d\u4e16\u754c')\n"], "sample_79": ["    def test_invalid_input(self):\n        self.assertEqual(pluralize(None), '')\n        self.assertEqual(pluralize(True), '')\n        self.assertEqual(pluralize(False), '')\n        self.assertEqual(pluralize(1.5), 's')\n        self.assertEqual(pluralize(Decimal(1.5)), 's')\n"], "sample_1039": ["def test_print_matrix_elements():\n    A = Matrix([[1, 2], [3, 4]])\n    assert mpp.doprint(A) == '<mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>3</mn></mtd><mtd><mn>4</mn></mtd></mtr></mtable>'\n    assert mp.doprint(A) == '<matrix><row><cn>1</cn><cn>2</cn></row><row><cn>3</cn><cn>4</cn></row></matrix>'\n"], "sample_705": ["def test_pytester_outcomes_with_skipped(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.skip(reason=\"This test is skipped\")\n            pass\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(skipped=1)\n"], "sample_607": ["def test_list_engines_empty(mocker):\n    with pytest.raises(ValueError, match=r\"xarray is unable to open\"):\n        plugins.list_engines()\n"], "sample_229": ["    def test_union_with_distinct_and_ordering(self):\n        qs1 = Number.objects.filter(num__lte=1)\n        qs2 = Number.objects.filter(num__gte=8)\n        qs3 = Number.objects.filter(num=5)\n        self.assertNumbersEqual(qs1.union(qs2, all=True).order_by('-num'), [5, 1, 0, 8, 9])\n\n"], "sample_790": ["def test_kernel_pca_copy_X():\n    rng = np.random.RandomState(0)\n    X = rng.rand(10, 10)\n    kpca = KernelPCA(copy_X=False)\n    kpca.fit(X)\n    assert_equal(kpca.X_fit_, X\n                  )  # X_fit_ should be a reference to the original X\n\n\n\n"], "sample_997": ["def test_issue_11275():\n    assert parse_expr('1/0', evaluate=False) == parse_expr('1/0', evaluate=True)\n"], "sample_735": ["def test_predict_proba_with_covariance_type_spherical():\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng, scale=7)\n    n_components = rand_data.n_components\n\n    X = rand_data.X['spherical']\n    gmm = GaussianMixture(n_components=n_components,\n                          covariance_type='spherical', random_state=rng)\n    gmm.fit(X)\n\n    # Check that the predicted probabilities sum to 1\n    y_pred_proba = gmm.predict_proba(X)\n    for sample_proba in y_pred_proba:\n        assert_almost_equal(np.sum(sample_proba), 1)\n\n\n\n"], "sample_400": ["    def test_operation_with_custom_name(self):\n        class Migration(migrations.Migration):\n            operations = [\n                migrations.CreateModel(\n                    \"Person\",\n                    fields=[],\n                    name=\"my_person\",\n                ),\n            ]\n\n        migration = Migration(\"some_migration\", \"test_app\")\n        self.assertEqual(migration.suggest_name(), \"my_person\")\n"], "sample_927": ["compilation error"], "sample_709": ["def test_pytester_outcomes_with_skipped(pytester: Pytester) -> None:\n    p1 = pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.skip\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest(str(p1))\n    result.assert_outcomes(skipped=1)\n"], "sample_75": ["    def test_prefetch_related_with_related_manager_cache(self):\n        with self.assertNumQueries(2):\n            authors = AuthorWithAge.objects.prefetch_related(\n                Prefetch(\n                    'first_book',\n                    queryset=Book.objects.prefetch_related('authors'),\n                ),\n            )\n        with self.assertNumQueries(0):\n            for author in authors:\n                self.assertEqual(len(author.first_book.authors.all()), 1)\n"], "sample_1003": ["def test_allowed_flags():\n    allowed_flags({'domain': ZZ}, [])\n    raises(FlagError, lambda: allowed_flags({'domain': ZZ, 'frac': True}, []))\n    allowed_flags({'domain': ZZ, 'frac': True}, ['frac'])\n"], "sample_989": ["def test_issue_10528():\n    assert Float(1.23456789012345678901234567890123, 100) == Float(1.23456789012345678901234567890123)\n"], "sample_828": ["def test_pairwise_distances_with_precomputed():\n    # Check pairwise_distances with precomputed distances\n    X = np.random.rand(10, 5)\n    D = pairwise_distances(X)\n    D_precomputed = np.copy(D)\n    distances = pairwise_distances(X, metric='precomputed',\n                                  distances=D_precomputed)\n    assert_array_almost_equal(distances, D)\n\n    # Check that precomputed distances are not modified\n    assert_array_almost_equal(D_precomputed, D)\n\n    # Check that precomputed distances are used even if metric is specified\n    distances = pairwise_distances(X, metric='euclidean',\n                                  distances=D_precomputed)\n    assert_array_almost_equal(distances, D)\n\n\n\n"], "sample_261": ["    def test_invalid_iso_8601(self):\n        invalid_inputs = (\n            'P4Y2M',\n            'P4Y2M3D',\n            'P4Y2M3DT1H',\n            'P4Y2M3DT1H1M',\n            'P4Y2M3DT1H1M1S.1',\n            'P4Y2M3DT1H1M1S.123456789',\n            'P4Y2M3DT1H1M1S.1234567890',\n            'P4Y2M3DT1H1M1S.12345678901',\n            'P4Y2M3DT1H1M1S.123456789012',\n            'P4Y2M3DT1H1M1S.1234567890123',\n            'P4Y2M3DT1H1M1S.12345678901234',\n            'P4Y2M3DT1H1M1S.123456789012345',\n            'P4Y2M3DT1H1M1S.1234567890123456',\n            'P4Y2M3DT1H1M1S.12345678901234567',\n            'P4Y2M3DT1H1M1S.123456789012345678',\n            'P4Y2M3DT1H1M1S.1234567890123456789',\n            'P4Y2M3DT1H1M1S.12345678901234567890',\n            'P4Y2M3DT1H1M1S.1234567890123"], "sample_835": ["def test_adaboost_sparse_sample_weights():\n    # Check that sample weights can be sparse\n    from scipy.sparse import csr_matrix\n\n    X, y = datasets.make_classification(n_samples=100, n_features=10, random_state=0)\n    sample_weights = csr_matrix((np.ones(100), (np.arange(100), np.arange(100))),\n                                shape=(100, 100))\n    clf = AdaBoostClassifier()\n    clf.fit(X, y, sample_weight=sample_weights)\n    assert clf.estimator_weights_.shape[0] == len(clf.estimators_)\n"], "sample_221": ["    def test_in_lookup_with_related_object(self):\n        \"\"\"\n        Test that pickling and unpickling a QuerySet with an __in=related_object\n        lookup doesn't evaluate the related object's queryset.\n        \"\"\"\n        group = Group.objects.create(name='Group 1')\n        event = Event.objects.create(title='Event 1', group=group)\n        events = Event.objects.filter(group__in=event.group)\n\n        with self.assertNumQueries(0):\n            dumped = pickle.dumps(events.query)\n\n        with self.assertNumQueries(0):\n            reloaded = pickle.loads(dumped)\n            reloaded_events = Event.objects.none()\n            reloaded_events.query = reloaded\n\n        self.assertSequenceEqual(reloaded_events, [event])\n"], "sample_1168": ["compilation error"], "sample_317": ["    def test_feed_with_custom_feed_generator_class(self):\n        class MyCustomFeed(Rss201rev2Feed):\n                handler.startElement('custom_element', {})\n                handler.endElement('custom_element')\n\n        response = self.client.get('/syndication/custom_feed/')\n        doc = minidom.parseString(response.content)\n        items = doc.getElementsByTagName('item')\n        for item in items:\n            self.assertTrue('custom_element' in item.childNodes)\n"], "sample_554": ["def test_text_bbox_clip():\n    fig, ax = plt.subplots()\n    text = ax.text(0.9, 0.9, \"This text is clipped\", clip_on=True)\n    fig.canvas.draw()\n    bbox = text.get_window_extent()\n    assert bbox.width < 1\n    assert bbox.height < 1\n\n\n"], "sample_1178": ["def test_FunctionCall_with_kwargs():\n    fc = FunctionCall('my_func', [1, 2], kwargs={'a': 3, 'b': 4})\n    assert fc.function_args == [1, 2]\n    assert fc.kwargs == {'a': 3, 'b': 4}\n    assert fc.func(*fc.args) == fc\n\n    fc2 = FunctionCall('my_func', [1, 2], kwargs={'a': 3})\n    assert fc2.function_args == [1, 2]\n    assert fc2.kwargs == {'a': 3}\n    assert fc2.func(*fc2.args) == fc2\n\n\n\n"], "sample_427": ["    def test_custom_renderer_with_template_name(self):\n        class CustomRenderer(TemplatesSetting):\n            formset_template_name = \"a/custom/formset/template.html\"\n\n        ChoiceFormSet = formset_factory(Choice, renderer=CustomRenderer)\n        formset = ChoiceFormSet()\n        self.assertEqual(formset.template_name, \"a/custom/formset/template.html\")\n\n\n\n"], "sample_367": ["    def test_cache_control_decorator_multiple_args(self):\n        class MyClass:\n            @method_decorator(cache_control(private=True, max_age=3600))\n                return HttpResponse()\n\n        request = HttpRequest()\n        response = MyClass().a_view(HttpRequestProxy(request))\n        self.assertEqual(response.headers['Cache-Control'], 'private, max-age=3600')\n"], "sample_1051": ["def test_custom_styles():\n    styles = [(Basic, {'color': 'green'}),\n              (Expr, {'color': 'red', 'shape': 'box'})]\n    text = dotprint(x + 2, styles=styles)\n    assert 'color=\"green\"' in text\n    assert 'color=\"red\"' in text\n    assert 'shape=\"box\"' in text\n"], "sample_129": ["    def test_floatformat_with_none(self):\n        self.assertEqual(floatformat(None), '')\n"], "sample_235": ["    def test_hook_with_database_cursor(self):\n        with transaction.atomic():\n            self.do(1)\n            transaction.on_commit(\n                lambda: self.notify(\n                    Thing.objects.using('default').get(num=1).id\n                )\n            )\n\n        self.assertDone([1])\n"], "sample_671": ["compilation error"], "sample_874": ["def test_step_parameter():\n    sel = StepSelector(step=2)\n    Xt_actual = sel.fit(X, y).transform(X)\n    assert_array_equal(Xt, Xt_actual)\n\n    sel = StepSelector(step=1)\n    Xt_actual = sel.fit(X, y).transform(X)\n    assert_array_equal(X, Xt_actual)\n\n    sel = StepSelector(step=0)\n    Xt_actual = sel.fit(X, y).transform(X)\n    assert_array_equal(Xt_actual, np.zeros_like(Xt))\n\n    # Check for invalid step values\n    with pytest.raises(ValueError):\n        StepSelector(step=-1)\n    with pytest.raises(ValueError):\n        StepSelector(step=0.5)\n"], "sample_667": ["    def test_basetemp_with_read_only_directory(testdir):\n        \"\"\"Integration test for #5524\"\"\"\n        testdir.makepyfile(\n            \"\"\"\n            import os\n            import stat\n\n                dir = tmp_path / 'dir'\n                dir.mkdir()\n                (dir / 'foo.txt').touch()\n                mode = os.stat(str(dir)).st_mode\n                os.chmod(str(dir), mode & ~stat.S_IREAD)"], "sample_1078": ["def test_Indexed_subs_with_IndexedBase():\n    A = IndexedBase(\"A\")\n    B = IndexedBase(\"B\")\n    i, j, k = symbols(\"i,j,k\")\n    assert A[i].subs(A, B) == B[i]\n    assert A[i, j].subs(A, B) == B[i, j]\n    assert A[i, j].subs(A, B).subs(B, A) == A[i, j]\n    assert A[i, j].subs(A, B).subs(B, C) == C[i, j]\n    assert A[i, j].subs(A, B).subs(B, C).subs(C, A) == A[i, j]\n    assert A[i, j].subs(A, B).subs(B, C).subs(C, B) == B[i, j]\n\n\n\n"], "sample_658": ["    def test_doctest_report_html(self, testdir):\n        result = self._run_doctest_report(testdir, \"html\")\n        result.stdout.fnmatch_lines(\n            [\n                \"*doctest-report.html*\",\n            ]\n        )\n"], "sample_1013": ["def test_issue_15089():\n    x = symbols('x')\n    f = lambdify(x, sin(x) / x, 'sympy')\n    assert f(1) == 0.8414709848078965\n"], "sample_725": ["def test_check_array_sparse_format():\n    X_csr = sp.csr_matrix([[1, 2], [3, 4]])\n    X_csc = sp.csc_matrix([[1, 2], [3, 4]])\n    X_dok = sp.dok_matrix([[1, 2], [3, 4]])\n    X_coo = sp.coo_matrix([[1, 2], [3, 4]])\n    X_lil = sp.lil_matrix([[1, 2], [3, 4]])\n    X_bsr = sp.bsr_matrix([[1, 2], [3, 4]])\n\n    formats = ['csr', 'csc', 'dok', 'coo', 'lil', 'bsr']\n    for format in formats:\n        X_sparse = getattr(sp, format)([[1, 2], [3, 4]])\n        check_array(X_sparse, accept_sparse=format)\n        assert_equal(X_sparse.format, format)\n\n    # Test that specifying a format that doesn't exist raises an error\n    assert_raises_regex(ValueError, \"Invalid sparse format\",\n                        check_array, sp.csr_matrix([[1, 2], [3, 4]]),\n                        accept_sparse='invalid_format')\n\n    # Test that specifying a list of formats works\n    check_array(X_csr, accept_sparse=['csr', 'csc'])\n    assert_equal(X_csr.format, 'csr')\n    check_array(X_csc, accept_sparse=['csr', 'csc'])\n    assert_equal(X_csc.format, 'csc')\n    check_array(X_dok, accept_sparse=['csr', 'csc'])\n    assert_raises_regex(ValueError, \"Sparse matrix format 'dok' not in\",\n                        check_array, X_dok, accept_sparse=['csr', 'csc'])\n\n\n\n"], "sample_350": ["    def test_union_with_multiple_models_and_ordering(self):\n        Celebrity.objects.create(name='Alice', age=30)\n        Celebrity.objects.create(name='Bob', age=25)\n        ReservedName.objects.create(name='Alice', order=1)\n        qs1 = Celebrity.objects.all().order_by('age')\n        qs2 = ReservedName.objects.all().order_by('order')\n        self.assertSequenceEqual(\n            list(qs1.union(qs2).values_list('name', flat=True)),\n            ['Alice', 'Bob', 'Alice'],\n        )\n\n\n\n"], "sample_875": ["def test_log_loss_multiclass_with_labels_and_eps():\n    y_true = np.array([0, 1, 2, 2])\n    y_pred = [[0.2, 0.7, 0.1], [0.6, 0.2, 0.2], [0.4, 0.1, 0.5], [0.6, 0.1, 0.3]]\n    labels = [0, 1, 2]\n    eps = 0.1\n    loss = log_loss(y_true, y_pred, labels=labels, eps=eps)\n    assert_almost_equal(loss, 0.6904911, decimal=6)\n"], "sample_294": ["    def test_csrf_token_on_500_stays_constant(self):\n        response = self.client.get('/internal_server_error/')\n        # The error handler returns status code 500.\n        self.assertEqual(response.status_code, 500)\n        token1 = response.content\n        response = self.client.get('/internal_server_error/')\n        self.assertEqual(response.status_code, 500)\n        token2 = response.content\n        self.assertTrue(equivalent_tokens(token1.decode('ascii'), token2.decode('ascii')))\n"], "sample_696": ["def test_argument_type_str_choice(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"arg\", [\"str\", \"int\", \"float\"])\n            pass\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: `type` argument to addoption() is the string.*\",\n        ]\n    )\n"], "sample_382": ["    def test_get_template_directories_with_multiple_dirs(self):\n        self.assertSetEqual(\n            autoreload.get_template_directories(),\n            {\n                Path(__file__).parent / 'templates',\n                Path(__file__).parent / 'templates_extra',\n            }\n        )\n"], "sample_728": ["def test_make_classification_with_n_features_greater_than_n_informative():\n    n_samples = 100\n    n_features = 10\n    n_informative = 5\n    n_redundant = 2\n    n_repeated = 3\n    weights = [0.1, 0.2, 0.3, 0.4]\n    random_state = 0\n\n    X, y = make_classification(n_samples=n_samples, n_features=n_features,\n                              n_informative=n_informative,\n                              n_redundant=n_redundant,\n                              n_repeated=n_repeated,\n                              weights=weights,\n                              random_state=random_state)\n\n    assert_equal(X.shape, (n_samples, n_features))\n    assert_equal(y.shape, (n_samples,))\n    assert_equal(np.unique(y).shape, (len(weights),))\n    assert_equal(sum(y == 0), int(n_samples * weights[0]))\n    assert_equal(sum(y == 1), int(n_samples * weights[1]))\n    assert_equal(sum(y == 2), int(n_samples * weights[2]))\n    assert_equal(sum(y == 3), int(n_samples * weights[3]))\n\n\n\n"], "sample_85": ["    def test_fast_delete_with_related_objects(self):\n        a = Avatar.objects.create(desc='a')\n        u = User.objects.create(avatar=a)\n        # 1 query to delete the user, 1 to delete the avatar\n        self.assertNumQueries(2, u.delete)\n        self.assertFalse(User.objects.exists())\n        self.assertFalse(Avatar.objects.exists())\n"], "sample_486": ["    def test_inlineformset_factory_nulls_default_pks_auto_parent_auto_child(self):\n        \"\"\"\n        #24958 - Variant of test_inlineformset_factory_nulls_default_pks for\n        the case of both parent and child objects having AutoField primary keys.\n        \"\"\"\n        FormSet = inlineformset_factory(\n            AutoPKParent, AutoPKChildOfUUIDPKParent, fields=\"__all__\"\n        )\n        formset = FormSet()\n        self.assertIsNone(formset.forms[0].fields[\"parent\"].initial)\n"], "sample_968": ["def test_warn_missing_reference_with_explicit_label(app, status, warning):\n    app.build()\n    assert 'index.rst:6: WARNING: undefined label: no-label' in warning.getvalue()\n    assert ('index.rst:7: WARNING: Failed to create a cross reference. A title or caption not found: existing-label'\n            in warning.getvalue())\n"], "sample_397": ["    def test_template_loaders_from_string(self):\n        engine = DjangoTemplates(\n            {\n                \"DIRS\": [],\n                \"APP_DIRS\": False,\n                \"NAME\": \"django\",\n                \"OPTIONS\": {\n                    \"loaders\": [\n                        (\"django.template.loaders.string.Loader\",)\n                    ]\n                },\n            }\n        )\n        template = engine.from_string(\"Hello {{ name }}\")\n        self.assertEqual(template.render({\"name\": \"World\"}), \"Hello World\")\n"], "sample_1163": ["def test_issue_16010():\n    from sympy import Symbol, exp, pi, Abs, re, im\n    x = Symbol('x')\n    y = Symbol('y')\n    assert re(Abs(exp(I*x) + exp(I*y))) == Abs(exp(I*x) + exp(I*y))\n    assert im(Abs(exp(I*x) + exp(I*y))) == Abs(exp(I*x) + exp(I*y))\n    assert Abs(exp(I*x) + exp(I*y)) == Abs(exp(I*x) + exp(I*y))\n    assert re(Abs(exp(I*x) + exp(I*y))) == re(Abs(exp(I*x) + exp(I*y)))\n    assert im(Abs(exp(I*x) + exp(I*y))) == im(Abs(exp(I*x) + exp(I*y)))\n    assert Abs(exp(I*x) + exp(I*y)) == Abs(exp(I*x) + exp(I*y))\n    assert Abs(exp(I*x) + exp(I*y)) == Abs(exp(I*x) + exp(I*y))\n    assert Abs(exp(I*x) + exp(I*y)) == Abs(exp(I*x) + exp(I*y))\n    assert Abs(exp(I*x) + exp(I*y)) == Abs(exp(I*x) + exp(I*y))\n    assert Abs(exp(I*x) + exp(I*y)) == Abs(exp(I*x) + exp(I*y))\n    assert Abs(exp(I*x) + exp(I*y)) == Abs(exp(I*x) + exp(I*y))\n    assert Abs(exp(I*x) + exp(I*y)) == Abs(exp(I*x) + exp(I*y))\n    assert Abs(exp(I*x) + exp(I*y)) == Abs(exp(I*x) + exp(I*y))\n    assert Abs(exp(I*x) +"], "sample_704": ["def test_node_repr_failure_with_fulltrace(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"x\", [1, 2, 3])\n            assert x == 4\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--fulltrace\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*1 failed in *\",\n            \"*AssertionError: 1 == 4*\",\n            \"*Traceback (most recent call last):*\",\n            \"*  File 'test_node_repr_failure_with_fulltrace.py', line 3, in test_this*\",\n            \"*    assert x == 4*\",\n        ]\n    )\n"], "sample_425": ["    def test_serialize_custom_field(self):\n        class MyCustomField(models.Field):\n                super().__init__(*args, **kwargs)\n\n                return \"MyCustomFieldType\"\n\n                return \"MyCustomFieldType\"\n\n                return forms.CharField(**kwargs)\n\n        class MyModel(models.Model):\n            my_field = MyCustomField()\n\n        with self.subTest(serialize=True):\n            self.assertSerializedFieldEqual(MyModel.my_field)\n        with self.subTest(deconstruct=True):\n            field, path, args, kwargs = deconstruct_field(MyModel.my_field)\n            self.assertEqual(field, \"MyCustomField\")\n            self.assertEqual(path, \"migrations.test_writer.MyCustomField\")\n            self.assertEqual(args, ())\n            self.assertEqual(kwargs, {})\n\n\n\n"], "sample_176": ["    def test_remove_model_with_field_added_to_base_model(self):\n        \"\"\"\n        Removing a model that has a field that's later added to its base\n        model should not cause issues.\n        \"\"\"\n        before = [\n            ModelState('app', 'readable', [\n                ('id', models.AutoField(primary_key=True)),\n            ]),\n            ModelState('app', 'book', [\n                ('id', models.AutoField(primary_key=True)),\n                ('title', models.CharField(max_length=200)),\n            ], bases=('app.readable',)),\n        ]\n        after = [\n            ModelState('app', 'readable', [\n                ('id', models.AutoField(primary_key=True)),\n                ('title', models.CharField(max_length=200)),\n            ]),\n        ]\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'app', 1)\n        self.assertOperationTypes(changes, 'app', 0, ['DeleteModel', 'AddField'])\n        self.assertOperationAttributes(changes, 'app', 0, 0, name='book')\n        self.assertOperationAttributes(changes, 'app', 0, 1, name='title', model_name='readable')\n"], "sample_990": ["def test_atanh_expansion():\n    x = Symbol('x')\n    assert atanh(x).expand(trig=True) == (1/2)*log((1 + x)/(1 - x))\n    assert atanh(2*x).expand(trig=True).expand() == \\\n        log(1 + 2*x) - log(1 - 2*x)\n    assert atanh(3*x).expand(trig=True).expand() == \\\n        log(1 + 3*x) - log(1 - 3*x)\n"], "sample_745": ["def test_sparse_matrix_input():\n    X_sparse = sparse.csr_matrix(np.random.randn(10, 10))\n    transformer = FunctionTransformer(accept_sparse=True)\n    assert_allclose_dense_sparse(transformer.fit_transform(X_sparse),\n                                 transformer.inverse_transform(\n                                     transformer.fit_transform(X_sparse)))\n"], "sample_496": ["    def test_suggestions_with_options(self):\n        args = ['runserver', '--insecure', '--settings=test_project.settings']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"Unknown command: 'runserver'. Did you mean runserver?\")\n"], "sample_1086": ["def test_issue_16310():\n    from sympy.physics.quantum import TensorProduct\n    a, b = symbols('a b')\n    assert str(TensorProduct(a, b)) == 'a \u2297 b'\n"], "sample_293": ["    def test_lookahead_and_lookbehind_together(self):\n        test_urls = [\n            ('/lookahead-/lookbehind+/a-city/', {'city': 'a-city'}),\n            ('/lookbehind-/lookahead+/a-city/', {'city': 'a-city'}),\n        ]\n        for test_url, kwargs in test_urls:\n            with self.subTest(url=test_url):\n                self.assertEqual(resolve(test_url).kwargs, kwargs)\n\n"], "sample_668": ["def test_external_plugins_integrated_ini(testdir, plugin):\n    testdir.syspathinsert()\n    testdir.makepyfile(**{plugin: \"\"})\n\n    testdir.makeini(\n        f\"\"\"\n        [pytest]\n        {plugin}\n        \"\"\"\n    )\n\n    with pytest.warns(pytest.PytestConfigWarning):\n        result = testdir.runpytest()\n"], "sample_1080": ["def test_refine_issue_13088():\n    from sympy.functions import sin, cos\n    x = Symbol('x', real=True)\n    assert refine(sin(x) * cos(x), Q.even(x)) == 0\n"], "sample_801": ["def test_repr_with_custom_indent():\n    pp = _EstimatorPrettyPrinter(indent=4)\n    lr = LogisticRegression()\n    expected = \"\"\"\n    LogisticRegression(C=1.0, class_weight=None, dual=False,\n                       fit_intercept=True, intercept_scaling=1,\n                       l1_ratio=None, max_iter=100,\n                       multi_class='warn', n_jobs=None, penalty='l2',\n                       random_state=None, solver='warn', tol=0.0001,\n                       verbose=0, warm_start=False)\"\"\"\n\n    expected = expected[1:]  # remove first \\n\n    assert pp.pformat(lr) == expected\n"], "sample_155": ["    def test_file_with_no_content_length(self):\n        with tempfile.NamedTemporaryFile() as tmp:\n            response = FileResponse(tmp)\n            self.assertFalse(response.has_header('Content-Length'))\n            response.close()\n"], "sample_985": ["compilation error"], "sample_178": ["    def test_all_valid_with_non_form_errors(self):\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '0',\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-MAX_NUM_FORMS': '1',  # should trigger a non-form error\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': '0',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '1',\n        }\n        ChoiceFormSet = formset_factory(Choice, validate_max=True)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [\n            {'__all__': ['Please submit 1 or fewer forms.']},\n            {'__all__': ['Please submit 1 or fewer forms.']}\n        ]\n        self.assertEqual(formset1._errors, expected_errors)\n        self.assertEqual(formset2._errors, expected_errors)\n"], "sample_1091": ["def test_issue_19018():\n    x, y = symbols('x y')\n    assert simplify(Eq(x**2 + y**2, 1)) == Eq(x**2 + y**2, 1)\n    assert simplify(Eq(x**2 + y**2, 1, evaluate=False)) == Eq(x**2 + y**2, 1, evaluate=False)\n"], "sample_856": ["def test_time_series_cv_with_groups():\n    X = np.arange(10).reshape((10, 1))\n    groups = np.array([0, 0, 1, 1, 1, 2, 2, 2, 2, 3])\n\n    tscv = TimeSeriesSplit(n_splits=3)\n    splits = tscv.split(X, groups=groups)\n    for train, test in splits:\n        assert all(groups[i] == groups[j] for i, j in zip(train, test))\n"], "sample_811": ["def test_check_sparse_matrices_with_different_shapes():\n    # Ensures that checks return valid sparse matrices even when shapes differ.\n    rng = np.random.RandomState(0)\n    XA = rng.random_sample((5, 4)).astype(np.float32)\n    XA_sparse = csr_matrix(XA)\n    XB = rng.random_sample((3, 4)).astype(np.float32)\n    XB_sparse = csr_matrix(XB)\n    XA_checked, XB_checked = check_pairwise_arrays(XA_sparse, XB_sparse)\n    assert issparse(XA_checked)\n    assert issparse(XB_checked)\n    assert_equal(XA_checked.shape, (5, 3))\n    assert_equal(XB_checked.shape, (3, 5))\n\n\n\n"], "sample_850": ["def test_nystroem_sparse_data():\n    # Test Nystroem with sparse data\n    n_samples = 1000\n    n_features = 100\n    X = csr_matrix(np.random.rand(n_samples, n_features))\n\n    nystroem = Nystroem(n_components=100, random_state=42)\n    X_transformed = nystroem.fit_transform(X)\n    assert X_transformed.shape == (n_samples, 100)\n    assert isinstance(X_transformed, np.ndarray)\n\n    # Test that the transformation works with sparse input\n    nystroem = Nystroem(n_components=100, random_state=42)\n    X_transformed = nystroem.fit_transform(X)\n    assert_array_equal(nystroem.components_, X.toarray())\n"], "sample_83": ["    def test_tag_compile_function(self):\n            return Node()\n        self.library.tag('name', compile_function)\n        self.assertEqual(self.library.tags['name'], compile_function)\n"], "sample_1147": ["def test_latex_printing_of_matrices_with_symbols():\n    from sympy import MatrixSymbol, symbols\n\n    x, y, z = symbols('x y z')\n    A = MatrixSymbol(\"A\", 2, 2)\n    B = MatrixSymbol(\"B\", 2, 2)\n\n    assert latex(A + B) == r\"A + B\"\n    assert latex(A - B) == r\"A - B\"\n    assert latex(A * B) == r\"A B\"\n    assert latex(A**2) == r\"A^{2}\"\n    assert latex(A * x) == r\"x A\"\n    assert latex(x * A) == r\"x A\"\n    assert latex(A * (B + x)) == r\"A \\left(B + x\\right)\"\n    assert latex(A * (B + x) * z) == r\"A \\left(B + x\\right) z\"\n    assert latex(A * (B + x) * z**2) == r\"A \\left(B + x\\right) z^{2}\"\n\n\n\n"], "sample_199": ["    def test_annotation_with_subquery_and_filter(self):\n        subquery = Book.objects.filter(rating__gt=4).values('publisher').annotate(count=Count('pk')).values('count')\n        qs = Publisher.objects.annotate(\n            has_high_rated_books=Exists(subquery.filter(publisher=OuterRef('pk'))),\n        ).filter(has_high_rated_books=True).values('name')\n        self.assertCountEqual(qs, [\n            {'name': 'Morgan Kaufmann'},\n            {'name': 'Sams'},\n        ])\n"], "sample_940": ["        def my_method(self):\n            pass\n"], "sample_876": ["def test_mlp_validation_fraction_with_partial_fit(MLPEstimator):\n    \"\"\"Check that validation_fraction works correctly with partial_fit.\"\"\"\n    mlp = MLPEstimator(\n        validation_fraction=0.2, random_state=0, early_stopping=True\n    )\n    X = X_digits[:100]\n    y = y_digits[:100]\n\n    # Fit on the first 80 samples\n    mlp.partial_fit(X[:80], y[:80])\n\n    # Validate that the validation set is correctly split\n    assert len(mlp.validation_scores_) > 0\n\n    # Fit on the remaining 20 samples\n    mlp.partial_fit(X[80:], y[80:])\n\n    # Validate that the validation scores are updated\n    assert len(mlp.validation_scores_) > 1\n"], "sample_736": ["def test_class_weight_with_sparse_data():\n    # Test class_weight with sparse data\n    rng = np.random.RandomState(42)\n    n_samples = 50\n    n_features = 20\n    X, y = make_classification(n_samples=n_samples, n_features=n_features,\n                               random_state=0)\n    X_sparse = sparse.csr_matrix(X)\n    class_weight = {0: 1, 1: 10}\n\n    lr_sparse = LogisticRegression(class_weight=class_weight)\n    lr_sparse.fit(X_sparse, y)\n\n    lr_dense = LogisticRegression(class_weight=class_weight)\n    lr_dense.fit(X, y)\n\n    assert_array_almost_equal(lr_sparse.coef_, lr_dense.coef_)\n"], "sample_836": ["compilation error"], "sample_859": ["def test_multi_task_lasso_cv_sparse_input():\n    n_samples, n_features = 10, 3\n    rng = np.random.RandomState(42)\n    X = rng.binomial(1, .5, size=(n_samples, n_features))\n    X = sparse.csr_matrix(X)\n    y = X[:, [0, 0]].copy()\n    est = MultiTaskLassoCV(n_alphas=5, fit_intercept=True).fit(X, y)\n    assert_array_almost_equal(est.coef_, [[1, 0, 0]] * 2, decimal=3)\n"], "sample_752": ["def test_iforest_contamination_auto():\n    \"\"\"Test that contamination='auto' works as expected.\"\"\"\n    rng = check_random_state(0)\n    X = rng.randn(100, 2)\n    y = np.zeros(100)\n    y[20:] = 1\n\n    clf_auto = IsolationForest(contamination='auto').fit(X, y)\n    clf_explicit = IsolationForest(contamination=0.2).fit(X, y)\n\n    # Check that the number of outliers predicted is roughly the same\n    assert_array_almost_equal(clf_auto.predict(X), clf_explicit.predict(X))\n\n    # Check that the decision function scores are similar\n    assert_array_almost_equal(clf_auto.decision_function(X),\n                             clf_explicit.decision_function(X))\n"], "sample_672": ["def test_circular_references():\n    class A:\n            self.b = b\n\n    class B:\n            self.a = a\n\n    a = A(B(a))\n    assert saferepr(a) == \"<[unpresentable exception ({!s}) raised in repr()] A object at 0x{:x}>\".format(\n        \"RecursionError\", id(a)\n    )\n"], "sample_596": ["    def test_concat_preserve_coordinate_order_with_different_sizes(self):\n        x = np.arange(0, 5)\n        y = np.arange(0, 10)\n        time = np.arange(0, 4)\n        data = np.zeros((4, 10, 5), dtype=bool)\n\n        ds1 = Dataset(\n            {\"data\": ([\"time\", \"y\", \"x\"], data[0:2])},\n            coords={\"time\": time[0:2], \"y\": y, \"x\": x},\n        )\n        ds2 = Dataset(\n            {\"data\": ([\"time\", \"y\", \"x\"], data[2:3])},\n            coords={\"time\": time[2:3], \"y\": y, \"x\": x},\n        )\n\n        expected = Dataset(\n            {\"data\": ([\"time\", \"y\", \"x\"], data[:3])},\n            coords={\"time\": time[:3], \"y\": y, \"x\": x},\n        )\n\n        actual = concat([ds1, ds2], dim=\"time\")\n\n        # check dimension order\n        for act, exp in zip(actual.dims, expected.dims):\n            assert act == exp\n            assert actual.dims[act] == expected.dims[exp]\n\n        # check coordinate order\n        for act, exp in zip(actual.coords, expected.coords):\n            assert act == exp\n            assert_identical(actual.coords[act], expected.coords[exp])\n"], "sample_923": ["compilation error"], "sample_569": ["    def test_regplot_yerr(self):\n\n        f, ax = plt.subplots()\n        yerr = np.random.randn(90)\n        lm.regplot(x=\"x\", y=\"y\", data=self.df, yerr=yerr)\n        assert len(ax.collections) == 2\n        assert len(ax.lines) == 1\n"], "sample_413": ["    def test_template_tags_with_different_library_name_and_module_name(self):\n        self.assertEqual(check_for_template_tags_with_the_same_name(None), [])\n"], "sample_724": ["def test_imputation_sparse_csr_axis_1():\n    # Test imputation with sparse CSR matrix, axis=1\n    X = sparse.csr_matrix([\n        [0, 1, 2],\n        [np.nan, 3, 4],\n        [5, np.nan, 6],\n    ])\n\n    X_true = sparse.csr_matrix([\n        [0, 1, 2],\n        [2, 3, 4],\n        [5, 3, 6],\n    ])\n\n    for strategy in ['mean', 'median', 'most_frequent']:\n        imputer = Imputer(missing_values=0, strategy=strategy, axis=1)\n        imputer.fit(X)\n        X_imputed = imputer.transform(X)\n        assert_array_almost_equal(X_imputed.toarray(), X_true.toarray())\n\n\n\n"], "sample_1123": ["def test_issue_17651():\n    with warns_deprecated_sympy():\n        c = ConditionSet(x, Eq(x, 1), S.Reals)\n        assert c == ConditionSet(x, x == 1, S.Reals)\n"], "sample_9": ["def test_read_html_unicode_escape():\n    \"\"\"\n    Test reading an HTML table with unicode values escaped\n    \"\"\"\n    table_in = ['<table>',\n                '<tr><td>&#x0394;</td></tr>',\n                '<tr><td>&#x0394;</td></tr>',\n                '</table>']\n    dat = Table.read(table_in, format='ascii.html')\n    assert np.all(dat['col1'] == ['\u0394', '\u0394'])\n"], "sample_348": ["    def test_actions_with_custom_permissions_has_method(self):\n        @admin.action(permissions=['custom'])\n            pass\n\n        class BandAdmin(ModelAdmin):\n            actions = (custom_permission_action,)\n\n        class BandAdminWithHasMethod(ModelAdmin):\n                return request.user.is_staff\n\n            actions = (custom_permission_action,)\n\n        self.assertIsValid(BandAdminWithHasMethod, Band)\n"], "sample_283": ["    def test_empty_settings(self):\n        self.assertEqual(\n            self.settings_to_cmd_args_env({}),\n            (['psql'], {}),\n        )\n"], "sample_942": ["def test_py_object_with_no_docstring(app):\n    text = (\".. py:class:: MyClass\\n\"\n            \"   :param str name: blah blah\\n\")\n    restructuredtext.parse(app, text)\n    index = PythonModuleIndex(app.env.get_domain('py'))\n    assert index.generate() == (\n        [('m', [IndexEntry('MyClass', 0, 'index', 'class-MyClass', '', '', '')])],\n        False\n    )\n"], "sample_198": ["    def test_output_field_in_deconstruct(self):\n        expr = ExpressionWrapper(F('field'), output_field=CharField())\n        path, args, kwargs = expr.deconstruct()\n        self.assertEqual(kwargs['output_field'].deconstruct(), CharField().deconstruct())\n"], "sample_906": ["def test_domain_cpp_parse_template_param_with_id(app):\n    text = (\".. cpp:template:: template<typename T> void f(T t)\\n\"\n            \"   :id: my_template\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.template, addnodes.index, addnodes.index, desc))\n    assert_node(doctree[0], addnodes.template, name='my_template')\n    assert_node(doctree[1], addnodes.index, entries=[('single', 'f (C++ template)', '_CPPv4I0E14_templateParamvv', '', None)])\n\n\n\n"], "sample_316": ["    def test_spooled_temp_file_closed_after_write(self):\n        with tempfile.SpooledTemporaryFile() as temp:\n            temp.write(b\"foo bar baz quux\\n\")\n            django_file = File(temp, name=\"something.txt\")\n            self.assertEqual(django_file.size, 17)\n            temp.close()\n            with self.assertRaises(ValueError):\n                django_file.read()\n"], "sample_1026": ["def test_issue_16640():\n    x = symbols('x')\n    f = lambdify(x, sin(x) / x)\n    assert f(1) == sin(1) / 1\n    assert f(0) == 1\n"], "sample_873": ["def test_get_feature_names_out():\n    sel = StepSelector()\n    sel.fit(X, y)\n    assert_array_equal(feature_names_t, sel.get_feature_names_out(input_features=feature_names))\n    assert_array_equal(feature_names_t, sel.get_feature_names_out())\n"], "sample_721": ["def test_check_array_sparse_format():\n    X_csr = sp.csr_matrix([[1, 2], [3, 4]])\n    X_csc = sp.csc_matrix([[1, 2], [3, 4]])\n    X_coo = sp.coo_matrix([[1, 2], [3, 4]])\n    X_dok = sp.dok_matrix([[1, 2], [3, 4]])\n    X_lil = sp.lil_matrix([[1, 2], [3, 4]])\n    X_bsr = sp.bsr_matrix([[1, 2], [3, 4]])\n\n    formats = ['csr', 'csc', 'coo', 'dok', 'lil', 'bsr']\n    for format in formats:\n        X_checked = check_array(getattr(sp, format)([[1, 2], [3, 4]]))\n        assert_equal(X_checked.format, format)\n\n    # Test that check_array doesn't change the format if it's already dense\n    X_dense = np.array([[1, 2], [3, 4]])\n    X_checked = check_array(X_dense)\n    assert_equal(X_checked.format, 'dense')\n"], "sample_1087": ["def test_f_polys():\n    for i in range(len(f_polys())):\n        poly = f_polys()[i]\n        assert Poly(poly, x, y, z) == Poly(poly)\n        assert Poly(poly, x, y) == Poly(poly, x, y, z).subs(z, 0)\n        assert Poly(poly, x) == Poly(poly, x, y, z).subs(y, 0).subs(z, 0)\n"], "sample_65": ["    def test_i18n_with_plural_forms(self):\n        with self.settings(LANGUAGE_CODE='fr'), override('fr'):\n            response = self.client.get('/jsi18n_plural_forms/')\n            self.assertContains(response, '1 article')\n            self.assertContains(response, '2 articles')\n            self.assertContains(response, '3 articles')\n            self.assertContains(response, '4 articles')\n"], "sample_416": ["    def test_empty_settings(self):\n        self.assertEqual(\n            self.settings_to_cmd_args_env({}),\n            ([\"psql\", \"postgres\"], None),\n        )\n"], "sample_311": ["    def test_non_admin_url_404_if_authenticated(self):\n        unknown_url = '/unknown/'\n        superuser = User.objects.create_superuser(\n            username='super',\n            password='secret',\n            email='super@example.com',\n        )\n        self.client.force_login(superuser)\n        response = self.client.get(unknown_url)\n        self.assertEqual(response.status_code, 404)\n"], "sample_169": ["    def test_key_transform_with_nested_lookup(self):\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(\n                value__d__0__contains=KeyTransform('f', KeyTransform('1', 'value'))\n            ),\n            [self.objs[4]],\n        )\n"], "sample_1047": ["def test_issue_16313_2():\n    x = Symbol('x', real=False)\n    k = Symbol('k', real=True)\n    l = Symbol('l', real=True, zero=False)\n    assert (x**2).is_real is None\n    assert (k*x**2).is_real is None\n    assert (l*x**2).is_real is None\n    assert (l*x**2*x).is_real is None\n    assert (x**2).is_positive is None\n    assert (k*x**2).is_positive is None\n    assert (l*x**2).is_positive is None\n"], "sample_618": ["def test_cross_errors(use_dask: bool) -> None:\n    a = xr.DataArray([1, 2, 3], dims=\"x\")\n    b = xr.DataArray([4, 5, 6], dims=\"y\")\n\n    if use_dask:\n        if not has_dask:\n            pytest.skip(\"requires dask\")\n        a = a.chunk()\n        b = b.chunk()\n\n    with pytest.raises(ValueError, match=r\"Dimensions must be the same\"):\n        xr.cross(a, b, dim=\"z\")\n\n    with pytest.raises(ValueError, match=r\"Dimensions must be the same\"):\n        xr.cross(a, b, dim=\"x\", axis=2)\n\n    with pytest.raises(ValueError, match=r\"axis must be in range\"):\n        xr.cross(a, b, dim=\"x\", axis=3)\n\n    with pytest.raises(ValueError, match=r\"Input arrays must have at least 2 dimensions\"):\n        xr.cross(a, b.isel(y=0), dim=\"x\")\n\n\n\n"], "sample_723": ["def test_imputation_sparse_csr_with_missing_values_not_zero():\n    # Test imputation with sparse CSR matrix and missing_values != 0\n    rng = np.random.RandomState(0)\n    dim = 10\n    dec = 10\n    shape = (dim * dim, dim + dec)\n\n    zeros = np.zeros(shape[0])\n    values = np.arange(1, shape[0] + 1)\n    values[4::2] = - values[4::2]\n\n    X = sparse.csr_matrix((values, (np.arange(shape[0]),\n                                    np.arange(shape[1]))),\n                          shape=shape)\n    X[4::2, :] = 0\n\n    X_true = sparse.csr_matrix((values, (np.arange(shape[0]),\n                                        np.arange(shape[1]))),\n                              shape=shape)\n    X_true[4::2, :] = X[4::2, :]\n\n    for strategy in [\"mean\", \"median\", \"most_frequent\"]:\n        imputer = SimpleImputer(missing_values=10, strategy=strategy)\n        imputer.fit(X)\n        X_imputed = imputer.transform(X)\n\n        assert_array_almost_equal(X_imputed.toarray(),\n                                  X_true.toarray(),\n                                  err_msg=\"Fail to impute the data \"\n                                  \"(strategy = %s)\" % (strategy))\n\n\n\n"], "sample_421": ["    def test_when_with_lookup_and_value(self):\n        with self.assertRaises(TypeError):\n            Case(\n                When(Q(pk=1), then=Value(1)),\n                When(Q(pk=2), then=2),\n            )\n"], "sample_151": ["    def test_mti_inheritance_model_removal_with_fk(self):\n        Animal = ModelState('app', 'Animal', [\n            (\"id\", models.AutoField(primary_key=True)),\n        ])\n        Dog = ModelState('app', 'Dog', [\n            (\"animal_id\", models.ForeignKey(\"app.Animal\", models.CASCADE)),\n        ], bases=('app.Animal',))\n        changes = self.get_changes([Animal, Dog], [Animal])\n        self.assertNumberMigrations(changes, 'app', 1)\n        self.assertOperationTypes(changes, 'app', 0, ['DeleteModel', 'RemoveField'])\n        self.assertOperationAttributes(changes, 'app', 0, 0, name='Dog')\n        self.assertOperationAttributes(changes, 'app', 0, 1, name='Dog', model_name='Dog', field_name='animal_id')\n"], "sample_259": ["    def test_prefetch_related_with_nested_lookups(self):\n        book1 = Book.objects.get(id=self.book1.id)\n        with self.assertNumQueries(2):\n            prefetch_related_objects(\n                [book1],\n                Prefetch(\n                    'authors',\n                    queryset=Author.objects.filter(name__startswith='A'),\n                    to_attr='the_authors',\n                    prefetch_related=[\n                        Prefetch('first_book', to_attr='first_book')\n                    ]\n                )\n            )\n\n        with self.assertNumQueries(0):\n            for author in book1.the_authors:\n                self.assertEqual(author.first_book.title, 'Poems')\n\n\n\n"], "sample_407": ["    def test_related_object_cache_after_update(self):\n        p = Parent.objects.create(name=\"Parent\")\n        c = Child.objects.create(name=\"Child\", parent=p)\n        self.assertEqual(c.parent, p)\n        p.name = \"New Parent\"\n        p.save()\n        self.assertEqual(c.parent, p)\n"], "sample_180": ["    def test_unique_constraint_with_non_unique_fields(self):\n        class Model(models.Model):\n            field1 = models.CharField(max_length=100)\n            field2 = models.CharField(max_length=100)\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(fields=['field1', 'field2'], name='name'),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to fields 'field1' and 'field2' which are \"\n                \"not unique together. Consider using a different set of fields \"\n                \"or a different constraint type.\",\n                obj=Model,\n                id='models.E017',\n            ),\n        ])\n"], "sample_466": ["    def test_serialize_custom_field(self):\n        class MyCustomField(models.Field):\n                super().__init__(*args, **kwargs)\n\n                return \"MyCustomFieldType\"\n\n                return \"MyCustomFieldType\"\n\n                return super().formfield(**kwargs)\n\n        class MyModel(models.Model):\n            my_field = MyCustomField()\n\n        with self.subTest(serialize=True):\n            self.assertSerializedEqual(MyModel.my_field)\n            self.assertSerializedResultEqual(\n                MyModel.my_field,\n                (\n                    \"migrations.test_writer.MyCustomField()\",\n                    {\"import migrations.test_writer\"},\n                ),\n            )\n\n        with self.subTest(deserialize=True):\n            field = self.deserialize_round_trip(MyModel.my_field)\n            self.assertIsInstance(field, MyCustomField)\n\n\n\n"], "sample_855": ["def test_dummy_regressor_with_empty_data():\n    X = []\n    y = []\n    reg = DummyRegressor()\n    with pytest.raises(ValueError):\n        reg.fit(X, y)\n"], "sample_273": ["    def test_auto_created_pk_across_apps(self, apps):\n        class BasicModel(models.Model):\n            class Meta:\n                app_label = 'basic'\n\n        class CheckFrameworkModel(models.Model):\n            class Meta:\n                app_label = 'check_framework'\n\n        self.assertEqual(checks.run_checks(app_configs=apps.get_app_configs()), [\n            Warning(self.msg, hint=self.hint, obj=BasicModel, id='models.W042'),\n        ])\n\n"], "sample_489": ["    def test_update_conflicts_no_unique_fields_no_update_fields(self):\n        with self.assertRaises(ValueError):\n            UpsertConflict.objects.bulk_create(\n                [\n                    UpsertConflict(number=1, rank=1, name=\"John\"),\n                    UpsertConflict(number=2, rank=2, name=\"Mary\"),\n                    UpsertConflict(number=3, rank=3, name=\"Hannah\"),\n                ],\n                update_conflicts=True,\n            )\n"], "sample_1034": ["def test_grover_multiple_targets():\n    nqubits = 3\n    basis_states = superposition_basis(nqubits)\n    oracle_function = lambda qubits: qubits == IntQubit(1, nqubits=nqubits) or qubits == IntQubit(5, nqubits=nqubits)\n    v = OracleGate(nqubits, oracle_function)\n    expected = (-13*basis_states)/64 + 264*IntQubit(1, nqubits=nqubits)/256 + 264*IntQubit(5, nqubits=nqubits)/256\n    assert apply_grover(oracle_function, nqubits) == qapply(expected)\n"], "sample_677": ["def test_nested_parentheses(expr: str, expected: bool) -> None:\n    matcher = {\"true\": True, \"false\": False}.__getitem__\n    assert evaluate(expr, matcher) is expected\n"], "sample_774": ["def test_one_hot_encoder_categorical_feature_indices():\n    enc = OneHotEncoder(handle_unknown='ignore')\n    X = np.array([['a', 1, 55], ['b', 2, 55], ['a', 3, 55]])\n    enc.fit(X)\n    assert_array_equal(enc.get_feature_names_out(),\n                       ['x0_a', 'x0_b', 'x1_1', 'x1_2', 'x1_3', 'x2_55'])\n    assert_array_equal(enc.categorical_feature_indices_, [0, 1, 2])\n    assert_array_equal(enc.categorical_feature_indices_,\n                       [0, 1, 2])\n\n\n\n"], "sample_1135": ["def test_issue_18507_continued():\n    assert Mul(zoo, zoo, evaluate=False) is nan\n    assert Mul(zoo, zoo, evaluate=True) is nan\n    assert Mul(zoo, zoo, evaluate=False, method='expand') is nan\n    assert Mul(zoo, zoo, evaluate=True, method='expand') is nan\n"], "sample_537": ["def test_psd_window_flattop_oversampling():\n    # flattop window with oversampling\n    a = [0.21557895, 0.41663158, 0.277263158, 0.083578947, 0.006947368]\n    fac = np.linspace(-np.pi, np.pi, 1024)\n    win = np.zeros(1024)\n    for k in range(len(a)):\n        win += a[k] * np.cos(k * fac)\n\n    u = np.array([0, 1, 2, 3, 1, 2, 1])\n    dt = 1.0\n    Su = np.abs(np.fft.fft(u) * dt)**2 / (dt * u.size)\n    P, f = mlab.psd(u, NFFT=u.size*2, Fs=1/dt, window=win,\n                    detrend=mlab.detrend_none, noverlap=0, pad_to=None,\n                    scale_by_freq=None,\n                    sides='onesided')\n    Su_1side = np.append([Su[0]], Su[1:4] + Su[4:][::-1])\n    assert_allclose(P, Su_1side, atol=1e-06)\n"], "sample_37": ["def test_wcs_from_string():\n    \"\"\"\n    Test reading a WCS from a string header.\n    \"\"\"\n    header_str = \"\"\""], "sample_295": ["    def test_output_field_with_expression(self):\n        expr = ExpressionWrapper(\n            F('cost') + F('tax'),\n            output_field=DecimalField()\n        )\n        self.assertIsInstance(expr.output_field, DecimalField)\n"], "sample_661": ["compilation error"], "sample_878": ["def test_column_transformer_with_transformers_with_fit_transform(remainder):\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n    class MyTransformer(BaseEstimator, TransformerMixin):\n            return self\n\n            return X * 2\n\n    ct = ColumnTransformer(\n        [\n            (\"my_transformer\", MyTransformer(), [\"a\"]),\n            (\"passthrough\", \"passthrough\", [\"b\"]),\n        ],\n        remainder=remainder,\n    )\n    X_trans = ct.fit_transform(df)\n    assert_array_equal(X_trans, np.array([[2, 4], [4, 5], [6, 6]]))\n\n    if remainder == \"passthrough\":\n        assert_array_equal(X_trans[:, 1], df[\"b\"])\n    else:\n        assert X_trans.shape[1] == 1\n"], "sample_398": ["    def test_user_change_password_with_custom_user_model(self):\n        u = UUIDUser.objects.create_superuser(\n            username=\"uuid\", email=\"foo@bar.com\", password=\"test\"\n        )\n        self.assertTrue(self.client.login(username=\"uuid\", password=\"test\"))\n\n        user_change_url = reverse(\n            \"custom_user_admin:auth_tests_uuiduser_change\", args=(u.pk,)\n        )\n        response = self.client.get(user_change_url)\n        self.assertEqual(response.status_code, 200)\n\n        password_change_url = reverse(\n            \"custom_user_admin:auth_tests_uuiduser_password_change\", args=(u.pk,)\n        )\n        response = self.client.get(password_change_url)\n        self.assertEqual(response.status_code, 200)\n\n        response = self.client.post(\n            password_change_url,\n            {\n                \"password1\": \"password1\",\n                \"password2\": \"password1\",\n            },\n        )\n        self.assertRedirects(response, user_change_url)\n        row = LogEntry.objects.latest(\"id\")\n        self.assertEqual(row.user_id, 1)  # hardcoded in CustomUserAdmin.log_change()\n        self.assertEqual(row.object_id, str(u.pk))\n        self.assertEqual(row.get_change_message(), \"Changed password.\")\n"], "sample_730": ["compilation error"], "sample_1093": ["def test_sympy_printing():\n    from sympy import MatrixSymbol, Matrix, eye, zeros, ones, diag, simplify\n    from sympy.printing.pycode import SymPyPrinter\n\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 3, 3)\n\n    expr1 = Matrix([A, B])\n    expr2 = eye(3)\n    expr3 = zeros(2, 3)\n    expr4 = ones(3, 2)\n    expr5 = diag(C)\n    expr6 = simplify(A + B)\n\n    prntr = SymPyPrinter()\n\n    assert prntr.doprint(expr1) == 'Matrix([[A, B]])'\n    assert prntr.doprint(expr2) == 'Matrix([[1, 0, 0], [0, 1, 0], [0, 0, 1]])'\n    assert prntr.doprint(expr3) == 'Matrix([[0, 0, 0], [0, 0, 0]])'\n    assert prntr.doprint(expr4) == 'Matrix([[1, 1], [1, 1], [1, 1]])'\n    assert prntr.doprint(expr5) == 'Matrix([[C[0, 0], 0, 0], [0, C[1, 1], 0], [0, 0, C[2, 2]]])'\n    assert prntr.doprint(expr6) == 'A + B'\n"], "sample_1172": ["compilation error"], "sample_1099": ["def test_eval_partial_derivative_mixed_tensor_expr3():\n    tau, alpha = symbols(\"tau alpha\")\n\n    base_expr3 = A(i)*H(j, k) + H(i, j)*A(k) + tau**alpha*A(i)\n\n    tensor_derivative = PartialDerivative(base_expr3, H(m, n))._perform_derivative()\n    assert (tensor_derivative - (L.delta(i, -m)*L.delta(j, -n)*A(k) +\n        L.delta(i, -m)*H(j, n)*L.delta(k, -n) +\n        L.delta(i, -n)*H(j, m)*L.delta(k, -m))).expand() == 0\n\n    vector_derivative = PartialDerivative(base_expr3, A(k))._perform_derivative()\n    assert (vector_derivative - (H(i, j)*L.delta(j, -k) +\n        L.delta(i, -k)*H(j, k) + tau**alpha*L.delta(i, -k))).expand() == 0\n\n    scalar_derivative = PartialDerivative(base_expr3, tau)._perform_derivative()\n    assert scalar_derivative - alpha*tau**(alpha-1)*A(i) == 0\n"], "sample_513": ["def test_legend_title_fontsize_inheritance():\n    fig, axes = plt.subplots(2, 2)\n    axes[0, 0].plot(range(10), label='Aardvark')\n    axes[0, 0].legend(title='My Legend', title_fontsize=16)\n    axes[0, 1].plot(range(10), label='B')\n    axes[0, 1].legend(title='Another Legend', title_fontsize=12)\n    axes[1, 0].plot(range(10), label='C')\n    axes[1, 0].legend(title='Third Legend')\n    axes[1, 1].plot(range(10), label='D')\n    axes[1, 1].legend(title='Fourth Legend', title_fontsize=None)\n\n    # Check that title_fontsize is inherited from rcParams if not set\n    assert axes[0, 0].legend().get_title().get_fontsize() == 16\n    assert axes[0, 1].legend().get_title().get_fontsize() == 12\n    assert axes[1, 0].legend().get_title().get_fontsize() == mpl.rcParams['legend.title_fontsize']\n    assert axes[1, 1].legend().get_title().get_fontsize() == mpl.rcParams['legend.title_fontsize']\n\n\n\n"], "sample_1065": ["def test_subfactorial_rewrite():\n    x = Symbol('x')\n    assert subfactorial(x).rewrite(uppergamma) == uppergamma(x + 1, -1)/S.Exp1\n    assert subfactorial(x).rewrite(factorial) == factorial(x)/factorial(x)\n    assert subfactorial(x).rewrite(gamma) == gamma(x + 1)/gamma(x + 1)\n"], "sample_675": ["        def test_bad_log_with_exception(monkeypatch):\n            monkeypatch.setattr(logging, 'raiseExceptions', False)\n            try:\n                logging.warning('oops', 'first', 2)\n            except Exception as e:\n                assert str(e) == \"Exception during logging\""], "sample_719": ["def test_vectorizer_custom_analyzer():\n        return [word.upper() for word in text.split()]\n\n    vect = CountVectorizer(analyzer=custom_analyzer)\n    X = vect.fit_transform(JUNK_FOOD_DOCS)\n    assert_array_equal(X[0].toarray(),\n                       [[1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])\n"], "sample_1195": ["compilation error"], "sample_966": ["def test_warn_missing_reference_with_explicit_target(app, status, warning):\n    app.build()\n    assert 'index.rst:6: WARNING: undefined label: no-label' in warning.getvalue()\n    assert ('index.rst:7: WARNING: Failed to create a cross reference. A title or caption not found: existing-label'\n            in warning.getvalue())\n"], "sample_248": ["    def test_no_startup_option(self):\n        with captured_stdout() as stdout:\n            call_command('shell', no_startup=True)\n        self.assertNotIn('PYTHONSTARTUP', stdout.getvalue())\n        self.assertNotIn('.pythonrc.py', stdout.getvalue())\n"], "sample_1007": ["def test_subfactorial_rewrite():\n    x = Symbol('x')\n    assert subfactorial(x).rewrite(gamma) == uppergamma(x + 1, -1)/S.Exp1\n    assert subfactorial(x).rewrite(factorial) == factorial(x)/factorial(x + 1)\n"], "sample_177": ["    def test_related_models_with_custom_manager(self):\n        class CustomManager(models.Manager):\n                return self.filter(name='related')\n\n        class A(models.Model):\n            name = models.CharField(max_length=50)\n            related = models.ForeignKey('B', models.CASCADE, related_name='related_to_a')\n\n        class B(models.Model):\n            name = models.CharField(max_length=50)\n            objects = CustomManager()\n\n        A_state = ModelState.from_model(A)\n        B_state = ModelState.from_model(B)\n        self.assertRelated(A_state, [B_state])\n        self.assertRelated(B_state, [A_state])\n"], "sample_424": ["    def test_references_field_by_related_name(self):\n        operation = FieldOperation(\n            \"Model\",\n            \"field\",\n            models.ForeignKey(\"Other\", models.CASCADE, related_name=\"related_to_model\"),\n        )\n        self.assertIs(\n            operation.references_field(\"Other\", \"related_to_model\", \"migrations\"),\n            True,\n        )\n        self.assertIs(\n            operation.references_field(\"Other\", \"whatever\", \"migrations\"), False\n        )\n\n\n\n"], "sample_807": ["def test_calibration_multiclass_imbalanced():\n    \"\"\"Test calibration for multiclass imbalanced datasets\"\"\"\n    # Test multi-class setting with imbalanced dataset\n    X, y = make_classification(n_samples=100, n_features=2,\n                               random_state=42,\n                               n_classes=3,\n                               class_sep=1.5,\n                               weights=[0.9, 0.05, 0.05])\n    X_train, y_train = X[::2], y[::2]\n    X_test, y_test = X[1::2], y[1::2]\n\n    clf = LinearSVC()\n    clf.fit(X_train, y_train)\n    for method in ['isotonic', 'sigmoid']:\n        cal_clf = CalibratedClassifierCV(clf, method=method, cv=2)\n        cal_clf.fit(X_train, y_train)\n        probas = cal_clf.predict_proba(X_test)\n        assert_array_almost_equal(np.sum(probas, axis=1), np.ones(len(X_test)))\n\n        # Check that log-loss of calibrated classifier is smaller than\n        # log-loss of naively turned OvR decision function to probabilities\n        # via softmax\n            e = np.exp(-y_pred)\n            return e / e.sum(axis=1).reshape(-1, 1)\n\n        uncalibrated_log_loss = \\\n            log_loss(y_test, softmax(clf.decision_function(X_test)))\n        calibrated_log_loss = log_loss(y_test, probas)\n        assert_greater(uncalibrated_log_loss, calibrated_log_loss)\n\n\n\n"], "sample_982": ["compilation error"], "sample_1052": ["def test_fcode_complex_mixed():\n    import sympy.utilities.codegen\n    sympy.utilities.codegen.COMPLEX_ALLOWED = True\n    x = Symbol('x')\n    y = Symbol('y', real=True)\n    z = Symbol('z', real=True)\n    result = codegen(('test', x + y + z), 'f95', 'test', header=False, empty=False)\n    source = (result[0][1])\n    expected = (\n        \"COMPLEX*16 function test(x, y, z)\\n\"\n        \"implicit none\\n\"\n        \"COMPLEX*16, intent(in) :: x\\n\"\n        \"REAL*8, intent(in) :: y\\n\"\n        \"REAL*8, intent(in) :: z\\n\"\n        \"test = x + y + z\\n\"\n        \"end function\\n\"\n        )\n    assert source == expected\n    sympy.utilities.codegen.COMPLEX_ALLOWED = False\n"], "sample_188": ["    def test_output_field_in_repr(self):\n        expr = ExpressionWrapper(F('name'), output_field=CharField(max_length=100))\n        self.assertIn(f'output_field={CharField(max_length=100)}', repr(expr))\n"], "sample_77": ["    def test_urlize_trim_url_limit(self):\n        long_url = 'https://www.example.com/this-is-a-very-long-url-that-needs-to-be-trimmed'\n        trimmed_url = urlize(long_url, trim_url_limit=20)\n        self.assertEqual(trimmed_url, 'https://www.example.com/this-is-a-very-long-url-that-needs-to-be-trimmed')\n        self.assertEqual(trimmed_url, 'https://www.example.com/this-is-a-very-long-url-that-needs-to-be-trimmed')\n"], "sample_731": ["def test_feature_names():\n    data = fetch()\n    assert(data.feature_names == ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms',\n                                   'Population', 'AveOccup', 'Latitude',\n                                   'Longitude'])\n"], "sample_834": ["def test_precomputed_transform():\n    rng = np.random.RandomState(42)\n    X = rng.randn(10, 5)\n    y = rng.randint(0, 2, size=10)\n    nca = NeighborhoodComponentsAnalysis(n_components=3, init='precomputed')\n    # Create a random precomputed transformation\n    transformation = rng.randn(5, 3)\n    nca.components_ = transformation\n    X_transformed = nca.transform(X)\n    assert_array_almost_equal(X_transformed,\n                              np.dot(X, transformation))\n"], "sample_148": ["    def test_quote_with_special_characters(self):\n        self.assertEqual(quote('something with & < > \" \\' \"'), 'something_0Awith_0A_0A_0A_0A_0A')\n"], "sample_592": ["    def test_summarize_attr_with_nested_dict(self):\n        attrs = {\"a\": {\"b\": \"value\"}, \"c\": 1}\n        expected = dedent(\n            \"\"\"\\\n            a: {'b': 'value'}\n            c: 1\"\"\"\n        ).strip()\n        actual = \"\\n\".join(formatting.summarize_attr(k, v) for k, v in attrs.items())\n        assert actual == expected\n"], "sample_1056": ["def test_complex():\n    z = complex(1, 2)\n    assert lambdarepr(z) == \"complex(1, 2)\"\n"], "sample_426": ["    def test_reversed_time_strings(self):\n        time_strings = {\n            \"minute\": npgettext_lazy(\n                \"naturaltime-past\",\n                \"%(num)d minute\",\n                \"%(num)d minutes\",\n                \"num\",\n            ),\n        }\n        with translation.override(\"cs\"):\n            for now in [self.t, self.t + self.onemicrosecond, self.t + self.oneday]:\n                with self.subTest(now):\n                    self.assertEqual(timeuntil(now, self.t, time_strings=time_strings), \"0\\xa0minut\")\n"], "sample_1197": ["def test_issue_25391():\n    from sympy.physics.units import Quantity, meter, second\n    from sympy.physics.units.systems.si import SI\n\n    q1 = Quantity('q1', dimension=meter)\n    q2 = Quantity('q2', dimension=meter)\n    SI.set_quantity_dimension(q1, meter)\n    SI.set_quantity_dimension(q2, meter)\n    q1.set_global_relative_scale_factor(1, meter)\n    q2.set_global_relative_scale_factor(2, meter)\n\n    expr = q1 + q2\n    assert expr.convert_to(meter) == 3*meter\n    assert expr.dimension == meter\n"], "sample_334": ["    def test_renderer_inheritance(self):\n        class CustomForm(Form):\n            default_renderer = CustomRenderer\n\n        class SubForm(CustomForm):\n            pass\n\n        form = SubForm()\n        self.assertIsInstance(form.renderer, CustomRenderer)\n"], "sample_959": ["def test_domain_cpp_parse_template_param_qualified_name(app, warning):\n    text = (\".. cpp:function:: template<typename T> void f(T t)\\n\"\n            \".. cpp:function:: template<typename T> void g(T::type t)\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index, desc, addnodes.index, desc))\n    assert_node(doctree[0], addnodes.index, entries=[('single', 'f (C++ function)', '_CPPv4I0E1fv', '', None)])\n    assert_node(doctree[2], addnodes.index, entries=[('single', 'g (C++ function)', '_CPPv4I0E1gv', '', None)])\n"], "sample_241": ["    def test_resolve_output_field_with_function(self):\n        expr = ExpressionWrapper(\n            Func('name', function='LENGTH'), output_field=IntegerField()\n        )\n        self.assertIsInstance(expr.output_field, IntegerField)\n"], "sample_1144": ["compilation error"], "sample_541": ["def test_MultiCursor_reset(horizOn, vertOn):\n    (ax1, ax3) = plt.figure().subplots(2, sharex=True)\n    ax2 = plt.figure().subplots()\n\n    multi = widgets.MultiCursor(\n        None, (ax1, ax2), useblit=False, horizOn=horizOn, vertOn=vertOn\n    )\n\n    # mock a motion_notify_event\n    event = mock_event(ax1, xdata=.5, ydata=.25)\n    multi.onmove(event)\n    ax1.figure.canvas.draw()\n\n    # Reset the cursor\n    multi.reset()\n\n    # Check that the lines are no longer visible\n    for l in multi.vlines:\n        assert not l.get_visible()\n    for l in multi.hlines:\n        assert not l.get_visible()\n"], "sample_1145": ["def test_refine_mul():\n    from sympy.abc import x, y, z\n    assert refine(x * y, Q.real(x) & Q.real(y)) == x * y\n    assert refine(x * y, Q.imaginary(x) & Q.imaginary(y)) == -I * x * y\n    assert refine(x * y, Q.real(x) & Q.imaginary(y)) == x * I * y\n    assert refine(x * y * z, Q.real(x) & Q.real(y) & Q.real(z)) == x * y * z\n    assert refine(x * y * z, Q.real(x) & Q.imaginary(y) & Q.imaginary(z)) == \\\n        -I * x * y * z\n    assert refine(x * y * z, Q.imaginary(x) & Q.real(y) & Q.imaginary(z)) == \\\n        I * x * y * z\n"], "sample_362": ["    def test_operation_with_no_suggested_name_and_initial_true(self):\n        class Migration(migrations.Migration):\n            initial = True\n            operations = [migrations.RunSQL('SELECT 1 FROM person;')]\n\n        migration = Migration('0001_initial', 'test_app')\n        self.assertEqual(migration.suggest_name(), 'initial')\n"], "sample_657": ["compilation error"], "sample_623": ["    def test_smaller_chunks(self, shape, pref_chunks, req_chunks):\n        \"\"\"Ensure that requested chunks smaller than preferred chunks are handled correctly.\"\"\"\n        initial = self.create_dataset(shape, pref_chunks)\n        final = xr.open_dataset(\n            initial,\n            engine=PassThroughBackendEntrypoint,\n            chunks=dict(zip(initial[self.var_name].dims, req_chunks)),\n        )\n        self.check_dataset(initial, final, explicit_chunks(req_chunks, shape))\n"], "sample_38": ["def test_invalid_wcs_header():\n    \"\"\"\n    Test that invalid WCS headers raise an error.\n    \"\"\"\n    invalid_header = \"\"\""], "sample_1200": ["def test_issue_24776():\n    from sympy.physics.units import Quantity, meter, second\n    from sympy.physics.units.systems.si import SI\n    q1 = Quantity('q1', dimension=meter/second)\n    q2 = Quantity('q2', dimension=meter/second**2)\n    SI.set_quantity_dimension(q1, meter/second)\n    SI.set_quantity_dimension(q2, meter/second**2)\n    q1.set_global_relative_scale_factor(1, meter/second)\n    q2.set_global_relative_scale_factor(1, meter/second**2)\n    expr = q1 + q2*second\n    assert SI._collect_factor_and_dimension(expr) == (1*meter/second + 1*meter/second**2*second, meter/second)\n"], "sample_993": ["def test_FreeGroupElm_cyclic_conjugates():\n    w = x*y*x*y*x\n    assert len(w.cyclic_conjugates()) == 5\n    assert w in w.cyclic_conjugates()\n    assert (x**2*y**5).cyclic_conjugates() == {(x**2*y**5), (y*x**2*y**5, (x*y*x**2*y**5), (y*x**2*y**5*x)}\n\n\n\n"], "sample_762": ["def test_pickle_version_warning_is_issued_when_estimator_has_no_version_info():\n    iris = datasets.load_iris()\n    tree = DecisionTreeClassifier().fit(iris.data, iris.target)\n    tree_pickle_noversion = pickle.dumps(tree)\n    message = pickle_error_message.format(estimator=\"DecisionTreeClassifier\",\n                                          old_version=\"pre-0.18\",\n                                          current_version=sklearn.__version__)\n    assert_warns_message(UserWarning, message, pickle.loads,\n                         tree_pickle_noversion)\n"], "sample_31": ["    def test_write_latex_with_kwargs(self, write, tmp_path, format):\n        fp = tmp_path / \"test_write_latex_kwargs.tex\"\n        kwargs = {\"format\": format, \"comment\": \"# This is a comment\"}\n        write(fp, **kwargs)\n        tbl = QTable.read(fp)\n        assert tbl.meta[\"comment\"] == \"# This is a comment\"\n"], "sample_559": ["def test_grid_with_axes_class_not_overriding_axis():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 2), axes_class=mpl.axes.Axes)\n    for ax in grid:\n        ax.plot([1, 2, 3], [4, 5, 6])\n"], "sample_593": ["def test_summarize_attrs_empty(dataset):\n    formatted = fh.summarize_attrs({})\n    assert formatted == \"\"\n"], "sample_860": ["def test_check_array_sparse_format():\n    X = sp.csr_matrix([[1, 2], [3, 4]])\n    assert check_array(X, accept_sparse='csr') is X\n    assert check_array(X, accept_sparse=['csr']) is X\n    assert check_array(X, accept_sparse=True) is X\n\n    with pytest.raises(ValueError, match=\"Sparse matrix format 'invalid' \"\n                       \"not supported\"):\n        check_array(X, accept_sparse='invalid')\n\n    with pytest.raises(ValueError, match=\"Sparse matrix format 'invalid' \"\n                       \"not supported\"):\n        check_array(X, accept_sparse=['invalid'])\n\n\n\n"], "sample_201": ["    def test_not_finished_sentinel(self):\n        storage = self.get_storage()\n        response = self.get_response()\n\n        # Store a few messages, then add the sentinel value.\n        storage.add(constants.INFO, 'message 1')\n        storage.add(constants.INFO, 'message 2')\n        storage.add(constants.INFO, 'message 3')\n        storage.add(constants.INFO, CookieStorage.not_finished)\n\n        # Ensure the sentinel value is correctly handled.\n        unstored_messages = storage.update(response)\n        self.assertEqual(self.stored_messages_count(storage, response), 3)\n        self.assertEqual(len(unstored_messages), 1)\n        self.assertEqual(unstored_messages[0], 'message 3')\n\n        # Retrieve the messages and ensure the sentinel is removed.\n        messages = list(storage)\n        self.assertEqual(messages, ['message 1', 'message 2'])\n\n        # Add more messages, ensuring the sentinel is not re-used.\n        storage.add(constants.INFO, 'message 4')\n        storage.add(constants.INFO, 'message 5')\n        storage.update(response)\n        self.assertEqual(self.stored_messages_count(storage, response), 5)\n"], "sample_642": ["def test_preprocess_options_no_match() -> None:\n    \"\"\"Test that options without a match are passed through.\"\"\"\n    with tempdir() as chroot:\n        with fake_home():\n            chroot_path = Path(chroot)\n            testutils.create_files([\"a/b/c/d/__init__.py\"])\n            os.chdir(chroot_path / \"a/b/c\")\n            args = [\"--unknown-option\", \"value\", \"script.py\"]\n            processed_args = _preprocess_options(Run(), args)\n            assert processed_args == [\"--unknown-option\", \"value\", \"script.py\"]\n"], "sample_428": ["    def test_grouping_with_non_uniform_digits(self):\n        self.assertEqual(\n            nformat(1234567890, \".\", grouping=(3, 2, 0), thousand_sep=\",\"),\n            \"123,456,789,0\",\n        )\n        self.assertEqual(\n            nformat(1234567890, \".\", grouping=(3, 2, 0), force_grouping=True),\n            \"123,456,789,0\",\n        )\n"], "sample_768": ["compilation error"], "sample_42": ["compilation error"], "sample_556": ["def test_savefig_metadata_overwrites():\n    fig = Figure()\n    fig.savefig(io.BytesIO(), format='png', metadata={'key1': 'value1'})\n    with pytest.raises(ValueError, match=\"metadata already set\"):\n        fig.savefig(io.BytesIO(), format='png', metadata={'key1': 'new_value'})\n"], "sample_1012": ["def test_print_complex():\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(1 + 2j) == '1 + 2j'\n"], "sample_412": ["    def test_urlize_trim_url_limit(self):\n        self.assertEqual(urlize(\"This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-too-long-to-display-in-full\", trim_url_limit=20),\n                         \"This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-too-long-to-display-in-full\")\n        self.assertEqual(urlize(\"This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-too-long-to-display-in-full\", trim_url_limit=10),\n                         \"This is a long URL: http://www.example.com/...\")\n"], "sample_783": ["def test_imputation_constant_sparse_dtype(X_data, missing_value):\n    # Test imputation using the constant strategy on sparse arrays with\n    # different data types.\n    X = sparse.csr_matrix(\n        [[X_data, X_data, X_data], [X_data, missing_value, X_data]],\n        dtype=np.float64)\n\n    X_true = sparse.csr_matrix(\n        [[X_data, -1, X_data], [X_data, -1, X_data]], dtype=np.float64)\n\n    imputer = SimpleImputer(strategy=\"constant\", fill_value=-1)\n    X_trans = imputer.fit_transform(X)\n\n    assert_allclose_sparse(X_trans, X_true)\n"], "sample_516": ["def test_text_rotation():\n    fig, ax = plt.subplots()\n    ax.text(0.5, 0.5, 'Rotated Text', ha='center', va='center', rotation=45)\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n"], "sample_124": ["    def test_renderer_with_template_name(self):\n        class CustomForm(Form):\n            name = CharField()\n\n        custom_renderer = CustomRenderer()\n        custom_renderer.template_name = 'custom_form.html'\n        form = CustomForm(renderer=custom_renderer)\n        self.assertEqual(form.renderer.template_name, 'custom_form.html')\n"], "sample_277": ["    def test_resolve_expression(self):\n        q = Q(id=1)\n        clause, joins = q.resolve_expression()\n        self.assertEqual(clause, 'id=1')\n        self.assertEqual(joins, [])\n"], "sample_90": ["    def test_related_objects_in_dict(self):\n        \"\"\"\n        Related objects are included in the dictionary representation.\n        \"\"\"\n        author = Author.objects.create(name='Jane Doe')\n        book = Book.objects.create(title='My Book', author=author)\n        data = model_to_dict(book)\n        self.assertIn('author', data)\n        self.assertEqual(data['author'], {'id': author.id, 'name': 'Jane Doe'})\n"], "sample_1151": ["compilation error"], "sample_538": ["compilation error"], "sample_545": ["def test_savefig_metadata_with_dpi():\n    fig = plt.figure(dpi=100)\n    fig.savefig(io.BytesIO(), format='png', metadata={'dpi': 200})\n    with open(io.BytesIO(), 'rb') as f:\n        metadata = PIL.Image.open(f).info.get('dpi')\n    assert metadata == 200\n"], "sample_347": ["    def test_localtime_ambiguous_or_imaginary(self):\n        for tz in PARIS_IMPLS:\n            with self.subTest(repr(tz)):\n                dt = datetime.datetime(2015, 10, 25, 2, 30)\n                local = timezone.localtime(dt, timezone=tz)\n                if _datetime_ambiguous_or_imaginary(dt, tz):\n                    self.assertEqual(local.tzinfo, tz)\n                else:\n                    self.assertEqual(local.tzinfo, timezone.get_current_timezone())\n"], "sample_208": ["    def test_add_field_to_existing_model_with_same_name(self):\n        before = [\n            ModelState('app', 'Book', [\n                ('id', models.AutoField(primary_key=True)),\n                ('title', models.CharField(max_length=200)),\n            ]),\n        ]\n        after = [\n            ModelState('app', 'Book', [\n                ('id', models.AutoField(primary_key=True)),\n                ('title', models.CharField(max_length=200)),\n                ('title', models.CharField(max_length=200, blank=True)),\n            ]),\n        ]\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'app', 1)\n        self.assertOperationTypes(changes, 'app', 0, ['AddField'])\n        self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='Book')\n"], "sample_1139": ["def test_issue_17860():\n    r = Range(1, 5)\n    assert r[1:3] == Range(2, 4)\n    assert r[1:4] == Range(2, 4)\n    assert r[1:5] == Range(2, 5)\n    assert r[0:3] == Range(1, 4)\n    assert r[0:5] == Range(1, 5)\n    assert r[1:-1] == Range(2, 4)\n    assert r[1:-2] == Range(2, 3)\n    assert r[2:] == Range(3, 5)\n    assert r[:-2] == Range(1, 3)\n    assert r[:-1] == Range(1, 4)\n"], "sample_371": ["    def test_sensitive_post_parameters_method_decorator(self):\n        class MyClass:\n            @method_decorator(sensitive_post_parameters())\n                return HttpResponse()\n\n        instance = MyClass()\n        response = instance.a_view(HttpRequest())\n        self.assertEqual(response.status_code, 200)\n\n\n\n"], "sample_553": ["def test_save_animation_with_bbox_inches(tmpdir, writer):\n    fig, ax = plt.subplots()\n    ax.set_xlim(0, 10)\n    ax.set_ylim(0, 10)\n    line, = ax.plot([], [])\n\n        line.set_data([i], [i])\n        return line,\n\n    anim = animation.FuncAnimation(fig, animate, frames=10, blit=True)\n    with tmpdir.as_cwd():\n        anim.save(\n            'test.gif', writer=writer, bbox_inches='tight',\n            dpi=100)\n\n\n\n"], "sample_1": ["    def model_d(x, y):\n        return x * y\n"], "sample_446": ["    def test_floatformat_with_locale(self):\n        with translation.override(\"de\", deactivate=True):\n            self.assertEqual(floatformat(12345.6789, 2), \"12345,68\")\n            self.assertEqual(floatformat(12345.6789, \"2\"), \"12345,68\")\n            self.assertEqual(floatformat(12345.6789, \"2u\"), \"12345.68\")\n            self.assertEqual(floatformat(12345.6789, \"2g\"), \"12.345,68\")\n            self.assertEqual(floatformat(12345.6789, \"2gu\"), \"12.345,68\")\n"], "sample_308": ["    def test_alternative_month_names(self):\n        my_birthday = datetime(1979, 7, 8, 22, 00)\n        self.assertEqual(dateformat.format(my_birthday, 'E'), 'July')\n"], "sample_113": ["    def test_simplify_regex_with_named_groups(self):\n        tests = (\n            (r'^/admin/(?P<app_label>\\w+)/(?P<model_name>\\w+)/$', '/admin/<app_label>/<model_name>/'),\n            (r'^/admin/(?P<app_label>\\w+)/(?P<model_name>\\w+)/(?P<action>add|change|delete|delete|view)/$', '/admin/<app_label>/<model_name>/<action>'),\n        )\n        for pattern, output in tests:\n            with self.subTest(pattern=pattern):\n                self.assertEqual(simplify_regex(pattern), output)\n"], "sample_809": ["def test_mutual_info_sparse():\n    # Test that sparse matrix input works correctly.\n    X = csr_matrix([[1, 0, 0],\n                    [0, 1, 1],\n                    [0, 0, 1]])\n    y = np.array([0, 1, 0])\n\n    mi_sparse = mutual_info_classif(X, y, discrete_features='auto')\n    mi_dense = mutual_info_classif(X.toarray(), y, discrete_features='auto')\n\n    assert_array_equal(mi_sparse, mi_dense)\n"], "sample_845": ["def test_vectorizer_with_empty_input(Estimator):\n    if issubclass(Estimator, HashingVectorizer):\n        pytest.xfail('HashingVectorizer is not supported on PyPy')\n    with pytest.raises(ValueError):\n        Estimator().fit_transform([])\n"], "sample_1113": ["def test_block_matrix_transpose():\n    A = BlockMatrix([[1, 2], [3, 4]])\n    assert (A.T).as_explicit() == BlockMatrix([[1, 3], [2, 4]])\n    B = BlockMatrix([[1, 2, 3], [4, 5, 6]])\n    assert (B.T).as_explicit() == BlockMatrix([[1, 4], [2, 5], [3, 6]])\n    C = BlockMatrix([[1, 2], [3, 4], [5, 6]])\n    assert (C.T).as_explicit() == BlockMatrix([[1, 3, 5], [2, 4, 6]])\n    D = BlockMatrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    assert (D.T).as_explicit() == BlockMatrix([[1, 4, 7], [2, 5, 8], [3, 6, 9]])\n    E = BlockMatrix([[1, 2], [3, 4], [5, 6]])\n    assert (E.T).as_explicit() == BlockMatrix([[1, 3, 5], [2, 4, 6]])\n    F = BlockMatrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    assert (F.T).as_explicit() == BlockMatrix([[1, 4, 7], [2, 5, 8], [3, 6, 9]])\n\n\n\n"], "sample_393": ["    def test_po_changed_with_updated_strings(self):\n        \"\"\"PO files are updated when existing strings are changed.\"\"\"\n        with open(self.PO_FILE, \"w\") as fp:\n            fp.write(\n                \"\"\"msgid \"This is an existing string.\""], "sample_449": ["    def test_close_connections_on_close_header(self):\n        request = WSGIRequest(self.request_factory.get(\"/\").environ)\n        client_address = (\"192.168.2.0\", 8080)\n        request.environ[\"HTTP_CONNECTION\"] = \"close\"\n        with self.assertLogs(\"django.server\", \"INFO\"):\n            server = WSGIServer((\"localhost\", 0), WSGIRequestHandler)\n            server.handle_error(request, client_address)\n        self.assertEqual(server.close_connection, True)\n"], "sample_132": ["    def test_sensitive_variables_decorator_with_args(self):\n        @sensitive_variables(exclude=['cooked_eggs'])\n            return password, cooked_eggs\n\n        with self.settings(DEBUG=True):\n            response = self.client.post('/test_view/', data={'password': 'secret', 'cooked_eggs': 'scrambled'})\n            self.assertContains(response, 'secret', status_code=500)\n            self.assertContains(response, 'scrambled', status_code=500)\n\n        with self.settings(DEBUG=False):\n            response = self.client.post('/test_view/', data={'password': 'secret', 'cooked_eggs': 'scrambled'})\n            self.assertContains(response, 'secret', status_code=500)\n            self.assertContains(response, 'scrambled', status_code=500)\n\n"], "sample_771": ["def test_power_transformer_sparse_matrix():\n    X = sparse.csr_matrix(X_2d)\n    for standardize in [True, False]:\n        pt = PowerTransformer(method='box-cox', standardize=standardize)\n        X_trans = pt.fit_transform(X)\n        assert isinstance(X_trans, sparse.csr_matrix)\n        X_inv = pt.inverse_transform(X_trans)\n        assert isinstance(X_inv, sparse.csr_matrix)\n        assert_array_almost_equal(X.toarray(), X_inv.toarray())\n\n\n\n"], "sample_1014": ["def test_reshape_with_symbolic_indices():\n    x, y = symbols(\"x y\")\n    arr = ImmutableDenseNDimArray([[x, y], [x, y]])\n    reshaped_arr = arr.reshape((2, 2))\n    assert reshaped_arr.shape == (2, 2)\n    assert reshaped_arr[0, 0] == x\n    assert reshaped_arr[0, 1] == y\n    assert reshaped_arr[1, 0] == x\n    assert reshaped_arr[1, 1] == y\n\n    reshaped_arr = arr.reshape((1, 4))\n    assert reshaped_arr.shape == (1, 4)\n    assert reshaped_arr[0, 0] == x\n    assert reshaped_arr[0, 1] == y\n    assert reshaped_arr[0, 2] == x\n    assert reshaped_arr[0, 3] == y\n\n    raises(ValueError, lambda: arr.reshape((3, 2)))\n    raises(ValueError, lambda: arr.reshape((2, 3)))\n"], "sample_1074": ["compilation error"], "sample_619": ["def test_decode_cf_datetime_with_cftime_datetime_array():\n    # GH 4422, 4506\n    from cftime import num2date\n\n    dates = [1, 2, 3]\n    units = \"days since 1-1-1\"\n    cftime_dates = cftime.num2date(dates, units, calendar=\"noleap\")\n    result = decode_cf_datetime(cftime_dates, units, calendar=\"noleap\", use_cftime=True)\n    np.testing.assert_array_equal(result, cftime_dates)\n"], "sample_574": ["    def test_label_format(self, t):\n\n        fmt = \"%b %Y\"\n        s = Temporal().label(format=fmt)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"Sep 1972\"\n"], "sample_119": ["    def test_complex_join_promotion(self):\n        query = Query(Item)\n        query.add_filter(Q(creator__num__gt=2) | Q(creator__name__icontains='John'))\n        query.add_filter(Q(modified__gt=F('created')))\n        query.add_select_related(['creator'])\n        query.promote_joins(set())\n        query.demote_joins(set())\n        # Check that the joins are promoted and demoted correctly\n        # based on the conditions in the query.\n        # This is a complex test case that requires a deeper understanding\n        # of the join promotion logic.\n        # You can use assertions to check the join types and the presence\n        # of specific conditions in the generated SQL.\n\n\n\n"], "sample_1184": ["compilation error"], "sample_739": ["compilation error"], "sample_409": ["    def test_render_with_plural_forms(self):\n        block_translate_node = BlockTranslateNode(\n            extra_context={\"count\": 2},\n            singular=[\n                Token(TokenType.TEXT, \"singular form\"),\n            ],\n            plural=[\n                Token(TokenType.TEXT, \"plural form\"),\n            ],\n        )\n        self.assertEqual(\n            block_translate_node.render(Context()), \"plural form\"\n        )\n\n"], "sample_714": ["compilation error"], "sample_280": ["    def test_aggregation_default_with_subquery(self):\n        with self.assertNumQueries(2):\n            result = Book.objects.annotate(\n                avg_rating=Avg('rating'),\n            ).filter(avg_rating__gt=4.0).aggregate(\n                value=Sum('price', default=Subquery(\n                    Book.objects.filter(avg_rating__lt=3.0).values('price').annotate(\n                        avg_price=Avg('price')\n                    ).values('avg_price')[:1],\n                )),\n            )\n        self.assertAlmostEqual(result['value'], Decimal('120.64'), places=2)\n"], "sample_415": ["    def test_unique_constraint_with_null_values(self):\n        with self.assertRaises(IntegrityError):\n            UniqueConstraintProduct.objects.create(name=self.p1.name, color=None)\n"], "sample_1166": ["compilation error"], "sample_143": ["    def test_camel_case_to_spaces(self):\n        self.assertEqual(text.camel_case_to_spaces('ThisIsACamelCaseString'), 'This Is A Camel Case String')\n        self.assertEqual(text.camel_case_to_spaces('thisIsACamelCaseString'), 'this Is A Camel Case String')\n        self.assertEqual(text.camel_case_to_spaces('this_is_a_camel_case_string'), 'this is a camel case string')\n        self.assertEqual(text.camel_case_to_spaces('camelCaseWithNumbers'), 'camel Case With Numbers')\n        self.assertEqual(text.camel_case_to_spaces('camelCaseWithMixedCase'), 'camel Case With Mixed Case')\n"], "sample_159": ["    def test_custom_permission_name_length_with_spaces(self):\n        custom_permission_name = 'some ridiculously long verbose name that is out of control' * 5\n\n        class Checked(models.Model):\n            class Meta:\n                permissions = [\n                    ('my_custom_permission', custom_permission_name),\n                ]\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The permission named '%s' of model 'auth_tests.Checked' is longer \"\n                \"than 255 characters.\" % custom_permission_name,\n                obj=Checked,\n                id='auth.E008',\n            ),\n        ])\n"], "sample_570": ["    def test_bootstrap_errorbars(self, long_df):\n\n        agg = EstimateAggregator(\"mean\", \"ci\", n_boot=1000, seed=0)\n        out = agg(long_df, \"y\")\n\n        agg_ref = EstimateAggregator(\"mean\", (\"se\", 1.96))\n        out_ref = agg_ref(long_df, \"y\")\n\n        assert out[\"ymin\"] == pytest.approx(out_ref[\"ymin\"], abs=1e-2)\n        assert out[\"ymax\"] == pytest.approx(out_ref[\"ymax\"], abs=1e-2)\n\n"], "sample_326": ["    def test_urlize_trim_url_limit(self):\n        tests = (\n            ('http://www.example.com/this-is-a-very-long-url-that-will-be-truncated',\n             'http://www.example.com/this-is-a-very-long-url-that-will-be-truncated\u2026'),\n            ('http://www.example.com/this-is-a-very-long-url-that-will-be-truncated?param1=value1&param2=value2',\n             'http://www.example.com/this-is-a-very-long-url-that-will-be-truncated?param1=value1&param2=value2\u2026'),\n            ('http://www.example.com/this-is-a-very-long-url-that-will-be-truncated?param1=value1&param2=value2&param3=value3',\n             'http://www.example.com/this-is-a-very-long-url-that-will-be-truncated?param1=value1&param2=value2&param3=value3\u2026'),\n        )\n        for value, output in tests:\n            with self.subTest(value=value):\n                self.assertEqual(urlize(value, trim_url_limit=20), output)\n\n\n\n"], "sample_511": ["def test_subplot_projection_reuse_with_kwargs():\n    fig = plt.figure()\n    ax1 = plt.subplot(111, projection='polar')\n    ax2 = plt.subplot(111, projection='polar', theta_offset=0)\n    assert ax1 is ax2\n\n    ax3 = plt.subplot(111, projection='polar', theta_offset=1)\n    assert ax3 is not ax1\n    assert ax3 is not ax2\n"], "sample_383": ["    def test_ticket_24605_subquery_with_distinct_on_related_field(self):\n        \"\"\"\n        Make sure __pk__in and __in work the same for related fields when\n        using a distinct on subquery, and the related field is distinct'd on.\n        \"\"\"\n        a1 = Ticket23605A.objects.create()\n        a2 = Ticket23605A.objects.create()\n        c1 = Ticket23605C.objects.create(field_c0=0.0)\n        Ticket23605B.objects.create(\n            modela_fk=a1,\n            field_b0=123,\n            field_b1=True,\n            modelc_fk=c1,\n        )\n        Ticket23605B.objects.create(\n            modela_fk=a1,\n            field_b0=23,\n            field_b1=True,\n            modelc_fk=c1,\n        )\n        Ticket23605B.objects.create(\n            modela_fk=a1,\n            field_b0=234,\n            field_b1=True,\n            modelc_fk=c1,\n        )\n        Ticket23605B.objects.create(\n            modela_fk=a1,\n            field_b0=12,\n            field_b1=True,\n            modelc_fk=c1,\n        )\n        Ticket23605B.objects.create(\n            modela_fk=a2,\n            field_b0=567,\n            field_b1=True,\n            modelc_fk=c1,\n        )\n        Ticket23605B.objects.create(\n            modela_fk=a2,\n            field_b0=76,\n            field_b1=True,\n            modelc_fk=c1,\n        )\n        Ticket23605B.objects.create(\n            modela_fk=a2,\n            field_b0=7,\n            field_b1="], "sample_877": ["def test_isotonic_regression_with_missing_values():\n    # Test handling of missing values in input data\n    X = np.array([1, 2, np.nan, 4, 5])\n    y = np.array([2, 4, 1, 5, 6])\n\n    # Check if fit raises an error\n    with pytest.raises(ValueError, match=\"Input contains missing values\"):\n        IsotonicRegression().fit(X, y)\n\n    # Check if predict raises an error\n    with pytest.raises(ValueError, match=\"Input contains missing values\"):\n        IsotonicRegression().predict(X)\n\n    # Test with imputation\n    from sklearn.impute import SimpleImputer\n    imputer = SimpleImputer(strategy=\"mean\")\n    X_imputed = imputer.fit_transform(X.reshape(-1, 1))\n    reg = IsotonicRegression()\n    reg.fit(X_imputed, y)\n    y_pred = reg.predict(X_imputed)\n    assert not np.isnan(y_pred).any()\n"], "sample_712": ["def test_one_hot_encoder_sparse_output():\n    X = np.array([['abc', 2, 55], ['def', 1, 55]])\n    enc = OneHotEncoder(sparse=True)\n    Xtr = enc.fit_transform(X)\n    assert isinstance(Xtr, sparse.csr_matrix)\n    assert Xtr.shape == (2, 5)\n"], "sample_563": ["def test_offsetbox_bbox_transform():\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100)\n    ab = AnchoredOffsetbox(loc='center', child=da, bbox_transform=ax.transAxes)\n    ax.add_artist(ab)\n    fig.canvas.draw()\n"], "sample_684": ["    def test_repr_locals_with_empty_locals(self) -> None:\n            pass\n\n        with mock.patch.object(func, \"__dict__\", {}):\n            excinfo = ExceptionInfo.from_current()\n            repr_locals = excinfo.traceback[0].reprlocals\n            assert repr_locals is None or repr_locals.lines == []\n"], "sample_364": ["    def test_converter_with_default_value(self):\n        @DynamicConverter.register_to_url\n            return value if value else default\n        with self.subTest(url='/dynamic/'):\n            url = reverse('dynamic', kwargs={'value': None})\n            self.assertEqual(url, '/dynamic/1/')\n        with self.subTest(url='/dynamic/abc/'):\n            url = reverse('dynamic', kwargs={'value': 'abc'})\n            self.assertEqual(url, '/dynamic/abc/')\n"], "sample_500": ["def test_colorbar_fraction_with_gridspec():\n    fig, axes = plt.subplots(2, 2, gridspec_kw={'height_ratios': [1, 2]})\n    im = axes[0, 0].imshow([[1, 2], [3, 4]])\n    cb = fig.colorbar(im, ax=axes[0, 0], fraction=0.05)\n    assert cb.ax.get_position().height == 0.05\n    \n    im = axes[1, 0].imshow([[1, 2], [3, 4]])\n    cb = fig.colorbar(im, ax=axes[1, 0], fraction=0.05)\n    assert cb.ax.get_position().height == 0.05\n"], "sample_921": ["        def __init__(self, value):\n            self._value = value\n"], "sample_125": ["    def test_delete_cookie_with_path(self):\n        response = HttpResponse()\n        response.set_cookie('c', path='/admin')\n        response.delete_cookie('c', path='/admin')\n        cookie = response.cookies['c']\n        self.assertEqual(cookie['path'], '/admin')\n        response.delete_cookie('c', path='/')\n        cookie = response.cookies['c']\n        self.assertEqual(cookie['path'], '/')\n\n"], "sample_741": ["def test_grid_search_with_preprocessor():\n    from sklearn.preprocessing import StandardScaler\n    X, y = make_classification(n_samples=100, n_features=20, random_state=0)\n\n    scaler = StandardScaler()\n    clf = MockClassifier()\n    grid_search = GridSearchCV(\n        Pipeline([('scaler', scaler), ('classifier', clf)]),\n        param_grid={'classifier__foo_param': [1, 2, 3]}, cv=5)\n    grid_search.fit(X, y)\n    assert_equal(grid_search.best_params_['scaler'], None)\n    assert_equal(grid_search.best_params_['classifier__foo_param'],\n                 grid_search.cv_results_['params'][grid_search.best_index_][\n                     'classifier__foo_param'])\n\n\n\n"], "sample_260": ["    def test_optimize_with_m2m_through(self):\n        \"\"\"\n        CreateModel, AlterModelTable, AlterUniqueTogether/AlterIndexTogether/\n        AlterOrderWithRespectTo followed by an add/alter/rename field should\n        optimize to CreateModel with options.\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    fields=[(\"name\", models.CharField(max_length=255))],\n                ),\n                migrations.CreateModel(\n                    \"Bar\",\n                    fields=[(\"name\", models.CharField(max_length=255))],\n                ),\n                migrations.CreateModel(\n                    \"Link\",\n                    fields=[(\"foo\", models.ForeignKey(\"migrations.Foo\", models.CASCADE)),\n                             (\"bar\", models.ForeignKey(\"migrations.Bar\", models.CASCADE))],\n                ),\n                migrations.AddField(\"Foo\", \"bars\", models.ManyToManyField(\"migrations.Bar\", through=\"migrations.Link\")),\n                migrations.AlterField(\"Foo\", \"bars\", models.ManyToManyField(\"migrations.Bar\", through=\"migrations.Link\",\n                                                                         related_name=\"foo_bars\")),\n            ],\n            [\n                migrations.CreateModel(\n                    \"Foo\",\n                    fields=[(\"name\", models.CharField(max_length=255))],\n                ),\n                migrations.CreateModel(\n                    \"Bar\",\n                    fields=[(\"name\", models.CharField(max_length=255))],\n                ),\n                migrations.CreateModel(\n                    \"Link\",\n                    fields=[(\"foo\", models.ForeignKey(\"migrations.Foo\", models.CASCADE)),\n                             (\"bar\", models.ForeignKey(\"migrations.Bar\", models.CASCADE)),\n                             ],\n                ),\n                migrations.AddField(\"Foo\", \"bars\", models.ManyToManyField(\"migrations.Bar\", through=\"migrations.Link\",\n                                                                         related_name=\"foo_bars\")),\n            ],\n        )\n\n\n\n"], "sample_268": ["    def test_snapshot_files_with_different_paths_to_same_file(self):\n        file1 = self.ensure_file(self.tempdir / 'test.py')\n        file2 = self.ensure_file(self.tempdir / 'test.py')\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[file1, file2]):\n            snapshot = list(self.reloader.snapshot_files())\n            self.assertEqual(len(snapshot), 1)\n            self.assertEqual(snapshot[0][0], file1)\n"], "sample_175": ["    def test_fast_delete_with_signals(self):\n            pass\n\n        origin = Origin.objects.create()\n        signal = models.signals.post_delete\n        signal.connect(receiver, sender=Referrer)\n        with self.assertNumQueries(2):\n            origin.delete()\n        signal.disconnect(receiver, sender=Referrer)\n"], "sample_879": ["def test_ordinal_encoder_handle_unknown_with_categories_and_missing():\n    \"\"\"Check OrdinalEncoder handles unknown categories and missing values when categories are provided.\"\"\"\n    X = np.array([[\"a\", np.nan], [\"b\", 1], [\"c\", np.nan]], dtype=object)\n    categories = [[\"a\", \"b\", \"c\"], [0, 1]]\n    oe = OrdinalEncoder(categories=categories, handle_unknown=\"use_encoded_value\", unknown_value=-1).fit(X)\n\n    X_trans = oe.transform(X)\n    assert_allclose(X_trans, [[0, np.nan], [1, 0], [2, np.nan]])\n\n    X_inverse = oe.inverse_transform(X_trans)\n    assert_array_equal(X_inverse, X)\n"], "sample_1069": ["def test_polylog():\n    assert octave_code(polylog(n, x)) == 'polylog(n, x)'\n"], "sample_185": ["    def test_round_away_from_one_with_precision(self):\n        tests = [\n            (0, 0, 0),\n            (0.25, 0, 0),\n            (0.5, 0, 0),\n            (0.75, 0, 0),\n            (1, 1, 0),\n            (1.25, 2, 0),\n            (1.5, 2, 0),\n            (1.75, 2, 0),\n            (2.25, 2, 0),\n            (2.5, 3, 0),\n            (-0.25, -1, 0),\n            (-0.5, -1, 0),\n            (-0.75, -1, 0),\n            (-1, -1, 0),\n            (-1.25, -2, 0),\n            (-1.5, -2, 0),\n            (-1.75, -2, 0),\n            (-2.25, -2, 0),\n            (-2.5, -3, 0),\n        ]\n        for value, expected, precision in tests:\n            with self.subTest(value=value):\n                self.assertEqual(round_away_from_one(value, precision), expected)\n"], "sample_587": ["    def test_merge_no_conflicts_with_attrs(self):\n        ds1 = xr.Dataset({\"a\": (\"x\", [1, 2]), \"x\": [0, 1], foo=\"bar\"})\n        ds2 = xr.Dataset({\"a\": (\"x\", [2, 3]), \"x\": [1, 2], foo=\"baz\"})\n        expected = xr.Dataset(\n            {\"a\": (\"x\", [1, 2, 3]), \"x\": [0, 1, 2]}, {\"foo\": [\"bar\", \"baz\", \"baz\"]}\n        )\n        assert expected.identical(ds1.merge(ds2, compat=\"no_conflicts\"))\n        assert expected.identical(ds2.merge(ds1, compat=\"no_conflicts\"))\n"], "sample_324": ["    def test_csrf_token_on_500_stays_constant(self):\n        response = self.client.get('/internal_server_error/')\n        self.assertEqual(response.status_code, 500)\n        token1 = response.content\n        response = self.client.get('/internal_server_error/')\n        self.assertEqual(response.status_code, 500)\n        token2 = response.content\n        self.assertTrue(equivalent_tokens(token1.decode('ascii'), token2.decode('ascii')))\n"], "sample_738": ["def test_vectorizer_empty_vocabulary():\n    # Test for empty vocabulary after fitting\n    vect = CountVectorizer(max_features=0)\n    X = vect.fit_transform(JUNK_FOOD_DOCS)\n    assert_array_equal(X.shape, (0, 0))\n    assert_equal(len(vect.vocabulary_), 0)\n\n    vect = TfidfVectorizer(max_features=0)\n    X = vect.fit_transform(JUNK_FOOD_DOCS)\n    assert_array_equal(X.shape, (0, 0))\n    assert_equal(len(vect.vocabulary_), 0)\n\n    vect = HashingVectorizer(n_features=0)\n    X = vect.fit_transform(JUNK_FOOD_DOCS)\n    assert_array_equal(X.shape, (0, 0))\n    assert_equal(len(vect.vocabulary_), 0)\n"], "sample_839": ["def test_vectorizer_with_empty_vocabulary(Estimator):\n    if issubclass(Estimator, HashingVectorizer):\n        pytest.xfail('HashingVectorizer is not supported on PyPy')\n    vec = Estimator(vocabulary=[])\n    assert_raises(ValueError, vec.fit_transform, ['hello world'])\n    assert_raises(ValueError, vec.transform, ['hello world'])\n\n\n\n"], "sample_57": ["    def test_password_too_short(self):\n        user = User.objects.get(username='testclient')\n        data = {'password1': 'abc', 'password2': 'abc'}\n        form = AdminPasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertIn(\n            'This password is too short. It must contain at least 8 characters.',\n            form.errors['password1']\n        )\n        self.assertIn(\n            'This password is too short. It must contain at least 8 characters.',\n            form.errors['password2']\n        )\n"], "sample_215": ["    def test_sensitive_variables_decorator_with_kwargs(self):\n        @sensitive_variables\n            return password, kwargs\n\n        with self.settings(DEBUG=True):\n            response = self.client.post('/test_view/', data={'password': 'secret', 'other': 'value'})\n            self.assertEqual(response.status_code, 500)\n            self.assertNotIn('secret', response.content)\n            self.assertNotIn('other', response.content)\n\n        with self.settings(DEBUG=False):\n            response = self.client.post('/test_view/', data={'password': 'secret', 'other': 'value'})\n            self.assertEqual(response.status_code, 500)\n            self.assertNotIn('secret', response.content)\n            self.assertIn('other', response.content)\n"], "sample_521": ["def test_grid_3d():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    ax.grid(True)\n    ax.set_xlim(0, 10)\n    ax.set_ylim(0, 10)\n    ax.set_zlim(0, 10)\n    fig.canvas.draw()\n"], "sample_689": ["def test_pytest_warning_captured_is_deprecated(testdir: Testdir) -> None:\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n            pytest.warning.capture(\"This is a warning\")\n        \"\"\"\n    )\n\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: The pytest_warning_captured is deprecated and will be removed in a future release.*\",\n            \"*Please use pytest_warning_recorded instead.*\",\n        ]\n    )\n"], "sample_1205": ["def test_PolyElement_gcd_with_ground_element():\n    R, x = ring(\"x\", ZZ)\n    f = x**2 - 2\n    g = 3\n\n    assert f.gcd(g) == 1\n    assert f.gcd(g) == R(1)\n\n    R, x, y = ring(\"x,y\", ZZ)\n    f = x**2 - y**2\n    g = 2\n\n    assert f.gcd(g) == 1\n    assert f.gcd(g) == R(1)\n\n    R, x = ring(\"x\", QQ)\n    f = x**2 - 2\n    g = 3\n\n    assert f.gcd(g) == 1\n    assert f.gcd(g) == R(1)\n\n    R, x = ring(\"x\", QQ.algebraic_field(sqrt(3)))\n    f = x**2 - 2\n    g = 3\n\n    assert f.gcd(g) == 1\n    assert f.gcd(g) == R(1)\n\n"], "sample_305": ["    def test_self_referential_fk_with_filter(self):\n        t1 = SelfRefFK.objects.create(name='t1')\n        t2 = SelfRefFK.objects.create(name='t2', parent=t1)\n        t3 = SelfRefFK.objects.create(name='t3', parent=t1)\n        t4 = SelfRefFK.objects.create(name='t4', parent=t2)\n        self.assertQuerysetEqual(\n            SelfRefFK.objects.filter(children__name='t4').annotate(num_children=Count('children')).order_by('name'),\n            [('t2', 1)],\n            lambda x: (x.name, x.num_children)\n        )\n"], "sample_58": ["    def test_render_with_custom_renderer(self):\n        class CustomRenderer(DjangoTemplates):\n                return 'Custom rendered output'\n\n        form = Form(renderer=CustomRenderer())\n        self.assertEqual(form.render(), 'Custom rendered output')\n"], "sample_946": ["def test_warn_missing_reference_with_explicit_label(app, status, warning):\n    app.build()\n    assert 'index.rst:6: WARNING: undefined label: no-label' in warning.getvalue()\n    assert ('index.rst:6: WARNING: Failed to create a cross reference. A title or caption not found: existing-label'\n            in warning.getvalue())\n"], "sample_572": ["    def test_bootstrap_errorbars(self, long_df):\n\n        agg = EstimateAggregator(\"mean\", \"ci\", n_boot=1000, seed=0)\n        out = agg(long_df, \"y\")\n\n        agg_ref = EstimateAggregator(\"mean\", (\"se\", 1.96))\n        out_ref = agg_ref(long_df, \"y\")\n\n        assert out[\"ymin\"] == pytest.approx(out_ref[\"ymin\"], abs=1e-2)\n        assert out[\"ymax\"] == pytest.approx(out_ref[\"ymax\"], abs=1e-2)\n"], "sample_396": ["    def test_ticket_24605_distinct_on_related_field(self):\n        \"\"\"\n        Subquery table names should be quoted when distinct on related field.\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        qs = Individual.objects.filter(\n            Q(alive=False),\n            Q(related_individual__isnull=True),\n        ).distinct(\"related_individual__id\")\n        self.assertQuerysetEqual(qs, [i4])\n"], "sample_800": ["def test_check_estimator_sparse_matrix_input():\n    # check that estimator handles sparse matrix input correctly\n    class TestSparseMatrixEstimator(BaseEstimator):\n            if sp.issparse(X):\n                return self\n            else:\n                raise ValueError(\"Only sparse matrices are accepted\")\n\n    check_estimator(TestSparseMatrixEstimator())\n"], "sample_899": ["def test_check_estimator_sparse_matrix_input():\n    # check that estimator handles sparse matrix input correctly\n    class TestSparseMatrixInput(BaseEstimator):\n            X = check_array(X)\n            return self\n\n            X = check_array(X)\n            return X\n\n    msg = \"Estimator doesn't check for sparse matrix input\"\n    assert_raises_regex(AssertionError, msg, check_estimator, TestSparseMatrixInput())\n"], "sample_390": ["    def test_was_modified_since_future_mtime(self):\n        header = http_date(1)\n        mtime = 1000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"], "sample_861": ["def test_grid_search_with_preprocessor():\n    from sklearn.preprocessing import StandardScaler\n    X, y = make_classification(n_samples=100, n_features=20, random_state=0)\n    scaler = StandardScaler()\n    preprocessor = Pipeline([\n        ('scaler', scaler),\n        ('clf', SVC())\n    ])\n    param_grid = {'clf__C': [0.1, 1, 10]}\n    gs = GridSearchCV(preprocessor, param_grid, cv=5)\n    gs.fit(X, y)\n    assert isinstance(gs.best_estimator_, Pipeline)\n    assert isinstance(gs.best_estimator_.steps[0][1], StandardScaler)\n    assert isinstance(gs.best_estimator_.steps[1][1], SVC)\n\n\n\n"], "sample_1112": ["compilation error"], "sample_6": ["def test_array_to_string():\n    c1 = ICRS([1, 2]*u.deg, [3, 4]*u.deg)\n    c2 = ICRS([1, 2]*u.deg, [3, 4]*u.deg, distance=[1, 2] * u.kpc)\n\n    assert c1.to_string() == 'ICRS(ra=[1.0, 2.0], dec=[3.0, 4.0])'\n    assert c2.to_string() == 'ICRS(ra=[1.0, 2.0], dec=[3.0, 4.0], distance=[1.0, 2.0])'\n\n\n"], "sample_267": ["    def test_sqlite_datetime_trunc(self):\n        with connection.cursor() as cursor:\n            cursor.execute('CREATE TABLE test_datetime (dt DATETIME)')\n            cursor.execute('INSERT INTO test_datetime (dt) VALUES (\"2023-10-27 10:30:00\")')\n            cursor.execute('SELECT strftime(\"%Y-%m-%d %H:%M:%S\", datetime(dt)) FROM test_datetime')\n            result = cursor.fetchone()[0]\n            self.assertEqual(result, '2023-10-27 10:30:00')\n            cursor.execute('SELECT strftime(\"%Y-%m-%d\", datetime(dt)) FROM test_datetime')\n            result = cursor.fetchone()[0]\n            self.assertEqual(result, '2023-10-27')\n            cursor.execute('SELECT strftime(\"%W\", datetime(dt)) FROM test_datetime')\n            result = cursor.fetchone()[0]\n            self.assertEqual(result, '43')\n            cursor.execute('SELECT strftime(\"%m\", datetime(dt)) FROM test_datetime')\n            result = cursor.fetchone()[0]\n            self.assertEqual(result, '10')\n            cursor.execute('SELECT strftime(\"%d\", datetime(dt)) FROM test_datetime')\n            result = cursor.fetchone()[0]\n            self.assertEqual(result, '27')\n            cursor.execute('SELECT strftime(\"%H\", datetime(dt)) FROM test_datetime')\n            result = cursor.fetchone()[0]\n            self.assertEqual(result, '10')\n            cursor.execute('SELECT strftime(\"%M\", datetime(dt)) FROM test_datetime')\n            result = cursor.fetchone()[0]\n            self.assertEqual(result, '30')\n            cursor.execute('SELECT strftime(\"%S\", datetime(dt)) FROM test_datetime')\n            result = cursor.fetchone()[0]\n            self.assertEqual(result, '00')\n\n\n\n"], "sample_1160": ["def test_issue_18134_boundary():\n    assert S.Integers.boundary == S.Integers\n    assert S.Naturals.boundary == S.Naturals\n    assert S.Naturals0.boundary == S.Naturals0\n    assert S.Rationals.boundary == S.Reals\n    assert S.Reals.boundary == S.Reals\n    assert S.Complexes.boundary == S.Complexes\n"], "sample_697": ["    def test_tmp_path_factory_handles_non_ascii_characters(\n        tmp_path_factory: TempPathFactory, monkeypatch: MonkeyPatch"], "sample_654": ["    def test_fixture_param_shadowing_indirect_with_scope(testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='module', params=['a', 'b'])\n                return request.param\n\n            @pytest.fixture(scope='module')\n                return argroot\n\n        @pytest.mark.parametrize(\"arg2\", [1], indirect=True)\n            assert arg2 == 1"], "sample_181": ["    def test_filtered_aggregate_with_subquery_and_exists(self):\n        subquery = Book.objects.filter(\n            rating__gt=4,\n            contact__age__gt=50,\n        ).values('contact__pk')\n        agg = Count('pk', filter=Exists(subquery))\n        self.assertEqual(Author.objects.aggregate(cnt=agg)['cnt'], 1)\n"], "sample_1008": ["def test_issue_12057():\n    N = ReferenceFrame('N')\n    A = N.orientnew('A', 'Axis', [0, N.z])\n    B = A.orientnew('B', 'Axis', [0, A.x])\n    C = B.orientnew('C', 'Axis', [0, B.y])\n    D = N.orientnew('D', 'Axis', [0, N.y])\n\n    assert N.dcm(C) == Matrix([\n        [1, 0, 0],\n        [0, cos(0), -sin(0)],\n        [0, sin(0), cos(0)]\n    ])\n    assert N.dcm(D) == Matrix([\n        [cos(0), -sin(0), 0],\n        [sin(0), cos(0), 0],\n        [0, 0, 1]\n    ])\n    assert A.dcm(C) == Matrix([\n        [cos(0), -sin(0), 0],\n        [sin(0), cos(0), 0],\n        [0, 0, 1]\n    ])\n    assert A.dcm(D) == Matrix([\n        [cos(0), -sin(0), 0],\n        [sin(0), cos(0), 0],\n        [0, 0, 1]\n    ])\n    assert B.dcm(C) == Matrix([\n        [1, 0, 0],\n        [0, cos(0), -sin(0)],\n        [0, sin(0), cos(0)]\n    ])\n    assert B.dcm(D) == Matrix([\n        [cos(0), -sin(0), 0],\n        [sin(0), cos(0), 0],\n        [0, 0, 1]\n    ])\n    assert C.dcm(D) == Matrix([\n        [cos(0), -sin(0), 0],\n        [sin(0), cos(0), 0],\n        [0, 0, 1]\n    ])\n\n\n\n"], "sample_524": ["def test_colorbar_with_custom_cmap():\n    fig, ax = plt.subplots()\n    data = np.random.rand(10, 10)\n    cmap = plt.cm.get_cmap('viridis')\n    norm = plt.Normalize(vmin=0, vmax=1)\n    im = ax.imshow(data, cmap=cmap, norm=norm)\n    cb = fig.colorbar(im, ax=ax)\n    assert cb.cmap is cmap\n    assert cb.norm is norm\n\n    # Test setting a custom colormap\n    custom_cmap = plt.cm.get_cmap('coolwarm')\n    cb.set_cmap(custom_cmap)\n    assert cb.cmap is custom_cmap\n\n    # Test setting a custom colormap with a different normalization\n    custom_norm = plt.Normalize(vmin=0.5, vmax=1.5)\n    cb.set_cmap(custom_cmap)\n    cb.set_norm(custom_norm)\n    assert cb.cmap is custom_cmap\n    assert cb.norm is custom_norm\n"], "sample_49": ["    def test_media_inheritance_with_custom_extend(self):\n        class MyWidget1(TextInput):\n            class Media:\n                css = {\n                    'all': ('path/to/css1', '/path/to/css2')\n                }\n                js = ('/path/to/js1', 'http://media.other.com/path/to/js2', 'https://secure.other.com/path/to/js3')\n\n        class MyWidget11(MyWidget1):\n            class Media:\n                extend = ('css',)\n                css = {\n                    'all': ('/path/to/css3', 'path/to/css1')\n                }\n                js = ('/path/to/js1', '/path/to/js4')\n\n        w11 = MyWidget11()\n        self.assertEqual(\n            str(w11.media),\n            \"\"\"<link href=\"/path/to/css3\" type=\"text/css\" media=\"all\" rel=\"stylesheet\">"], "sample_780": ["    def test_lda_partial_fit_reset(method):\n        # Test partial_fit resets internal state when called with new data\n        rng = np.random.RandomState(0)\n        n_components, X = _build_sparse_mtx()\n        lda = LatentDirichletAllocation(n_components=n_components,\n                                        learning_method=method,\n                                        total_samples=100,\n                                        random_state=rng)\n        lda.partial_fit(X)\n        lda.partial_fit(X)  # Second partial_fit with same data\n\n        # Check if perplexity is the same after two consecutive partial_fits\n        perp_1 = lda.perplexity(X, sub_sampling=False)\n        perp_2 = lda.perplexity(X, sub_sampling=False)\n        assert_almost_equal(perp_1, perp_2)\n"], "sample_131": ["    def test_clone_test_db(self, mocked_migrate, mocked_ensure_connection):\n        creation = connection.creation_class(connection)\n        saved_settings = copy.deepcopy(connection.settings_dict)\n        try:\n            connection.settings_dict['TEST'] = {'NAME': 'hodor'}\n            with mock.patch.object(creation, '_clone_test_db'):\n                creation.clone_test_db(suffix='_2', verbosity=0, autoclobber=True)\n            mocked_migrate.assert_not_called()\n        finally:\n            connection.settings_dict = saved_settings\n"], "sample_789": ["def test_sample_weight_classification():\n    # Check classification with sample weights.\n    X, y = datasets.make_classification(n_samples=100, n_features=20,\n                random_state=42)\n    sample_weight = np.random.rand(100)\n\n    clf = AdaBoostClassifier(random_state=0)\n    clf.fit(X, y, sample_weight=sample_weight)\n    assert_equal(len(clf.estimator_weights_), len(clf.estimators_))\n    assert_equal(len(clf.estimator_errors_), len(clf.estimators_))\n\n\n\n"], "sample_889": ["def test_calibration_with_non_calibrated_estimator(data):\n    class NonCalibratedClassifier(BaseEstimator):\n            pass\n\n            return np.ones((len(X), 2))\n\n    clf = NonCalibratedClassifier()\n    calibrated_clf = CalibratedClassifierCV(clf)\n    with pytest.raises(ValueError, match=\"The estimator does not have a \"\n                                        \"predict_proba method\"):\n        calibrated_clf.fit(*data)\n"], "sample_825": ["compilation error"], "sample_781": ["def test_forest_oob_score_with_sparse_data():\n    X = csr_matrix(np.random.rand(100, 10))\n    y = np.random.randint(0, 2, size=100)\n    clf = RandomForestClassifier(n_estimators=10, oob_score=True, random_state=42)\n    clf.fit(X, y)\n    assert hasattr(clf, 'oob_score_')\n    assert not np.isnan(clf.oob_score_)\n\n\n\n"], "sample_152": ["    def test_fast_delete_with_signals(self):\n        class SignalReceiver:\n                self.called = False\n\n                self.called = True\n\n        receiver = SignalReceiver()\n        models.signals.post_delete.connect(receiver, sender=R)\n\n        r = R.objects.create()\n        r.delete()\n\n        self.assertTrue(receiver.called)\n        self.assertFalse(R.objects.exists())\n"], "sample_904": ["def test_ref_to_nonexistent_label(app, status, warning):\n    text = (\".. _nonexistent: \\n\"\n            \"This is a reference to nonexistent label\\n\")\n    restructuredtext.parse(app, text)\n    assert (\"nonexistent.rst:2: WARNING: label 'nonexistent' not found\" in warning.getvalue())\n"], "sample_153": ["    def test_postgresql_check_constraints(self):\n        with mock.patch(\n            'django.db.backends.utils.CursorWrapper.fetchone', create=True,\n            return_value=('supports_table_check_constraints',)\n        ):\n            self.assertEqual(check_database_backends(databases=self.databases), [])\n\n        with mock.patch(\n            'django.db.backends.utils.CursorWrapper.fetchone', create=True,\n            return_value=('does_not_support_table_check_constraints',)\n        ):\n            result = check_database_backends(databases=self.databases)\n            self.assertEqual(len(result), 2)\n            self.assertEqual([r.id for r in result], ['postgresql.W027', 'postgresql.W027'])\n"], "sample_621": ["    def test_isel(self, indexes) -> None:\n        assert indexes.isel({\"x\": 1, \"y\": 0, \"z\": [0, 2]}) == {\n            \"x\": indexes[\"x\"][1],\n            \"y\": indexes[\"y\"][0],\n            \"z\": indexes[\"z\"][[0, 2]],\n        }\n\n        with pytest.raises(KeyError, match=r\"not all values found\"):\n            indexes.isel({\"x\": [0]})\n\n        with pytest.raises(KeyError):\n            indexes.isel({\"x\": 0})\n\n        with pytest.raises(ValueError, match=r\"cannot provide labels for both.*\"):\n            indexes.isel({\"x\": {\"one\": 0}, \"y\": 0})\n\n        with pytest.raises(ValueError, match=r\"invalid multi-index level names\"):\n            indexes.isel({\"z\": {\"three\": 0}})\n\n        with pytest.raises(IndexError):\n            indexes.isel({\"z\": slice(None, None, 2)})\n\n"], "sample_522": ["def test_colorbar_fractional_position():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc, fraction=0.1, pad=0.05)\n    fig.draw_without_rendering()\n    # check that the colorbar is the right size\n    assert cb.ax.get_position().width * fig.get_size_inches()[0] > 0.1 - 0.05\n    assert cb.ax.get_position().height * fig.get_size_inches()[1] > 0.1 - 0.05\n\n\n\n"], "sample_844": ["def test_xi_parameter():\n    # Test the xi parameter's effect on cluster identification\n    centers = [[1, 1], [-1, -1], [1, -1]]\n    X, labels_true = make_blobs(n_samples=750, centers=centers,\n                cluster_std=0.4, random_state=0)\n\n    # Test with xi=0.1\n    clust1 = OPTICS(min_samples=10, cluster_method='xi', xi=0.1).fit(X)\n    # Test with xi=0.3\n    clust2 = OPTICS(min_samples=10, cluster_method='xi', xi=0.3).fit(X)\n\n    # Check that xi=0.3 identifies more clusters\n    assert len(set(clust1.labels_)) < len(set(clust2.labels_))\n\n    # Check that xi=0.1 identifies fewer clusters\n    assert len(set(clust1.labels_)) < len(set(clust2.labels_))\n\n\n\n"], "sample_895": ["def test_column_transformer_with_custom_transformer():\n    class MyCustomTransformer(BaseEstimator):\n            return self\n\n            return X * 2\n\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame([[1, 2], [3, 4]], columns=[\"a\", \"b\"])\n    ct = ColumnTransformer(\n        [(\"custom\", MyCustomTransformer(), [\"a\"]), (\"passthrough\", \"passthrough\", [\"b\"])],\n    )\n    X_trans = ct.fit_transform(df)\n    assert_array_equal(X_trans, [[2, 2], [6, 8]])\n"], "sample_791": ["def test_one_hot_encoder_with_unknown_categories_and_handle_unknown_ignore():\n    enc = OneHotEncoder(handle_unknown='ignore')\n    X = [['abc', 2, 55], ['def', 1, 55], ['ghi', 3, 59]]\n    exp = np.array([[1., 0., 1., 1],\n                    [0., 1., 0., 1],\n                    [0., 0., 0., 0]])\n    assert_array_equal(enc.fit_transform(X).toarray(), exp)\n    assert_array_equal(enc.inverse_transform(enc.transform(X)).toarray(),\n                       X)\n\n    # Test with a pandas DataFrame\n    pd = pytest.importorskip('pandas')\n    X_df = pd.DataFrame({'A': ['abc', 'def', 'ghi'],\n                         'B': [2, 1, 3],\n                         'C': [55, 55, 59]})\n    enc = OneHotEncoder(handle_unknown='ignore')\n    exp_df = pd.DataFrame(exp, columns=['A_abc', 'A_def', 'B_2', 'B_1'])\n    assert_frame_equal(enc.fit_transform(X_df), exp_df)\n    assert_frame_equal(enc.inverse_transform(enc.transform(X_df)),\n                       X_df)\n\n\n\n"], "sample_539": ["def test_MultiCursor_reset(horizOn, vertOn):\n    (ax1, ax3) = plt.figure().subplots(2, sharex=True)\n    ax2 = plt.figure().subplots()\n\n    multi = widgets.MultiCursor(\n        None, (ax1, ax2), useblit=False, horizOn=horizOn, vertOn=vertOn\n    )\n\n    # mock a motion_notify_event\n    event = mock_event(ax1, xdata=.5, ydata=.25)\n    multi.onmove(event)\n\n    # force a draw + draw event to exercise clear\n    ax1.figure.canvas.draw()\n\n    # the lines in the first two ax should both move\n    for l in multi.vlines:\n        assert l.get_xdata() == (.5, .5)\n    for l in multi.hlines:\n        assert l.get_ydata() == (.25, .25)\n\n    multi.reset()\n    for l in multi.vlines:\n        assert l.get_xdata() == (0, 0)\n    for l in multi.hlines:\n        assert l.get_ydata() == (0, 0)\n"], "sample_331": ["    def test_invalid_iso_8601(self):\n        invalid_inputs = (\n            'P4Y2M',\n            'P4Y2M3D',\n            'P4Y2M3D1H',\n            'P4Y2M3D1H1M',\n            'P4Y2M3D1H1M1S.1',\n            'P4Y2M3D1H1M1S.123456789',\n            'P4Y2M3D1H1M1S.1234567890',\n            'P4Y2M3D1H1M1S.12345678901',\n            'P4Y2M3D1H1M1S.123456789012',\n            'P4Y2M3D1H1M1S.1234567890123',\n            'P4Y2M3D1H1M1S.12345678901234',\n            'P4Y2M3D1H1M1S.123456789012345',\n            'P4Y2M3D1H1M1S.1234567890123456',\n            'P4Y2M3D1H1M1S.12345678901234567',\n            'P4Y2M3D1H1M1S.123456789012345678',\n            'P4Y2M3D1H1M1S.1234567890123456789',\n            'P4Y2M3D1H1M1S.12345678901234567890',\n            'P4Y2M3D1H1M1S.1234567890123"], "sample_13": ["def test_angle_wrap_at_full_circle(value, expected_value):\n    angle = Angle(value, u.rad)\n    wrapped_angle = angle.wrap_at(2 * np.pi, inplace=False)\n    assert wrapped_angle.value == expected_value\n"], "sample_977": ["def test_user_functions():\n    known_functions = {\n        'my_func': [(lambda x: True, 'MyFunc')]\n    }\n    settings = {'user_functions': known_functions}\n    assert mcode(my_func(x), settings=settings) == \"MyFunc[x]\"\n"], "sample_534": ["def test_contour_with_masked_data():\n    x = np.arange(10)\n    y = np.arange(10)\n    X, Y = np.meshgrid(x, y)\n    z = np.sin(X * Y)\n    mask = np.zeros_like(z, dtype=bool)\n    mask[5, 5] = True\n    masked_z = np.ma.masked_array(z, mask=mask)\n\n    fig, ax = plt.subplots()\n    cs = ax.contour(X, Y, masked_z)\n    assert len(cs.collections) == 1\n    assert isinstance(cs.collections[0], LineCollection)\n    assert all(isinstance(line, Line2D) for line in cs.collections[0].get_segments())\n    ax.clabel(cs)\n"], "sample_321": ["    def test_csrf_token_on_500_stays_constant(self):\n        response = self.client.get('/internal_server_error/')\n        # The error handler returns status code 599.\n        self.assertEqual(response.status_code, 599)\n        token1 = response.content\n        response = self.client.get('/internal_server_error/')\n        self.assertEqual(response.status_code, 599)\n        token2 = response.content\n        self.assertTrue(equivalent_tokens(token1.decode('ascii'), token2.decode('ascii')))\n"], "sample_126": ["    def test_mti_inheritance_model_removal_with_fk(self):\n        \"\"\"\n        #23406 - Removing an MTI model with a FK to the base model\n        should delete the FK in the base model.\n        \"\"\"\n        Animal = ModelState('app', 'Animal', [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=100)),\n        ])\n        Dog = ModelState('app', 'Dog', [], bases=('app.Animal',),\n                        fields=[\n                            (\"breed\", models.CharField(max_length=100)),\n                        ])\n        changes = self.get_changes([Animal, Dog], [Animal])\n        self.assertNumberMigrations(changes, 'app', 1)\n        self.assertOperationTypes(changes, 'app', 0, ['DeleteModel', 'RemoveField'])\n        self.assertOperationAttributes(changes, 'app', 0, 0, name='Dog')\n        self.assertOperationAttributes(changes, 'app', 0, 1, name='Animal', field_name='dog')\n"], "sample_328": ["    def test_related_objects(self):\n        tags = self.create_tags()\n        notes = self.notes\n        for note, tag in zip(notes, tags):\n            note.tag = tag\n        with self.assertNumQueries(1):\n            Note.objects.bulk_update(notes, ['tag'])\n        self.assertSequenceEqual(Note.objects.filter(tag__isnull=False), notes)\n"], "sample_615": ["def test_cross_invalid_dims(use_dask) -> None:\n    if use_dask and not has_dask:\n        pytest.skip(\"requires dask\")\n\n    a = np.arange(30).reshape(3, 10)\n    b = np.arange(30).reshape(10, 3)\n\n    da_a = xr.DataArray(a, dims=[\"a\", \"b\"])\n    da_b = xr.DataArray(b, dims=[\"b\", \"a\"])\n\n    if use_dask:\n        da_a = da_a.chunk({\"a\": 2})\n        da_b = da_b.chunk({\"b\": 2})\n\n    with pytest.raises(ValueError, match=r\"Dimensions must be\"):\n        xr.cross(da_a, da_b, dim=\"c\")\n\n    with pytest.raises(ValueError, match=r\"Dimensions must be\"):\n        xr.cross(da_a, da_b, dim=[\"a\", \"b\"])\n\n    with pytest.raises(ValueError, match=r\"Dimensions must be\"):\n        xr.cross(da_a, da_b, dim=\"a\", axis=2)\n\n    with pytest.raises(ValueError, match=r\"Dimensions must be\"):\n        xr.cross(da_a, da_b, dim=\"b\", axis=2)\n\n    with pytest.raises(ValueError, match=r\"Dimensions must be\"):\n        xr.cross(da_a, da_b, dim=\"a\", axis=-3)\n\n    with pytest.raises(ValueError, match=r\"Dimensions must be\"):\n        xr.cross(da_a, da_b, dim=\"b\", axis=-3)\n\n\n\n"], "sample_70": ["    def test_fast_delete_with_related_objects(self):\n        a = Avatar.objects.create(desc='a')\n        u = User.objects.create(avatar=a)\n        # 1 query to delete the user\n        # 1 query to delete the avatar\n        self.assertNumQueries(2, u.delete)\n        self.assertFalse(User.objects.exists())\n        self.assertFalse(Avatar.objects.exists())\n"], "sample_1084": ["def test_issue_17356():\n    from sympy.abc import x, y\n    assert imageset(Lambda(x, x**2 + y**2), S.Reals) == S.Reals\n    assert imageset(Lambda(x, x**2 + y**2), S.Integers) == S.Integers\n    assert imageset(Lambda(x, x**2 + y**2), S.Naturals) == S.Naturals\n    assert imageset(Lambda(x, x**2 + y**2), S.Complexes) == S.Reals\n"], "sample_1157": ["def test_issue_19501_continued():\n    x = Symbol('x')\n    eq = parse_expr('E**(x*(1+x))', local_dict={'x': x}, transformations=(\n        standard_transformations +\n        (implicit_multiplication_application,)))\n    assert eq.free_symbols == {x}\n"], "sample_1114": ["def test_issue_18050_continued():\n    assert imageset(Lambda(x, 2*x + 3*I), S.Reals\n        ) == ImageSet(Lambda(x, 2*x + 3*I), S.Reals)\n    assert imageset(Lambda(x, 2*x + 3*I), S.Complexes\n        ) == ImageSet(Lambda(x, 2*x + 3*I), S.Complexes)\n"], "sample_353": ["    def test_create_permissions_with_custom_permissions(self):\n        \"\"\"\n        Custom permissions defined in the app's settings are created.\n        \"\"\"\n        custom_permissions = [\n            ('my_custom_permission', 'Some custom permission'),\n        ]\n        self.app_config.permissions = custom_permissions\n        permission_content_type = ContentType.objects.get_by_natural_key('auth', 'permission')\n\n        create_permissions(self.app_config, verbosity=0)\n\n        self.assertEqual(Permission.objects.filter(\n            content_type=permission_content_type,\n        ).count(), 1)\n        self.assertEqual(Permission.objects.filter(\n            content_type=permission_content_type,\n            codename='my_custom_permission',\n        ).count(), 1)\n\n\n\n"], "sample_204": ["    def test_loading_squashed_complex_multi_apps_partial_squash(self):\n        loader = MigrationLoader(connection)\n        recorder = MigrationRecorder(connection)\n        recorder.record_applied('app1', '1_auto')\n        recorder.record_applied('app1', '2_auto')\n        recorder.record_applied('app2', '1_squashed_2')\n        loader.build_graph()\n\n        plan = set(loader.graph.forwards_plan(('app1', '4_auto')))\n        plan = plan - loader.applied_migrations.keys()\n        expected_plan = {\n            ('app1', '3_auto'),\n            ('app1', '4_auto'),\n        }\n        self.assertEqual(plan, expected_plan)\n\n"], "sample_464": ["    def test_content_type_buffer_with_content_type_header(self):\n        response = FileResponse(io.BytesIO(b\"binary content\"), content_type=\"text/plain\")\n        self.assertEqual(response.headers[\"Content-Type\"], \"text/plain\")\n"], "sample_941": ["    def test_stringify_type_hints_typing_GenericMeta():\n        from typing import GenericMeta\n        class MyGenericMeta(GenericMeta):\n            pass\n        \n        class MyGenericClass(metaclass=MyGenericMeta):\n            T = TypeVar('T')\n                self.value = value\n        \n        assert stringify(MyGenericClass) == \"tests.test_util_typing.MyGenericClass\"\n        assert stringify(MyGenericClass[int]) == \"tests.test_util_typing.MyGenericClass[int]\"\n"], "sample_384": ["    def test_prefetch_related_with_bulk_update(self):\n        # Create some related objects\n        tags = [Tag.objects.create(name=str(i)) for i in range(10)]\n        notes = [Note.objects.create(note=str(i), misc=str(i)) for i in range(10)]\n        for note, tag in zip(notes, tags):\n            note.tag = tag\n        Note.objects.bulk_create(notes)\n\n        # Pre-fetch related objects\n        notes_with_prefetch = Note.objects.select_related(\"tag\").all()\n\n        # Update the notes\n        for note in notes_with_prefetch:\n            note.note = \"updated\"\n\n        # Bulk update the notes\n        Note.objects.bulk_update(notes_with_prefetch, [\"note\"])\n\n        # Assert that the notes are updated and the related tags are still present\n        for note in notes_with_prefetch:\n            self.assertEqual(note.note, \"updated\")\n            self.assertIsNotNone(note.tag)\n"], "sample_639": ["def test_base_checker_add_message() -> None:\n    checker = OtherBasicChecker()\n    checker.add_message(\n        \"W0001\",\n        line=10,\n        node=None,\n        args=(\"arg1\", \"arg2\"),\n        confidence=Confidence.HIGH,\n        col_offset=5,\n        end_lineno=12,\n        end_col_offset=10,\n    )\n    assert len(checker.linter.messages) == 1\n    assert checker.linter.messages[0].msgid == \"W0001\"\n    assert checker.linter.messages[0].line == 10\n    assert checker.linter.messages[0].col_offset == 5\n    assert checker.linter.messages[0].end_lineno == 12\n    assert checker.linter.messages[0].end_col_offset == 10\n    assert checker.linter.messages[0].args == (\"arg1\", \"arg2\")\n    assert checker.linter.messages[0].confidence == Confidence.HIGH\n\n\n\n"], "sample_184": ["    def test_unique_constraint_include_with_condition(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_include_id',\n                        condition=models.Q(age__gte=100),\n                        include=['id'],\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_partial_indexes else [\n            Warning(\n                '%s does not support unique constraints with conditions and '\n                'non-key columns.',\n                % connection.display_name,\n                hint=(\n                    \"A constraint won't be created. Silence this warning if \"\n                    \"you don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W040',\n            ),\n        ]\n        self.assertEqual(errors, expected)\n"], "sample_1131": ["compilation error"], "sample_458": ["    def test_floatformat_with_locale(self):\n        with translation.override(\"de\"):\n            self.assertEqual(floatformat(12345.6789, 2), \"12.345,68\")\n            self.assertEqual(floatformat(12345.6789, \"2u\"), \"12345,68\")\n            with self.settings(\n                USE_THOUSAND_SEPARATOR=True,\n                NUMBER_GROUPING=3,\n                THOUSAND_SEPARATOR=\"!\",\n            ):\n                self.assertEqual(floatformat(12345.6789, \"2gu\"), \"12!345,68\")\n                self.assertEqual(floatformat(12345.6789, \"2ug\"), \"12!345,68\")\n"], "sample_99": ["    def test_trunc_func_with_timezone_and_output_field(self):\n        start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n        end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n        start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n        end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n        self.create_model(start_datetime, end_datetime)\n        melb = pytz.timezone('Australia/Melbourne')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated_date=Trunc('start_datetime', 'day', output_field=DateField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(melb).date(), 'day')),\n                (end_datetime, truncate_to(end_datetime.astimezone(melb).date(), 'day')),\n            ],\n            lambda m: (m.start_datetime, m.truncated_date)\n        )\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated_time=Trunc('start_datetime', 'hour', output_field=TimeField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(melb).time(), 'hour')),\n                (end_datetime, truncate_to(end_datetime.astimezone(melb).time(), 'hour')),\n            ],\n            lambda m: (m.start_datetime, m.truncated_time)\n        )\n\n        with self.assertRaisesMessage(ValueError, \"Cannot truncate TimeField 'start_time' to DateField\"):\n            list(DTModel.objects.annotate(truncated=Trunc('start_time', 'year', output_field=DateField())))\n\n\n\n"], "sample_937": ["    def test_unparse_slice(source, expected):\n        module = ast.parse(source)\n        assert ast.unparse(module.body[0].value) == expected\n"], "sample_1154": ["def test__linsolve_non_homogeneous():\n    eqs = [\n        x + y + z == 1,\n        2*x - y + 3*z == 2,\n        x + 2*y - z == 3\n    ]\n    sol = {x:1, y:1, z:0}\n    assert _linsolve(eqs, [x, y, z]) == sol\n"], "sample_14": ["def test_angle_from_string_with_units():\n    \"\"\"\n    Test that Angle can be created from strings with units,\n    including those with non-standard unit abbreviations.\n    \"\"\"\n    # Test with standard unit abbreviations\n    a1 = Angle('10d', u.deg)\n    assert a1.value == 10.0\n    assert a1.unit == u.deg\n\n    a2 = Angle('1h', u.hourangle)\n    assert a2.value == 1.0\n    assert a2.unit == u.hourangle\n\n    # Test with non-standard unit abbreviations\n    a3 = Angle('10d', u.degree)\n    assert a3.value == 10.0\n    assert a3.unit == u.degree\n\n    a4 = Angle('1h', u.hour)\n    assert a4.value == 1.0\n    assert a4.unit == u.hour\n\n    # Test with mixed units\n    a5 = Angle('10d 20m 30s', u.deg)\n    assert a5.value == 10.347222222222222\n    assert a5.unit == u.deg\n\n    a6 = Angle('1h 20m 30s', u.hourangle)\n    assert a6.value == 1.3472222222222222\n    assert a6.unit == u.hourangle\n\n\n\n"], "sample_746": ["compilation error"], "sample_814": ["def test_gradient_boosting_with_missing_values():\n    # Test handling of missing values in both regression and classification\n    X, y = datasets.make_regression(n_samples=100, n_features=10,\n                                    random_state=0,\n                                    missing_values=np.nan)\n    X_with_missing = np.copy(X)\n    X_with_missing[np.random.choice(X_with_missing.shape[0],\n                                     size=10, replace=False),\n                   np.random.choice(X_with_missing.shape[1],\n                                     size=10, replace=False)] = np.nan\n\n    for estimator in (GradientBoostingClassifier(),\n                      GradientBoostingRegressor()):\n        # Test with missing values in the training data\n        estimator.fit(X_with_missing, y)\n        # Test with missing values in the test data\n        with pytest.raises(ValueError,\n                           match=\"Input contains missing values\"):\n            estimator.predict(X_with_missing)\n\n        # Test with missing values in both training and test data\n        with pytest.raises(ValueError,\n                           match=\"Input contains missing values\"):\n            estimator.predict(X_with_missing)\n\n\n\n"], "sample_509": ["compilation error"], "sample_608": ["    def test_repr_large_dataset(tmp_path) -> None:\n        n_vars = 100\n        n_coords = 50\n        n_attrs = 20\n        data = np.random.randn(100, 5, 1)\n        coords = {\n            f\"coord_{i}\": np.arange(100) for i in range(n_coords)\n        }\n        attrs = {f\"attr_{i}\": i for i in range(n_attrs)}\n\n        ds = xr.Dataset(\n            data_vars={\"var\": ((\"x\", \"y\", \"z\"), data)},\n            coords=coords,\n            attrs=attrs,\n        )\n        ds.to_netcdf(tmp_path / \"large_dataset.nc\", engine=\"netcdf4\")\n\n        with xr.open_dataarray(tmp_path / \"large_dataset.nc\") as ds:\n            actual = formatting.dataset_repr(ds)\n            assert \"Dimensions without coordinates\" in actual\n            assert \"Data variables\" in actual\n            assert \"Attributes\" in actual\n            assert \"Coordinates\" in actual\n"], "sample_748": ["def test_grid_search_with_custom_scorer_and_refit():\n    X, y = make_classification(n_samples=100, random_state=42)\n\n        return np.mean(y_true == y_pred)\n\n    param_grid = {'C': [0.1, 1, 10]}\n    grid_search = GridSearchCV(SVC(probability=False), param_grid,\n                              scoring=custom_scorer, refit=True)\n    grid_search.fit(X, y)\n\n    best_params = grid_search.best_params_\n    best_score = grid_search.best_score_\n\n    # Check if refit is working correctly\n    best_estimator = grid_search.best_estimator_\n    best_estimator.fit(X, y)\n    y_pred = best_estimator.predict(X)\n    assert_almost_equal(np.mean(y == y_pred), best_score)\n\n    # Check if the best parameters are correctly stored\n    assert_equal(best_params, grid_search.best_params_)\n"], "sample_601": ["def test_cftime_strftime_accessor(cftime_rounding_dataarray, cftime_date_type, use_dask):\n    import dask.array as da\n\n    date_format = \"%Y%m%d%H\"\n    expected = xr.DataArray(\n        [\n            [\n                cftime_date_type(1, 1, 1, 1).strftime(date_format),\n                cftime_date_type(1, 1, 1, 15).strftime(date_format),\n            ],\n            [\n                cftime_date_type(1, 1, 1, 23).strftime(date_format),\n                cftime_date_type(1, 1, 2, 1).strftime(date_format),\n            ],\n        ],\n        name=\"strftime\",\n    )\n\n    if use_dask:\n        chunks = {\"dim_0\": 1}\n        # Currently a compute is done to inspect a single value of the array\n        # if it is of object dtype to check if it is a cftime.datetime (if not\n        # we raise an error when using the dt accessor).\n        with raise_if_dask_computes(max_computes=1):\n            result = cftime_rounding_dataarray.chunk(chunks).dt.strftime(date_format)\n        expected = expected.chunk(chunks)\n        assert isinstance(result.data, da.Array)\n        assert result.chunks == expected.chunks\n    else:\n        result = cftime_rounding_dataarray.dt.strftime(date_format)\n\n    assert_identical(result, expected)\n"], "sample_145": ["    def test_actions_callable(self):\n        class BandAdmin(ModelAdmin):\n            actions = ('not_callable',)\n\n        self.assertIsInvalid(\n            BandAdmin, Band,\n            \"The value of 'actions[0]' must be a callable.\",\n            id='admin.E131',\n        )\n"], "sample_1020": ["def test_user_functions():\n        return x**2 + 1\n    settings = {'user_functions': {'my_func': my_func}}\n    assert mcode(my_func(x), **settings) == \"my_func[x]\"\n"], "sample_1072": ["def test_issue_11207_complex():\n    x, y = symbols('x y', complex=True)\n    assert floor(floor(ceiling(x**3 + y*I)/y)) == floor(ceiling(x**3 + y*I)/y)\n    assert ceiling(floor(ceiling(x**3 + y*I)/y)) == ceiling(floor(ceiling(x**3 + y*I)/y))\n    assert floor(ceiling(-floor(x**Rational(7, 2) + y*I)/y)) == -floor(x**Rational(7, 2) + y*I)/y\n    assert -ceiling(-ceiling(floor(x + y*I)/y)) == ceiling(floor(x + y*I)/y)\n"], "sample_228": ["    def test_all_valid_with_non_form_errors(self):\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '0',\n            'choices-MAX_NUM_FORMS': '1',\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': '0',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '1',\n        }\n        ChoiceFormSet = formset_factory(Choice, extra=1, max_num=1, validate_max=True)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [{}, {'non_form_errors': ['You may only specify a maximum of 1 form.']}]\n        self.assertEqual(formset1._errors, expected_errors)\n        self.assertEqual(formset2._errors, expected_errors)\n"], "sample_757": ["def test_one_hot_encoder_sparse_output():\n    X = np.array([['abc', 2, 55], ['def', 1, 55]])\n    enc = OneHotEncoder(sparse=True)\n    X_tr = enc.fit_transform(X)\n    assert isinstance(X_tr, sparse.csr_matrix)\n    assert X_tr.shape == (2, 6)\n\n    enc = OneHotEncoder(sparse=True, handle_unknown='ignore')\n    X_tr = enc.fit_transform(X)\n    assert isinstance(X_tr, sparse.csr_matrix)\n    assert X_tr.shape == (2, 6)\n"], "sample_764": ["def test_column_transformer_sparse_threshold_with_remainder():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder=SparseMatrixTrans(),\n                           sparse_threshold=0.5)\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n\n    #  SparseMatrixTrans creates 3 features for each column, thus:\n    assert X_trans.shape == (3, 3)\n    assert_array_equal(X_trans.toarray(), np.eye(3))\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], SparseMatrixTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n\n\n\n"], "sample_994": ["def test_issue_10679():\n    assert Float(1.23456789012345678901234567890123, 100) == Float(1.23456789012345678901234567890123)\n"], "sample_257": ["    def test_key_transform_with_subquery(self):\n        obj = NullableJSONModel.objects.create(value={'d': [{'f': 'g'}]})\n        subquery_obj = NullableJSONModel.objects.create(value={'d': [{'f': 'h'}]})\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(\n                value__d__0__f=KeyTransform('f', Subquery(\n                    NullableJSONModel.objects.filter(pk=OuterRef('pk')).values('value__d__0__f')\n                )),\n            ),\n            [obj],\n        )\n"], "sample_141": ["    def test_datetime_with_timezone(self):\n        dt = datetime.datetime(2023, 10, 26, 10, 30, 0, tzinfo=datetime.timezone.utc)\n        self.assertEqual(\n            json.dumps({'dt': dt}, cls=DjangoJSONEncoder),\n            '{\"dt\": \"2023-10-26T10:30:00+00:00\"}'\n        )\n"], "sample_494": ["    def test_serialize_custom_field(self):\n        class CustomField(models.Field):\n                super().__init__(*args, **kwargs)\n\n                return \"custom_field\"\n\n                return value\n\n                return value\n\n        class MyModel(models.Model):\n            my_field = CustomField()\n\n        string, imports = MigrationWriter.serialize(MyModel)\n        self.assertIn(\"CustomField\", string)\n        self.assertIn(\"from migrations.test_writer import CustomField\", imports)\n"], "sample_1066": ["def test_print_hypergeometric_2f1():\n    assert mathml(hypergeometric_2f1(a, b, c, x), printer='presentation') == \\\n        '<mrow><msub><mo>&#x222F;</mo><mn>2</mn></msub><mfenced><mrow><mi>a</mi><mo>,</mo><mi>b</mi><mo>;</mo><mi>c</mi><mo>;</mo><mi>x</mi></mrow></mfenced></mrow>'\n    assert mathml(hypergeometric_2f1(a, b, c, x, y), printer='presentation') == \\\n        '<mrow><msub><mo>&#x222F;</mo><mn>2</mn></msub><mfenced><mrow><mi>a</mi><mo>,</mo><mi>b</mi><mo>;</mo><mi>c</mi><mo>;</mo><mi>x</mi><mo>,</mo><mi>y</mi></mrow></mfenced></mrow>'\n"], "sample_74": ["    def test_empty_dbinfo(self):\n        self.assertEqual(\n            self._run_it({}), (\n                ['psql'],\n                {},\n            )\n        )\n"], "sample_61": ["    def test_username_validator_flags(self):\n        v_ascii = validators.ASCIIUsernameValidator()\n        v_unicode = validators.UnicodeUsernameValidator()\n\n        # Test with ASCII flag\n        with self.assertRaises(ValidationError):\n            v_ascii('\u00c9ric')\n        with self.assertRaises(ValidationError):\n            v_ascii('\u0623\u062d\u0645\u062f')\n\n        with self.assertRaises(ValidationError):\n            v_unicode('o\\'connell')\n        with self.assertRaises(ValidationError):\n            v_unicode('zerowidth\\u200Bspace')\n\n        # Test with Unicode flag\n        with self.assertRaises(ValidationError):\n            v_unicode('o\\'connell')\n        with self.assertRaises(ValidationError):\n            v_unicode('zerowidth\\u200Bspace')\n\n        with self.assertRaises(ValidationError):\n            v_ascii('\u00c9ric')\n        with self.assertRaises(ValidationError):\n            v_ascii('\u0623\u062d\u0645\u062f')\n"], "sample_926": ["compilation error"], "sample_43": ["def test_fitness_function_errors():\n    with pytest.raises(ValueError):\n        bayesian_blocks(t, fitness='events', p0=100)\n\n    with pytest.raises(ValueError):\n        bayesian_blocks(t, fitness='events', gamma=100)\n\n    with pytest.raises(ValueError):\n        bayesian_blocks(t, fitness='events', ncp_prior=100)\n\n    with pytest.raises(ValueError):\n        bayesian_blocks(t, fitness='regular_events', dt=-0.01)\n\n    with pytest.raises(ValueError):\n        bayesian_blocks(t, fitness='measures', p0=100)\n\n    with pytest.raises(ValueError):\n        bayesian_blocks(t, fitness='measures', gamma=100)\n\n    with pytest.raises(ValueError):\n        bayesian_blocks(t, fitness='measures', ncp_prior=100)\n"], "sample_1191": ["compilation error"], "sample_96": ["    def test_actions_callable(self):\n        class BandAdmin(ModelAdmin):\n            actions = ('not_callable',)\n\n        self.assertIsInvalid(\n            BandAdmin, Band,\n            \"The value of 'actions[0]' must be a callable.\",\n            id='admin.E128',\n        )\n"], "sample_158": ["    def test_non_unique_intersection_foreign_object(self):\n        class Parent(models.Model):\n            a = models.PositiveIntegerField()\n            b = models.PositiveIntegerField()\n            c = models.PositiveIntegerField()\n            d = models.PositiveIntegerField()\n\n        class Child(models.Model):\n            a = models.PositiveIntegerField()\n            b = models.PositiveIntegerField()\n            d = models.PositiveIntegerField()\n            value = models.CharField(max_length=255)\n            parent = models.ForeignObject(\n                Parent,\n                on_delete=models.SET_NULL,\n                from_fields=('a', 'b', 'd'),\n                to_fields=('a', 'b', 'd'),\n                related_name='children',\n            )\n\n        field = Child._meta.get_field('parent')\n        self.assertEqual(field.check(from_model=Child), [])\n"], "sample_102": ["    def test_union_with_distinct_and_ordering(self):\n        qs1 = Number.objects.filter(num__lte=1).values('num')\n        qs2 = Number.objects.filter(num__gte=2, num__lte=3).values('num')\n        self.assertNumbersEqual(qs1.union(qs2, all=True).order_by('num'), [1, 2, 3])\n\n"], "sample_352": ["    def test_ticket_24605_distinct_on_related_field(self):\n        \"\"\"\n        Test distinct on related field in subquery.\n        \"\"\"\n        a1 = Ticket23605A.objects.create()\n        a2 = Ticket23605A.objects.create()\n        c1 = Ticket23605C.objects.create(field_c0=10000.0)\n        Ticket23605B.objects.create(\n            modela_fk=a1, field_b0=10000.0,\n            field_b1=True,\n            modelc_fk=c1,\n        )\n        Ticket23605B.objects.create(\n            modela_fk=a2, field_b0=10000.0,\n            field_b1=True,\n            modelc_fk=c1,\n        )\n        qs = Ticket23605A.objects.filter(\n            Q(ticket23605b__modelc__field_c0=10000.0) &\n            Q(ticket23605b__pk__in=Ticket23605B.objects.order_by('modela_fk').distinct('modela_fk'))\n        )\n        self.assertSequenceEqual(qs, [a1, a2])\n"], "sample_815": ["def test_multilabel_jaccard_similarity_score_multiclass():\n    y_true = np.array([[0, 1, 1], [1, 0, 1], [0, 1, 0]])\n    y_pred = np.array([[0, 1, 1], [1, 0, 1], [0, 1, 1]])\n    score = jaccard_similarity_score(y_true, y_pred, average='micro')\n    assert_almost_equal(score, 0.66666667)\n\n    score = jaccard_similarity_score(y_true, y_pred, average='macro')\n    assert_almost_equal(score, 0.66666667)\n\n    score = jaccard_similarity_score(y_true, y_pred, average='samples')\n    assert_almost_equal(score, np.array([0.66666667, 0.66666667, 0.5]))\n"], "sample_1189": ["def test_issue_23711():\n    if not scipy:\n        skip(\"scipy not installed\")\n    x = symbols('x')\n    f = lambdify(x, scipy.special.erf(x), modules='scipy')\n    assert abs(f(0) - 0) < 1e-10\n    assert abs(f(1) - 0.842700793) < 1e-10\n"], "sample_189": ["    def test_cache_key_with_user_and_language(self):\n        request = self.factory.get(self.path)\n        request.user = User.objects.create_user('testuser', 'test@example.com')\n        translation.activate('es')\n        template = engines['django'].from_string(\"This is a test\")\n        response = TemplateResponse(request, template)\n        key = get_cache_key(request)\n        self.assertEqual(\n            key,\n            'views.decorators.cache.cache_page.settingsprefix.GET.'\n            'user_testuser_lang_es.d41d8cd98f00b204e9800998ecf8427e'\n        )\n"], "sample_281": ["    def test_custom_to_field_with_related_model_pk(self):\n        q = Question.objects.create(question='Is this a question?')\n        opts = {\n            'app_label': Question._meta.app_label,\n            'model_name': Question._meta.model_name,\n            'field_name': 'related_questions',\n        }\n        request = self.factory.get(self.url, {'term': 'is', **opts})\n        request.user = self.superuser\n        response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n        self.assertEqual(response.status_code, 200)\n        data = json.loads(response.content.decode('utf-8'))\n        self.assertEqual(data, {\n            'results': [{'id': str(q.big_id), 'text': q.question}],\n            'pagination': {'more': False},\n        })\n"], "sample_846": ["def test_column_transformer_sparse_remainder_with_remainder_transformer():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).astype('float').T\n    ct = ColumnTransformer([('trans1', StandardScaler(), [0])],\n                           remainder=SparseMatrixTrans(),\n                           sparse_threshold=0.8)\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n    assert X_trans.shape == (3, 3)\n    assert_array_equal(X_trans.toarray(), np.eye(3))\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], SparseMatrixTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n\n\n\n"], "sample_1104": ["def test_issue_15678():\n    from sympy.functions import exp, sin\n    assert str(exp(sin(x))) == 'exp(sin(x))'\n"], "sample_4": ["    def test_readwrite_html_table_metadata(self, cosmo, read, write, tmp_path, add_cu):\n        \"\"\"Test if metadata is read and written correctly.\"\"\"\n        fp = tmp_path / \"test_readwrite_html_table_metadata.html\"\n\n        # Write with metadata\n        write(fp, format=\"ascii.html\", metadata={\"key\": \"value\"})\n\n        # Read and check metadata\n        got = read(fp, format=\"ascii.html\")\n        assert got.meta == {\"key\": \"value\"}\n\n        # Write with metadata from cosmology\n        write(fp, format=\"ascii.html\", cosmology=cosmo)\n        got = read(fp, format=\"ascii.html\")\n        assert got.meta == cosmo.meta\n\n        # Test that metadata is not overwritten\n        got.meta[\"new_key\"] = \"new_value\"\n        write(fp, format=\"ascii.html\", cosmology=got)\n        got2 = read(fp, format=\"ascii.html\")\n        assert got2.meta == {\"key\": \"value\", \"new_key\": \"new_value\"}\n"], "sample_442": ["    def test_compress(self):\n        signer = signing.Signer(key=\"predictable-secret\")\n        data = b\"This is a long string that should be compressed\"\n        compressed_signed = signer.sign_object(data, compress=True)\n        uncompressed_signed = signer.sign_object(data, compress=False)\n        self.assertTrue(compressed_signed.startswith(\".\"))\n        self.assertFalse(uncompressed_signed.startswith(\".\"))\n        self.assertEqual(signer.unsign_object(compressed_signed), data)\n        self.assertEqual(signer.unsign_object(uncompressed_signed), data)\n        # Check that compression actually saves space\n        self.assertLess(len(compressed_signed), len(uncompressed_signed))\n"], "sample_33": ["def test_OrderedDescriptorContainer():\n    class TypedAttribute(OrderedDescriptor):\n        _class_attribute_ = 'typed_attributes'\n        _name_attribute_ = 'name'\n\n    class Point2D(metaclass=OrderedDescriptorContainer):\n        x = TypedAttribute((float, int))\n        y = TypedAttribute((float, int))\n\n    p1 = Point2D(1.0, 2.0)\n    assert isinstance(p1.typed_attributes, OrderedDict)\n    assert len(p1.typed_attributes) == 2\n    assert p1.typed_attributes['x'].name == 'x'\n    assert p1.typed_attributes['y'].name == 'y'\n\n    class Point3D(Point2D):\n        z = TypedAttribute((float, int))\n\n    p2 = Point3D(1.0, 2.0, 3.0)\n    assert isinstance(p2.typed_attributes, OrderedDict)\n    assert len(p2.typed_attributes) == 3\n    assert p2.typed_attributes['x'].name == 'x'\n    assert p2.typed_attributes['y'].name == 'y'\n    assert p2.typed_attributes['z'].name == 'z'\n\n    # Test _inherit_descriptors_\n    class Point3D_Inherit(Point2D):\n        _inherit_descriptors_ = (TypedAttribute,)\n        z = TypedAttribute((float, int))\n\n    p3 = Point3D_Inherit(1.0, 2.0, 3.0)\n    assert isinstance(p3.typed_attributes, OrderedDict)\n    assert len(p3.typed_attributes) == 3\n    assert p3.typed_attributes['x'].name == 'x'\n    assert p3.typed_attributes['y'].name == 'y'\n    assert p3.typed_attributes['z'].name == 'z'\n\n\n\n"], "sample_86": ["    def test_keep_lazy_no_lazy_args(self):\n        @keep_lazy_text\n            return a + b\n\n        self.assertEqual(my_func('hello', 'world'), 'helloworld')\n"], "sample_249": ["    def test_clone_test_db(self, mocked_sync_apps, mocked_migrate, *mocked_objects):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        creation = test_connection.creation_class(test_connection)\n        if connection.vendor == 'oracle':\n            # Don't close connection on Oracle.\n            creation.connection.close = mock.Mock()\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db'):\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n            # Migrations run.\n            mocked_migrate.assert_called()\n            args, kwargs = mocked_migrate.call_args\n            self.assertEqual(args, ([('app_unmigrated', '0001_initial')],))\n            self.assertEqual(len(kwargs['plan']), 1)\n            # App is not synced.\n            mocked_sync_apps.assert_not_called()\n            creation.clone_test_db(suffix='_clone', verbosity=0)\n            # Migrations run again for the clone.\n            mocked_migrate.assert_called_with(\n                [],\n                **kwargs\n            )\n            args, kwargs = mocked_migrate.call_args\n            self.assertEqual(args, ([('app_unmigrated', '0001_initial')],))\n            self.assertEqual(len(kwargs['plan']), 1)\n            # App is not synced.\n            mocked_sync_apps.assert_not_called()\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n"], "sample_1203": ["def test_orbit_homomorphism():\n    from sympy.combinatorics import Permutation\n    from sympy.combinatorics.perm_groups import PermutationGroup\n    from sympy.combinatorics.homomorphisms import orbit_homomorphism\n\n    G = PermutationGroup([Permutation(0, 1, 2), Permutation(0, 2, 1)])\n    omega = [0, 1, 2]\n    H = orbit_homomorphism(G, omega)\n    assert H.domain == G\n    assert H.codomain == PermutationGroup(len(omega))\n    assert H.is_injective()\n    assert H.is_surjective()\n    assert H.is_isomorphism()\n\n    G = PermutationGroup([Permutation(0, 1, 2), Permutation(0, 2, 1)])\n    omega = [0, 1, 2, 3]\n    H = orbit_homomorphism(G, omega)\n    assert H.domain == G\n    assert H.codomain == PermutationGroup(len(omega))\n    assert H.is_injective()\n    assert H.is_surjective()\n    assert H.is_isomorphism()\n\n    G = PermutationGroup([Permutation(0, 1), Permutation(1, 2)])\n    omega = [0, 1, 2]\n    H = orbit_homomorphism(G, omega)\n    assert H.domain == G\n    assert H.codomain == PermutationGroup(len(omega))\n    assert H.is_injective()\n    assert H.is_surjective()\n    assert H.is_isomorphism()\n\n    G = PermutationGroup([Permutation(0, 1, 2), Permutation(0, 2, 1)])\n    omega = [0, 1, 2, 3]\n    H = orbit_homomorphism(G, omega)\n    assert H.domain == G\n    assert H.codomain == PermutationGroup(len(omega))\n    assert H.is_injective()\n    assert H.is_surjective()\n    assert H.is_isomorphism()\n\n    G = PermutationGroup([Permutation(0, 1, 2), Permutation(0, 2"], "sample_359": ["    def test_references_field_by_related_name(self):\n        operation = FieldOperation('Model', 'field', models.ForeignKey('Other', models.CASCADE, related_name='related_field'))\n        self.assertIs(operation.references_field('Other', 'related_field', 'migrations'), True)\n        self.assertIs(operation.references_field('Other', 'whatever', 'migrations'), False)\n"], "sample_484": ["    def test_negative_length(self):\n        with self.assertRaisesMessage(ValueError, \"'length' must be greater than 0\"):\n            Author.objects.annotate(raises=Right(\"name\", -1))\n"], "sample_34": ["def test_unit_summary_table():\n    from .. import astrophys\n    from ...tests.helper import assert_follows_unicode_guidelines\n\n    for unit_name, unit in astrophys.__dict__.items():\n        if isinstance(unit, u.UnitBase):\n            summary = utils._unit_summary(unit)\n            assert_follows_unicode_guidelines(summary)\n"], "sample_298": ["    def test_token_with_different_algorithm(self):\n        user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n        p0 = PasswordResetTokenGenerator()\n        p0.algorithm = 'sha512'\n        tk0 = p0.make_token(user)\n        p1 = PasswordResetTokenGenerator()\n        p1.algorithm = 'sha256'\n        tk1 = p1.make_token(user)\n        self.assertNotEqual(tk0, tk1)\n        self.assertIs(p0.check_token(user, tk0), True)\n        self.assertIs(p1.check_token(user, tk1), True)\n"], "sample_243": ["    def test_filter_with_related_fields(self):\n        query = Query(Item)\n        where = query.build_where(Q(creator__name__icontains='foo'))\n        lookup = where.children[0]\n        self.assertIsInstance(lookup, Q)\n        self.assertEqual(lookup.children[0].connector, OR)\n        self.assertIsInstance(lookup.children[0].children[0], Exact)\n        self.assertEqual(lookup.children[0].children[0].lhs.target, Item._meta.get_field('creator'))\n        self.assertEqual(lookup.children[0].children[0].rhs, 'foo')\n"], "sample_1050": ["def test_NumPyPrinter_print_MatrixBase():\n    n = NumPyPrinter()\n    A = MatrixSymbol(\"A\", 2, 2)\n    assert n.doprint(A) == 'numpy.array([[None, None], [None, None]])'\n"], "sample_769": ["def test_balanced_accuracy_score_with_multiclass_labels():\n    y_true = np.array([0, 1, 2, 0, 1, 2])\n    y_pred = np.array([0, 1, 2, 0, 1, 2])\n    balanced = balanced_accuracy_score(y_true, y_pred)\n    assert_almost_equal(balanced, 1.0)\n\n    y_true = np.array([0, 1, 2, 0, 1, 2])\n    y_pred = np.array([0, 0, 2, 0, 1, 2])\n    balanced = balanced_accuracy_score(y_true, y_pred)\n    assert_almost_equal(balanced, 0.8333)\n\n    y_true = np.array([0, 1, 2, 0, 1, 2])\n    y_pred = np.array([0, 1, 1, 0, 1, 2])\n    balanced = balanced_accuracy_score(y_true, y_pred)\n    assert_almost_equal(balanced, 0.8333)\n\n    y_true = np.array([0, 1, 2, 0, 1, 2])\n    y_pred = np.array([0, 1, 1, 0, 0, 2])\n    balanced = balanced_accuracy_score(y_true, y_pred)\n    assert_almost_equal(balanced, 0.6667)\n\n\n\n"], "sample_933": ["def test_gettext_additional_targets(app):\n    app.builder.build_all()\n\n    assert (app.outdir / 'extapi.pot').isfile()\n    assert (app.outdir / 'subdir.pot').isfile()\n    assert (app.outdir / 'markup.pot').isfile()\n    assert (app.outdir / 'index_entries.pot').isfile()\n"], "sample_193": ["    def test_proxy_with_fk_to_base(self):\n        A = self.create_model(\"A\")\n        B = self.create_model(\"B\", bases=(A,), proxy=True)\n        C = self.create_model(\"C\", foreign_keys=[models.ForeignKey('B', models.CASCADE)])\n        self.assertRelated(A, [B, C])\n        self.assertRelated(B, [C])\n        self.assertRelated(C, [B])\n\n\n\n"], "sample_1098": ["def test_meijerg_as_hyper():\n    from sympy import meijerg, hyper, symbols\n    a, b, c, d, x = symbols('a b c d x')\n    assert meijerg([], [a], [b], [c], x).as_hyper() == \\\n        hyper([a], [b, c], x)\n    assert meijerg([a], [], [b], [c], x).as_hyper() == \\\n        hyper([a], [b, c], x)\n    assert meijerg([], [], [a], [b], x).as_hyper() == \\\n        hyper([], [a, b], x)\n    assert meijerg([a], [b], [c], [d], x).as_hyper() == \\\n        hyper([a], [b, c, d], x)\n    assert meijerg([a, b], [c], [d], [e], x).as_hyper() == \\\n        hyper([a, b], [c, d, e], x)\n    assert meijerg([a, b], [c, d], [e, f], [g], x).as_hyper() == \\\n        hyper([a, b], [c, d, e, f, g], x)\n\n\n\n"], "sample_186": ["    def test_list_filter_works_on_through_field_with_custom_through_model(self):\n        class CustomThroughModel(models.Model):\n            book = models.ForeignKey(Book, on_delete=models.CASCADE)\n            author = models.ForeignKey(Author, on_delete=models.CASCADE)\n            featured = models.BooleanField(default=False)\n\n        class BookAdminWithCustomThrough(admin.ModelAdmin):\n            list_filter = ['authorsbooks__featured']\n\n        Book.authorsbooks = models.ManyToManyField(\n            Author, through=CustomThroughModel\n        )\n        try:\n            errors = BookAdminWithCustomThrough(Book, AdminSite()).check()\n            self.assertEqual(errors, [])\n        finally:\n            Book.authorsbooks = models.ManyToManyField(Author)\n\n\n\n"], "sample_831": ["def test_export_text_multi_output():\n    clf = DecisionTreeClassifier(max_depth=2, random_state=0, n_jobs=-1)\n    X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n    y = [[0, 1], [1, 0], [0, 1], [1, 0]]\n    clf.fit(X, y)\n\n    expected_report = dedent(\"\"\"\n    |--- feature_0 <= 3.5\n    |   |--- weights: [0.5, 0.5] class: [0, 1]\n    |--- feature_0 >  3.5\n    |   |--- weights: [0.5, 0.5] class: [1, 0]\n    \"\"\").lstrip()\n    assert export_text(clf, show_weights=True) == expected_report\n"], "sample_232": ["    def test_contains_contained_by_with_key_transform_invalid(self):\n        tests = [\n            ('value__d__contains', 'e', 'value__d__contains', 'e'),\n            ('value__d__contains', [{'f': 'g'}], 'value__d__contains', [{'f': 'g'}]),\n            ('value__contains', KeyTransform('baz', 'value'), 'value__contains', KeyTransform('baz', 'value')),\n            ('value__baz__contains', {'a': 'b'}, 'value__baz__contains', {'a': 'b'}),\n            ('value__baz__contained_by', {'a': 'b', 'c': 'd', 'e': 'f'}, 'value__baz__contained_by', {'a': 'b', 'c': 'd', 'e': 'f'}),\n            (\n                'value__contained_by',\n                KeyTransform('x', RawSQL(\n                    self.raw_sql,\n                    ['{\"x\": {\"a\": \"b\", \"c\": 1, \"d\": \"e\"}}'],\n                )),\n                'value__contained_by',\n                KeyTransform('x', RawSQL(\n                    self.raw_sql,\n                    ['{\"x\": {\"a\": \"b\", \"c\": 1, \"d\": \"e\"}}'],\n                )),\n            ),\n        ]\n        for lookup, value, expected_lookup, expected_value in tests:\n            with self.subTest(lookup=lookup, value=value):\n                self.assertIs(NullableJSONModel.objects.filter(\n                    **{lookup: value},\n                ).exists(), True)\n                self.assertIs(NullableJSONModel.objects.filter(\n                    **{expected_lookup: expected_value},\n                ).exists(), True)\n"], "sample_662": ["    def test_report_to_json_with_user_properties(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n                assert False\n            \"\"\"\n        )\n        reprec = testdir.inline_run(\n            \"--userprop1=value1 --userprop2=value2\"\n        )\n        reports = reprec.getreports(\"pytest_runtest_logreport\")\n        assert len(reports) == 3\n        test_a_call = reports[1]\n        data = test_a_call._to_json()\n        assert data[\"user_properties\"] == [\n            {\"name\": \"user_prop1\", \"value\": \"value1\"},\n            {\"name\": \"user_prop2\", \"value\": \"value2\"},\n        ]\n"], "sample_1089": ["compilation error"], "sample_922": ["    def test_pyfunction_signature_full_py38(app):\n        # case: separator at head\n        text = \".. py:function:: hello(*, a)\"\n        doctree = restructuredtext.parse(app, text)\n        assert_node(doctree[1][0][1],\n                    [desc_parameterlist, ([desc_parameter, desc_sig_operator, \"*\"],\n                    [desc_parameter, desc_sig_name, \"a\"])])\n\n        # case: separator in the middle\n        text = \".. py:function:: hello(a, /, b, *, c)\"\n        doctree = restructuredtext.parse(app, text)\n        assert_node(doctree[1][0][1],\n                    [desc_parameterlist, ([desc_parameter, desc_sig_name, \"a\"],\n                    [desc_parameter, desc_sig_operator, \"/\"],\n                    [desc_parameter, desc_sig_name, \"b\"],\n                    [desc_parameter, desc_sig_operator, \"*\"],\n                    [desc_parameter, desc_sig_name, \"c\"])])\n\n        # case: separator in the middle (2)\n        text = \".. py:function:: hello(a, /, *, b)\"\n        doctree = restructuredtext.parse(app, text)\n        assert_node(doctree[1][0][1],\n                    [desc_parameterlist, ([desc_parameter, desc_sig_name, \"a\"],\n                    [desc_parameter, desc_sig_operator, \"/\"],\n                    [desc_parameter, desc_sig_operator, \"*\"],\n                    [desc_parameter, desc_sig_name, \"b\"])])\n\n        # case: separator at tail\n        text = \".. py:function:: hello(a, /)\"\n        doctree = restructuredtext.parse(app, text)\n        assert_node(doctree[1][0][1],\n                    [desc_parameterlist, ([desc_parameter, desc_sig_name, \"a\"],\n                    [desc_parameter, desc_sig_operator,"], "sample_1115": ["def test_tensor_index_type_with_dummy_name():\n    with warns_deprecated_sympy():\n        L = TensorIndexType(\"L\", dummy_name=\"dummy_L\")\n        assert L.dummy_name == \"dummy_L\"\n        assert L.name == \"L\"\n"], "sample_479": ["    def test_rename_unique_together(self):\n        self.assertOptimizesTo(\n            [\n                migrations.RenameUniqueTogether(\n                    \"Pony\",\n                    new_name=\"new_name\",\n                    old_name=\"old_name\",\n                    fields=(\"weight\", \"pink\"),\n                ),\n                migrations.RenameUniqueTogether(\n                    \"Pony\",\n                    new_name=\"new_name\",\n                    old_name=\"mid_name\",\n                    fields=(\"weight\", \"pink\"),\n                ),\n            ],\n            [\n                migrations.RenameUniqueTogether(\n                    \"Pony\",\n                    new_name=\"new_name\",\n                    fields=(\"weight\", \"pink\"),\n                ),\n            ],\n        )\n        self.assertOptimizesTo(\n            [\n                migrations.RenameUniqueTogether(\n                    \"Pony\",\n                    new_name=\"mid_name\",\n                    old_name=\"old_name\",\n                    fields=(\"weight\", \"pink\"),\n                ),\n                migrations.RenameUniqueTogether(\n                    \"Pony\",\n                    new_name=\"new_name\",\n                    old_name=\"mid_name\",\n                    fields=(\"weight\", \"pink\"),\n                ),\n            ],\n            [\n                migrations.RenameUniqueTogether(\n                    \"Pony\", new_name=\"new_name\", fields=(\"weight\", \"pink\")\n                ),\n            ],\n        )\n        self.assertDoesNotOptimize(\n            [\n                migrations.RenameUniqueTogether(\n                    \"Pony\",\n                    new_name=\"mid_name\",\n                    old_name=\"old_name\",\n                    fields=(\"weight\", \"pink\"),\n                ),\n                migrations.RenameUniqueTogether(\n                    \"Pony\",\n                    new_name=\"new_name\",\n                    old_fields=(\"weight\", \"pink\"),\n                ),\n            ]\n        )\n"], "sample_363": ["    def test_ManyToMany_using_to_field(self):\n        from selenium.webdriver.common.by import By\n        self.admin_login(username='super', password='secret', login_url='/')\n        self.selenium.get(self.live_server_url + reverse('admin:admin_widgets_profile_add'))\n\n        main_window = self.selenium.current_window_handle\n        # Click the Add User button to add new\n        self.selenium.find_element(By.ID, 'add_id_user').click()\n        self.wait_for_and_switch_to_popup()\n        password_field = self.selenium.find_element(By.ID, 'id_password')\n        password_field.send_keys('password')\n\n        username_field = self.selenium.find_element(By.ID, 'id_username')\n        username_value = 'newuser'\n        username_field.send_keys(username_value)\n\n        save_button_css_selector = '.submit-row > input[type=submit]'\n        self.selenium.find_element(By.CSS_SELECTOR, save_button_css_selector).click()\n        self.selenium.switch_to.window(main_window)\n        # The field now contains the new user\n        self.selenium.find_element(By.CSS_SELECTOR, '#id_user option[value=newuser]')\n\n        # Click the Change User button to change it\n        self.selenium.find_element(By.ID, 'change_id_user').click()\n        self.wait_for_and_switch_to_popup()\n\n        username_field = self.selenium.find_element(By.ID, 'id_username')\n        username_value = 'changednewuser'\n        username_field.clear()\n        username_field.send_keys(username_value)\n\n        save_button_css_selector = '.submit-row > input[type=submit]'\n        self.selenium.find_element(By.CSS_SELECTOR, save_button_css_selector).click()\n        self.selenium.switch_to.window(main_window)\n        self.selenium.find_element(By.CSS_SELECT"], "sample_282": ["    def test_label_tag(self):\n        form = ComplexFieldForm()\n        self.assertHTMLEqual(\n            form.fields['field1'].label_tag(),\n            '<label for=\"id_field1\">Field1:</label>',\n        )\n        self.assertHTMLEqual(\n            form.fields['field1'].label_tag(contents='My Field'),\n            '<label for=\"id_field1\">My Field:</label>',\n        )\n        self.assertHTMLEqual(\n            form.fields['field1'].label_tag(contents='My Field', label_suffix='!'),\n            '<label for=\"id_field1\">My Field!</label>',\n        )\n        self.assertHTMLEqual(\n            form.fields['field1'].label_tag(attrs={'class': 'my-label'}),\n            '<label class=\"my-label\" for=\"id_field1\">Field1:</label>',\n        )\n"], "sample_1073": ["def test_issue_14186():\n    assert sqrtdenest(sqrt(2 + sqrt(2 + sqrt(2)))) == sqrt(2 + sqrt(2 + sqrt(2)))\n"], "sample_602": ["def test_to_netcdf_with_compute_false():\n    ds = xr.Dataset(\n        data_vars={\"a\": ((\"x\", \"y\"), np.arange(12).reshape(3, 4))},\n        coords={\"x\": np.arange(3), \"y\": np.arange(4)},\n    )\n\n        assert isinstance(result, dask.delayed.Delayed)\n        result = result.compute()\n        assert isinstance(result, bytes)\n        assert len(result) > 0\n\n    result = to_netcdf(ds, mode=\"w\", compute=False)\n    _check_delayed_result(result)\n"], "sample_1043": ["def test_user_functions():\n    from sympy import symbols, sin, cos\n\n        return x**2 + y**2\n\n    known_functions = {\n        'my_func': [(lambda x, y: True), my_func]\n    }\n    p = MCodePrinter(known_functions=known_functions)\n    assert p.doprint(my_func(x, y)) == \"my_func[x, y]\"\n"], "sample_1136": ["def test_issue_20138():\n    p = Poly(x**2 + y**2, x, y)\n    assert p.as_expr() == x**2 + y**2\n"], "sample_1138": ["compilation error"], "sample_778": ["def test_nmf_sparse_input_with_custom_init():\n    # Smoke test for sparse input with custom initialization\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(rng.randn(10, 5))\n    A[:, 2 * np.arange(5)] = 0\n    A_sparse = csc_matrix(A)\n\n    W_init = np.abs(rng.randn(10, 3))\n    H_init = np.abs(rng.randn(3, 5))\n\n    for solver in ('cd', 'mu'):\n        model = NMF(solver=solver, random_state=0, n_components=3,\n                    max_iter=400)\n        model.fit_transform(A_sparse, W=W_init, H=H_init)\n        assert_array_almost_equal(model.components_, H_init, decimal=10)\n        assert_array_almost_equal(model.transform(A_sparse),\n                                  model.fit_transform(A_sparse,\n                                                     W=W_init,\n                                                     H=H_init),\n                                  decimal=10)\n\n\n\n"], "sample_929": ["def test_pyexception_signature_with_args(app):\n    text = (\".. py:exception:: MyException\\n\"\n            \"   :args:\\n\"\n            \"       arg1: int\\n\"\n            \"       arg2: str\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"exception \"],\n                                                    [desc_name, \"MyException\"])],\n                                  [desc_content, (addnodes.index,\n                                                  desc)])]))\n    assert_node(doctree[1][0][1], addnodes.index,\n                entries=[('single', 'MyException (built-in exception)', 'MyException', '', None)])\n    assert_node(doctree[1][0][2], addnodes.index,\n                entries=[('pair', 'arg1: int', 'arg1', '', None),\n                         ('pair', 'arg2: str', 'arg2', '', None)])\n\n\n\n"], "sample_25": ["    def test_header_append_with_duplicate_keywords(self):\n        h = fits.Header()\n        h.append(\"FOO = 1\")\n        h.append(\"FOO = 2\")\n        assert h[\"FOO\"] == 2.0\n        assert h.comments[\"FOO\"] == \"no comment\"\n\n"], "sample_506": ["def test_circular_spine():\n    fig, ax = plt.subplots()\n    ax.spines['top'].set_patch_circle((0.5, 0.5), 0.3)\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n"], "sample_1100": ["def test_issue_18507_cont():\n    assert Mul(zoo, zoo, evaluate=False) is nan\n    assert Mul(zoo, zoo, evaluate=True) is nan\n    assert Mul(zoo, zoo, evaluate=False,  simplify=False) is nan\n    assert Mul(zoo, zoo, evaluate=True, simplify=False) is nan\n"], "sample_379": ["    def test_mark_safe_with_unicode_characters(self):\n        s = mark_safe('a\\u00e4b')\n        self.assertRenderEqual('{{ s }}', 'a\\u00e4b', s=s)\n"], "sample_1037": ["def test_transpose_simplify():\n    A = MatrixSymbol('A', 3, 2)\n    B = MatrixSymbol('B', 2, 3)\n    assert (A.T * B).simplify() == (B.T * A).simplify()\n    assert (A.T * A.T).simplify() == (A * A.T).simplify()\n    assert (A.T * B.T).simplify() == (B * A).simplify()\n    assert (A.T * A).simplify() == (A * A.T).simplify()\n    assert (A.T * ZeroMatrix(2, 3)).simplify() == ZeroMatrix(3, 3)\n    assert (ZeroMatrix(3, 2) * A.T).simplify() == ZeroMatrix(3, 2)\n    assert (A.T * Identity(2)).simplify() == A.T\n    assert (Identity(3) * A.T).simplify() == A.T\n"], "sample_276": ["    def test_simplify_regex_with_groups(self):\n        tests = (\n            (r'^/admin/(?P<app_label>\\w+)/(?P<model_name>\\w+)/$', '/admin/<app_label>/<model_name>/'),\n            (r'^/admin/(?P<app_label>\\w+)/(?P<model_name>\\w+)/(?P<id>\\d+)$', '/admin/<app_label>/<model_name>/<id>'),\n        )\n        for pattern, output in tests:\n            with self.subTest(pattern=pattern):\n                self.assertEqual(simplify_regex(pattern), output)\n"], "sample_488": ["    def test_namespace_package_with_subpackages(self):\n        \"\"\"\n        A namespace package with subpackages can be an app if it has only one path.\n        \"\"\"\n        with extend_sys_path(os.path.join(self.base_location, \"sub\")):\n            with self.settings(INSTALLED_APPS=[\"nsapp.sub\"]):\n                app_config = apps.get_app_config(\"nsapp.sub\")\n                self.assertEqual(app_config.path, os.path.join(self.app_path, \"sub\"))\n"], "sample_89": ["    def test_should_stop_returns_false_if_no_changes(self):\n        with mock.patch.object(self.reloader, 'snapshot_files', return_value={self.existing_file: 123}) as mocked_snapshot:\n            self.assertFalse(self.reloader.should_stop())\n            mocked_snapshot.assert_called_once()\n"], "sample_798": ["def test_ridge_classifier_multiclass():\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5,\n                               n_classes=3, random_state=0)\n    ridge = RidgeClassifier()\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape[0], X.shape[1])\n    assert_equal(ridge.coef_.shape[1], 3)\n"], "sample_251": ["    def test_alias_with_subquery(self):\n        qs = Book.objects.alias(\n            top_rating=Subquery(\n                Book.objects.filter(pubdate__year=OuterRef('pubdate_year')).order_by('-rating').values('rating')[:1]\n            ),\n        ).annotate(\n            pubdate_year=ExtractYear('pubdate'),\n        ).values('pubdate_year', 'top_rating')\n        self.assertCountEqual(qs, [\n            {'pubdate_year': 1991, 'top_rating': 5.0},\n            {'pubdate_year': 1995, 'top_rating': 4.0},\n            {'pubdate_year': 2007, 'top_rating': 4.5},\n            {'pubdate_year': 2008, 'top_rating': 4.0},\n        ])\n"], "sample_590": ["    def test_concat_mixed_dims(self):\n        # GH439\n        ds1 = Dataset({\"x\": [1, 2], \"y\": [3, 4]})\n        ds2 = Dataset({\"x\": [5, 6], \"y\": [7, 8]})\n        actual = concat([ds1, ds2], dim=\"x\")\n        expected = Dataset({\"x\": [1, 2, 5, 6], \"y\": [3, 4, 7, 8]})\n        assert_identical(actual, expected)\n\n        ds1 = Dataset({\"x\": [1, 2], \"y\": [3, 4]})\n        ds2 = Dataset({\"x\": [5, 6], \"y\": [7, 8], \"z\": [9, 10]})\n        with raises_regex(ValueError, \"cannot concatenate\"):\n            concat([ds1, ds2], dim=\"x\")\n\n        ds1 = Dataset({\"x\": [1, 2], \"y\": [3, 4]})\n        ds2 = Dataset({\"x\": [5, 6], \"z\": [9, 10]})\n        with raises_regex(ValueError, \"cannot concatenate\"):\n            concat([ds1, ds2], dim=\"x\")\n"], "sample_872": ["def test_label_ranking_average_precision_score_with_ties():\n    y_true = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]])\n    y_score = np.array([[0.1, 0.2, 0.3], [0.4, 0.3, 0.2], [0.5, 0.4, 0.1]])\n    # Create ties in y_score\n    y_score[:, 0] = 0.1\n    result = label_ranking_average_precision_score(y_true, y_score)\n    assert result == pytest.approx(0.3333)\n"], "sample_287": ["    def test_list_filter_works_on_through_field_with_custom_model(self):\n        \"\"\"\n        Ensure list_filter can access reverse fields even when the app registry\n        is not ready; refs #24146.\n        \"\"\"\n        class CustomThroughModel(models.Model):\n            book = models.ForeignKey(Book, on_delete=models.CASCADE)\n            author = models.ForeignKey(Author, on_delete=models.CASCADE)\n\n        class BookAdminWithCustomThroughListFilter(admin.ModelAdmin):\n            list_filter = ['custom_through__featured']\n\n        # Temporarily pretending apps are not ready yet. This issue can happen\n        # if the value of 'list_filter' refers to a 'through__field'.\n        Book._meta.apps.ready = False\n        try:\n            errors = BookAdminWithCustomThroughListFilter(Book, AdminSite()).check()\n            self.assertEqual(errors, [])\n        finally:\n            Book._meta.apps.ready = True\n"], "sample_21": ["def test_read_write_masked_values(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1[\"a\"] = [1, 2, np.nan, 4]\n    t1[\"b\"] = [np.nan, 2, 3, 4]\n    t1.write(test_file, format=\"ascii.qdp\")\n    t2 = Table.read(test_file, format=\"ascii.qdp\")\n    assert np.allclose(t1[\"a\"], t2[\"a\"])\n    assert np.allclose(t1[\"b\"], t2[\"b\"])\n"], "sample_330": ["    def test_delete_cascade(self):\n        obj = Object.objects.create()\n        ref = ObjectReference.objects.create(obj=obj)\n        self.assertEqual(Object.objects.count(), 2)\n\n        obj.delete()\n        self.assertFalse(Object.objects.filter(id=obj.id).exists())\n        self.assertFalse(ObjectReference.objects.filter(obj_id=obj.id).exists())\n"], "sample_349": ["    def test_optgroups(self):\n        beatles = Band.objects.create(name='The Beatles', style='rock')\n        who = Band.objects.create(name='The Who', style='rock')\n        form = AlbumForm()\n        optgroups = form['band'].field.widget.optgroups('band', [beatles.pk])\n        self.assertEqual(len(optgroups), 2)\n        self.assertEqual(optgroups[0][1], [form['band'].field.widget.create_option('band', '', '', False, 0)])\n        self.assertEqual(optgroups[1][1], [form['band'].field.widget.create_option('band', beatles.pk, 'The Beatles', True, 1)])\n"], "sample_16": ["    def test_array_function_dispatch(self):\n        # This is a basic test to ensure that array functions are dispatched correctly.\n        # It's not exhaustive, but it covers a few key cases.\n        # TODO: This test needs to be expanded to cover more array functions and edge cases.\n        for func in FUNCTION_HELPERS:\n            if func in DISPATCHED_FUNCTIONS:\n                # Skip functions that are already dispatched.\n                continue\n            try:\n                # Try dispatching the function with a Quantity array.\n                q = np.array([1, 2, 3]) * u.m\n                result = func(q)\n                assert isinstance(result, u.Quantity)\n                assert result.unit == q.unit\n            except Exception as e:\n                # If the function raises an exception, log it and continue.\n                print(f\"Function {func} raised an exception: {e}\")\n                continue\n\n\n\n"], "sample_1164": ["compilation error"], "sample_278": ["    def test_output_field_override(self):\n        expr = ExpressionWrapper(F('name'), output_field=CharField(max_length=10))\n        self.assertEqual(expr.output_field, CharField(max_length=10))\n"], "sample_60": ["    def test_get_formset_kwargs_with_custom_form(self):\n        class CustomForm(ModelForm):\n            class Meta:\n                model = Media\n                fields = ['description']\n\n        class MediaInline(GenericTabularInline):\n            form = CustomForm\n            model = Media\n\n        class EpisodeAdmin(admin.ModelAdmin):\n            inlines = [MediaInline]\n\n        ma = EpisodeAdmin(Episode, self.site)\n        formset = ma.get_formset(request)\n        self.assertEqual(formset.fields, ['description', 'id', 'DELETE'])\n\n"], "sample_345": ["    def test_snapshot_files_with_different_mtimes(self):\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file, self.existing_file]):\n            self.increment_mtime(self.existing_file)\n            snapshot1 = dict(self.reloader.snapshot_files())\n            self.increment_mtime(self.existing_file)\n            snapshot2 = dict(self.reloader.snapshot_files())\n            self.assertNotEqual(snapshot1[self.existing_file], snapshot2[self.existing_file])\n"], "sample_841": ["def test_ridge_saga_with_sparse_matrix():\n    # Test Ridge with the 'saga' solver and sparse input matrices\n    rng = np.random.RandomState(42)\n    n_samples, n_features = 100, 5\n    X = rng.randn(n_samples, n_features)\n    y = rng.randn(n_samples)\n\n    # Convert to sparse matrix\n    X_sparse = sp.csr_matrix(X)\n\n    ridge = Ridge(solver='saga')\n    ridge.fit(X_sparse, y)\n    assert ridge.coef_.shape == (n_features,)\n"], "sample_901": ["def test_k_means_with_sparse_data_and_sample_weight():\n    from sklearn.datasets import make_sparse_toy\n    X, y = make_sparse_toy(n_samples=100, n_features=10, density=0.1)\n    sample_weight = np.random.rand(100)\n\n    km = KMeans(n_clusters=5, random_state=42)\n    km.fit(X, sample_weight=sample_weight)\n    assert km.cluster_centers_.shape[0] == 5\n    assert km.labels_.shape[0] == 100\n"], "sample_763": ["def test_check_array_sparse_dtype_warning():\n    X = sp.csr_matrix([[1, 2], [3, 4]], dtype=np.float32)\n    with pytest.warns(DataConversionWarning, match=r\"Data with input dtype float32 were all converted to float64\"):\n        check_array(X, dtype=np.float64)\n    assert_equal(X.dtype, np.float64)\n"], "sample_638": ["def test_project_name_is_used(mock_writer, mock_subprocess):\n    \"\"\"Test that the project name is used in the output.\"\"\"\n    with mock.patch(\"sys.argv\", [\"pyreverse\", \"-p\", \"MyProject\", TEST_DATA_DIR]):\n        main.Run([])\n    mock_writer.DiagramWriter().write.assert_called_once()\n    assert mock_writer.DiagramWriter().write.call_args[0][0].project_name == \"MyProject\"\n"], "sample_986": ["def test_issue_10418():\n    from sympy import symbols, sin, cos, pi\n    x, y = symbols('x y')\n    assert (sin(x)*cos(y) + cos(x)*sin(y)).evalf(subs={x: pi/4, y: pi/3}) == 0.8660254037844386\n"], "sample_473": ["compilation error"], "sample_18": ["    def test_array_operations(self):\n        q1 = self.q * 2\n        assert_no_info(q1)\n        q2 = self.q + self.q\n        assert_no_info(q2)\n        q3 = self.q - self.q\n        assert_no_info(q3)\n        q4 = self.q.T\n        assert_no_info(q4)\n        q5 = np.dot(self.q, self.q)\n        assert_no_info(q5)\n"], "sample_1183": ["def test_Domain_from_sympy():\n    for dom in (ZZ, QQ, RR, CC, EX, EXRAW):\n        assert dom.from_sympy(1) == dom(1)\n        assert dom.from_sympy(S.One) == dom(1)\n        assert dom.from_sympy(2) == dom(2)\n        assert dom.from_sympy(S.Two) == dom(2)\n        assert dom.from_sympy(S.Pi) == dom(S.Pi)\n        assert dom.from_sympy(S.E) == dom(S.E)\n        assert dom.from_sympy(S.Infinity) == dom(S.Infinity)\n        assert dom.from_sympy(-1) == dom(-1)\n        assert dom.from_sympy(-S.One) == dom(-1)\n        assert dom.from_sympy(-2) == dom(-2)\n        assert dom.from_sympy(-S.Two) == dom(-2)\n\n    for dom in (ZZ_I, QQ_I):\n        assert dom.from_sympy(1) == dom(1)\n        assert dom.from_sympy(S.One) == dom(1)\n        assert dom.from_sympy(2) == dom(2)\n        assert dom.from_sympy(S.Two) == dom(2)\n        assert dom.from_sympy(S.Pi) == dom(S.Pi)\n        assert dom.from_sympy(S.E) == dom(S.E)\n        assert dom.from_sympy(S.Infinity) == dom(S.Infinity)\n        assert dom.from_sympy(-1) == dom(-1)\n        assert dom.from_sympy(-S.One) == dom(-1)\n        assert dom.from_sympy(-2) == dom(-2)\n        assert dom.from_sympy(-S.Two) == dom(-2)\n        assert dom.from_sympy(I) == dom.from_sympy(S.ImaginaryUnit)\n        assert dom.from_sympy(S.ImaginaryUnit) == dom(I)\n\n    for dom in (ZZ"], "sample_792": ["def test_class_prior_with_partial_fit():\n    # Test that class prior is correctly updated with partial_fit\n    iris = load_iris()\n    iris_data1, iris_data2, iris_target1, iris_target2 = train_test_split(\n        iris.data, iris.target, test_size=0.4, random_state=415)\n\n    clf = MultinomialNB()\n    clf.partial_fit(iris_data1, iris_target1, classes=[0, 1, 2])\n    assert_array_almost_equal(clf.class_log_prior_,\n                              np.log([0.5, 0.25, 0.25]))\n\n    clf.partial_fit(iris_data2, iris_target2)\n    assert_array_almost_equal(clf.class_log_prior_,\n                              np.log([0.66666667, 0.22222222, 0.11111111]))\n"], "sample_786": ["def test_ignored_features():\n    X = np.array([[1, 2, 3],\n                  [4, 5, 6],\n                  [7, 8, 9]])\n    kbd = KBinsDiscretizer(n_bins=3, ignore_features=[1], encode='ordinal')\n    kbd.fit(X)\n    Xt = kbd.transform(X)\n    assert Xt.shape[1] == 2\n    assert_array_equal(Xt[:, 0], np.array([0, 1, 2]))\n    assert_array_equal(Xt[:, 1], np.array([0, 1, 2]))\n"], "sample_256": ["    def test_password_too_short(self):\n        user = User.objects.get(username='testclient')\n        data = {'password1': 'abc', 'password2': 'abc'}\n        form = AdminPasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertIn('password1', form.errors)\n        self.assertIn('password2', form.errors)\n        self.assertIn('This password is too short. It must contain at least 8 characters.', form.errors['password1'])\n        self.assertIn('This password is too short. It must contain at least 8 characters.', form.errors['password2'])\n"], "sample_865": ["def test_sparse_data_with_missing_values():\n    # Test handling of sparse data with missing values\n    X = csr_matrix(np.random.rand(100, 10))\n    X[::2, :] = np.nan\n    y = np.random.rand(100)\n    for tree_cls in [DecisionTreeClassifier, DecisionTreeRegressor]:\n        est = tree_cls(random_state=0)\n        with pytest.raises(ValueError):\n            est.fit(X, y)\n"], "sample_45": ["    def test_trunc_func_with_timezone_and_output_field(self):\n        start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n        end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n        start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n        end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n        self.create_model(start_datetime, end_datetime)\n        self.create_model(end_datetime, start_datetime)\n\n        melb = pytz.timezone('Australia/Melbourne')\n\n            self.assertQuerysetEqual(\n                DTModel.objects.annotate(\n                    truncated=func('start_datetime', kind, output_field=output_field, tzinfo=melb)\n                ).order_by('start_datetime'),\n                [\n                    (start_datetime, truncate_to(start_datetime.astimezone(melb), kind, melb, output_field)),\n                    (end_datetime, truncate_to(end_datetime.astimezone(melb), kind, melb, output_field))\n                ],\n                lambda m: (m.start_datetime, m.truncated)\n            )\n\n        test_trunc_func(TruncYear, 'year', DateField())\n        test_trunc_func(TruncQuarter, 'quarter', DateField())\n        test_trunc_func(TruncMonth, 'month', DateField())\n        test_trunc_func(TruncWeek, 'week', DateField())\n        test_trunc_func(TruncDay, 'day', DateField())\n        test_trunc_func(TruncHour, 'hour', TimeField())\n        test_trunc_func(TruncMinute, 'minute', TimeField())\n        test_trunc_func(TruncSecond, 'second', TimeField())\n"], "sample_154": ["    def test_empty_databases(self, mock_connections):\n        issues = check_database_backends(databases=[])\n        self.assertEqual(issues, [])\n"], "sample_370": ["    def test_nested_prefetch_with_filter(self):\n        \"\"\"\n        Nested prefetch with a filter on the child queryset should work correctly.\n        \"\"\"\n        house = House.objects.create(name='Big house', address='123 Main St')\n        Room.objects.create(name='Kitchen', house=house)\n        Room.objects.create(name='Living Room', house=house)\n        Room.objects.create(name='Bedroom', house=house)\n\n        queryset = House.objects.prefetch_related(\n            Prefetch(\n                'rooms',\n                queryset=Room.objects.filter(name__startswith='L').prefetch_related(\n                    Prefetch('house', queryset=House.objects.only('address')),\n                ),\n            ),\n        )\n        with self.assertNumQueries(3):\n            house = queryset.first()\n\n        self.assertEqual(house.rooms.filter(name__startswith='L').first().house.address, '123 Main St')\n"], "sample_634": ["    def test_expand_modules_nonexistent(self, files_or_modules, expected):\n        \"\"\"Test expand_modules with nonexistent modules/files\"\"\"\n        ignore_list, ignore_list_re = [], []\n        modules, errors = expand_modules(\n            files_or_modules,\n            ignore_list,\n            ignore_list_re,\n            get_global_option(self, \"ignore-paths\"),\n        )\n        assert modules == expected\n        assert errors\n"], "sample_472": ["    def test_paginating_with_custom_ordering(self):\n        paginator = Paginator(Article.objects.order_by(\"headline\"), 5)\n        p = paginator.page(1)\n        self.assertEqual(\n            [article.headline for article in p.object_list],\n            [\"Article 1\", \"Article 2\", \"Article 3\", \"Article 4\", \"Article 5\"],\n        )\n\n        paginator = Paginator(Article.objects.order_by(\"-headline\"), 5)\n        p = paginator.page(1)\n        self.assertEqual(\n            [article.headline for article in p.object_list],\n            [\"Article 9\", \"Article 8\", \"Article 7\", \"Article 6\", \"Article 5\"],\n        )\n"], "sample_172": ["    def test_related_field_widget_with_related_name(self):\n        self.admin_login(username='super', password='secret', login_url='/')\n        self.selenium.get(self.live_server_url + reverse('admin:admin_widgets_profile_change', args=(1,)))\n\n        # Click the Add User button to add new\n        self.selenium.find_element_by_id('add_id_user').click()\n        self.wait_for_and_switch_to_popup()\n        password_field = self.selenium.find_element_by_id('id_password')\n        password_field.send_keys('password')\n\n        username_field = self.selenium.find_element_by_id('id_username')\n        username_value = 'newuser'\n        username_field.send_keys(username_value)\n\n        save_button_css_selector = '.submit-row > input[type=submit]'\n        self.selenium.find_element_by_css_selector(save_button_css_selector).click()\n        self.selenium.switch_to.window(self.selenium.window_handles[0])\n        self.selenium.find_element_by_css_selector('#id_user option[value=newuser]').click()\n        self.selenium.find_element_by_css_selector(save_button_css_selector).click()\n        self.wait_for_text('li.success', 'The profile \u201cnewuser\u201d was added successfully.')\n        profiles = Profile.objects.all()\n        self.assertEqual(len(profiles), 1)\n        self.assertEqual(profiles[0].user.username, username_value)\n"], "sample_485": ["    def test_urlize_trim_url_limit(self):\n        self.assertEqual(urlize(\"This is a very long URL: http://example.com/this-is-a-very-long-url-that-is-longer-than-the-limit-of-20-characters\", trim_url_limit=20),\n                         \"This is a very long URL: http://example.com/this-is-a-very-long-url-that-is-longer-than-the-limit-of-20-characters\")\n        self.assertEqual(urlize(\"This is a very long URL: http://example.com/this-is-a-very-long-url-that-is-longer-than-the-limit-of-20-characters\", trim_url_limit=10),\n                         \"This is a very long URL: http://example.com/this-is-a-very-long-url-that-is-longer-than-the-limit-of-20-characters...\")\n"], "sample_536": ["def test_MultiCursor_reset(horizOn, vertOn):\n    (ax1, ax3) = plt.figure().subplots(2, sharex=True)\n    ax2 = plt.figure().subplots()\n\n    multi = widgets.MultiCursor(\n        None, (ax1, ax2), useblit=False, horizOn=horizOn, vertOn=vertOn\n    )\n\n    # mock a motion_notify_event\n    event = mock_event(ax1, xdata=.5, ydata=.25)\n    multi.onmove(event)\n    ax1.figure.canvas.draw()\n\n    # reset the cursor\n    multi.reset()\n\n    # check that the lines are gone\n    assert len(multi.vlines) == 0\n    assert len(multi.hlines) == 0\n"], "sample_1148": ["def test_matrix_transpose():\n    A = MatrixSymbol('A', 2, 3)\n    B = Transpose(A)\n    assert B.shape == (3, 2)\n    assert B[i, j] == A[j, i]\n    assert A.T == B\n    assert Transpose(Transpose(A)) == A\n    raises(TypeError, lambda: Transpose(1))\n    raises(TypeError, lambda: Transpose(S.Pi))\n    raises(ShapeError, lambda: Transpose(Matrix([[1, 2], [3, 4], [5, 6], [7, 8]])))\n"], "sample_826": ["def test_one_hot_encoder_get_feature_names_single_column(X, expected_names):\n    enc = OneHotEncoder()\n    enc.fit(X.reshape(1, -1))\n    feature_names = enc.get_feature_names()\n    assert_array_equal(expected_names, feature_names)\n"], "sample_272": ["    def test_minimize_rollbacks_circular_dependency(self):\n        \"\"\"\n        Minimize rollbacks when target has circular dependencies.\n\n        a: 1 <--- 2\n        b:    \\- 1\n        c:     \\- 1\n\n        If a1 is applied already and a2 is not, and we're asked to migrate to\n        a1, don't apply or unapply b1 or c1, regardless of their current state.\n        \"\"\"\n        a1_impl = FakeMigration('a1')\n        a1 = ('a', '1')\n        a2_impl = FakeMigration('a2')\n        a2 = ('a', '2')\n        b1_impl = FakeMigration('b1')\n        b1 = ('b', '1')\n        c1_impl = FakeMigration('c1')\n        c1 = ('c', '1')\n        graph = MigrationGraph()\n        graph.add_node(a1, a1_impl)\n        graph.add_node(a2, a2_impl)\n        graph.add_node(b1, b1_impl)\n        graph.add_node(c1, c1_impl)\n        graph.add_dependency(None, a2, a1)\n        graph.add_dependency(None, b1, a1)\n        graph.add_dependency(None, c1, a1)\n        graph.add_dependency(None, a1, a2)\n        graph.add_dependency(None, a1, b1)\n        graph.add_dependency(None, a1, c1)\n\n        executor = MigrationExecutor(None)\n        executor.loader = FakeLoader(graph, {\n            a1: a1_impl,\n            b1: b1_impl,\n        })\n\n        plan = executor.migration_plan({a1})\n\n        self.assertEqual(plan, [])\n"], "sample_610": ["def test_infer_freq_with_custom_calendar(freq, calendar):\n    indx = xr.cftime_range(\"2000-01-01\", periods=3, freq=freq, calendar=calendar)\n    out = xr.infer_freq(indx)\n    assert out == freq\n"], "sample_1082": ["    def test_issue_11715():\n        assert acosh(1).rewrite(log) == 0\n        assert acosh(2).rewrite(log) == log(1 + sqrt(3))\n        assert acosh(3).rewrite(log) == log(1 + sqrt(8))\n"], "sample_107": ["    def test_cleanse_setting_handles_nested_dictionaries(self):\n        initial = {'user': {'name': 'cooper', 'password': 'secret'}}\n        expected = {'user': {'name': 'cooper', 'password': CLEANSED_SUBSTITUTE}}\n        self.assertEqual(cleanse_setting('SETTING_NAME', initial), expected)\n"], "sample_279": ["    def test_opclasses_with_condition(self):\n        msg = 'UniqueConstraint with conditions cannot have opclasses.'\n        with self.assertRaisesMessage(ValueError, msg):\n            models.UniqueConstraint(\n                fields=['name'],\n                name='name_with_condition_and_opclasses',\n                condition=models.Q(color__isnull=True),\n                opclasses=['text_pattern_ops'],\n            )\n\n"], "sample_1186": ["def test_array_shape_from_iterable():\n    for ArrayType in array_types:\n        # Test empty iterable\n        with raises(ValueError):\n            ArrayType(None)\n        with raises(ValueError):\n            ArrayType(())\n\n        # Test single element iterable\n        test_array = ArrayType([1])\n        assert test_array.shape == (1,)\n\n        # Test 2D iterable\n        test_array = ArrayType([[1, 2], [3, 4]])\n        assert test_array.shape == (2, 2)\n\n        # Test 3D iterable\n        test_array = ArrayType([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n        assert test_array.shape == (2, 2, 2)\n\n        # Test iterable with varying dimensions\n        test_array = ArrayType([1, [2, 3], [[4, 5], [6, 7]]])\n        assert test_array.shape == (3,)\n\n        # Test iterable with nested lists of different lengths\n        with raises(ValueError):\n            ArrayType([[1, 2], [3, 4, 5]])\n\n        # Test iterable with mixed data types\n        test_array = ArrayType([1, 'a', [2, 3]])\n        assert test_array.shape == (3,)\n\n\n\n"], "sample_302": ["    def test_runshell_handles_sigint(self):\n        sigint_handler = signal.getsignal(signal.SIGINT)\n        with mock.patch('subprocess.run') as run:\n            with mock.patch.object(\n                BaseDatabaseClient,\n                'settings_to_cmd_args_env',\n                return_value=([], None),\n            ):\n                self.client.runshell(None)\n        run.assert_called_once_with([], env=None, check=True)\n        # Assert that the original SIGINT handler was restored.\n        self.assertEqual(signal.getsignal(signal.SIGINT), sigint_handler)\n"], "sample_495": ["    def test_paginating_with_custom_page_class(self):\n        class MyPage(Page):\n                return f\"<Page {self.number} of {self.paginator.num_pages}>\"\n\n        paginator = Paginator(Article.objects.order_by('id'), 5, Page=MyPage)\n        p = paginator.page(1)\n        self.assertEqual(\"<Page 1 of 2>\", str(p))\n"], "sample_612": ["    def test_resample_with_multiple_coords(self):\n        times = pd.date_range(\"2000-01-01\", freq=\"6H\", periods=10)\n        lat = np.arange(3)\n        lon = np.arange(4)\n        ds = Dataset(\n            {\n                \"data\": ([\"time\", \"lat\", \"lon\"], np.random.randn(10, 3, 4)),\n                \"time\": times,\n                \"lat\": lat,\n                \"lon\": lon,\n            }\n        )\n        actual = ds.resample(time=\"1D\").mean()\n        expected = ds.isel(time=[0, 4, 8]).mean()\n        assert_identical(actual, expected)\n"], "sample_1174": ["def test_issue_16184():\n    from sympy import Symbol, exp, Abs, re, im, I\n    x = Symbol('x', real=True)\n    y = Symbol('y', real=True)\n    z = Symbol('z', complex=True)\n    assert re(exp(I*x)*z) == re(exp(I*x))*re(z) - im(exp(I*x))*im(z)\n    assert im(exp(I*x)*z) == re(exp(I*x))*im(z) + im(exp(I*x))*re(z)\n    assert Abs(exp(I*x)*z) == Abs(exp(I*x))*Abs(z)\n    assert re(exp(I*x)*z) == re(exp(I*x))*re(z) - im(exp(I*x))*im(z)\n    assert im(exp(I*x)*z) == re(exp(I*x))*im(z) + im(exp(I*x))*re(z)\n    assert Abs(exp(I*x)*z) == Abs(exp(I*x))*Abs(z)\n    assert re(exp(I*x)*z) == re(exp(I*x))*re(z) - im(exp(I*x))*im(z)\n    assert im(exp(I*x)*z) == re(exp(I*x))*im(z) + im(exp(I*x))*re(z)\n    assert Abs(exp(I*x)*z) == Abs(exp(I*x))*Abs(z)\n    assert re(exp(I*x)*z) == re(exp(I*x))*re(z) - im(exp(I*x))*im(z)\n    assert im(exp(I*x)*z) == re(exp(I*x))*im(z) + im(exp(I*x))*re(z)\n    assert Abs(exp(I*x)*z) == Abs(exp(I*x))*Abs(z)\n    assert re(exp(I*x)*z) == re(exp(I*x))*re(z) - im(exp"], "sample_1134": ["def test_issue_17511():\n    from sympy.physics.quantum import TensorProduct\n    a, b = symbols('a b')\n    psi = TensorProduct(a, b)\n    assert latex(psi) == r'a \\otimes b'\n"], "sample_0": ["def test_repr_fake(UncertClass):\n    fake_uncert = UncertClass([1, 2, 3])\n    repr_str = repr(fake_uncert)\n    assert isinstance(repr_str, str)\n    # Check if the repr string contains the array and unit information\n    assert 'array: [1, 2, 3]' in repr_str\n    assert 'unit: ' in repr_str\n\n\n\n"], "sample_264": ["    def test_not_finished_sentinel(self):\n        storage = self.get_storage()\n        response = self.get_response()\n\n        # Add a few messages to the storage.\n        for i in range(5):\n            storage.add(constants.INFO, f'Message {i}')\n\n        # Update the response with the messages, ensuring the\n        # 'not_finished' sentinel is set.\n        storage.update(response)\n\n        # Retrieve the messages from the cookie.\n        messages = storage._decode(response.cookies[storage.cookie_name].value)\n\n        # Assert that the 'not_finished' sentinel is present.\n        self.assertEqual(messages[-1], CookieStorage.not_finished)\n\n        # Remove the sentinel and assert that the correct number of\n        # messages are retrieved.\n        messages.pop()\n        self.assertEqual(len(messages), 4)\n\n        # Add more messages, exceeding the max_cookie_size.\n        for i in range(5, 10):\n            storage.add(constants.INFO, f'Message {i}')\n\n        # Update the response again, ensuring the 'not_finished' sentinel\n        # is set.\n        storage.update(response)\n\n        # Retrieve the messages from the cookie.\n        messages = storage._decode(response.cookies[storage.cookie_name].value)\n\n        # Assert that the 'not_finished' sentinel is present.\n        self.assertEqual(messages[-1], CookieStorage.not_finished)\n\n        # Remove the sentinel and assert that the correct number of\n        # messages are retrieved.\n        messages.pop()\n        self.assertEqual(len(messages), 9)\n\n\n\n"], "sample_546": ["def test_toolmanager_set_active_tool():\n    with pytest.warns(UserWarning, match=_EXPECTED_WARNING_TOOLMANAGER):\n        plt.rcParams['toolbar'] = 'toolmanager'\n    fig = plt.gcf()\n    initial_tool = fig.canvas.manager.toolmanager.get_active_tool()\n    assert initial_tool is not None\n    fig.canvas.manager.toolmanager.set_active_tool('pan')\n    assert fig.canvas.manager.toolmanager.get_active_tool() == 'pan'\n    with pytest.warns(UserWarning,\n                      match=\"ToolManager does not control tool 'foo'\"):\n        fig.canvas.manager.toolmanager.set_active_tool('foo')\n    assert fig.canvas.manager.toolmanager.get_active_tool() == 'pan'\n"], "sample_685": ["def test_log_format_with_custom_formatter(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_level == logging.WARNING\n\n            logger = logging.getLogger('catchlog')\n            logger.info(\"INFO message\")\n            logger.warning(\"WARNING message\")\n            logger.error(\"ERROR message\")\n\n            assert \"INFO message\" in caplog.text\n            assert \"WARNING message\" in caplog.text\n            assert \"ERROR message\" in caplog.text\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_format = %(asctime)s - %(name)s - %(levelname)s - %(message)s\n        log_file = test.log\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*INFO message*\", \"*WARNING message*\", \"*ERROR message*\"])\n    assert result.ret == 0\n"], "sample_242": ["    def test_year_lookup_bounds(self):\n        look_up = YearExact(\n            lhs=Value(datetime(2010, 1, 1, 0, 0, 0), output_field=DateTimeField()),\n            rhs=Value(2010),\n        )\n        connection = mock.MagicMock()\n        connection.features = mock.MagicMock(has_native_uuid_field=False)\n        start, finish = look_up.year_lookup_bounds(connection, 2010)\n        self.assertEqual(start, datetime(2010, 1, 1, 0, 0, 0))\n        self.assertEqual(finish, datetime(2010, 12, 31, 23, 59, 59))\n"], "sample_797": ["def test_power_transformer_sparse_matrix():\n    X_sparse = sparse.csr_matrix(X_2d)\n    for standardize in [True, False]:\n        pt = PowerTransformer(method='box-cox', standardize=standardize)\n        X_trans = pt.fit_transform(X_sparse)\n        assert isinstance(X_trans, sparse.csr_matrix)\n        assert_array_almost_equal(X_trans.toarray(), pt.transform(X_2d))\n\n        X_inv_trans = pt.inverse_transform(X_trans)\n        assert isinstance(X_inv_trans, sparse.csr_matrix)\n        assert_array_almost_equal(X_inv_trans.toarray(), X_2d)\n\n\n\n"], "sample_76": ["    def test_language_settings_consistent_with_en_us(self):\n        with self.settings(LANGUAGE_CODE='en-us', LANGUAGES=[('en', 'English'), ('en-us', 'English (US)')]):\n            self.assertEqual(check_language_settings_consistent(None), [])\n"], "sample_552": ["def test_savefig_metadata_with_kwargs():\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.plot([1, 2, 3], [4, 5, 6])\n    with pytest.raises(ValueError, match=\"metadata is not supported\"):\n        fig.savefig(io.BytesIO(), format='png', metadata={'foo': 'bar'}, dpi=100)\n"], "sample_758": ["def test_check_array_sparse_format_deprecation():\n    with pytest.warns(DeprecationWarning, match=\"The 'format' parameter\"):\n        check_array(sp.csr_matrix([[1, 2], [3, 4]]), format='csr')\n"], "sample_519": ["def test_unpickle_with_subplotspec():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[1, 1])\n    fig2 = pickle.loads(pickle.dumps(fig))\n    assert len(fig2.axes) == 2\n    assert isinstance(fig2.axes[0].get_subplotspec(), SubplotsSpec)\n    assert isinstance(fig2.axes[1].get_subplotspec(), SubplotsSpec)\n"], "sample_598": ["    def test_short_numpy_repr_lines(array_shape, expected_lines):\n        array = np.random.randn(*array_shape)\n        num_lines = formatting.short_numpy_repr(array).count(\"\\n\") + 1\n        assert num_lines == expected_lines\n"], "sample_103": ["    def test_subquery_with_aggregate_in_annotation(self):\n        avg_rating_qs = Book.objects.filter(publisher=OuterRef('pk')).values('publisher').annotate(avg_rating=Avg('rating'))\n        publisher_qs = Publisher.objects.annotate(\n            avg_rating_of_books=Subquery(avg_rating_qs, output_field=FloatField())\n        ).annotate(count=Count('book'))\n        with self.assertNumQueries(1) as ctx:\n            list(publisher_qs)\n        self.assertEqual(ctx[0]['sql'].count('SELECT'), 2)\n"], "sample_361": ["    def test_urlize_trim_url_limit(self):\n        self.assertEqual(urlize('This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit', trim_url_limit=15),\n                         'This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit')\n        self.assertEqual(urlize('This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit', trim_url_limit=25),\n                         'This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit')\n        self.assertEqual(urlize('This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit', trim_url_limit=10),\n                         'This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit')\n"], "sample_490": ["    def test_unique_constraint_with_violation_error_message_and_code(self):\n        constraint = models.UniqueConstraint(\n            models.F(\"baz__lower\"),\n            name=\"unique_lower_baz\",\n            violation_error_message=\"BAZ\",\n            violation_error_code=\"baz\",\n        )\n        with self.assertRaisesMessage(ValidationError, \"BAZ\"):\n            UniqueConstraintProduct.objects.create(baz=\"baz\")\n        with self.assertRaises(ValidationError) as cm:\n            UniqueConstraintProduct.objects.create(baz=\"baz\")\n        self.assertEqual(cm.exception.code, \"baz\")\n"], "sample_568": ["def test_text_3d_rotation():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    txt = Text(0.5, 0.5, r'Foo bar', rotation=(45, 30))\n    art3d.text_2d_to_3d(txt, z=1)\n    ax.add_artist(txt)\n    assert txt.get_rotation() == (45, 30)\n"], "sample_930": ["def test_create_index_with_subentries(app):\n    text = (\".. index:: pair: docutils; reStructuredText\\n\"\n            \".. index:: pair: Python; interpreter\\n\"\n            \".. index:: pair: Sphinx; documentation tool\\n\"\n            \".. index:: pair: Sphinx; :+1:\\n\"\n            \".. index:: pair: Sphinx; \u0415\u043b\u044c\\n\"\n            \".. index:: pair: Sphinx; \u0451\u043b\u043a\u0430\\n\"\n            \".. index:: pair: Sphinx; documentation tool; :+2:\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 7\n    assert index[0] == ('Symbols', [(':+1:', [[], [('Sphinx', [('', '#index-3')])], None]),\n                (':+2:', [[], [('Sphinx', [('', '#index-6')])], None])])\n    assert index[1] == ('D',\n                        [('documentation tool', [[], [('Sphinx', [('', '#index-2')]),\n                ('Sphinx', [('', '#index-6')])], None]),\n                         ('docutils', [[], [('reStructuredText', [('', '#index-0')])], None])])\n    assert index[2] == ('I', [('interpreter', [[], [('Python', [('', '#index-1')])], None])])\n    assert index[3] == ('P', [('Python', [[], [('interpreter', [('', '#index-1')])], None])])\n    assert index[4] == ('R', [('reStructuredText', [[], [('docutils', [('', '#index-0')])], None])])\n    assert index[5] == ('S',\n                        [('Sphinx', [[],\n                                     [(':+1:', [('', '#index-3')]),\n                                      ('documentation tool', [('', '#index-2')]),\n                                      ('documentation tool', [('', '#index-6')]),\n                                      ('\u0451\u043b\u043a\u0430', [('', '#index-5')]),\n                                      ('\u0415\u043b\u044c', [('', '#index-4')"], "sample_309": ["    def test_no_change(self):\n        tests = (\n            ('http://example.com', 'http://example.com'),\n            ('https://example.com', 'https://example.com'),\n            ('/path/to/resource', '/path/to/resource'),\n            ('http://example.com/path/to/resource', 'http://example.com/path/to/resource'),\n        )\n        for url, expected in tests:\n            with self.subTest(url=url):\n                self.assertEqual(escape_leading_slashes(url), expected)\n"], "sample_1201": ["compilation error"], "sample_1085": ["def test_issue_11097():\n    assert Float('1.2345678901234567890123456789012345678901234567890').n(100) == '1.2345678901234567890123456789012345678901234567890'\n"], "sample_802": ["def test_pipeline_memory_with_fit_transform():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        if LooseVersion(joblib_version) < LooseVersion('0.12'):\n            # Deal with change of API in joblib\n            memory = Memory(cachedir=cachedir, verbose=10)\n        else:\n            memory = Memory(location=cachedir, verbose=10)\n        # Test with Transformer + SVC\n        clf = SVC(gamma='scale', probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', transf), ('svc', clf)])\n        cached_pipe = Pipeline([('transf', transf), ('svc', clf)],\n                               memory=memory)\n\n        # Memoize the transformer at the first fit_transform\n        cached_pipe.fit_transform(X, y)\n        pipe.fit_transform(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert not hasattr(transf, 'means_')\n        # Check that we are reading the cache while fitting\n        # a second time\n        cached_pipe.fit_transform(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba("], "sample_1202": ["def test_issue_11668():\n    assert Float('1.23', 10).as_mpf() == (0, int(123), -1, 10)\n    assert Float('1.23', 10).as_mpf(dps=10) == (0, int(123), -1, 10)\n    assert Float('1.23', 10).as_mpf(dps=15) == (0, int(12300000000), -1, 15)\n"], "sample_866": ["def test_affinity_propagation_preference_default():\n    X = np.array([[1, 2], [1, 4], [1, 0],\n                  [4, 2], [4, 4], [4, 0]])\n    af = AffinityPropagation()\n    labels = af.fit_predict(X)\n    assert np.unique(labels).size == 3\n"], "sample_253": ["    def test_snapshot_files_with_non_existing_files(self):\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.nonexistent_file]):\n            snapshot = dict(self.reloader.snapshot_files())\n            self.assertNotIn(self.nonexistent_file, snapshot)\n"], "sample_63": ["    def test_invalid_loader(self):\n        with self.assertRaises(ImproperlyConfigured):\n            Engine(loaders=['invalid_loader'])\n"], "sample_886": ["def test_set_output_with_sparse_data():\n    \"\"\"Check that set_output handles sparse data correctly.\"\"\"\n    from scipy.sparse import csr_matrix\n\n    X = csr_matrix([[1, 0, 3], [0, 0, 1]])\n    est = EstimatorWithSetOutput().fit(X)\n\n    with pytest.raises(ValueError, match=\"Pandas output does not support sparse data\"):\n        est.set_output(transform=\"pandas\")\n        est.transform(X)\n"], "sample_127": ["    def test_ignore_conflicts_with_existing_objects(self):\n        data = [\n            TwoFields(f1=1, f2=1),\n            TwoFields(f1=2, f2=2),\n            TwoFields(f1=3, f2=3),\n        ]\n        TwoFields.objects.bulk_create(data)\n        self.assertEqual(TwoFields.objects.count(), 3)\n\n        existing_objects = [\n            TwoFields(f1=2, f2=2),\n            TwoFields(f1=3, f2=3),\n        ]\n        TwoFields.objects.bulk_create(existing_objects, ignore_conflicts=True)\n        self.assertEqual(TwoFields.objects.count(), 3)\n        self.assertIsNone(existing_objects[0].pk)\n        self.assertIsNone(existing_objects[1].pk)\n\n        new_objects = [\n            TwoFields(f1=4, f2=4),\n            TwoFields(f1=5, f2=5),\n        ]\n        TwoFields.objects.bulk_create(new_objects, ignore_conflicts=True)\n        self.assertEqual(TwoFields.objects.count(), 5)\n        self.assertIsNone(new_objects[0].pk)\n        self.assertIsNone(new_objects[1].pk)\n\n        # Verify that the existing objects were not overwritten\n        self.assertEqual(TwoFields.objects.get(f1=2, f2=2).pk, existing_objects[0].pk)\n        self.assertEqual(TwoFields.objects.get(f1=3, f2=3).pk, existing_objects[1].pk)\n\n\n\n"], "sample_292": ["    def test_csrf_token_on_500_stays_constant(self):\n        response = self.client.get('/internal_server_error/')\n        # The error handler returns status code 599.\n        self.assertEqual(response.status_code, 599)\n        token1 = response.content\n        response = self.client.get('/internal_server_error/')\n        self.assertEqual(response.status_code, 599)\n        token2 = response.content\n        self.assertTrue(equivalent_tokens(token1.decode('ascii'), token2.decode('ascii')))\n"], "sample_310": ["    def test_simplify_regex_with_lookarounds(self):\n        tests = (\n            (r'(?<!a)b(?!c)', '/b'),\n            (r'(?<=a)b(?=c)', '/b'),\n            (r'(?<!a)b(?!c)', '/b'),\n            (r'(?<=a)b(?=c)', '/b'),\n            (r'(?<!a)(?P<b>\\w+)(?!c)', '/<b>'),\n        )\n        for pattern, output in tests:\n            with self.subTest(pattern=pattern):\n                self.assertEqual(simplify_regex(pattern), output)\n"], "sample_627": ["    def test_concat_different_index_types() -> None:\n        ds1 = Dataset(coords={\"x\": (\"x\", [1, 2])})\n        ds2 = Dataset(coords={\"x\": pd.Index([3, 4])})\n\n        with pytest.raises(\n            ValueError, match=r\"Index types must be consistent.*\"\n        ):\n            concat([ds1, ds2], dim=\"x\")\n"], "sample_670": ["def test_nested_parens(expr: str, expected: bool) -> None:\n    matcher = {\"true\": True, \"false\": False}.__getitem__\n    assert evaluate(expr, matcher) is expected\n"], "sample_389": ["    def test_media_url_with_trailing_slash(self):\n        # MEDIA_URL should have a trailing slash if it doesn't already.\n        tests = (\n            (\"/media/\", \"/media\", \"/media/\"),\n            (\"/media\", \"/media/\", \"/media/\"),\n            (\"/media/\", \"/media\", \"/media/\"),\n            (\"/media\", \"/media\", \"/media\"),\n        )\n        for original_url, expected_url in tests:\n            with self.settings(MEDIA_URL=original_url):\n                self.assertEqual(settings.MEDIA_URL, expected_url)\n\n\n\n"], "sample_1165": ["def test_quaternion_complex_multiplication():\n    q1 = Quaternion(1, 2, 3, 4)\n    q2 = Quaternion(5 + 6*I, 7 + 8*I, 9 + 10*I, 11 + 12*I)\n\n    assert q1 * q2 == Quaternion(\n        -12 - 16*I, 10 + 14*I, 22 + 26*I, 34 + 40*I)\n    assert q2 * q1 == Quaternion(\n        -12 - 16*I, 10 + 14*I, 22 + 26*I, 34 + 40*I)\n"], "sample_571": ["    def test_regplot_y_jitter(self):\n\n        f, ax = plt.subplots()\n        x, y = self.df.x, self.df.y\n        lm.regplot(x=x, y=y, scatter_kws={'y_jitter': 0.1})\n        x, y = ax.collections[0].get_offsets().T\n        assert np.all(np.abs(y - self.df.y) < 0.1)\n"], "sample_651": ["    def test_re_emit_match_multiple_with_order(self) -> None:\n        with pytest.warns(UserWarning, match=\"user warning 1\"):\n            warnings.warn(\"user warning 1\", UserWarning)\n            warnings.warn(\"user warning 2\", UserWarning)\n\n        with pytest.warns(UserWarning, match=\"user warning 2\"):\n            warnings.warn(\"user warning 1\", UserWarning)\n            warnings.warn(\"user warning 2\", UserWarning)\n"], "sample_1062": ["compilation error"], "sample_405": ["    def test_references_field_by_related_name(self):\n        operation = FieldOperation(\n            \"Model\",\n            \"field\",\n            models.ForeignKey(\"Other\", models.CASCADE, related_name=\"related_field\"),\n        )\n        self.assertIs(\n            operation.references_field(\"Other\", \"related_field\", \"migrations\"), True\n        )\n        self.assertIs(\n            operation.references_field(\"Other\", \"whatever\", \"migrations\"), False\n        )\n"], "sample_333": ["    def test_renderer_is_callable(self):\n        class CustomRenderer(object):\n                return 'Custom rendered form'\n\n        form = Form()\n        form.renderer = CustomRenderer()\n        self.assertEqual(form.render(), 'Custom rendered form')\n"], "sample_944": ["def test_stringify_type_hints_GenericMeta():\n    from typing import GenericMeta  # type: ignore\n    class MyGenericMeta(GenericMeta):\n            return super().__new__(cls, name, bases, attrs)\n\n    MyGenericClass = MyGenericMeta('MyGenericClass', (object,), {})\n    assert stringify(MyGenericClass) == \"tests.test_util_typing.MyGenericClass\"\n"], "sample_123": ["    def test_relative_urls(self):\n        tests = (\n            ('/path/to/resource', '/path/to/resource'),\n            ('/path/to/resource/', '/path/to/resource%2F'),\n            ('/path/to/resource?param=value', '/path/to/resource%3Fparam%3Dvalue'),\n        )\n        for url, expected in tests:\n            with self.subTest(url=url):\n                self.assertEqual(escape_leading_slashes(url), expected)\n"], "sample_440": ["    def test_update_conflicts_with_target_unsupported(self):\n        msg = (\n            \"This database backend does not support updating conflicts with \"\n            \"specifying a target field.\"\n        )\n        with self.assertRaisesMessage(NotSupportedError, msg):\n            TwoFields.objects.bulk_create(\n                [TwoFields(f1=1, f2=1), TwoFields(f1=2, f2=2)],\n                update_conflicts=True,\n                update_fields=[\"f2\"],\n                unique_fields=[\"f1\"],\n                target_field=\"f1\",\n            )\n"], "sample_557": ["def test_subplot_mosaic_with_empty_subplots():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1])\n    ax3 = fig.add_subplot(gs[1, 0])\n    ax4 = fig.add_subplot(gs[1, 1])\n\n    with pytest.raises(ValueError, match=\"All of the rows must have the same length\"):\n        fig.subplot_mosaic(\"AB\\nCD\")\n    with pytest.raises(ValueError, match=\"All of the rows must have the same length\"):\n        fig.subplot_mosaic(\"AB\\nAC\")\n    with pytest.raises(ValueError, match=\"All of the rows must have the same length\"):\n        fig.subplot_mosaic(\"AB\\nABC\")\n\n    fig.subplot_mosaic(\"AB\\n\\nCD\")\n    fig.subplot_mosaic(\"AB\\n\\n\")\n\n\n\n"], "sample_218": ["    def test_trunc_func_with_timezone_and_output_field(self):\n        start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n        end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n        start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n        end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n        self.create_model(start_datetime, end_datetime)\n\n        melb = pytz.timezone('Australia/Melbourne')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated_date=Trunc('start_datetime', 'day', output_field=DateField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(melb).date(), 'day')),\n                (end_datetime, truncate_to(end_datetime.astimezone(melb).date(), 'day')),\n            ],\n            lambda m: (m.start_datetime, m.truncated_date)\n        )\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated_time=Trunc('start_datetime', 'hour', output_field=TimeField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(melb).time(), 'hour')),\n                (end_datetime, truncate_to(end_datetime.astimezone(melb).time(), 'hour')),\n            ],\n            lambda m: (m.start_datetime, m.truncated_time)\n        )\n\n\n\n"], "sample_1015": ["def test_ccode_complex():\n    z = symbols('z', complex=True)\n    assert ccode(z.real) == 'creal(z)'\n    assert ccode(z.imag) == 'cimag(z)'\n    assert ccode(z.conjugate()) == 'conj(z)'\n    assert ccode(abs(z)) == 'cabs(z)'\n    assert ccode(z**2) == 'pow(z, 2)'\n    assert ccode(z + 2) == 'z + 2.0'\n    assert ccode(z * 2) == '2.0*z'\n    assert ccode(sin(z)) == 'csin(z)'\n    assert ccode(cos(z)) == 'ccos(z)'\n    assert ccode(exp(z)) == 'cexpm1(z)'\n    assert ccode(log(z)) == 'clog(z)'\n"], "sample_192": ["    def test_all_valid_with_non_form_errors(self):\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '0',\n            'choices-MAX_NUM_FORMS': '1',  # should be ignored\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': '0',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '1',\n        }\n        ChoiceFormSet = formset_factory(Choice, extra=1, max_num=1, validate_max=True)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [{}, {'votes': ['This field is required.']}]\n        self.assertEqual(formset1._errors, expected_errors)\n        self.assertEqual(formset2._errors, expected_errors)\n"], "sample_410": ["    def test_get_codename(self):\n        p = Permission.objects.get(codename=\"view_customemailfield\")\n        self.assertEqual(p.codename, \"view_customemailfield\")\n"], "sample_517": ["def test_text_bbox_with_transform():\n    fig, ax = plt.subplots()\n    text = ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    bbox = text.get_bbox()\n    assert bbox.width > 0\n    assert bbox.height > 0\n"], "sample_368": ["    def test_minimize_rollbacks_circular(self):\n        \"\"\"\n        Minimize rollbacks when there are circular dependencies.\n\n        a: 1 <--- 2\n        b:    \\- 1\n        c:     \\- 1\n        \"\"\"\n        a1_impl = FakeMigration('a1')\n        a1 = ('a', '1')\n        a2_impl = FakeMigration('a2')\n        a2 = ('a', '2')\n        b1_impl = FakeMigration('b1')\n        b1 = ('b', '1')\n        c1_impl = FakeMigration('c1')\n        c1 = ('c', '1')\n        graph = MigrationGraph()\n        graph.add_node(a1, a1_impl)\n        graph.add_node(a2, a2_impl)\n        graph.add_node(b1, b1_impl)\n        graph.add_node(c1, c1_impl)\n        graph.add_dependency(None, a2, a1)\n        graph.add_dependency(None, b1, a1)\n        graph.add_dependency(None, c1, a1)\n        graph.add_dependency(None, a1, b1)\n        graph.add_dependency(None, a1, c1)\n\n        executor = MigrationExecutor(None)\n        executor.loader = FakeLoader(graph, {\n            a1: a1_impl,\n            b1: b1_impl,\n        })\n\n        plan = executor.migration_plan({a1})\n\n        self.assertEqual(plan, [])\n"], "sample_387": ["    def test_related_field_widget_with_related_name(self):\n        from selenium.webdriver.common.by import By\n        from django.contrib.auth.models import User\n\n        self.admin_login(username=\"super\", password=\"secret\", login_url=\"/\")\n        self.selenium.get(\n            self.live_server_url + reverse(\"admin:admin_widgets_profile_add\")\n        )\n\n        main_window = self.selenium.current_window_handle\n        # Click the Add User button to add new\n        self.selenium.find_element(By.ID, \"add_id_user\").click()\n        self.wait_for_and_switch_to_popup()\n        password_field = self.selenium.find_element(By.ID, \"id_password\")\n        password_field.send_keys(\"password\")\n\n        username_field = self.selenium.find_element(By.ID, \"id_username\")\n        username_value = \"newuser\"\n        username_field.send_keys(username_value)\n\n        save_button_css_selector = \".submit-row > input[type=submit]\"\n        self.selenium.find_element(By.CSS_SELECTOR, save_button_css_selector).click()\n        self.selenium.switch_to.window(main_window)\n        # The field now contains the new user\n        self.selenium.find_element(By.CSS_SELECTOR, \"#id_user option[value=newuser]\")\n\n        # Now, check the related field\n        self.selenium.find_element(By.ID, \"view_id_user\").click()\n        self.wait_for_value(\"#id_username\", \"newuser\")\n        self.selenium.back()\n\n        # Check the related field again\n        self.selenium.find_element(By.ID, \"view_id_user\").click()\n        self.wait_for_value(\"#id_username\", \"newuser\")\n        self.selenium.back()\n\n        # Go ahead and submit the form to make sure it works\n        self.selenium.find_element(By.CSS_SELECTOR, save_button_css_selector).click()\n        self.wait_for_"], "sample_960": ["def test_warn_missing_reference_with_explicit_label(app, status, warning):\n    app.build()\n    assert 'index.rst:6: WARNING: undefined label: no-label' in warning.getvalue()\n    assert ('index.rst:7: WARNING: Failed to create a cross reference. A title or caption not found: existing-label'\n            in warning.getvalue())\n"], "sample_237": ["    def test_custom_permission_codename_collision(self):\n        class Checked(models.Model):\n            class Meta:\n                permissions = [\n                    ('my_permission', 'my_codename'),\n                    ('another_permission', 'my_codename'),\n                ]\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The permission codenamed 'my_codename' is duplicated for \"\n                \"model 'auth_tests.Checked'.\",\n                obj=Checked,\n                id='auth.E006',\n            ),\n        ])\n"], "sample_491": ["    def test_custom_renderer_with_form_field_errors(self):\n        class CustomRenderer(DjangoTemplates):\n            form_template_name = \"forms_tests/custom_form.html\"\n            field_template_name = \"forms_tests/custom_field.html\"\n\n        class UserRegistration(Form):\n            username = CharField(max_length=10)\n            password1 = CharField(widget=PasswordInput)\n            password2 = CharField(widget=PasswordInput)\n\n                if (\n                    self.cleaned_data.get(\"password1\")\n                    and self.cleaned_data.get(\"password2\")\n                    and self.cleaned_data[\"password1\"] != self.cleaned_data[\"password2\"]\n                ):\n                    raise ValidationError(\"Please make sure your passwords match.\")\n                return self.cleaned_data\n\n        @override_settings(FORM_RENDERER=CustomRenderer)\n            if request.method == \"POST\":\n                form = UserRegistration(request.POST, auto_id=False)\n            else:\n                form = UserRegistration(auto_id=False)\n            if form.is_valid():\n                return \"VALID\"\n            return render(request, \"forms_tests/custom_form.html\", {\"form\": form})\n\n        response = test_view(MockRequest(method=\"POST\", POST={\"username\": \"django\", \"password1\": \"foo\", \"password2\": \"bar\"}))\n        self.assertHTMLEqual(\n            response.content,\n            b'<div class=\"fieldWrapper\"><label for=\"id_username\">Username:</label><input type=\"text\" name=\"username\" required id=\"id_username\"></div>'\n            b'<div class=\"fieldWrapper\"><label for=\"id_password1\">Password1:</label><input type=\"password\" name=\"password1\" required id=\"id_password1\"></div>'\n            b'<div class=\"fieldWrapper\"><label for=\"id_password2\">Password2:</label><input type=\"password\" name=\"password2\" required id=\"id_password2\"></div>'\n            b'<div class=\"errorlist\"><li>Please make sure your passwords match.</li></div>',\n        )\n\n\n\n"], "sample_433": ["    def test_multiple_migrations_with_same_name(self):\n        class Migration(migrations.Migration):\n            operations = [migrations.CreateModel(\"Person\", fields=[])]\n\n        migration1 = Migration(\"0001_initial\", \"test_app\")\n        migration2 = Migration(\"0001_initial\", \"test_app\")\n        self.assertEqual(migration1.suggest_name(), migration2.suggest_name())\n"], "sample_130": ["    def test_complex_related_lookups(self):\n        query = Query(Ranking)\n        where = query.build_where(Q(author__name__icontains='foo') & Q(rank__gt=10))\n        self.assertEqual(where.connector, AND)\n\n        author_lookup = where.children[0]\n        self.assertIsInstance(author_lookup, Q)\n        self.assertEqual(author_lookup.children[0].__class__.__name__, 'Contains')\n        self.assertEqual(author_lookup.children[0].rhs, 'foo')\n        self.assertEqual(author_lookup.children[0].lhs.target, Author._meta.get_field('name'))\n\n        rank_lookup = where.children[1]\n        self.assertIsInstance(rank_lookup, GreaterThan)\n        self.assertEqual(rank_lookup.rhs, 10)\n        self.assertEqual(rank_lookup.lhs.target, Ranking._meta.get_field('rank'))\n"], "sample_117": ["    def test_password_too_short(self):\n        user = User.objects.get(username='testclient')\n        data = {'password1': 'abc', 'password2': 'abc'}\n        form = AdminPasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertIn('password1', form.errors)\n        self.assertIn('password2', form.errors)\n        self.assertIn('This password is too short. It must contain at least 8 characters.', form.errors['password1'][0])\n        self.assertIn('This password is too short. It must contain at least 8 characters.', form.errors['password2'][0])\n\n\n\n"], "sample_222": ["    def test_spooled_temp_file_close_after_read(self):\n        with tempfile.SpooledTemporaryFile() as temp:\n            temp.write(b\"foo bar baz quux\\n\")\n            temp.seek(0)\n            django_file = File(temp, name=\"something.txt\")\n            django_file.read()\n        # Check that the file is closed\n        self.assertTrue(temp.closed)\n"], "sample_20": ["def test_masked_column_with_units(tmp_path):\n    filename = tmp_path / \"test_masked_units.fits\"\n    t = Table([np.array([1.0, 2.0, np.nan], dtype=float),\n               np.array([1.0, 2.0, np.nan], dtype=float)],\n              names=[\"a\", \"b\"],\n              meta={\"a\": {\"unit\": \"m/s\"}})\n    t[\"a\"].mask = [False, True, False]\n    t[\"b\"].mask = [True, False, True]\n    t.write(filename, format=\"fits\")\n\n    t2 = Table.read(filename)\n    assert np.all(t[\"a\"].mask == t2[\"a\"].mask)\n    assert np.all(t[\"b\"].mask == t2[\"b\"].mask)\n    assert t[\"a\"].unit == t2[\"a\"].unit\n"], "sample_577": ["    def test_default_object_is_hashable(self):\n        assert hash(Default()) == hash(\"<default>\")\n"], "sample_849": ["def test_repeated_stratified_kfold_with_groups():\n    rng = np.random.RandomState(42)\n    X = np.random.rand(100, 5)\n    y = rng.randint(0, 2, size=100)\n    groups = rng.randint(0, 5, size=100)\n\n    rskf = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=42)\n    for train, test in rskf.split(X, y, groups=groups):\n        assert len(np.unique(groups[train])) == 5\n        assert len(np.unique(groups[test])) == 5\n"], "sample_1193": ["compilation error"], "sample_17": ["    def test_dispatch_to_quantity(self, func):\n        x = np.array([1, 2, 3]) * u.m\n        result = func(x)\n        assert isinstance(result, Quantity)\n        assert result.unit == x.unit\n"], "sample_562": ["def test_line_styles_with_dashes():\n    fig, ax = plt.subplots()\n    for ls in [\"-\", \"--\", \"-.\", \":\", (0, (3, 3)), (0, (5, 5, 1, 5))]:\n        ax.plot(range(10), linestyle=ls, color='C{}'.format(i))\n    fig.canvas.draw()\n"], "sample_991": ["def test_issue_14161():\n    x = Symbol('x')\n    p = Product(x**k, (k, 0, oo))\n    assert p.rewrite(Sum) == exp(Sum(k*log(x), (k, 0, oo)))\n"], "sample_1006": ["def test_subfactorial_rewrite():\n    x = Symbol('x')\n    assert subfactorial(x).rewrite(factorial) == factorial(x)/factorial(x + 1)\n    assert subfactorial(x).rewrite(gamma) == uppergamma(x + 1, -1)/S.Exp1\n"], "sample_884": ["def test_property_deprecation():\n    with pytest.warns(FutureWarning, match=\"n_features_ is deprecated\"):\n        instance = MockClass2()\n        assert instance.n_features_ == 10\n"], "sample_652": ["compilation error"], "sample_711": ["def test_node_repr_failure_with_fixture_import_failure(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            raise Exception(\"Fixture import failure\")\n\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            str(\n                Path(__file__).parent / \"test_node.py\"\n            )\n            + \":*: Fixture import failure\",\n            \"*1 failed in *\",\n        ]\n    )\n"], "sample_755": ["def test_silhouette_sparse_matrices():\n    # Test with sparse matrices\n    dataset = datasets.load_iris()\n    X_dense = dataset.data\n    X_csr = csr_matrix(X_dense)\n    X_dok = sp.dok_matrix(X_dense)\n    X_lil = sp.lil_matrix(X_dense)\n    y = dataset.target\n\n    for X in [X_csr, X_dok, X_lil]:\n        D = pairwise_distances(X, metric='euclidean')\n        score_precomputed = silhouette_score(D, y, metric='precomputed')\n        assert score_precomputed > 0\n        score_euclidean = silhouette_score(X, y, metric='euclidean')\n        pytest.approx(score_precomputed, score_euclidean)\n\n\n\n"], "sample_118": ["    def test_exact_query_rhs_with_selected_columns_multiple(self):\n        newest_author = Author.objects.create(name='Author 2')\n        authors_max_ids = Author.objects.filter(\n            name='Author 2',\n        ).values(\n            'name',\n        ).annotate(\n            max_id=Max('id'),\n        ).values('max_id')\n        authors = Author.objects.filter(id__in=authors_max_ids[:2])\n        self.assertEqual(len(authors), 2)\n"], "sample_1192": ["def test_symbols_with_spaces():\n    x = Symbol('x ')\n    y = Symbol(' y')\n    z = Symbol('z ')\n    assert x == Symbol('x')\n    assert y == Symbol('y')\n    assert z == Symbol('z')\n    assert symbols('x y z') == (x, y, z)\n"], "sample_453": ["    def test_override_prepopulated_fields_js(self):\n        article = Article.objects.all()[0]\n        request = self.factory.get(\n            reverse(\"admin:admin_views_article_change\", args=[article.pk])\n        )\n        request.user = self.superuser\n        admin = ArticleAdmin(Article, site)\n        response = admin.change_view(request, str(article.pk))\n        response.render()\n        self.assertContains(response, \"override-prepopulated_fields_js\")\n"], "sample_843": ["def test_kernel_is_stationary(kernel):\n    # Test the is_stationary method of kernels.\n    assert kernel.is_stationary() == kernel.is_stationary()\n"], "sample_207": ["    def test_contains_with_key_transform_and_subquery(self):\n        subquery = NullableJSONModel.objects.filter(value__baz__a='b').values('pk')\n        self.assertIs(NullableJSONModel.objects.filter(\n            value__contains=KeyTransform('baz', subquery),\n        ).exists(), True)\n"], "sample_224": ["    def test_aggregation_subquery_annotation_with_distinct(self):\n        distinct_authors_qs = Author.objects.filter(\n            pk=OuterRef('pk'),\n        ).values('name').annotate(\n            distinct_count=Count('name', distinct=True)\n        )\n        author_qs = Author.objects.annotate(\n            distinct_author_count=Subquery(distinct_authors_qs),\n        ).annotate(count=Count('book'))\n        self.assertEqual(author_qs.count(), Author.objects.count())\n"], "sample_527": ["def test_toolmanager_add_tool():\n    with pytest.warns(UserWarning, match=_EXPECTED_WARNING_TOOLMANAGER):\n        plt.rcParams['toolbar'] = 'toolmanager'\n    fig = plt.gcf()\n    initial_len = len(fig.canvas.manager.toolmanager.tools)\n    tool_name = 'my_tool'\n    class MyTool(object):\n        pass\n    fig.canvas.manager.toolmanager.add_tool(tool_name, MyTool())\n    assert len(fig.canvas.manager.toolmanager.tools) == initial_len + 1\n    assert fig.canvas.manager.toolmanager.get_tool(tool_name) is not None\n    with pytest.warns(UserWarning, match=f\"Tool '{tool_name}' already exists\"):\n        fig.canvas.manager.toolmanager.add_tool(tool_name, MyTool())\n"], "sample_1036": ["def test_matmul_with_symbols():\n    a, b = symbols('a b', commutative=False)\n    assert MatMul(a, b, A, A.T).args == (a, b, A, A.T)\n    assert MatMul(a, A, b, A.T).args == (a, A, b, A.T)\n"], "sample_822": ["def test_pairwise_distances_chunked_sparse_matrices():\n    # Test pairwise_distances_chunked with sparse matrices\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((1000, 10)).astype(np.float32)\n    Y = rng.random_sample((1000, 10)).astype(np.float32)\n    X_sparse = csr_matrix(X)\n    Y_sparse = csr_matrix(Y)\n\n    # Test with dense output\n    dist_dense = pairwise_distances_chunked(X_sparse, Y_sparse,\n                                          dense_output=True,\n                                          working_memory=1)\n    dist_sparse = pairwise_distances_chunked(X_sparse, Y_sparse,\n                                          dense_output=False,\n                                          working_memory=1)\n    assert_array_almost_equal(dist_dense, dist_sparse.todense())\n\n    # Test with sparse output\n    dist_sparse = pairwise_distances_chunked(X_sparse, Y_sparse,\n                                          dense_output=False,\n                                          working_memory=1)\n    assert issparse(dist_sparse)\n\n    # Test with different chunk sizes\n    for chunk_size in [100, 500, 1000]:\n        dist_sparse = pairwise_distances_chunked(X_sparse, Y_sparse,\n                                              dense_output=False,\n                                              chunk_size=chunk_size,\n                                              working_memory=1)\n        assert issparse(dist_sparse)\n\n\n\n"], "sample_80": ["    def test_related_fields(self):\n        query = Query(Author)\n        where = query.build_where(Q(book__title__icontains='Django'))\n        lookup = where.children[0]\n        self.assertIsInstance(lookup, Q)\n        self.assertEqual(lookup.children[0].connector, OR)\n        self.assertEqual(lookup.children[0].children[0].lhs.target, Book._meta.get_field('title'))\n        self.assertEqual(lookup.children[0].children[0].rhs, 'Django')\n\n"], "sample_1124": ["def test_FracElement_gcd():\n    F, x,y = field(\"x,y\", ZZ)\n    f = (x**2 + 3*y)/(x*y)\n    g = (x*y + 1)/(x**2 + 1)\n\n    assert f.gcd(g) == 1\n    assert g.gcd(f) == 1\n\n    h = (x**2 + 3*y)/(x*y)\n    assert h.gcd(h) == h\n    assert h.gcd(1) == 1\n\n    raises(TypeError, lambda: f.gcd(x))\n    raises(TypeError, lambda: f.gcd(F.ring))\n"], "sample_676": ["compilation error"], "sample_1118": ["def test_matpow_zero_exponent():\n    A = MatrixSymbol('A', 2, 2)\n    assert MatPow(A, 0).doit() == Identity(2)\n    assert MatPow(ZeroMatrix(2, 2), 0).doit() == Identity(2)\n    assert MatPow(OneMatrix(2, 2), 0).doit() == Identity(2)\n"], "sample_1009": ["compilation error"], "sample_910": ["def test_pending_logging_flush(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    with logging.pending_logging() as memhandler:\n        logger.warning('message1')\n        logger.warning('message2')\n\n    assert 'WARNING: message1\\nWARNING: message2' in strip_escseq(warning.getvalue())\n"], "sample_551": ["def test_poly_collection_3d():\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    verts = np.array([\n        [[0, 0, 0], [1, 0, 0], [1, 1, 0], [0, 1, 0]],\n        [[0, 0, 1], [1, 0, 1], [1, 1, 1], [0, 1, 1]]\n    ])\n    poly_collection = Poly3DCollection(verts, facecolors='b', edgecolors='k')\n    ax.add_collection3d(poly_collection)\n    ax.set_xlim([0, 1.2])\n    ax.set_ylim([0, 1.2])\n    ax.set_zlim([0, 1.2])\n    ax.set_xlabel('X')\n    ax.set_ylabel('Y')\n    ax.set_zlabel('Z')\n    plt.show()\n"], "sample_1142": ["def test_matrix_transpose():\n    A = MatrixSymbol('A', 2, 3)\n    B = MatrixSymbol('B', 3, 2)\n    C = Transpose(A)\n    assert C.shape == (3, 2)\n    assert C[i, j] == A[j, i]\n    assert Transpose(Transpose(A)) == A\n    assert Transpose(A*B) == Transpose(B).T * Transpose(A).T\n    assert Transpose(A + B) == Transpose(A) + Transpose(B)\n    assert Transpose(A - B) == Transpose(A) - Transpose(B)\n    assert Transpose(A**2) == Transpose(A)**2\n    assert Transpose(A.T) == A\n    assert Transpose(ZeroMatrix(2, 3)) == ZeroMatrix(3, 2)\n    assert Transpose(Identity(2)) == Identity(2)\n"], "sample_163": ["    def test_user_change_password_with_custom_user_model(self):\n        u = UUIDUser.objects.create_superuser(\n            username=\"uuid\", email=\"foo@bar.com\", password=\"test\"\n        )\n        self.assertTrue(self.client.login(username=\"uuid\", password=\"test\"))\n\n        user_change_url = reverse(\n            \"custom_user_admin:auth_tests_uuiduser_change\", args=(u.pk,)\n        )\n        response = self.client.get(user_change_url)\n        self.assertEqual(response.status_code, 200)\n\n        password_change_url = reverse(\n            \"custom_user_admin:auth_tests_uuiduser_password_change\", args=(u.pk,)\n        )\n        response = self.client.get(password_change_url)\n        self.assertEqual(response.status_code, 200)\n\n        response = self.client.post(\n            password_change_url,\n            {\n                \"password1\": \"password1\",\n                \"password2\": \"password1\",\n            },\n        )\n        self.assertRedirects(response, user_change_url)\n        row = LogEntry.objects.latest(\"id\")\n        self.assertEqual(row.user_id, 1)  # hardcoded in CustomUserAdmin.log_change()\n        self.assertEqual(row.object_id, str(u.pk))\n        self.assertEqual(row.get_change_message(), \"Changed password.\")\n"], "sample_254": ["    def test_inline_formset_error_with_stacked_and_tabular_inlines(self):\n        self.admin_login(username='super', password='secret')\n        self.selenium.get(self.live_server_url + reverse('admin:admin_inlines_holder6_add'))\n        stacked_inline_formset_selector = 'div#inner6stacked_set-group fieldset.module.collapse'\n        tabular_inline_formset_selector = 'div#inner6tabular_set-group fieldset.module.collapse'\n        # Inlines without errors, both inlines collapsed\n        self.selenium.find_element_by_xpath('//input[@value=\"Save\"]').click()\n        self.assertEqual(\n            len(self.selenium.find_elements_by_css_selector(stacked_inline_formset_selector + '.collapsed')), 1\n        )\n        self.assertEqual(\n            len(self.selenium.find_elements_by_css_selector(tabular_inline_formset_selector + '.collapsed')), 1\n        )\n        show_links = self.selenium.find_elements_by_link_text('SHOW')\n        self.assertEqual(len(show_links), 2)\n\n        # Inlines with errors, both inlines expanded\n        test_fields = [\n            '#id_inner6stacked_set-0-dummy',\n            '#id_inner6tabular_set-0-dummy',\n        ]\n        for show_index, field_name in enumerate(test_fields):\n            show_links[show_index].click()\n            self.wait_until_visible(field_name)\n            self.selenium.find_element_by_id(field_name[1:]).send_keys(1)\n        hide_links = self.selenium.find_elements_by_link_text('HIDE')\n        self.assertEqual(len(hide_links), 2)\n        for hide_index, field_name in enumerate(test_fields):\n            hide_link = hide_links[hide_index]\n            self.selenium.execute_script('window.scrollTo(0, %s);' % hide_link.location['y'])\n            hide_link.click()\n            "], "sample_880": ["compilation error"], "sample_1106": ["def test_matmul_with_zero_matrix():\n    assert MatMul(A, ZeroMatrix(m, n)).doit() == ZeroMatrix(n, n)\n    assert MatMul(ZeroMatrix(n, m), B).doit() == ZeroMatrix(n, l)\n    assert MatMul(A, ZeroMatrix(m, n), B).doit() == ZeroMatrix(n, l)\n"], "sample_1077": ["def test_issue_12116():\n    a = Interval(0, 1)\n    b = Interval(1, 2)\n    c = ComplexRegion(a * b)\n    assert c.measure == 1\n    assert c.measure == 1\n    assert c.measure == 1\n\n\n\n"], "sample_478": ["    def test_actions_with_custom_permissions_has_method(self):\n        @admin.action(permissions=[\"custom\"])\n            pass\n\n        class BandAdmin(ModelAdmin):\n            actions = (custom_permission_action,)\n\n                return request.user.is_staff\n\n        self.assertIsValid(BandAdmin, Band)\n"], "sample_505": ["def test_date2num_with_tzinfo():\n    tz = dateutil.tz.gettz('Europe/London')\n    dt = datetime.datetime(2023, 10, 26, 10, 0, tzinfo=tz)\n    num = mdates.date2num(dt)\n    assert isinstance(num, float)\n    assert mdates.num2date(num, tz=tz) == dt\n"], "sample_643": ["def test_template_option_with_custom_fields(linter: PyLinter) -> None:\n    output = StringIO()\n    linter.reporter.out = output\n    linter.config.msg_template = \"{path}:{line}:{col}:{msg_id} ({symbol}) - {obj}\"\n    linter.open()\n    linter.set_current_module(\"my_mod\")\n\n    linter.add_message(\"C0301\", line=1, args=(1, 2), obj=\"my_object\")\n    linter.add_message(\n        \"line-too-long\", line=2, end_lineno=2, end_col_offset=4, args=(3, 4)\n    )\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert out_lines[1] == \"my_mod:1:0: C0301 (line-too-long) - my_object\"\n    assert out_lines[2] == \"my_mod:2:0: line-too-long (line-too-long) - \"\n\n\n\n"], "sample_236": ["    def test_fast_delete_related_fields_with_signals(self):\n        \"\"\"\n        Fast-deleting related fields should not trigger deletion signals\n        if they are not explicitly connected.\n        \"\"\"\n        class MySignalReceiver:\n                self.called = False\n\n                self.called = True\n\n        receiver = MySignalReceiver()\n        models.signals.post_delete.connect(receiver.receiver, sender=Referrer)\n\n        origin = Origin.objects.create()\n        referer = Referrer.objects.create(origin=origin, unique_field=42)\n        with self.assertNumQueries(2):\n            referer.delete()\n\n        self.assertFalse(receiver.called)\n        models.signals.post_delete.disconnect(receiver.receiver, sender=Referrer)\n"], "sample_954": ["def test_productionlist(app, status, warning):\n    app.builder.build_all()\n    content = (app.outdir / 'python.1').read_text()\n    assert '.nf\\n' in content\n    assert '.fi\\n' in content\n    assert ' ::= ' in content\n"], "sample_395": ["    def test_get_template_directories_no_dirs(self):\n        self.assertSetEqual(autoreload.get_template_directories(), set())\n"], "sample_701": ["def test_argument_percent_default(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        import argparse\n\n            parser.addoption(\n                \"--myoption\",\n                type=str,\n                default=\"%default\",\n                help=\"My option\",\n            )\n        \"\"\"\n    )\n    result = pytester.runpytest(\"--myoption\", \"--myoption=value\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: pytest now uses argparse. \\\"\\\\%default\\\" should be changed to \\\"\\\\%default\\\"*\n        ]\n    )\n"], "sample_1019": ["compilation error"]}, "raw_scored_generations": {"sample_0": [false], "sample_1": [false], "sample_3": [false], "sample_2": [false], "sample_4": [false], "sample_5": [false], "sample_6": [false], "sample_7": [false], "sample_8": [false], "sample_9": [false], "sample_10": [false], "sample_11": [false], "sample_12": [false], "sample_13": [false], "sample_14": [false], "sample_15": [true], "sample_16": [true], "sample_17": [false], "sample_18": [false], "sample_19": [false], "sample_20": [false], "sample_21": [false], "sample_22": [false], "sample_23": [true], "sample_24": [false], "sample_25": [true], "sample_26": [false], "sample_27": [true], "sample_28": [true], "sample_29": [false], "sample_30": [true], "sample_31": [false], "sample_32": [true], "sample_33": [false], "sample_34": [false], "sample_35": [true], "sample_36": [true], "sample_37": [false], "sample_38": [false], "sample_39": [false], "sample_40": [false], "sample_41": [false], "sample_42": [false], "sample_43": [false], "sample_44": [false], "sample_45": [false], "sample_46": [false], "sample_47": [true], "sample_48": [false], "sample_49": [false], "sample_50": [false], "sample_51": [true], "sample_52": [true], "sample_54": [false], "sample_53": [false], "sample_55": [false], "sample_58": [false], "sample_56": [false], "sample_57": [false], "sample_59": [true], "sample_60": [false], "sample_61": [true], "sample_62": [true], "sample_63": [false], "sample_64": [false], "sample_65": [true], "sample_67": [false], "sample_66": [true], "sample_68": [true], "sample_69": [false], "sample_70": [false], "sample_71": [false], "sample_72": [false], "sample_73": [false], "sample_75": [false], "sample_74": [false], "sample_76": [true], "sample_77": [false], "sample_78": [false], "sample_79": [false], "sample_80": [false], "sample_82": [false], "sample_81": [false], "sample_83": [false], "sample_85": [false], "sample_84": [true], "sample_86": [false], "sample_88": [false], "sample_87": [false], "sample_89": [false], "sample_90": [false], "sample_91": [false], "sample_92": [false], "sample_93": [false], "sample_94": [false], "sample_95": [false], "sample_98": [false], "sample_96": [false], "sample_99": [false], "sample_97": [true], "sample_100": [true], "sample_102": [false], "sample_101": [false], "sample_103": [false], "sample_104": [false], "sample_107": [true], "sample_106": [false], "sample_105": [false], "sample_108": [false], "sample_109": [true], "sample_111": [true], "sample_110": [false], "sample_112": [false], "sample_113": [false], "sample_114": [true], "sample_115": [false], "sample_116": [false], "sample_117": [false], "sample_118": [false], "sample_119": [false], "sample_120": [false], "sample_121": [false], "sample_122": [false], "sample_123": [false], "sample_124": [true], "sample_125": [true], "sample_126": [false], "sample_127": [false], "sample_128": [false], "sample_129": [true], "sample_130": [false], "sample_131": [true], "sample_132": [false], "sample_133": [true], "sample_135": [false], "sample_134": [false], "sample_136": [true], "sample_139": [true], "sample_137": [false], "sample_138": [true], "sample_140": [false], "sample_141": [false], "sample_142": [false], "sample_143": [false], "sample_144": [false], "sample_145": [false], "sample_146": [false], "sample_147": [false], "sample_148": [false], "sample_151": [false], "sample_149": [true], "sample_152": [false], "sample_150": [false], "sample_153": [false], "sample_154": [false], "sample_155": [false], "sample_156": [false], "sample_157": [false], "sample_158": [false], "sample_159": [true], "sample_160": [false], "sample_161": [false], "sample_162": [true], "sample_163": [false], "sample_164": [false], "sample_165": [true], "sample_166": [true], "sample_167": [false], "sample_168": [false], "sample_169": [false], "sample_171": [false], "sample_170": [false], "sample_172": [true], "sample_173": [false], "sample_174": [false], "sample_175": [false], "sample_176": [false], "sample_177": [false], "sample_178": [false], "sample_180": [false], "sample_179": [false], "sample_182": [false], "sample_181": [false], "sample_183": [false], "sample_184": [false], "sample_185": [false], "sample_186": [false], "sample_187": [false], "sample_188": [false], "sample_189": [false], "sample_190": [false], "sample_191": [true], "sample_192": [false], "sample_193": [false], "sample_194": [false], "sample_195": [false], "sample_196": [false], "sample_198": [true], "sample_197": [false], "sample_199": [false], "sample_200": [false], "sample_201": [false], "sample_202": [false], "sample_203": [false], "sample_204": [false], "sample_205": [false], "sample_206": [false], "sample_207": [false], "sample_208": [false], "sample_209": [false], "sample_210": [false], "sample_211": [false], "sample_213": [false], "sample_212": [false], "sample_214": [false], "sample_215": [false], "sample_216": [false], "sample_217": [false], "sample_218": [false], "sample_219": [false], "sample_220": [true], "sample_221": [false], "sample_222": [true], "sample_223": [true], "sample_224": [false], "sample_225": [false], "sample_226": [false], "sample_227": [false], "sample_228": [false], "sample_229": [false], "sample_230": [false], "sample_231": [false], "sample_232": [false], "sample_233": [true], "sample_234": [false], "sample_235": [false], "sample_236": [false], "sample_237": [false], "sample_238": [false], "sample_239": [false], "sample_240": [false], "sample_241": [true], "sample_242": [false], "sample_243": [false], "sample_244": [false], "sample_245": [true], "sample_246": [true], "sample_247": [false], "sample_248": [true], "sample_249": [false], "sample_250": [false], "sample_251": [false], "sample_252": [false], "sample_253": [true], "sample_254": [true], "sample_256": [false], "sample_255": [false], "sample_257": [false], "sample_258": [false], "sample_259": [false], "sample_260": [true], "sample_261": [false], "sample_262": [false], "sample_263": [false], "sample_264": [false], "sample_265": [true], "sample_266": [false], "sample_267": [true], "sample_268": [true], "sample_269": [true], "sample_270": [false], "sample_271": [true], "sample_272": [false], "sample_273": [false], "sample_274": [false], "sample_275": [false], "sample_276": [true], "sample_277": [false], "sample_278": [false], "sample_279": [false], "sample_280": [false], "sample_281": [true], "sample_282": [false], "sample_283": [false], "sample_284": [false], "sample_285": [false], "sample_286": [false], "sample_287": [false], "sample_288": [true], "sample_289": [false], "sample_290": [true], "sample_291": [true], "sample_292": [true], "sample_293": [false], "sample_294": [false], "sample_295": [true], "sample_296": [false], "sample_297": [false], "sample_298": [true], "sample_299": [false], "sample_300": [false], "sample_301": [true], "sample_302": [false], "sample_303": [false], "sample_304": [true], "sample_305": [true], "sample_306": [false], "sample_307": [false], "sample_308": [true], "sample_309": [true], "sample_310": [false], "sample_312": [false], "sample_311": [true], "sample_313": [false], "sample_314": [false], "sample_315": [true], "sample_316": [true], "sample_317": [false], "sample_318": [false], "sample_319": [false], "sample_320": [false], "sample_321": [true], "sample_322": [false], "sample_323": [true], "sample_324": [false], "sample_325": [true], "sample_326": [false], "sample_327": [false], "sample_328": [false], "sample_329": [false], "sample_330": [false], "sample_331": [false], "sample_332": [true], "sample_333": [false], "sample_334": [true], "sample_335": [true], "sample_336": [false], "sample_337": [true], "sample_338": [true], "sample_339": [false], "sample_340": [false], "sample_341": [false], "sample_342": [true], "sample_343": [false], "sample_344": [false], "sample_345": [true], "sample_346": [false], "sample_347": [false], "sample_348": [false], "sample_349": [false], "sample_350": [false], "sample_351": [false], "sample_352": [false], "sample_353": [false], "sample_354": [false], "sample_355": [false], "sample_356": [true], "sample_357": [true], "sample_358": [false], "sample_359": [false], "sample_360": [false], "sample_361": [false], "sample_362": [true], "sample_363": [false], "sample_364": [false], "sample_365": [false], "sample_366": [false], "sample_367": [false], "sample_368": [true], "sample_369": [false], "sample_370": [false], "sample_371": [false], "sample_372": [false], "sample_373": [false], "sample_374": [true], "sample_375": [false], "sample_376": [false], "sample_377": [false], "sample_378": [false], "sample_379": [true], "sample_380": [false], "sample_381": [false], "sample_382": [false], "sample_383": [false], "sample_384": [false], "sample_385": [false], "sample_386": [true], "sample_387": [false], "sample_388": [true], "sample_389": [false], "sample_390": [false], "sample_391": [false], "sample_392": [true], "sample_393": [false], "sample_394": [true], "sample_395": [false], "sample_396": [false], "sample_397": [true], "sample_398": [false], "sample_399": [false], "sample_400": [false], "sample_401": [false], "sample_402": [false], "sample_403": [false], "sample_404": [false], "sample_405": [false], "sample_406": [true], "sample_407": [true], "sample_408": [false], "sample_409": [false], "sample_410": [true], "sample_411": [false], "sample_412": [false], "sample_413": [true], "sample_414": [false], "sample_415": [false], "sample_416": [true], "sample_417": [false], "sample_418": [false], "sample_419": [false], "sample_420": [false], "sample_421": [false], "sample_422": [false], "sample_423": [false], "sample_424": [false], "sample_425": [false], "sample_426": [false], "sample_427": [true], "sample_428": [false], "sample_429": [false], "sample_430": [false], "sample_431": [false], "sample_432": [true], "sample_433": [true], "sample_434": [false], "sample_435": [false], "sample_436": [true], "sample_437": [false], "sample_438": [false], "sample_439": [false], "sample_440": [false], "sample_441": [false], "sample_442": [false], "sample_443": [false], "sample_444": [false], "sample_445": [false], "sample_446": [false], "sample_447": [false], "sample_448": [false], "sample_449": [false], "sample_450": [false], "sample_451": [false], "sample_453": [false], "sample_452": [false], "sample_454": [false], "sample_455": [false], "sample_456": [false], "sample_457": [false], "sample_458": [false], "sample_459": [false], "sample_460": [true], "sample_461": [false], "sample_462": [false], "sample_463": [false], "sample_464": [true], "sample_465": [false], "sample_466": [false], "sample_467": [false], "sample_469": [false], "sample_468": [false], "sample_470": [false], "sample_471": [false], "sample_472": [true], "sample_473": [false], "sample_474": [false], "sample_475": [false], "sample_476": [false], "sample_477": [false], "sample_478": [false], "sample_479": [false], "sample_480": [false], "sample_481": [false], "sample_482": [false], "sample_483": [false], "sample_484": [true], "sample_485": [false], "sample_486": [false], "sample_487": [false], "sample_488": [false], "sample_489": [true], "sample_490": [false], "sample_491": [false], "sample_492": [false], "sample_493": [false], "sample_494": [false], "sample_495": [false], "sample_496": [false], "sample_497": [true], "sample_498": [true], "sample_499": [false], "sample_500": [false], "sample_501": [false], "sample_502": [false], "sample_503": [false], "sample_504": [false], "sample_505": [true], "sample_506": [false], "sample_507": [true], "sample_508": [true], "sample_509": [false], "sample_510": [false], "sample_511": [false], "sample_512": [false], "sample_513": [false], "sample_514": [false], "sample_515": [false], "sample_516": [false], "sample_517": [false], "sample_518": [true], "sample_519": [false], "sample_520": [false], "sample_521": [false], "sample_522": [true], "sample_523": [false], "sample_524": [false], "sample_525": [false], "sample_526": [true], "sample_527": [false], "sample_528": [false], "sample_529": [true], "sample_530": [false], "sample_531": [false], "sample_532": [false], "sample_533": [true], "sample_534": [false], "sample_535": [false], "sample_536": [false], "sample_537": [false], "sample_538": [false], "sample_539": [false], "sample_540": [false], "sample_541": [false], "sample_542": [false], "sample_543": [false], "sample_544": [false], "sample_545": [false], "sample_546": [false], "sample_547": [false], "sample_548": [false], "sample_549": [false], "sample_550": [false], "sample_551": [false], "sample_552": [false], "sample_553": [false], "sample_554": [false], "sample_555": [true], "sample_556": [false], "sample_557": [false], "sample_558": [false], "sample_559": [false], "sample_560": [true], "sample_561": [false], "sample_562": [false], "sample_563": [false], "sample_564": [false], "sample_565": [false], "sample_566": [false], "sample_567": [false], "sample_568": [false], "sample_569": [false], "sample_570": [true], "sample_571": [false], "sample_572": [true], "sample_573": [false], "sample_574": [false], "sample_575": [false], "sample_576": [false], "sample_577": [false], "sample_578": [false], "sample_579": [true], "sample_580": [true], "sample_581": [false], "sample_582": [false], "sample_583": [false], "sample_584": [false], "sample_585": [true], "sample_586": [false], "sample_587": [false], "sample_588": [false], "sample_589": [false], "sample_590": [false], "sample_591": [false], "sample_592": [true], "sample_593": [false], "sample_594": [false], "sample_595": [true], "sample_596": [true], "sample_597": [false], "sample_598": [true], "sample_599": [false], "sample_600": [false], "sample_601": [false], "sample_602": [false], "sample_603": [false], "sample_604": [true], "sample_605": [false], "sample_606": [false], "sample_607": [false], "sample_608": [true], "sample_609": [false], "sample_610": [false], "sample_611": [false], "sample_612": [false], "sample_613": [false], "sample_614": [true], "sample_615": [false], "sample_616": [false], "sample_617": [true], "sample_618": [false], "sample_619": [false], "sample_620": [false], "sample_621": [false], "sample_622": [true], "sample_623": [false], "sample_624": [false], "sample_625": [false], "sample_626": [false], "sample_627": [true], "sample_628": [false], "sample_629": [true], "sample_630": [false], "sample_631": [false], "sample_632": [false], "sample_633": [false], "sample_634": [false], "sample_635": [false], "sample_636": [false], "sample_637": [true], "sample_638": [false], "sample_639": [false], "sample_640": [false], "sample_641": [false], "sample_642": [false], "sample_643": [false], "sample_644": [false], "sample_645": [false], "sample_646": [true], "sample_647": [true], "sample_648": [true], "sample_649": [true], "sample_650": [false], "sample_651": [false], "sample_652": [false], "sample_653": [false], "sample_654": [false], "sample_655": [false], "sample_656": [true], "sample_657": [false], "sample_658": [false], "sample_659": [true], "sample_660": [false], "sample_661": [false], "sample_662": [false], "sample_663": [false], "sample_664": [false], "sample_665": [false], "sample_666": [false], "sample_667": [false], "sample_668": [false], "sample_669": [false], "sample_670": [false], "sample_671": [false], "sample_672": [false], "sample_673": [true], "sample_674": [false], "sample_675": [false], "sample_676": [false], "sample_677": [false], "sample_678": [false], "sample_679": [true], "sample_680": [false], "sample_681": [false], "sample_682": [false], "sample_683": [false], "sample_684": [false], "sample_685": [false], "sample_686": [false], "sample_687": [false], "sample_688": [true], "sample_689": [false], "sample_690": [false], "sample_691": [false], "sample_692": [false], "sample_693": [true], "sample_694": [false], "sample_695": [false], "sample_696": [false], "sample_697": [false], "sample_698": [false], "sample_699": [true], "sample_700": [false], "sample_701": [false], "sample_702": [false], "sample_703": [false], "sample_704": [false], "sample_705": [false], "sample_706": [false], "sample_707": [false], "sample_708": [false], "sample_709": [false], "sample_710": [true], "sample_711": [false], "sample_712": [true], "sample_713": [false], "sample_714": [false], "sample_715": [false], "sample_716": [false], "sample_717": [true], "sample_718": [false], "sample_719": [false], "sample_720": [false], "sample_721": [false], "sample_722": [true], "sample_723": [false], "sample_724": [false], "sample_725": [false], "sample_726": [false], "sample_727": [false], "sample_728": [false], "sample_729": [false], "sample_730": [false], "sample_731": [false], "sample_732": [false], "sample_733": [false], "sample_734": [false], "sample_735": [true], "sample_736": [true], "sample_737": [false], "sample_738": [false], "sample_739": [false], "sample_740": [false], "sample_741": [false], "sample_742": [true], "sample_743": [false], "sample_744": [false], "sample_745": [true], "sample_746": [false], "sample_747": [false], "sample_748": [false], "sample_749": [false], "sample_750": [true], "sample_751": [false], "sample_752": [false], "sample_753": [true], "sample_754": [false], "sample_755": [true], "sample_756": [false], "sample_757": [false], "sample_758": [false], "sample_759": [false], "sample_760": [false], "sample_761": [false], "sample_762": [false], "sample_763": [false], "sample_764": [false], "sample_765": [false], "sample_766": [false], "sample_767": [false], "sample_768": [false], "sample_769": [false], "sample_770": [true], "sample_771": [false], "sample_772": [false], "sample_773": [false], "sample_774": [false], "sample_775": [false], "sample_776": [false], "sample_777": [false], "sample_778": [false], "sample_779": [false], "sample_780": [true], "sample_781": [true], "sample_782": [false], "sample_783": [false], "sample_784": [false], "sample_785": [false], "sample_786": [false], "sample_787": [false], "sample_788": [false], "sample_789": [true], "sample_790": [false], "sample_791": [false], "sample_792": [false], "sample_793": [false], "sample_794": [false], "sample_795": [false], "sample_796": [true], "sample_797": [false], "sample_798": [false], "sample_799": [false], "sample_800": [false], "sample_801": [false], "sample_802": [false], "sample_803": [false], "sample_804": [false], "sample_805": [true], "sample_806": [false], "sample_807": [false], "sample_808": [true], "sample_809": [false], "sample_810": [false], "sample_811": [false], "sample_812": [false], "sample_813": [false], "sample_814": [false], "sample_815": [false], "sample_816": [false], "sample_817": [false], "sample_818": [true], "sample_819": [false], "sample_820": [false], "sample_821": [false], "sample_822": [false], "sample_823": [false], "sample_824": [false], "sample_825": [false], "sample_826": [false], "sample_827": [false], "sample_828": [false], "sample_829": [false], "sample_830": [true], "sample_831": [false], "sample_832": [false], "sample_833": [false], "sample_834": [false], "sample_835": [false], "sample_836": [false], "sample_837": [false], "sample_838": [false], "sample_839": [false], "sample_840": [false], "sample_841": [false], "sample_842": [false], "sample_843": [false], "sample_844": [false], "sample_845": [false], "sample_846": [false], "sample_847": [true], "sample_848": [false], "sample_849": [true], "sample_850": [false], "sample_851": [true], "sample_852": [false], "sample_853": [false], "sample_854": [false], "sample_855": [true], "sample_856": [false], "sample_857": [true], "sample_858": [false], "sample_859": [false], "sample_860": [false], "sample_861": [true], "sample_862": [false], "sample_863": [false], "sample_864": [true], "sample_865": [true], "sample_866": [false], "sample_867": [false], "sample_868": [false], "sample_869": [true], "sample_870": [false], "sample_871": [false], "sample_872": [false], "sample_873": [false], "sample_874": [false], "sample_875": [false], "sample_876": [false], "sample_877": [false], "sample_878": [false], "sample_879": [false], "sample_880": [false], "sample_881": [false], "sample_882": [false], "sample_883": [false], "sample_884": [true], "sample_885": [true], "sample_886": [true], "sample_887": [false], "sample_888": [false], "sample_889": [false], "sample_890": [false], "sample_891": [false], "sample_892": [true], "sample_893": [false], "sample_894": [false], "sample_895": [false], "sample_896": [false], "sample_897": [false], "sample_898": [false], "sample_899": [false], "sample_900": [false], "sample_901": [false], "sample_902": [false], "sample_903": [false], "sample_904": [false], "sample_905": [false], "sample_906": [false], "sample_907": [false], "sample_908": [false], "sample_909": [false], "sample_910": [true], "sample_911": [false], "sample_912": [false], "sample_913": [false], "sample_914": [true], "sample_915": [false], "sample_916": [false], "sample_917": [false], "sample_918": [false], "sample_919": [false], "sample_920": [false], "sample_921": [false], "sample_922": [false], "sample_923": [false], "sample_924": [false], "sample_925": [false], "sample_926": [false], "sample_927": [false], "sample_928": [false], "sample_929": [false], "sample_930": [false], "sample_931": [false], "sample_932": [false], "sample_933": [false], "sample_934": [false], "sample_935": [false], "sample_936": [false], "sample_937": [true], "sample_938": [false], "sample_939": [false], "sample_940": [false], "sample_941": [false], "sample_942": [false], "sample_943": [false], "sample_944": [false], "sample_945": [false], "sample_946": [false], "sample_947": [false], "sample_948": [false], "sample_949": [false], "sample_950": [false], "sample_951": [false], "sample_952": [false], "sample_953": [false], "sample_954": [false], "sample_955": [true], "sample_956": [true], "sample_957": [false], "sample_958": [false], "sample_959": [false], "sample_960": [false], "sample_961": [false], "sample_962": [false], "sample_963": [false], "sample_964": [false], "sample_965": [false], "sample_966": [false], "sample_967": [false], "sample_968": [false], "sample_969": [false], "sample_970": [false], "sample_971": [false], "sample_972": [false], "sample_973": [false], "sample_974": [false], "sample_975": [false], "sample_976": [true], "sample_977": [false], "sample_978": [false], "sample_979": [false], "sample_980": [false], "sample_981": [false], "sample_982": [false], "sample_983": [false], "sample_984": [true], "sample_985": [false], "sample_986": [false], "sample_987": [false], "sample_988": [false], "sample_989": [true], "sample_990": [false], "sample_991": [false], "sample_992": [false], "sample_993": [false], "sample_994": [true], "sample_995": [true], "sample_996": [true], "sample_997": [false], "sample_998": [false], "sample_999": [false], "sample_1000": [false], "sample_1001": [false], "sample_1002": [false], "sample_1003": [false], "sample_1004": [false], "sample_1005": [false], "sample_1006": [false], "sample_1007": [false], "sample_1008": [true], "sample_1009": [false], "sample_1010": [false], "sample_1011": [true], "sample_1012": [false], "sample_1013": [false], "sample_1014": [false], "sample_1015": [false], "sample_1016": [false], "sample_1017": [false], "sample_1018": [true], "sample_1019": [false], "sample_1020": [false], "sample_1021": [false], "sample_1022": [false], "sample_1023": [false], "sample_1024": [false], "sample_1025": [false], "sample_1026": [false], "sample_1027": [true], "sample_1028": [false], "sample_1029": [false], "sample_1030": [false], "sample_1031": [false], "sample_1032": [false], "sample_1033": [true], "sample_1034": [false], "sample_1035": [false], "sample_1036": [false], "sample_1037": [false], "sample_1038": [false], "sample_1039": [false], "sample_1040": [false], "sample_1041": [false], "sample_1042": [false], "sample_1043": [false], "sample_1044": [true], "sample_1045": [true], "sample_1046": [false], "sample_1047": [true], "sample_1048": [false], "sample_1049": [false], "sample_1050": [false], "sample_1051": [false], "sample_1052": [true], "sample_1053": [false], "sample_1054": [false], "sample_1055": [true], "sample_1056": [false], "sample_1057": [false], "sample_1058": [false], "sample_1059": [false], "sample_1060": [false], "sample_1061": [true], "sample_1062": [false], "sample_1063": [true], "sample_1064": [true], "sample_1065": [false], "sample_1066": [false], "sample_1067": [true], "sample_1068": [false], "sample_1069": [false], "sample_1070": [true], "sample_1071": [false], "sample_1072": [false], "sample_1073": [true], "sample_1074": [false], "sample_1075": [false], "sample_1076": [false], "sample_1077": [true], "sample_1078": [false], "sample_1079": [false], "sample_1080": [false], "sample_1081": [false], "sample_1082": [true], "sample_1083": [true], "sample_1084": [false], "sample_1085": [false], "sample_1086": [false], "sample_1087": [false], "sample_1088": [false], "sample_1089": [false], "sample_1090": [false], "sample_1091": [true], "sample_1092": [false], "sample_1093": [false], "sample_1094": [false], "sample_1095": [false], "sample_1096": [false], "sample_1097": [false], "sample_1098": [false], "sample_1099": [false], "sample_1100": [false], "sample_1101": [true], "sample_1102": [false], "sample_1103": [false], "sample_1104": [true], "sample_1105": [true], "sample_1106": [false], "sample_1107": [false], "sample_1108": [false], "sample_1109": [false], "sample_1110": [false], "sample_1111": [false], "sample_1112": [false], "sample_1113": [false], "sample_1114": [true], "sample_1115": [false], "sample_1116": [false], "sample_1117": [true], "sample_1118": [true], "sample_1119": [false], "sample_1120": [false], "sample_1121": [false], "sample_1122": [false], "sample_1123": [false], "sample_1124": [false], "sample_1125": [false], "sample_1126": [false], "sample_1127": [false], "sample_1128": [false], "sample_1129": [false], "sample_1130": [false], "sample_1131": [false], "sample_1132": [false], "sample_1133": [false], "sample_1134": [false], "sample_1135": [false], "sample_1136": [false], "sample_1137": [false], "sample_1138": [false], "sample_1139": [false], "sample_1140": [false], "sample_1141": [false], "sample_1142": [false], "sample_1143": [false], "sample_1144": [false], "sample_1145": [false], "sample_1146": [false], "sample_1147": [false], "sample_1148": [false], "sample_1149": [true], "sample_1150": [false], "sample_1151": [false], "sample_1152": [false], "sample_1153": [false], "sample_1154": [false], "sample_1155": [false], "sample_1156": [false], "sample_1157": [true], "sample_1158": [false], "sample_1159": [false], "sample_1160": [false], "sample_1161": [true], "sample_1162": [false], "sample_1163": [false], "sample_1164": [false], "sample_1165": [false], "sample_1166": [false], "sample_1167": [false], "sample_1168": [false], "sample_1169": [true], "sample_1170": [true], "sample_1171": [false], "sample_1172": [false], "sample_1173": [true], "sample_1174": [false], "sample_1175": [false], "sample_1176": [false], "sample_1177": [false], "sample_1178": [false], "sample_1179": [false], "sample_1180": [false], "sample_1181": [true], "sample_1182": [false], "sample_1183": [false], "sample_1184": [false], "sample_1185": [false], "sample_1186": [false], "sample_1187": [false], "sample_1188": [false], "sample_1189": [true], "sample_1190": [false], "sample_1191": [false], "sample_1192": [false], "sample_1193": [false], "sample_1194": [false], "sample_1195": [false], "sample_1196": [true], "sample_1197": [false], "sample_1198": [false], "sample_1199": [false], "sample_1200": [false], "sample_1201": [false], "sample_1202": [false], "sample_1203": [false], "sample_1204": [false], "sample_1205": [false], "sample_1206": [false], "sample_1207": [false], "sample_1208": [false], "sample_1209": [false]}}