{"raw_generations": {"sample_33": ["def test_receiver_decorator(self):\n        return True\n\n    @receiver(a_signal)\n        return True\n\n    a_signal.connect(receiver_func)\n    self.assertTrue(a_signal.has_listeners())\n\n    a_signal.disconnect(receiver_func)\n    self.assertFalse(a_signal.has_listeners())\n\n    self.assertTrue(decorated_receiver(None))\n    self.assertTrue(a_signal.has_listeners())\n\n    a_signal.disconnect(decorated_receiver)\n    self.assertFalse(a_signal.has_listeners())\n", "def test_signal_send_robust(self):\n    \"\"\"\n    Test that signal.send_robust() catches and logs exceptions\n    \"\"\"\n        raise ValueError(\"Test exception\")\n\n    a_signal.connect(raising_receiver)\n    responses = a_signal.send_robust(sender=None)\n    self.assertEqual(len(responses), 1)\n    self.assertIsInstance(responses[0][1], ValueError)\n\n        return \"Test response\"\n\n    a_signal.connect(non_raising_receiver)\n    responses = a_signal.send_robust(sender=None)\n    self.assertEqual(len(responses), 2)\n    self.assertIsInstance(responses[0][1], ValueError)\n    self.assertEqual(responses[1][1], \"Test response\")\n", "    def test_receiver_decorator(self):\n        \"\"\"\n        Test that the @receiver decorator correctly connects and disconnects receivers.\n        \"\"\"\n        @receiver(a_signal)\n            return 'receiver_func'\n\n        self.assertIn(receiver_func, a_signal.receivers)\n\n        a_signal.disconnect(receiver_func)\n        self.assertNotIn(receiver_func, a_signal.receivers)\n\n        @receiver([a_signal, b_signal])\n            return 'receiver_func_two'\n\n        self.assertIn(receiver_func_two, a_signal.receivers)\n        self.assertIn(receiver_func_two, b_signal.receivers)\n\n        a_signal.disconnect(receiver_func_two)\n        self.assertNotIn(receiver_func_two, a_signal.receivers)\n        self.assertIn(receiver_func_two, b_signal.receivers)\n\n        b_signal.disconnect(receiver_func_two)\n        self.assertNotIn(receiver_func_two, a_signal.receivers)\n        self.assertNotIn(receiver_func_two, b_signal.receivers)\n\n        @receiver(a_signal, sender='test_sender')\n            return 'receiver_func_three'\n\n        self.assertIn(receiver_func_three, a_signal.receivers)\n\n        a_signal.disconnect(receiver_func_three, sender='test_sender')\n        self.assertNotIn(receiver_func_three, a_signal.receivers)\n", "def test_disconnect_by_dispatch_uid(self):\n        pass\n\n        pass\n\n    a_signal.connect(receiver_1, dispatch_uid='uid1')\n    a_signal.connect(receiver_2, dispatch_uid='uid2')\n\n    self.assertEqual(len(a_signal.receivers), 2)\n    self.assertTrue(a_signal.disconnect(dispatch_uid='uid1'))\n    self.assertEqual(len(a_signal.receivers), 1)\n    self.assertFalse(a_signal.disconnect(dispatch_uid='uid1'))\n    self.assertTrue(a_signal.disconnect(dispatch_uid='uid2'))\n    self.assertEqual(len(a_signal.receivers), 0)\n\n    # test disconnect with weak ref\n    r1_ref = weakref.ref(receiver_1)\n    a_signal.connect(r1_ref, dispatch_uid='uid1')\n    self.assertEqual(len(a_signal.receivers), 1)\n    self.assertTrue(a_signal.disconnect(dispatch_uid='uid1'))\n    self.assertEqual(len(a_signal.receivers), 0)\n\n    # test disconnect with dispatch_uid and sender\n    a_signal.connect(receiver_1, sender='sender1', dispatch_uid='uid1')\n    a_signal.connect(receiver_2, sender='sender2', dispatch_uid='uid2')\n    self.assertEqual(len(a_signal.receivers), 2)\n    self.assertTrue(a_signal.disconnect(sender='sender1', dispatch_uid='uid1'))\n    self.assertEqual(len(a_signal.receivers), 1)\n    self.assertFalse(a_signal.disconnect(sender='sender1', dispatch_uid='uid1'))\n    self.assertTrue(a_signal.disconnect(sender='sender2', dispatch_uid='uid2'))\n    self.assertEqual(len(a_signal.receivers), 0)\n", "def test_connect_and_disconnect(self):\n    # Connect a receiver\n    a_signal.connect(receiver_1_arg, 'sender')\n    self.assertTrue(a_signal.has_listeners(sender='sender'))\n\n    # Disconnect the receiver\n    a_signal.disconnect(receiver_1_arg, 'sender')\n    self.assertFalse(a_signal.has_listeners(sender='sender'))\n\n    # Try to disconnect a receiver that is not connected\n    self.assertFalse(a_signal.disconnect(receiver_1_arg, 'sender'))\n\n    # Connect a receiver with a dispatch_uid\n    a_signal.connect(receiver_1_arg, 'sender', dispatch_uid='uid')\n    self.assertTrue(a_signal.has_listeners(sender='sender'))\n\n    # Try to connect another receiver with the same dispatch_uid\n    self.assertFalse(a_signal.receivers[-1][0] == (a_signal.connect(receiver_1_arg, 'sender', dispatch_uid='uid').receivers[-1][0]))\n\n    # Disconnect a receiver with a dispatch_uid\n    a_signal.disconnect(receiver=None, sender='sender', dispatch_uid='uid')\n    self.assertFalse(a_signal.has_listeners(sender='sender'))\n\n    # Test that the caching doesn't break the disconnect functionality\n    d_signal.connect(receiver_1_arg, 'sender')\n    self.assertTrue(d_signal.has_listeners(sender='sender'))\n    d_signal.disconnect(receiver_1_arg, 'sender')\n    self.assertFalse(d_signal.has_listeners(sender='sender'))\n"], "sample_42": ["    def test_serialize_lazy_object(self):\n        lazy_value = SimpleLazyObject(lambda: 123)\n        serializer = serializer_factory(lazy_value)\n        self.assertIsInstance(serializer, BaseSimpleSerializer)\n        serialized, imports = serializer.serialize()\n        self.assertEqual(serialized, '123')\n        self.assertEqual(imports, set())\n", "    def test_serializer_factory_float(self):\n        serializer = serializer_factory(1.2)\n        self.assertIsInstance(serializer, BaseSimpleSerializer)\n        string, imports = serializer.serialize()\n        self.assertEqual(string, '1.2')\n        self.assertEqual(imports, set())\n", "    def test_serializer_factory(self):\n        self.assertIsInstance(serializer_factory(datetime.datetime.now()), DatetimeDatetimeSerializer)\n        self.assertIsInstance(serializer_factory(datetime.date.today()), DateTimeSerializer)\n        self.assertIsInstance(serializer_factory(datetime.timedelta(days=1)), DateTimeSerializer)\n        self.assertIsInstance(serializer_factory(datetime.time(12, 0, 0)), DateTimeSerializer)\n        self.assertIsInstance(serializer_factory(decimal.Decimal('1.1')), DecimalSerializer)\n        self.assertIsInstance(serializer_factory(DeconstructibleInstances()), DeconstructableSerializer)\n        self.assertIsInstance(serializer_factory(Money('1.1')), DeconstructableSerializer)\n        self.assertIsInstance(serializer_factory(TextEnum.A), EnumSerializer)\n        self.assertIsInstance(serializer_factory(TextTranslatedEnum.A), EnumSerializer)\n        self.assertIsInstance(serializer_factory(BinaryEnum.A), EnumSerializer)\n        self.assertIsInstance(serializer_factory(IntEnum.A), EnumSerializer)\n        self.assertIsInstance(serializer_factory(functools.partial(print, 'Hello')), FunctoolsPartialSerializer)\n        self.assertIsInstance(serializer_factory([1, 2, 3]), SequenceSerializer)\n        self.assertIsInstance(serializer_factory((1, 2, 3)), TupleSerializer)\n        self.assertIsInstance(serializer_factory({1, 2, 3}), SetSerializer)\n        self.assertIsInstance(serializer_factory(frozenset([1, 2, 3])), FrozensetSerializer)\n        self.assertIsInstance(serializer_factory({'a': 1, 'b': 2}), DictionarySerializer)\n        self.assertIsInstance(serializer_factory(models.Field()), ModelFieldSerializer)\n        self.assertIsInstance(serializer_factory(FoodManager()), ModelManagerSerializer)\n        self.assertIsInstance(serializer_factory(FoodQuerySet()), DeconstructableSerializer)\n        self.assertIsInstance(serializer_factory(migrations.RunPython(print)), OperationSerializer)\n        self.assertIsInstance(serializer_factory(uuid.UUID('00000000-0000-0000-0000-000000000000')), UUIDSerializer)\n        self.assertIsInstance(serializer_factory(pathlib.Path('/path/to/file')), PathSerializer)\n        self.assertIsInstance(serializer_factory(os.PathLike('/path/to/file')), PathLikeSerializer)\n        self.assertIsInstance(serializer_factory(re.compile('regex')), RegexSerializer)\n        self.assertIsInstance(serializer_factory(SettingsReference('SETTING')), SettingsReferenceSerializer)\n        self.assertIsInstance(serializer_factory(TestModel1.thing), ModelFieldSerializer)\n        self.assertIsInstance(serializer_factory(lambda: print('Hello')), FunctionTypeSerializer)\n        self.assertIsInstance(serializer_factory(SimpleLazyObject(lambda: print('Hello'))), FunctionTypeSerializer)\n", "    def test_float_serializer(self):\n        self.assertEqual(serializer_factory(float('inf')).serialize()[0], 'float(\"inf\")')\n        self.assertEqual(serializer_factory(float('-inf')).serialize()[0], 'float(\"-inf\")')\n        self.assertEqual(serializer_factory(float('nan')).serialize()[0], 'float(\"nan\")')\n", "    def test_decimal(self):\n        decimal_value = decimal.Decimal('1.1')\n        serializer = serializer_factory(decimal_value)\n        serialized_value, imports = serializer.serialize()\n        self.assertEqual(serialized_value, \"Decimal('1.1')\")\n        self.assertEqual(imports, {\"from decimal import Decimal\"})\n"], "sample_112": ["def test_isotonic_regression_auto_determination():\n    # Test that the increasing parameter is correctly determined in 'auto' mode.\n    X, y = make_regression(n_samples=100, n_features=1, random_state=42)\n    iso_reg = IsotonicRegression(increasing=\"auto\")\n    iso_reg.fit(X, y)\n\n    # Check that the increasing parameter is correctly determined when the\n    # relationship is increasing.\n    assert iso_reg.increasing_ == check_increasing(X[:, 0], y)\n\n    # Check that the increasing parameter is correctly determined when the\n    # relationship is decreasing.\n    y = -y\n    iso_reg.fit(X, y)\n    assert iso_reg.increasing_ == check_increasing(X[:, 0], y)\n", "def test_isotonic_regression_pickle():\n    \"\"\"Test that an IsotonicRegression model is picklable.\"\"\"\n    X, y = make_regression(n_samples=10, n_features=1, random_state=41)\n    iso_reg = IsotonicRegression()\n    iso_reg.fit(X, y)\n\n    # Check that the unpickled model has the same parameters\n    pickled_iso_reg = pickle.loads(pickle.dumps(iso_reg))\n    assert pickled_iso_reg.get_params() == iso_reg.get_params()\n\n    # Check that the unpickled model makes the same predictions\n    X_new = np.array([[0.5]])\n    assert_allclose(iso_reg.predict(X_new), pickled_iso_reg.predict(X_new))\n", "def test_check_increasing(X, y, increasing, expected_increasing):\n    result = check_increasing(X, y)\n    assert result == expected_increasing\n", "def test_isotonic_regression_y_min_y_max():\n    \"\"\"Test isotonic regression with y_min and y_max.\"\"\"\n    rng = np.random.RandomState(0)\n    y = np.linspace(0, 10, 100)\n    y += rng.normal(0, 1, size=100)\n    y_fit = isotonic_regression(y, y_min=0, y_max=10)\n    assert_array_almost_equal(np.min(y_fit), 0)\n    assert_array_almost_equal(np.max(y_fit), 10)\n", "def test_isotonic_regression_no_sample_weight():\n    \"\"\"Check isotonic regression with no sample weights\"\"\"\n    n_samples = 100\n    rng = np.random.RandomState(0)\n    X = np.sort(rng.rand(n_samples))\n    y = 3 * X + rng.rand(n_samples)\n    y_pred = isotonic_regression(y)\n    assert np.all(y_pred[:-1] <= y_pred[1:])\n\n    # Test with X not sorted\n    X = rng.rand(n_samples)\n    y = 3 * X + rng.rand(n_samples)\n    y_pred = isotonic_regression(y, increasing=True)\n    assert np.all(y_pred[:-1] <= y_pred[1:])\n\n    # Test with X not sorted and decreasing\n    y_pred = isotonic_regression(y, increasing=False)\n    assert np.all(y_pred[:-1] >= y_pred[1:])\n"], "sample_84": ["def test_pyobj_property():\n    class TestClass:\n            self.module = \"test_module\"\n            self.cls = \"test_class\"\n            self.instance = \"test_instance\"\n\n    test_class = TestClass()\n    pyobj_context = PyobjContext()\n\n    pyobj_context.module = property(lambda self: test_class.module)\n    pyobj_context.cls = property(lambda self: test_class.cls)\n    pyobj_context.instance = property(lambda self: test_class.instance)\n\n    assert pyobj_context.module == \"test_module\"\n    assert pyobj_context.cls == \"test_class\"\n    assert pyobj_context.instance == \"test_instance\"\n\n    del pyobj_context.module\n    del pyobj_context.cls\n    del pyobj_context.instance\n\n    with pytest.raises(AttributeError):\n        pyobj_context.module\n\n    with pytest.raises(AttributeError):\n        pyobj_context.cls\n\n    with pytest.raises(AttributeError):\n        pyobj_context.instance\n", "def test_pyfunc_call_coroutine(capsys):\n    @pytest.mark.asyncio\n    async def test_func():\n        assert True\n\n    item = Function(name='test_func', parent=None, callobj=test_func)\n    pytest.warns(PytestUnhandledCoroutineWarning, item.ihook.pytest_pyfunc_call, pyfuncitem=item)\n    out, err = capsys.readouterr()\n    assert 'Coroutine functions are not natively supported and have been skipped.' in err\n", "def test_function_repr_failure(tmp_path, capsys):\n    # create a test module\n    p = tmp_path / \"test_func_repr_failure.py\"\n    p.write_text(\n        textwrap.dedent(\n            \"\"\"\\\n                assert 0 == 1\n            \"\"\"\n        )\n    )\n\n    # run pytest with the --tb=short option\n    args = [\"--tb=short\", str(p)]\n    if sys.version_info < (3, 6):\n        args.append(SHOW_PYTEST_WARNINGS_ARG)\n    with pytest.raises(SystemExit) as excinfo:\n        pytest.main(args)\n    assert excinfo.value.code == 1\n\n    # check that the captured output does not contain any full file paths\n    out, err = capsys.readouterr()\n    assert p.as_posix() not in err\n", "def test_Metafunc_parametrize_with_invalid_indirect_parameter(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            return \"bar\"\n\n            assert param == \"bar\"\n\n        pytest.mark.parametrize(\"param\", [\"bar\"], indirect=True)\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n    assert result.ret == 1\n    result.stdout.fnmatch_lines([\"*indirect fixture 'param' doesn't exist*\"])\n\n", "def test_pytest_pycollect_makeitem():\n    class TestClass:\n            pass\n\n            pass\n\n    test_module = Path(\"test_module.py\")\n    with test_module.syspath():\n        test_module.write(pycode=\"\"\"\n            class TestClass:\n                    pass\n\n                    pass\n        \"\"\")\n        node = test_module.pycollect_makemodule()\n        assert len(node.collect()) == 1\n        assert isinstance(node.collect()[0], Class)\n        assert node.collect()[0].obj == TestClass\n"], "sample_85": ["def test_colored_level_formatter(level_name, level_value):\n    formatter = ColoredLevelFormatter(None, \"%(levelname)s\")\n    formatted_level_name = formatter._level_to_fmt_mapping[level_value]\n    assert formatted_level_name == level_name\n\n", "def test_get_actual_log_level_valid():\n    from logging import DEBUG\n    import pytest\n    from _pytest.config import Config\n    config = Config()\n    config.getini = lambda x: None\n    config.getoption = lambda x: None\n    assert get_actual_log_level(config, 'log_level') is None\n\n    config.getoption = lambda x: 'DEBUG'\n    assert get_actual_log_level(config, 'log_level') == DEBUG\n\n    config.getini = lambda x: 'DEBUG'\n    config.getoption = lambda x: None\n    assert get_actual_log_level(config, 'log_level') == DEBUG\n\n    config.getini = lambda x: '10'\n    config.getoption = lambda x: None\n    assert get_actual_log_level(config, 'log_level') == 10\n\n", "def caplog_with_messages(caplog):\n    with caplog.at_level(logging.INFO):\n        logging.info(\"Test message\")\n        yield caplog\n        caplog.clear()\n", "def test_get_option_ini():\n    config = pytest.config\n    # Test that get_option_ini returns the option if it exists in config\n    config.option = pytest.mock.Mock()\n    config.option.log_print = True\n    config.option.log_level = \"INFO\"\n    assert get_option_ini(config, \"log_print\") is True\n    assert get_option_ini(config, \"log_level\") == \"INFO\"\n\n    # Test that get_option_ini returns the ini value if the option is not in config\n    config.option = pytest.mock.Mock()\n    config.option.log_print = None\n    config.inicfg = {\"log_print\": \"true\"}\n    assert get_option_ini(config, \"log_print\") == \"true\"\n\n    # Test that get_option_ini returns None if the option and ini value do not exist\n    config.option = pytest.mock.Mock()\n    config.option.log_print = None\n    config.inicfg = {}\n    assert get_option_ini(config, \"log_print\") is None\n\n    # Test that get_option_ini raises an error if multiple names are provided\n    with pytest.raises(TypeError):\n        get_option_ini(config, \"log_print\", \"log_level\")\n", "def test_get_option_ini(monkeypatch):\n    \"\"\"Test get_option_ini function\"\"\"\n    config = pytest.Mock()\n    config.getoption.return_value = \"option_value\"\n    config.getini.return_value = None\n\n    result = get_option_ini(config, \"test_option\")\n    assert result == \"option_value\"\n\n    config.getoption.return_value = None\n    config.getini.return_value = \"ini_value\"\n    result = get_option_ini(config, \"test_option\")\n    assert result == \"ini_value\"\n\n    config.getoption.return_value = None\n    config.getini.return_value = None\n    result = get_option_ini(config, \"test_option\")\n    assert result is None\n\n"], "sample_4": ["    def test_http_response(self):\n        response = HttpResponse()\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response['Content-Type'], 'text/html; charset=utf-8')\n", "    def test_init(self):\n        response = HttpResponseBase()\n        self.assertEqual(response.status_code, 200)\n", "    def test_reason_phrase_property(self):\n        response = HttpResponseBase(status=200)\n        self.assertEqual(response.reason_phrase, 'OK')\n", "    def test_reason_phrase(self):\n        response = HttpResponseBase(status=200)\n        self.assertEqual(response.reason_phrase, 'OK')\n", "    def test_default_status_code(self):\n        response = HttpResponseBase()\n        self.assertEqual(response.status_code, 200)\n"], "sample_66": ["    def test_raw_id_fields_item_invalid(self):\n        class MyAdmin(ModelAdmin):\n            raw_id_fields = [\"non_existent_field\"]\n\n        self.assertIsInvalid(\n            MyAdmin,\n            ValidationTestModel,\n            \"The value of 'raw_id_fields[0]' refers to 'non_existent_field', which \"\n            \"is not a field of 'validationtestmodel'.\",\n            id=\"admin.E002\",\n        )\n", "    def test_list_editable_is_valid(self):\n        class MyModelAdmin(ModelAdmin):\n            list_editable = (\"name\",)\n\n        self.assertIsValid(MyModelAdmin, ValidationTestModel)\n", "    def test_inline_model_admin_checks(self):\n        class TestModelAdmin(admin.ModelAdmin):\n            pass\n\n        class TestInlineModelAdmin(admin.TabularInline):\n            pass\n\n        class TestInlineModelAdminWithModel(TestInlineModelAdmin):\n            model = ValidationTestModel\n\n        self.assertIsValid(\n            TestModelAdmin, ValidationTestModel, admin_site=AdminSite()\n        )\n        self.assertIsInvalid(\n            TestInlineModelAdmin,\n            ValidationTestModel,\n            msg=\"The value of 'model' must be a Model.\",\n            id=\"admin.E105\",\n        )\n        self.assertIsValid(\n            TestInlineModelAdminWithModel,\n            ValidationTestModel,\n            admin_site=AdminSite(),\n        )\n\n        class TestInlineModelAdminWithModelNotSubclassingModel(\n            TestInlineModelAdminWithModel\n        ):\n            model = ValidationTestInlineModel\n\n        self.assertIsInvalid(\n            TestInlineModelAdminWithModelNotSubclassingModel,\n            ValidationTestModel,\n            msg=\"The value of 'TestInlineModelAdminWithModelNotSubclassingModel.model' must be a Model.\",\n            id=\"admin.E106\",\n            invalid_obj=TestInlineModelAdminWithModelNotSubclassingModel,\n        )\n\n        class TestInlineModelAdminWithFormsetNotSubclassingBaseModelFormSet(\n            TestInlineModelAdminWithModel\n        ):\n            formset = forms.BaseFormSet\n\n        self.assertIsInvalid(\n            TestInlineModelAdminWithFormsetNotSubclassingBaseModelFormSet,\n            ValidationTestModel,\n            msg=\"The value of 'TestInlineModelAdminWithFormsetNotSubclassingBaseModelFormSet.formset' must inherit from 'BaseModelFormSet'.\",\n            id=\"admin.E206\",\n            invalid_obj=TestInlineModelAdminWithFormsetNotSubclassingBaseModelFormSet,\n        )\n\n        class TestInlineModelAdminWithExtraNotInt(TestInlineModelAdminWithModel):\n            extra = \"test\"\n\n        self.assertIsInvalid(\n            TestInlineModelAdminWithExtraNotInt,\n            ValidationTestModel,\n            msg=\"The value of 'extra' must be an integer.\",\n            id=\"admin.E203\",\n        )\n\n        class TestInlineModelAdminWithMaxNumNotInt(TestInlineModelAdminWithModel):\n            max_num = \"test\"\n\n        self.assertIsInvalid(\n            TestInlineModelAdminWithMaxNumNotInt,\n            ValidationTestModel,\n            msg=\"The value of 'max_num' must be", "    def test_raw_id_fields(self):\n        class TestAdmin(admin.ModelAdmin):\n            raw_id_fields = [\"nonexistent_field\"]\n\n        self.assertIsInvalid(\n            TestAdmin,\n            ValidationTestModel,\n            \"The value of 'raw_id_fields' refers to 'nonexistent_field', which \"\n            \"is not a field of 'validationtestmodel'.\",\n            id=\"admin.E002\",\n        )\n", "    def test_fieldsets_is_list_or_tuple(self):\n        class TestAdmin(ModelAdmin):\n            fieldsets = \"not a list or tuple\"\n\n        self.assertIsInvalid(\n            TestAdmin, ValidationTestModel, \"The value of 'fieldsets' must be a list or tuple.\", id=\"admin.E007\"\n        )\n"], "sample_116": ["def test_create_index_with_empty_entries(app):\n    app.builder.env.domains['index'].entries = {}\n    index_entries = IndexEntries(app.builder.env)\n    result = index_entries.create_index(app.builder)\n    assert result == []\n", "def test_create_index():\n    with restructuredtext.sphinxrunner() as app:\n        app.builder.name = 'html'\n        env = app.env\n        index_entries = IndexEntries(env)\n        domain = env.get_domain('index')\n        domain.entries['test'] = [('single', 'entry', 'tid', 'main', None)]\n        result = index_entries.create_index(app.builder)\n        assert len(result) == 1\n        assert len(result[0][1]) == 1\n        assert len(result[0][1][0][0]) == 1\n        assert result[0][1][0][0][0][0] == 'main'\n        assert result[0][1][0][0][0][1].startswith('genindex.html#tid')\n", "def test_create_index(app, status, warning):\n    # Create a test environment\n    env = app.builder.env\n    index_entries = IndexEntries(env)\n\n    # Add some test entries\n    domain = env.get_domain('index')\n    domain.entries['file1'] = [\n        ('single', 'Test', 'test-id', 'Test entry', 'T'),\n        ('pair', 'Test Pair', 'test-pair-id', 'Test pair entry', 'TP'),\n        ('triple', 'Test Triple', 'test-triple-id', 'Test triple entry', 'TT'),\n        ('see', 'Test See', 'test-see-id', 'Test see entry', 'TS'),\n        ('seealso', 'Test Seealso', 'test-seealso-id', 'Test seealso entry', 'TSA')\n    ]\n\n    # Create the index\n    index = index_entries.create_index(app.builder)\n\n    # Check the index structure\n    assert len(index) > 0\n    for key, entries in index:\n        assert isinstance(key, str)\n        assert isinstance(entries, list)\n\n    # Check the sub-index entries\n    for _, entries in index:\n        for entry in entries:\n            assert isinstance(entry, tuple)\n            assert len(entry) == 2\n            assert isinstance(entry[0], str)\n            assert isinstance(entry[1], list)\n            assert len(entry[1]) == 3\n            assert isinstance(entry[1][0], list)\n            assert isinstance(entry[1][1], dict)\n            assert isinstance(entry[1][2], str)\n\n    # Check that the entries are sorted\n    prev_key = ''\n    for key, _ in index:\n        assert key >= prev_key\n        prev_key = key\n\n    # Check that the sub-entries are sorted\n    for _, entries in index:\n        prev_subkey = ''\n        for entry in entries:\n            assert entry[0] >= prev_subkey\n            prev_subkey = entry[0]\n", "def test_create_index(tmp_path):\n    # create a dummy environment and builder\n    env = restructuredtext.build_environment(tmp_path)\n    builder = restructuredtext.DummyBuilder(env)\n\n    # create index entries\n    domain = env.get_domain('index')\n    domain.entries['dummy'] = [\n        ('single', 'single_entry', 'dummy_id', 'Single Entry', None),\n        ('pair', 'first second', 'dummy_id', 'First Second', None),\n        ('triple', 'first second third', 'dummy_id', 'First Second Third', None),\n        ('see', 'see_entry see_also', 'dummy_id', 'See Entry', None),\n        ('seealso', 'seealso_entry see_also', 'dummy_id', 'Seealso Entry', None),\n    ]\n\n    # create index\n    index = IndexEntries(env)\n    result = index.create_index(builder)\n\n    # check if the index is correctly created\n    assert len(result) > 0\n    for key, entries in result:\n        assert isinstance(key, str)\n        assert isinstance(entries, list)\n        for entry in entries:\n            assert isinstance(entry, tuple)\n            assert len(entry) == 2\n            assert isinstance(entry[0], str)\n            assert isinstance(entry[1], list)\n\n    # test with group_entries=False\n    result = index.create_index(builder, group_entries=False)\n    assert len(result) > 0\n    for key, entries in result:\n        assert isinstance(key, str)\n        assert isinstance(entries, list)\n        for entry in entries:\n            assert isinstance(entry, tuple)\n            assert len(entry) == 2\n            assert isinstance(entry[0], str)\n            assert isinstance(entry[1], list)\n\n    # test with invalid index entry type\n    domain.entries['dummy'].append(('invalid', 'invalid_entry', 'dummy_id', 'Invalid Entry', None))\n    with pytest.raises(ValueError):\n        index.create_index(builder)\n\n    # test with missing index entry value\n    domain.entries['dummy'].append(('single', '', 'dummy_id', 'Missing Entry', None))\n    with pytest.raises(ValueError):\n        index.create_index(builder)\n", "def test_create_index(app, status, warning, caplog):\n    \"\"\"Test create_index with a simple index.\"\"\"\n    app.builder.env.domains['index'].entries['test'] = [\n        ('single', 'test', 'tid', 'Test', None),\n        ('pair', 'test1,test2', 'tid', 'Test', None),\n    ]\n\n    index_entries = IndexEntries(app.builder.env)\n    result = index_entries.create_index(app.builder)\n\n    assert len(result) == 1\n    assert len(result[0][1]) == 1\n\n    assert caplog.records == []\n\n"], "sample_52": ["    def test_create_model_with_unique_together(self):\n        # Create a model with unique_together option\n        operation = migrations.CreateModel(\n            \"UniqueTogetherModel\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"field1\", models.CharField(max_length=10)),\n                (\"field2\", models.CharField(max_length=10)),\n            ],\n            options={\"unique_together\": [[\"field1\", \"field2\"]]},\n        )\n        \n        # Test state change\n        project_state = ProjectState()\n        operation.state_forwards(\"app_name\", project_state)\n        model_state = project_state.models[\"app_name\", \"uniquetogethermodel\"]\n        self.assertEqual(model_state.options[\"unique_together\"], [[\"field1\", \"field2\"]])\n\n        # Test database operation\n        with connection.schema_editor(atomic=True) as schema_editor:\n            operation.database_forwards(\"app_name\", schema_editor, project_state, project_state)\n            model = project_state.apps.get_model(\"app_name\", \"UniqueTogetherModel\")\n            self.assertEqual(\n                connection.introspection.get_constraints(model._meta.db_table),\n                {\n                    \"unique_togethermodel_field1_field2_key\": {\n                        \"type\": \"unique\",\n                        \"fields\": [\"field1\", \"field2\"],\n                        \"deferrable\": False,\n                        \"deferrable_temp\": False,\n                    }\n                },\n            )\n\n        # Test database reverse operation\n        with connection.schema_editor(atomic=True) as schema_editor:\n            operation.database_backwards(\"app_name\", schema_editor, project_state, project_state)\n            self.assertEqual(\n                connection.introspection.get_constraints(model._meta.db_table),\n                {},\n            )\n", "    def test_rename_index(self):\n        \"\"\"Test renaming an index.\"\"\"\n        operation = RenameIndex(\"test\", \"new_index\", \"old_index\")\n        project_state = ProjectState()\n        app_label = \"test_app\"\n        model_name = \"test\"\n        model_state = ModelState(\n            app_label, \"test\", fields=[], options={}, bases=[], managers=[]\n        )\n        project_state.add_model(model_state)\n\n        # State alteration\n        with self.assertRaises(IntegrityError):\n            operation.state_forwards(app_label, project_state)\n        with self.assertRaises(IntegrityError):\n            operation.state_backwards(app_label, project_state)\n\n        # Database alteration\n        with atomic(), CaptureQueriesContext(connection) as queries:\n            operation.database_forwards(app_label, self.schema_editor, project_state, project_state)\n        self.assertEqual(len(queries), 1)\n        self.assertEqual(queries[0][\"sql\"].startswith(\"ALTER INDEX\"), True)\n\n        with atomic(), CaptureQueriesContext(connection) as queries:\n            operation.database_backwards(app_label, self.schema_editor, project_state, project_state)\n        self.assertEqual(len(queries), 1)\n        self.assertEqual(queries[0][\"sql\"].startswith(\"ALTER INDEX\"), True)\n", "    def test_rename_index(self):\n        # Create an index on a model.\n        operation = migrations.AddIndex(\n            model_name=\"Food\",\n            index=models.Index(fields=[\"name\"]),\n        )\n        self.apply_operations(operation)\n\n        # Rename the index on the model.\n        rename_operation = migrations.RenameIndex(\n            model_name=\"Food\",\n            new_name=\"new_index_name\",\n            old_name=\"Food_name_bf4b2706_idx\",\n        )\n        self.apply_operations(rename_operation)\n\n        # Assert that the index name has been changed.\n        with self.assertNumQueries(1):\n            with connection.cursor() as cursor:\n                cursor.execute(\"SHOW INDEX FROM food\")\n                result = cursor.fetchall()\n                self.assertEqual(result[0][2], \"new_index_name\")\n\n        # Reverse the rename operation.\n        self.reverse_operations(rename_operation)\n\n        # Assert that the index name has been reverted.\n        with self.assertNumQueries(1):\n            with connection.cursor() as cursor:\n                cursor.execute(\"SHOW INDEX FROM food\")\n                result = cursor.fetchall()\n                self.assertEqual(result[0][2], \"Food_name_bf4b2706_idx\")\n", "    def test_add_constraint(self):\n        \"\"\"\n        Test adding a CheckConstraint to a model.\n        \"\"\"\n        operation = AddConstraint(\n            \"unicode\", models.CheckConstraint(check=models.Q(unicode_field__startswith=\"A\"))\n        )\n        self.apply_operations(\n            [\n                migrations.CreateModel(\n                    name=\"Unicode\",\n                    fields=[\n                        (\"id\", models.AutoField(primary_key=True, serialize=False)),\n                        (\n                            \"unicode_field\",\n                            models.CharField(max_length=255),\n                        ),\n                    ],\n                ),\n                operation,\n            ]\n        )\n\n        # Test that the constraint was added to the model state\n        model_state = self.project_state.apps.get_model(\"test_app\", \"Unicode\")\n        self.assertEqual(len(model_state.options[\"constraints\"]), 1)\n\n        # Test that the constraint was added to the database\n        with CaptureQueriesContext(connection) as queries:\n            UnicodeModel.objects.create(unicode_field=\"A test string\")\n        self.assertEqual(len(queries.captured_queries), 1)\n\n        # Test that the constraint prevents invalid data from being inserted\n        with self.assertRaises(IntegrityError):\n            UnicodeModel.objects.create(unicode_field=\"Invalid string\")\n\n        # Reverse the migration and check that the constraint is removed\n        self.reverse_operations(\n            [\n                migrations.RemoveConstraint(\n                    model_name=\"unicode\", name=operation.constraint.name\n                )\n            ]\n        )\n        with CaptureQueriesContext(connection) as queries:\n            UnicodeModel.objects.create(unicode_field=\"Invalid string\")\n        self.assertEqual(len(queries.captured_queries), 1)\n", "    def test_rename_index(self):\n        self.apply_operations(\n            [\n                migrations.CreateModel(\n                    \"TestModel\",\n                    fields=[\n                        (\"id\", models.AutoField(primary_key=True)),\n                        (\"name\", models.CharField(max_length=255)),\n                    ],\n                ),\n                migrations.AddIndex(\n                    model_name=\"TestModel\",\n                    index=models.Index(fields=[\"name\"], name=\"index_name\"),\n                ),\n                migrations.RenameIndex(\n                    model_name=\"TestModel\",\n                    old_name=\"index_name\",\n                    new_name=\"new_index_name\",\n                ),\n            ],\n            atomic=True,\n        )\n        # Make sure we actually renamed the index\n        with connection.cursor() as cursor:\n            cursor.execute(\n                \"\"\"\n                SELECT 1\n                FROM pg_indexes\n                WHERE tablename = 'testmodel'\n                AND indexname = 'new_index_name';\n                \"\"\"\n            )\n            self.assertEqual(cursor.fetchone()[0], 1)\n"], "sample_69": ["def test_artist_inspector_rest_style():\n    fig, ax = plt.subplots()\n    line, = ax.plot([1, 2, 3])\n\n    stream = io.StringIO()\n    martist.setp(line, file=stream)\n    assert '``' in stream.getvalue()\n\n    mpl.rcParams['docstring.hardcopy'] = False\n    stream = io.StringIO()\n    martist.setp(line, file=stream)\n    assert '``' not in stream.getvalue()\n", "def test_artist_getp_and_setp():\n    # getp test\n    fig, ax = plt.subplots()\n    line, = ax.plot([1, 2, 3])\n    assert martist.getp(line, 'linewidth') == 1.5\n    assert martist.getp(line, 'color') == (0.0, 0.0, 0.0, 1.0)\n\n    # setp test\n    martist.setp(line, 'linewidth', 2)\n    martist.setp(line, 'color', 'r')\n    assert line.get_linewidth() == 2\n    assert line.get_color() == (1.0, 0.0, 0.0, 1.0)\n\n    # setp with multiple artists\n    fig, ax = plt.subplots()\n    line1, line2 = ax.plot([1, 2, 3], [4, 5, 6])\n    martist.setp(line1, line2, 'linewidth', 2)\n    martist.setp(line1, line2, 'color', 'r')\n    assert line1.get_linewidth() == 2\n    assert line2.get_linewidth() == 2\n    assert line1.get_color() == (1.0, 0.0, 0.0, 1.0)\n    assert line2.get_color() == (1.0, 0.0, 0.0, 1.0)\n\n    # setp with MATLAB style string/value pairs\n    fig, ax = plt.subplots()\n    line, = ax.plot([1, 2, 3])\n    martist.setp(line, 'linewidth', 2, 'color', 'r')\n    assert line.get_linewidth() == 2\n    assert line.get_color() == (1.0, 0.0, 0.0, 1.0)\n", "def test_artist_getp_setp():\n    fig, ax = plt.subplots()\n    line, = ax.plot([1, 2, 3])\n\n    # Test getp\n    assert martist.getp(line, 'color') == [0.0, 0.0, 0.0, 1.0]\n    assert martist.getp(line, 'linestyle') == '-'\n    martist.getp(line)\n\n    # Test setp\n    martist.setp(line, color='red', linestyle='--')\n    assert line.get_color() == [1.0, 0.0, 0.0, 1.0]\n    assert line.get_linestyle() == '--'\n\n    # Test setp with multiple artists\n    line2, = ax.plot([1, 2, 3])\n    martist.setp([line, line2], color='blue', linestyle='-.')\n\n    # Test setp with file argument\n    with io.StringIO() as f:\n        martist.setp(line, file=f)\n        assert 'linewidth or lw: float' in f.getvalue()\n\n    # Test setp with invalid property\n    with pytest.raises(ValueError):\n        martist.setp(line, invalid_property='value')\n", "def test_artist_setter_properties():\n    fig, ax = plt.subplots()\n    line, = ax.plot([1, 2, 3])\n    line.set_agg_filter(None)\n    line.set_animated(True)\n    line.set_alpha(0.5)\n    line.set_clip_box(ax.bbox)\n    line.set_clip_on(True)\n    line.set_clip_path(mpatches.Circle((0.5, 0.5), 0.5, transform=ax.transAxes))\n    line.set_figure(fig)\n    line.set_in_layout(True)\n    line.set_label('Test Label')\n    line.set_picker(True)\n    line.set_rasterized(True)\n    line.set_sketch_params(1, 2, 3)\n    line.set_transform(mtransforms.Affine2D())\n    line.set_url('https://matplotlib.org')\n    line.set_visible(False)\n    line.set_zorder(1)\n\n    # Test setter properties using the set method\n    line.set(linewidth=2, color='r', linestyle='--')\n    line.set(lw=2, c='r', ls='--')\n\n    # Test property aliases\n    assert line.get_linewidth() == 2\n    assert line.get_color() == (1.0, 0, 0, 1.0)\n    assert line.get_linestyle() == '--'\n\n    # Test invalid setter properties\n    with pytest.raises(AttributeError):\n        line.set_invalid_property('value')\n\n    # Test invalid setter values\n    with pytest.raises(ValueError):\n        line.set_alpha(-1)\n\n    # Test setter properties using the update method\n    line.update(linewidth=3, color='g', linestyle=':')\n    assert line.get_linewidth() == 3\n    assert line.get_color() == (0, 0.5, 0, 1.0)\n    assert line.get_linestyle() == ':'\n\n    # Test update with invalid properties\n    with pytest.raises(AttributeError):\n        line.update(invalid_property='value')\n", "def test_alpha():\n    fig, ax = plt.subplots()\n    ax.add_patch(mpatches.Circle((0.5, 0.5), 0.2, alpha=0.5))\n    ax.add_patch(mpatches.Circle((0.7, 0.7), 0.1, alpha=0.8))\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n\n"], "sample_127": ["def test_print_latex():\n    # Test latex printer\n    assert latex(3*x**2/y) == r'\\frac{3 x^{2}}{y}'\n    assert latex(3*x**2/y, fold_short_frac=True) == r'3 x^{2} / y'\n    assert latex(3*x**2/y, fold_short_frac=False) == r'\\frac{3 x^{2}}{y}'\n\n    assert latex(Integral(r, r)/2/pi, long_frac_ratio=0) == \\\n        r'\\frac{1}{2 \\pi} \\int r\\, dr'\n    assert latex(Integral(r, r)/2/pi, long_frac_ratio=2) == \\\n        r'\\frac{\\int r\\, dr}{2 \\pi}'\n\n    assert latex((2*tau)**Rational(7,2), fold_frac_powers=True) == \\\n        r'8 \\sqrt{2} \\tau^{7/2}'\n    assert latex((2*tau)**Rational(7,2), fold_frac_powers=False) == \\\n        r'8 \\sqrt{2} \\tau^{\\frac{7}{2}}'\n\n    assert latex(2*mu, mode='inline') == r'$2 \\mu$'\n    assert latex(2*mu, mode='equation') == r'\\begin{equation}2 \\mu\\end{equation}'\n    assert latex(2*mu, mode='equation*', itex=True) == r'$$2 \\mu$$'\n\n    assert latex((2*tau)**sin(Rational(7,2)), fold_func_brackets=True) == \\\n        r'\\left(2 \\tau\\right)^{\\sin {\\frac{7}{2}}}'\n    assert latex((2*tau)**sin(Rational(7,2)), fold_func_brackets=False) == \\\n        r'\\left(2 \\tau\\right)^{\\sin{\\left (\\frac{7}{2} \\right )}}'\n\n    assert latex((2*tau)**sin(Rational(7,2)), mul_symbol=\"ldot\") == \\\n        r'\\left(2 \\,. \\, \\tau\\right)^{\\sin{\\left (\\frac{7}{2} \\right )}}'\n    assert latex((2*tau)**sin(Rational(7,2)), mul_symbol=\"dot\") == \\\n        r'\\left(2 \\cdot \\tau\\right)^", "def test_Subs():\n    from sympy import Function, sin, cos, symbols, Matrix, Symbol\n    from sympy.abc import x\n    f = Function('f')\n    assert latex(Subs(f(x), (x, sin(x)))) == \\\n        r\"\\left. f\\left(x\\right) \\right|_{x=\\sin{\\left (x \\right )}\"\n    assert latex(Subs(sin(x), (x, f(x)))) == \\\n        r\"\\left. \\sin{\\left (x \\right )} \\right|_{x=f\\left(x\\right)}\"\n    A = Matrix([[sin(x), cos(x)], [cos(x), sin(x)]])\n    assert latex(Subs(A, (x, f(x)))) == \\\n        r\"\\left. \\left[\\begin{matrix}\\sin{\\left (x \\right )} & \\cos{\\left (x \\right )}\\\\\\cos{\\left (x \\right )} & \\sin{\\left (x \\right )}\\end{matrix}\\right] \\right|_{x=f\\left(x\\right)}\"\n", "def test_translate():\n    assert translate('betadotprime') == r\"\\dot{\\beta}'\"\n    assert translate('betadot') == r\"\\dot{\\beta}\"\n    assert translate('betaprime') == r\"{\\beta}'\"\n    assert translate('beta') == r\"\\beta\"\n    assert translate('BETA') == r\"B\"\n    assert translate('gammaprime') == r\"{\\gamma}'\"\n    assert translate('gammaprimeprm') == r\"{\\gamma}''\"\n    assert translate('gammaprimeprmprm') == r\"{\\gamma}'''\"\n\n    assert translate('alpha') == r\"\\alpha\"\n    assert translate('ALPHA') == r\"A\"\n    assert translate('alpha1') == r\"\\alpha_1\"\n\n    assert translate('ohm') == r\"\\ohm\"\n    assert translate('OHM') == r\"\\Omega\"\n    assert translate('Omega') == r\"\\Omega\"\n    assert translate('omicron') == r\"o\"\n    assert translate('Omicron') == r\"O\"\n\n    assert translate('alphahathat') == r\"\\hat{\\hat{\\alpha}}\"\n    assert translate('alphahathatdot') == r\"\\dot{\\hat{\\hat{\\alpha}}}\"\n    assert translate('alphahathatdotprime') == r\"{\\dot{\\hat{\\hat{\\alpha}}}'\"\n    assert translate('alphahathatprime') == r\"{\\hat{\\hat{\\alpha}}'\"\n    assert translate('alphahat') == r\"\\hat{\\alpha}\"\n    assert translate('alphahatdot') == r\"\\dot{\\hat{\\alpha}}\"\n    assert translate('alphahatdotprime') == r\"{\\dot{\\hat{\\alpha}}'\"\n    assert translate('alphahatprime') == r\"{\\hat{\\alpha}}'\"\n    assert translate('alphadot') == r\"\\dot{\\alpha}\"\n    assert translate('alphadotdot') == r\"\\ddot{\\alpha}\"\n    assert translate('alphadotdotdot') == r\"\\dddot{\\alpha}\"\n    assert translate('alphadotdotdotdot') == r\"\\ddddot{\\alpha}\"\n    assert translate('alphadotprime') == r\"{\\dot{\\alpha}}'\"\n    assert translate('alphadotprimeprm') == r\"{\\dot{\\alpha}}''\"\n    assert translate('alphadotprimeprmprm') == r\"{\\dot{\\alpha}}'''\"\n    assert translate('", "def test_latex_lambdify():\n    f = Function('f')\n    s = latex(f(x, y))\n    assert s == r'f{\\left ( x, \\  y \\right )}'\n", "def test_latex():\n    # test that latex can handle default symbolic atoms\n    assert latex(S.NegativeOne) == '-1'\n    assert latex(S.Half) == r'\\frac{1}{2}'\n    assert latex(S.ImaginaryUnit) == r'i'\n    assert latex(S.Infinity) == r'\\infty'\n    assert latex(S.NegativeInfinity) == r'-\\infty'\n    assert latex(S.Pi) == r'\\pi'\n    assert latex(S.EulerGamma) == r'\\gamma'\n    assert latex(S.Exp1) == r'e'\n    assert latex(S.GoldenRatio) == r'\\phi'\n    assert latex(S.TribonacciConstant) == r'\\psi'\n    assert latex(S.Catalan) == r'C'\n    assert latex(S.Plaumel) == r'\\mu'\n\n    # test that latex can handle symbolic roots\n    assert latex(root(x**2 + y**2, 3)) == r'\\sqrt[3]{x^{2} + y^{2}}'\n\n    # test that latex can handle symbolic integrals\n    assert latex(Integral(x*y, x)) == r'\\int x y\\, dx'\n\n    # test that latex can handle symbolic summations\n    assert latex(Sum(x*y, (x, 1, 2))) == r'\\sum_{x=1}^{2} x y'\n\n    # test that latex can handle symbolic products\n    assert latex(Product(x*y, (x, 1, 2))) == r'\\prod_{x=1}^{2} x y'\n\n    # test that latex can handle symbolic unions\n    assert latex(Union(x, y)) == r' x \\cup y'\n\n    # test that latex can handle symbolic intersections\n    assert latex(x & y) == r' x \\cap y'\n\n    # test that latex can handle symbolic differences\n    assert latex(x - y) == r' x \\setminus y'\n\n    # test that latex can handle symbolic symmetric differences\n    assert latex(x ^ y) == r' x \\triangle y'\n\n    # test that latex can handle empty set\n    assert latex(S.EmptySet) == r'\\emptyset'\n\n    # test that latex can handle a quantity\n    assert latex(degree) == r'^{\\circ}'\n\n    # test that latex can handle Tuple\n    assert latex((x, y)) == r'\\left ( x, \\  y\\"], "sample_65": ["    def test_floatformat_default(self):\n        output = self.engine.render_to_string(\"floatformat01\")\n        self.assertEqual(output, \"34.2\")\n", "    def test_unordered_list(self):\n        output = self.engine.render_to_string(\"unordered_list01\", {\"a\": ['States', ['Kansas', ['Lawrence', 'Topeka'], 'Illinois']]})\n        self.assertEqual(output, '<li>States\\n<ul>\\n\\t\\t\\t\\t<li>Kansas\\n\\t\\t\\t\\t\\t<ul>\\n\\t\\t\\t\\t\\t\\t<li>Lawrence</li>\\n\\t\\t\\t\\t\\t\\t<li>Topeka</li>\\n\\t\\t\\t\\t\\t</ul>\\n\\t\\t\\t\\t</li>\\n\\t\\t\\t\\t<li>Illinois</li>\\n\\t\\t\\t</ul>\\n\\t\\t\\t</li>')\n", "    def test_truncatechars(self):\n        output = self.engine.render_to_string(\"truncatechars01\", {\"a\": \"123456\"})\n        self.assertEqual(output, \"12345\")\n", "    def test_safeseq(self):\n        output = self.engine.render_to_string(\"safe_seq01\", {\"a\": [\"<b>1</b>\", \"<i>2</i>\", \"<u>3</u>\"]})\n        self.assertEqual(output, \"<b>1</b><i>2</i><u>3</u>\")\n", "    def test_linebreaks_filter(self):\n        # Test linebreaks filter with a string containing newlines.\n        template = self.engine.from_string('{{ value|linebreaks }}')\n        value = \"Hello\\nWorld\\n\\nThis is a test.\"\n        self.assertEqual(template.render({'value': value}).strip(),\n                         \"<br>Hello<br>World<br><br>This is a test.\")\n\n        # Test linebreaks filter with an HTML string containing newlines.\n        template = self.engine.from_string('{{ value|linebreaks }}')\n        value = \"Hello\\n<b>World</b>\\n\\nThis is a <a href='#'>test</a>.\"\n        self.assertEqual(template.render({'value': mark_safe(value)}).strip(),\n                         \"Hello<br><b>World</b><br><br>This is a <a href='#'>test</a>.\")\n\n        # Test linebreaks filter with autoescape disabled.\n        template = self.engine.from_string('{{ value|linebreaks }}')\n        value = \"Hello\\n<b>World</b>\\n\\nThis is a <a href='#'>test</a>.\"\n        self.assertEqual(template.render({'value': value}).strip(),\n                         \"Hello<br><b>World</b><br><br>This is a <a href='#'>test</a>.\")\n\n        # Test linebreaks filter with autoescape enabled.\n        template = self.engine.from_string('{{ value|linebreaks }}')\n        value = \"Hello\\n<b>World</b>\\n\\nThis is a <a href='#'>test</a>.\"\n        self.assertEqual(template.render({'value': value}, autoescape=True).strip(),\n                         \"Hello<br>&lt;b&gt;World&lt;/b&gt;<br><br>This is a &lt;a href=&#x27;#&#x27;&gt;test&lt;/a&gt;.\")\n\n        # Test linebreaks filter with an empty string.\n        template = self.engine.from_string('{{ value|linebreaks }}')\n        value = \"\"\n        self.assertEqual(template.render({'value': value}).strip(), \"\")\n\n        # Test linebreaks filter with None.\n        template = self.engine.from_string('{{ value|linebreaks }}')\n        value = None\n        self.assertEqual(template.render({'value': value}).strip(), \"\")\n"], "sample_28": ["    def test_login_view(self):\n        request = RequestFactory().get(reverse('test_adminsite:login'))\n        request.user = User()\n        response = site.login(request)\n        self.assertEqual(response.status_code, 302)\n        self.assertRedirects(response, reverse('test_adminsite:index'))\n", "    def setUpTestData(cls):\n        cls.u1 = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.u2 = User.objects.create_user(username='normal', password='secret', email='normal@example.com', is_staff=True)\n        cls.u3 = User.objects.create_user(username='inactive', password='secret', email='inactive@example.com', is_active=False, is_staff=True)\n", "    def test_init(self):\n        site = admin.AdminSite(name='test_adminsite')\n        self.assertEqual(site.name, 'test_adminsite')\n        self.assertEqual(site._registry, {})\n        self.assertIn('delete_selected', site._actions)\n", "    def test_init(self):\n        site = admin.AdminSite(name='custom')\n        self.assertEqual(site.name, 'custom')\n        self.assertEqual(site._registry, {})\n        self.assertIn('delete_selected', site._actions)\n        self.assertIn('delete_selected', site._global_actions)\n", "    def setUpTestData(cls):\n        cls.u1 = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n"], "sample_89": ["def test_ischildnode_edge_cases():\n    assert nodes.ischildnode(\"\", \"\")\n    assert nodes.ischildnode(\"foo\", \"foo\")\n    assert nodes.ischildnode(\"foo\", \"foo::Bar\")\n    with pytest.raises(TypeError):\n        nodes.ischildnode(None, \"foo\")\n    with pytest.raises(TypeError):\n        nodes.ischildnode(\"foo\", None)\n", "def test_ischildnode_invalid_inputs():\n    with pytest.raises(TypeError):\n        nodes.ischildnode(None, \"nodeid\")\n    with pytest.raises(TypeError):\n        nodes.ischildnode(\"baseid\", None)\n    with pytest.raises(TypeError):\n        nodes.ischildnode(\"baseid\", 123)\n    with pytest.raises(TypeError):\n        nodes.ischildnode(123, \"nodeid\")\n", "def test_ischildnode(baseid, nodeid, expected):\n    assert nodes.ischildnode(baseid, nodeid) == expected\n", "def test_ischildnode_branching_tree():\n    # Test ischildnode on a tree with multiple branches\n    assert nodes.ischildnode(\"foo\", \"foo/bar\") is True\n    assert nodes.ischildnode(\"foo\", \"foo/bar/baz\") is True\n    assert nodes.ischildnode(\"foo/bar\", \"foo/bar/baz\") is True\n    assert nodes.ischildnode(\"foo/bar\", \"foo/baz\") is False\n    assert nodes.ischildnode(\"foo/bar\", \"foo/bar/baz/qux\") is True\n    assert nodes.ischildnode(\"foo/bar/baz\", \"foo/bar/baz/qux\") is True\n", "def test_ischildnode_with_empty_baseid(tmp_path):\n    \"\"\"Test that ischildnode returns False when baseid is empty and nodeid is not empty.\"\"\"\n    baseid = \"\"\n    nodeid = \"foo\"\n    assert not nodes.ischildnode(baseid, nodeid)\n"], "sample_80": ["def test_inline_variable_array_repr():\n    # test dask array\n    da = xr.DataArray(np.random.rand(3, 4), dims=(\"x\", \"y\")).chunk()\n    assert formatting.inline_variable_array_repr(da, 80) == formatting.inline_dask_repr(da.data)\n\n    # test sparse array\n    sa = xr.DataArray((np.random.rand(3, 4) > 0.5).astype(bool), dims=(\"x\", \"y\"))\n    sa.data = sa.data.tocsr()\n    assert formatting.inline_variable_array_repr(sa, 80) == formatting.inline_sparse_repr(sa.data)\n\n    # test numpy array\n    na = xr.DataArray(np.random.rand(3, 4), dims=(\"x\", \"y\"))\n    assert formatting.inline_variable_array_repr(na, 80) == formatting.format_array_flat(na, 80)\n", "    def test_format_array_flat_dask_array(self):\n        import dask.array as da\n\n        array = da.random.random((3, 4), chunks=(2, 2))\n        result = formatting.format_array_flat(array, max_width=20)\n        assert len(result) <= 20\n", "def test_format_items():\n    # Test with a timedelta64 array\n    timedelta64_array = np.array([np.timedelta64(1, 'h'), np.timedelta64(2, 'h')])\n    expected_timedelta64 = [\"1 hours\", \"2 hours\"]\n    assert formatting.format_items(timedelta64_array) == expected_timedelta64\n\n    # Test with a datetime64 array\n    datetime64_array = np.array(['2000-01-01', '2000-01-02'], dtype='datetime64')\n    expected_datetime64 = [\"2000-01-01\", \"2000-01-02\"]\n    assert formatting.format_items(datetime64_array) == expected_datetime64\n\n    # Test with a float array\n    float_array = np.array([1.23456789, 2.3456789])\n    expected_float = [\"1.2346\", \"2.346\"]\n    assert formatting.format_items(float_array) == expected_float\n\n    # Test with a string array\n    string_array = np.array(['hello', 'world'])\n    expected_string = [\"'hello'\", \"'world'\"]\n    assert formatting.format_items(string_array) == expected_string\n\n    # Test with a bytes array\n    bytes_array = np.array([b'hello', b'world'])\n    expected_bytes = [\"b'hello'\", \"b'world'\"]\n    assert formatting.format_items(bytes_array) == expected_bytes\n", "    def test_array_repr(self):\n        # Test DataArray\n        array = xr.DataArray(np.array([1, 2, 3]), dims=\"x\")\n        expected = dedent(\n            \"\"\"\\\n        <xarray.DataArray (x: 3)>\n        [1 2 3]\n        Dimensions without coordinates: x\n        \"\"\"\n        )\n        assert formatting.array_repr(array) == expected\n\n        # Test Variable\n        variable = array.variable\n        expected = dedent(\n            \"\"\"\\\n        <xarray.Variable (x: 3)>\n        [1 2 3]\n        \"\"\"\n        )\n        assert formatting.array_repr(variable) == expected\n\n        # Test IndexVariable\n        index = array.coords[\"x\"]\n        expected = dedent(\n            \"\"\"\\\n        <xarray.IndexVariable (x: 3)>\n        [0 1 2]\n        \"\"\"\n        )\n        assert formatting.array_repr(index) == expected\n\n        # Test DataArray with no data\n        array = xr.DataArray(np.array([]), dims=\"x\")\n        expected = dedent(\n            \"\"\"\\\n        <xarray.DataArray (x: 0)>\n        []\n        Dimensions without coordinates: x\n        \"\"\"\n        )\n        assert formatting.array_repr(array) == expected\n", "def test_format_array_flat():\n    array = np.arange(20).reshape(4, 5)\n    result = formatting.format_array_flat(array, 80)\n    assert len(result) <= 80\n\n    array = np.arange(20).reshape(4, 5).astype(np.float64)\n    result = formatting.format_array_flat(array, 80)\n    assert len(result) <= 80\n\n    array = np.arange(20).reshape(4, 5).astype(np.int64)\n    result = formatting.format_array_flat(array, 80)\n    assert len(result) <= 80\n\n    array = np.array([1.23456789, 2.3456789])\n    result = formatting.format_array_flat(array, 80)\n    assert len(result) <= 80\n\n    array = np.array([np.nan, 2.3456789])\n    result = formatting.format_array_flat(array, 80)\n    assert len(result) <= 80\n\n    array = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n    result = formatting.format_array_flat(array, 80)\n    assert len(result) <= 80\n\n    array = np.array([])\n    result = formatting.format_array_flat(array, 80)\n    assert len(result) <= 80\n"], "sample_124": ["def test_hyperbolic_functions():\n    x = symbols('x')\n    z = Symbol('z')\n\n    # Test sinh\n    assert sinh(x).diff(x) == cosh(x)\n    assert sinh(x).conjugate() == sinh(x.conjugate())\n    assert sinh(x).as_real_imag() == (sinh(x.expand()), 0)\n    assert sinh(x).is_real == x.is_real\n    assert sinh(x)._eval_rewrite_as_exp(x) == (exp(x) - exp(-x)) / 2\n\n    # Test cosh\n    assert cosh(x).diff(x) == sinh(x)\n    assert cosh(x).conjugate() == cosh(x.conjugate())\n    assert cosh(x).as_real_imag() == (cosh(x.expand()), 0)\n    assert cosh(x).is_real == x.is_real\n    assert cosh(x)._eval_rewrite_as_exp(x) == (exp(x) + exp(-x)) / 2\n\n    # Test tanh\n    assert tanh(x).diff(x) == 1 - tanh(x)**2\n    assert tanh(x).conjugate() == tanh(x.conjugate())\n    assert tanh(x).as_real_imag() == (tanh(x.expand()), 0)\n    assert tanh(x).is_real == x.is_real\n    assert tanh(x)._eval_rewrite_as_exp(x) == (exp(x) - exp(-x)) / (exp(x) + exp(-x))\n\n    # Test coth\n    assert coth(x).diff(x) == -1/sinh(x)**2\n    assert coth(x).conjugate() == coth(x.conjugate())\n    assert coth(x).as_real_imag() == (coth(x.expand()), 0)\n    assert coth(x).is_real == x.is_real\n    assert coth(x)._eval_rewrite_as_exp(x) == (exp(x) + exp(-x)) / (exp(x) - exp(-x))\n\n    # Test csch\n    assert csch(x).diff(x) == -coth(x) * csch(x)\n    assert csch(x).conjugate() == csch(x.conjugate())\n    assert csch(x).as_real_imag() == (csch(x.expand()), 0)\n    assert csch(x).is_real == x.is_real\n    assert csch(x)._eval_rewrite_as_exp", "def test_hyperbolic_functions():\n    x = Symbol('x')\n    z = Symbol('z')\n\n    assert sinh(x).diff(x) == cosh(x)\n    assert cosh(x).diff(x) == sinh(x)\n    assert tanh(x).diff(x) == 1 - tanh(x)**2\n    assert coth(x).diff(x) == -1/sinh(x)**2\n\n    assert sinh(x).conjugate() == sinh(x.conjugate())\n    assert cosh(x).conjugate() == cosh(x.conjugate())\n    assert tanh(x).conjugate() == tanh(x.conjugate())\n    assert coth(x).conjugate() == coth(x.conjugate())\n\n    assert sinh(nan) == nan\n    assert cosh(nan) == nan\n    assert tanh(nan) == nan\n    assert coth(nan) == nan\n\n    assert sinh(oo) == oo\n    assert cosh(oo) == oo\n    assert tanh(oo) == 1\n    assert coth(oo) == 1\n\n    assert sinh(-oo) == -oo\n    assert cosh(-oo) == oo\n    assert tanh(-oo) == -1\n    assert coth(-oo) == -1\n\n    assert sinh(0) == 0\n    assert cosh(0) == 1\n    assert tanh(0) == 0\n    assert coth(0) == zoo\n\n    assert sinh(x).series(x, 0, 4) == x + x**3/6 + O(x**4)\n    assert cosh(x).series(x, 0, 4) == 1 + x**2/2 + O(x**4)\n    assert tanh(x).series(x, 0, 4) == x - x**3/3 + O(x**4)\n    assert coth(x).series(x, 0, 4) == 1/x + x/3 - x**3/45 + O(x**4)\n\n    assert sinh(pi*I/2) == I\n    assert cosh(pi*I/2) == 0\n    assert tanh(pi*I/2) == -I\n    assert coth(pi*I/2) == I\n\n    assert sinh(pi*I/3) == sqrt(3)*I/2\n    assert cos", "def test_hyperbolic_functions():\n    x = Symbol('x')\n    assert sinh(nan) == nan\n    assert sinh(oo) == oo\n    assert sinh(-oo) == -oo\n    assert sinh(0) == 0\n    assert sinh(pi*I) == 0\n    assert sinh(pi*I/2) == I\n    assert sinh(pi*I/3) == sqrt(3)/2*I\n    assert sinh(pi*I/4) == I/sqrt(2)\n    assert sinh(pi*I/6) == I/2\n    assert sinh(-pi*I) == 0\n    assert sinh(-pi*I/2) == -I\n    assert sinh(-pi*I/3) == -sqrt(3)/2*I\n    assert sinh(-pi*I/4) == -I/sqrt(2)\n    assert sinh(-pi*I/6) == -I/2\n    assert sinh(zoo) == nan\n    assert sinh(log(2) + log(sqrt(2) + 1)) == 1\n    assert sinh(log(2) + log(sqrt(2) - 1)) == -1\n\n    assert cosh(nan) == nan\n    assert cosh(oo) == oo\n    assert cosh(-oo) == oo\n    assert cosh(0) == 1\n    assert cosh(pi*I) == -1\n    assert cosh(pi*I/2) == 0\n    assert cosh(pi*I/3) == 1/2\n    assert cosh(pi*I/4) == sqrt(2)/2\n    assert cosh(pi*I/6) == sqrt(3)/2\n    assert cosh(-pi*I) == -1\n    assert cosh(-pi*I/2) == 0\n    assert cosh(-pi*I/3) == 1/2\n    assert cosh(-pi*I/4) == sqrt(2)/2\n    assert cosh(-pi*I/6) == sqrt(3)/2\n    assert cosh(zoo) == nan\n    assert cosh(log(sqrt(2) + 1)) == sqrt(2)\n    assert cosh(log(2) + log(sqrt(2) - 1)) == sqrt(2)\n\n    assert tanh(nan) == nan\n    assert tanh(oo) == 1\n    assert tanh(-oo)", "def test_hyperbolic_functions():\n    x = symbols('x')\n    s = Symbol('s')\n\n    # sinh\n    assert sinh(x).fdiff() == cosh(x)\n    assert sinh(x).inverse() == asinh\n    assert sinh(nan) == nan\n    assert sinh(oo) == oo\n    assert sinh(-oo) == -oo\n    assert sinh(0) == 0\n    assert sinh(1) == sinh(1)\n    assert sinh(-1) == -sinh(1)\n    assert sinh(pi*I) == 0\n    assert sinh(1 + pi*I) == -sinh(1)\n    assert sinh(x).diff(x) == cosh(x)\n\n    # cosh\n    assert cosh(x).fdiff() == sinh(x)\n    assert cosh(x).inverse() == acosh\n    assert cosh(nan) == nan\n    assert cosh(oo) == oo\n    assert cosh(-oo) == oo\n    assert cosh(0) == 1\n    assert cosh(1) == cosh(1)\n    assert cosh(-1) == cosh(1)\n    assert cosh(pi*I/2) == 0\n    assert cosh(1 + pi*I/2) == cosh(1)\n    assert cosh(x).diff(x) == sinh(x)\n\n    # tanh\n    assert tanh(x).fdiff() == 1 - tanh(x)**2\n    assert tanh(x).inverse() == atanh\n    assert tanh(nan) == nan\n    assert tanh(oo) == 1\n    assert tanh(-oo) == -1\n    assert tanh(0) == 0\n    assert tanh(1) == tanh(1)\n    assert tanh(-1) == -tanh(1)\n    assert tanh(pi*I/4) == I\n    assert tanh(1 + pi*I/4) == -tanh(1)\n    assert tanh(x).diff(x) == 1 - tanh(x)**2\n\n    # coth\n    assert coth(x).fdiff() == -coth(x)**2 + 1\n    assert coth(x).inverse() == acoth\n    assert coth(nan) == nan\n    assert coth(oo) == 1\n    assert co", "def test_hyperbolic_functions():\n    x, y = symbols('x y')\n\n    # test sinh\n    assert sinh(nan) == nan\n    assert sinh(oo) == oo\n    assert sinh(-oo) == -oo\n    assert sinh(0) == 0\n    assert sinh(pi*I/2) == I\n    assert sinh(pi*I/2).diff(x) == 0\n    assert sinh(x).diff(x) == cosh(x)\n    assert sinh(x + pi*I/2) == I*cosh(x)\n    assert sinh(2*x).series(x, 0, 4) == 2*x + 2*x**3/3 + O(x**4)\n    assert sinh(x).as_real_imag() == (sinh(x.as_real_imag()[0]), cosh(x.as_real_imag()[0])*sin(x.as_real_imag()[1]))\n    assert sinh(log(2)) == sqrt(3)/2\n    assert sinh(log(sqrt(2) + 1)) == 1\n\n    # test cosh\n    assert cosh(nan) == nan\n    assert cosh(oo) == oo\n    assert cosh(-oo) == oo\n    assert cosh(0) == 1\n    assert cosh(pi*I/2) == 0\n    assert cosh(pi*I/2).diff(x) == 0\n    assert cosh(x).diff(x) == sinh(x)\n    assert cosh(x + pi*I/2) == -sinh(x)\n    assert cosh(2*x).series(x, 0, 4) == 1 + 2*x**2 + 2*x**4/3 + O(x**5)\n    assert cosh(x).as_real_imag() == (cosh(x.as_real_imag()[0])*cos(x.as_real_imag()[1]), sinh(x.as_real_imag()[0])*sin(x.as_real_imag()[1]))\n    assert cosh(log(sqrt(2) + 1)) == sqrt(2) + 1\n    assert cosh(log(2)) == 3/2\n\n    # test tanh\n    assert tanh(nan) == nan\n    assert tanh(oo) == 1\n    assert tanh(-oo) == -1\n    assert tanh(0) == 0\n    assert tanh(pi*I/4) == I\n    assert tanh(pi"], "sample_64": ["    def test_prepopulated_fields_js_tag(self):\n        # Create a mock context with adminform and inline_admin_formsets\n        context = {\n            \"adminform\": Mock(\n                prepopulated_fields=[\n                    {\n                        \"field\": Mock(auto_id=\"id_field\", name=\"field_name\"),\n                        \"dependencies\": [Mock(auto_id=\"id_dependency\", name=\"dependency_name\")],\n                    }\n                ]\n            ),\n            \"inline_admin_formsets\": [\n                [\n                    Mock(\n                        original=None,\n                        prepopulated_fields=[\n                            {\n                                \"field\": Mock(auto_id=\"id_inline_field\", name=\"inline_field_name\"),\n                                \"dependencies\": [\n                                    Mock(auto_id=\"id_inline_dependency\", name=\"inline_dependency_name\")\n                                ],\n                            }\n                        ],\n                    )\n                ]\n            ],\n        }\n\n        # Call the prepopulated_fields_js function\n        context = prepopulated_fields_js(context)\n\n        # Check if the prepopulated_fields and prepopulated_fields_json are correctly populated\n        self.assertEqual(len(context[\"prepopulated_fields\"]), 2)\n        self.assertIn(\"prepopulated_fields_json\", context)\n        prepopulated_fields_json = json.loads(context[\"prepopulated_fields_json\"])\n        self.assertEqual(len(prepopulated_fields_json), 2)\n\n        # Check the contents of the prepopulated_fields_json\n        self.assertEqual(prepopulated_fields_json[0][\"id\"], \"#id_field\")\n        self.assertEqual(prepopulated_fields_json[0][\"name\"], \"field_name\")\n        self.assertEqual(prepopulated_fields_json[0][\"dependency_ids\"], [\"#id_dependency\"])\n        self.assertEqual(prepopulated_fields_json[0][\"dependency_list\"], [\"dependency_name\"])\n        self.assertEqual(prepopulated_fields_json[0][\"maxLength\"], 50)\n        self.assertEqual(prepopulated_fields_json[0][\"allowUnicode\"], False)\n\n        self.assertEqual(prepopulated_fields_json[1][\"id\"], \"#id_inline_field\")\n        self.assertEqual(prepopulated_fields_json[1][\"name\"], \"inline_field_name\")\n        self.assertEqual(prepopulated_fields_json[1][\"dependency_ids\"], [\"#id_inline_dependency\"])\n        self.assertEqual(prepopulated_fields_json[1][\"dependency_list\"], [\"inline_dependency_name\"])\n        self.assertEqual(prepopulated_fields_json[1][\"maxLength\"], 50)\n        self.assertEqual(prepopulated_fields_json[1][\"allowUnicode\"], False)\n", "    def test_prepopulated_fields_js(self):\n        # Create a mock request\n        request = self.request_factory.get(reverse(\"admin:tests_article_change\", args=(1,)))\n        request.user = self.user\n\n        # Create a mock context\n        mock_context = {\n            \"adminform\": ArticleAdmin(Article, site).get_formset_request(request, Article())[0],\n            \"inline_admin_formsets\": [],\n            \"add\": False,\n            \"change\": True,\n            \"is_popup\": False,\n            \"save_as\": False,\n        }\n\n        # Call the prepopulated_fields_js function\n        context = prepopulated_fields_js(mock_context)\n\n        # Check that the prepopulated_fields and prepopulated_fields_json are correctly updated\n        self.assertIn(\"prepopulated_fields\", context)\n        self.assertIn(\"prepopulated_fields_json\", context)\n        self.assertIsInstance(context[\"prepopulated_fields\"], list)\n        self.assertIsInstance(context[\"prepopulated_fields_json\"], str)\n\n        # Check that the prepopulated_fields_json is correctly formatted\n        try:\n            json.loads(context[\"prepopulated_fields_json\"])\n        except json.JSONDecodeError:\n            self.fail(\"prepopulated_fields_json is not a valid JSON\")\n", "    def test_submit_row_context(self):\n        # Create a mock request\n        request = self.request_factory.get(reverse(\"admin:index\"))\n\n        # Create a mock admin user\n        user = User.objects.create_superuser(\"testuser\", \"test@example.com\", \"password\")\n        request.user = user\n\n        # Create a mock change view\n        change_view = ArticleAdmin(Article, site)\n        change_view.request = request\n        change_view.model_admin = ArticleAdmin\n        change_view.opts = Article._meta\n        change_view.object_id = 1\n\n        # Create a mock context\n        context = {\n            \"add\": False,\n            \"change\": True,\n            \"is_popup\": False,\n            \"save_as\": False,\n            \"show_save\": True,\n            \"show_save_and_add_another\": True,\n            \"show_save_and_continue\": True,\n            \"has_add_permission\": True,\n            \"has_change_permission\": True,\n            \"has_view_permission\": True,\n            \"has_editable_inline_admin_formsets\": False,\n        }\n\n        # Call the submit_row function\n        result_context = submit_row(context)\n\n        # Test the resulting context\n        self.assertIn(\"can_change\", result_context)\n        self.assertIn(\"show_delete_link\", result_context)\n        self.assertIn(\"show_save_as_new\", result_context)\n        self.assertIn(\"show_save_and_add_another\", result_context)\n        self.assertIn(\"show_save_and_continue\", result_context)\n        self.assertIn(\"show_save\", result_context)\n        self.assertIn(\"show_close\", result_context)\n\n        self.assertEqual(result_context[\"can_change\"], True)\n        self.assertEqual(result_context[\"show_delete_link\"], True)\n        self.assertEqual(result_context[\"show_save_as_new\"], True)\n        self.assertEqual(result_context[\"show_save_and_add_another\"], True)\n        self.assertEqual(result_context[\"show_save_and_continue\"], True)\n        self.assertEqual(result_context[\"show_save\"], True)\n        self.assertEqual(result_context[\"show_close\"], False)\n", "def test_prepopulated_fields_js_tag(self):\n    \"\"\"\n    Test that the prepopulated_fields_js tag correctly generates the required context.\n    \"\"\"\n    # Create a mock request\n    request = self.request_factory.get(\"/admin/\")\n    request.user = self.superuser\n\n    # Create a mock ModelAdmin instance\n    model_admin = ArticleAdmin(Article, site)\n\n    # Create a mock InlineAdminFormSet\n    inline_admin_formset = model_admin.get_inline_instances(request)\n    inline_admin_form = inline_admin_formset[0].forms[0]\n\n    # Set up the context\n    context = {\n        \"adminform\": model_admin.get_form(request, Article()),\n        \"inline_admin_formsets\": [inline_admin_formset],\n        \"request\": request,\n    }\n\n    # Call the prepopulated_fields_js function\n    new_context = prepopulated_fields_js(context)\n\n    # Check that the prepopulated_fields context variable is updated\n    self.assertIn(\"prepopulated_fields\", new_context)\n    self.assertIn(\"prepopulated_fields_json\", new_context)\n\n    # Check that the prepopulated_fields_json is a valid JSON string\n    try:\n        json.loads(new_context[\"prepopulated_fields_json\"])\n    except json.JSONDecodeError:\n        self.fail(\"prepopulated_fields_json is not a valid JSON string\")\n\n    # Check that the prepopulated_fields contains the expected fields\n    self.assertEqual(len(new_context[\"prepopulated_fields\"]), 1)\n    field = new_context[\"prepopulated_fields\"][0]\n    self.assertIn(\"field\", field)\n    self.assertIn(\"dependencies\", field)\n", "    def test_prepopulated_fields_js_tag(self):\n        admin_form = self.model_admin.get_formset(request=None).form\n        admin_form.fields[\"title\"].widget.attrs[\"class\"] = \"vTextField\"\n        admin_form.fields[\"title\"].prepopulated_fields = {\n            \"field\": admin_form.fields[\"title\"],\n            \"dependencies\": [admin_form.fields[\"slug\"]],\n        }\n\n        context = {\n            \"adminform\": admin_form,\n            \"inline_admin_formsets\": [[]],\n        }\n        prepopulated_fields_js(context)\n        self.assertIn(\"prepopulated_fields\", context)\n        self.assertIn(\"prepopulated_fields_json\", context)\n\n        prepopulated_fields = json.loads(context[\"prepopulated_fields_json\"])\n        self.assertEqual(len(prepopulated_fields), 1)\n        self.assertEqual(prepopulated_fields[0][\"id\"], \"#id_title\")\n        self.assertEqual(prepopulated_fields[0][\"name\"], \"title\")\n        self.assertEqual(prepopulated_fields[0][\"dependency_ids\"], [\"#id_slug\"])\n        self.assertEqual(prepopulated_fields[0][\"dependency_list\"], [\"slug\"])\n        self.assertEqual(prepopulated_fields[0][\"maxLength\"], 50)\n        self.assertEqual(prepopulated_fields[0][\"allowUnicode\"], True)\n"], "sample_15": ["def test_check_language_settings_consistent(self):\n    with override_settings(LANGUAGE_CODE='invalid'):\n        errors = check_language_settings_consistent(None, None)\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, 'translation.E004')\n\n    with override_settings(LANGUAGE_CODE='en'):\n        errors = check_language_settings_consistent(None, None)\n        self.assertEqual(len(errors), 0)\n", "    def test_check_language_settings_consistent_valid(self):\n        errors = check_language_settings_consistent(None, None)\n        self.assertEqual(errors, [])\n", "    def test_check_setting_language_code(self):\n        with self.subTest('LANGUAGE_CODE is invalid'):\n            with override_settings(LANGUAGE_CODE=None):\n                self.assertEqual(\n                    check_setting_language_code(None, None),\n                    [Error('You have provided an invalid value for the LANGUAGE_CODE setting: None.', id='translation.E001')]\n                )\n            with override_settings(LANGUAGE_CODE=123):\n                self.assertEqual(\n                    check_setting_language_code(None, None),\n                    [Error('You have provided an invalid value for the LANGUAGE_CODE setting: 123.', id='translation.E001')]\n                )\n            with override_settings(LANGUAGE_CODE=b'en'):\n                self.assertEqual(\n                    check_setting_language_code(None, None),\n                    [Error(\"You have provided an invalid value for the LANGUAGE_CODE setting: b'en'.\", id='translation.E001')]\n                )\n            for tag in self.invalid_tags:\n                with override_settings(LANGUAGE_CODE=tag):\n                    self.assertEqual(\n                        check_setting_language_code(None, None),\n                        [Error(f'You have provided an invalid value for the LANGUAGE_CODE setting: {tag!r}.', id='translation.E001')]\n                    )\n\n        with self.subTest('LANGUAGE_CODE is valid'):\n            for tag in self.valid_tags:\n                with override_settings(LANGUAGE_CODE=tag):\n                    self.assertEqual(\n                        check_setting_language_code(None, None),\n                        []\n                    )\n", "    def test_check_language_settings_consistent(self):\n        with override_settings(LANGUAGE_CODE='en', LANGUAGES=(('en', 'English'),)):\n            self.assertEqual(check_language_settings_consistent(None, None), [])\n\n        with override_settings(LANGUAGE_CODE='fr', LANGUAGES=(('en', 'English'),)):\n            self.assertEqual(len(check_language_settings_consistent(None, None)), 1)\n            self.assertEqual(check_language_settings_consistent(None, None)[0].msg, E004.msg)\n\n        with override_settings(LANGUAGE_CODE='fr', LANGUAGES=(('fr', 'French'),)):\n            self.assertEqual(check_language_settings_consistent(None, None), [])\n", "    def test_check_setting_language_code(self):\n        # Test LANGUAGE_CODE is a string and valid language code\n        with override_settings(LANGUAGE_CODE='fr-ca'):\n            self.assertEqual(check_setting_language_code(None), [])\n\n        # Test LANGUAGE_CODE is not a string\n        with override_settings(LANGUAGE_CODE=123):\n            self.assertEqual(len(check_setting_language_code(None)), 1)\n\n        # Test LANGUAGE_CODE is not a valid language code\n        with override_settings(LANGUAGE_CODE='abc'):\n            self.assertEqual(len(check_setting_language_code(None)), 1)\n"], "sample_2": ["def test_wcs_p4_pix2foc(self):\n    filename = get_pkg_data_filename('wcs', '0009.fits')\n    h = fits.getheader(filename)\n    w = wcs.WCS(h)\n    assert w.det2im1 is not None\n    x = np.array([0.5, 0.5])\n    with catch_warnings(AstropyWarning) as w:\n        focal = w.p4_pix2foc(x)\n        assert len(w) == 1\n        assert w[0].category == \"invalid-unit\"\n    assert len(w) == 1\n    assert_allclose(focal, np.array([-0.25169885, -0.07506534]))\n", "    def test_all_world2pix_diverging(self):\n        \"\"\"\n        Test that WCS.all_world2pix raises NoConvergence when the\n        algorithm is diverging for a given set of points.\n        \"\"\"\n        header = get_pkg_data_filename('wcs', 'm87_hst_01106_01_wfc_f814w_wcs.fits',\n                                      encoding=\"binary\")\n        hdu = fits.open(header)[1]\n        w = wcs.WCS(hdu.header)\n\n        with pytest.raises(wcs.NoConvergence):\n            w.all_world2pix(\n                np.array([2.0e7, 2.0e7, 1.0e7, 1.0e7]),\n                np.array([2.0e7, 1.0e7, 2.0e7, 1.0e7]),\n                1, maxiter=10, quiet=False, tolerance=1.0e-10)\n\n        with catch_warnings(wcs.NoConvergence) as w:\n            w.all_world2pix(\n                np.array([2.0e7, 2.0e7, 1.0e7, 1.0e7]),\n                np.array([2.0e7, 1.0e7, 2.0e7, 1.0e7]),\n                1, maxiter=10, quiet=True, tolerance=1.0e-10)\n\n        assert len(w) == 1\n", "    def test_dropaxis(self):\n        # Test for dropping an axis.\n        f = get_pkg_data_filename('wcs/det2im.fits')\n        hdu = fits.open(f)\n        w = wcs.WCS(hdu[0].header, naxis=2)\n\n        # Test that the axes can be dropped\n        with NumpyRNGContext(123456789):\n            ra, dec = w.all_pix2world(1, 1, 0)\n            # Put noise into the header\n            w._naxis = np.array(w._naxis) + np.random.uniform(-0.1, 0.1, 2)\n\n            w_drop = w.dropaxis(1)\n            assert w_drop.naxis == 1\n            assert w_drop._naxis[0] == w._naxis[0]\n            assert_allclose(w_drop.wcs.crpix, w.wcs.crpix[:1], atol=0.1)\n\n            ra2 = w_drop.all_pix2world(1, 0)\n            assert_allclose(ra2, ra, atol=0.1)\n\n            # Test that dropaxis does not modify the original WCS\n            assert w.naxis == 2\n            assert_allclose(w.wcs.crpix, [1.0, 1.0], atol=0.1)\n            assert_allclose(w.all_pix2world(1, 1, 0), [ra, dec])\n\n        # Test that axis 1 can be dropped\n        w_drop = w.dropaxis(0)\n        assert w_drop.naxis == 1\n        assert w_drop._naxis[0] == w._naxis[1]\n        assert_allclose(w_drop.wcs.crpix, w.wcs.crpix[1:], atol=0.1)\n\n        dec2 = w_drop.all_pix2world(1, 0)\n        assert_allclose(dec2, dec, atol=0.1)\n", "    def test_footprint_to_file(self):\n        # Test WCS.footprint_to_file\n        hdu = fits.open(get_pkg_data_filename(\n            'wcs/casa_relpath.fits'))[0]\n        w = wcs.WCS(hdu.header)\n        footprint = w.calc_footprint()\n        # Check correct results for this image\n        # The footprint is in pixel coordinates and is in clockwise order from\n        # bottom left, so the first corner is the bottom left\n        assert_allclose(footprint[0], (0.5, 0.5), atol=1e-2)\n        # The last corner is the bottom left again\n        assert_allclose(footprint[-1], (0.5, 0.5), atol=1e-2)\n        # The maximum y value is the top middle\n        assert_allclose(footprint[2], (1000.5, 1000.5), atol=1e-2)\n        # The maximum x value is the top right\n        assert_allclose(footprint[1], (1001.5, 999.5), atol=1e-2)\n        # The minimum x value is the bottom right\n        assert_allclose(footprint[3], (1.5, 1.5), atol=1e-2)\n\n        # Test writing it to a file\n        with io.StringIO() as f:\n            w.footprint_to_file(coordsys='J2000', fobj=f)\n            footprint_from_file = f.getvalue()\n\n        # Check that the file contains the correct coordinates\n        assert footprint_from_file.count('J2000') == 1\n        assert footprint_from_file.count('polygon') == 1\n        assert_allclose(np.fromstring(footprint_from_file, sep=',').reshape(4, 2),\n                        footprint, atol=1e-2)\n", "    def test_calc_footprint(self):\n        # Test that the footprint of an image is calculated correctly.\n        # Use an example image from the astrometry.net\n        filename = get_pkg_data_filename('data/2MASS/9901265c_h.fits')\n        hdulist = fits.open(filename)\n        w = wcs.WCS(hdulist[0].header, hdulist)\n        footprint = w.calc_footprint(center=True)\n        assert_array_almost_equal(footprint, [[96.54974987, -45.83427017],\n                                             [96.54974987, -45.83399578],\n                                             [96.55025622, -45.83399578],\n                                             [96.55025622, -45.83427017]])\n\n        # Test that footprint is None if header is None\n        w = wcs.WCS(None)\n        assert w.calc_footprint() is None\n\n        # Test that footprint is None if the image size cannot be determined\n        w = wcs.WCS('naxis  = 2')\n        assert w.calc_footprint() is None\n\n        # Test that an error is raised if center is False\n        w = wcs.WCS(hdulist[0].header, hdulist)\n        hdulist[0].header['NAXIS1'] = 1\n        hdulist[0].header['NAXIS2'] = 1\n        with raises(ValueError):\n            w.calc_footprint(center=False)\n        hdulist.close()\n"], "sample_41": ["    def test_formset_with_custom_kwarg(self):\n        CustomKwargFormset = formset_factory(CustomKwargForm, extra=1)\n\n        formset = CustomKwargFormset(custom_kwarg='value')\n        self.assertEqual(formset.empty_form.custom_kwarg, 'value')\n\n        formset = CustomKwargFormset(data={'form-0-custom_kwarg': 'value'}, custom_kwarg='default_value')\n        self.assertEqual(formset.forms[0].custom_kwarg, 'value')\n", "    def test_management_form_rendering(self):\n        formset = self.make_choiceformset(formset_data=[('Coke', 3)])\n        self.assertHTMLEqual(str(formset.management_form), (\n            '<input type=\"hidden\" name=\"choices-TOTAL_FORMS\" value=\"1\" '\n            'id=\"id_choices-TOTAL_FORMS\"><input type=\"hidden\" '\n            'name=\"choices-INITIAL_FORMS\" value=\"0\" '\n            'id=\"id_choices-INITIAL_FORMS\"><input type=\"hidden\" '\n            'name=\"choices-MIN_NUM_FORMS\" value=\"0\" '\n            'id=\"id_choices-MIN_NUM_FORMS\"><input type=\"hidden\" '\n            'name=\"choices-MAX_NUM_FORMS\" value=\"1000\" '\n            'id=\"id_choices-MAX_NUM_FORMS\">'\n        ))\n", "    def test_management_form(self):\n        formset = self.make_choiceformset(\n            formset_data=[('A', '1'), ('B', '2')],\n            total_forms=2,\n            initial_forms=2,\n            max_num_forms=2,\n            min_num_forms=2,\n        )\n        management_form = formset.management_form\n        self.assertIsInstance(management_form, ManagementForm)\n        self.assertEqual(management_form.cleaned_data[TOTAL_FORM_COUNT], 2)\n        self.assertEqual(management_form.cleaned_data[INITIAL_FORM_COUNT], 2)\n        self.assertEqual(management_form.cleaned_data[MIN_NUM_FORM_COUNT], 2)\n        self.assertEqual(management_form.cleaned_data[MAX_NUM_FORM_COUNT], 2)\n", "    def test_formset_with_custom_initial_data(self):\n        data = [\n            {'name': 'Drink 1'},\n            {'name': 'Drink 2'},\n            {'name': 'Drink 3'},\n        ]\n        formset = FavoriteDrinksFormSet(initial=data)\n        self.assertEqual(len(formset.initial_forms), 3)\n", "    def test_management_form(self):\n        formset = self.make_choiceformset()\n        management_form = formset.management_form\n        self.assertIsInstance(management_form, Form)\n        self.assertEqual(management_form.fields[TOTAL_FORM_COUNT].initial, 1)\n        self.assertEqual(management_form.fields[INITIAL_FORM_COUNT].initial, 0)\n        self.assertEqual(management_form.fields[MIN_NUM_FORM_COUNT].initial, 0)\n        self.assertEqual(management_form.fields[MAX_NUM_FORM_COUNT].initial, 1000)\n\n        formset = self.make_choiceformset(total_forms=5)\n        management_form = formset.management_form\n        self.assertEqual(management_form.fields[TOTAL_FORM_COUNT].initial, 5)\n\n        formset = self.make_choiceformset(formset_data=[('Coke', 1)])\n        management_form = formset.management_form\n        self.assertEqual(management_form.fields[TOTAL_FORM_COUNT].initial, 1)\n        self.assertEqual(management_form.fields[INITIAL_FORM_COUNT].initial, 1)\n\n        formset = self.make_choiceformset(formset_data=[('Coke', 1)], total_forms=10)\n        management_form = formset.management_form\n        self.assertEqual(management_form.fields[TOTAL_FORM_COUNT].initial, 10)\n"], "sample_132": ["def test_convex_hull():\n    points = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4)]\n    convex_hull_result = convex_hull(*points)\n    assert convex_hull_result == Polygon(Point2D(-5, 2), Point2D(1, 1), Point2D(3, 1), Point2D(15, 4))\n\n    hull, _ = convex_hull(*points, polygon=False)\n    assert hull == (Point2D(-5, 2), Point2D(15, 4))\n\n    with raises(ValueError):\n        convex_hull(Point2D(0, 0))\n\n    with raises(ValueError):\n        convex_hull(Point2D(0, 0), Point2D(1, 1), Point2D(2, 2))\n\n    with raises(ValueError):\n        convex_hull(Point2D(0, 0), Point2D(0, 0))\n\n    with raises(ValueError):\n        convex_hull(Point2D(0, 0), Point2D(0, 0), Point2D(0, 0), Point2D(1, 1))\n", "def test_idiff():\n    x = Symbol('x')\n    y = Symbol('y')\n    a = Symbol('a')\n    eq1 = x**2 + y**2 - 4\n    eq2 = x + y + a\n    assert idiff(eq1, y, x) == -x/y\n    assert idiff(eq1, y, x, 2).simplify() == -(x**2 + y**2)/y**3\n    assert idiff(eq2, y, x) == -1\n    assert idiff(eq2, [y, a], x) == -Derivative(a, x) - 1\n    assert idiff(x**2*y - y**2 + a**2, y, x) == x/y\n    assert idiff(x**2*y - y**2 + a**2, [y, a], x) == x/y - 2*a*Derivative(a, x)/y\n", "def test_find():\n    x = Symbol('x')\n    y = Symbol('y')\n    a = Symbol('a')\n    eq = x**2 + y**2 - a\n    assert find(x, eq) == x\n    raises(ValueError, lambda: find('z', eq))\n    raises(ValueError, lambda: find(a, x**2 + y**2 - a))\n", "def test_idiff():\n    x = Symbol('x')\n    y = Symbol('y')\n    eq = x**2 + y**2 - 4\n    assert idiff(eq, y, x) == -x/y\n\n    x, y, a = symbols('x y a')\n    assert idiff(x + a + y, y, x) == -1\n\n    assert idiff(x + a + y, [y, a], x) == -Derivative(a, x) - 1\n\n    # Check that the function works for irrational numbers.\n    a = sqrt(2)\n    eq = x**2 + y**2 - a**2\n    assert idiff(eq, y, x) == -x/y\n\n    # Check that the function works for symbolic expressions.\n    f = Function('f')\n    eq = x**2 + f(x)**2 - 4\n    assert idiff(eq, f(x), x) == -x/f(x)\n", "def test_idiff():\n    x = Symbol('x')\n    y = Function('y')(x)\n    y2 = Function('y')(x, x)\n    f = y + x\n    f2 = y2 + x**2\n\n    assert idiff(f, y, x) == -1\n    assert idiff(f, y, x, n=2) == 0\n    assert idiff(f2, y2, x, n=2) == -2\n\n    a = Symbol('a')\n    assert idiff(f, y, x, n=1).subs(y, a) == -1\n    assert idiff(f2, y2, x, n=2).subs(y2, a) == -2\n\n    u, v = symbols('u v', cls=Function)\n    eq = u(x) + v(x) + x\n    assert idiff(eq, [u(x), v(x)], x) == -Derivative(v(x), x) - 1\n\n    # issue 11428\n    eq = sqrt(x + y**2)\n    assert idiff(eq, y, x) == -y/sqrt(x + y**2)\n\n    # issue 14411\n    from sympy.abc import x, y\n    from sympy import exp, sin\n    assert idiff(exp(x)*sin(y), y, x) == -exp(x)*sin(y)/tan(y)\n\n    # issue 14533\n    eq = 2*y*(1 - x) + 4*x**2 - 3*x - y**2\n    assert idiff(eq, y, x) == 2 - 4*y/(2*(1 - x) - 2*x)\n\n    # issue 15591\n    eq = x**3 - 3*y**2*x + 2*y**3 - 1\n    assert idiff(eq, y, x, n=2).subs(x, 0) == 12\n\n    # issue 16939\n    from sympy import cos\n    assert idiff(cos(x) + y, y, x) == tan(x)\n\n    # issue 17635\n    u, v = symbols('u v', cls=Function)\n    eq = u(x)**2 + v(x)**2 - 1\n    assert idiff(eq, [u(x), v(x)], x) == -Derivative(u"], "sample_152": ["def test_ndim_array_creation():\n    # Test creation from a flat list with shape\n    a = ImmutableDenseNDimArray([1, 2, 3, 4, 5, 6], (2, 3))\n    assert a.tolist() == [[1, 2, 3], [4, 5, 6]]\n\n    # Test creation from a matrix\n    m = Matrix([[1, 2], [3, 4]])\n    b = ImmutableDenseNDimArray(m)\n    assert b.tolist() == [[1, 2], [3, 4]]\n\n    # Test creation from an iterable (numpy array)\n    import numpy as np\n    c = ImmutableDenseNDimArray(np.array([[1, 2], [3, 4]]))\n    assert c.tolist() == [[1, 2], [3, 4]]\n\n    # Test creation from a sparse array\n    d = ImmutableSparseNDimArray({(0, 0): 1, (1, 1): 2}, (2, 2))\n    e = ImmutableDenseNDimArray(d)\n    assert e.tolist() == [[1, 0], [0, 2]]\n\n    # Test creation from a scalar\n    f = ImmutableDenseNDimArray(5)\n    assert f.tolist() == [5]\n", "def test_ndim_array_creation():\n    # Test creation with a list and shape\n    a = ImmutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    assert a.tolist() == [[1, 2], [3, 4]]\n\n    # Test creation with a matrix\n    m = Matrix([[1, 2], [3, 4]])\n    a = ImmutableDenseNDimArray(m)\n    assert a.tolist() == [[1, 2], [3, 4]]\n\n    # Test creation with a flat list and shape\n    a = ImmutableDenseNDimArray([1, 2, 3, 4, 5, 6], (2, 3))\n    assert a.tolist() == [[1, 2, 3], [4, 5, 6]]\n\n    # Test creation with a nested list\n    a = ImmutableDenseNDimArray([[1, 2], [3, 4]])\n    assert a.tolist() == [[1, 2], [3, 4]]\n\n    # Test creation with a nested list with different depths\n    a = ImmutableDenseNDimArray([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n    assert a.tolist() == [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n\n    # Test creation with a scalar value\n    a = ImmutableDenseNDimArray(1)\n    assert a.tolist() == [1]\n\n    # Test creation with an empty list\n    a = ImmutableDenseNDimArray([])\n    assert a.tolist() == []\n", "def test_ndimarray():\n    a = ImmutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    b = ImmutableDenseNDimArray([4, 4, 4, 4], (2, 2))\n    c = a + b\n    assert c.tolist() == [[5, 5], [5, 5]]\n    assert a - b == ImmutableDenseNDimArray([-3, -3, -3, -3], (2, 2))\n    assert a * 2 == ImmutableDenseNDimArray([2, 4, 6, 8], (2, 2))\n    assert 2 * a == ImmutableDenseNDimArray([2, 4, 6, 8], (2, 2))\n    assert a / 2 == ImmutableDenseNDimArray([1/2, 1, 3/2, 2], (2, 2))\n    assert -a == ImmutableDenseNDimArray([-1, -2, -3, -4], (2, 2))\n    assert a.rank() == 2\n    assert a.tolist() == [[1, 2], [3, 4]]\n    assert a == ImmutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    assert a != ImmutableDenseNDimArray([1, 2, 3, 5], (2, 2))\n    assert a.shape == (2, 2)\n    assert a.transpose() == ImmutableDenseNDimArray([1, 3, 2, 4], (2, 2))\n    assert a.conjugate() == ImmutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    assert a.adjoint() == ImmutableDenseNDimArray([1, 3, 2, 4], (2, 2))\n    assert a.diff(x) == ImmutableDenseNDimArray([0, 0, 0, 0], (2, 2))\n    a[0,0] = 5\n    assert a.tolist() == [[5, 2], [3, 4]]\n    a[1,1] = sin(x)\n    assert a.tolist() == [[5, ", "def test_ndimarray_getitem():\n    a = ImmutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    assert a[0, 0] == 1\n    assert a[0, 1] == 2\n    assert a[1, 0] == 3\n    assert a[1, 1] == 4\n    with raises(ValueError):\n        a[0, 2]\n    with raises(ValueError):\n        a[2, 0]\n    with raises(ValueError):\n        a[0, 0, 0]\n    with raises(ValueError):\n        a[0:2, 0:2]\n", "def test_NDimArray_hash():\n    # Ensure hash for NDimArray is deterministic.\n    arr = ImmutableDenseNDimArray([x, y], (2,))\n    assert hash(arr) == hash((arr.shape, tuple(arr)))\n"], "sample_51": ["def test_was_modified_since_header_with_length(self):\n    mtime = 1643723900\n    size = 1024\n    header = f\"Wed, 21-Jan-2022 14:18:20 GMT; length={size}\"\n    self.assertFalse(was_modified_since(header, mtime, size))\n", "def test_serve_file(self):\n    \"\"\"\n    Test that a file can be served by the serve view.\n    \"\"\"\n    file_path = path.join(media_dir, \"test.txt\")\n    with open(file_path, \"w\") as f:\n        f.write(\"Hello, world!\")\n\n    url = f\"/{self.prefix}/test.txt\"\n    response = self.client.get(url)\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(response.content, b\"Hello, world!\")\n", "def test_serve(self):\n    # Set up a test URL pattern\n    urls.urlpatterns += static(self.prefix, document_root=media_dir)\n\n    # Test serving a file\n    response = self.client.get(f'/{self.prefix}/views_tests.py')\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(response['Content-Type'], 'text/x-python')\n    self.assertEqual(response['Last-Modified'], http_date(path.getmtime(path.join(media_dir, 'views_tests.py'))))\n\n    # Test serving a file with a If-Modified-Since header\n    mtime = path.getmtime(path.join(media_dir, 'views_tests.py'))\n    response = self.client.get(f'/{self.prefix}/views_tests.py', HTTP_IF_MODIFIED_SINCE=http_date(mtime))\n    self.assertEqual(response.status_code, 304)\n\n    # Test serving a directory with indexes\n    response = self.client.get(f'/{self.prefix}/')\n    self.assertEqual(response.status_code, 200)\n    self.assertTemplateUsed(response, 'static/directory_index.html')\n\n    # Test serving a directory without indexes\n    with self.settings(DEBUG=False):\n        response = self.client.get(f'/{self.prefix}/')\n        self.assertEqual(response.status_code, 404)\n\n    # Test serving a non-existent file\n    response = self.client.get(f'/{self.prefix}/non_existent_file.txt')\n    self.assertEqual(response.status_code, 404)\n\n    # Test serving a file with an encoding\n    response = self.client.get(f'/{self.prefix}/test_gzip.txt.gz')\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(response['Content-Encoding'], 'gzip')\n\n    # Test serving a file with a URL encoded path\n    response = self.client.get(f'/{self.prefix}/{quote(\"test space.txt\")}')\n    self.assertEqual(response.status_code, 200)\n", "    def test_serve_file(self):\n        \"\"\"\n        Test that serve() returns a HttpResponse with the file content.\n        \"\"\"\n        file_path = path.join(media_dir, \"test.txt\")\n        with open(file_path, \"w\") as f:\n            f.write(\"Hello, World!\")\n        url_pattern = static(\"site_media/\", document_root=media_dir)\n        response = self.client.get(url_pattern + quote(\"test.txt\"))\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.content, b\"Hello, World!\")\n        self.assertEqual(response[\"Content-Type\"], \"text/plain\")\n", "    def test_directory_index(self):\n        with self.settings(DEBUG=True, ROOT_URLCONF=\"view_tests.urls\"):\n            from django.test import TestCase\n            from django.urls import path\n            from django.views import static\n            from django.views.static import serve\n\n            urls.urlpatterns += [\n                path('site_media/<path:path>', serve, {'document_root': media_dir, 'show_indexes': True}),\n            ]\n\n            response = self.client.get('/site_media/')\n            self.assertEqual(response.status_code, 200)\n            self.assertTemplateUsed(response, 'static/directory_index.html')\n\n            # Test default template\n            with override_settings(TEMPLATE_DIRS=[]):\n                response = self.client.get('/site_media/')\n                self.assertEqual(response.status_code, 200)\n                self.assertContains(response, '<h1>Index of /</h1>')\n\n            # Test directory index with subdirectories and files\n            test_dir = path.join(media_dir, 'test_dir')\n            test_file = path.join(test_dir, 'test_file.txt')\n            path.makedirs(test_dir, exist_ok=True)\n            with open(test_file, 'w') as f:\n                f.write('Test file content')\n\n            response = self.client.get('/site_media/test_dir/')\n            self.assertEqual(response.status_code, 200)\n            self.assertContains(response, '<li><a href=\"test_file.txt\">test_file.txt</a></li>')\n            self.assertContains(response, '<li><a href=\"../\">../</a></li>')\n\n            # Test directory index with subdirectories only\n            response = self.client.get('/site_media/')\n            self.assertEqual(response.status_code, 200)\n            self.assertContains(response, '<li><a href=\"test_dir/\">test_dir/</a></li>')\n            self.assertContains(response, '<li><a href=\"../\">../</a></li>')\n\n            # Test directory index with files only\n            path.rmdir(test_dir)\n            response = self.client.get('/site_media/')\n            self.assertEqual(response.status_code, 200)\n            self.assertContains(response, '<h1>Index of /</h1>')\n"], "sample_134": ["def test_printing():\n    printer = NumPyPrinter()\n\n    # Test printing of CodegenArrayContraction\n    A = CodegenArrayContraction(CodegenArrayTensorProduct(a, MatrixSymbol('B', 3, 3), MatrixSymbol('C', 3, 3)), [(0, 2)])\n    assert printer._print(A) == \"numpy.einsum(a, B, C, [0, 1], [1, 2])\"\n\n    # Test printing of CodegenArrayDiagonal\n    A = CodegenArrayDiagonal(MatrixSymbol('B', 3, 3), [(0, 1)])\n    assert printer._print(A) == \"numpy.diagonal(B, 0, axis1=0, axis2=1)\"\n\n    # Test printing of CodegenArrayPermuteDims\n    A = CodegenArrayPermuteDims(MatrixSymbol('B', 3, 3), (0, 1))\n    assert printer._print(A) == \"numpy.transpose(B, (0, 1))\"\n\n    # Test printing of CodegenArrayElementwiseAdd\n    A = CodegenArrayElementwiseAdd(a, b, c)\n    assert printer._print(A) == \"numpy.add(a, numpy.add(b, c))\"\n\n    # Test printing of BlockMatrix\n    A = BlockMatrix([[a, b], [c, d]])\n    assert printer._print(A) == \"numpy.block([[a, b], [c, d]])\"\n\n    # Test printing of Identity\n    A = Identity(3)\n    assert printer._print(A) == \"numpy.eye(3)\"\n\n    # Test printing of MatrixBase\n    A = MatrixSymbol('A', 3, 3)\n    assert printer._print(A) == \"numpy.array(A.tolist())\"\n\n    # Test printing of Piecewise\n    A = Piecewise((x, x > 0), (x**2, x < 0))\n    assert printer._print(A) == \"numpy.select([x > 0, x < 0], [x, x**2], default=numpy.nan)\"\n\n    # Test printing of Pow with 0.5 exponent\n    A = a**0.5\n    assert printer._print(A) == \"numpy.sqrt(a)\"\n\n    # Test printing of sinc\n    A = cbrt(a)/a\n    assert printer._print(A) == \"numpy.sinc(a/3.", "def test_printers():\n    # Test NumPyPrinter._print_CodegenArrayElementwiseAdd\n    expr = CodegenArrayElementwiseAdd([1, 2], [3, 4])\n    assert NumPyPrinter().doprint(expr) == \"numpy.add(1, 3)\"\n\n    # Test NumPyPrinter._print_CodegenArrayElementwiseAdd with multiple arguments\n    expr = CodegenArrayElementwiseAdd([1, 2], [3, 4], [5, 6])\n    assert NumPyPrinter().doprint(expr) == \"numpy.add(numpy.add(1, 3), 5)\"\n\n    # Test NumPyPrinter._print_CodegenArrayElementwiseAdd with symbolic arguments\n    expr = CodegenArrayElementwiseAdd(a, b, c)\n    assert NumPyPrinter().doprint(expr) == \"numpy.add(numpy.add(a, b), c)\"\n\n    # Test SymPyPrinter._print_Function\n    expr = a.func(a, b)\n    assert SymPyPrinter().doprint(expr) == \"sympy.%s(a, b)\" % a.func.__name__\n\n    # Test NumPyPrinter._print_SparseMatrix\n    from sympy import Matrix\n    M = Matrix([[1, 2], [0, 0]])\n    assert NumPyPrinter().doprint(M) == \"numpy.array([[1, 2], [0, 0]])\"\n\n    # Test SciPyPrinter._print_assoc_legendre\n    from sympy import assoc_legendre\n    expr = assoc_legendre(1, 2, x)\n    assert SciPyPrinter().doprint(expr) == \"scipy.special.lpmv(1, 2, x)\"\n", "def test_NumPyPrinter():\n    printer = NumPyPrinter()\n    assert printer._print_Sum(Sum(x**2, (x, a, b))) == \"(builtins.sum((x**2 for x in range(a, b+1)))\"\n\n    assert printer._print_Mod(Mod(x, y)) == \"numpy.mod(x, y)\"\n    assert printer._print(cbrt(x)) == \"x**(1/3)\"\n    assert printer._print(sqrt(x)) == \"numpy.sqrt(x)\"\n\n    matrix = MatrixSymbol('matrix', 3, 3)\n    block_matrix = BlockMatrix([[matrix, matrix], [matrix, matrix]])\n    assert printer._print(block_matrix) == \"numpy.block([[matrix, matrix], [matrix, matrix]])\"\n    assert printer._print(Identity(3)) == \"numpy.eye(3)\"\n    assert printer._print(eye(3)) == \"numpy.eye(3)\"\n\n    contraction = CodegenArrayContraction(CodegenArrayTensorProduct((a, b), (c, d), (e, f)))\n    assert printer._print(contraction) == \"numpy.einsum('ij,ji->', a, b), c, f\"\n\n    array_diagonal = CodegenArrayDiagonal(a, [(0, 1)])\n    assert printer._print(array_diagonal) == \"numpy.diagonal(a, 0, axis1=0, axis2=1)\"\n\n    permutation = CodegenArrayPermuteDims(a, (1, 0))\n    assert printer._print(permutation) == \"numpy.transpose(a, (1, 0))\"\n\n    array_elementwise_add = CodegenArrayElementwiseAdd(a, b, c)\n    assert printer._print(array_elementwise_add) == \"numpy.add(numpy.add(a, b), c)\"\n", "def test_NumPyPrinter():\n    n = NumPyPrinter()\n\n    assert n._print_MatPow(MatrixSymbol('A', 2, 2)**2) == 'numpy.linalg.matrix_power(A, 2)'\n    assert n._print_Inverse(MatrixSymbol('A', 2, 2)) == 'numpy.linalg.inv(A)'\n\n    # Test block matrix\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    D = MatrixSymbol('D', 2, 2)\n    b = BlockMatrix([[A, B], [C, D]])\n    assert n._print(b) == 'numpy.block([[A, B], [C, D]])'\n\n    # Test identity matrix\n    assert n._print(Identity(2)) == 'numpy.eye(2)'\n\n    # Test CodegenArrayContraction\n    A = CodegenArrayTensorProduct([[a, b], [c, d]])\n    B = CodegenArrayTensorProduct([[x, y], [z, t]])\n    contraction = CodegenArrayContraction(A, [(0, 2)])\n    assert n._print(contraction) == 'numpy.einsum(a, b, x, z, [0, 1], [0, 1])'\n\n    # Test CodegenArrayDiagonal\n    assert n._print(CodegenArrayDiagonal(x, [(0, 1)])) == 'numpy.diagonal(x, 0, axis1=0, axis2=1)'\n\n    # Test CodegenArrayPermuteDims\n    expr = CodegenArrayPermuteDims(a, (1, 0))\n    assert n._print(expr) == \"numpy.transpose(a, (1, 0))\"\n\n    # Test CodegenArrayElementwiseAdd\n    assert n._print(CodegenArrayElementwiseAdd([a, b, c])) == 'numpy.add(numpy.add(a, b), c)'\n\n    # Test CodegenArrayTensorProduct\n    expr = CodegenArrayTensorProduct([[a, b], [c, d]])\n    assert n._print(expr) == 'numpy.einsum(a, b, [0, 1], [0, 1])'\n\n    # Test _print_Piecewise\n    pw = Piecewise((1, x > 0), (-1", "def test_Print():\n    prnt = Piecewise((a, x > 0), (b, x < 0), (c, x == 0))\n    prnt = prnt.printed\n    assert NumPyPrinter().doprint(prnt) == \\\n        'numpy.select([x > 0, x < 0, x == 0], [a, b, c], default=numpy.nan)'\n    assert NumPyPrinter().doprint(Mod(x, 3)) == 'numpy.mod(x, 3)'\n    assert NumPyPrinter().doprint(Sum(x**2, (x, 0, 3)).func) == \\\n        'def _lambdifygenerated(x):\\n    return x**2'\n    assert NumPyPrinter().doprint(Sum(x**2, (x, 0, 3)).doit()) == \\\n        '(builtins.sum(_lambdifygenerated(x) for x in range(0, 3+1)))'\n"], "sample_55": ["def test_no_translations_decorator(self):\n        return translation.get_language()\n\n    handle_func = no_translations(dummy_handle)\n    with mock.patch(\"django.utils.translation.get_language\", return_value=\"en\"):\n        self.assertIsNone(handle_func())\n", "    def test_base_command(self):\n        class Command(BaseCommand):\n                pass\n\n        command = Command()\n        self.assertEqual(command.help, \"\")\n        self.assertEqual(command.output_transaction, False)\n        self.assertEqual(command.requires_migrations_checks, False)\n        self.assertEqual(command.requires_system_checks, \"__all__\")\n        self.assertEqual(command.base_stealth_options, (\"stderr\", \"stdout\"))\n        self.assertEqual(command.stealth_options, ())\n        self.assertEqual(command.suppressed_base_arguments, set())\n\n        with self.assertRaises(NotImplementedError):\n            command.handle()\n", "    def test_base_command_output_transaction(self):\n        class TestCommand(BaseCommand):\n            help = \"Test command\"\n            output_transaction = True\n\n                return \"SELECT * FROM my_table;\"\n\n        cmd = TestCommand()\n        with captured_stderr() as stderr:\n            cmd.execute(\"arg\", verbosity=1)\n        self.assertIn(\"BEGIN;\", stderr.getvalue())\n        self.assertIn(\"COMMIT;\", stderr.getvalue())\n        self.assertIn(\"SELECT * FROM my_table;\", stderr.getvalue())\n", "    def test_no_translations_decorator(self, mock_get_language, mock_activate):\n        class DummyCommand(BaseCommand):\n            @no_translations\n                translation.get_language()\n                translation.activate(\"de\")\n\n        mock_get_language.return_value = \"fr\"\n        command = DummyCommand()\n        command.handle()\n        self.assertEqual(mock_get_language.call_count, 2)\n        self.assertEqual(mock_activate.call_args_list[0][0][0], \"fr\")\n        self.assertEqual(mock_activate.call_args_list[1][0][0], \"de\")\n", "    def test_base_command(self):\n        class TestCommand(BaseCommand):\n            help = \"Test command\"\n\n                pass\n\n        with captured_stderr() as stderr:\n            command = TestCommand()\n            command.stdout = StringIO()\n            command.stderr = StringIO()\n            command.run_from_argv([\"manage.py\", \"test_command\"])\n\n        self.assertEqual(stderr.getvalue(), \"\")\n\n        with captured_stderr() as stderr:\n            command = TestCommand()\n            command.stdout = StringIO()\n            command.stderr = StringIO()\n            command.handle()\n\n        with self.assertRaises(NotImplementedError):\n            command.handle()\n\n        with captured_stderr() as stderr:\n            command = TestCommand()\n            command.stdout = StringIO()\n            command.stderr = StringIO()\n            command.execute()\n\n        self.assertEqual(stderr.getvalue(), \"\")\n\n        with captured_stderr() as stderr:\n            command = TestCommand()\n            command.stdout = StringIO()\n            command.stderr = StringIO()\n            command.execute()\n\n        with self.assertRaises(NotImplementedError):\n            command.execute()\n\n        with captured_stderr() as stderr:\n            command = TestCommand()\n            command.stdout = StringIO()\n            command.stderr = StringIO()\n            command.print_help(\"manage.py\", \"test_command\")\n\n        self.assertNotEqual(stderr.getvalue(), \"\")\n\n        command = TestCommand()\n        command.stdout = StringIO()\n        command.stderr = StringIO()\n        self.assertEqual(command.get_version(), django.get_version())\n"], "sample_49": ["def test_watch_for_template_changes(self):\n    sender = mock.MagicMock()\n    watch_for_template_changes(sender)\n    sender.watch_dir.assert_called_once()\n    self.assertIn(str(EXTRA_TEMPLATES_DIR), sender.watch_dir.call_args[0][0])\n", "def test_template_changed_resets_loaders(self):\n    \"\"\"\n    Test that template_changed resets loaders when a template file changes.\n    \"\"\"\n    file_path = EXTRA_TEMPLATES_DIR / 'test_template.html'\n    file_path.touch()\n    with mock.patch('template_tests.template_reloading.reset_loaders') as reset_loaders_mock:\n        autoreload._notify_file_changed(file_path)\n        self.assertTrue(reset_loaders_mock.called)\n", "def test_template_changed_calls_reset_loaders(self):\n    file_path = mock.Mock(spec=Path)\n    file_path.suffix = '.html'\n    template_dir = mock.Mock(spec=Path)\n    template_dir.parents = [mock.Mock()]\n    template_dir.parents[0].parents = [template_dir]\n    get_template_directories.return_value = [template_dir]\n    with self.settings(MEDIA_ROOT='path/to/media/root'):\n        self.assertTrue(template_changed(mock.Mock(), file_path))\n    self.assertTrue(template_dir in file_path.parents)\n    reset_loaders.assert_called_once()\n", "    def test_template_changed(self, mock_reset_loaders):\n        with mock.patch('django.template.autoreload.get_template_directories') as mock_get_template_directories:\n            mock_get_template_directories.return_value = [Path('/path/to/templates')]\n            file_path = Path('/path/to/templates/template.html')\n            self.assertTrue(autoreload.template_changed(None, file_path))\n            mock_reset_loaders.assert_called_once()\n", "    def test_template_changed_calls_reset_loaders(self, reset_loaders):\n        template_dir = EXTRA_TEMPLATES_DIR\n        file_path = template_dir / 'test_template.html'\n        autoreload._cached_files[file_path] = 1\n        result = template_changed(None, file_path)\n        reset_loaders.assert_called_once()\n        self.assertTrue(result)\n"], "sample_13": ["    def test_http_date_parsing_rfc1123(self):\n        dt = datetime(2022, 1, 1, 12, 0, 0)\n        date_str = http_date(calendar.timegm(dt.utctimetuple()))\n        self.assertEqual(parse_http_date(date_str), calendar.timegm(dt.utctimetuple()))\n", "    def test_valid_base64_string(self):\n        encoded_string = urlsafe_base64_encode(b'test_string')\n        decoded_string = urlsafe_base64_decode(encoded_string)\n        self.assertEqual(decoded_string, b'test_string')\n", "    def test_urlsafe_base64_encode(self):\n        self.assertEqual(urlsafe_base64_encode(b'Hello World!'), 'SGVsbG8gd29ybGQh')\n        self.assertEqual(urlsafe_base64_encode(b'Hello World'), 'SGVsbG8gd29ybA')\n", "    def test_urlencode_with_none_value(self):\n        with self.assertRaises(TypeError) as cm:\n            urlencode(MultiValueDict({'a': None}))\n        self.assertEqual(str(cm.exception), self.cannot_encode_none_msg)\n", "    def test_limited_parse_qsl(self):\n        test_cases = [\n            ('a=1&b=2', [('a', '1'), ('b', '2')]),\n            ('a=1&a=2', [('a', '1'), ('a', '2')]),\n            ('a=&b=2', [('a', ''), ('b', '2')]),\n            ('a=1&b=', [('a', '1'), ('b', '')]),\n            ('a=1&', [('a', '1')]),\n            ('&a=1', []),\n            ('', []),\n            ('a', []),\n        ]\n        for query_string, expected in test_cases:\n            self.assertEqual(limited_parse_qsl(query_string), expected)\n        \n        # Test keep_blank_values\n        test_cases = [\n            ('a=&b=2', [('a', ''), ('b', '2')]),\n            ('a=1&b=', [('a', '1'), ('b', '')]),\n            ('', []),\n            ('a', []),\n        ]\n        for query_string, expected in test_cases:\n            self.assertEqual(limited_parse_qsl(query_string, keep_blank_values=True), expected)\n        \n        # Test encoding\n        test_cases = [\n            ('a=%C3%A9&b=2', [('a', '\\u00e9'), ('b', '2')]),\n            ('a=%C3%89&b=2', [('a', '\\u00c9'), ('b', '2')]),\n        ]\n        for query_string, expected in test_cases:\n            self.assertEqual(limited_parse_qsl(query_string, encoding='utf-8'), expected)\n        \n        # Test errors\n        test_cases = [\n            ('a=%FF&b=2', [('a', '\\ufffd'), ('b', '2')]),\n            ('a=%FF&b=2', [('a', '\\ufffd'), ('b', '2')]),\n        ]\n        for query_string, expected in test_cases:\n            self.assertEqual(limited_parse_qsl(query_string, errors='replace'), expected)\n        \n        # Test fields_limit\n        query_string = 'a=1&a=2&a=3'\n        with self.assertRaises(TooManyFieldsSent):\n            limited_parse_qsl(query_string, fields_limit=2)\n"], "sample_48": ["    def test_rename_model_state_forwards(self):\n        # Test state alteration\n        operation = RenameModel(\"OldModel\", \"NewModel\")\n        project_state = ProjectState()\n        operation.state_forwards(\"testapp\", project_state)\n        self.assertIn(\"NewModel\", project_state.models)\n        self.assertNotIn(\"OldModel\", project_state.models)\n", "    def test_create_model(self):\n        operation = migrations.CreateModel(\n            \"MyModel\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=255)),\n            ],\n        )\n        self.assertState(\n            operation,\n            self.initial_state.clone(),\n            ProjectState(\n                apps=[self.app_label],\n                models={\n                    self.app_label: {\n                        \"MyModel\": ModelState(\n                            app_label=self.app_label,\n                            name=\"MyModel\",\n                            fields=[\n                                (\"id\", models.AutoField(primary_key=True)),\n                                (\"name\", models.CharField(max_length=255)),\n                            ],\n                            options={},\n                            bases=(models.Model,),\n                            managers=[(\"objects\", models.Manager())],\n                        )\n                    }\n                },\n            ),\n        )\n\n        # Test database_forwards and database_backwards.\n        with CaptureQueriesContext(connection) as captured_queries:\n            operation.database_forwards(self.app_label, self.schema_editor, self.initial_state.clone(), self.get_state())\n            self.assertEqual(len(captured_queries.captured_queries), 1)\n            captured_queries.captured_queries = []\n            operation.database_backwards(self.app_label, self.schema_editor, self.get_state(), self.initial_state.clone())\n            self.assertEqual(len(captured_queries.captured_queries), 1)\n", "    def test_add_constraint(self):\n        \"\"\"\n        Tests that the AddConstraint operation adds the constraint.\n        \"\"\"\n        model_name = 'TestModel'\n        constraint_name = 'test_constraint'\n\n        # Create a migration adding the constraint\n        migration = Migration('test_app', '0001_add_constraint')\n        migration.operations.append(AddConstraint(model_name, models.CheckConstraint(\n            check=models.Q(id__gt=0),\n            name=constraint_name,\n        )))\n\n        # Run the migration forwards\n        with connection.schema_editor(atomic=False) as schema_editor:\n            migration.apply(schema_editor, state_project=ProjectState())\n\n        # Check that the constraint has been added to the state\n        state = ProjectState()\n        state.apps_ready()\n        model_state = state.models['test_app', model_name]\n        self.assertEqual(len(model_state.options['constraints']), 1)\n        self.assertEqual(model_state.options['constraints'][0].name, constraint_name)\n\n        # Run the migration backwards\n        with connection.schema_editor(atomic=False) as schema_editor:\n            migration.reverse(schema_editor, state_project=ProjectState())\n\n        # Check that the constraint has been removed from the state\n        state = ProjectState()\n        state.apps_ready()\n        model_state = state.models['test_app', model_name]\n        self.assertEqual(len(model_state.options['constraints']), 0)\n", "    def test_alter_model_options(self):\n        # Create a model\n        model_name = 'AlterModelOptionsTestsModel'\n        state = ProjectState()\n        self.apply_operations([\n            migrations.CreateModel(\n                name=model_name,\n                fields=[('id', models.AutoField(primary_key=True)),\n                options={'permissions': [('can_eat', 'Can eat'), ('can_drink', 'Can drink')]},\n            ),\n        ], state=state)\n        model_state = state.models[(self.app_label, model_name)]\n\n        # Alter the options\n        self.apply_operations([\n            migrations.AlterModelOptions(\n                name=model_name,\n                options={'permissions': [('can_eat', 'Can eat pizza'), ('can_drink', 'Can drink beer')]},\n            ),\n        ], state=state)\n        model_state = state.models[(self.app_label, model_name)]\n\n        # Assert that the permissions were changed correctly.\n        self.assertEqual(model_state.options['permissions'], [('can_eat', 'Can eat pizza'), ('can_drink', 'Can drink beer')])\n\n        # Reverse the alteration.\n        self.apply_operations([\n            migrations.AlterModelOptions(\n                name=model_name,\n                options={'permissions': [('can_eat', 'Can eat'), ('can_drink', 'Can drink')]},\n            ),\n        ], state=state)\n        model_state = state.models[(self.app_label, model_name)]\n\n        # Assert that the permissions were changed back correctly.\n        self.assertEqual(model_state.options['permissions'], [('can_eat', 'Can eat'), ('can_drink', 'Can drink')])\n", "    def test_alter_model_options_state_forwards(self):\n        # Test state_forwards method.\n        operation = AlterModelOptions('testmodel', {'ordering': ['name'], 'verbose_name': 'Test Model'})\n        self.apply_state(operation)\n        self.assertModelExists('testmodel')\n        self.assertEqual(self.model_states['testmodel'].options['ordering'], ['name'])\n        self.assertEqual(self.model_states['testmodel'].options['verbose_name'], 'Test Model')\n"], "sample_12": ["def test_altered_db_table_with_proxy(self):\n    before_states = [\n        self.author_name,\n        self.author_proxy_notproxy,\n    ]\n    after_states = [\n        self.author_renamed_with_db_table_options,\n        self.author_proxy_proxy,\n    ]\n    changes = self.get_changes(before_states, after_states)\n    self.assertNumberMigrations(changes, \"testapp\", 2)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"RenameModel\"])\n    self.assertOperationAttributes(changes, \"testapp\", 1, 0, name=\"Author\", table=\"author_two\")\n    self.assertOperationTypes(changes, \"testapp\", 1, [\"AlterModelTable\", \"AlterModelOptions\"])\n", "def test_rename_model_with_field_renames(self):\n    # Make some model states\n    author_with_book = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200)),\n        (\"book\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n    ])\n    writer_with_book_renamed = ModelState(\"testapp\", \"Writer\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200)),\n        (\"book_title\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n    ])\n\n    # Test autodetector\n    changes = MigrationAutodetector(\n        self.make_project_state([author_with_book]),\n        self.make_project_state([writer_with_book_renamed]),\n    )._detect_changes()\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"RenameModel\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, old_name=\"Author\", new_name=\"Writer\")\n    self.assertNumberMigrations(changes, \"otherapp\", 0)\n", "def test_autodetector_migration_name_timestamp(self):\n    # Verify the migration name timestamp\n    timestamp = MigrationAutodetector.parse_number(MigrationAutodetector.suggest_name([]))\n    self.assertIsNotNone(timestamp)\n    self.assertGreater(timestamp, 0)\n\n    # Verify that we can still parse migration names with leading zeros\n    self.assertEqual(MigrationAutodetector.parse_number('0001_migration_name'), 1)\n\n    # Verify that we can still parse migration names with custom prefixes\n    self.assertEqual(MigrationAutodetector.parse_number('0010_custom_migration_name'), 10)\n", "def test_generated_added_field_deconstructible_list_with_different_elements(self):\n    \"\"\"Tests generated added fields with a deconstructible list default that contains different elements.\"\"\"\n    before = []\n    after = [self.author_name_deconstructible_list_1]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, ['CreateModel'])\n    self.assertOperationTypes(changes, \"testapp\", 0, ['AddField'])\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 1, default__kwargs__otheritem=123)\n", "    def test_add_field_with_user(self):\n        # Create initial state with a book model and a custom user model\n        before_state = self.make_project_state([\n            self.book,\n            self.custom_user,\n        ])\n\n        # Create final state with an author model with a FK to the custom user\n        after_state = self.make_project_state([\n            self.author_with_custom_user,\n            self.book,\n            self.custom_user,\n        ])\n\n        changes = self.get_changes(before_state, after_state)\n\n        self.assertNumberMigrations(changes, \"testapp\", 1)\n        self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\", \"AddField\"])\n\n        # Make sure the field is created with the correct target model\n        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 1, target_model=\"thirdapp.CustomUser\")\n\n        # Make sure the field is created with the correct related model\n        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 1, related_model=\"thirdapp.CustomUser\")\n"], "sample_6": ["    def test_username_validators(self):\n        ascii_validator = ASCIIUsernameValidator()\n        unicode_validator = UnicodeUsernameValidator()\n\n        # Test valid usernames\n        valid_usernames = ['test', 'test123', 'test@abc', 'test.abc', 'test-abc', 'test_abc']\n        for username in valid_usernames:\n            ascii_validator(username)\n            unicode_validator(username)\n\n        # Test invalid usernames\n        invalid_usernames = ['test\u00a3', 'test\u20ac', 'test\u00a5', 'test@\u00a3', 'test.\u20ac', 'test-\u00a5', 'test_\u00a3']\n        for username in invalid_usernames:\n            with self.assertRaises(ValidationError):\n                ascii_validator(username)\n            unicode_validator(username)  # Should not raise an error\n\n        # Test non-ASCII usernames\n        non_ascii_usernames = ['test\u00a3', 'test\u20ac', 'test\u00a5']\n        for username in non_ascii_usernames:\n            with self.assertRaises(ValidationError):\n                ascii_validator(username)\n            unicode_validator(username)  # Should not raise an error\n", "    def test_username_validator_ascii(self):\n        validator = ASCIIUsernameValidator()\n        valid_usernames = ['user123', 'user@name', 'user.name', 'user-name', 'user_name']\n        invalid_usernames = ['us\u00e9r', 'user$']\n\n        for username in valid_usernames:\n            try:\n                validator(username)\n            except ValidationError:\n                self.fail(f'Valid username {username} raised a ValidationError')\n\n        for username in invalid_usernames:\n            with self.assertRaises(ValidationError):\n                validator(username)\n", "    def test_username_validators(self):\n        ascii_validator = ASCIIUsernameValidator()\n        unicode_validator = UnicodeUsernameValidator()\n\n        valid_usernames = ['test_user', 'test-user', 'test.user', 'test@user', 'test+user']\n        for username in valid_usernames:\n            ascii_validator(username)\n            unicode_validator(username)\n\n        invalid_usernames = ['test!user', 'test\u00a3user', 'test$user']\n        for username in invalid_usernames:\n            with self.assertRaises(ValidationError):\n                ascii_validator(username)\n                unicode_validator(username)\n\n        # Test non-ASCII characters\n        non_ascii_username = 'test\u00fcser'\n        unicode_validator(non_ascii_username)\n        with self.assertRaises(ValidationError):\n            ascii_validator(non_ascii_username)\n", "    def test_username_validators(self):\n        ascii_validator = ASCIIUsernameValidator()\n        unicode_validator = UnicodeUsernameValidator()\n\n        valid_usernames = [\n            'test_user',\n            'test_user123',\n            'test_user@example',\n            'test_user.test@example',\n            'test_user+test@example',\n            'test_user-test',\n        ]\n\n        for username in valid_usernames:\n            ascii_validator(username)\n            unicode_validator(username)\n\n        invalid_usernames = [\n            'test user',  # space is not allowed\n            'test_user\u00a3',  # non-ASCII character\n        ]\n\n        for username in invalid_usernames:\n            with self.assertRaises(ValidationError):\n                ascii_validator(username)\n\n            unicode_validator(username)  # should not raise ValidationError\n", "    def test_ascii_username_validator(self):\n        validator = ASCIIUsernameValidator()\n        self.assertIsNone(validator('john_doe'))\n        self.assertIsNone(validator('john.doe'))\n        self.assertIsNone(validator('john@doe'))\n        self.assertIsNone(validator('john+doe'))\n        self.assertIsNone(validator('john123'))\n\n        with self.assertRaises(ValidationError):\n            validator('john~doe')  # not allowed character\n        with self.assertRaises(ValidationError):\n            validator('j\u00f3hn_doe')  # not an ASCII character\n"], "sample_153": ["def test_pretty_printing():\n    # test pretty printing of pretty printing functions\n    assert pretty(pretty(x)) == \"pretty(x)\"\n    assert upretty(upretty(x)) == \"pretty(x)\"\n\n    # test pretty printing of empty vectors\n    assert pretty(Vector.zero) == \"0\"\n    assert upretty(Vector.zero) == \"0\"\n\n    # test pretty printing of simple vectors\n    assert pretty(v[0]) == \"0\"\n    assert upretty(v[0]) == \"0\"\n    assert pretty(v[1]) == \"i_N\"\n    assert upretty(v[1]) == \"i_N\"\n    assert pretty(v[2]) == \"- i_N\"\n    assert upretty(v[2]) == \"- i_N\"\n    assert pretty(v[3]) == \"i_N + j_N\"\n    assert upretty(v[3]) == \"i_N + j_N\"\n    assert pretty(v[4]) == \"a*i_N\"\n    assert upretty(v[4]) == \"a*i_N\"\n    assert pretty(v[5]) == \"a*i_N - b*j_N\"\n    assert upretty(v[5]) == \"a*i_N - b*j_N\"\n    assert pretty(v[6]) == \"(a**2 + x_N)*i_N + k_N\"\n    assert upretty(v[6]) == \"(a**2 + x_N)*i_N + k_N\"\n    assert pretty(v[7]) == \"(a**2 + b)*i_N + 3*(y_C - c)*k_N\"\n    assert upretty(v[7]) == \"(a**2 + b)*i_N + 3\u22c5(y_C - c)*k_N\"\n    assert pretty(v[8]) == \"j_N + (-Integral(f(b)) + x_C**2)*k_N\"\n    assert upretty(v[8]) == upretty_v_8\n    assert pretty(v[8]) == pretty_v_8\n    assert pretty(v[9]) == \"i_N + k_C\"\n    assert upretty(v[9]) == \"i_N + k_C\"\n    assert pretty(v[10]) == \"i_N\"\n    assert upretty(v[10]) == \"i_N\"\n    assert pretty(v[11]) == \"(a**2 + b)*i_N + Integral(f(b))*k_N\"\n    assert upretty(v[11]) == upretty_v_11\n    assert pretty(v[", "def test_Differential():\n    R = CoordSys3D('R')\n    x, y, z = R.base_scalars()\n    v = Vector(R.i*R.j*R.k)  # type: ignore\n    d = Del()\n    expr = d(v, x, y, z)\n    upretty_expr = \"\"\"\\", "def test_printing_differential():\n    x, y, z = N.base_scalars()\n    dv = Del()\n    upretty_dv = \"\"\"\u2202_x  \u2202_y  \u2202_z\\n\u2202/\u2202x \u2202/\u2202y \u2202/\u2202z\"\"\"\n    pretty_dv = \"\"\"\u2202/\u2202x \u2202/\u2202y \u2202/\u2202z\\n\u2202/\u2202x \u2202/\u2202y \u2202/\u2202z\"\"\"\n    assert upretty(dv) == upretty_dv\n    assert pretty(dv) == pretty_dv\n    dv1 = Del(x, y, z)\n    upretty_dv1 = \"\"\"\u2202\u00b2  \u2202\u00b2  \u2202\u00b2\\n\u2202x \u2202y \u2202z\\n\u2202/\u2202x \u2202/\u2202y \u2202/\u2202z\"\"\"\n    pretty_dv1 = \"\"\"\u2202\u00b2  \u2202\u00b2  \u2202\u00b2\\n\u2202x \u2202y \u2202z\\n\u2202/\u2202x \u2202/\u2202y \u2202/\u2202z\"\"\"\n    assert upretty(dv1) == upretty_dv1\n    assert pretty(dv1) == pretty_dv1\n", "def test_pretty_Curl():\n    curl = Del(C).Curl(v[4]).to_matrix(C)\n    upretty_curl = \"\"\"\\", "def test_pretty_print_tensor():\n    R = CoordSys3D('R')\n    v1 = R.i + R.j + R.k\n    v2 = v1 | R.i\n    v3 = v1 | (R.j + R.k)\n    v4 = R.i | R.j\n    v5 = R.i | (R.j + R.k)\n    v6 = R.i | R.i\n    v7 = v1 | (2*R.j + R.k)\n    v8 = v1 | R.i + v1 | R.j\n    v9 = R.i | (R.j + R.k) + R.j | R.k\n    v10 = 3*R.i | (2*R.j + 4*R.k)\n\n    upretty_v2 = \"\"\"\\"], "sample_140": ["def test_partial_velocity():\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    p = Point('p')\n    u1, u2 = dynamicsymbols('u1 u2')\n    p.set_vel(N, u1 * N.x + u2 * A.y)\n    assert p.partial_velocity(N, u1) == N.x\n    assert p.partial_velocity(N, u1, u2) == (N.x, A.y)\n    with raises(ValueError):\n        p.partial_velocity(A, u1)\n    with raises(ValueError):\n        p.partial_velocity(N, u1**2)\n", "def test_partial_velocity():\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    p = Point('p')\n    u1, u2 = dynamicsymbols('u1, u2')\n    p.set_vel(N, u1 * N.x + u2 * A.y)\n    assert p.partial_velocity(N, u1) == N.x\n    assert p.partial_velocity(N, u1, u2) == (N.x, A.y)\n\n    # Test for 0 generalized speeds\n    assert p.partial_velocity(N) == ()\n\n    # Test for non-existent generalized speed\n    q = dynamicsymbols('q')\n    with raises(ValueError):\n        p.partial_velocity(N, q)\n", "def test_point_partial_velocity():\n    q = dynamicsymbols('q')\n    qd = dynamicsymbols('q', 1)\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    p = Point('p')\n    p.set_vel(N, qd * N.x + q * A.y)\n    partial_velocity = p.partial_velocity(N, qd)\n    assert partial_velocity == N.x\n\n    partial_velocities = p.partial_velocity(N, qd, q)\n    assert partial_velocities == (N.x, A.y)\n\n    p.set_vel(N, qd * N.x)\n    raises(ValueError, lambda: p.partial_velocity(N, q))\n\n    p.set_vel(N, qd * N.x + q * A.y)\n    p2 = Point('p2')\n    p2.set_pos(p, q * N.x)\n    p2.partial_velocity(N, qd)\n", "def test_partial_velocity():\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    p = Point('p')\n    u1, u2 = dynamicsymbols('u1, u2')\n    p.set_vel(N, u1 * N.x + u2 * A.y)\n    assert p.partial_velocity(N, u1) == N.x\n    assert p.partial_velocity(N, u1, u2) == (N.x, A.y)\n    \n    raises(ValueError, lambda: p.partial_velocity(N, u1, 3))  # test for TypeError on invalid input\n", "def test_pdict_list():\n    N = ReferenceFrame('N')\n    P1 = Point('P1')\n    P2 = Point('P2')\n    P3 = Point('P3')\n    P1.set_pos(P2, 10 * N.x)\n    P2.set_pos(P3, 10 * N.y)\n    assert P1._pdict_list(P3, 0) == [P1, P2, P3]\n    with raises(ValueError):\n        P1._pdict_list(P3, 1)\n"], "sample_19": ["    def test_get_traceback_data(self):\n        # Create a request\n        request = RequestFactory().get('/')\n\n        # Create an exception\n        try:\n            raise Exception('Test exception')\n        except Exception:\n            exc_type, exc_value, tb = sys.exc_info()\n\n        # Create an exception reporter\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n\n        # Test get_traceback_data method\n        data = reporter.get_traceback_data()\n\n        # Check if the data contains the expected keys\n        self.assertIn('is_email', data)\n        self.assertIn('frames', data)\n        self.assertIn('request', data)\n        self.assertIn('request_meta', data)\n        self.assertIn('user_str', data)\n        self.assertIn('filtered_POST_items', data)\n        self.assertIn('settings', data)\n        self.assertIn('sys_executable', data)\n        self.assertIn('sys_version_info', data)\n        self.assertIn('server_time', data)\n        self.assertIn('django_version_info', data)\n        self.assertIn('sys_path', data)\n        self.assertIn('template_info', data)\n        self.assertIn('template_does_not_exist', data)\n        self.assertIn('postmortem', data)\n        self.assertIn('exception_type', data)\n        self.assertIn('exception_value', data)\n        self.assertIn('lastframe', data)\n", "    def test_get_safe_settings(self):\n        filter = SafeExceptionReporterFilter()\n        settings_dict = filter.get_safe_settings()\n        self.assertIn('SECRET_KEY', settings_dict)\n        self.assertEqual(settings_dict['SECRET_KEY'], SafeExceptionReporterFilter.cleansed_substitute)\n", "    def test_get_safe_settings(self):\n        with override_settings(SECRET_KEY='secret_key', API_KEY='api_key'):\n            filter = SafeExceptionReporterFilter()\n            settings = filter.get_safe_settings()\n            self.assertEqual(settings['SECRET_KEY'], '********************')\n            self.assertEqual(settings['API_KEY'], '********************')\n            self.assertEqual(settings['TEST'], 'test')\n", "    def test_get_traceback_data(self):\n        request = RequestFactory().get('/')\n        exc_type = Http404\n        exc_value = Http404('Test 404 error')\n        tb = inspect.stack()[0][0]\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIn('request', data)\n        self.assertIn('request_meta', data)\n        self.assertIn('user_str', data)\n        self.assertIn('filtered_POST_items', data)\n        self.assertIn('settings', data)\n        self.assertIn('exception_type', data)\n        self.assertIn('exception_value', data)\n        self.assertIn('frames', data)\n        self.assertEqual(len(data['frames']), 1)\n        frame = data['frames'][0]\n        self.assertIn('filename', frame)\n        self.assertIn('function', frame)\n        self.assertIn('lineno', frame)\n        self.assertIn('vars', frame)\n", "    def test_get_traceback_frame_variables(self):\n        request = RequestFactory().get('/')\n        request.user = User()\n\n                return x / y\n            return inner\n\n        try:\n            outer()(1, 0)\n        except ZeroDivisionError:\n            tb = sys.exc_info()[2]\n\n        reporter = ExceptionReporter(request, *sys.exc_info())\n        frame_vars = reporter.filter.get_traceback_frame_variables(request, tb.tb_frame.f_back)\n        self.assertEqual(frame_vars[0], ('x', 1))\n        self.assertEqual(frame_vars[1], ('y', 0))\n\n        # Make sure a lazy MultiValueDict doesn't cause a TypeError (#21098)\n            return MultiValueDict({'foo': ['bar']})\n        lazy_mvd = SimpleLazyObject(lazy_mvd_getter)\n        with mock.patch.dict(tb.tb_frame.f_locals, {'lazy_mvd': lazy_mvd}):\n            frame_vars = reporter.filter.get_traceback_frame_variables(request, tb.tb_frame.f_back)\n            self.assertEqual(frame_vars[0], ('lazy_mvd', 'bar'))\n"], "sample_119": ["def test_mcodeprinter():\n    assert mcode(pi) == 'Pi'\n    assert mcode(oo) == 'Infinity'\n    assert mcode(-oo) == '-Infinity'\n    assert mcode(exp(x)) == 'Exp[x]'\n    assert mcode(sin(x)) == 'Sin[x]'\n    assert mcode(cos(x)) == 'Cos[x]'\n    assert mcode(x**2) == 'x^2'\n    assert mcode(x + y + z) == 'x + y + z'\n    assert mcode(x*y*z) == 'x*y*z'\n    assert mcode(Integral(x**2, x)) == 'Hold[Integrate[x^2, x]]'\n    assert mcode(Sum(x**2, (x, 0, 10))) == 'Hold[Sum[x^2, {x, 0, 10}]]'\n    assert mcode(Derivative(x**2, x)) == 'Hold[D[x^2, x]]'\n    assert mcode(Tuple(x, y, z)) == '{x, y, z}'\n    assert mcode(Rational(1, 2)) == '1/2'\n    assert mcode(Integer(1)) == '1'\n    assert mcode(f(x)) == 'f[x]'  # assuming f is a custom function\n    assert mcode(f(x, y)) == 'f[x, y]'  # assuming f is a custom function\n", "def test_mcode_printer():\n    assert mcode(x**2) == 'x^2'\n    assert mcode(x**-2) == 'x^(-2)'\n    assert mcode(x**(1/2)) == 'x^(1/2)'\n    assert mcode(x**(S(1)/2)) == 'x^(1/2)'\n    assert mcode(x**(Rational(1, 2))) == 'x^(1/2)'\n    assert mcode(x**(Integer(1)/2)) == 'x^(1/2)'\n    assert mcode(2*x**2) == '2*x^2'\n    assert mcode(2*x**-2) == '2*x^(-2)'\n    assert mcode(2*x**(1/2)) == '2*x^(1/2)'\n    assert mcode(2*x**(S(1)/2)) == '2*x^(1/2)'\n    assert mcode(2*x**(Rational(1, 2))) == '2*x^(1/2)'\n    assert mcode(2*x**(Integer(1)/2)) == '2*x^(1/2)'\n    assert mcode(exp(x)) == 'Exp[x]'\n    assert mcode(sin(x)) == 'Sin[x]'\n    assert mcode(cos(x)) == 'Cos[x]'\n    assert mcode(pi) == 'Pi'\n    assert mcode(oo) == 'Infinity'\n    assert mcode(-oo) == '-Infinity'\n    assert mcode(Integral(x, (x, 0, 1))) == \"Hold[Integrate[x, {x, 0, 1}]]\"\n    assert mcode(Sum(x, (x, 0, 10))) == \"Hold[Sum[x, {x, 0, 10}]]\"\n    assert mcode(Derivative(x**2, x)) == \"Hold[D[x^2, x]]\"\n    assert mcode((x, y, z)) == '{x, y, z}'\n    assert mcode(Tuple(x, y, z)) == '{x, y, z}'\n    assert mcode(f(x, y, z)) == 'f[x, y, z]'\n", "def test_mcodeprinter():\n    assert mcode(x**2) == 'x^2'\n    assert mcode(x**2 + 3) == 'x^2 + 3'\n    assert mcode(S(3)/2) == '3/2'\n    assert mcode(S(3)/2*x) == '(3/2)*x'\n    assert mcode(oo) == 'Infinity'\n    assert mcode(-oo) == '-Infinity'\n    assert mcode(pi) == 'Pi'\n    assert mcode(sin(x)) == 'Sin[x]'\n    assert mcode(cos(x)) == 'Cos[x]'\n    assert mcode(exp(x)) == 'Exp[x]'\n    assert mcode(Derivative(f(x), x)) == 'Hold[D[f[x], x]]'\n    assert mcode(Integral(sin(x), x)) == 'Hold[Integrate[Sin[x], x]]'\n    assert mcode(Sum(x**2, (x, 0, 3))) == 'Hold[Sum[x^2, {x, 0, 3}]]'\n    assert mcode((1, 2, 3)) == '{1, 2, 3}'\n    assert mcode((x, y, z)) == '{x, y, z}'\n", "def test_mathematica_code():\n    # Test function\n    assert mcode(sin(x)) == \"Sin[x]\"\n    assert mcode(cos(x)) == \"Cos[x]\"\n    assert mcode(exp(x)) == \"Exp[x]\"\n\n    # Test power\n    assert mcode(x**2) == \"x^2\"\n    assert mcode(x**-2) == \"x^(-2)\"\n\n    # Test mul\n    assert mcode(x*y) == \"x*y\"\n    assert mcode(x*y*z) == \"x*y*z\"\n\n    # Test infinity\n    assert mcode(oo) == \"Infinity\"\n    assert mcode(-oo) == \"-Infinity\"\n\n    # Test pi\n    assert mcode(pi) == \"Pi\"\n\n    # Test integral\n    assert mcode(Integral(sin(x), x)) == \"Hold[Integrate[Sin[x], x]]\"\n\n    # Test derivative\n    assert mcode(Derivative(sin(x), x)) == \"Hold[D[Sin[x], x]]\"\n\n    # Test sum\n    assert mcode(Sum(x**2, (x, 0, 3))) == \"Hold[Sum[x^2, {x, 0, 3}]]\"\n\n    # Test tuple and list\n    assert mcode((x, y, z)) == \"{x, y, z}\"\n    assert mcode([x, y, z]) == \"{x, y, z}\"\n\n    # Test Rational\n    assert mcode(Rational(1, 2)) == \"1/2\"\n\n    # Test custom function\n    assert mcode(f(x)) == \"f[x]\"\n", "def test_mcode_printer():\n    assert mcode(x**2 + 3*x - 4) == 'x^2 + 3*x - 4'\n    assert mcode(x**2 + 3*x - 4, user_functions={'x**2': 'x_squared'}) == 'x_squared + 3*x - 4'\n    assert mcode(sin(x)) == 'Sin[x]'\n    assert mcode(cos(x)) == 'Cos[x]'\n    assert mcode(exp(x)) == 'Exp[x]'\n    assert mcode(oo) == 'Infinity'\n    assert mcode(-oo) == '-Infinity'\n    assert mcode(pi) == 'Pi'\n    assert mcode(x*y) == 'x*y'\n    assert mcode((x, y)) == '{x, y}'\n    assert mcode([x, y]) == '{x, y}'\n    assert mcode(Tuple(x, y)) == '{x, y}'\n    assert mcode(f(x, y, z)) == 'f[x, y, z]'\n    assert mcode(Derivative(f(x, y, z), x)) == 'Hold[D[f[x, y, z], x]]'\n    assert mcode(Integral(f(x), x)) == 'Hold[Integrate[f[x], x]]'\n    assert mcode(Sum(f(x), (x, 1, 10))) == 'Hold[Sum[f[x], {x, 1, 10}]]'\n    assert mcode(Rational(1, 2)) == '1/2'\n    assert mcode(Integer(10)) == '10'\n"], "sample_133": ["def test_codegen_argument_sequence():\n    x, y, z = symbols('x y z')\n    routine = make_routine('test', [x*y, Eq(z, x + y)], (y, x, z))\n    assert [arg.name for arg in routine.arguments] == [y, x]\n    assert [arg.name for arg in routine.result_variables] == [z]\n\n    raises(CodeGenArgumentListError, lambda: make_routine('test', [x*y, Eq(z, x + y)], (y, x)))\n\n    raises(CodeGenArgumentListError, lambda: make_routine('test', [x*y, Eq(z, x + y)], (y, z)))\n", "def test_rust_codegen():\n    x, y = symbols('x y')\n    cg = RustCodeGen()\n    r = cg.routine(\"test\", x*y, (x, y))\n    assert get_string(cg.dump_rs, [r], \"test\", header=False, empty=False) == (\n        \"fn test(x: f64, y: f64) {\\n\"\n        \"    let result_0;\\n\"\n        \"    result_0 = x*y;\\n\"\n        \"    (result_0, )\\n\"\n        \"}\\n\"\n    )\n", "def test_routine():\n    x, y = symbols('x y')\n    r1 = make_routine('f', Eq(x + y, x + y))\n    assert len(r1.results) == 0\n    assert len(r1.arguments) == 2\n\n    r2 = make_routine('f', [x + y, Eq(x + y, x + y)])\n    assert len(r2.results) == 1\n    assert len(r2.arguments) == 2\n\n    r3 = make_routine('f', (x + y, Eq(x + y, x + y)))\n    assert len(r3.results) == 1\n    assert len(r3.arguments) == 2\n\n    r4 = make_routine('f', (Eq(x + y, x + y), Eq(x + y, x + y)))\n    assert len(r4.results) == 0\n    assert len(r4.arguments) == 2\n\n    r5 = make_routine('f', [Eq(x + y, x + y), Eq(x + y, x + y)])\n    assert len(r5.results) == 0\n    assert len(r5.arguments) == 2\n\n    r6 = make_routine('f', Eq(x + y, x + y))\n    assert len(r6.results) == 0\n    assert len(r6.arguments) == 2\n\n    r7 = make_routine('f', x + y)\n    assert len(r7.results) == 1\n    assert len(r7.arguments) == 2\n", "def test_Routine():\n    from sympy import symbols\n    from sympy.utilities.codegen import Routine, InputArgument, Result, OutputArgument\n\n    x, y = symbols('x y')\n\n    # Test input arguments\n    routine = Routine('test', [InputArgument(x), InputArgument(y)], [], [], [])\n    assert routine.arguments == [InputArgument(x), InputArgument(y)]\n\n    # Test results\n    routine = Routine('test', [InputArgument(x)], [Result(x + y)], [], [])\n    assert routine.results == [Result(x + y)]\n\n    # Test output arguments\n    routine = Routine('test', [InputArgument(x)], [OutputArgument(y, y, x + y)], [], [])\n    assert routine.results == [OutputArgument(y, y, x + y)]\n\n    # Test invalid argument type\n    raises(ValueError, lambda: Routine('test', [object()], [], [], []))\n", "def test_routine_cse():\n    # Check that the routine() method correctly handles common subexpressions\n    # and the cse flag.\n    from sympy import symbols, sin, cos, sin, cos\n    x, y = symbols('x y')\n\n    # Create the expressions.\n    expr1 = sin(x) + sin(x)*sin(y)\n    expr2 = sin(x) + sin(x)*cos(y)\n\n    # Create a routine with cse=False.\n    r1 = CCodeGen().routine('test', (expr1, expr2), cse=False)\n\n    # Create a routine with cse=True.\n    r2 = CCodeGen().routine('test', (expr1, expr2), cse=True)\n\n    # Check that they produce different code.\n    assert get_string(CCodeGen().dump_c, [r1], 'test1') != \\\n        get_string(CCodeGen().dump_c, [r2], 'test2')\n"], "sample_148": ["def test_periodic_argument():\n    from sympy import exp_polar, I, pi, periodic_argument\n    assert periodic_argument(exp_polar(10*I*pi), 2*pi) == 0\n    assert periodic_argument(exp_polar(5*I*pi), 4*pi) == pi\n    assert periodic_argument(exp_polar(5*I*pi), 2*pi) == pi\n    assert periodic_argument(exp_polar(5*I*pi), 3*pi) == -pi\n    assert periodic_argument(exp_polar(5*I*pi), pi) == 0\n    assert periodic_argument(exp_polar(5*I*pi), oo) == 5*pi\n", "def test_polar_lift():\n    x = Symbol('x', real=True)\n    y = Symbol('y')\n    p = Symbol('p', polar=True)\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*p) == 4*p\n    assert polar_lift(y) == polar_lift(y)  # issue 7273\n    assert polar_lift(2 + I) == polar_lift(2 + I)\n    assert polar_lift(y*I + 2) == 2*polar_lift(I*y + 1)\n    assert polar_lift(-y*I + 2) == 2*polar_lift(-I*y + 1)\n", "def test_polarify():\n    x, y = symbols('x y')\n    assert polarify(x + y) == (x + y, {})\n    assert polarify(2*x + I) == (2*x + I, {})\n    assert polarify(x + 2*I) == (x + 2*I, {})\n    assert polarify((1 + I)**x) == ((1 + I)**_x, {_x: x})\n", "def test_principal_branch():\n    x = Symbol('x')\n    z = Symbol('z')\n    assert principal_branch(oo, pi) == oo\n    assert principal_branch(zoo, pi) == zoo\n    assert principal_branch(-zoo, pi) == -zoo\n    assert principal_branch(zoo*I, pi) == zoo*I\n    assert principal_branch(-zoo*I, pi) == -zoo*I\n    assert principal_branch(1 + I, pi) == 1 + I\n    assert principal_branch(z, pi) == z\n    assert principal_branch(x, pi) == x\n    assert principal_branch(exp_polar(5*I*pi), pi) == exp_polar(0)\n    assert principal_branch(exp_polar(5*I*pi)*z, pi) == z\n    assert principal_branch(exp_polar(3*I*pi/2), 2*pi) == -I\n    assert principal_branch(exp_polar(7*I*pi/2), 4*pi) == I\n    assert principal_branch(exp_polar(13*I*pi/2), 4*pi) == -I\n", "def test_principal_branch():\n    z = Symbol('z')\n    x = Symbol('x')\n    p = Symbol('p', positive=True)\n    assert principal_branch(z, oo) == z\n    assert principal_branch(exp_polar(2*pi*I)*3, 2*pi) == 3*exp_polar(0)\n    assert principal_branch(exp_polar(2*pi*I)*3*z, 2*pi) == 3*principal_branch(z, 2*pi)\n"], "sample_23": ["    def test_union_without_support_for_union(self):\n        with self.assertRaises(NotSupportedError):\n            Number.objects.union(Number.objects.all())\n", "def test_get_with_select_for_update(self):\n    with self.assertNumQueries(1):\n        with transaction.atomic():\n            obj = Number.objects.select_for_update().get(num=0)\n            self.assertEqual(obj.num, 0)\n", "def test_union_fields_mismatch(self):\n    # Test that union does not work when fields do not match.\n    qs1 = Number.objects.values('num').filter(num=1)\n    qs2 = Number.objects.values('other_num').filter(other_num=2)\n    with self.assertRaisesMessage(TypeError, \"Merging 'QuerySet' classes must involve the same values in each case.\"):\n        qs1.union(qs2)\n", "def test_intersection(self):\n    \"\"\"\n    Regression test for #28874.\n\n    Ensure that the intersection of two QuerySets with different model instances\n    (but same model) works correctly.\n    \"\"\"\n    numbers = Number.objects.all()\n    numbers_copy = Number.objects.all()\n\n    self.assertEqual(numbers & numbers_copy, numbers)\n\n    # Ensure that the intersection of an empty QuerySet with another QuerySet\n    # works correctly.\n    empty = Number.objects.none()\n    self.assertEqual(numbers & empty, empty)\n    self.assertEqual(empty & numbers, empty)\n", "def test_union_query_sets(self):\n    qs1 = Number.objects.filter(num__gt=5)\n    qs2 = Number.objects.filter(other_num__gt=5)\n    qs = qs1.union(qs2)\n    self.assertEqual(qs.count(), 10)\n\n    qs = qs1.union(qs2, all=True)\n    self.assertEqual(qs.count(), 10)\n\n    qs1 = Number.objects.filter(num__gt=5).annotate(flag=Value('qs1'))\n    qs2 = Number.objects.filter(other_num__gt=5).annotate(flag=Value('qs2'))\n    qs = qs1.union(qs2, all=True)\n    self.assertEqual(qs.count(), 10)\n\n    # Test that a union of empty querysets returns an empty queryset\n    qs1 = Number.objects.none()\n    qs2 = Number.objects.none()\n    qs = qs1.union(qs2)\n    self.assertEqual(qs.count(), 0)\n\n    qs = qs1.union(qs2, all=True)\n    self.assertEqual(qs.count(), 0)\n\n    # Test that union() doesn't work with non-model querysets\n    with self.assertRaisesMessage(ValueError, 'Merging \\'QuerySet\\' classes must involve the same values in each case.'):\n        qs1.union(ReservedName.objects.all())\n\n    # Test that union() doesn't work with querysets with different annotations\n    with self.assertRaisesMessage(ValueError, 'Merging \\'QuerySet\\' classes must involve the same values in each case.'):\n        qs1.union(Number.objects.annotate(other=Value(1)))\n\n    # Test that union() doesn't work with querysets with different extra select\n    with self.assertRaisesMessage(ValueError, 'Merging \\'QuerySet\\' classes must involve the same values in each case.'):\n        qs1.union(Number.objects.extra(select={'other': '1'}))\n"], "sample_146": ["def test_strprinter():\n    printer = StrPrinter()\n    assert printer._print_Catalan(Catalan) == 'Catalan'\n    assert printer._print_EulerGamma(EulerGamma) == 'EulerGamma'\n    assert printer._print_GoldenRatio(GoldenRatio) == 'GoldenRatio'\n    assert printer._print_TribonacciConstant(TribonacciConstant) == 'TribonacciConstant'\n    assert printer._print_ImaginaryUnit(I) == 'I'\n    assert printer._print_Infinity(oo) == 'oo'\n    assert printer._print_ComplexInfinity(zoo) == 'zoo'\n    assert printer._print_NegativeInfinity(-oo) == '-oo'\n    assert printer._print_NaN(nan) == 'nan'\n    assert printer._print_Order(O(x)) == 'O(x)'\n    assert printer._print_Pi(pi) == 'pi'\n    assert printer._print_UniversalSet(S.UniversalSet) == 'UniversalSet'\n    assert printer._print_EmptySet(S.EmptySet) == 'EmptySet'\n    assert printer._print_EmptySequence(S.EmptySequence) == 'EmptySequence'\n    assert printer._print_Complexes(S.Complexes) == 'Complexes'\n    assert printer._print_Reals(S.Reals) == 'Reals'\n    assert printer._print_Rationals(S.Rationals) == 'Rationals'\n    assert printer._print_Naturals(S.Naturals) == 'Naturals'\n    assert printer._print_Naturals0(S.Naturals0) == 'Naturals0'\n    assert printer._print_Integers(S.Integers) == 'Integers'\n    assert printer._print_Zero(S.Zero) == '0'\n    assert printer._print_One(S.One) == '1'\n    assert printer._print_Integer(Integer(5)) == '5'\n    assert printer._print_Rational(Rational(5, 2)) == '5/2'\n    assert printer._print_Float(Float(0.5)) == '0.5'\n    assert printer._print_Symbol(Symbol('x')) == 'x'\n    assert printer._print_Wild(Wild('x')) == 'x_'\n    assert printer._print_WildFunction(WildFunction('x')) == 'x_'\n    assert printer._print_WildDot(Wild('x', 'dot')) == 'x'\n    assert printer._print_WildStar", "def test_StrPrinter():\n    printer = StrPrinter()\n\n    assert printer._print_UniversalSet(S.UniversalSet) == \"UniversalSet\"\n    assert printer._print_EmptySet(S.EmptySet) == \"EmptySet\"\n\n    assert printer._print_AlgebraicNumber(S.Catalan) == \"Catalan\"\n    assert printer._print_AlgebraicNumber(S.EulerGamma) == \"EulerGamma\"\n    assert printer._print_AlgebraicNumber(S.GoldenRatio) == \"GoldenRatio\"\n    assert printer._print_AlgebraicNumber(S.TribonacciConstant) == \"TribonacciConstant\"\n\n    assert printer._print_Str(\"test\") == \"test\"\n    assert printer._print_StrReprPrinter(\"test\") == \"'test'\"\n\n    assert printer._print_Predicate(Q.is_even) == \"Q.is_even\"\n    assert printer._print_Predicate(Q.is_odd) == \"Q.is_odd\"\n\n    assert printer._print_Integers(S.Integers) == \"Integers\"\n    assert printer._print_Naturals(S.Naturals) == \"Naturals\"\n    assert printer._print_Naturals0(S.Naturals0) == \"Naturals0\"\n    assert printer._print_Rationals(S.Rationals) == \"Rationals\"\n    assert printer._print_Reals(S.Reals) == \"Reals\"\n    assert printer._print_Complexes(S.Complexes) == \"Complexes\"\n    assert printer._print_EmptySequence(S.EmptySequence) == \"EmptySequence\"\n\n    assert printer._print_MatPow(Matrix([[1, 2], [3, 4]])**2) == \"Matrix([[1, 2], [3, 4]])**2\"\n    assert printer._print_MatPow(Matrix([[1, 2], [3, 4]])**-1) == \"Matrix([[1, 2], [3, 4]])**(-1)\"\n\n    assert printer._print_TensorIndex('i') == 'i'\n    assert printer._print_TensorHead('A', 'i') == 'A'\n    assert printer._print_Tensor('A', ('i', 'j')) == 'A'\n\n    assert printer._print_PolyRing(ring.PolyRing(x, ZZ)) == \"Polynomial ring in x over ZZ with lex order\"\n    assert printer._print_FracField(field.FracField(x, ZZ)) == \"Rational function", "def test_StrPrinter():\n    printer = StrPrinter()\n\n    assert printer._print_Add(Add(x, y, evaluate=False)) == \"+ x + y\"\n    assert printer._print_Pow(Pow(x, y)) == \"x**y\"\n    assert printer._print_Pow(Pow(x, 2)) == \"x**2\"\n    assert printer._print_Pow(Pow(x, 0)) == \"1\"\n    assert printer._print_Pow(Pow(x, 1)) == \"x\"\n    assert printer._print_Pow(Pow(x, -1)) == \"1/x\"\n    assert printer._print_Pow(Pow(x, S.Half)) == \"sqrt(x)\"\n    assert printer._print_Pow(Pow(x, -S.Half)) == \"1/sqrt(x)\"\n    assert printer._print_Pow(Pow(x, -2)) == \"1/x**2\"\n    assert printer._print_Mul(Mul(x, y)) == \"x*y\"\n    assert printer._print_Mul(Mul(x, 2)) == \"2*x\"\n    assert printer._print_Mul(Mul(2, x)) == \"2*x\"\n    assert printer._print_Mul(Mul(x, S.Half)) == \"x/2\"\n    assert printer._print_Mul(Mul(S.Half, x)) == \"x/2\"\n    assert printer._print_Mul(Mul(x, y, 2)) == \"2*x*y\"\n    assert printer._print_Mul(Mul(x, y, z)) == \"x*y*z\"\n    assert printer._print_Mul(Mul(x, y, 2, 3)) == \"6*x*y\"\n    assert printer._print_Mul(Mul(2, x, y, z)) == \"2*x*y*z\"\n    assert printer._print_Mul(Mul(3, 2, x, y, z)) == \"6*x*y*z\"\n    assert printer._print_Mul(Mul(-x, y, 2, 3)) == \"-6*x*y\"\n    assert printer._print_Mul(Mul(-2, x, y, z)) == \"-2*x*y*z\"\n    assert printer._print_Mul(Mul(-3, -2, x, y, z)) == \"6*x*y*z\"\n\n    assert printer._print_Limit(Limit(x, x, 0, '+')) == \"Limit", "def test_str_printer():\n    p = StrPrinter()\n    assert p._print_Str(\"hello\") == \"hello\"\n    assert p._print_Str(\"hello\") != repr(\"hello\")\n\n    p = StrReprPrinter()\n    assert p._print_Str(\"hello\") == repr(\"hello\")\n\n    # test _print_relational\n    assert sstr(Eq(x, y)) == \"Eq(x, y)\"\n    assert sstr(Ne(x, y)) == \"Ne(x, y)\"\n\n    # test _print_dict\n    assert sstr({x: y, z: w}) == \"{x: y, z: w}\"\n\n    # test _print_frozenset\n    assert sstr(frozenset([x, y, z])) == \"frozenset({x, y, z})\"\n\n    # test _print_RootSum\n    eq = Poly(x**2 - y, x)\n    assert sstr(RootSum(eq, Lambda(x, x**2))) == \"RootSum(x**2 - y, Lambda(x, x**2))\"\n\n    # test _print_GroebnerBasis\n    F = [Poly(x**2 + y, x, y, order=grlex), Poly(x*y + y, x, y, order=grlex)]\n    G = groebner(F, x, y, order=grlex)\n    assert sstr(G) == \"GroebnerBasis([x**2 + y, x*y + y], x, y, domain='ZZ', order='grlex')\"\n\n    # test _print_Cycle\n    assert sstr(Cycle(1, 2, 3)) == \"(1 2 3)\"\n\n    # test _print_Permutation\n    p = [0, 3, 1, 2]\n    assert sstr(Permutation(p)) == \"Permutation([0, 3, 1, 2])\"\n    assert sstr(Permutation(p), perm_cyclic=False) == \"Permutation([0, 3, 1, 2])\"\n    assert sstr(Permutation(p), perm_cyclic=True) == \"(0)(1 3 2)\"\n\n    # test _print_PolyElement\n    P = Poly(x**2 + y, x, y)\n    assert sstr(P) == \"Poly(x**2 + y, x, y, domain='", "def test_StrPrinter_coverage():\n    p = StrPrinter()\n\n    # test for _print_Cycle\n    expr = Point((1, 2))\n    assert p._print_Point(expr) is None  # should be None, Point is not handled\n\n    # test for _print_Inverse\n    expr = TransferFunction(1, 2)\n    assert p._print_TransferFunction(expr) is None  # should be None, TransferFunction is not handled\n\n    # test for _print_Basic\n    class CustomExpr(Expr):\n            return Basic.__new__(cls, 1, 2)\n    expr = CustomExpr()\n    assert p._print_CustomExpr(expr) == \"CustomExpr(1, 2)\"\n\n    # test for _print_Predicates\n    expr = Q.is_even(x)\n    assert p._print_Predicate(expr) == \"Q.even\"\n\n    # test for _print_Quantity\n    expr = second\n    assert p._print_Quantity(expr) == \"second\"\n\n    # test for _print_WildFunction\n    expr = WildFunction('f')\n    assert p._print_WildFunction(expr) == \"f_\"\n\n    # test for _print_GaussianElement\n    expr = Poly(x**2 + 2*x + 1, x, ZZ_I)\n    assert p._print_GaussianElement(expr) is None  # should be None, Poly is not handled\n\n    # test for _print_EmptySet and _print_EmptySequence\n    expr = set()\n    assert p._print_EmptySet(set()) == \"set()\"\n    expr = []\n    assert p._print_EmptySequence([]) == \"[]\"\n\n    # test for _print_TensorIndex, _print_TensorHead, _print_Tensor\n    from sympy.tensor.indexed import IndexedBase\n    expr = IndexedBase('A')\n    assert p._print_IndexedBase(expr) is None  # should be None, IndexedBase is not handled\n\n    # test for _print_FreeGroupElement\n    from sympy.combinatorics.free_groups import free_group\n    F, a, b = free_group('ab')\n    expr = a*b\n    assert p._print_FreeGroupElement(expr) == \"a*b\"\n\n    # test for _print_NDimArray\n    expr = NDimArray([1, 2, 3])\n    assert p._print_N"], "sample_17": ["def test_test_db_signature(self):\n    test_connection = get_connection_copy()\n    base_creation = BaseDatabaseCreation(test_connection)\n    test_db_signature = base_creation.test_db_signature()\n\n    self.assertIsInstance(test_db_signature, tuple)\n    self.assertEqual(len(test_db_signature), 4)\n    self.assertEqual(test_db_signature[0], test_connection.settings_dict['HOST'])\n    self.assertEqual(test_db_signature[1], test_connection.settings_dict['PORT'])\n    self.assertEqual(test_db_signature[2], test_connection.settings_dict['ENGINE'])\n    self.assertEqual(test_db_signature[3], TEST_DATABASE_PREFIX + test_connection.settings_dict['NAME'])\n", "def test_clone_test_db(self):\n    creation = BaseDatabaseCreation(get_connection_copy())\n    with mock.patch.object(creation, '_clone_test_db') as mock_clone:\n        creation.clone_test_db(suffix='clone1', verbosity=1, autoclobber=False, keepdb=False)\n        mock_clone.assert_called_once_with('clone1', 1, False)\n\n    with mock.patch.object(creation, '_clone_test_db') as mock_clone:\n        creation.clone_test_db(suffix='clone2', verbosity=0, autoclobber=True, keepdb=True)\n        mock_clone.assert_called_once_with('clone2', 0, True)\n", "    def test_test_db_signature(self):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['HOST'] = 'test_host'\n        test_connection.settings_dict['PORT'] = 1234\n        test_connection.settings_dict['ENGINE'] = 'django.db.backends.sqlite3'\n        test_connection.settings_dict['NAME'] = 'test_db_name'\n        test_connection.settings_dict['TEST'] = {'NAME': 'test_test_db_name'}\n\n        base_creation = BaseDatabaseCreation(test_connection)\n        expected_signature = ('test_host', 1234, 'django.db.backends.sqlite3', 'test_test_db_name')\n        self.assertEqual(base_creation.test_db_signature(), expected_signature)\n\n        test_connection.settings_dict['TEST'] = {'NAME': ''}\n        expected_signature = ('test_host', 1234, 'django.db.backends.sqlite3', TEST_DATABASE_PREFIX + 'test_db_name')\n        self.assertEqual(base_creation.test_db_signature(), expected_signature)\n\n        test_connection.settings_dict['NAME'] = None\n        with self.assertRaises(KeyError):\n            base_creation.test_db_signature()\n", "    def test_create_test_db_verbosity_1(self, mock_stderr):\n        test_connection = get_connection_copy()\n        creation = BaseDatabaseCreation(test_connection)\n        creation.create_test_db(verbosity=1)\n        self.assertIn('Creating test database for alias', mock_stderr.write.call_args[0][0])\n", "    def test_get_test_db_name(self):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['NAME'] = 'custom_test_db'\n        creation = BaseDatabaseCreation(test_connection)\n        self.assertEqual(creation._get_test_db_name(), 'custom_test_db')\n\n        test_connection.settings_dict['TEST']['NAME'] = ''\n        creation = BaseDatabaseCreation(test_connection)\n        self.assertEqual(creation._get_test_db_name(), TEST_DATABASE_PREFIX + test_connection.settings_dict['NAME'])\n"], "sample_99": ["def test_supervised_mixin_fit_integer():\n    # Test that SupervisedIntegerMixin correctly handles integer targets\n    X = iris.data\n    y = iris.target\n    neigh = neighbors.NeighborsBase(n_neighbors=5)\n    neigh.fit(X, y)\n\n    # Check that classes_ is correctly set\n    assert_array_equal(neigh.classes_, np.unique(y))\n\n    # Check that _y is correctly set\n    assert_array_equal(neigh._y, y)\n\n    # Test with 2D integer targets\n    y_2d = np.column_stack((y, y))\n    neigh.fit(X, y_2d)\n    assert_array_equal(neigh.classes_, [np.unique(y) for _ in range(2)])\n    assert_array_equal(neigh._y, y_2d)\n", "def test_neighbor_weights():\n    # test neighbor weights function with callable\n    X = np.array([[0], [3], [1]])\n    neigh = neighbors.NearestNeighbors(n_neighbors=2, algorithm='brute',\n                                       weights=_weight_func)\n    neigh.fit(X)\n\n    # check that weights are returned correctly\n    dist, ind = neigh.kneighbors(X, return_distance=True)\n    assert_array_almost_equal(dist, np.array([[0., np.sqrt(2)],\n                                              [np.sqrt(8), np.sqrt(2)],\n                                              [np.sqrt(2), np.sqrt(8)]]))\n    assert_array_equal(ind, np.array([[0, 2], [1, 2], [0, 1]]))\n\n    # check that weights are used correctly in prediction\n    neigh = neighbors.KNeighborsClassifier(n_neighbors=2, algorithm='brute',\n                                           weights=_weight_func)\n    neigh.fit(X, np.array([0, 1, 1]))\n    assert_array_equal(neigh.predict(X), np.array([0, 1, 1]))\n", "def test_kneighborsMixin():\n    # Test kneighborsMixin with sparse input and metric 'precomputed'\n    X = np.array([[0, 1, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1]])\n    neigh = neighbors.NearestNeighbors(n_neighbors=2, algorithm='brute', metric='precomputed')\n    neigh.fit(X)\n    dist, ind = neigh.kneighbors(X)\n\n    # Test kneighborsMixin with sparse input and metric 'precomputed'\n    X_sparse = csr_matrix(X)\n    neigh.fit(X_sparse)\n    dist_sparse, ind_sparse = neigh.kneighbors(X_sparse)\n\n    assert_array_almost_equal(dist, dist_sparse)\n    assert_array_equal(ind, ind_sparse)\n\n    # Test kneighborsMixin with dense input and metric 'minkowski'\n    X_dense = np.array([[0, 1, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1]])\n    neigh = neighbors.NearestNeighbors(n_neighbors=2, algorithm='brute', metric='minkowski')\n    neigh.fit(X_dense)\n    dist_dense, ind_dense = neigh.kneighbors(X_dense)\n\n    # Test kneighborsMixin with sparse input and metric 'minkowski'\n    X_sparse = csr_matrix(X)\n    neigh.fit(X_sparse)\n    with assert_warns(DataConversionWarning):\n        dist_sparse, ind_sparse = neigh.kneighbors(X_sparse)\n\n    assert_array_almost_equal(dist_dense, dist_sparse)\n    assert_array_equal(ind_dense, ind_sparse)\n\n    # Test kneighborsMixin with radius based neighbors\n    neigh = neighbors.NearestNeighbors(radius=0.4, algorithm='brute', metric='minkowski')\n    neigh.fit(X_dense)\n    dist, ind = neigh.radius_neighbors(X_dense)\n\n    # Test kneighborsMixin with radius based neighbors and sparse input\n    neigh.fit(X_sparse)\n    with assert_warns(DataConversionWarning):\n        dist_sparse, ind_sparse = neigh.radius_neighbors(X_sparse)\n\n    assert_array_almost_equal(dist, dist_sparse)\n    assert_array_equal(ind, ind_sparse)\n\n    # Test kneighborsMixin with weighted distances\n    neigh = neighbors.NearestNeighbors(n_neighbors=2, algorithm='brute', metric='minkowski')\n    neigh.fit(X_dense)\n    weights = np.array([1, 2, 3, 4])\n    with assert", "def test_kneighbors_mixin_query_is_train():\n    for algorithm, metric, sparse in product(ALGORITHMS, ['euclidean', 'manhattan'],\n                                             [True, False]):\n        neigh = neighbors.NearestNeighbors(n_neighbors=3, algorithm=algorithm,\n                                           metric=metric)\n\n        if sparse:\n            X = csc_matrix(iris.data)\n        else:\n            X = iris.data\n\n        neigh.fit(X)\n\n        result = neigh.kneighbors(X)\n        assert_array_equal(result[0].shape, (150, 2))\n        assert_array_equal(result[1].shape, (150, 2))\n\n        assert_array_equal(result[0][0, 0], 0)\n        assert_array_equal(result[1][0, 0], 0)\n\n        # the sample itself should have distance 0\n        assert_array_equal(result[0][0, 0], 0)\n        # the sample itself should be the first returned\n        assert_array_equal(result[1][0, 0], 0)\n\n        # if query data is the same as the indexed data, the first NN of\n        # every sample should be itself\n        for i, x in enumerate(result[1]):\n            assert_array_equal(x[0], i)\n", "def test_kneighbors_radius_neighbors():\n    # Test kneighbors and radius_neighbors with all possible metric, algorithm\n    # and sparse/dense combinations.\n\n    # Special case for metric='precomputed' which needs a square X matrix.\n    X = iris.data\n    n_samples, n_features = X.shape\n    X_precomputed = pairwise_distances(X)\n\n        if metric == 'precomputed':\n            return X_precomputed\n        return X\n\n        if radius is None:\n            return 5\n        return None\n\n    for (algorithm, metric, sparse_type, radius) in product(\n            ALGORITHMS, VALID_METRICS['brute'], SPARSE_TYPES,\n            [None, 1]):\n        if metric not in VALID_METRICS_SPARSE['brute'] and sparse_type is not None:\n            continue\n        X_sparse = sparse_type(X)\n        n_neighbors = _get_n_neighbors(radius)\n        X = _get_X(metric)\n        neigh = neighbors.NearestNeighbors(\n            algorithm=algorithm, metric=metric, n_neighbors=n_neighbors,\n            radius=radius, n_jobs=1)\n        neigh.fit(X)\n        if sparse_type is None:\n            neigh.fit(X_sparse)\n\n        if radius is None:\n            neigh.kneighbors(X, return_distance=False)\n            neigh.kneighbors(X_sparse, return_distance=False)\n        else:\n            neigh.radius_neighbors(X, radius, return_distance=False)\n            neigh.radius_neighbors(X_sparse, radius, return_distance=False)\n\n    # Test kneighbors and radius_neighbors with weighted=True\n\n    for (algorithm, metric) in product(\n            ALGORITHMS, VALID_METRICS['brute']):\n        neigh = neighbors.NearestNeighbors(\n            algorithm=algorithm, metric=metric, n_neighbors=5,\n            weights=_weight_func, n_jobs=1)\n        neigh.fit(X)\n        neigh.kneighbors(X, return_distance=False)\n\n    # Test kneighbors and radius_neighbors with weights='distance'\n\n    for (algorithm, metric) in product(\n            ALGORITHMS, VALID_METRICS['brute']):\n        neigh = neighbors.NearestNeighbors(\n            algorithm=algorithm, metric=metric, n_neighbors=5,\n            weights='distance', n_jobs=1)\n        neigh.fit(X)\n        neigh.kneighbors(X, return_distance=False)\n\n    # Test kneighbors and radius_neighbors with n_neighbors=1\n\n    for (algorithm, metric) in product(\n            ALGORITHMS,"], "sample_34": ["    def test_check_model_name_db_lookup_clashes(self):\n        with self.assertRaisesMessage(\n            Error,\n            \"'_MyModel' cannot start or end with an underscore as it collides with the query lookup syntax.\",\n        ):\n            model_class = type('MyModel', (models.Model,), {\n                '__module__': 'test',\n                'Meta': type('Meta', (), {'app_label': 'test'}),\n            })\n            model_class.__name__ = '_MyModel'\n            checks.run_checks_on_model(model_class, **{'databases': ['default']})\n\n        with self.assertRaisesMessage(\n            Error,\n            \"'My_Model' cannot contain double underscores as it collides with the query lookup syntax.\",\n        ):\n            model_class = type('MyModel', (models.Model,), {\n                '__module__': 'test',\n                'Meta': type('Meta', (), {'app_label': 'test'}),\n            })\n            model_class.__name__ = 'My_Model'\n            checks.run_checks_on_model(model_class, **{'databases': ['default']})\n", "def test_model_check_default_pk(self):\n    with modify_settings(INSTALLED_APPS={'append': ['check_framework.tests.model_checks.test_model_checks']}, DEFAULT_AUTO_FIELD='django.db.models.AutoField'):\n        class Model(models.Model):\n            pass\n\n        checks = Model.check()\n        self.assertEqual(len(checks), 0)\n\n    with modify_settings(INSTALLED_APPS={'append': ['check_framework.tests.model_checks.test_model_checks']}, DEFAULT_AUTO_FIELD=None):\n        class Model(models.Model):\n            pass\n\n        checks = Model.check()\n        self.assertEqual(len(checks), 1)\n        self.assertIsInstance(checks[0], Warning)\n        self.assertEqual(checks[0].id, 'models.W042')\n\n    with modify_settings(INSTALLED_APPS={'append': ['check_framework.tests.model_checks.test_model_checks']}, DEFAULT_AUTO_FIELD='django.db.models.AutoField'):\n        class Model(models.Model):\n            id = models.AutoField()\n\n        checks = Model.check()\n        self.assertEqual(len(checks), 0)\n\n    with modify_settings(INSTALLED_APPS={'append': ['check_framework.tests.model_checks.test_model_checks']}, DEFAULT_AUTO_FIELD=None):\n        class Model(models.Model):\n            id = models.AutoField()\n\n        checks = Model.check()\n        self.assertEqual(len(checks), 0)\n", "def test_model_unpickle(self):\n    # We need a model to test pickling.\n    class PickleModel(models.Model):\n        pass\n\n    # Create an instance of the model.\n    instance = PickleModel()\n\n    # Pickle the instance.\n    pickled_instance = instance.__reduce__()\n\n    # Check that the pickled instance can be unpickled correctly.\n    unpickled_instance = pickled_instance[0](*pickled_instance[1], *pickled_instance[2])\n\n    # Check that the unpickled instance is the correct class.\n    self.assertIsInstance(unpickled_instance, PickleModel)\n", "    def test_default_pk(self):\n        from check_framework.test_models import (\n            CustomPKModel, CustomPKWithDefaultModel, LegacyModel,\n        )\n        self.assertEqual(CustomPKModel._meta.pk.name, 'custom_id')\n        self.assertEqual(CustomPKModel._meta.pk.auto_created, False)\n        self.assertEqual(CustomPKWithDefaultModel._meta.pk.name, 'custom_id')\n        self.assertEqual(CustomPKWithDefaultModel._meta.pk.auto_created, False)\n        self.assertEqual(LegacyModel._meta.pk.name, 'id')\n        self.assertEqual(LegacyModel._meta.pk.auto_created, True)\n", "    def test_model_validation(self):\n        with self.assertRaisesMessage(\n            Error,\n            \"'ModelWithExistingDBTable' defines the same db_table as model 'check_framework.tests.apps.DuplicateDBTableConfig.ModelWithExistingDBTable' in another app.\"\n        ):\n            checks.model_checks.check_all_models(app_configs=['check_framework.tests.apps.DuplicateDBTableConfig'])\n"], "sample_123": ["def test_comp():\n    assert comp(1, 1) == True\n    assert comp(1, 2) == True\n    assert comp(1, 1.0000000000001) == True\n    assert comp(1, 2, 10**-10) == False\n    assert comp(1, 1, 10**-10) == True\n    assert comp(1.0000000000001, 1, 10**-10) == True\n    assert comp(1.0000000000001, 1, 10**-15) == False\n    assert comp(1.0000000000001, 1, 10**-17) == False\n    assert comp(1.0000000000001, 1, 10**-15, tol=10**-17) == True\n    assert comp(1.0000000000001, 1, 10**-15, tol=10**-16) == True\n    assert comp(1.0000000000001, 1, 10**-15, tol=10**-18) == False\n\n    assert comp(1, 0.9999999999999, 10**-10) == True\n    assert comp(1, 0.9999999999999, 10**-15) == True\n    assert comp(1, 0.9999999999999, 10**-17) == False\n\n    assert comp(1.0000000000001, 1.0000000000001) == True\n    assert comp(1.0000000000001, 1.00000000000011) == True\n    assert comp(1.0000000000001, 1.00000000000011, tol=10**-15) == True\n    assert comp(1.0000000000001, 1.00000000000011, tol=10**-17) == False\n\n    assert comp(1.0000000000001, -1.0000000000001) == False\n    assert comp(1.0000000000001, -1.00000000000011, tol=10**-15) == False\n    assert comp(1.0000000000001, -1.00000000000011, tol=10**", "def test_comp():\n    assert comp(nan, 1) is True\n    assert comp(oo, 1) is False\n    assert comp(nan, oo) is False\n    assert comp(nan, -oo) is False\n    assert comp(nan, nan) is False\n\n    assert comp(oo, 1, 0.5) is True\n    assert comp(oo, oo, 1) is False\n    assert comp(oo, -oo, 0.5) is False\n    assert comp(nan, nan, 0.5) is False\n\n    assert comp(oo, oo, 2) is True\n    assert comp(-oo, -oo, 2) is True\n    assert comp(oo, -oo, 2) is False\n\n    assert comp(1, 1) is True\n    assert comp(1, 2) is False\n    assert comp(1, 1.000000000000001) is True\n    assert comp(1, '1') is True\n    assert comp(1, 2, 2) is True\n\n    assert comp(-oo, -oo) is True\n    assert comp(oo, oo) is True\n    assert comp(nan, nan) is True\n\n    assert comp(1e-15, 0) is False\n    assert comp(1e-15, 0, 1e-15) is True\n    assert comp(1e-15, 0, 1e-16) is False\n    assert comp(1e-15, 0, 1e-14) is True\n", "def test_comp_with_complex():\n    assert comp(0.9999999999999999, 1) == True\n    assert comp(0.9999999999999999, 1, 1e-10) == False\n", "def test_mod_inverse():\n    assert mod_inverse(2, 3) == 2\n    assert mod_inverse(-2, 3) == 1\n    assert mod_inverse(2, 5) == 3\n    assert mod_inverse(3, 11) == 4\n    assert mod_inverse(8, 11) == 7\n    assert mod_inverse(2, 1) == 0\n    assert mod_inverse(0, 11) == 0\n    assert mod_inverse(1, 11) == 1\n\n    assert mod_inverse(S(1)/7, S(5)/2) == S(7)/2\n\n    raises(ValueError, lambda: mod_inverse(2, 4))\n    raises(ValueError, lambda: mod_inverse(2, 4.0))\n    raises(ValueError, lambda: mod_inverse(2, 2))\n\n    # non-integer moduli must be invertible as a Rational\n    assert mod_inverse(2, Rational(3, 2)) == Rational(1, 3)\n    raises(ValueError, lambda: mod_inverse(2, Rational(4, 2)))\n\n    # exact values\n    assert mod_inverse(Rational(3, 2), 5) == Rational(-2)\n    assert mod_inverse(3, Rational(5, 2)) == Rational(-4, 5)\n    # non-exact values\n    raises(ValueError, lambda: mod_inverse(Rational(3, 2), 5.0))\n    raises(ValueError, lambda: mod_inverse(3.0, Rational(5, 2)))\n\n    assert mod_inverse(1, 3**100) == 1\n\n    # the inverse of 2 mod 10**6 is 500001 (see issue 3015)\n    assert mod_inverse(2, 10**6) == 500001\n\n    seterr(True)\n    raises(ZeroDivisionError, lambda: mod_inverse(0, 0))\n    seterr(False)\n    assert mod_inverse(0, 0) == nan\n", "def test_mod_inverse():\n    assert mod_inverse(2, 3) == 2\n    assert mod_inverse(S(2)/7, S(5)/2) == S(7)/2\n    assert mod_inverse(-2, 5) == -2\n    assert mod_inverse(3, 9) == 4\n    assert mod_inverse(6, 7) == 6\n    assert mod_inverse(17, 19) == 17\n    assert mod_inverse(7, 13) == 2\n    assert mod_inverse(7, 13, S.Half) == 2\n    assert mod_inverse(-1, 11) == -1\n    assert mod_inverse(2, 15) == 8\n    assert mod_inverse(121, 209) == 121\n    assert mod_inverse(121, 239) == 143\n    assert mod_inverse(-7, 8) == 1\n    assert mod_inverse(121, 481) == 4\n    assert mod_inverse(121, 529) == 1\n    assert mod_inverse(121, 547) == 516\n    assert mod_inverse(-121, 547) == 31\n    assert mod_inverse(7, 11) == 8\n    assert mod_inverse(11, 13) == 6\n    assert mod_inverse(121, 11) == 121\n    assert mod_inverse(121, 13) == 12\n    assert mod_inverse(121, 31) == 4\n    assert mod_inverse(121, 127) == 121\n    assert mod_inverse(121, 128) == 121\n    assert mod_inverse(121, 239) == 143\n    assert mod_inverse(121, 247) == 197\n    assert mod_inverse(121, 277) == 242\n    assert mod_inverse(121, 283) == 265\n    assert mod_inverse(121, 289) == 289\n    assert mod_inverse(121, 293) == 103\n    assert mod_inverse(121, 301) == 4\n    assert mod_inverse(121, 313) == 36\n    assert mod_inverse(121, 319) == 212\n    assert mod_inverse(121, 321) == 259\n    assert mod_inverse(121, 323) == 71\n   "], "sample_149": ["def test_monomial_pow():\n    assert monomial_pow((1, 2, 3), 2) == (2, 4, 6)\n    assert monomial_pow((1, 2, 3), 0) == (0, 0, 0)\n    assert monomial_pow((1, 2, 3), -1) == (-1, -2, -3)\n", "def test_monomial_pow():\n    assert monomial_pow((1, 2, 3), 2) == (2, 4, 6)\n    assert monomial_pow((4, 5, 6), 0) == (0, 0, 0)\n\n    with raises(ValueError):\n        monomial_pow((1, 2, 3), -1)\n", "def test_itermonomials():\n    # Test Case I. max_degrees and min_degrees are both integers\n    assert list(itermonomials([x, y], 2)) == [1, x, y, x**2, x*y, y**2]\n    assert list(itermonomials([x, y], 3)) == [1, x, y, x**2, x*y, y**2, x**3, x**2*y, x*y**2, y**3]\n    assert list(itermonomials([x, y], 2, 1)) == [x, y, x**2, x*y, y**2]\n\n    # Test Case II. max_degrees and min_degrees are both lists\n    assert list(itermonomials([x, y], [2, 4], [1, 2])) == [x**2*y**2, x**2*y**3, x**2*y**4, x*y**2, x*y**3, x*y**4]\n", "def test_itermonomials():\n    # Test case I: max_degrees and min_degrees are both integers\n    assert sorted(itermonomials([x, y], 2), key=lambda m: (m.as_expr(x, y), m)) == [\n        S.One, x, y, x**2, x*y, y**2]\n    assert sorted(itermonomials([x, y], 3), key=lambda m: (m.as_expr(x, y), m)) == [\n        S.One, x, y, x**2, x*y, y**2, x**3, x**2*y, x*y**2, y**3]\n    assert sorted(itermonomials([x, y], 2, 1), key=lambda m: (m.as_expr(x, y), m)) == [\n        x, y, x**2, x*y, y**2]\n    assert sorted(itermonomials([a, b, x], 2), key=lambda m: (m.as_expr(a, b, x), m)) == [\n        S.One, a, b, x, a**2, a*x, b**2, b*x, x**2, a*b, b*a]\n\n    # Test case II: max_degrees and min_degrees are both lists\n    assert sorted(itermonomials([x, y], [2, 4], [1, 2]), key=lambda m: (m.as_expr(x, y), m)) == [\n        x**2*y**4, x**2*y**3, x**2*y**2, x*y**4, x*y**3, x*y**2]\n", "def test_itermonomials():\n    assert list(itermonomials([x], 2)) == [1, x, x**2]\n    assert list(itermonomials([x, y], 2)) == [1, x, y, x**2, x*y, y**2]\n    assert list(itermonomials([x, y, z], 2)) == [\n        1, x, y, z, x**2, x*y, x*z, y**2, y*z, z**2, x**2*y, x**2*z, x*y**2, x*z**2, y**2*z, y*z**2, x*y*z, x**2*y*z, x*y**2*z, x*y*z**2]\n    assert list(itermonomials([x, y], 2, 1)) == [x, y, x**2, x*y, y**2]\n    assert list(itermonomials([x, y], [2, 2], [1, 1])) == [x*y]\n    assert list(itermonomials([x, y], [1, 2], [1, 1])) == [x*y, x*y**2]\n    assert list(itermonomials([x, y], [2, 1], [1, 1])) == [x*y, x**2*y]\n\n    assert list(itermonomials([x, y], 3)) == [1, x, y, x**2, x*y, y**2, x**3, x**2*y, x*y**2, y**3]\n    assert list(itermonomials([x, y], 3, 1)) == [x, y, x**2, x*y, y**2, x**3, x**2*y, x*y**2, y**3]\n    assert list(itermonomials([x, y], [2, 4], [1, 2])) == [x**2*y**2, x**2*y**3, x**2*y**4, x*y**2, x*y**3, x*y**4]\n\n    a, b = symbols('a, b', commutative=False)\n    assert set(itermonomials([a, b, x], 2)) == {1, a, a**2, b"], "sample_46": ["    def test_references_table(self):\n        self.assertTrue(self.reference.references_table('table'))\n        self.assertFalse(self.reference.references_table('other_table'))\n", "    def test_rename_table_references(self):\n        self.reference.rename_table_references('table', 'new_table')\n        self.assertEqual(self.reference.table, 'new_table')\n        self.assertEqual(str(self.reference), 'NEW_TABLE')\n", "    def test_rename_table_references(self):\n        self.reference.rename_table_references('table', 'new_table')\n        self.assertEqual(self.reference.table, 'new_table')\n        self.assertEqual(str(self.reference), 'NEW_TABLE')\n", "    def test_rename_table_references(self):\n        self.reference.rename_table_references('table', 'new_table')\n        self.assertEqual(self.reference.table, 'new_table')\n        self.assertEqual(self.reference.references_table('new_table'), True)\n        self.assertEqual(self.reference.references_table('old_table'), False)\n        self.assertEqual(str(self.reference), 'NEW_TABLE')\n", "    def test_str_representation(self):\n        quote_name = lambda column: f'\"{column}\"'\n        columns = Columns('table', ['column1', 'column2'], quote_name)\n        self.assertEqual(str(columns), '\"column1\", \"column2\"')\n"], "sample_93": ["def test_tmp_path_factory_from_config(tmp_path):\n    class ConfigMock:\n            self.option = option\n            self.trace = MockTrace()\n\n        class option:\n            @property\n                return tmp_path / \"basetemp\"\n\n    config = ConfigMock(option=None)\n    factory = TempPathFactory.from_config(config)\n    assert factory.getbasetemp() == tmp_path / \"pytest-of-unknown\"\n    assert factory.mktemp(\"foo-\").name.startswith(\"foo-\")\n    assert factory.mktemp(\"foo-\").parent == factory.getbasetemp()\n\n    config = ConfigMock(option=\"path/to/basetemp\")\n    factory = TempPathFactory.from_config(config)\n    assert factory.getbasetemp() == Path(\"path/to/basetemp\")\n    assert factory.mktemp(\"foo-\").name.startswith(\"foo-\")\n    assert factory.mktemp(\"foo-\").parent == factory.getbasetemp()\n", "def test_temp_path_factory_from_config(tmp_path: Path, monkeypatch: MonkeyPatch) -> None:\n    class ConfigMock:\n            self.trace = {\"tmpdir\": \"trace\"}\n            self.option = attr.Mock()\n            self.option.basetemp = tmp_path\n\n    config = ConfigMock()\n    factory = TempPathFactory.from_config(config, _ispytest=True)\n    assert factory.getbasetemp() == tmp_path\n    assert factory.mktemp(\"test\", numbered=True).parent == tmp_path\n\n", "def test_temp_path_factory_init(tmp_path_factory, monkeypatch):\n    # Test with a custom basetemp\n    custom_basetemp = Path(tmp_path_factory.mktemp(\"custom_basetemp\"))\n    factory = TempPathFactory.from_config(\n        Config(), given_basetemp=custom_basetemp, _ispytest=True\n    )\n    assert factory.getbasetemp() == custom_basetemp\n\n    # Test with environment variable PYTEST_DEBUG_TEMPROOT\n    env_basetemp = Path(tmp_path_factory.mktemp(\"env_basetemp\"))\n    monkeypatch.setenv(\"PYTEST_DEBUG_TEMPROOT\", str(env_basetemp))\n    factory = TempPathFactory.from_config(Config(), _ispytest=True)\n    assert factory.getbasetemp().parent == env_basetemp\n\n    # Test with default basetemp\n    monkeypatch.delenv(\"PYTEST_DEBUG_TEMPROOT\", raising=False)\n    factory = TempPathFactory.from_config(Config(), _ispytest=True)\n    assert factory.getbasetemp().is_dir()\n", "def test_tmp_path_factory_init(tmp_path_factory: TempPathFactory, monkeypatch: MonkeyPatch) -> None:\n    # Test that TempPathFactory can be initialized with a given basetemp\n    given_basetemp = tmp_path_factory.mktemp(\"given-basetemp\")\n    tmppath_factory = TempPathFactory(given_basetemp, tmp_path_factory._trace, _ispytest=True)\n    assert tmppath_factory._given_basetemp == given_basetemp\n    assert tmppath_factory._basetemp is not None\n\n    # Test that TempPathFactory can be initialized without a given basetemp\n    tmppath_factory = TempPathFactory(None, tmp_path_factory._trace, _ispytest=True)\n    assert tmppath_factory._given_basetemp is None\n    assert tmppath_factory._basetemp is not None\n\n    # Test that TempPathFactory raises an error if basename is not relative\n    with pytest.raises(ValueError):\n        tmppath_factory.mktemp(\"/absolute/path\", numbered=True)\n\n    # Test that TempPathFactory raises an error if basename is not normalized\n    with pytest.raises(ValueError):\n        tmppath_factory.mktemp(\"./not/normalized/path\", numbered=True)\n\n", "def test_getbasetemp(tmp_path_factory: TempPathFactory, monkeypatch: MonkeyPatch):\n    basetemp = tmp_path_factory.getbasetemp()\n    assert basetemp.exists()\n    assert basetemp.is_dir()\n\n    # test that a given basetemp is used\n    given_basetemp = tmp_path_factory.mktemp(\"given_basetemp\")\n    new_factory = TempPathFactory(given_basetemp, tmp_path_factory._trace)\n    new_basetemp = new_factory.getbasetemp()\n    assert new_basetemp == given_basetemp\n\n    # test that a non-existent given basetemp is created\n    given_basetemp = tmp_path_factory.mktemp(\"given_basetemp\", numbered=False)\n    given_basetemp.rmdir()\n    assert not given_basetemp.exists()\n    new_factory = TempPathFactory(given_basetemp, tmp_path_factory._trace)\n    new_basetemp = new_factory.getbasetemp()\n    assert new_basetemp == given_basetemp\n    assert new_basetemp.exists()\n    assert new_basetemp.is_dir()\n\n    # test that an environment variable is used\n    env_var = \"PYTEST_DEBUG_TEMPROOT\"\n    given_basetemp = tmp_path_factory.mktemp(\"given_basetemp\")\n    monkeypatch.setenv(env_var, str(given_basetemp))\n    new_factory = TempPathFactory(None, tmp_path_factory._trace)\n    new_basetemp = new_factory.getbasetemp()\n    assert new_basetemp.resolve().parent == given_basetemp.resolve()\n\n    # test that getuser() does not work\n        raise ImportError\n    monkeypatch.setattr(\"getpass.getuser\", getuser_side_effect)\n    new_factory = TempPathFactory(None, tmp_path_factory._trace)\n    new_basetemp = new_factory.getbasetemp()\n    assert new_basetemp.resolve().parent.name.startswith(\"pytest-of-unknown\")\n\n    # test that a default basetemp is used\n    default_basetemp = tmp_path_factory.mktemp(\"default_basetemp\")\n    new_factory = TempPathFactory(None, tmp_path_factory._trace)\n    monkeypatch.setattr(sys.modules[\"tempfile\"], \"gettempdir\", lambda: str(default_basetemp))\n    new_basetemp = new_factory.getbasetemp()\n    assert new_basetemp.resolve().parent == default_basetemp"], "sample_16": ["    def test_model_format_dict(self):\n        class TestModel(models.Model):\n            class Meta:\n                verbose_name = 'Test Model'\n                verbose_name_plural = 'Test Models'\n\n        model_instance = TestModel()\n        model_subclass = type('TestModelSubclass', (models.Model,), {})\n        queryset = models.QuerySet(model=model_subclass)\n\n        for obj in [model_instance, model_subclass, queryset]:\n            self.assertEqual(model_format_dict(obj), {\n                'verbose_name': 'Test Model',\n                'verbose_name_plural': 'Test Models',\n            })\n", "    def test_booleanfield(self):\n        field = models.BooleanField()\n        value = True\n        self.assertEqual(display_for_field(value, field, 'N/A'), '<img src=\"/static/admin/img/icon-yes.svg\" alt=\"True\">')\n", "    def test_lookup_needs_distinct(self):\n        # Test lookup_needs_distinct with a non-m2m path\n        class Model(models.Model):\n            field = models.CharField(max_length=10)\n\n        self.assertFalse(lookup_needs_distinct(Model._meta, 'field'))\n\n        # Test lookup_needs_distinct with an m2m path\n        class Model(models.Model):\n            field = models.ManyToManyField('self')\n\n        self.assertTrue(lookup_needs_distinct(Model._meta, 'field'))\n\n        # Test lookup_needs_distinct with a path that follows a relation\n        class Model(models.Model):\n            field = models.ForeignKey('self', on_delete=models.CASCADE)\n\n        self.assertFalse(lookup_needs_distinct(Model._meta, 'field__field'))\n", "    def test_can_fast_delete(self):\n        \"\"\"\n        Test that can_fast_delete always returns False.\n        \"\"\"\n        self.assertFalse(self.n.can_fast_delete())\n        # Test that it returns False even when some objects are protected\n        self.n.protected = set([self.objs[0]])\n        self.assertFalse(self.n.can_fast_delete())\n", "    def test_quote(self):\n        self.assertEqual(quote('hello'), 'hello')\n        self.assertEqual(quote('hello/world'), 'hello_world')\n        self.assertEqual(quote('hello:world'), 'hello_world')\n        self.assertEqual(quote('hello/world:with spaces'), 'hello_world_with spaces')\n"], "sample_82": ["def test_groupby_reduce(dataset):\n    grouped = dataset.groupby(\"x\")\n    result = grouped.reduce(np.mean)\n    expected = dataset.mean(dim=\"x\")\n    assert_identical(result, expected)\n\n    result = grouped.reduce(np.mean, dim=\"y\")\n    expected = dataset.mean(dim=\"y\")\n    assert_identical(result, expected)\n\n    with raises_regex(ValueError, \"cannot reduce over dimensions\"):\n        grouped.reduce(np.mean, dim=\"invalid_dim\")\n\n    with raises_regex(ValueError, \"can't specify both `grouper` and `bins`\"):\n        dataset.groupby(\"x\", bins=[0, 1, 2], grouper=pd.Grouper(freq=\"M\"))\n", "def test_groupby_quantile():\n    \"\"\"Test the `quantile` method of GroupBy object.\"\"\"\n    da = xr.DataArray(\n        [[1.3, 8.4, 0.7, 6.9], [0.7, 4.2, 9.4, 1.5], [6.5, 7.3, 2.6, 1.9]],\n        coords={\"x\": [0, 0, 1], \"y\": [1, 1, 2, 2]},\n        dims=(\"x\", \"y\"),\n    )\n    ds = xr.Dataset({\"a\": da})\n    q = 0.5\n\n    expected_array = da.quantile(q, dim=\"x\")\n    expected_dataset = ds.quantile(q, dim=\"x\")\n\n    grouped_array = da.groupby(\"x\")\n    grouped_dataset = ds.groupby(\"x\")\n\n    assert_allclose(grouped_array.quantile(q), expected_array)\n    assert_allclose(grouped_dataset.quantile(q, dim=\"x\"), expected_dataset)\n", "def test_groupby_quantile(array):\n    result = array.groupby(\"x\").quantile(0.5)\n    expected = array.isel(x=1).median(dim=[\"y\", \"z\"], skipna=True)\n    assert_equal(result, expected)\n\n    result = array.groupby(\"x\").quantile([0.25, 0.75])\n    expected = array.stack(sample=(\"x\", \"y\", \"z\")).quantile(\n        [0.25, 0.75], dim=\"sample\"\n    )\n    assert_equal(result.transpose(\"x\", \"quantile\", \"y\", \"z\"), expected)\n\n    result = array.groupby(\"x\").quantile(0.5, dim=\"y\")\n    expected = array.median(dim=\"y\", skipna=True)\n    assert_equal(result, expected)\n\n    with raises_regex(ValueError, \"Failed to group data\"):\n        array.groupby(\"x\").quantile(0.5, dim=\"x\")\n", "def test_groupby_map(dataset):\n        return da * 2\n\n    result = dataset.groupby(\"x\").map(scale)\n    expected = dataset.map(scale)\n    assert_identical(result, expected)\n\n", "def test_groupby_quantile(dataset):\n    # Test that quantile works on a groupby object\n    grouped = dataset.groupby(\"z\")\n    expected = grouped.quantile(0.5, dim=...)\n\n    # Check that the quantiles are calculated correctly\n    assert_allclose(expected.foo, np.median(dataset.foo, axis=(2,)))\n\n    # Check that the result has the correct dimensions and coordinates\n    assert expected.dims == (\"z\", \"quantile\")\n    assert_equal(expected.z, dataset.z)\n    assert \"y\" not in expected.coords\n\n    # Check that the result has the correct data variables\n    assert \"foo\" in expected.data_vars\n\n    # Check that the result is a Dataset\n    assert isinstance(expected, xr.Dataset)\n\n    # Test with multiple quantiles\n    expected = grouped.quantile([0.25, 0.5, 0.75], dim=...)\n    assert expected.dims == (\"z\", \"quantile\")\n    assert expected.quantile.size == 3\n"], "sample_20": ["    def test_check_model_name_db_lookup_clashes(self):\n        class Model(models.Model):\n            class Meta:\n                app_label = 'tests'\n                model_name = '_Test'\n\n        expected_errors = [\n            Error(\n                \"The model name '_Test' cannot start or end with an underscore \"\n                \"as it collides with the query lookup syntax.\",\n                id='models.E023',\n            )\n        ]\n        self.assertEqual(Model.check(), expected_errors)\n\n        class Model(models.Model):\n            class Meta:\n                app_label = 'tests'\n                model_name = 'Test_Model'\n\n        expected_errors = [\n            Error(\n                \"The model name 'Test_Model' cannot contain double underscores as \"\n                \"it collides with the query lookup syntax.\",\n                id='models.E024',\n            )\n        ]\n        self.assertEqual(Model.check(), expected_errors)\n", "    def test_partial_index(self):\n        class Author(models.Model):\n            name = models.CharField(max_length=200)\n            is_active = models.BooleanField(default=False)\n\n            class Meta:\n                indexes = [\n                    models.Index(fields=['name'], condition=models.Q(is_active=True)),\n                ]\n\n        with connection.schema_editor(atomic=True):\n            Author._meta.indexes = Author._meta.indexes.copy()\n            Author._meta.indexes[0].condition = models.Q(is_active=False)\n            Author._meta.concrete_model._check_index_together()\n\n        self.assertEqual(Author._meta.indexes[0].condition, models.Q(is_active=False))\n", "    def test_ordering_clash(self):\n        with self.assertRaisesMessage(Error, \"ordering' and 'order_with_respect_to' cannot be used together.\"):\n            class ModelWithOrderingClash(models.Model):\n                ordering = ['id']\n                order_with_respect_to = models.ForeignKey('self', on_delete=models.CASCADE)\n\n                class Meta:\n                    app_label = 'ordering_model_checks'\n", "def test_index_together_max_length(self):\n    \"\"\"Test _check_long_column_names for 'index_together'.\"\"\"\n    with register_lookup(Lower, lookup_name='lower'):\n        class ModelWithIndex(models.Model):\n            char_field = models.CharField(max_length=255)\n            class Meta:\n                indexes = [\n                    models.Index(Lower('char_field').desc(), Lower('char_field')),\n                ]\n\n        # Skip databases where the model won't be created\n        max_len, db_alias = get_max_column_name_length()\n        if max_len is not None:\n            with override_settings(DATABASES={\n                db_alias: {'ENGINE': connection.vendor},\n                'other': {'ENGINE': connection.vendor}\n            }, DATABASE_ROUTERS=[EmptyRouter()]):\n                errors = ModelWithIndex.check(databases=[db_alias, 'other'])\n                self.assertEqual(len(errors), 1)\n                self.assertEqual(errors[0].obj, ModelWithIndex)\n                self.assertEqual(errors[0].id, 'models.E018')\n", "    def test_model_name_db_lookup_clashes(self):\n        # model name starts with an underscore\n        with self.assertRaisesMessage(\n            Error,\n            \"The model name '_Model' cannot start or end with an underscore as it collides with the query lookup syntax.\",\n            id='models.E023',\n        ):\n            class Model(models.Model):\n                pass\n            check_model(Model)\n\n        # model name ends with an underscore\n        with self.assertRaisesMessage(\n            Error,\n            \"The model name 'Model_' cannot start or end with an underscore as it collides with the query lookup syntax.\",\n            id='models.E023',\n        ):\n            class Model_(models.Model):\n                pass\n            check_model(Model_)\n\n        # model name contains double underscores\n        with self.assertRaisesMessage(\n            Error,\n            \"The model name 'Model__Foo' cannot contain double underscores as it collides with the query lookup syntax.\",\n            id='models.E024',\n        ):\n            class Model__Foo(models.Model):\n                pass\n            check_model(Model__Foo)\n\n        # valid model name\n        class Model(models.Model):\n            pass\n        errors = check_model(Model)\n        self.assertEqual(errors, [])\n"], "sample_136": ["def test_blockcut():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (1, 3))\n    assert B.blocks.shape == (2, 2)\n    assert B.blocks[0, 0].shape == (1, 1)\n    assert B.blocks[0, 1].shape == (1, 3)\n    assert B.blocks[1, 0].shape == (3, 1)\n    assert B.blocks[1, 1].shape == (3, 3)\n", "def test_blockcut():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (2, 2), (2, 2))\n    assert isinstance(B, BlockMatrix)\n    assert ImmutableMatrix(B.blocks[0, 0]) == ImmutableMatrix(2, 2, range(4))\n    assert ImmutableMatrix(B.blocks[0, 1]) == ImmutableMatrix(2, 2, range(4, 8))\n    assert ImmutableMatrix(B.blocks[1, 0]) == ImmutableMatrix(2, 2, range(8, 12))\n    assert ImmutableMatrix(B.blocks[1, 1]) == ImmutableMatrix(2, 2, range(12, 16))\n", "def test_bounds():\n    assert blockcut ImmutableMatrix(10, 10, range(100)), (1, 3, 6), (2, 4)) == \\\n        BlockMatrix([\n            [Matrix([[0, 1], [10, 11], [20, 21]]),\n             Matrix([[2, 3], [12, 13], [22, 23]]),\n             Matrix([[4, 5], [14, 15], [24, 25]]),\n             Matrix([[6, 7], [16, 17], [26, 27]]),\n             Matrix([[8, 9], [18, 19], [28, 29]])],\n            [Matrix([[30, 31], [40, 41], [50, 51]]),\n             Matrix([[32, 33], [42, 43], [52, 53]]),\n             Matrix([[34, 35], [44, 45], [54, 55]]),\n             Matrix([[36, 37], [46, 47], [56, 57]]),\n             Matrix([[38, 39], [48, 49], [58, 59]])],\n            [Matrix([[60, 61], [70, 71], [80, 81]]),\n             Matrix([[62, 63], [72, 73], [82, 83]]),\n             Matrix([[64, 65], [74, 75], [84, 85]]),\n             Matrix([[66, 67], [76, 77], [86, 87]]),\n             Matrix([[68, 69], [78, 79], [88, 89]])],\n            [Matrix([[90, 91], [100, 101], [110, 111]]),\n             Matrix([[92, 93], [102, 103], [112, 113]]),\n             Matrix([[94, 95], [104, 105], [114, 115]]),\n             Matrix([[96, 97], [106, 107], [116, 117]]),\n             Matrix([[98, 99], [108, 109], [118, 119]])]\n        ])\n    assert blockcut(ImmutableMatrix(10, 10, range(100)), (1, 3, 6), (4, 6)) == \\\n        BlockMatrix([\n            [Matrix([[", "def test_blockcut():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (1, 3))\n    assert isinstance(B, BlockMatrix)\n    assert ImmutableMatrix(B.blocks[0, 1]) == ImmutableMatrix([[1, 2, 3]])\n    assert ImmutableMatrix(B.blocks[1, 0]) == ImmutableMatrix([[4], [5], [6]])\n    assert ImmutableMatrix(B.blocks[1, 1]) == ImmutableMatrix([[ 7, 8, 9], [10, 11, 12], [13, 14, 15]])\n", "def test_bounds():\n    assert bounds((1, 2, 3)) == [(0, 1), (1, 3), (3, 6)]\n    assert bounds((5, 1, 1)) == [(0, 5), (5, 6), (6, 7)]\n    assert bounds((1,)) == [(0, 1)]\n"], "sample_91": ["def test_evaluate_skip_marks_skipif_with_multiple_conditions():\n    class Item:\n            if name == \"skipif\":\n                return [\n                    Mark(\"skipif\", args=(\"sys.platform == 'win32'\", \"sys.version_info < (3, 9)\"), kwargs={})\n                ]\n            return []\n\n            return None\n\n    item = Item()\n    skipped = evaluate_skip_marks(item)\n    assert skipped is not None\n    assert skipped.reason == \"condition: sys.platform == 'win32'\"\n", "def test_evaluate_xfail_marks_with_runxfail_option(tmp_path, pytestconfig):\n    pytestconfig.option.runxfail = True\n    p = tmp_path / \"test_xfail.py\"\n    p.write_text(\n        \"\"\"\\\n        import pytest\n\n        @pytest.mark.xfail(condition=True, run=True)\n            assert 1 == 2\n        \"\"\"\n    )\n    result = pytestconfig.hook.pytest_deselected(items=[])\n    result = pytestconfig.hook.pytest_runtest_setup(items=[p])\n    result = pytestconfig.hook.pytest_runtest_call(items=[p])\n    xfailed = evaluate_xfail_marks(p)\n    assert xfailed.run is True\n    assert xfailed.reason == \"\"\n    assert xfailed.strict is False\n    assert xfailed.raises is None\n", "    def test_evaluate_skip_marks_unconditional(self):\n        # Create an item with a skip mark\n        class TestItem:\n                if name == \"skip\":\n                    yield pytest.mark.skip(reason=\"unconditional skip\")\n                else:\n                    return []\n        item = TestItem()\n\n        # Evaluate the skip marks\n        result = evaluate_skip_marks(item)\n        assert result is not None\n        assert isinstance(result, Skip)\n        assert result.reason == \"unconditional skip\"\n\n        # Test with reason as the first arg\n        class TestItem:\n                if name == \"skip\":\n                    yield pytest.mark.skip(\"reason from arg\")\n                else:\n                    return []\n        item = TestItem()\n\n        # Evaluate the skip marks\n        result = evaluate_skip_marks(item)\n        assert result is not None\n        assert isinstance(result, Skip)\n        assert result.reason == \"reason from arg\"\n", "def test_evaluate_condition_string_condition(tmp_path, monkeypatch):\n    # Create a test item with a string condition\n    item = runtestprotocol.Item(\"test_foo\", tmp_path)\n    item.obj = lambda: None\n    item.obj.__globals__ = {\"os\": os, \"sys\": sys}\n    mark = pytest.mark.skipif(\"os.name == 'nt'\", reason=\"Windows only\")\n\n    # Test that the condition is evaluated correctly\n    result, reason = evaluate_condition(item, mark, \"os.name == 'nt'\")\n    assert result == (os.name == 'nt')\n    assert reason == \"condition: os.name == 'nt'\"\n\n    # Test that a syntax error in the condition raises a failure\n    mark = pytest.mark.skipif(\"invalid syntax\", reason=\"Windows only\")\n    with pytest.raises(pytest.fail.Exception):\n        evaluate_condition(item, mark, \"invalid syntax\")\n\n    # Test that a runtime error in the condition raises a failure\n    mark = pytest.mark.skipif(\"1 / 0\", reason=\"Windows only\")\n    with pytest.raises(pytest.fail.Exception):\n        evaluate_condition(item, mark, \"1 / 0\")\n", "    def test_evaluate_xfail_marks_with_run_true(self, testdir):\n        testdir.makepyfile(\"\"\"\n            import pytest\n            @pytest.mark.xfail(run=True, reason=\"test reason\")\n                assert 1 == 0\n        \"\"\")\n        item = testdir.getitem(\"test_xfail\")\n        result = evaluate_xfail_marks(item)\n        assert result is not None\n        assert result.run is True\n        assert result.reason == \"test reason\"\n"], "sample_118": ["def test_ccode_Indexed():\n    len_y = 5\n    y = IndexedBase('y', shape=(len_y,))\n    t = IndexedBase('t', shape=(len_y,))\n    Dy = IndexedBase('Dy', shape=(len_y-1,))\n    i = Idx('i', len_y-1)\n    e= Eq(Dy[i], (y[i+1]-y[i])/(t[i+1]-t[i]))\n    assert ccode(e.rhs, assign_to=e.lhs, contract=True) == (\n        'for (int i = 0; i < 4; i++) {\\n'\n        '   Dy[i] = (y[i + 1] - y[i])/(t[i + 1] - t[i]);\\n'\n        '}'\n    )\n    assert ccode(e.rhs, assign_to=e.lhs, contract=False) == 'Dy[i] = (y[i + 1] - y[i])/(t[i + 1] - t[i]);'\n", "def test_ccode():\n    printer = CCodePrinter()\n    assert printer._print_Symbol(x) == 'x'\n    assert printer._print_Pow(x**2) == 'pow(x, 2)'\n    assert printer._print_Rational(Rational(3, 2)) == '3.0L/2.0L'\n    assert printer._print_Indexed(IndexedBase('x', shape=(3,))(Idx('i', 3))) == 'x[i]'\n    assert printer._print_Idx(Idx('i', 3)) == 'i'\n    assert printer._print_Exp1(exp(1)) == 'M_E'\n    assert printer._print_Pi(pi) == 'M_PI'\n    assert printer._print_Infinity(oo) == 'HUGE_VAL'\n    assert printer._print_NegativeInfinity(-oo) == '-HUGE_VAL'\n    assert printer._print_Relational(Eq(x, y)) == 'x == y'\n    assert printer._print_AugmentedAssignment(aug_assign(x, '+', 2)) == 'x += 2;'\n\n    # Test contract=True\n    i = Idx('i', 5)\n    expr = IndexedBase('x', shape=(5,))(i)\n    assert ccode(expr, IndexedBase('y', shape=(5,)), contract=True) == \\\n        'for (int i=0; i<5; i++) {\\n   y[i] = x[i];\\n}'\n\n    # Test contract=False\n    assert ccode(expr, IndexedBase('y', shape=(5,)), contract=False) == \\\n        'y[i] = x[i];'\n", "def test_ccode_print_Symbol():\n    printer = CCodePrinter()\n    assert printer._print_Symbol(x) == 'x'\n", "def test_MatrixElement():\n    A = MatrixSymbol('A', 3, 3)\n    B = MatrixSymbol('B', 3, 3)\n    expr = A[0, 1] + B[1, 2]\n    assert ccode(expr, A[0, 0]) == \"A[0] = A[1] + B[5];\"\n", "def test_ccode_MatrixElement():\n    A = MatrixSymbol('A', 3, 3)\n    a = A[0, 0]\n    assert ccode(a) == 'A[0]'\n    assert ccode(a, assign_to='b') == 'b = A[0];'\n"], "sample_62": ["    def test_file_based_cache_set_get(self):\n        cache_name = \"default\"\n        cache_key = \"test_key\"\n        cache_value = \"test_value\"\n        cache = caches[cache_name]\n        cache.set(cache_key, cache_value)\n        self.assertEqual(cache.get(cache_key), cache_value)\n", "    def setUp(self):\n        self.cache = caches[\"default\"]\n", "    def setUp(self):\n        self.cache = caches[\"default\"]\n        self.cache.clear()\n", "    def setUp(self):\n        self.cache = caches[\"default\"]\n", "    def setUp(self):\n        self.cache = caches[\"default\"]\n        self.factory = RequestFactory()\n"], "sample_8": ["    def test_get_traceback_data(self):\n        request = RequestFactory().get('/')\n        reporter = ExceptionReporter(request, Exception, Exception('error'), None)\n        data = reporter.get_traceback_data()\n        self.assertIn('request', data)\n        self.assertIn('request_GET_items', data)\n        self.assertIn('request_FILES_items', data)\n        self.assertIn('request_COOKIES_items', data)\n", "    def test_cleanse_setting(self):\n        self.assertEqual(cleanse_setting('KEY', 'value'), CLEANSED_SUBSTITUTE)\n        self.assertEqual(cleanse_setting('OTHER', 'value'), 'value')\n", "    def test_get_traceback_data(self):\n        exc_type = ValueError\n        exc_value = ValueError('error message')\n        tb = mock.Mock()\n        request = RequestFactory().get('/')\n\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n\n        self.assertIn('exception_type', data)\n        self.assertIn('exception_value', data)\n        self.assertIn('frames', data)\n        self.assertIn('request', data)\n        self.assertIn('filtered_POST_items', data)\n        self.assertIn('settings', data)\n        self.assertIn('sys_executable', data)\n        self.assertIn('sys_version_info', data)\n        self.assertIn('server_time', data)\n        self.assertIn('django_version_info', data)\n        self.assertIn('sys_path', data)\n", "    def test_sensitive_key(self):\n        self.assertEqual(cleanse_setting('API_KEY', '123456'), CLEANSED_SUBSTITUTE)\n", "    def test_cleanse_sensitive_settings(self):\n        settings_dict = get_safe_settings()\n        self.assertIn('SOME_SECRET_SETTING', settings_dict)\n        self.assertEqual(settings_dict['SOME_SECRET_SETTING'], CLEANSED_SUBSTITUTE)\n        self.assertIn('SOME_PUBLIC_SETTING', settings_dict)\n        self.assertEqual(settings_dict['SOME_PUBLIC_SETTING'], 'public')\n"], "sample_101": ["def test_pipeline_get_params():\n    \"\"\"Test that get_params works correctly on a pipeline.\"\"\"\n    pipe = Pipeline([('step1', NoTrans()), ('step2', NoTrans())])\n    params = pipe.get_params()\n    assert params['steps'] == [('step1', NoTrans()), ('step2', NoTrans())]\n    assert params['step1__a'] is None\n    assert params['step2__b'] is None\n\n    pipe = Pipeline([('step1', NoTrans(a=1)), ('step2', NoTrans(b=2))])\n    params = pipe.get_params()\n    assert params['steps'] == [('step1', NoTrans(a=1)), ('step2', NoTrans(b=2))]\n    assert params['step1__a'] == 1\n    assert params['step2__b'] == 2\n\n    pipe = Pipeline([('step1', NoTrans(a=1, b=2)), ('step2', NoTrans())])\n    params = pipe.get_params()\n    assert params['steps'] == [('step1', NoTrans(a=1, b=2)), ('step2', NoTrans())]\n    assert params['step1__a'] == 1\n    assert params['step1__b'] == 2\n    assert 'step1__c' not in params\n\n    pipe = Pipeline([('step1', NoTrans(a=1, b=2)), ('step2', NoTrans())])\n    params = pipe.get_params(deep=False)\n    assert params['steps'] == [('step1', NoTrans(a=1, b=2)), ('step2', NoTrans())]\n    assert 'step1__a' not in params\n    assert 'step2__b' not in params\n", "def test_pipeline_with_weighted_union():\n    # Test that FeatureUnion with transformer_weights works in a pipeline\n    iris = load_iris()\n    X, y = iris.data, iris.target\n    union = FeatureUnion(\n        [(\"pca\", PCA(n_components=1)), (\"svd\", TruncatedSVD(n_components=1))],\n        transformer_weights={\"pca\": 10, \"svd\": 1}\n    )\n    pipe = Pipeline([(\"union\", union), (\"svc\", SVC())])\n    pipe.fit(X, y)\n    assert_array_almost_equal(pipe[\"union\"].transformer_weights_, [10, 1])\n\n    # Test with memory and transformer_weights\n    mem = Memory(location=mkdtemp(), verbose=0)\n    union = FeatureUnion(\n        [(\"pca\", PCA(n_components=1)), (\"svd\", TruncatedSVD(n_components=1))],\n        transformer_weights={\"pca\": 10, \"svd\": 1}, n_jobs=2\n    )\n    pipe = Pipeline([(\"union\", union), (\"svc\", SVC())], memory=mem)\n    pipe.fit(X, y)\n    assert_array_almost_equal(pipe[\"union\"].transformer_weights_, [10, 1])\n    shutil.rmtree(mem.location)\n", "def test_pipeline_feature_union_memory_cache():\n    \"\"\"Test that a Pipeline with a FeatureUnion and a Memory cache works.\"\"\"\n    # Use a Memory cache that stores results on disk\n    mem = Memory(location=mkdtemp())\n\n    # Create a Pipeline with a FeatureUnion and a Memory cache\n    pipe = Pipeline([\n        ('union', FeatureUnion([\n            ('pca', PCA(n_components=2)),\n            ('svd', TruncatedSVD(n_components=2)),\n        ])),\n        ('clf', SVC())\n    ], memory=mem)\n\n    # Fit the Pipeline\n    iris = load_iris()\n    pipe.fit(iris.data, iris.target)\n\n    # Check that the cache has been populated\n    assert len(mem.cache) > 0\n\n    # Try to fit again, this should be faster due to the cache\n    start_time = time.time()\n    pipe.fit(iris.data, iris.target)\n    end_time = time.time()\n    assert end_time - start_time < 1\n\n    # Clean up the temporary directory\n    shutil.rmtree(mem.location)\n", "def test_make_pipeline():\n    # test with list of estimators\n    pipeline = make_pipeline(StandardScaler(), LogisticRegression())\n    assert len(pipeline.steps) == 2\n    assert isinstance(pipeline.steps[0][1], StandardScaler)\n    assert isinstance(pipeline.steps[1][1], LogisticRegression)\n\n    # test with string and estimator\n    pipeline = make_pipeline('standardScaler', LogisticRegression())\n    assert len(pipeline.steps) == 2\n    assert isinstance(pipeline.steps[0][1], StandardScaler)\n    assert isinstance(pipeline.steps[1][1], LogisticRegression)\n\n    # test with estimators that have different parameter names\n    pipeline = make_pipeline(Mult(mult=2), LogisticRegression())\n    assert len(pipeline.steps) == 2\n    assert isinstance(pipeline.steps[0][1], Mult)\n    assert isinstance(pipeline.steps[1][1], LogisticRegression)\n    assert pipeline.steps[0][1].mult == 2\n\n    # test with memory parameter\n    memory = Memory(location='.', verbose=0)\n    pipeline = make_pipeline(StandardScaler(), LogisticRegression(), memory=memory)\n    assert len(pipeline.steps) == 2\n    assert pipeline.memory == memory\n\n    # test with invalid input\n    assert_raises(TypeError, make_pipeline, StandardScaler, 'invalid')\n\n    # test with estimators that have fit_params\n    pipeline = make_pipeline(TransfFitParams(), LogisticRegression())\n    assert len(pipeline.steps) == 2\n    assert isinstance(pipeline.steps[0][1], TransfFitParams)\n    assert isinstance(pipeline.steps[1][1], LogisticRegression)\n", "def test_pipeline_memory_joblib():\n    # Test if caching is working correctly with different joblib versions.\n    iris = load_iris()\n    X, y = iris.data, iris.target\n\n    # Create a pipeline with caching\n    memory = Memory(location=mkdtemp(), verbose=0)\n    pipe = Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=2))],\n                    memory=memory)\n\n    # Fit the pipeline\n    pipe.fit(X, y)\n\n    # Check if the cache is created\n    assert memory.location is not None\n    assert len(memory.cache) > 0\n\n    # Check if the cached result is used\n    pipe.fit(X, y)\n    assert len(memory.cache) == 1\n\n    # Clean up the cache directory\n    shutil.rmtree(memory.location)\n\n    # Test the case where the memory location is deleted between two fit calls\n    memory = Memory(location=mkdtemp(), verbose=0)\n    pipe = Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=2))],\n                    memory=memory)\n\n    # Fit the pipeline\n    pipe.fit(X, y)\n\n    # Remove the memory location\n    shutil.rmtree(memory.location)\n\n    # Check if the cache is recreated\n    pipe.fit(X, y)\n    assert len(memory.cache) > 0\n\n    # Clean up the cache directory\n    shutil.rmtree(memory.location)\n\n    # Check that the memory location is deleted after the pipeline is deleted\n    memory = Memory(location=mkdtemp(), verbose=0)\n    pipe = Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=2))],\n                    memory=memory)\n\n    del pipe\n    assert not memory.location.exists()\n\n    # Test for the case when fit_params are used\n    pipe = Pipeline([('transf', DummyTransf()), ('estim', LogisticRegression())],\n                    memory=memory)\n    pipe.fit(X, y, transf__a=0.5)\n    assert pipe.named_steps['transf'].timestamp_ != pipe.named_steps['transf'].fit(X, y, a=0.5).timestamp_\n\n    # Check if the memory is properly cleaned up when an exception is raised\n    class BrokenTransformer(Transf):\n            raise ValueError\n\n    pipe = Pipeline([('transf', BrokenTransformer())], memory=memory)\n    assert_raise_message(ValueError, pipe.fit, X, y)\n"], "sample_11": ["    def test_frozenset_serializer(self):\n        value = frozenset([1, 2, 3])\n        serializer = serializer_factory(value)\n        serialized_value, imports = serializer.serialize()\n        self.assertEqual(serialized_value, \"frozenset([1, 2, 3])\")\n        self.assertEqual(imports, set())\n", "    def test_serializer_factory_models_field(self):\n        field = models.CharField(max_length=255)\n        serializer = serializer_factory(field)\n        self.assertIsInstance(serializer, ModelFieldSerializer)\n", "    def test_float_serializer(self):\n        serializer = serializer_factory(1.0)\n        self.assertIsInstance(serializer, FloatSerializer)\n", "    def test_serializer_factory_for_regex(self):\n        # Test that serializer_factory can handle re.compile objects\n        regex = re.compile('test')\n        serializer = serializer_factory(regex)\n        self.assertIsInstance(serializer, RegexSerializer)\n        serialized_regex, imports = serializer.serialize()\n        self.assertEqual(serialized_regex, \"re.compile('test')\")\n        self.assertEqual(imports, {'import re'})\n", "    def test_serializer_factory(self):\n        tests = [\n            (datetime.date(2022, 1, 1), 'datetime.date(2022, 1, 1)', {'import datetime'}),\n            (datetime.datetime(2022, 1, 1, 0, 0, tzinfo=utc), \"datetime.datetime(2022, 1, 1, 0, 0, tzinfo=utc)\", {'import datetime', 'from django.utils.timezone import utc'}),\n            (decimal.Decimal('1.0'), \"Decimal('1.0')\", {'from decimal import Decimal'}),\n            (datetime.time(12, 0), 'datetime.time(12, 0)', {'import datetime'}),\n            (datetime.timedelta(days=1), 'datetime.timedelta(days=1)', {'import datetime'}),\n            (uuid.UUID('00000000-0000-0000-0000-000000000000'), \"uuid.UUID('00000000-0000-0000-0000-000000000000')\", {'import uuid'}),\n            (SettingsReference('SECRET_KEY', 'my_secret_key'), \"settings.SECRET_KEY\", {'from django.conf import settings'}),\n            (float('inf'), 'float(\"inf\")', set()),\n            (float('-inf'), 'float(\"-inf\")', set()),\n            (math.nan, 'float(\"nan\")', set()),\n            (functools.partial(lambda x: x), 'functools.partial(<function <lambda> at 0x...>)', {'import functools'}),\n            (lambda: None, '<function <lambda> at 0x...>', {'import types'}),\n            (Money('1.0'), 'Money(\"1.0\")', set()),\n            (re.compile(r'hello'), 're.compile(\"hello\")', {'import re'}),\n            (EmailValidator(), 'EmailValidator()', set()),\n            (RegexValidator(re.compile(r'hello')), 'RegexValidator(re.compile(\"hello\"))', {'import re'}),\n            (list(), '[]', set()),\n            (tuple(), '()', set()),\n            (set(), 'set()', set()),\n            (frozenset(), 'frozenset()', set()),\n            ({}, '{}', set()),\n            ({1, 2, 3}, '{1, 2, 3}', set()),\n            ({'a': 1, 'b': 2}, \"{'a': 1, 'b"], "sample_122": ["def test_col_op():\n    A = SparseMatrix(eye(3)*2)\n    A[0, 1] = -1\n    A.col_op(1, lambda v, i: v + 2*A[i, 0])\n    assert A == SparseMatrix([[2, 4, 0], [4, 0, 0], [0, 2, 2]])\n    \n    A = SparseMatrix(zeros(3))\n    raises(ValueError, lambda: A.col_op(3, lambda v, i: v))\n    \n    A = SparseMatrix(zeros(3))\n    raises(TypeError, lambda: A.col_op(1, 2))\n", "def test_sparse_matrix_col_join():\n    M = SparseMatrix(eye(3))\n    N = SparseMatrix(zeros(3, 4))\n    result = M.col_join(N)\n    assert result.shape == (3, 7)\n    assert result.rows == 3\n    assert result.cols == 7\n    assert result.nnz == 3\n", "def test_sparse_matrix():\n    # Test SparseMatrix init with generator\n    s = SparseMatrix(3, 3, ((1, 1), (1, 2), (2, 2), (2, 3)))\n    assert s.rows == 3\n    assert s.cols == 3\n    assert s[1, 1] == 1\n    assert s[1, 2] == 1\n    assert s[2, 2] == 1\n    assert s[2, 3] == 1\n\n    # Test SparseMatrix init with list\n    s = SparseMatrix(3, 3, [(1, 1), (1, 2), (2, 2), (2, 3)])\n    assert s.rows == 3\n    assert s.cols == 3\n    assert s[1, 1] == 1\n    assert s[1, 2] == 1\n    assert s[2, 2] == 1\n    assert s[2, 3] == 1\n\n    # Test SparseMatrix init with dict\n    s = SparseMatrix(3, 3, {(1, 1): 1, (1, 2): 1, (2, 2): 1, (2, 3): 1})\n    assert s.rows == 3\n    assert s.cols == 3\n    assert s[1, 1] == 1\n    assert s[1, 2] == 1\n    assert s[2, 2] == 1\n    assert s[2, 3] == 1\n\n    # Test SparseMatrix init with matrix\n    m = Matrix(3, 3, [(1, 2, 3), (4, 5, 6), (7, 8, 9)])\n    s = SparseMatrix(m)\n    assert s.rows == 3\n    assert s.cols == 3\n    assert s[0, 0] == 1\n    assert s[0, 1] == 2\n    assert s[0, 2] == 3\n    assert s[1, 0] == 4\n    assert s[1, 1] == 5\n    assert s[1, 2] == 6\n    assert s[2, 0]", "def test_col_list():\n    M = SparseMatrix(((1, 0), (0, 1), (0, 0)))\n    assert M.col_list() == [(0, 0, 1), (1, 1, 1)]\n    M = SparseMatrix(((0, 1, 0), (1, 0, 0), (0, 0, 1)))\n    assert M.col_list() == [(0, 1, 1), (1, 0, 1), (2, 2, 1)]\n    M = SparseMatrix(((0, 0, 0), (1, 2, 3), (0, 0, 0)))\n    assert M.col_list() == [(1, 0, 1), (1, 1, 2), (1, 2, 3)]\n", "def test_sparse_matrix():\n    s = Symbol('s')\n    M = SparseMatrix(2, 2, {(0, 0): s})\n    M2 = M.applyfunc(lambda x: Abs(x))\n    assert M2[0, 0] == Abs(s)\n\n    # Test empty matrix\n    M = SparseMatrix(2, 2, {})\n    assert M.applyfunc(lambda x: x) == M\n\n    # Test invalid input\n    raises(TypeError, lambda: M.applyfunc('invalid input'))\n\n    # Test with a symbolic expression\n    x = Symbol('x')\n    M = SparseMatrix(2, 2, {(0, 0): x})\n    assert M.applyfunc(lambda x: x**2)[0, 0] == x**2\n\n    # Test with a PurePoly\n    x = Symbol('x')\n    M = SparseMatrix(2, 2, {(0, 0): PurePoly(x**2 + 1, x)})\n    assert M.applyfunc(lambda x: x**2)[0, 0] == PurePoly((x**2 + 1)**2, x)\n\n    # Test with a matrix containing I\n    M = SparseMatrix(2, 2, {(0, 0): I})\n    assert M.applyfunc(lambda x: x**2)[0, 0] == -1\n\n    # Test with a matrix containing Rational\n    M = SparseMatrix(2, 2, {(0, 0): Rational(1, 2)})\n    assert M.applyfunc(lambda x: x**2)[0, 0] == Rational(1, 4)\n"], "sample_54": ["def test_json_script(self):\n    data = {\"key\": \"value\"}\n    expected_output = '<script type=\"application/json\">{}</script>'.format(\n        json.dumps(data, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n    )\n    self.check_output(json_script, data, expected_output)\n\n    element_id = \"test-id\"\n    expected_output = '<script id=\"{}\" type=\"application/json\">{}</script>'.format(\n        element_id, json.dumps(data, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n    )\n    self.check_output(json_script, data, element_id, expected_output)\n", "def test_json_script(self):\n    # Test json_script with a simple value\n    value = {\"key\": \"value\"}\n    expected_output = '<script type=\"application/json\">{&#34;key&#34;: &#34;value&#34;}</script>'\n    self.check_output(json_script, value, expected_output)\n\n    # Test json_script with a complex value\n    value = {\"key\": \"value\", \"list\": [1, 2, 3], \"dict\": {\"a\": 1, \"b\": 2}}\n    expected_output = (\n        '<script type=\"application/json\">'\n        '&#34;key&#34;: &#34;value&#34;, &#34;list&#34;: [1, 2, 3], &#34;dict&#34;: &#34;{' \n        '&#34;a&#34;: 1, &#34;b&#34;: 2}&#34;'\n        '}</script>'\n    )\n    self.check_output(json_script, value, expected_output)\n\n    # Test json_script with a custom encoder\n    class CustomEncoder(DjangoJSONEncoder):\n            if isinstance(obj, datetime):\n                return obj.isoformat()\n            return super().default(obj)\n\n    value = {\"date\": datetime(2022, 1, 1)}\n    expected_output = (\n        '<script type=\"application/json\">&#34;date&#34;: &#34;2022-01-01T00:00:00&#34;</script>'\n    )\n    self.check_output(json_script, value, expected_output, CustomEncoder)\n", "    def test_json_script(self):\n        data = {'foo': 'bar'}\n        expected_output = '<script id=\"my-id\" type=\"application/json\">{\"foo\": \"bar\"}</script>'\n        self.check_output(json_script, data, output=expected_output)\n        self.check_output(json_script, data, 'my-id', output=expected_output)\n", "def test_urlizer(self):\n    urlizer = Urlizer()\n    self.check_output(urlizer, \"Hello world\")\n    self.check_output(urlizer, \"Hello http://example.com world\")\n    self.check_output(urlizer, \"Hello www.example.com world\")\n    self.check_output(urlizer, \"Hello example@example.com world\")\n    self.check_output(urlizer, \"Hello https://example.com world\")\n    self.check_output(urlizer, \"Hello https://example.com/path/to/resource world\")\n    self.check_output(urlizer, \"Hello https://example.com/path/to/resource?query=string world\")\n    self.check_output(urlizer, \"Hello https://example.com/path/to/resource#anchor world\")\n", "def test_smart_urlquote(self):\n    test_urls = [\n        (\"https://example.com\", \"https://example.com\"),\n        (\"http://example.com\", \"http://example.com\"),\n        (\"www.example.com\", \"http://www.example.com\"),\n        (\"example.com\", \"http://example.com\"),\n        (\"http://example.com/path with spaces\", \"http://example.com/path%20with%20spaces\"),\n        (\"http://example.com/path%20with%20spaces\", \"http://example.com/path%20with%20spaces\"),\n        (\"http://example.com/path with spaces?query=string\", \"http://example.com/path%20with%20spaces?query=string\"),\n        (\"http://example.com/path with spaces#fragment\", \"http://example.com/path%20with%20spaces#fragment\"),\n    ]\n    for input_url, expected_url in test_urls:\n        self.check_output(smart_urlquote, input_url, expected_url)\n"], "sample_29": ["    def test_can_filter(self):\n        company_query = Company.objects.all()\n        self.assertTrue(company_query.can_filter())\n        company_query = Company.objects.all()[:10]\n        self.assertFalse(company_query.can_filter())\n        company_query = Company.objects.all()[1:10]\n        self.assertFalse(company_query.can_filter())\n        company_query = Company.objects.all()[:10:2]\n        self.assertFalse(company_query.can_filter())\n", "    def test_annotation_select(self):\n        alias = 'salary_sum'\n        company_query = self.company_query.annotate(salary_sum=Sum('ceo__salary'))\n        self.assertEqual(company_query.query.annotation_select, {alias: Sum(Col(alias, F('salary')))})\n        self.assertEqual(company_query.query.annotation_select_mask, {alias})\n\n        company_query = self.company_query.annotate(salary_sum=Sum('ceo__salary')).values('name', 'salary_sum')\n        self.assertEqual(company_query.query.annotation_select, {alias: Sum(Col(alias, F('salary'))})\n        self.assertEqual(company_query.query.annotation_select_mask, {alias})\n", "def test_names_to_path(self):\n    company_query = Company.objects.values(\n        \"name\", \"num_employees\", \"num_chairs\"\n    ).order_by(\n        \"name\", \"num_employees\", \"num_chairs\"\n    )\n\n    names_with_path, final_field, targets, names = company_query.query.names_to_path(\n        [\"name\"], company_query.model._meta, allow_many=True, fail_on_missing=True\n    )\n    self.assertEqual(names_with_path, [(\"name\", [])])\n    self.assertEqual(final_field, Company._meta.get_field(\"name\"))\n    self.assertEqual(targets, (Company._meta.get_field(\"name\"),))\n    self.assertEqual(names, [])\n\n    names_with_path, final_field, targets, names = company_query.query.names_to_path(\n        [\"ceo__firstname\"], company_query.model._meta, allow_many=True, fail_on_missing=True\n    )\n    self.assertEqual(names_with_path, [(\"ceo\", [\"ceo\"]), (\"firstname\", [])])\n    self.assertEqual(final_field, Employee._meta.get_field(\"firstname\"))\n    self.assertEqual(targets, (Employee._meta.get_field(\"firstname\"),))\n    self.assertEqual(names, [])\n\n    names_with_path, final_field, targets, names = company_query.query.names_to_path(\n        [\"ceo__firstname\", \"lastname\"], company_query.model._meta, allow_many=True, fail_on_missing=True\n    )\n    self.assertEqual(names_with_path, [(\"ceo\", [\"ceo\"]), (\"firstname\", []), (\"lastname\", [])])\n    self.assertEqual(final_field, Employee._meta.get_field(\"lastname\"))\n    self.assertEqual(targets, (Employee._meta.get_field(\"lastname\"),))\n    self.assertEqual(names, [])\n\n    with self.assertRaises(FieldError):\n        company_query.query.names_to_path(\n            [\"ceo__firstname\", \"nonexistent\"], company_query.model._meta, allow_many=True, fail_on_missing=True\n        )\n", "def test_join_with_default(self):\n    # Create a join with default join type.\n    join = Join(Company._meta.db_table, None)\n    self.assertIsNone(join.join_type)\n    query = Query(Company)\n    alias = query.join(join)\n    self.assertEqual(query.alias_map[alias].join_type, INNER)\n\n    # Create a join with nullable foreign key.\n    join = Join(Company._meta.db_table, None, join_field=Company._meta.get_field('ceo'))\n    self.assertIsNone(join.join_type)\n    query = Query(Company)\n    alias = query.join(join)\n    self.assertEqual(query.alias_map[alias].join_type, LOUTER)\n", "    def test_resolve_ref(self):\n        query = Company.objects.filter(name=\"Example Inc.\").query\n        with self.assertRaises(FieldError):\n            query.resolve_ref('nonexistent_field')\n        alias = query.resolve_ref('name').alias\n        self.assertEqual(alias, query.alias_map[query.get_initial_alias()].table_alias)\n        with self.assertRaises(FieldError):\n            query.resolve_ref('ceo__nonexistent_field')\n        ref = query.resolve_ref('ceo__firstname')\n        self.assertEqual(ref.alias, query.alias_map['T2'].table_alias)\n        self.assertIsInstance(ref, Col)\n        self.assertEqual(ref.target.column, 'firstname')\n        query = Company.objects.filter(name=\"Example Inc.\").annotate(x=RawSQL('1')).query\n        ref = query.resolve_ref('x')\n        self.assertIsInstance(ref, RawSQL)\n        self.assertEqual(ref.sql, '1')\n"], "sample_37": ["    def test_select_related_descend(self):\n        self.assertTrue(select_related_descend(\n            self.example_inc._meta.get_field('ceo'),\n            False,\n            {'ceo': ['firstname', 'lastname']},\n            {'id', 'firstname', 'lastname'}\n        ))\n        self.assertFalse(select_related_descend(\n            self.example_inc._meta.get_field('num_employees'),\n            False,\n            {'ceo': ['firstname', 'lastname']},\n            {'id', 'firstname', 'lastname'}\n        ))\n        self.assertFalse(select_related_descend(\n            self.example_inc._meta.get_field('ceo'),\n            True,\n            {'num_employees': ['num_chairs']},\n            {'id', 'firstname', 'lastname'}\n        ))\n        self.assertFalse(select_related_descend(\n            self.example_inc._meta.get_field('ceo'),\n            True,\n            {'ceo': ['firstname', 'lastname']},\n            {}\n        ))\n", "    def test_register_lookup_mixin(self):\n        class Lookup:\n            lookup_name = 'test_lookup'\n\n        class TestModel(Model):\n            class Meta:\n                app_label = 'test_app'\n\n        register = RegisterLookupMixin()\n        register.register_lookup(Lookup)\n        self.assertEqual(register.get_lookup('test_lookup'), Lookup)\n\n        # Test clearing cached lookups\n        register._clear_cached_lookups()\n        self.assertEqual(register.get_lookups.cache_info().currsize, 0)\n\n        # Test unregistering lookups\n        register._unregister_lookup(Lookup)\n        self.assertIsNone(register.get_lookup('test_lookup'))\n", "    def test_Q_combination(self):\n        q1 = Q(num_employees=10)\n        q2 = Q(num_chairs=5)\n        q3 = Q(name='Foobar Ltd.')\n\n        q = q1 & q2\n        self.assertEqual(q.connector, Q.AND)\n        self.assertEqual(q.children, [(q1, Q.AND), (q2, Q.AND)])\n\n        q = q1 | q2\n        self.assertEqual(q.connector, Q.OR)\n        self.assertEqual(q.children, [(q1, Q.OR), (q2, Q.OR)])\n\n        q = ~q3\n        self.assertEqual(q.connector, Q.AND)\n        self.assertEqual(q.children, [(q3, Q.AND)])\n        self.assertTrue(q.negated)\n\n        q = q1 & q2 & q3\n        self.assertEqual(q.connector, Q.AND)\n        self.assertEqual(q.children, [(q1, Q.AND), (q2, Q.AND), (q3, Q.AND)])\n\n        q = q1 | q2 | q3\n        self.assertEqual(q.connector, Q.OR)\n        self.assertEqual(q.children, [(q1, Q.OR), (q2, Q.OR), (q3, Q.OR)])\n", "    def test_select_related_descend(self):\n        self.assertTrue(select_related_descend(\n            self.example_inc._meta.get_field('ceo'),\n            restricted=False,\n            requested={'ceo': {}},\n            load_fields=None,\n            reverse=False\n        ))\n        self.assertFalse(select_related_descend(\n            self.example_inc._meta.get_field('ceo'),\n            restricted=True,\n            requested={},\n            load_fields=None,\n            reverse=False\n        ))\n", "    def test_resolve_expression_with_filter(self):\n        query = self.company_query.filter(num_employees__gte=100)\n        where_clause, joins = query.query._add_q(\n            Q(num_employees__gte=100), reuse=None, allow_joins=True, split_subq=False, check_filterable=False\n        )\n        self.assertEqual(where_clause, ('num_employees >= %s', [100]))\n        self.assertEqual(len(joins), 0)\n"], "sample_56": ["    def test_app_dirs_and_loaders(self):\n        errors = check_setting_app_dirs_loaders([], [])\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, E001.id)\n", "    def test_string_if_invalid_int(self):\n        errors = check_string_if_invalid_is_string(None)\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, E002.id)\n", "    def test_string_if_invalid_is_not_string(self):\n        errors = check_string_if_invalid_is_string(None)\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, E002.id)\n        self.assertEqual(\n            errors[0].msg, E002.msg.format(123, type(123).__name__)\n        )\n", "def test_check_setting_app_dirs_loaders_error(self):\n    errors = check_setting_app_dirs_loaders(None)\n    self.assertEqual(len(errors), 1)\n    self.assertEqual(errors[0].id, E001.id)\n    self.assertEqual(errors[0].msg, E001.msg)\n", "def test_setting_app_dirs_loaders(self):\n    expected_errors = [copy(E001)]\n    self.assertEqual(check_setting_app_dirs_loaders(None), expected_errors)\n    self.assertEqual(check_setting_app_dirs_loaders(None), expected_errors)\n\n"], "sample_88": ["def test_saferepr():\n    class ExceptionRaisingRepr:\n            raise Exception(\"Test exception\")\n\n    instance = ExceptionRaisingRepr()\n    result = saferepr(instance)\n    assert \"Exception('Test exception')\" in result\n    assert \"ExceptionRaisingRepr\" in result\n    assert \"object at\" in result\n\n", "def test_saferepr_exceptions():\n    class ExceptionalObject:\n            raise ZeroDivisionError(\"division by zero\")\n\n    obj = ExceptionalObject()\n    assert \"ZeroDivisionError\" in saferepr(obj)\n", "def test_saferepr_with_failing_repr():\n    class FailingRepr:\n            raise ValueError(\"failing repr\")\n\n    obj = FailingRepr()\n    result = saferepr(obj)\n    assert \"ValueError\" in result\n    assert \"failing repr\" in result\n    assert \"FailingRepr\" in result\n\n", "def test_saferepr_exception_handling():\n    class ErrorRaisingObject:\n            raise Exception(\"Something went wrong\")\n\n    obj = ErrorRaisingObject()\n    assert \"Exception(\" in saferepr(obj)\n", "def test_saferepr_on_non_string_object():\n    obj = [1, 2, 3, \"hello\", None, True]\n    result = saferepr(obj)\n    assert len(result) <= 240\n    assert all(str(item) in result for item in obj)\n\n"], "sample_74": ["def test_colorbar_extension_shape_proportional():\n    fig1 = _colorbar_extension_shape(spacing='proportional')\n    fig2 = _colorbar_extension_shape(spacing='proportional')\n    return fig1, fig2\n", "def test_colorbar_extension_shape():\n    \"\"\"Test the shape of colorbar extensions for uniform and proportional spacing.\"\"\"\n    fig1 = _colorbar_extension_shape('uniform')\n    fig2 = _colorbar_extension_shape('proportional')\n    return fig1, fig2\n", "def test_colorbar_extension_shape():\n    fig1 = _colorbar_extension_shape('uniform')\n    fig2 = _colorbar_extension_shape('proportional')\n    check_figures_equal(fig1, _colorbar_extension_shape('uniform'))\n    check_figures_equal(fig2, _colorbar_extension_shape('proportional'))\n    plt.close('all')\n", "def test_colorbar_extension_shapes():\n    \"\"\"\n    Test that colorbar extensions have the correct shapes when\n    extendrect is False (triangular) and True (rectangular) for\n    both uniform and proportional spacing.\n    \"\"\"\n    # Get a colormap and appropriate norms for each extension type.\n    cmap, norms = _get_cmap_norms()\n\n    # Create a figure and adjust whitespace for subplots.\n    fig = plt.figure()\n    fig.subplots_adjust(hspace=.3)\n    for i, extension_type in enumerate(('neither', 'min', 'max', 'both')):\n        # Get the appropriate norm and use it to get colorbar boundaries.\n        norm = norms[extension_type]\n        boundaries = values = norm.boundaries\n        values = values[:-1]\n        # Create a subplot for uniform spacing.\n        cax = fig.add_subplot(2, 4, i + 1)\n        Colorbar(cax, cmap=cmap, norm=norm,\n                 boundaries=boundaries, values=values,\n                 extend=extension_type,\n                 orientation='horizontal', spacing='uniform')\n        # Create a subplot for proportional spacing.\n        cax = fig.add_subplot(2, 4, i + 5)\n        Colorbar(cax, cmap=cmap, norm=norm,\n                 boundaries=boundaries, values=values,\n                 extend=extension_type,\n                 orientation='horizontal', spacing='proportional')\n        # Create a subplot for uniform spacing with rectangular extensions.\n        cax = fig.add_subplot(4, 4, i + 9)\n        Colorbar(cax, cmap=cmap, norm=norm,\n                 boundaries=boundaries, values=values,\n                 extend=extension_type, extendrect=True,\n                 orientation='horizontal', spacing='uniform')\n        # Create a subplot for proportional spacing with rectangular extensions.\n        cax = fig.add_subplot(4, 4, i + 13)\n        Colorbar(cax, cmap=cmap, norm=norm,\n                 boundaries=boundaries, values=values,\n                 extend=extension_type, extendrect=True,\n                 orientation='horizontal', spacing='proportional')\n    # Turn off text and ticks.\n    for ax in fig.axes:\n        ax.tick_params(left=False, labelleft=False,\n                      bottom=False, labelbottom=False)\n", "def test_colorbar_extension_length():\n    \"\"\"\n    Test the shape of colorbar extensions for various extension lengths and\n    spacings.\n    \"\"\"\n    # Test extension lengths for uniform and proportional spacing.\n    _colorbar_extension_length('uniform')\n    _colorbar_extension_length('proportional')\n\n"], "sample_111": ["def test_average_method_parameter():\n    # Test that an invalid average_method raises an error\n    with pytest.raises(ValueError,\n                      match=\"'average_method' must be 'min', 'geometric', \"\n                            \"'arithmetic', or 'max'\"):\n        adjusted_mutual_info_score(y1, y2, average_method=\"invalid\")\n\n    # Test that valid average methods do not raise errors\n    for average_method in ['min', 'geometric', 'arithmetic', 'max']:\n        adjusted_mutual_info_score(y1, y2, average_method=average_method)\n\n    # Test that valid average methods do not raise errors\n    for average_method in ['min', 'geometric', 'arithmetic', 'max']:\n        normalized_mutual_info_score(y1, y2, average_method=average_method)\n", "def test_entropy():\n    # Test empty input\n    assert_allclose(entropy([]), 1.0)\n    # Test single class\n    assert_allclose(entropy([1, 1, 1, 1]), 0.0)\n    # Test multiple classes\n    assert_allclose(entropy([1, 1, 2, 2, 3, 3]), np.log(3), atol=1e-10)\n    # Test random distribution\n    y = rng.randint(10, size=1000)\n    assert_allclose(entropy(y), np.log(10), atol=1e-2)\n", "def test_entropy():\n    # Test with a trivial case\n    assert_allclose(entropy(np.array([1, 1, 1, 1])), 0.0)\n\n    # Test with a case with 2 classes\n    assert_allclose(entropy(np.array([1, 1, 2, 2])), np.log(2))\n\n    # Test with a case with 3 classes\n    assert_allclose(entropy(np.array([1, 1, 2, 3, 3, 3])), np.log(3))\n\n    # Test with a case with 4 classes with different probabilities\n    assert_allclose(entropy(np.array([1, 1, 2, 2, 2, 3, 3, 3, 3])), np.log(4))\n\n    # Test with a case with one class\n    assert_allclose(entropy(np.array([1, 1, 1, 1, 1, 1])), 0.0)\n\n    # Test with an empty array\n    assert_allclose(entropy(np.array([])), 1.0)\n\n    # Test with a single element array\n    assert_allclose(entropy(np.array([1])), 0.0)\n", "def test_normalized_mutual_info_score_average_method():\n    y_pred = [1, 1, 1, 0, 0, 0]\n    y_true = [1, 1, 0, 0, 0, 0]\n    assert_allclose(normalized_mutual_info_score(y_true, y_pred, average_method='min'), 0.21609640474436814)\n    assert_allclose(normalized_mutual_info_score(y_true, y_pred, average_method='geometric'), 0.27415783464504377)\n    assert_allclose(normalized_mutual_info_score(y_true, y_pred, average_method='arithmetic'), 0.31127879124650744)\n    assert_allclose(normalized_mutual_info_score(y_true, y_pred, average_method='max'), 0.38685280723485663)\n\n    # test error handling\n    with pytest.raises(ValueError,\n                      match=\"'average_method' must be 'min', 'geometric', 'arithmetic', or 'max'\"):\n        normalized_mutual_info_score(y_true, y_pred, average_method='foo')\n", "def test_adjusted_mutual_info_score():\n    # Test with different averages methods\n    labels_true = np.array([0, 0, 0, 1, 1, 1])\n    labels_pred = np.array([0, 0, 1, 1, 0, 1])\n    score_max = adjusted_mutual_info_score(labels_true, labels_pred,\n                                          average_method='max')\n    score_min = adjusted_mutual_info_score(labels_true, labels_pred,\n                                          average_method='min')\n    score_geometric = adjusted_mutual_info_score(labels_true, labels_pred,\n                                                average_method='geometric')\n    score_arithmetic = adjusted_mutual_info_score(labels_true, labels_pred,\n                                                 average_method='arithmetic')\n\n    assert_allclose(score_max, 0.25649527382461273)\n    assert_allclose(score_min, 0.25649527382461273)\n    assert_allclose(score_geometric, 0.25649527382461273)\n    assert_allclose(score_arithmetic, 0.25649527382461273)\n\n    # Test with three classes\n    labels_true = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])\n    labels_pred = np.array([0, 0, 0, 1, 1, 2, 1, 2, 2])\n    score_max = adjusted_mutual_info_score(labels_true, labels_pred,\n                                          average_method='max')\n    score_min = adjusted_mutual_info_score(labels_true, labels_pred,\n                                          average_method='min')\n    score_geometric = adjusted_mutual_info_score(labels_true, labels_pred,\n                                                average_method='geometric')\n    score_arithmetic = adjusted_mutual_info_score(labels_true, labels_pred,\n                                                 average_method='arithmetic')\n\n    assert_allclose(score_max, 0.39634756716182357)\n    assert_allclose(score_min, 0.39634756716182357)\n    assert_allclose(score_geometric, 0.39634756716182357)\n    assert_allclose(score_arithmetic, 0.39634756716182357)\n\n    # Test with identical labels\n    labels_true = np.array([0, 0, 0, 0, 0, 0, 0])\n    labels_pred = np.array([0, 0, 0, 0, 0,"], "sample_47": ["def test_check_replacements(self):\n    \"\"\"\n    Test that check_replacements() correctly marks replacement migrations applied\n    when their replaced set all are.\n    \"\"\"\n    # Create a replacement migration that replaces two migrations.\n    migration = mock.Mock()\n    migration.replaces = [(\"app1\", \"0001_migration1\"), (\"app1\", \"0002_migration2\")]\n    self.loader.replacements = {(\"app1\", \"squashed\"): migration}\n\n    # Make sure the replaced migrations are marked as applied.\n    self.recorder.record_applied(\"app1\", \"0001_migration1\")\n    self.recorder.record_applied(\"app1\", \"0002_migration2\")\n\n    # Call check_replacements().\n    executor = MigrationExecutor(connection)\n    executor.check_replacements()\n\n    # The replacement migration should be marked as applied.\n    self.recorder.recorded_calls = []\n    self.recorder.record_applied.assert_called_once_with(\"app1\", \"squashed\")\n", "def test_migration_plan_with_replacements(self):\n    # Create a test app with a replacement migration\n    app_label = \"test_app\"\n    migration_name = \"0001_initial\"\n    replacement_name = \"0002 Replacement\"\n    self.create_test_app(app_label, \"migrations/test_executor/test_migration_plan_with_replacements\")\n    self.create_test_migration(app_label, migration_name, dependencies=[])\n    self.create_test_migration(app_label, replacement_name, dependencies=[(app_label, migration_name)], replaces=[(app_label, migration_name)])\n    self.add_initial_migration(app_label)\n    recorder = MigrationRecorder(connection)\n    recorder.record_applied(app_label, migration_name)\n    executor = MigrationExecutor(connection)\n\n    # Test the migration plan with the replacement migration\n    targets = [(app_label, replacement_name)]\n    plan = executor.migration_plan(targets)\n    self.assertEqual(len(plan), 1)\n    self.assertEqual(plan[0][0].name, replacement_name)\n\n    # Test the migration plan with the replaced migration\n    targets = [(app_label, migration_name)]\n    with self.assertRaises(InvalidMigrationPlan):\n        executor.migration_plan(targets)\n", "def test_detect_soft_applied(self):\n    \"\"\"\n    Test the detect_soft_applied method in MigrationExecutor.\n    \"\"\"\n\n    # Create a test app with an initial migration that creates a model\n    test_app = self.create_app(\"test_app\")\n    initial_migration = self.make_migration(test_app, operations=[\n        migrations.CreateModel(\"Model\", [\n            (\"id\", models.AutoField(primary_key=True)),\n        ]),\n    ])\n    executor = MigrationExecutor(connection)\n    recorder = MigrationRecorder(connection)\n\n    # Apply the migration\n    executor.apply_migration(ProjectState(), initial_migration, fake=False)\n\n    # Check that the migration is detected as applied\n    project_state = ProjectState()\n    result, _ = executor.detect_soft_applied(project_state, initial_migration)\n    self.assertTrue(result)\n\n    # Revert the migration\n    executor.unapply_migration(project_state, initial_migration, fake=False)\n\n    # Check that the migration is not detected as applied\n    project_state = ProjectState()\n    result, _ = executor.detect_soft_applied(project_state, initial_migration)\n    self.assertFalse(result)\n\n    # Test a migration that adds a field\n    add_field_migration = self.make_migration(test_app, operations=[\n        migrations.AddField(\"Model\", \"field\", models.IntegerField(null=True)),\n    ])\n    executor.apply_migration(project_state, add_field_migration, fake=False)\n\n    # Check that the migration is detected as applied\n    project_state = ProjectState()\n    result, _ = executor.detect_soft_applied(project_state, add_field_migration)\n    self.assertTrue(result)\n\n    # Revert the migration\n    executor.unapply_migration(project_state, add_field_migration, fake=False)\n\n    # Check that the migration is not detected as applied\n    project_state = ProjectState()\n    result, _ = executor.detect_soft_applied(project_state, add_field_migration)\n    self.assertFalse(result)\n", "def test_executor_migration_plan_with_replacement_migration(self):\n    \"\"\"\n    Test the migration plan generated by the executor when a replacement\n    migration is applied.\n    \"\"\"\n    with isolate_lru_cache():\n        # Create a migration graph with a replacement migration\n        migration_graph = MigrationGraph()\n        migration_graph.add_node((\"app1\", \"0001_initial\"), dependencies=[])\n        migration_graph.add_node((\"app1\", \"0002_replace\"), dependencies=[(\"app1\", \"0001_initial\")])\n        migration_graph.add_dependency((\"app1\", \"0002_replace\"), (\"app1\", \"0001_initial\"), \"replacement\")\n        migration_graph.add_node((\"app1\", \"0003_test\"), dependencies=[(\"app1\", \"0002_replace\")])\n\n        # Set up the migration recorder\n        migration_recorder = MigrationRecorder(connection)\n        migration_recorder.record_applied(\"app1\", \"0001_initial\")\n\n        # Create a migration executor\n        executor = MigrationExecutor(connection)\n\n        # Generate the migration plan\n        plan = executor.migration_plan([(\"app1\", \"0003_test\")])\n\n        # Check the plan\n        self.assertEqual(len(plan), 2)\n        self.assertEqual(plan[0][0].name, \"0002_replace\")\n        self.assertEqual(plan[1][0].name, \"0003_test\")\n\n        # Test the migration plan with clean_start=True\n        plan = executor.migration_plan([(\"app1\", \"0003_test\")], clean_start=True)\n        self.assertEqual(len(plan), 3)\n        self.assertEqual(plan[0][0].name, \"0001_initial\")\n        self.assertEqual(plan[1][0].name, \"0002_replace\")\n        self.assertEqual(plan[2][0].name, \"0003_test\")\n\n        # Test that the migration plan raises an error when both forwards and\n        # backwards migrations are in the plan\n        plan = [(\"app1\", \"0003_test\", False), (\"app1\", \"0001_initial\", True)]\n        with self.assertRaises(InvalidMigrationPlan):\n            executor.migrate(targets=[(\"app1\", \"0003_test\")], plan=plan)\n", "    def test_migration_plan_with_replaced_migration(self):\n        \"\"\"\n        Regression test for #21460: ensure the migration plan correctly\n        includes replaced migrations.\n        \"\"\"\n        # Create some test migrations\n        structure = {\n            'migrations': [\n                ('0001_initial', {\n                    ('CreateModel', 'Author', [\n                        ('name', models.CharField(max_length=200)),\n                    ]),\n                }),\n                ('0002_replaced', {\n                    migrations.ReplaceMigration('0001_initial', 'replaced_0001_initial'),\n                    ('CreateModel', 'Book', [\n                        ('author', models.ForeignKey('Author')),\n                        ('title', models.CharField(max_length=200)),\n                    ]),\n                }),\n                ('0003_add_field', {\n                    ('AddField', 'Book', 'page_count', models.IntegerField()),\n                }),\n            ],\n            'replaced': [\n                ('0001_initial', {\n                    ('CreateModel', 'Author', [\n                        ('name', models.CharField(max_length=200)),\n                    ]),\n                }),\n            ],\n        }\n        self.set_up_test_migration_structure(structure)\n\n        # Make some fake migration history\n        self.recorder.record_applied('migrations', '0002_replaced')\n        self.recorder.record_applied('migrations', '0003_add_field')\n\n        # Get the executor and loader\n        executor = MigrationExecutor(connection)\n        loader = executor.loader\n\n        # Make a migration plan to migrate up to the end\n        plan = executor.migration_plan([('migrations', None)])\n        self.assertEqual(len(plan), 3)\n\n        # Check the replaced migration is in the plan\n        replaced_migration = loader.get_migration('migrations', '0002_replaced')\n        self.assertIn(replaced_migration, [item[0] for item in plan])\n"], "sample_75": ["def test_imagegrid_init():\n    fig = plt.figure()\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode='single')\n    assert len(grid.cbar_axes) == 1\n    assert grid.cbar_axes[0].get_visible()\n\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode='each')\n    assert len(grid.cbar_axes) == 4\n    for ax in grid.cbar_axes:\n        assert ax.get_visible()\n\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode='edge')\n    assert len(grid.cbar_axes) == 2\n    for ax in grid.cbar_axes:\n        assert ax.get_visible()\n\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode=None)\n    assert len(grid.cbar_axes) == 4\n    for ax in grid.cbar_axes:\n        assert not ax.get_visible()\n", "def test_imagegrid_init():\n    # Test the initialization of ImageGrid\n    fig, ax = plt.subplots()\n    grid = ImageGrid(fig, 111, (2, 2), aspect=True, label_mode=\"L\")\n    assert grid.ngrids == 4\n    assert grid._nrows == 2\n    assert grid._ncols == 2\n    assert len(grid.axes_all) == 4\n", "def test_grid_init():\n    fig = plt.figure(figsize=(6, 6))\n    grid = Grid(fig, 111, (3, 3), label_mode=\"L\")\n    assert len(grid) == 9\n    assert grid.get_geometry() == (3, 3)\n    assert grid.get_aspect() is False\n    grid.set_aspect(True)\n    assert grid.get_aspect() is True\n    grid.set_axes_pad((0.03, 0.04))\n    assert grid.get_axes_pad() == (0.03, 0.04)\n\n", "def test_axesgrid_share_all():\n    fig = plt.figure(figsize=(10, 8))\n\n    grid = AxesGrid(fig, 111, nrows_ncols=(2, 2),\n                    label_mode=\"1\", share_all=True, aspect=False,\n                    cbar_location=\"right\", cbar_mode=\"single\")\n\n    for i, (im, ax) in enumerate(zip([np.random.rand(10, 10)] * 4, grid)):\n        im = ax.imshow(im)\n        ax.cax.colorbar(im)\n        ax.cax.toggle_label(True)\n\n    for ax in grid.axes_all:\n        ax.set_xticks([])\n        ax.set_yticks([])\n\n    grid.axes_llc.set_xticks([0, 5, 10])\n    grid.axes_llc.set_yticks([0, 5, 10])\n", "def test_grid_image():\n    fig = plt.figure(figsize=(6, 6))\n    grid = ImageGrid(fig, 111, (2, 2), label_mode=\"1\", axes_pad=0.5)\n    for ax in grid:\n        ax.set_xlim(0, 10)\n        ax.set_ylim(0, 10)\n        ax.set_xticks([1, 5, 9])\n        ax.set_yticks([1, 5, 9])\n        ax.grid(True)\n    ax = grid[0]\n    ax.add_patch(Circle((5, 5), 3, ec='r', fc='r'))\n    ax.set_xticklabels(['A', 'B', 'C'])\n    ax.set_yticklabels(['D', 'E', 'F'])\n    ax.grid(True)\n    return fig\n"], "sample_147": ["def test_derivative_free_symbols():\n    # test that free_symbols correctly includes variables of differentiation\n    # when they are functions\n    x = Symbol('x')\n    f = Function('f')\n    d = Derivative(f(x), x)\n    assert d.free_symbols == {x, f(x)}\n\n    # test that free_symbols does not include variables of differentiation\n    # when they are not functions\n    d = Derivative(x**2, x)\n    assert d.free_symbols == set()\n", "def test_nargs():\n    from sympy.core.function import Function\n    f1 = Function('f')\n    assert f1.nargs == S.Naturals0\n    f2 = Function('f', nargs=2)\n    assert f2.nargs == S.FiniteSet(2)\n    f3 = Function('f', nargs=(1, 2))\n    assert f3.nargs == S.FiniteSet(1, 2)\n    f4 = Function('f', nargs=0)\n    assert f4.nargs == S.FiniteSet(0)\n    f5 = Function('f', nargs=None)\n    assert f5.nargs == S.Naturals0\n    f6 = Function('f', nargs=(1, 3, 2))\n    assert f6.nargs == S.FiniteSet(1, 2, 3)\n", "def test_Derivative_kind():\n    D = Derivative\n    assert D(comm_x, comm_x).kind == NumberKind\n    assert D(noncomm_x, noncomm_x).kind == UndefinedKind\n    assert D(2, comm_x).kind == NumberKind\n    assert D(noncomm_x, comm_x, comm_x).kind == UndefinedKind\n    assert D(Mul(comm_x, comm_x, evaluate=False), comm_x).kind == UndefinedKind\n    assert D(Mul(comm_x, noncomm_x, evaluate=False), comm_x).kind == UndefinedKind\n    assert D(D(comm_x, comm_x), comm_x).kind == NumberKind\n    assert D(D(noncomm_x, noncomm_x), noncomm_x).kind == UndefinedKind\n    assert D(Integral(comm_x, (comm_x, 0, 1)), comm_x).kind == NumberKind\n    assert D(Integral(noncomm_x, (noncomm_x, 0, 1)), noncomm_x).kind == UndefinedKind\n    assert D(Matrix([[comm_x]]), comm_x).kind == MatrixKind\n    assert D(Matrix([[noncomm_x]]), noncomm_x).kind == MatrixKind\n    assert D(SparseMatrix([[comm_x]]), comm_x).kind == MatrixKind\n    assert D(SparseMatrix([[noncomm_x]]), noncomm_x).kind == MatrixKind\n    assert D(ImmutableMatrix([[comm_x]]), comm_x).kind == MatrixKind\n    assert D(ImmutableMatrix([[noncomm_x]]), noncomm_x).kind == MatrixKind\n    assert D(ImmutableSparseMatrix([[comm_x]]), comm_x).kind == MatrixKind\n    assert D(ImmutableSparseMatrix([[noncomm_x]]), noncomm_x).kind == MatrixKind\n    assert D(MatMul(comm_x, Matrix([[comm_x]])), comm_x).kind == MatrixKind\n    assert D(MatMul(noncomm_x, Matrix([[noncomm_x]])), noncomm_x).kind == MatrixKind\n    assert D(MatrixSymbol('M'), comm_x).kind == MatrixKind\n", "def test_derivative_variable_count():\n    # Test that Derivative._sort_variable_count returns the correct list\n    # of variables when the input is a tuple of tuples\n    D = Derivative\n    x, y = comm_x, Symbol('y')\n    assert D._sort_variable_count([(x, 2), (y, 3)]) == [(x, 2), (y, 3)]\n    assert D._sort_variable_count([(y, 2), (x, 3)]) == [(x, 3), (y, 2)]\n    assert D._sort_variable_count([(x, 2), (x, 3)]) == [(x, 5)]\n    assert D._sort_variable_count([(x, 2), (y, 3), (x, 1)]) == [(x, 3), (y, 3)]\n\n    # Test that Derivative._sort_variable_count returns the correct list\n    # of variables when the input is a list of tuples\n    assert D._sort_variable_count([(x, 2), (y, 3)]) == [(x, 2), (y, 3)]\n    assert D._sort_variable_count([(y, 2), (x, 3)]) == [(x, 3), (y, 2)]\n    assert D._sort_variable_count([(x, 2), (x, 3)]) == [(x, 5)]\n    assert D._sort_variable_count([(x, 2), (y, 3), (x, 1)]) == [(x, 3), (y, 3)]\n\n    # Test that Derivative._sort_variable_count raises an error when the input\n    # is not a list or tuple\n    try:\n        D._sort_variable_count('invalid')\n        assert False\n    except TypeError:\n        assert True\n", "    def test_Derivative_coverage(self):\n        # Check whether differentiation variables can be commutative or not\n        self.assertIsInstance(Derivative(comm_x**2, comm_x).doit(), Mul)\n        self.assertIsInstance(Derivative(noncomm_x**2, noncomm_x).doit(), Add)\n        \n        # Check the derivative of an Integral\n        x, y = symbols('x y')\n        i = Integral(x*y)\n        self.assertIsInstance(Derivative(i, x).doit(), Integral)\n        self.assertIsInstance(Derivative(i, y).doit(), Integral)\n        \n        # Check the derivative of a Matrix\n        M = Matrix([[1, 2], [3, 4]])\n        self.assertIsInstance(Derivative(M, x).doit(), Matrix)\n        self.assertIsInstance(Derivative(M, comm_x).doit(), Matrix)\n        \n        # Check the derivative of an ImmutableMatrix\n        M = ImmutableMatrix([[1, 2], [3, 4]])\n        self.assertIsInstance(Derivative(M, x).doit(), ImmutableMatrix)\n        self.assertIsInstance(Derivative(M, comm_x).doit(), ImmutableMatrix)\n        \n        # Check the derivative of a SparseMatrix\n        M = SparseMatrix([[1, 2], [3, 4]])\n        self.assertIsInstance(Derivative(M, x).doit(), SparseMatrix)\n        self.assertIsInstance(Derivative(M, comm_x).doit(), SparseMatrix)\n        \n        # Check the derivative of an ImmutableSparseMatrix\n        M = ImmutableSparseMatrix([[1, 2], [3, 4]])\n        self.assertIsInstance(Derivative(M, x).doit(), ImmutableSparseMatrix)\n        self.assertIsInstance(Derivative(M, comm_x).doit(), ImmutableSparseMatrix)\n        \n        # Check the derivative of a MatrixSymbol\n        M = MatrixSymbol('M', 2, 2)\n        self.assertIsInstance(Derivative(M, x).doit(), Derivative)\n        self.assertIsInstance(Derivative(M, comm_x).doit(), Derivative)\n"], "sample_115": ["def test_wrap_in_pandas_container():\n    # Test wrapping a numpy array\n    data = np.array([[1, 2], [3, 4]])\n    wrapped = _wrap_in_pandas_container(data, columns=[\"a\", \"b\"])\n    assert wrapped.shape == (2, 2)\n    assert wrapped.columns.tolist() == [\"a\", \"b\"]\n\n    # Test wrapping a pandas DataFrame\n    df = pd.DataFrame(data, columns=[\"a\", \"b\"])\n    wrapped = _wrap_in_pandas_container(df, columns=[\"c\", \"d\"])\n    assert wrapped.shape == (2, 2)\n    assert wrapped.columns.tolist() == [\"c\", \"d\"]\n\n    # Test wrapping with callable columns\n        return [\"e\", \"f\"]\n\n    wrapped = _wrap_in_pandas_container(data, columns=get_columns)\n    assert wrapped.shape == (2, 2)\n    assert wrapped.columns.tolist() == [\"e\", \"f\"]\n\n    # Test wrapping with sparse data raises an error\n    sparse_data = csr_matrix(data)\n    with pytest.raises(ValueError):\n        _wrap_in_pandas_container(sparse_data, columns=[\"a\", \"b\"])\n\n    # Test wrapping with None columns\n    wrapped = _wrap_in_pandas_container(data, columns=None)\n    assert wrapped.shape == (2, 2)\n    assert wrapped.columns.tolist() == [0, 1]\n\n    # Test wrapping a pandas DataFrame with None columns\n    df = pd.DataFrame(data, columns=[\"a\", \"b\"])\n    wrapped = _wrap_in_pandas_container(df, columns=None)\n    assert wrapped.shape == (2, 2)\n    assert wrapped.columns.tolist() == [\"a\", \"b\"]\n\n    # Test wrapping with index\n    wrapped = _wrap_in_pandas_container(data, columns=[\"a\", \"b\"], index=[1, 2])\n    assert wrapped.shape == (2, 2)\n    assert wrapped.columns.tolist() == [\"a\", \"b\"]\n    assert wrapped.index.tolist() == [1, 2]\n", "def test_wrap_in_pandas_container(data_to_wrap, columns, index, expected):\n    pd = pytest.importorskip(\"pandas\")\n    result = _wrap_in_pandas_container(data_to_wrap, columns=columns, index=index)\n    pd.testing.assert_frame_equal(result, expected)\n\n", "def test_wrap_in_pandas_container():\n    # Test that _wrap_in_pandas_container raises an error for sparse data\n    sparse_data = csr_matrix(np.array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]))\n    with pytest.raises(ValueError):\n        _wrap_in_pandas_container(sparse_data, columns=[\"A\", \"B\", \"C\"])\n\n    # Test that _wrap_in_pandas_container works with a callable for columns\n        return [\"A\", \"B\", \"C\"]\n\n    dense_data = np.array([[1, 2, 3], [4, 5, 6]])\n    wrapped_data = _wrap_in_pandas_container(dense_data, columns=get_columns())\n    assert_array_equal(wrapped_data.columns.values, np.array([\"A\", \"B\", \"C\"]))\n\n    # Test that _wrap_in_pandas_container works with an index\n    wrapped_data = _wrap_in_pandas_container(dense_data, columns=[\"A\", \"B\", \"C\"], index=[1, 2])\n    assert_array_equal(wrapped_data.index.values, np.array([1, 2]))\n\n    # Test that _wrap_in_pandas_container works with a DataFrame\n    df = pd.DataFrame(dense_data, columns=[\"A\", \"B\", \"C\"])\n    wrapped_data = _wrap_in_pandas_container(df, columns=[\"D\", \"E\", \"F\"])\n    assert_array_equal(wrapped_data.columns.values, np.array([\"D\", \"E\", \"F\"]))\n\n    # Test that _wrap_in_pandas_container works with None for columns\n    wrapped_data = _wrap_in_pandas_container(dense_data, columns=None)\n    assert_array_equal(wrapped_data.columns.values, np.array([0, 1, 2]))\n\n    # Test that _wrap_in_pandas_container works with None for columns and a DataFrame\n    df = pd.DataFrame(dense_data, columns=[\"A\", \"B\", \"C\"])\n    wrapped_data = _wrap_in_pandas_container(df, columns=None)\n    assert_array_equal(wrapped_data.columns.values, np.array([\"A\", \"B\", \"C\"]))\n\n", "def test_wrap_in_pandas_container(columns):\n    import pandas as pd\n    data_to_wrap = np.array([[1, 2], [3, 4]])\n    if columns == \"default\":\n        pd.testing.assert_frame_equal(\n            _wrap_in_pandas_container(data_to_wrap, columns=[0, 1], index=[0, 1]),\n            pd.DataFrame(data_to_wrap, columns=[0, 1], index=[0, 1]),\n        )\n    elif columns is None:\n        pd.testing.assert_frame_equal(\n            _wrap_in_pandas_container(data_to_wrap, columns=None, index=[0, 1]),\n            pd.DataFrame(data_to_wrap, columns=[0, 1], index=[0, 1]),\n        )\n    else:\n        pd.testing.assert_frame_equal(\n            _wrap_in_pandas_container(data_to_wrap, columns=columns, index=[0, 1]),\n            pd.DataFrame(data_to_wrap, columns=[\"a\", \"b\"], index=[0, 1]),\n        )\n", "def test_wrap_in_pandas_container_sparse_data():\n    # Test that sparse data raises an error\n    sparse_data = csr_matrix(np.array([[1, 0], [0, 2]]))\n    with pytest.raises(ValueError):\n        _wrap_in_pandas_container(sparse_data, columns=[1, 2])\n\n"], "sample_126": ["def test_mpf_norm():\n    # simplest case\n    assert mpf_norm((1, 5, 0, 3), 5) == (1, 5, 0, 3)\n    assert mpf_norm((1, 0, 3, 3), 5) == (0, 0, 0, 3)\n    assert mpf_norm((1, 0, -2, 3), 5) == (1, 0, -2, 3)\n    assert mpf_norm((1, 0, -2, 3), 5) == (1, 0, -2, 3)\n", "def test_comp():\n    assert comp(1.2, 1.2)\n    assert comp(1.2, 1.2, 1)\n    assert not comp(1.2, 1.3, 1)\n    assert comp(Float(1.2), 1.2)\n    assert comp(Float(1.2), 1.2, 1)\n    assert not comp(Float(1.2), 1.3, 1)\n\n    assert comp(1.2, '1.2')\n    assert comp(Float(1.2), '1.2')\n\n    assert not comp(1.2, '1.3', 1)\n    assert not comp(Float(1.2), '1.3', 1)\n\n    # Note the second term is returned as a Float\n    assert same_and_same_prec(comp(1.2, 1.3, 1e-10)[0], 1.2)\n    assert same_and_same_prec(comp(Float(1.2), 1.3, 1e-10)[0], 1.2)\n", "def test_mod_inverse():\n    assert mod_inverse(5, 3) == 2\n    assert mod_inverse(7, 11) == 8\n    assert mod_inverse(15, 22) == 13\n    assert mod_inverse(7, 7) == 1\n    assert mod_inverse(0, 4) == 0\n    assert mod_inverse(4, 0) == S.NaN\n    assert mod_inverse(-1, 3) == 2\n    assert mod_inverse(3, -7) == -5\n    assert mod_inverse(7, -11) == -8\n    assert mod_inverse(1, 1) == 1\n    assert mod_inverse(1, 7) == 1\n    assert mod_inverse(-1, 7) == 6\n    assert mod_inverse(-7, 1) == -0\n    assert mod_inverse(-7, -1) == -0\n    assert mod_inverse(1, -1) == -1\n    assert mod_inverse(1, -7) == -1\n    assert mod_inverse(-1, -7) == -6\n    assert mod_inverse(7, 7) == 1\n    assert mod_inverse(-7, 7) == 6\n    assert mod_inverse(7, -7) == -1\n    assert mod_inverse(-7, -7) == -6\n    assert mod_inverse(Rational(7, 9), 11) == Rational(7, 9)*8\n    assert mod_inverse(2, Rational(5, 9)) == 2*9/5\n", "def test_mod_inverse():\n    assert mod_inverse(Rational(3, 8), 5) == 7\n    assert mod_inverse(2, 3) == 2\n    assert mod_inverse(7, 4) == 7\n    assert mod_inverse(-3, 11) == 4\n    assert mod_inverse(1, 1) == 1\n    assert mod_inverse(1, 2) == 1\n    assert mod_inverse(2, 1) == 2\n    assert mod_inverse(1, S.Infinity) == 0\n    assert mod_inverse(1, -S.Infinity) == 0\n    assert mod_inverse(1, S.ComplexInfinity) == 0\n    assert mod_inverse(1, S.NegativeInfinity) == 0\n    assert mod_inverse(1, S.Zero) == S.ComplexInfinity\n    assert mod_inverse(1, nan) == nan\n\n    assert mod_inverse(7, 5) == 3\n\n    assert mod_inverse(Rational(1, 3), Rational(2, 3)) == 2\n\n    assert mod_inverse(Rational(1, 7), 10) == 3\n    assert mod_inverse(Rational(1, 7), 11) == 8\n\n    assert mod_inverse(Rational(7, 11), 10) == 7\n    assert mod_inverse(Rational(7, 11), 11) == 8\n\n    # Check that no inverse exists\n    assert mod_inverse(2, 4) == S.ComplexInfinity\n\n    # Check that no inverse exists (rational)\n    assert mod_inverse(Rational(4, 6), Rational(2, 3)) == S.ComplexInfinity\n\n    # Check that no inverse exists (sympy floats)\n    assert mod_inverse(Float(2.0), Float(4.0)) == S.ComplexInfinity\n\n    # Check that no inverse exists (mpmath floats)\n    assert mod_inverse(mpf(2.0), mpf(4.0)) == S.ComplexInfinity\n\n    # Check that no inverse exists (mixed types)\n    assert mod_inverse(2, Float(4)) == S.ComplexInfinity\n    assert mod_inverse(mpf(2), mpf(4)) == S.ComplexInfinity\n    assert mod_inverse(Float(2), mpf(4)) == S.ComplexInfinity", "def test_comp():\n    # test that Floats are equivalent\n    a = Float('0.1', 30)\n    b = Float('1e-1', 30)\n    assert a == b\n\n    # check that equivalence works to a specified tolerance\n    a = Float('0.1', 30)\n    b = Float('0.1', 30) + 1e-35\n    assert comp(a, b, 1e-30)\n\n    # check that different numbers are not equivalent\n    a = Float('0.1', 30)\n    b = Float('0.100000000000000000001', 30)\n    assert not comp(a, b)\n\n    # check that Float and non-Float can be compared\n    a = Float('0.1', 30)\n    b = Rational(1, 10)\n    assert comp(a, b)\n\n    # check that the tolerance does not affect the decision\n    a = Float('0.1', 30)\n    b = Rational(1, 10)\n    assert comp(a, b, 1e-30)\n\n    # check that non-Float and Float can be compared\n    a = Rational(1, 10)\n    b = Float('0.1', 30)\n    assert comp(a, b)\n\n    # test that Floats are equivalent when one of them is nan\n    a = Float('0.1', 30)\n    b = Float('0.1', 30) + nan\n    assert comp(a, b) == False\n\n    # test that Floats are not equivalent when one of them is nan\n    a = Float('0.1', 30)\n    b = nan\n    assert comp(a, b) == False\n\n    # check that comp works with non-Float, non-Rational, and non-Integer\n    a = Symbol('x')\n    b = 1\n    raises(TypeError, lambda: comp(a, b))\n\n    # test that non-Float, non-Rational, non-Integer comparison is not\n    # possible, also with a tolerance\n    a = Symbol('x')\n    b = 1\n    raises(TypeError, lambda: comp(a, b, 1e-5))\n\n    # Test that mpf tuples are not considered to be equal when the\n    # mantissa is zero\n    a = mpf_norm(_mpf_nan,"], "sample_138": ["def test_blockcut():\n    B = blockcut(ImmutableMatrix(4, 4, range(16)), (1, 3), (1, 3))\n    assert isinstance(B, BlockMatrix)\n    assert B.blocks.shape == (2, 2)\n    assert B.blocks[0, 0].shape == (1, 1)\n    assert B.blocks[0, 1].shape == (1, 3)\n    assert B.blocks[1, 0].shape == (3, 1)\n    assert B.blocks[1, 1].shape == (3, 3)\n", "def test_blockmatrix():\n    # Test creation of BlockMatrix\n    BM = BlockMatrix([[A, B], [C, D]])\n    assert BM.blocks == ImmutableMatrix([[A, B], [C, D]])\n\n    # Test blockshape\n    assert BM.blockshape == (2, 2)\n\n    # Test rowblocksizes\n    assert BM.rowblocksizes == [n, n]\n\n    # Test colblocksizes\n    assert BM.colblocksizes == [n, n]\n\n    # Test structurally_equal\n    BM2 = BlockMatrix([[A, B], [C, D]])\n    assert BM.structurally_equal(BM2)\n\n    # Test _blockmul\n    assert BM._blockmul(BM2).blocks == ImmutableMatrix([[A*BM2.blocks[0, 0], A*BM2.blocks[0, 1] + B*BM2.blocks[1, 0], B*BM2.blocks[1, 1]],\n                                                       [C*BM2.blocks[0, 0] + D*BM2.blocks[1, 0], C*BM2.blocks[0, 1] + D*BM2.blocks[1, 1]]])\n\n    # Test _blockadd\n    assert BM._blockadd(BM2).blocks == ImmutableMatrix([[A+BM2.blocks[0, 0], B+BM2.blocks[0, 1]], [C+BM2.blocks[1, 0], D+BM2.blocks[1, 1]]])\n\n    # Test _eval_transpose\n    assert BM._eval_transpose().blocks == ImmutableMatrix([[A.T, C.T], [B.T, D.T]])\n\n    # Test _eval_trace\n    assert BM._eval_trace() == A.trace() + D.trace()\n\n    # Test _eval_determinant\n    BM3 = BlockMatrix([[A, B], [ZeroMatrix(n, n), D]])\n    assert BM3._eval_determinant() == A.det() * D.det()\n\n    # Test as_real_imag\n    assert BM.as_real_imag() == (BM, BM)\n\n    # Test transpose\n    assert BM.transpose().blocks == ImmutableMatrix([[A.T, C.T], [B.T, D.T]])\n\n    # Test _entry\n    assert BM._entry(1, 1) == D\n\n    # Test is_Identity\n    BM4 = BlockMatrix([[Identity(n), ZeroMatrix(n", "def test_blockmatrix():\n    n = 3\n    M = ImmutableMatrix(n, n, range(n*n))\n    B = blockcut(M, (1, 2), (1, 2))\n    assert B.blocks.shape == (2, 2)\n    assert B.blocks[0, 0].shape == (1, 1)\n    assert B.blocks[0, 1].shape == (1, 2)\n    assert B.blocks[1, 0].shape == (2, 1)\n    assert B.blocks[1, 1].shape == (2, 2)\n    assert ImmutableMatrix(B) == M\n", "def test_blockcut():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (1, 3))\n    assert isinstance(B, BlockMatrix)\n    assert ImmutableMatrix(B.blocks[0, 1]).tolist() == [[1, 2, 3]]\n\n    M = ImmutableSparseMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (1, 3))\n    assert isinstance(B, BlockMatrix)\n    assert ImmutableMatrix(B.blocks[0, 1]).tolist() == [[1, 2, 3]]\n", "def test_block_collapse():\n    # Test block_collapse with a BlockDiagMatrix\n    bdm = BlockDiagMatrix(A, B)\n    res = block_collapse(bdm)\n    assert res == bdm\n\n    # Test block_collapse with a non-block matrix\n    M = ImmutableMatrix(2, 2, [1, 2, 3, 4])\n    res = block_collapse(M)\n    assert res == M\n\n    # Test block_collapse with a block matrix and a scalar\n    b = BlockMatrix([[A, B], [C, D]])\n    res = block_collapse(2 * b)\n    assert res == 2 * b\n"], "sample_117": ["def test_restify():\n    assert restify(MyClass1) == ':class:`test_util_typing.MyClass1`'\n    assert restify(MyClass2) == ':class:`test_util_typing.MyClass2`'\n    assert restify(MyList) == ':class:`test_util_typing.MyList`\\\\ [T]'\n    assert restify(MyInt) == ':class:`MyInt`'\n    assert restify(int) == ':class:`int`'\n    assert restify(str) == ':class:`str`'\n    assert restify(List) == ':class:`list`'\n    assert restify(Dict) == ':class:`dict`'\n    assert restify(Union) == ':obj:`Union`'\n    assert restify(Optional[int]) == ':obj:`Optional`\\\\ [:obj:`int`]'\n    assert restify(Callable[[int], str]) == ':class:`Callable`\\\\ [[int], :class:`str`]'\n    assert restify(Tuple[int, str]) == ':class:`tuple`\\\\ [:class:`int`, :class:`str`]'\n    assert restify(Any) == ':obj:`Any`'\n    assert restify(NoneType) == ':obj:`None`'\n    assert restify(Ellipsis) == '...'\n    assert restify(Struct) == ':class:`struct.Struct`'\n    assert restify(BrokenType) == ':obj:`test_util_typing.BrokenType`'\n", "def test_stringify():\n    assert stringify(int) == 'int'\n    assert stringify(str) == 'str'\n    assert stringify(float) == 'float'\n    assert stringify(bool) == 'bool'\n    assert stringify(complex) == 'complex'\n    assert stringify(None) == 'None'\n    assert stringify(Ellipsis) == '...'\n    assert stringify(Struct) == 'struct.Struct'\n    assert stringify(Integral) == 'numbers.Integral'\n    assert stringify(Callable) == 'typing.Callable'\n    assert stringify(Generic) == 'typing.Generic'\n    assert stringify(Tuple) == 'tuple'\n    assert stringify(List) == 'list'\n    assert stringify(Dict) == 'dict'\n    assert stringify(Union) == 'Union'\n    assert stringify(Optional) == 'Optional'\n    assert stringify(Any) == 'typing.Any'\n    assert stringify(MyClass1) == ':class:`test_util_typing.MyClass1`'\n    assert stringify(MyClass2) == ':class:`MyClass2`'\n    assert stringify(MyInt) == 'MyInt'\n    assert stringify(MyList[int]) == ':class:`test_util_typing.MyList`\\\\ [int]'\n    assert stringify(BrokenType) == 'test_util_typing.BrokenType'\n", "def test_restify_on_builtins():\n    assert restify(int) == ':class:`int`'\n    assert restify(float) == ':class:`float`'\n    assert restify(str) == ':class:`str`'\n    assert restify(list) == ':class:`list`'\n    assert restify(dict) == ':class:`dict`'\n    assert restify(tuple) == ':class:`tuple`'\n\n", "def test_restify():\n    assert restify(None) == ':obj:`None`'\n    assert restify(Struct) == ':class:`struct.Struct`'\n    assert restify(MyClass1) == ':class:`test_util_typing.MyClass1`'\n    assert restify(MyClass2) == ':class:`test_util_typing.<MyClass2>`'\n    assert restify(MyList) == ':class:`test_util_typing.MyList`\\\\ [~T]'  # coverage for generic alias\n    assert restify(BrokenType) == ':class:`test_util_typing.BrokenType`'  # coverage for broken __args__\n    assert restify(Any) == ':obj:`Any`'\n    assert restify(Callable) == ':class:`Callable`'\n    assert restify(Dict) == ':class:`Dict`'\n    assert restify(Generator) == ':class:`Generator`'\n    assert restify(List) == ':class:`List`'\n    assert restify(Tuple) == ':class:`Tuple`'\n    assert restify(TypeVar) == ':obj:`TypeVar`'\n    assert restify(Union) == ':obj:`Union`'\n    assert restify(Integral) == ':class:`numbers.Integral`'\n    assert restify(MyInt) == ':class:`MyInt`'  # coverage for NewType\n", "def test_restify():\n    # test type aliases\n    assert restify(MyInt) == ':class:`MyInt`'\n    # test generic types\n    assert restify(MyList[int]) == ':class:`MyList`\\\\ [\\\\:class:`int`]'\n    # test unbounded TypeVars\n    assert restify(MyList[T]) == ':class:`MyList`\\\\ [T]'\n    # test struct.Struct\n    assert restify(Struct) == ':class:`struct.Struct`'\n    # test broken types\n    assert restify(BrokenType) == ':obj:`BrokenType`'\n\n"], "sample_63": ["    def test_read_only_password_hash_widget(self):\n        widget = ReadOnlyPasswordHashWidget()\n        self.assertEqual(widget.template_name, \"auth/widgets/read_only_password_hash.html\")\n        self.assertTrue(widget.read_only)\n", "    def test_widget_attrs(self):\n        field = ReadOnlyPasswordHashField()\n        widget = field.widget\n        self.assertEqual(widget.template_name, \"auth/widgets/read_only_password_hash.html\")\n        self.assertTrue(widget.read_only)\n", "    def test_user_creation_form_password_mismatch(self):\n        form_data = {\n            \"username\": \"testuser\",\n            \"password1\": \"password123\",\n            \"password2\": \"password456\",\n        }\n        form = UserCreationForm(data=form_data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(len(form.errors), 1)\n        self.assertIn(\"password2\", form.errors)\n", "    def test_render(self):\n        widget = ReadOnlyPasswordHashWidget()\n        output = widget.render(\"password\", \"pbkdf2_sha256$260000$ blah...\")\n        self.assertInHTML(\n            '<span class=\"password-summary\">Algorithm: <strong>PBKDF2 SHA256</strong></span>',\n            output,\n        )\n        self.assertInHTML(\n            '<span class=\"password-summary\">Iterations: <strong>260000</strong></span>',\n            output,\n        )\n        self.assertInHTML(\n            '<span class=\"password-summary\">Salt: <strong>...</strong></span>',\n            output,\n        )\n        self.assertInHTML(\n            '<span class=\"password-summary\">Hash: <strong>...</strong></span>',\n            output,\n        )\n", "    def test_read_only_password_hash_field(self):\n        field = ReadOnlyPasswordHashField()\n        self.assertEqual(field.widget.attrs[\"readonly\"], True)\n        self.assertEqual(field.widget.template_name, \"auth/widgets/read_only_password_hash.html\")\n"], "sample_31": ["    def test_ipython_interface(self):\n        with mock.patch('IPython.start_ipython') as mock_start_ipython:\n            call_command('shell', interface='ipython')\n            mock_start_ipython.assert_called_once_with(argv=[])\n", "def test_interface_argument(self):\n    with self.assertRaisesMessage(CommandError, \"Couldn't import invalid interface.\"):\n        call_command('shell', interface='invalid')\n", "    def test_handle_interface_choice(self, mock_bpython, mock_ipython):\n        call_command('shell', interface='ipython')\n        mock_ipython.assert_called_once()\n        mock_bpython.assert_not_called()\n\n        call_command('shell', interface='bpython')\n        mock_bpython.assert_called_once()\n        mock_ipython.assert_called_once()\n", "    def test_handle_command(self, mock_get_commands, mock_call_command):\n        call_command('shell', command=self.script_globals)\n        mock_call_command.assert_called_once_with(\n            'shell', '--command', self.script_globals, interactive=False\n        )\n", "def test_interface_argument(self):\n    with self.assertRaises(CommandError) as cm:\n        call_command('shell', interface='nonexistent')\n    self.assertEqual(str(cm.exception), \"Couldn't import nonexistent interface.\")\n"], "sample_81": ["def test_fixme_note_tags(self):\n    # Test that note tags are correctly detected and reported.\n    set_config(self.linter, notes=(\"FIXME\", \"XXX\", \"TODO\"))\n    code = \"# FIXME: this is a fixme note\"\n    messages = self.checker.visit_tokens(_tokenize_str(code))\n    self.assertEqual(len(messages), 1)\n    self.assertIsInstance(messages[0], MessageTest)\n    self.assertEqual(messages[0].symbol, \"fixme\")\n", "def test_fixme_in_disabled_pragma(self):\n    \"\"\"Test fixme in disabled pragma is not reported.\"\"\"\n    set_config(self, notes=(\"FIXME\",))\n    code = \"\"\"", "    def test_check_encoding_valid_ascii(self):\n        module = \"\"\"", "    def test_fixme_disabled_by_pragma(self):\n        code = \"\"\"\n        # pylint: disable=fixme\n        # FIXME: This is a disabled fixme\n        \"\"\"\n        with set_config(self.linter, notes=(\"FIXME\",)):\n            self.linter.check(_tokenize_str(code))\n            self.assertEqual(self.linter.stats.error, 0)\n            self.assertEqual(self.linter.stats.warning, 0)\n", "    def test_encoding_declaration(self):\n        set_config(self.linter, notes=['FIXME'])\n        with self.assertAddsMessages(\n            MessageTest('fixme', line=1, args='FIXME')\n        ):\n            self.checker.open()\n            self.checker.process_tokens(_tokenize_str('# -*- coding: utf-8 -*-\\n# FIXME'))\n            self.checker.open()\n            self.checker.process_module(self.get_module('''\n                # -*- coding: utf-8 -*-\n                # FIXME\n            '''))\n"], "sample_114": ["def test_class_distribution():\n    # Test with dense array\n    y = np.array([[1, 0], [0, 1], [1, 1]])\n    classes, n_classes, class_prior = class_distribution(y)\n    assert_array_equal(classes, [np.array([0, 1]), np.array([0, 1])])\n    assert_array_equal(n_classes, [2, 2])\n    assert_array_almost_equal(class_prior, [np.array([2. / 3, 1. / 3]), np.array([1. / 3, 2. / 3])])\n\n    # Test with sparse array\n    y = csc_matrix(np.array([[1, 0], [0, 1], [1, 1]]))\n    classes, n_classes, class_prior = class_distribution(y)\n    assert_array_equal(classes, [np.array([0, 1]), np.array([0, 1])])\n    assert_array_equal(n_classes, [2, 2])\n    assert_array_almost_equal(class_prior, [np.array([2. / 3, 1. / 3]), np.array([1. / 3, 2. / 3])])\n\n    # Test with sample weights\n    y = np.array([[1, 0], [0, 1], [1, 1]])\n    sample_weight = np.array([1, 1, 0.5])\n    classes, n_classes, class_prior = class_distribution(y, sample_weight)\n    assert_array_equal(classes, [np.array([0, 1]), np.array([0, 1])])\n    assert_array_equal(n_classes, [2, 2])\n    assert_array_almost_equal(class_prior, [np.array([5. / 6, 1. / 6]), np.array([1. / 6, 5. / 6])])\n", "def test_class_distribution():\n    # Test for multilabel-indicator format\n    y = np.array([[0, 1], [1, 1], [0, 0]])\n    classes, n_classes, class_prior = class_distribution(y)\n    assert_array_equal(classes, [np.array([0, 1])])\n    assert_array_equal(n_classes, [2])\n    assert_array_almost_equal(class_prior, [np.array([2 / 3, 1 / 3])])\n\n    # Test for multiclass format\n    y = np.array([[0, 1], [1, 0], [0, 0]])\n    classes, n_classes, class_prior = class_distribution(y)\n    assert_array_equal(classes, [np.array([0, 1])])\n    assert_array_equal(n_classes, [2])\n    assert_array_almost_equal(class_prior, [np.array([2 / 3, 1 / 3])])\n\n    # Test for multiclass-multioutput format\n    y = np.array([[0, 1, 0], [1, 0, 1], [0, 0, 0]])\n    classes, n_classes, class_prior = class_distribution(y)\n    assert_array_equal(classes, [np.array([0, 1]), np.array([0, 1])])\n    assert_array_equal(n_classes, [2, 2])\n    assert_array_almost_equal(class_prior, [np.array([2 / 3, 1 / 3]), np.array([2 / 3, 1 / 3])])\n\n    # Test with sample_weight\n    y = np.array([[0, 1], [1, 1], [0, 0]])\n    sample_weight = np.array([1, 2, 3])\n    classes, n_classes, class_prior = class_distribution(y, sample_weight)\n    assert_array_equal(classes, [np.array([0, 1])])\n    assert_array_equal(n_classes, [2])\n    assert_array_almost_equal(class_prior, [np.array([5 / 6, 1 / 6])])\n\n    # Test with sparse matrix\n    y = csr_matrix(np.array([[0, 1], [1, 1], [0, 0]]))\n    classes, n_classes, class_prior = class_distribution(y)\n    assert_array_equal(classes, [np.array([0, 1])])\n    assert_array_equal(n_classes, [2])\n", "def test_unique_labels(y, expected):\n    ys_types = set(type_of_target(y) for y in [y])\n    unique_labels_set = set(unique_labels(y))\n    expected_set = set(expected)\n    assert unique_labels_set == expected_set\n", "def test_unique_labels_multilabel():\n    # Test unique_labels with multilabel indicator input\n    y1 = np.array([[0, 1], [1, 1]])\n    y2 = np.array([[0, 0], [1, 0]])\n    expected = np.array([0, 1])\n    assert_array_equal(unique_labels(y1, y2), expected)\n", "def test_type_of_target_mixed_types():\n    # Test that type_of_target raises an error when input contains mixed types\n    with pytest.raises(ValueError):\n        type_of_target(y=[1, 2, \"a\", 3], input_name=\"y\")\n\n    with pytest.raises(ValueError):\n        type_of_target(y=[1.0, 2.0, \"a\", 3.0], input_name=\"y\")\n\n    with pytest.raises(ValueError):\n        type_of_target(y=[\"a\", \"b\", 1, 2], input_name=\"y\")\n\n    with pytest.raises(ValueError):\n        type_of_target(y=[1, 2, 1.0, 3.0], input_name=\"y\")\n"], "sample_130": ["def test_lambdify_with_typed_arguments():\n    x = symbols('x', real=True)\n    f = lambdify(x, x**2, 'numpy')\n    assert f(2) == 4\n    assert f(2.0) == 4.0\n    raises(TypeError, lambda: f(\"a\"))\n", "def test_lambdify_functional_args():\n    x, y, z = symbols('x,y,z')\n    f = lambdify((x, (y, z)), x + y + z, 'math')\n    assert f(1, (2, 3)) == 6\n    f = lambdify(((x, y), z), x + y + z, 'math')\n    assert f((1, 2), 3) == 6\n    f = lambdify(((x, (y, z)),), x + y + z, 'math')\n    assert f(((1, (2, 3)),)) == 6\n", "def test_lambdify_with_implemented_function():\n    f = implemented_function(Function('f'), lambda x: x**2)\n    expr = f(x)\n    func = lambdify(x, expr)\n    assert func(2) == 4\n", "def test_lambdify_with_mpmath_modules():\n    @conservempmath_dps(20)\n        mpmath.mp.dps = dps\n        f = lambdify(x, exp(x), mpmath)\n        assert mpmath.nstr(f(1), 20) == mpmath.nstr(mpmath.exp(1), 20)\n        assert mpmath.nstr(f(1), 50) == mpmath.nstr(mpmath.exp(1), 50)\n\n    test_mpmath(20)\n    test_mpmath(50)\n", "def test_lambdify_keywords():\n    x, y = symbols('x y')\n    f = lambdify((x, y), x + y)\n    assert f(x=1, y=2) == 3\n    f = lambdify(x, x + y)\n    assert f(x=1) == y + 1\n"], "sample_131": ["def test_mcode():\n    assert mcode(x**2) == 'x^2'\n    assert mcode(x**-2) == 'x^(-2)'\n    assert mcode(x**0.5) == 'x^0.5'\n    assert mcode(S(3)/2) == '3/2'\n    assert mcode(pi) == 'Pi'\n    assert mcode(oo) == 'Infinity'\n    assert mcode(-oo) == '-Infinity'\n    assert mcode(exp(x)) == 'Exp[x]'\n    assert mcode(sin(x)) == 'Sin[x]'\n    assert mcode(cos(x)) == 'Cos[x]'\n    assert mcode(conjugate(x)) == 'Conjugate[x]'\n    assert mcode(Max(x, y, z)) == 'Max[x, y, z]'\n    assert mcode(Min(x, y, z)) == 'Min[x, y, z]'\n    assert mcode(Integral(x**2, x)) == 'Hold[Integrate[x^2, x]]'\n    assert mcode(Sum(x**2, (x, 1, 10))) == 'Hold[Sum[x^2, {x, 1, 10}]]'\n    assert mcode(Derivative(x**2, x)) == 'Hold[D[x^2, x]]'\n    assert mcode(Derivative(f(x), x)) == 'f[x]'\n    assert mcode(Tuple(x, y, z)) == '{x, y, z}'\n    assert mcode((x, y, z)) == '{x, y, z}'\n", "def test_mcode_printer():\n    # Test Pow\n    assert mcode(x**2) == 'x^2'\n\n    # Test Mul\n    assert mcode(x*y) == 'x*y'\n    assert mcode(x*y*z) == 'x*y*z'\n\n    # Test Pi\n    assert mcode(pi) == 'Pi'\n\n    # Test Infinity and NegativeInfinity\n    assert mcode(oo) == 'Infinity'\n    assert mcode(-oo) == '-Infinity'\n\n    # Test List, Tuple and Tuple\n    assert mcode([1, 2, 3]) == '{1, 2, 3}'\n    assert mcode((1, 2, 3)) == '{1, 2, 3}'\n    assert mcode(Tuple(1, 2, 3)) == '{1, 2, 3}'\n\n    # Test Function\n    assert mcode(sin(x)) == 'Sin[x]'\n    assert mcode(cos(x)) == 'Cos[x]'\n    assert mcode(conjugate(x)) == 'Conjugate[x]'\n    assert mcode(Max(x, y)) == 'Max[x, y]'\n    assert mcode(Min(x, y)) == 'Min[x, y]'\n\n    # Test Integral\n    assert mcode(Integral(x, x)) == 'Hold[Integrate[x, x]]'\n    assert mcode(Integral(x**2, (x, 0, 1))) == 'Hold[Integrate[x**2, {x, 0, 1}]]'\n\n    # Test Sum\n    assert mcode(Sum(x, (x, 0, 10))) == 'Hold[Sum[x, {x, 0, 10}]]'\n\n    # Test Derivative\n    assert mcode(Derivative(x**2, x)) == 'Hold[D[x**2, x]]'\n    assert mcode(Derivative(x**2, (x, 2))) == 'Hold[D[x**2, {x, 2}]]'\n\n    # Test user functions\n    assert mcode(f(x), user_functions={'f': 'myf'}) == 'myf[x]'\n\n    # Test allow_unknown_functions\n    assert mcode(f(x), allow_unknown_functions=True) == 'f[x]'\n", "def test_mcode():\n    # test functions\n    assert mcode(exp(x)) == 'Exp[x]'\n    assert mcode(sin(x)) == 'Sin[x]'\n    assert mcode(cos(x)) == 'Cos[x]'\n    assert mcode(tan(x)) == 'Tan[x]'\n    assert mcode(cot(x)) == 'Cot[x]'\n    assert mcode(asin(x)) == 'ArcSin[x]'\n    assert mcode(acos(x)) == 'ArcCos[x]'\n    assert mcode(atan(x)) == 'ArcTan[x]'\n    assert mcode(sinh(x)) == 'Sinh[x]'\n    assert mcode(cosh(x)) == 'Cosh[x]'\n    assert mcode(tanh(x)) == 'Tanh[x]'\n    assert mcode(coth(x)) == 'Coth[x]'\n    assert mcode(sech(x)) == 'Sech[x]'\n    assert mcode(csch(x)) == 'Csch[x]'\n    assert mcode(asinh(x)) == 'ArcSinh[x]'\n    assert mcode(acosh(x)) == 'ArcCosh[x]'\n    assert mcode(atanh(x)) == 'ArcTanh[x]'\n    assert mcode(acoth(x)) == 'ArcCoth[x]'\n    assert mcode(asech(x)) == 'ArcSech[x]'\n    assert mcode(acsch(x)) == 'ArcCsch[x]'\n    assert mcode(conjugate(x)) == 'Conjugate[x]'\n\n    # test power\n    assert mcode(x**3) == 'x^3'\n    assert mcode(x**(2*y)) == 'x^(2*y)'\n\n    # test multiplication\n    assert mcode(x*y) == 'x*y'\n    assert mcode(x*y*z) == 'x*y*z'\n    assert mcode(x*y*z**2) == 'x*y*z^2'\n\n    # test constants\n    assert mcode(pi) == 'Pi'\n    assert mcode(oo) == 'Infinity'\n    assert mcode(-oo) == '-Infinity'\n\n    # test Integral\n    assert mcode(Integral(x**2, x)) == 'Hold[Integrate[x^2, x]]'\n    assert mcode(Integral(x**2, (x, 0, 1))) == 'Hold[Integrate[x^2, {x, 0, 1}]]'\n\n    # test Sum\n    assert mcode(S", "def test_mcode():\n    # Test known functions\n    assert mcode(exp(x)) == 'Exp[x]'\n    assert mcode(sin(x)) == 'Sin[x]'\n    assert mcode(cos(x)) == 'Cos[x]'\n    assert mcode(tan(x)) == 'Tan[x]'\n    assert mcode(cot(x)) == 'Cot[x]'\n    assert mcode(asin(x)) == 'ArcSin[x]'\n    assert mcode(acos(x)) == 'ArcCos[x]'\n    assert mcode(atan(x)) == 'ArcTan[x]'\n    assert mcode(sinh(x)) == 'Sinh[x]'\n    assert mcode(cosh(x)) == 'Cosh[x]'\n    assert mcode(tanh(x)) == 'Tanh[x]'\n    assert mcode(coth(x)) == 'Coth[x]'\n    assert mcode(sech(x)) == 'Sech[x]'\n    assert mcode(csch(x)) == 'Csch[x]'\n    assert mcode(asinh(x)) == 'ArcSinh[x]'\n    assert mcode(acosh(x)) == 'ArcCosh[x]'\n    assert mcode(atanh(x)) == 'ArcTanh[x]'\n    assert mcode(acoth(x)) == 'ArcCoth[x]'\n    assert mcode(asech(x)) == 'ArcSech[x]'\n    assert mcode(acsch(x)) == 'ArcCsch[x]'\n    assert mcode(conjugate(x)) == 'Conjugate[x]'\n\n    # Test number symbols and infinity\n    assert mcode(pi) == 'Pi'\n    assert mcode(oo) == 'Infinity'\n    assert mcode(-oo) == '-Infinity'\n\n    # Test user-defined functions\n    assert mcode(f(x)) == 'f[x]'\n\n    # Test list, tuple, and Tuple\n    assert mcode([x, y, z]) == '{x, y, z}'\n    assert mcode((x, y, z)) == '{x, y, z}'\n    assert mcode(Tuple(x, y, z)) == '{x, y, z}'\n\n    # Test Integral\n    assert mcode(Integral(x**2, (x, 0, 1))) == 'Hold[Integrate[x**2, {x, 0, 1}]]'\n\n    # Test Sum\n    assert mcode(Sum(x**2, (x, 0, 10))) == '", "def test_functions():\n    assert mcode(sin(x)) == 'Sin[x]'\n    assert mcode(cos(x)) == 'Cos[x]'\n    assert mcode(exp(x)) == 'Exp[x]'\n    assert mcode(Max(x, y)) == 'Max[x, y]'\n    assert mcode(Min(x, y)) == 'Min[x, y]'\n    assert mcode(conjugate(x)) == 'Conjugate[x]'\n"], "sample_32": ["def test_json_field_key_transform_exact(self):\n    json_data = {'key1': 'value1', 'key2': {'key21': 'value21'}}\n    obj = JSONModel.objects.create(data=json_data)\n    self.assertEqual(\n        JSONModel.objects.filter(data__key1__exact='value1').get().id,\n        obj.id\n    )\n    self.assertEqual(\n        JSONModel.objects.filter(data__key2__key21__exact='value21').get().id,\n        obj.id\n    )\n    self.assertIsNone(JSONModel.objects.filter(data__key3__exact='value3').first())\n    self.assertIsNone(JSONModel.objects.filter(data__key2__key22__exact='value22').first())\n", "    def test_json_field_key_transform_iexact_lookup(self):\n        obj1 = JSONModel.objects.create(data={'name': 'John'})\n        obj2 = JSONModel.objects.create(data={'name': 'john'})\n        self.assertEqual(JSONModel.objects.filter(data__name__iexact='John').count(), 2)\n        self.assertEqual(JSONModel.objects.filter(data__name__iexact='Jane').count(), 0)\n        self.assertEqual(\n            JSONModel.objects.filter(data__name__iexact=Value('John', output_field=models.CharField())).count(),\n            2,\n        )\n        self.assertEqual(\n            JSONModel.objects.filter(data__name__iexact=Value('Jane', output_field=models.CharField())).count(),\n            0,\n        )\n", "    def test_jsonfield_lookups(self):\n        json_data = {'key1': 'value1', 'key2': {'key3': 'value2'}}\n\n        obj = JSONModel.objects.create(data=json_data)\n        self.assertEqual(JSONModel.objects.filter(data__key1='value1').count(), 1)\n        self.assertEqual(JSONModel.objects.filter(data__key2__key3='value2').count(), 1)\n\n        self.assertEqual(JSONModel.objects.filter(data__contains={'key1': 'value1'}).count(), 1)\n        self.assertEqual(JSONModel.objects.filter(data__contained_by={'key1': 'value1', 'key2': {'key3': 'value2'}}).count(), 1)\n\n        self.assertEqual(JSONModel.objects.filter(data__has_key='key1').count(), 1)\n        self.assertEqual(JSONModel.objects.filter(data__has_keys=['key1', 'key2']).count(), 1)\n        self.assertEqual(JSONModel.objects.filter(data__has_any_keys=['key1', 'key3']).count(), 1)\n\n        self.assertEqual(JSONModel.objects.filter(data__exact=json_data).count(), 1)\n\n        self.assertEqual(JSONModel.objects.filter(data__key1='value1').count(), 1)\n        self.assertEqual(JSONModel.objects.filter(data__key2__key3='value2').count(), 1)\n\n        self.assertEqual(JSONModel.objects.filter(data__key1__iexact='VALUE1').count(), 1)\n        self.assertEqual(JSONModel.objects.filter(data__key2__key3__iexact='VALUE2').count(), 1)\n\n        self.assertEqual(JSONModel.objects.filter(data__key1__icontains='val').count(), 1)\n        self.assertEqual(JSONModel.objects.filter(data__key2__key3__icontains='val').count(), 1)\n\n        self.assertEqual(JSONModel.objects.filter(data__key1__startswith='val').count(), 1)\n        self.assertEqual(JSONModel.objects.filter(data__key2__key3__startswith='val').count(), 1)\n\n        self.assertEqual(JSONModel.objects.filter(data__key1__istartswith='VAL').count(), 1)\n        self.assertEqual(JSONModel.objects.filter(data__key2__key3__istartswith='VAL').count(), 1)\n\n        self.assertEqual(JSONModel.objects.filter(data__key1__endswith='1').count(), 1)\n        self.assertEqual(JSONModel.objects.filter(data__key2__key3__endswith='2').count", "    def test_jsonfield_encoder_decoder(self):\n        json_data = {'a': 1, 'b': 2}\n\n        # Test with default encoder and decoder.\n        default_field = JSONField()\n        self.assertEqual(\n            default_field.get_prep_value(json_data),\n            json.dumps(json_data, cls=DjangoJSONEncoder)\n        )\n\n        loaded_data = default_field.from_db_value(\n            json.dumps(json_data, cls=DjangoJSONEncoder), None, connection\n        )\n        self.assertEqual(loaded_data, json_data)\n\n        # Test with custom encoder and decoder.\n            if isinstance(obj, dict):\n                return {str(k): v for k, v in obj.items()}\n            return obj\n\n            return {k: v for k, v in dct.items()}\n\n        custom_field = JSONField(encoder=custom_encoder, decoder=custom_decoder)\n        self.assertEqual(\n            custom_field.get_prep_value(json_data),\n            json.dumps(json_data, cls=custom_encoder)\n        )\n\n        loaded_data = custom_field.from_db_value(\n            json.dumps(json_data, cls=custom_encoder), None, connection\n        )\n        self.assertEqual(loaded_data, json_data)\n", "    def test_from_db_value_with_invalid_json(self):\n        json_field = JSONField()\n        with self.assertRaisesMessage(ValueError, 'Value must be valid JSON.'):\n            json_field.from_db_value('invalid json', None, connection)\n"], "sample_128": ["def test_domain_postprocess():\n    # Test if the domain is Composite and generators interfere\n    opt = Options((x, y), {'domain': QQ[x, y]})\n    raises(GeneratorsError, lambda: Domain.postprocess(opt))\n\n    # Test if EX domain is requested and no generators are provided\n    opt = Options({}, {'domain': EX})\n    raises(GeneratorsError, lambda: Domain.postprocess(opt))\n", "def test_domain():\n    assert Domain.preprocess('ZZ') == ZZ\n    assert Domain.preprocess('QQ') == QQ\n    assert Domain.preprocess('RR') == RR\n    assert Domain.preprocess('CC') == CC\n    assert Domain.preprocess('EX') == EX\n\n    assert Domain.preprocess('R_30') == RR(30)\n    assert Domain.preprocess('C_30') == CC(30)\n\n    assert Domain.preprocess('FF(2)') == FF(2)\n    assert Domain.preprocess('GF(2)') == GF(2)\n\n    assert Domain.preprocess('ZZ[x,y]') == ZZ.old_poly_ring(x, y)\n    assert Domain.preprocess('QQ[x,y,z]') == QQ.old_poly_ring(x, y, z)\n    assert Domain.preprocess('RR[x,y,z]') == RR.old_poly_ring(x, y, z)\n    assert Domain.preprocess('CC[x,y,z]') == CC.old_poly_ring(x, y, z)\n\n    assert Domain.preprocess('ZZ<sqrt(2)>') == QQ.algebraic_field(sqrt(2))\n    assert Domain.preprocess('QQ<sqrt(2),I>') == QQ.algebraic_field(sqrt(2), I)\n\n    raises(OptionError, lambda: Domain.preprocess('invalid'))\n    raises(OptionError, lambda: Domain.preprocess(1))\n    raises(OptionError, lambda: Domain.preprocess([1, 2, 3]))\n", "def test_domain():\n    assert Options([x, y], {'domain': 'ZZ'}).domain == ZZ\n    assert Options([x, y], {'domain': 'QQ'}).domain == QQ\n    assert Options([x, y], {'domain': 'RR'}).domain == RR\n    assert Options([x, y], {'domain': 'CC'}).domain == CC\n    assert Options([x, y], {'domain': 'ZZ[x, y]'}).domain == ZZ.poly_ring(x, y)\n    assert Options([x, y], {'domain': 'QQ[x, y]'}).domain == QQ.poly_ring(x, y)\n    assert Options([x, y], {'domain': 'RR[x, y]'}).domain == RR.poly_ring(x, y)\n    assert Options([x, y], {'domain': 'CC[x, y]'}).domain == CC.poly_ring(x, y)\n    assert Options([x, y], {'domain': 'ZZ(x, y)'}).domain == ZZ.frac_field(x, y)\n    assert Options([x, y], {'domain': 'QQ(x, y)'}).domain == QQ.frac_field(x, y)\n    assert Options([x, y], {'domain': 'QQ<sqrt(2)>'}).domain == QQ.algebraic_field(sqrt(2))\n\n    raises(OptionError, lambda: Options([x, y], {'domain': 'invalid'}))\n\n    assert Options([x, y], {'domain': EX}).domain == EX\n\n    raises(GeneratorsError, lambda: Options([x, y], {'domain': EX, 'gens': [x]}))\n\n    assert Options([x, y], {'domain': 'ZZ', 'extension': I}).domain == QQ.algebraic_field(I)\n\n    assert Options([x, y], {'domain': 'ZZ', 'gaussian': True}).extension == {I}\n\n    assert Options([x, y], {'domain': 'ZZ', 'modulus': 5}).domain == FF(5, True)\n\n    assert Options([x, y], {'domain': 'ZZ', 'modulus': 5, 'symmetric': False}).domain == FF(5, False)\n", "def test_domain():\n    assert isinstance(Options([x], {'domain': 'ZZ'}).domain, ZZ)\n    assert isinstance(Options([x], {'domain': 'QQ'}).domain, QQ)\n    assert isinstance(Options([x], {'domain': 'EX'}).domain, EX)\n    assert isinstance(Options([x], {'domain': 'ZZ[x]'}).domain, ZZ.poly_ring(x))\n    assert isinstance(Options([x], {'domain': 'QQ[x]'}).domain, QQ.poly_ring(x))\n    assert isinstance(Options([x], {'domain': 'RR[x]'}).domain, RR.poly_ring(x))\n    assert isinstance(Options([x], {'domain': 'CC[x]'}).domain, CC.poly_ring(x))\n    assert isinstance(Options([x], {'domain': 'ZZ[x,y]'}).domain, ZZ.poly_ring(x, y))\n    assert isinstance(Options([x], {'domain': 'QQ[x,y]'}).domain, QQ.poly_ring(x, y))\n    assert isinstance(Options([x], {'domain': 'RR[x,y]'}).domain, RR.poly_ring(x, y))\n    assert isinstance(Options([x], {'domain': 'CC[x,y]'}).domain, CC.poly_ring(x, y))\n    assert isinstance(Options([x], {'domain': 'QQ[x, sqrt(2)]'}).domain, QQ.algebraic_field(sqrt(2)))\n    assert isinstance(Options([x], {'domain': 'QQ[x, sqrt(2), sqrt(3)]'}).domain, QQ.algebraic_field(sqrt(2), sqrt(3)))\n\n    raises(OptionError, lambda: Options([x], {'domain': 'ABC'}))\n    raises(GeneratorsError, lambda: Options([x, y], {'domain': 'ZZ[x]'}))\n    raises(GeneratorsError, lambda: Options([], {'domain': 'EX'}))\n", "def test_options():\n    a = Symbol('a')\n    b = Symbol('b')\n    s = Symbol('s')\n\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z')\n\n    # Test domain\n    assert Options((x, y, z), {'domain': 'ZZ'}).domain == ZZ\n    assert Options((x, y, z), {'domain': 'QQ'}).domain == QQ\n    assert Options((x, y, z), {'domain': 'RR'}).domain == RR\n    assert Options((x, y, z), {'domain': 'CC'}).domain == CC\n    assert Options((x, y, z), {'domain': 'EX'}).domain == EX\n\n    assert Options((x, y, z), {'domain': 'R_10'}).domain == RR(10)\n    assert Options((x, y, z), {'domain': 'C_10'}).domain == CC(10)\n\n    assert Options((x, y, z), {'domain': 'FF(7)'}).domain == FF(7)\n    assert Options((x, y, z), {'domain': 'GF(7)'}).domain == GF(7)\n\n    assert Options((x, y, z), {'domain': 'ZZ[x]'}).domain == ZZ.poly_ring(x)\n    assert Options((x, y, z), {'domain': 'QQ[x]'}).domain == QQ.poly_ring(x)\n    assert Options((x, y, z), {'domain': 'RR[x]'}).domain == RR.poly_ring(x)\n    assert Options((x, y, z), {'domain': 'CC[x]'}).domain == CC.poly_ring(x)\n\n    assert Options((x, y, z), {'domain': 'ZZ[x,y]'}).domain == ZZ.poly_ring(x, y)\n    assert Options((x, y, z), {'domain': 'QQ[x,y]'}).domain == QQ.poly_ring(x, y)\n    assert Options((x, y, z), {'domain': 'RR[x,y]'}).domain == RR.poly_ring(x, y)\n    assert Options((x, y, z), {'domain': 'CC[x,y]'}).domain == CC.poly_ring(x, y)\n\n    assert Options((x, y, z), {'domain': 'ZZ[x,z]'}).domain == ZZ.poly_ring(x, z)\n    assert Options((x, y, z), {'domain': 'QQ[x,z]'}).domain"], "sample_144": ["def test_refine():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n\n    assert refine(arg(x), Q.positive(x)) == 0\n    assert refine(arg(x), Q.negative(x)) == pi\n\n    assert refine(sign(x), Q.positive(x) & Q.nonzero(x)) == 1\n    assert refine(sign(x), Q.negative(x) & Q.nonzero(x)) == -1\n    assert refine(sign(x), Q.zero(x)) == 0\n\n    assert refine(sign(I*y), Q.positive(im(y))) == I\n    assert refine(sign(I*y), Q.negative(im(y))) == -I\n\n    assert refine(re(x), Q.real(x)) == x\n    assert refine(re(x), Q.imaginary(x)) == 0\n    assert refine(im(x), Q.real(x)) == 0\n    assert refine(im(x), Q.imaginary(x)) == -I*x\n\n    assert refine(atan2(y,x), Q.real(y) & Q.positive(x)) == atan(y/x)\n    assert refine(atan2(y,x), Q.negative(y) & Q.negative(x)) == atan(y/x) - pi\n    assert refine(atan2(y,x), Q.positive(y) & Q.negative(x)) == atan(y/x) + pi\n    assert refine(atan2(y,x), Q.zero(y) & Q.negative(x)) == pi\n    assert refine(atan2(y,x), Q.positive(y) & Q.zero(x)) == pi/2\n    assert refine(atan2(y,x), Q.negative(y) & Q.zero(x)) == -pi/2\n    assert refine(atan2(y,x), Q.zero(y) & Q.zero(x)) == nan\n", "def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n", "def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    expr1 = X[0, 1]\n    expr2 = X[1, 0]\n    assert refine(expr1, Q.symmetric(X)) == expr1\n    assert refine(expr2, Q.symmetric(X)) == expr1\n", "def test_refine_arg():\n    x = Symbol('x', real=True)\n    assert refine(arg(x), Q.positive(x)) == 0\n    assert refine(arg(x), Q.negative(x)) == pi\n    assert refine(arg(I*x), Q.positive(x)) == pi/2\n    assert refine(arg(-I*x), Q.positive(x)) == -pi/2\n", "def test_refine():\n    # Test refining a non-Atom\n    expr = x + y\n    assumptions = Q.real(x) & Q.positive(y)\n    assert refine(expr, assumptions) == expr\n    \n    # Test refining an Atom\n    expr = Abs(x)\n    assumptions = Q.real(x) & Q.negative(x)\n    assert refine(expr, assumptions) == -x\n    \n    # Test refining an expression that is a handler key\n    expr = atan2(y, x)\n    assumptions = Q.real(y) & Q.negative(x)\n    assert refine(expr, assumptions) == atan(y/x) + pi\n    \n    # Test refining a complex expression\n    expr = refine(x*y*Abs(z), Q.real(x) & Q.positive(y) & Q.negative(z))\n    assert expr == -x*y*z\n\n    # Test refining a MatrixElement\n    X = MatrixSymbol('X', 3, 3)\n    expr = X[1, 0]\n    assumptions = Q.symmetric(X)\n    assert refine(expr, assumptions) == X[0, 1]\n\n    # Test refining an expression that is not a handler key\n    expr = exp(x)\n    assumptions = Q.real(x) & Q.positive(x)\n    assert refine(expr, assumptions) == expr\n"], "sample_35": ["    def test_model_form_metaclass(self):\n        class TestModelForm(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = ('choice',)\n\n        self.assertEqual(TestModelForm._meta.model, ChoiceModel)\n        self.assertEqual(TestModelForm._meta.fields, ('choice',))\n", "    def test_validate_unique(self):\n        from ..models import Author\n        class AuthorForm(ModelForm):\n            class Meta:\n                model = Author\n                fields = ('name',)\n\n        author = Author.objects.create(name='John Doe')\n        form = AuthorForm({'name': 'John Doe'})\n        self.assertFalse(form.is_valid())\n", "    def test_construct_instance(self):\n        from ..models import Book\n\n        class TestForm(ModelForm):\n            class Meta:\n                model = Book\n                fields = ['title', 'author']\n\n        book = Book.objects.create(title='Book Title', author='Book Author')\n\n        form = TestForm(instance=book)\n        instance = construct_instance(form, book)\n\n        self.assertEqual(instance.title, 'Book Title')\n        self.assertEqual(instance.author, 'Book Author')\n", "    def test_model_form_save_new(self):\n        from .models import Book\n\n        class BookForm(forms.ModelForm):\n            class Meta:\n                model = Book\n                fields = ('title',)\n\n        form = BookForm({'title': 'New Book'})\n        self.assertTrue(form.is_valid())\n        book = form.save()\n        self.assertIsNotNone(book.pk)\n        self.assertEqual(Book.objects.count(), 1)\n", "    def test_modelform_with_modelchoicefield(self):\n        from ..models import ChoiceModel, ChoiceModelForm\n        from ..forms import ModelChoiceField\n\n        # Test ModelChoiceField with a model queryset\n        class MyModelChoiceField(ModelChoiceField):\n                return obj.name\n\n        class MyModelForm(ChoiceModelForm):\n            my_field = MyModelChoiceField(queryset=ChoiceModel.objects.all())\n\n        form = MyModelForm()\n        self.assertEqual(len(form.fields['my_field'].choices), 2)\n        self.assertEqual(form.fields['my_field'].choices[0][1], 'Choice 1')\n        self.assertEqual(form.fields['my_field'].choices[1][1], 'Choice 2')\n\n        # Test ModelChoiceField with invalid queryset\n        with self.assertRaises(ValueError):\n            class InvalidModelChoiceField(ModelChoiceField):\n                    super().__init__(queryset='invalid_queryset')\n            InvalidModelChoiceField()\n\n        # Test ModelChoiceField with invalid to_field_name\n        with self.assertRaises(ValueError):\n            class InvalidToFieldModelChoiceField(ModelChoiceField):\n                    super().__init__(queryset=ChoiceModel.objects.all(), to_field_name='invalid_field')\n            InvalidToFieldModelChoiceField()\n"], "sample_61": ["def test_format_decimal_positions_and_grouping(self):\n    self.assertEqual(nformat(1234567.89, '.', decimal_pos=2, grouping=3, thousand_sep=','),\n                     '1,234,567.89')\n    self.assertEqual(nformat(1234567.89, ',', decimal_pos=2, grouping=3, thousand_sep='.'),\n                     '1.234.567,89')\n    self.assertEqual(nformat(1234567.89, '.', decimal_pos=0, grouping=3, thousand_sep=','),\n                     '1,234,568')\n    self.assertEqual(nformat(1234567.89, '.', decimal_pos=None, grouping=3, thousand_sep=','),\n                     '1,234,567.89')\n    self.assertEqual(nformat(Decimal('1234567.89'), '.', decimal_pos=2, grouping=3, thousand_sep=','),\n                     '1,234,567.89')\n    self.assertEqual(nformat(Decimal('1234567.89'), ',', decimal_pos=2, grouping=3, thousand_sep='.'),\n                     '1.234.567,89')\n    self.assertEqual(nformat(Decimal('1234567.89'), '.', decimal_pos=0, grouping=3, thousand_sep=','),\n                     '1,234,568')\n    self.assertEqual(nformat(Decimal('1234567.89'), '.', decimal_pos=None, grouping=3, thousand_sep=','),\n                     '1,234,567.89')\n", "def test_format_decimal_with_exponent(self):\n    # Test that Decimals with more than 200 digits are formatted using scientific notation.\n    # This test covers the case where the number is a Decimal and has an exponent.\n    number = Decimal(\"1.23456789012345678901234567890123456789\")\n    formatted_number = format(number, \".\", decimal_pos=20, grouping=3, thousand_sep=\",\")\n    self.assertRegex(formatted_number, r\"^1\\.2345678901234567890e\\+20$\")\n", "def test_formatting_with_large_float(self):\n    # Test formatting of very large floats, which are converted to Decimals.\n    large_float = 1.12345678901234567890123456789012345678901234567890123456789\n    formatted = nformat(large_float, decimal_sep=\".\")  # Should be converted to Decimal.\n    self.assertIsInstance(formatted, str)\n    self.assertNotIn(\"e\", formatted)  # Should not be in scientific notation.\n\n    # Test formatting of very small floats, which are converted to Decimals.\n    small_float = 1.12345678901234567890123456789012345678901234567890123456789e-200\n    formatted = nformat(small_float, decimal_sep=\".\")  # Should be converted to Decimal.\n    self.assertIsInstance(formatted, str)\n    self.assertNotIn(\"e\", formatted)  # Should not be in scientific notation.\n\n    # Test formatting of very large/small Decimals.\n    large_decimal = Decimal(\"1.12345678901234567890123456789012345678901234567890123456789\")\n    small_decimal = Decimal(\"1.12345678901234567890123456789012345678901234567890123456789e-200\")\n    formatted_large = nformat(large_decimal, decimal_sep=\".\")\n    formatted_small = nformat(small_decimal, decimal_sep=\".\")\n    self.assertIsInstance(formatted_large, str)\n    self.assertIsInstance(formatted_small, str)\n    self.assertNotIn(\"e\", formatted_large)  # Should not be in scientific notation.\n    self.assertNotIn(\"e\", formatted_small)  # Should not be in scientific notation.\n", "def test_format_force_grouping(self):\n    # Test that force_grouping works correctly\n    self.assertEqual(format(1234, \",\", decimal_pos=2, grouping=3, force_grouping=True), \"1,234.00\")\n    self.assertEqual(format(1234, \".\", decimal_pos=2, grouping=3, force_grouping=False), \"1234.00\")\n", "    def test_format_with_force_grouping(self):\n        self.assertEqual(format(1234567, '.', force_grouping=True), '1,234,567')\n        self.assertEqual(format(1234567, ',', force_grouping=True), '1.234.567')\n        self.assertEqual(format(1234567.89, '.', force_grouping=True), '1,234.89')\n        self.assertEqual(format(1234567.89, ',', force_grouping=True), '1.234,89')\n"], "sample_108": ["def test_base_libsvm_predict_proba_shape():\n    # test that predict_proba has correct shape\n    clf = svm.SVC(kernel='linear', probability=True, random_state=0)\n    clf.fit(X, Y)\n    y_pred = clf.predict_proba(T)\n    assert y_pred.shape == (len(T), 2)\n\n    # test with multi-class problem\n    clf.fit(iris.data, iris.target)\n    y_pred = clf.predict_proba(iris.data)\n    assert y_pred.shape == (iris.data.shape[0], 3)\n", "def test_base_libsvm_predict_proba_not_implemented():\n    # Test predict_proba raises an AttributeError for a BaseLibSVM object\n    class MockBaseLibSVM(BaseLibSVM):\n            self.probability = True\n            self._impl = 'one_class'\n\n    clf = MockBaseLibSVM()\n    assert_raise_message(NotImplementedError, \"predict_proba is not implemented.\",\n                         clf.predict_proba, np.array([[1, 2]]))\n", "def test_base_libsvm_fit():\n    # Test BaseLibSVM fit method with precomputed kernel\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    kernel = lambda X, Y: np.dot(X, Y.T)\n\n    clf = BaseLibSVM(kernel='linear', degree=3, gamma='auto', coef0=0.0,\n                     tol=1e-3, C=1.0, nu=0.5, epsilon=0.1, shrinking=True,\n                     probability=False, cache_size=200, class_weight=None,\n                     verbose=False, max_iter=-1, random_state=None)\n    clf.fit(X, y)\n\n    # Test BaseLibSVM fit method with sparse data\n    X_sparse = sparse.csr_matrix(X)\n    clf.fit(X_sparse, y)\n\n    # Test BaseLibSVM fit method with invalid gamma value\n    clf.gamma = 0\n    with pytest.raises(ValueError):\n        clf.fit(X, y)\n\n    # Test BaseLibSVM fit method with invalid sample weight\n    sample_weight = np.array([1, 2, 3])\n    with pytest.raises(ValueError):\n        clf.fit(X, y, sample_weight=sample_weight)\n\n    # Test BaseLibSVM fit method with invalid shape of X\n    X_invalid = np.array([[1, 2, 3], [4, 5, 6]])\n    with pytest.raises(ValueError):\n        clf.fit(X_invalid, y)\n", "def test_base_libsvm_sparse_predict():\n    # Test sparse predict function in BaseLibSVM class\n    X = sparse.csr_matrix(np.array([[1, 0, 0], [0, 1, 0]]))\n    y = np.array([1, 2])\n    clf = svm.SVC(kernel='linear')\n    with ignore_warnings(category=ConvergenceWarning):\n        clf.fit(X, y)\n    X_test = sparse.csr_matrix(np.array([[1, 0, 0], [0, 1, 0]]))\n    y_pred = clf.predict(X_test)\n    assert_array_equal(y_pred, np.array([1, 2]))\n\n", "def test_base_libsvm_kernel():\n    \"\"\"Test BaseLibSVM kernel parameter\"\"\"\n    for kernel in [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]:\n        clf = svm.SVC(kernel=kernel, random_state=0)\n        clf.fit(X, Y)\n        assert_array_equal(clf.predict(T), true_result)\n\n    for kernel in [\"precomputed\", \"linear\", \"poly\", \"rbf\", \"sigmoid\"]:\n        clf = svm.SVC(kernel=kernel, random_state=0)\n        clf.fit(iris.data, iris.target)\n        assert_array_equal(clf.predict(iris.data[:3]), iris.target[:3])\n\n    # Test callable kernel\n    clf = svm.SVC(kernel=rbf_kernel, gamma=1, random_state=0)\n    clf.fit(X, Y)\n    assert_array_equal(clf.predict(T), true_result)\n\n    # Test string kernel\n    clf = svm.SVC(kernel=\"rbf\", gamma=1, random_state=0)\n    clf.fit(X, Y)\n    assert_array_equal(clf.predict(T), true_result)\n\n    # Test invalid kernel\n    with assert_raise_message(ValueError, \"The kernel can be 'precomputed', \"\n                                        \"'linear', 'poly', 'rbf', 'sigmoid'\"):\n        svm.SVC(kernel=\"invalid_kernel\").fit(X, Y)\n\n    # Test invalid gamma for kernel\n    with assert_raise_message(ValueError, \"The gamma value of 0.0 is invalid. \"\n                                        \"Use 'auto' to set gamma to a value of \"\n                                        \"1 / n_features.\"):\n        svm.SVC(kernel=\"rbf\", gamma=0).fit(X, Y)\n\n    # Test gamma as string\n    clf = svm.SVC(kernel=\"rbf\", gamma=\"auto\", random_state=0)\n    clf.fit(X, Y)\n    assert_array_equal(clf.predict(T), true_result)\n\n    # Test gamma as scale\n    clf = svm.SVC(kernel=\"rbf\", gamma=\"scale\", random_state=0)\n    clf.fit(X, Y)\n    assert_array_equal(clf.predict(T), true_result)\n\n    # Test invalid gamma as string\n    with assert_raise_message(ValueError, \"When 'gamma' is a string, it should \"\n                                        \"be either 'scale' or 'auto'. Got \"\n                                        \"'invalid' instead.\"):\n        svm.SVC(kernel=\"rbf\", gamma=\"invalid\").fit(X, Y)\n"], "sample_141": ["def test_convert_to():\n    assert convert_to(mile, kilometer) == 25146*kilometer/15625\n    assert convert_to(mile, kilometer).n() == 1.609344*kilometer\n    assert convert_to(speed_of_light, meter/second) == 299792458*meter/second\n    assert convert_to(day, second) == 86400*second\n    assert convert_to(3*newton, kilogram*meter/second**2) == 3*kilogram*meter/second**2\n    assert convert_to(atomic_mass_constant, gram) == 1.660539060e-24*gram\n    assert convert_to(speed_of_light, [meter, second]) == 299792458*meter/second\n    assert convert_to(3*newton, [centimeter, gram, second]) == 300000*centimeter*gram/second**2\n    assert convert_to(atomic_mass_constant, [gravitational_constant, speed_of_light, hbar]).n() == 7.62963085040767e-20*gravitational_constant**(-S.Half)*hbar**S.Half*speed_of_light**S.Half\n    assert convert_to(foot - 6*inch, meter) == meter/3\n    assert convert_to((foot - 6*inch) * kilo, meter) == 250*meter/3\n", "def test_convert_to_with_non_compatible_dimensions():\n    expr = joule\n    target_units = [kilogram, second]\n    with raises(ValueError):\n        convert_to(expr, target_units)\n", "def test_convert_to():\n    # Test that we can convert between units of the same dimension\n    assert convert_to(meter, kilometer) == 1000*kilometer\n    assert convert_to(kilometer, meter) == 1000*meter\n    # Test that we can convert between units of different dimensions\n    assert convert_to(kg * meter**2 / second**2, joule) == joule\n    # Test that we can convert between units of different dimensions and prefixes\n    assert convert_to(kilo * joule, joule) == 1000 * joule\n    # Test that we can convert between units of different dimensions and prefixes (2)\n    assert convert_to(joule, kilo * joule) == joule / 1000\n    # Test that we can convert to multiple units\n    assert convert_to(gravitational_constant, [kg, meter, second]) == gravitational_constant\n    # Test that we can convert to multiple units with prefixes\n    assert convert_to(gravitational_constant, [kilo * kg, kilometer, second]) == gravitational_constant / 1000\n    # Test that we can convert to multiple units with prefixes (2)\n    assert convert_to(gravitational_constant, [kg, kilometer, kilo * second]) == gravitational_constant / 1000000\n    # Test that we cannot convert to units of different dimensions\n    with raises(ValueError):\n        convert_to(meter, second)\n    # Test that we cannot convert to units of different dimensions (2)\n    with raises(ValueError):\n        convert_to(second, meter)\n    # Test that we cannot convert to units of different dimensions (3)\n    with raises(ValueError):\n        convert_to(meter, joule)\n", "def test_convert_to():\n    # Test conversion to multiple units\n    assert convert_to(speed_of_light, [meter, second]) == speed_of_light\n    assert convert_to(3*newton, [centimeter, gram, second]) == 3*newton\n    assert convert_to(atomic_mass_constant, [gravitational_constant, speed_of_light, joule]).n().free_symbols == set()\n\n    # Test conversion to units with different dimension systems\n    assert convert_to(meter, [inch]).n() == Rational(39.3701)*inch\n    assert convert_to(inch, [meter]).n() == Rational(1, 39.3701)*meter\n\n    # Test conversion of quantities with prefixes\n    assert convert_to(kilo*kilogram, [gram]).n() == 1000*gram\n    assert convert_to(gram, [kilo*kilogram]).n() == gram/1000*kilo*kilogram\n\n    # Test conversion of quantities with non-SI units\n    assert convert_to(mile, [kilometer]).n() == Rational(25146, 15625)*kilometer\n    assert convert_to(kilometer, [mile]).n() == Rational(15625, 25146)*mile\n\n    # Test conversion to multiple units with different dimension systems\n    assert convert_to(speed_of_light, [foot, second]).n().free_symbols == set()\n    assert convert_to(3*newton, [inch, pound, second]).n().free_symbols == set()\n    assert convert_to(atomic_mass_constant, [gravitational_constant, speed_of_light, erg]).n().free_symbols == set()\n", "def test_quantity_simplify():\n    assert quantity_simplify(kilo * meter * meter) == 1000000*meter**2\n    assert quantity_simplify(foot - 6 * inch) == foot / 2\n    assert quantity_simplify(kilo * gram) == 1000*gram\n"], "sample_142": ["def test_generate_oriented_forest():\n    n = 4\n    expected_permutations = [\n        [0, 1, 2, 3],\n        [0, 1, 2, 2],\n        [0, 1, 2, 1],\n        [0, 1, 2, 0],\n        [0, 1, 1, 1],\n        [0, 1, 1, 0],\n        [0, 1, 0, 1],\n        [0, 1, 0, 0],\n        [0, 0, 0, 0],\n    ]\n    assert set(generate_oriented_forest(n)) == set(expected_permutations)\n", "def test_kbints():\n    assert list(kbins([], 2)) == [[]]\n    assert list(kbins([], 3)) == [[]]\n    assert list(kbins([1, 2], 2)) == [[1], [2]]\n    assert list(kbins([1, 2], 3)) == [[1], [], [2]]\n    assert list(kbins([1, 2, 3], 2)) == [[1], [2, 3]], list(kbins([1, 2, 3], 2))\n    assert list(kbins([1, 2, 3, 4], 3)) == [[1], [2], [3, 4]], list(kbins([1, 2, 3, 4], 3))\n", "def test_multiset_partitions():\n    assert sorted(list(multiset_partitions([1, 1, 1, 2, 2, 3], 3))) == \\\n        sorted([[[1, 1], [1, 2], [2, 3]], [[1, 1], [1, 3], [2, 2]], [[1, 2], [1, 2], [1, 3]], [[1, 2], [1, 3], [2, 2]], [[1, 3], [1, 3], [2, 2]]])\n    assert sorted(list(multiset_partitions([1, 1, 1, 2, 2, 3]))) == \\\n        sorted([[[1, 1, 1, 2, 2, 3]], [[1, 1], [1, 1, 2, 2, 3]], [[1, 1], [1, 1, 2, 2, 3]], [[1, 1], [1, 2, 2, 3]], [[1, 1], [1, 2, 3, 2]], [[1, 1], [1, 3, 2, 2]], [[1, 1], [2, 2, 1, 3]], [[1, 1], [2, 2, 3, 1]], [[1, 1], [2, 3, 1, 2]], [[1, 1], [2, 3, 2, 1]], [[1, 1], [3, 1, 1, 2]], [[1, 1], [3, 1, 2, 2]], [[1, 1], [3, 2, 1, 2]], [[1, 1], [3, 2, 2, 1]], [[1, 1, 2], [1, 2, 3]], [[1, 1, 2], [1, 3, 2]], [[1, 1, 2], [2, 1, 3]], [[1, 1, 2], [2, 2, 3]], [[1, 1, 2], [2, 3, 1", "def test_minlex():\n    # Test if minlex gives lexically smallest result\n    s = \"dabc\"\n    minlex_s = minlex(s)\n    assert minlex_s == \"aabc\"\n\n    # Test if minlex handles directed=False\n    s = \"dabc\"\n    minlex_s_directed = minlex(s, directed=False)\n    assert minlex_s_directed == \"abcd\"\n", "def test_multiset_permutations():\n    assert list(multiset_permutations('aab')) == ['aab', 'aba', 'baa']\n    assert list(multiset_permutations('banana')) == [\n        'banana', 'anabna', 'annaba', 'naabna', 'nabana', 'nanaba',\n        'abnana', 'anbana', 'annaba', 'banaan', 'banana', 'nabana',\n        'anbana', 'abnanb', 'abnana', 'abbana', 'ababna', 'abnaba',\n        'baabna', 'baanab', 'babana', 'banaab', 'banaan', 'bnabaa',\n        'bnabaa', 'bnnaab', 'nabaab', 'naabb', 'naabn', 'naaab',\n        'naabb', 'nabaa', 'nabab', 'nabaa', 'nabba', 'nbaab', 'nbaba',\n        'nbaab', 'nbbaa', 'nnaba', 'nnaab', 'nnbaa']\n    assert len(list(multiset_permutations([1, 2, 3, 1, 2, 1, 2, 1]))) == 420\n    # assert len(list(multiset_permutations(list(range(4)))) == 24\n    # assert len(list(multiset_permutations(list(range(5)))) == 120\n    assert len(list(multiset_permutations(list(range(5)), 2))) == 15\n    assert len(list(multiset_permutations(list(range(6)), 2))) == 15\n    assert len(list(multiset_permutations(list(range(5)), 4))) == 5\n    assert len(list(multiset_permutations(list(range(5)), 5))) == 1\n    assert len(list(multiset_permutations(list(range(6)), 6))) == 1\n"], "sample_105": ["def test_voting_regressor_weights(voting):\n    # Test that VotingRegressor works with weights\n    X, y = datasets.make_regression(n_samples=10, n_features=1, n_informative=1, noise=0.1, random_state=1)\n    estimators = [('lr', LinearRegression()), ('rf', RandomForestRegressor(n_estimators=10, random_state=1))]\n    vr = VotingRegressor(estimators, voting=voting, weights=[0.7, 0.3])\n    vr.fit(X, y)\n    y_pred = vr.predict(X)\n    assert len(y_pred) == len(y)\n\n    # Test that VotingRegressor raises an error with incorrect weights\n    with pytest.raises(ValueError):\n        VotingRegressor(estimators, voting=voting, weights=[0.7, 0.2, 0.1])\n", "def test_voting_regressor_weighted_predict():\n    # Test that VotingRegressor.predict returns correct values when weights are\n    # provided.\n    r1 = LinearRegression()\n    r2 = RandomForestRegressor(n_estimators=10, random_state=1)\n    X = np.array([[1, 1], [2, 4], [3, 9], [4, 16], [5, 25], [6, 36]])\n    y = np.array([2, 6, 12, 20, 30, 42])\n    er = VotingRegressor([('lr', r1), ('rf', r2)], weights=[0.5, 0.5])\n    er.fit(X, y)\n    y_pred = er.predict(X)\n    assert_almost_equal(y_pred, np.array([ 3.3,  5.7, 11.8, 19.7, 28. , 40.3]))\n\n    # Now test with different weights\n    er = VotingRegressor([('lr', r1), ('rf', r2)], weights=[0.2, 0.8])\n    er.fit(X, y)\n    y_pred = er.predict(X)\n    assert_almost_equal(y_pred, np.array([ 3.28,  5.76, 11.88, 19.88, 28.2 , 40.48]))\n", "def test_voting_regressor_set_params():\n    # Test setting the parameters of the ensemble estimator\n    reg1 = LinearRegression()\n    reg2 = DummyRegressor(strategy='mean')\n    ereg = VotingRegressor([('lr', reg1), ('dr', reg2)])\n\n    # Check if all parameters are set correctly\n    assert ereg.get_params() == {'estimators': [('lr', reg1), ('dr', reg2)],\n                                 'weights': None,\n                                 'n_jobs': None}\n\n    # Set a parameter for the ensemble\n    ereg.set_params(n_jobs=2)\n    assert ereg.get_params() == {'estimators': [('lr', reg1), ('dr', reg2)],\n                                 'weights': None,\n                                 'n_jobs': 2}\n\n    # Set a parameter for a sub-estimator\n    ereg.set_params(lr__fit_intercept=False)\n    assert reg1.get_params() == {'copy_X': True, 'fit_intercept': False,\n                                 'n_jobs': None, 'normalize': False}\n\n    # Remove one sub-estimator\n    ereg.set_params(dr=None)\n    assert ereg.estimators == [('lr', reg1)]\n", "def test_voting_regressor_weights():\n    # Test VotingRegressor with weights\n    regr1 = LinearRegression()\n    regr2 = RandomForestRegressor(n_estimators=10, random_state=1)\n    regr3 = DummyRegressor()\n\n    X_train, X_test, y_train, y_test = train_test_split(X_r, y_r, test_size=0.2)\n\n    er = VotingRegressor([('lr', regr1), ('rf', regr2), ('dummy', regr3)],\n                         weights=[2, 1, 0])\n    er.fit(X_train, y_train)\n\n    y_pred = er.predict(X_test)\n    assert_array_almost_equal(y_pred, (2 * regr1.fit(X_train, y_train).predict(X_test) +\n                                       regr2.fit(X_train, y_train).predict(X_test)) / 3)\n\n    # Test with weights of zero\n    er = VotingRegressor([('lr', regr1), ('rf', regr2), ('dummy', regr3)],\n                         weights=[0, 0, 0])\n    with pytest.raises(NotFittedError):\n        er.predict(X_test)\n\n    # Test with weights None\n    er = VotingRegressor([('lr', regr1), ('rf', regr2), ('dummy', regr3)])\n    er.fit(X_train, y_train)\n    y_pred = er.predict(X_test)\n    assert_array_almost_equal(y_pred, (regr1.fit(X_train, y_train).predict(X_test) +\n                                       regr2.fit(X_train, y_train).predict(X_test) +\n                                       regr3.fit(X_train, y_train).predict(X_test)) / 3)\n\n    # Test that weights with a single estimator work\n    er = VotingRegressor([('lr', regr1)], weights=[1])\n    er.fit(X_train, y_train)\n    y_pred = er.predict(X_test)\n    assert_array_almost_equal(y_pred, regr1.fit(X_train, y_train).predict(X_test))\n\n    # Test that weights with no estimators raises an error\n    with pytest.raises(ValueError):\n        VotingRegressor([], weights=[1])\n", "def test_voting_regressor_weights():\n    # Test if VotingRegressor correctly handles weights\n    r1 = LinearRegression()\n    r2 = RandomForestRegressor(n_estimators=10, random_state=1)\n    er = VotingRegressor([('lr', r1), ('rf', r2)], weights=[2, 1])\n    er.fit(X_r, y_r)\n    y_pred = er.predict(X_r)\n    er.set_params(weights=[1, 2])\n    y_pred_changed = er.predict(X_r)\n    assert_array_almost_equal(y_pred, y_pred_changed)\n\n"], "sample_53": ["def test_generate_renamed_indexes(self):\n    \"\"\"\n    Test that renamed indexes are correctly generated.\n    \"\"\"\n    # Create a project state with a model that has an index\n    before_state = self.make_project_state(\n        [\n            self.book_indexes,\n        ]\n    )\n\n    # Create a project state with a model that has the same index but with a different name\n    after_state = self.make_project_state(\n        [\n            self.book_unordered_indexes,\n        ]\n    )\n\n    # Generate the changes\n    changes = MigrationAutodetector(before_state, after_state)._detect_changes()\n\n    # Check that a RenameIndex operation is generated\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"RenameIndex\"])\n\n    # Check that the RenameIndex operation has the correct attributes\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        0,\n        model_name=\"book\",\n        old_name=\"book_title_author_idx\",\n        new_name=\"book_author_title_idx\",\n    )\n", "def test_detect_changes_alter_unique_together_with_renamed_fields(self):\n    before_state = ProjectState()\n    before_state.add_model(self.author_with_book)\n    after_state = ProjectState()\n    after_state.add_model(self.book_unique_together)\n    after_state.add_model(self.author_name_renamed)\n\n    changes = MigrationAutodetector(before_state, after_state)._detect_changes()\n\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\"])\n    self.assertOperationAttributes(\n        changes, \"otherapp\", 0, 0, name=\"Book\", unique_together={(\"writer\", \"title\")}\n    )\n", "def test_altered_indexes(self):\n    # Create models with indexes\n    before_state = self.make_project_state(\n        [self.author_empty, self.book_indexes, self.publisher]\n    )\n    after_state = self.make_project_state(\n        [\n            self.author_empty,\n            self.book_unordered_indexes,\n            self.publisher,\n        ]\n    )\n    changes = MigrationAutodetector(before_state, after_state)._detect_changes()\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"RemoveIndex\", \"AddIndex\"])\n\n    # Create models with indexes in index_together\n    before_state = self.make_project_state(\n        [self.author_empty, self.book_foo_together, self.publisher]\n    )\n    after_state = self.make_project_state(\n        [\n            self.author_empty,\n            self.book_foo_together_2,\n            self.publisher,\n        ]\n    )\n    changes = MigrationAutodetector(before_state, after_state)._detect_changes()\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterIndexTogether\"])\n\n    # Create models with indexes in index_together and index_together changed\n    before_state = self.make_project_state(\n        [self.author_empty, self.book_foo_together, self.publisher]\n    )\n    after_state = self.make_project_state(\n        [\n            self.author_empty,\n            self.book_foo_together_3,\n            self.publisher,\n        ]\n    )\n    changes = MigrationAutodetector(before_state, after_state)._detect_changes()\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"RemoveIndex\", \"AddIndex\", \"AlterIndexTogether\"])\n\n    # Create models with indexes in index_together, index_together changed and indexes\n    before_state = self.make_project_state(\n        [self.author_empty, self.book_foo_together, self.publisher]\n    )\n    after_state = self.make_project_state(\n        [\n            self.author_empty,\n            self.book_foo_together_4,\n            self.publisher,\n        ]\n    )\n    changes = MigrationAutodetector(before_state, after_state)._detect_changes()\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"Remove", "def test_altered_indexes(self):\n    before_states = [\n        self.book_indexes,\n    ]\n    after_states = [\n        self.book_unordered_indexes,\n    ]\n    changes = self.get_changes(before_states, after_states)\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterIndexTogether\"])\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        0,\n        index_together={(\"title\", \"author\")},\n    )\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        1,\n        index_together={(\"author\", \"title\")},\n    )\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        2,\n        name=\"book_author_title_idx\",\n    )\n", "def test_create_model_with_custom_field(self):\n    # Create a custom field that is deconstructible\n    class CustomField(models.Field):\n            return (\"CustomField\", (), {})\n\n    before_states = self.make_project_state([self.author_empty])\n    after_states = self.make_project_state(\n        [ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True)), (\"custom_field\", CustomField())])]\n    )\n    changes = MigrationAutodetector(before_states, after_states)._detect_changes()\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\"])\n    self.assertOperationFieldAttributes(\n        changes,\n        \"testapp\",\n        0,\n        0,\n        name=\"custom_field\",\n        column=\"custom_field\",\n        max_length=None,\n        primary_key=False,\n        unique=False,\n        db_index=False,\n        default=models.NOT_PROVIDED,\n        editable=True,\n        serialize=True,\n    )\n"], "sample_137": ["def test_is_palindromic():\n    assert is_palindromic([1, 2, 3, 2, 1])\n    assert not is_palindromic([1, 2, 3, 4, 5])\n    assert is_palindromic('abccba')\n    assert not is_palindromic('hello')\n    assert is_palindromic((1, 2, 1), 0, -1)\n    assert not is_palindromic((1, 2, 3), 0, -1)\n    assert is_palindromic('aba', 0, 3)\n    assert not is_palindromic('abx', 0, 3)\n", "def test_kbinst():\n    # test 00\n    assert set(kbins([1, 2, 3], 2, ordered=0)) == {([1, 2], [3]), ([1, 3], [2]), ([2, 3], [1]), ([1], [2, 3])}\n    # test 01\n    assert set(kbins([1, 2, 3], 2, ordered=1)) == {([1, 2], [3]), ([1, 3], [2]), ([2, 3], [1])}\n    # test 10\n    assert set(kbins([1, 2, 3], 2, ordered=10)) == {([1, 2], [3]), ([1, 3], [2]), ([2, 3], [1]), ([2], [1, 3]), ([3], [1, 2]), ([1], [3, 2]), ([3, 1], [2]), ([3, 2], [1]), ([2, 1], [3]), ([2, 3], [1])}\n    # test 11\n    assert set(kbins([1, 2, 3], 2, ordered=11)) == {([1, 2], [3]), ([1, 3], [2]), ([2, 3], [1]), ([2], [1, 3]), ([3], [1, 2]), ([1], [3, 2]), ([3, 1], [2]), ([3, 2], [1]), ([2, 1], [3]), ([2, 3], [1]), ([1, 3], [2]), ([2, 1], [3])}\n", "def test_multiset_partitions():\n    # Check that the set partitions are generated in the correct order.\n    expected_partitions = [\n        [[1, 1, 1, 1]],\n        [[1, 1, 1], [1]],\n        [[1, 1], [1, 1]],\n        [[1, 1], [1], [1]],\n        [[1], [1], [1], [1]]\n    ]\n    assert list(multiset_partitions(4)) == expected_partitions\n\n    # Check that the number of partitions is correct for some larger inputs.\n    assert len(list(multiset_partitions(7))) == 15\n    assert len(list(multiset_partitions(8))) == 22\n    assert len(list(multiset_partitions(9))) == 30\n\n    # Check that the partitions are correct for a multiset with repeated elements.\n    expected_partitions = [\n        [[1, 1, 1], [2, 2]],\n        [[1, 1], [1, 2, 2]],\n        [[1], [1, 1], [2, 2]],\n        [[1], [1], [1], [2, 2]],\n        [[1, 2, 2], [1, 1]],\n        [[1, 2], [1, 2], [1]],\n        [[1, 2], [1], [1], [2]],\n        [[1], [1, 2], [1, 2]],\n        [[1], [1], [1, 2], [2]],\n        [[1], [1], [1], [1], [2, 2]],\n        [[1], [1], [1], [2], [2]],\n        [[1, 1], [1, 1], [2]],\n        [[1, 1], [1], [1], [2]],\n        [[1, 1], [1], [2], [2]],\n        [[1], [1, 1], [1], [2]],\n        [[1], [1], [1, 1], [2]],\n        [[1], [1], [1], [1], [2]],\n        [[1], [1], [2], [2]]\n    ]\n    assert sorted(multiset_partitions([1, 1, 1, 2, 2])) == expected_partitions\n\n    # Check that the partitions", "def test_multiset_partitions():\n    # Test the multiset_partitions function.\n    assert len(list(multiset_partitions([1,1,1,2,2]))) == 15\n    assert len(list(multiset_partitions([1,2,3]))) == 7\n    assert len(list(multiset_partitions([1,2,3,4]))) == 15\n    assert len(list(multiset_partitions([1,2,3,4,5]))) == 52\n    assert len(list(multiset_partitions([1,2,2,2]))) == 8\n\n    # Test the multiset_partitions function with m parameter.\n    assert len(list(multiset_partitions([1,1,1,2,2], 2))) == 6\n    assert len(list(multiset_partitions([1,2,3], 3))) == 4\n    assert len(list(multiset_partitions([1,2,3,4], 2))) == 8\n    assert len(list(multiset_partitions([1,2,3,4,5], 3))) == 25\n    assert len(list(multiset_partitions([1,2,2,2], 1))) == 1\n\n    # Test the multiset_partitions function with duplicate elements.\n    assert len(list(multiset_partitions([1,1,1,1,1]))) == 1\n    assert len(list(multiset_partitions([2,2,2,2]))) == 1\n    assert len(list(multiset_partitions([3,3,3,3,3]))) == 1\n    assert len(list(multiset_partitions([4,4,4,4,4,4]))) == 1\n    assert len(list(multiset_partitions([5,5,5,5,5,5,5]))) == 1\n\n    # Test the multiset_partitions function with empty input.\n    assert len(list(multiset_partitions([]))) == 1\n\n    # Test the multiset_partitions function with m parameter and empty input.\n    assert len(list(multiset_partitions([], 2))) == 0\n    assert len(list(multiset_partitions([], 1))) == 0\n", "def test_multiset_permutations():\n    assert set(multiset_permutations([1, 1, 2, 2])) == {\n        (1, 1, 2, 2), (1, 2, 1, 2), (1, 2, 2, 1), (2, 1, 1, 2),\n        (2, 1, 2, 1), (2, 2, 1, 1)\n    }\n    assert set(multiset_permutations([1, 1, 1, 2])) == {\n        (1, 1, 1, 2), (1, 1, 2, 1), (1, 2, 1, 1), (2, 1, 1, 1)\n    }\n    assert set(multiset_permutations([1, 1, 1, 1])) == {(1, 1, 1, 1)}\n"], "sample_86": ["def test_junitxml_with_record_property(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n            record_property(\"example_key\", 1)\n            assert 1 == 1\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    testnode = dom.find_first_by_tag(\"testcase\")\n    properties = testnode.find_first_by_tag(\"properties\")\n    assert properties\n    assert properties.get_unique_child.tag == \"property\"\n    assert properties.get_unique_child[\"name\"] == \"example_key\"\n    assert properties.get_unique_child[\"value\"] == \"1\"\n", "def test_properties_collection(testdir):\n    # Create a test file with a test that collects properties\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            return request.config._xml.add_global_property\n\n            record_property(\"my_key\", \"my_value\")\n            record_property(\"my_other_key\", \"my_other_value\")\n    \"\"\"\n    )\n\n    # Run the test and collect the output\n    result, dom = runandparse(testdir)\n\n    # Check that the properties are correctly collected\n    properties = dom.find_first_by_tag(\"properties\")\n    assert properties.find_nth_by_tag(\"property\", 0).assert_attr(name=\"my_key\", value=\"my_value\")\n    assert properties.find_nth_by_tag(\"property\", 1).assert_attr(name=\"my_other_key\", value=\"my_other_value\")\n\n", "def test_xml_node_properties(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            import pytest\n\n            @pytest.fixture\n                return request.node.user_properties.append\n\n                record_property(\"example_key\", \"example_value\")\n        \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    testcase = dom.find_first_by_tag(\"testcase\")\n    assert testcase.assert_attr(\n        example_key=\"example_value\",\n    )\n", "    def test_update_testcase_duration(self):\n        xml = LogXML(\"log.xml\", \"\", \"test_suite\")\n        reporter = xml.node_reporter(\"node1\")\n        report = BaseReport(\n            \"node1\",\n            \"call\",\n            0,\n            1,\n            [],\n            [],\n            [],\n            \"\",\n            \"\",\n            \"teardown\",\n            0,\n            \"teardown\",\n            0,\n            0,\n        )\n        xml.update_testcase_duration(report)\n        assert reporter.duration == 0.0\n        report = BaseReport(\n            \"node1\",\n            \"call\",\n            0,\n            1,\n            [],\n            [],\n            [],\n            \"\",\n            \"\",\n            \"call\",\n            1,\n            \"call\",\n            0,\n            0,\n        )\n        xml.update_testcase_duration(report)\n        assert reporter.duration == 1.0\n", "def test_node_reporter_add_property(testdir):\n    logxml = LogXML(\n        \"test.log\", None, \"my_suite\", \"no\", \"total\", \"xunit1\", log_passing_tests=True\n    )\n    node_reporter = logxml.node_reporter(\"node1\")\n\n    node_reporter.add_property(\"foo\", \"bar\")\n    node_reporter.add_property(\"baz\", \"qux\")\n\n    testcase = node_reporter.to_xml()\n    properties = testcase.find_by_tag(\"properties\")\n    assert len(properties) == 1\n    property_node = properties[0]\n    assert property_node.find_nth_by_tag(\"property\", 0).assert_attr(name=\"foo\") == \"bar\"\n    assert property_node.find_nth_by_tag(\"property\", 0).text == \"bar\"\n    assert property_node.find_nth_by_tag(\"property\", 1).assert_attr(name=\"baz\") == \"baz\"\n    assert property_node.find_nth_by_tag(\"property\", 1).text == \"qux\"\n\n"], "sample_83": ["def test_colorized_text_reporter(reporter):\n    with warnings.catch_warnings(record=True) as w:\n        reporter = ColorizedTextReporter()\n        assert len(w) == 0\n\n        # Test colorized text reporter with deprecated color mapping\n        deprecated_color_mapping = {\n            \"I\": (\"green\", \"bold\"),\n            \"C\": (\"red\",),\n        }\n        reporter = ColorizedTextReporter(color_mapping=deprecated_color_mapping)\n        assert len(w) == 1\n        assert w[0].category == DeprecationWarning\n\n        # Test colorized text reporter with valid color mapping\n        valid_color_mapping = {\n            \"I\": MessageStyle(\"green\", (\"bold\",)),\n            \"C\": MessageStyle(\"red\"),\n        }\n        reporter = ColorizedTextReporter(color_mapping=valid_color_mapping)\n        assert len(w) == 1  # Still one deprecation warning from previous test\n\n        # Test handle_message method\n        message = Message(\n            msg_id=\"I\",\n            symbol=\"symbol\",\n            msg=\"message\",\n            C=\"C\",\n            category=\"category\",\n            confidence=HIGH,\n            abscolumn=1,\n            column=1,\n            lineno=1,\n            obj=\"obj\",\n            end_lineno=1,\n            end_column=1,\n        )\n        with StringIO() as output:\n            with redirect_stdout(output):\n                reporter.handle_message(message)\n            output.seek(0)\n            assert \"message\" in output.read()\n\n        # Test _get_decoration method\n        assert isinstance(reporter._get_decoration(\"I\"), MessageStyle)\n", "def test_colorize_ansi_with_message_style():\n    msg = \"Test message\"\n    msg_style = MessageStyle(\"red\", (\"bold\", \"underline\"))\n    colorized_msg = colorize_ansi(msg, msg_style)\n    assert colorized_msg.startswith(\"\\033[\")\n    assert \"\\033[31;1;4m\" in colorized_msg\n    assert \"\\033[0m\" in colorized_msg\n    assert msg in colorized_msg\n\n", "def test_colorized_text_reporter_handle_message(caplog):\n    # Create a PyLinter instance with a ColorizedTextReporter\n    linter = PyLinter()\n    reporter = ColorizedTextReporter()\n    linter.set_reporter(reporter)\n    linter.set_option(\"exit-zero\", True)\n\n    # Create a message to test\n    msg = Message(\n        msg_id=\"E0001\",\n        line=1,\n        column=1,\n        msg=\"Test message\",\n        symbol=\"test-symbol\",\n        C=\"E\",\n        category=\"Error\",\n    )\n\n    # Test the handle_message method\n    reporter.handle_message(msg)\n\n    # Check that the message is colorized correctly\n    assert \"Test message\" in caplog.text\n    assert \"\\033[31m\" in caplog.text  # Red color code for Error messages\n", "def test_handle_message_with_colorized_text_reporter(capsys, reporter):\n    \"\"\"Test handle_message with a colorized text reporter.\"\"\"\n    linter = PyLinter()\n    linter.set_reporter(ColorizedTextReporter())\n    msg = Message(\n        msg_id=\"W0001\",\n        symbol=\"symbol\",\n        msg=\"message\",\n        C=\"W\",\n        category=\"category\",\n        line=1,\n        column=1,\n    )\n    linter.handle_message(msg)\n    captured = capsys.readouterr()\n    assert \"\\033[\" in captured.out\n", "def test_colorize_ansi(reporter):\n    text_reporter = TextReporter()\n    message = \"Hello, world!\"\n    message_style = MessageStyle(\"green\")\n    colorized_message = colorize_ansi(message, message_style)\n    assert colorized_message.startswith(\"\\033[32m\")\n    assert colorized_message.endswith(\"mHello, world!\\033[0m\")\n"], "sample_7": ["    def test_common_roots(self):\n        path1 = Path('/a/b/c/d/e')\n        path2 = Path('/a/b/c/d/f')\n        path3 = Path('/a/b/c/g/h')\n        roots = autoreload.common_roots([path1, path2, path3])\n        self.assertEqual(roots, (Path('/a/b/c'),))\n", "    def test_watchman_subscriptions(self):\n        # Create a WatchmanReloader instance.\n        reloader = autoreload.WatchmanReloader()\n\n        # Create a temporary directory to watch.\n        temp_dir = self.temporary_file('temp_dir')\n        temp_dir.mkdir()\n\n        # Create a temporary file to watch.\n        temp_file = temp_dir / 'temp_file.py'\n        temp_file.touch()\n\n        # Add the temporary file to the reloader.\n        reloader.watch_file(temp_file)\n\n        # Add the temporary directory to the reloader.\n        reloader.watch_dir(temp_dir, '*.py')\n\n        # Update the reloader's watches.\n        reloader.update_watches()\n\n        # Check that the reloader has subscriptions for the file and directory.\n        self.assertIn(temp_file, reloader.extra_files)\n        self.assertIn(temp_dir, reloader.directory_globs)\n\n        # Simulate a file change.\n        temp_file.touch()\n\n        # Check that the reloader notifies the file change.\n        with mock.patch.object(reloader, 'notify_file_changed') as mock_notify:\n            reloader._check_subscription('subscription')\n            mock_notify.assert_called_once_with(temp_file)\n\n        # Clean up.\n        shutil.rmtree(temp_dir)\n", "    def test_check_availability(self):\n        original_client = autoreload.pywatchman.client\n        try:\n            with mock.patch('pywatchman.client') as mock_client:\n                mock_client.side_effect = autoreload.WatchmanError('Mock error')\n                with self.assertRaises(autoreload.WatchmanUnavailable):\n                    autoreload.WatchmanReloader.check_availability()\n        finally:\n            autoreload.pywatchman.client = original_client\n", "    def test_check_errors_decorator(self):\n        @autoreload.check_errors\n            raise ValueError('Test error')\n\n        with self.assertRaises(ValueError) as context:\n            test_function()\n        self.assertEqual(str(context.exception), 'Test error')\n", "    def test_sys_path_directories(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            sys_path = Path(tempdir)\n            sys.path.insert(0, str(sys_path))\n\n            # File in sys.path\n            file_path = sys_path / 'file.txt'\n            file_path.touch()\n            self.assertIn(file_path.parent, list(autoreload.sys_path_directories()))\n\n            # Non-existent directory in sys.path\n            dir_path = sys_path / 'non_existent_dir'\n            sys.path.insert(0, str(dir_path))\n            self.assertNotIn(dir_path, list(autoreload.sys_path_directories()))\n\n            # Cleanup\n            sys.path.remove(str(sys_path))\n            sys.path.remove(str(dir_path))\n"], "sample_22": ["    def test_slugify(self):\n        self.assertEqual(text.slugify(\"Hello World\"), \"hello-world\")\n        self.assertEqual(text.slugify(\"   Hello   World   \"), \"hello-world\")\n        self.assertEqual(text.slugify(\"Hello_World\"), \"hello_world\")\n        self.assertEqual(text.slugify(\"Hello---World\"), \"hello-world\")\n        self.assertEqual(text.slugify(\"\u00e1\u00e9\u00ed\u00f3\u00fa\"), \"aeiou\")\n        self.assertEqual(text.slugify(\"\u00e1\u00e9\u00ed\u00f3\u00fa\", allow_unicode=True), \"\u00e1\u00e9\u00ed\u00f3\u00fa\")\n", "def test_text_truncator(self):\n    truncator = text.Truncator(\"This is a long string that needs to be truncated.\")\n    self.assertEqual(truncator.chars(10), \"This is a l\u2026\")\n\n    truncator = text.Truncator(\"<p>This is a long string that needs to be truncated.</p>\")\n    self.assertEqual(truncator.chars(15, html=True), \"<p>This is a\u2026</p>\")\n\n    truncator = text.Truncator(\"This is a long string that needs to be truncated.\")\n    self.assertEqual(truncator.words(3), \"This is a\u2026\")\n\n    truncator = text.Truncator(\"<p>This is a long string that needs to be truncated.</p>\")\n    self.assertEqual(truncator.words(3, html=True), \"<p>This is\u2026</p>\")\n\n    truncator = text.Truncator(\"\")\n    self.assertEqual(truncator.chars(10), \"\")\n    self.assertEqual(truncator.words(10), \"\")\n\n    truncator = text.Truncator(\"<p></p>\")\n    self.assertEqual(truncator.chars(10, html=True), \"<p></p>\")\n    self.assertEqual(truncator.words(10, html=True), \"<p></p>\")\n", "    def test_unescape_entities(self):\n        with override('en'):\n            self.assertEqual(text.unescape_entities('&amp;'), '&')\n            self.assertEqual(text.unescape_entities('&lt;'), '<')\n            self.assertEqual(text.unescape_entities('&gt;'), '>')\n            self.assertEqual(text.unescape_entities('&quot;'), '\"')\n            self.assertEqual(text.unescape_entities('&apos;'), \"'\")\n            self.assertEqual(text.unescape_entities('&#38;'), '&')\n            self.assertEqual(text.unescape_entities('&#60;'), '<')\n            self.assertEqual(text.unescape_entities('&#62;'), '>')\n            self.assertEqual(text.unescape_entities('&#34;'), '\"')\n            self.assertEqual(text.unescape_entities('&#39;'), \"'\")\n", "    def test_unescape_entities(self):\n        self.assertEqual(text.unescape_entities('A &amp; B'), 'A & B')\n        self.assertEqual(text.unescape_entities('&copy; 2020'), ' 2020')\n        self.assertEqual(text.unescape_entities('&#169; 2020'), ' 2020')\n        self.assertEqual(text.unescape_entities('&#xA9; 2020'), ' 2020')\n        self.assertEqual(text.unescape_entities('A &#x26; B'), 'A & B')\n", "    def test_slugify(self):\n        # Test that slugify() preserves ASCII characters\n        self.assertEqual(text.slugify('Hello World'), 'hello-world')\n\n        # Test that slugify() removes non-ASCII characters when allow_unicode=False\n        self.assertEqual(text.slugify('\u00e1\u00e9\u00ed\u00f3\u00fa'), '')\n\n        # Test that slugify() preserves non-ASCII characters when allow_unicode=True\n        self.assertEqual(text.slugify('\u00e1\u00e9\u00ed\u00f3\u00fa', allow_unicode=True), '\u00e1\u00e9\u00ed\u00f3\u00fa')\n\n        # Test that slugify() converts spaces to dashes\n        self.assertEqual(text.slugify('Hello World'), 'hello-world')\n\n        # Test that slugify() removes underscores\n        self.assertEqual(text.slugify('Hello_World'), 'hello-world')\n\n        # Test that slugify() converts uppercase characters to lowercase\n        self.assertEqual(text.slugify('HELLO WORLD'), 'hello-world')\n\n        # Test that slugify() removes leading and trailing whitespace\n        self.assertEqual(text.slugify('   Hello World   '), 'hello-world')\n\n        # Test that slugify() removes leading and trailing dashes and underscores\n        self.assertEqual(text.slugify('_Hello_World_'), 'hello-world')\n\n        # Test that slugify() replaces multiple dashes with a single dash\n        self.assertEqual(text.slugify('Hello---World'), 'hello-world')\n\n        # Test that slugify() replaces multiple underscores with a single dash\n        self.assertEqual(text.slugify('Hello___World'), 'hello-world')\n\n        # Test that slugify() replaces multiple spaces with a single dash\n        self.assertEqual(text.slugify('Hello   World'), 'hello-world')\n\n        # Test that slugify() handles special characters\n        self.assertEqual(text.slugify('Hello! World@'), 'hello-world')\n\n        # Test that slugify() handles non-English characters\n        self.assertEqual(text.slugify('\u00a1Hola Mundo!'), 'hola-mundo')\n"], "sample_72": ["def test_subplots_adjust():\n    fig, axs = plt.subplots(2, 2)\n    fig.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9)\n    assert axs[0, 0].get_position().x0 == pytest.approx(0.1)\n    assert axs[0, 0].get_position().y0 == pytest.approx(0.1)\n    assert axs[1, 1].get_position().x1 == pytest.approx(0.9)\n    assert axs[1, 1].get_position().y1 == pytest.approx(0.9)\n\n    fig.subplots_adjust(left=0.2, bottom=0.2, right=0.8, top=0.8)\n    assert axs[0, 0].get_position().x0 == pytest.approx(0.2)\n    assert axs[0, 0].get_position().y0 == pytest.approx(0.2)\n    assert axs[1, 1].get_position().x1 == pytest.approx(0.8)\n    assert axs[1, 1].get_position().y1 == pytest.approx(0.8)\n", "def test_figure_draw_without_rendering():\n    fig = Figure()\n    assert not fig.stale\n    ax = fig.add_subplot(111)\n    ax.set_title('Title')\n    ax.text(0.5, 0.5, 'Text')\n    fig.draw_without_rendering()\n    assert not fig.stale\n    assert ax.title.get_window_extent().width > 0\n    assert ax.texts[0].get_window_extent().width > 0\n", "def test_layout_engine_deprecation_warning():\n    # Test that using tight_layout/constrained_layout parameter on Figure\n    # constructor triggers deprecation warnings.\n\n    with pytest.warns(DeprecationWarning,\n                      match=\"The Figure parameters 'layout' and 'tight_layout' \"\n                            \"cannot be used together\"):\n        fig = Figure(tight_layout=True, layout='constrained')\n\n    with pytest.warns(DeprecationWarning,\n                      match=\"The Figure parameters 'layout' and \"\n                            \"'constrained_layout' cannot be used together\"):\n        fig = Figure(constrained_layout=True, layout='tight')\n\n    with pytest.warns(DeprecationWarning, match=\"set_tight_layout\"):\n        fig.set_tight_layout(True)\n\n    with pytest.warns(DeprecationWarning, match=\"set_constrained_layout\"):\n        fig.set_constrained_layout(True)\n\n    with pytest.warns(DeprecationWarning, match=\"set_constrained_layout_pads\"):\n        fig.set_constrained_layout_pads(w_pad=0.1)\n", "def test_layout_engine_api():\n    fig = Figure()\n\n    # test case for: layout parameter\n    with pytest.warns(UserWarning, match=_EXPECTED_WARNING_TOOLMANAGER):\n        fig.set_layout_engine(layout=\"constrained\")\n    assert isinstance(fig.get_layout_engine(), transforms.ConstrainedLayoutEngine)\n    \n    # test case for: layout parameter with engine\n    fig.set_layout_engine(layout=transforms.ConstrainedLayoutEngine())\n    assert isinstance(fig.get_layout_engine(), transforms.ConstrainedLayoutEngine)\n    \n    # test case for: no layout parameter\n    fig.set_layout_engine()\n    assert isinstance(fig.get_layout_engine(), transforms.ConstrainedLayoutEngine)\n    \n    # test case for: layout=\"none\"\n    fig.set_layout_engine(layout=\"none\")\n    assert fig.get_layout_engine() is None\n    \n    # test case for: layout=\"tight\"\n    fig.set_layout_engine(layout=\"tight\")\n    assert isinstance(fig.get_layout_engine(), transforms.TightLayoutEngine)\n    \n    # test case for: layout=\"compressed\"\n    fig.set_layout_engine(layout=\"compressed\")\n    assert isinstance(fig.get_layout_engine(), transforms.ConstrainedLayoutEngine)\n    \n    # test case for: layout=None\n    fig.set_layout_engine(layout=None)\n    assert isinstance(fig.get_layout_engine(), transforms.ConstrainedLayoutEngine)\n", "def test_subplots_adjust():\n    fig = Figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2)\n\n    fig.subplots_adjust(top=0.8)\n\n    # Without any rendering, the _geometryDirty attribute is always True\n    assert ax1.get_position().frozen is True\n    assert ax2.get_position().frozen is True\n\n    fig.canvas.draw()\n\n    assert ax1.get_position().frozen is False\n    assert ax2.get_position().frozen is False\n\n    fig.subplots_adjust(top=0.9)\n\n    assert ax1.get_position().frozen is True\n    assert ax2.get_position().frozen is True\n\n    fig.canvas.draw()\n\n    assert ax1.get_position().frozen is False\n    assert ax2.get_position().frozen is False\n\n    # Test with constrained_layout\n    fig = Figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2)\n    fig.set_constrained_layout(True)\n\n    fig.subplots_adjust(top=0.8)\n\n    fig.canvas.draw()\n\n    assert ax1.get_position().frozen is False\n    assert ax2.get_position().frozen is False\n\n    fig.subplots_adjust(top=0.9)\n\n    assert ax1.get_position().frozen is False\n    assert ax2.get_position().frozen is False\n\n    fig.canvas.draw()\n\n    assert ax1.get_position().frozen is False\n    assert ax2.get_position().frozen is False\n"], "sample_150": ["def test_solve_biquadratic():\n    f = Poly(y**2 - 4 + x, y, x, domain='ZZ')\n    g = Poly(y*2 + 3*x - 7, y, x, domain='ZZ')\n    NewOption = Poly.Options((x, y), {'domain': 'ZZ'})\n\n    solutions = solve_biquadratic(f, g, NewOption)\n    expected_solutions = [(41/27, 11/9), (1/3, 3)]\n    assert set(solutions) == set(expected_solutions)\n\n    f = Poly(y + x**2 - 3, y, x, domain='ZZ')\n    g = Poly(-y + x - 4, y, x, domain='ZZ')\n\n    solutions = solve_biquadratic(f, g, NewOption)\n    expected_solutions = [(7/2 - sqrt(29)/2, -sqrt(29)/2 - 1/2), (sqrt(29)/2 + 7/2, -1/2 + sqrt(29)/2)]\n    assert set(solutions) == set(expected_solutions)\n", "def test_solve_biquadratic():\n    x, y = symbols('x y')\n    f = Poly(y**2 - 4 + x, y, x, domain='ZZ')\n    g = Poly(y*2 + 3*x - 7, y, x, domain='ZZ')\n    assert solve_biquadratic(f, g, parallel_poly_from_expr([f, g], x, y)[1]) == \\\n        [(Rational(1, 3), Rational(11, 9)), (Rational(41, 27), Rational(11, 9))]\n\n    f = Poly(y + x**2 - 3, y, x, domain='ZZ')\n    g = Poly(-y + x - 4, y, x, domain='ZZ')\n    assert solve_biquadratic(f, g, parallel_poly_from_expr([f, g], x, y)[1]) == \\\n        [(Rational(7, 2) + sqrt(29)/2, sqrt(29)/2 - Rational(1, 2)), \n         (Rational(7, 2) - sqrt(29)/2, -sqrt(29)/2 - Rational(1, 2))]\n\n    # Test that a SolveFailed is raised when the system is not zero-dimensional\n    f = Poly(x - y, x, y, domain='ZZ')\n    g = Poly(x + y, x, y, domain='ZZ')\n    raises(SolveFailed, lambda: solve_biquadratic(f, g, parallel_poly_from_expr([f, g], x, y)[1]))\n\n    # Test that a SolveFailed is raised when there are more than two equations\n    f = Poly(x - y, x, y, domain='ZZ')\n    g = Poly(x + y, x, y, domain='ZZ')\n    h = Poly(x + y**2, x, y, domain='ZZ')\n    raises(ValueError, lambda: solve_biquadratic(f, g, parallel_poly_from_expr([f, g, h], x, y)[1]))\n", "def test_solve_poly_system():\n    x, y = symbols('x y')\n    raises(SolveFailed, lambda: solve_biquadratic(Poly(x**2 - y, x, y), Poly(x**2 + y, x, y), parallel_poly_from_expr([x**2 - y, x**2 + y], x, y)[1]))\n\n    assert solve_poly_system([x**2 + y, x + y], x, y) == [(-sqrt(-y), y), (sqrt(-y), y)]\n\n    assert solve_poly_system([x**2 + y + 1, x + y - 1], x, y) == []\n", "def test_solve_poly_system_biquadratic():\n    x, y = symbols('x y')\n    f = Poly(x**2 + y**2 - 1, x, y)\n    g = Poly(x + y, x, y)\n    assert solve_biquadratic(f, g) == [(-sqrt(2)/2, sqrt(2)/2), (sqrt(2)/2, -sqrt(2)/2)]\n\n", "def test_solve_biquadratic():\n    x, y = symbols('x y')\n\n    # Test case: two bivariate quadratic equations with 3 solutions\n    f = Poly(x**2 + y**2 - 4, x, y, domain='ZZ')\n    g = Poly(x + y - 3, x, y, domain='ZZ')\n    solutions = solve_biquadratic(f, g, parallel_poly_from_expr([f, g], x, y)[1])\n    assert set(solutions) == set([(1, 2), (2, 1)])\n\n    # Test case: two bivariate quadratic equations with 2 solutions\n    f = Poly(x**2 + y**2 - 2, x, y, domain='ZZ')\n    g = Poly(x + y - 2, x, y, domain='ZZ')\n    solutions = solve_biquadratic(f, g, parallel_poly_from_expr([f, g], x, y)[1])\n    assert set(solutions) == set([(1, 1), (1, 1)])\n\n    # Test case: two bivariate quadratic equations with 0 solutions\n    f = Poly(x**2 + y**2 - 4, x, y, domain='ZZ')\n    g = Poly(x + y - 1, x, y, domain='ZZ')\n    with raises(SolveFailed):\n        solve_biquadratic(f, g, parallel_poly_from_expr([f, g], x, y)[1])\n\n    # Test case: two bivariate quadratic equations with non-zero dimensional solution\n    f = Poly(x**2 + y**2, x, y, domain='ZZ')\n    g = Poly(x + y, x, y, domain='ZZ')\n    with raises(SolveFailed):\n        solve_biquadratic(f, g, parallel_poly_from_expr([f, g], x, y)[1])\n"], "sample_40": ["def test_boundfield_init(self):\n    form = Person()\n    field = form.fields['first_name']\n    bound_field = BoundField(form, field, 'first_name')\n    self.assertEqual(bound_field.name, 'first_name')\n    self.assertEqual(bound_field.html_name, 'first_name')\n    self.assertEqual(bound_field.html_initial_name, 'initial-first_name')\n    self.assertEqual(bound_field.html_initial_id, 'initial-id_first_name')\n", "    def test_bound_field_rendering(self):\n        form = Person({'first_name': 'John', 'last_name': 'Doe', 'birthday': '1990-01-01'})\n        bound_field = form['first_name']\n        self.assertEqual(str(bound_field), '<input type=\"text\" name=\"first_name\" value=\"John\">')\n\n        # Test rendering with custom widget\n        form = PersonNew({'first_name': 'John', 'last_name': 'Doe', 'birthday': '1990-01-01'})\n        bound_field = form['first_name']\n        self.assertIn('id=\"first_name_id\"', str(bound_field))\n\n        # Test rendering of hidden field\n        bound_field = form['birthday']\n        self.assertEqual(bound_field.as_hidden(), '<input type=\"hidden\" name=\"birthday\" value=\"1990-01-01\">')\n\n        # Test rendering of textarea\n        form = Person({'first_name': 'John', 'last_name': 'Doe', 'birthday': '1990-01-01'})\n        bound_field = form['first_name']\n        self.assertEqual(bound_field.as_textarea(), '<textarea name=\"first_name\" cols=\"40\" rows=\"10\">John</textarea>')\n\n        # Test rendering of label\n        bound_field = form['first_name']\n        self.assertEqual(bound_field.label_tag(), '<label for=\"id_first_name\">First name:</label>')\n\n        # Test rendering of label with custom id\n        form = PersonNew({'first_name': 'John', 'last_name': 'Doe', 'birthday': '1990-01-01'})\n        bound_field = form['first_name']\n        self.assertEqual(bound_field.label_tag(), '<label for=\"first_name_id\">First name:</label>')\n\n        # Test rendering of errors\n        form = Person({'first_name': '', 'last_name': 'Doe', 'birthday': '1990-01-01'})\n        form.is_valid()\n        bound_field = form['first_name']\n        self.assertEqual(str(bound_field.errors), '<ul class=\"errorlist\"><li>This field cannot be blank.</li></ul>')\n\n        # Test rendering of CSS classes\n        form = Person({'first_name': 'John', 'last_name': 'Doe', 'birthday': '1990-01-01'})\n        bound_field = form['first_name']\n        self.assertEqual(bound_field.css_classes(), '')\n        form = Person({'first_name", "def test_boundfield_rendering(self):\n    form = Person({'first_name': 'John', 'last_name': 'Doe', 'birthday': '2020-01-01'})\n    form.is_valid()\n    bound_field = form['first_name']\n    self.assertEqual(str(bound_field), '<input type=\"text\" name=\"first_name\" value=\"John\">')\n\n    bound_field_hidden = form.hidden_fields()[0]\n    self.assertEqual(str(bound_field_hidden), '<input type=\"hidden\" name=\"birthday\" value=\"2020-01-01\">')\n\n    bound_field_textarea = BoundField(form, CharField(widget=Textarea), 'description')\n    self.assertEqual(bound_field_textarea.as_textarea(), '<textarea name=\"description\" cols=\"40\" rows=\"10\"></textarea>')\n\n    bound_field_hidden_initial = BoundField(form, CharField(show_hidden_initial=True), 'initial_field')\n    self.assertEqual(str(bound_field_hidden_initial), '<input type=\"text\" name=\"initial_field\" value=\"\"><input type=\"hidden\" name=\"initial_field\" value=\"\">')\n", "    def test_boundfield(self):\n        form = Person()\n        bound_field = form['first_name']\n        self.assertIsInstance(bound_field, BoundField)\n        self.assertEqual(bound_field.name, 'first_name')\n        self.assertEqual(bound_field.label, 'First name')\n        self.assertEqual(bound_field.help_text, '')\n\n        form = PersonNew()\n        bound_field = form['first_name']\n        self.assertEqual(bound_field.label_tag(), '<label for=\"first_name_id\">First name:</label>')\n        self.assertEqual(bound_field.auto_id, 'id_first_name')\n        self.assertEqual(bound_field.id_for_label, 'first_name_id')\n        self.assertEqual(bound_field.widget_type, 'textinput')\n\n        form = Person(data={'first_name': 'John'})\n        bound_field = form['first_name']\n        self.assertEqual(bound_field.value(), 'John')\n        self.assertEqual(bound_field.data, 'John')\n        self.assertEqual(bound_field.initial, '')\n\n        form = Person(data={'first_name': 'John', 'last_name': 'Doe'})\n        bound_field = form['first_name']\n        self.assertTrue(bound_field)\n        self.assertEqual(len(bound_field), 1)\n        self.assertEqual(bound_field.errors, [])\n\n        bound_field = form['non_existent_field']\n        self.assertEqual(bound_field, None)\n", "    def test_boundfield_subwidgets(self):\n        form = PersonNew({'first_name': 'John', 'last_name': 'Doe', 'birthday': '2000-01-01'})\n        bound_field = form['first_name']\n        self.assertIsInstance(bound_field.subwidgets, list)\n        self.assertEqual(len(bound_field.subwidgets), 1)\n        self.assertIsInstance(bound_field.subwidgets[0], BoundWidget)\n        self.assertEqual(bound_field.subwidgets[0].parent_widget.__class__.__name__, 'TextInput')\n"], "sample_155": ["def test_get_dimensional_expr():\n    x = symbols('x')\n    expr = x**2\n    expected_expr = S.One\n    assert SI.get_dimensional_expr(expr) == expected_expr\n\n    expr = 2 * x\n    expected_expr = S.One\n    assert SI.get_dimensional_expr(expr) == expected_expr\n\n    expr = x + 2\n    expected_expr = S.One\n    assert SI.get_dimensional_expr(expr) == expected_expr\n\n    expr = sin(x)\n    expected_expr = S.One\n    assert SI.get_dimensional_expr(expr) == expected_expr\n\n    expr = diff(x**2, x)\n    expected_expr = S.One\n    assert SI.get_dimensional_expr(expr) == expected_expr\n\n    expr = integrate(x**2, x)\n    expected_expr = S.One\n    assert SI.get_dimensional_expr(expr) == expected_expr\n\n    expr = Quantity(\"meter\")\n    expected_expr = length.name\n    assert SI.get_dimensional_expr(expr) == expected_expr\n", "def test_get_dimensional_expr():\n    x = symbols('x')\n    expr = 5 * meter * (second ** -1)\n    expected = length / time\n    assert SI.get_dimensional_expr(expr) == expected\n\n    expr = 5 * meter / second\n    expected = length / time\n    assert SI.get_dimensional_expr(expr) == expected\n\n    expr = 5 * meter + 3 * meter\n    expected = length\n    assert SI.get_dimensional_expr(expr) == expected\n\n    expr = diff(x**2, x)\n    expected = S.One\n    assert SI.get_dimensional_expr(expr) == expected\n\n    expr = sin(x)\n    expected = S.One\n    assert SI.get_dimensional_expr(expr) == expected\n\n    expr = integrate(x**2, x)\n    expected = S.One\n    assert SI.get_dimensional_expr(expr) == expected\n\n    expr = sqrt(x)\n    expected = S.One\n    assert SI.get_dimensional_expr(expr) == expected\n\n    expr = exp(x)\n    expected = S.One\n    assert SI.get_dimensional_expr(expr) == expected\n\n    expr = log(x)\n    expected = S.One\n    assert SI.get_dimensional_expr(expr) == expected\n\n    expr = Abs(x)\n    expected = S.One\n    assert SI.get_dimensional_expr(expr) == expected\n", "def test_UnitSystem():\n    # Test the UnitSystem class\n    us = UnitSystem((meter, kilogram, second), name=\"SI\", descr=\"International System of Units\")\n    assert str(us) == \"SI\"\n    assert repr(us) == '<UnitSystem: (meter, kilogram, second)>'\n\n    # Test the extend method\n    new_us = us.extend((kelvin,), name=\"SI_k\", description=\"International System of Units with temperature\")\n    assert new_us.name == \"SI_k\"\n    assert new_us.descr == \"International System of Units with temperature\"\n    assert new_us._base_units == (meter, kilogram, second, kelvin)\n    assert new_us._units == (meter, kilogram, second, kelvin)\n\n    # Test the get_dimension_system method\n    assert us.get_dimension_system() is not None\n\n    # Test the get_quantity_dimension method\n    assert us.get_quantity_dimension(meter) == length\n\n    # Test the get_quantity_scale_factor method\n    assert us.get_quantity_scale_factor(meter) == 1\n\n    # Test the get_unit_system method\n    assert UnitSystem.get_unit_system(\"SI\") == us\n\n    # Test the get_default_unit_system method\n    assert UnitSystem.get_default_unit_system().name == \"SI\"\n\n    # Test the dim property\n    assert us.dim == 3\n\n    # Test the is_consistent property\n    assert us.is_consistent\n\n    # Test the derived_units property\n    assert isinstance(us.derived_units, dict)\n\n    # Test the get_dimensional_expr method\n    x, y = symbols('x y')\n    expr = x * y\n    assert us.get_dimensional_expr(expr) == length ** 2\n\n    # Test the _collect_factor_and_dimension method\n    expr = x * y\n    factor, dim = us._collect_factor_and_dimension(expr)\n    assert factor == x * y\n    assert dim == length ** 2\n\n    # Test the get_units_non_prefixed method\n    assert us.get_units_non_prefixed() == {meter, kilogram, second}\n", "def test_UnitSystem_extend():\n    us = UnitSystem((length, time, mass), name=\"CustomUnitSystem\")\n    new_us = us.extend((temperature,), name=\"ExtendedCustomUnitSystem\")\n    assert new_us.dim == 4\n    assert new_us.name == \"ExtendedCustomUnitSystem\"\n    assert new_us._base_units == (length, time, mass, temperature)\n", "def test_UnitSystem_get_dimensional_expr():\n    x, y = symbols('x y')\n\n    # test simple expression\n    expr = 3*x**2*y\n    dim = SI.get_dimensional_expr(expr)\n    assert dim == length**2*time\n\n    # test derivative\n    expr = diff(x**3*y**2, x)\n    dim = SI.get_dimensional_expr(expr)\n    assert dim == length**2\n\n    # test trigonometric function\n    expr = sin(x)\n    dim = SI.get_dimensional_expr(expr)\n    assert dim == 1\n\n    # test exponential function\n    expr = exp(x)\n    dim = SI.get_dimensional_expr(expr)\n    assert dim == 1\n\n    # test logarithmic function\n    expr = log(x)\n    dim = SI.get_dimensional_expr(expr)\n    assert dim == 1\n\n    # test absolute value function\n    expr = Abs(x)\n    dim = SI.get_dimensional_expr(expr)\n    assert dim == length\n\n    # test add expression\n    expr = x + y\n    dim = SI.get_dimensional_expr(expr)\n    assert dim == length\n\n    # test quantities\n    expr = joule\n    dim = SI.get_dimensional_expr(expr)\n    assert dim == energy\n\n    # test physical constant\n    expr = speed_of_light\n    dim = SI.get_dimensional_expr(expr)\n    assert dim == length/time\n\n    # test custom function\n    custom_func = Function('custom_func')\n    expr = custom_func(x, y)\n    dim = SI.get_dimensional_expr(expr)\n    assert dim == 1\n\n    # test custom function with arguments that have dimensions\n    expr = custom_func(x, y)\n    dim = SI.get_dimensional_expr(expr)\n    assert dim == 1\n\n    # test with Dimension\n    expr = length\n    dim = SI.get_dimensional_expr(expr)\n    assert dim == length\n\n    # test with Quantity\n    expr = Quantity('custom_quantity', abbrev='cq', dimension=length)\n    dim = SI.get_dimensional_expr(expr)\n    assert dim == length\n"], "sample_21": ["    def test_cannot_defer_constraint_checks_on_delete_restricted(self):\n        # Create some test data\n        parent = P.objects.create()\n        child = R.objects.create(parent=parent)\n\n        # Create a restricted relation\n        Referrer.objects.create(referred=child)\n\n        # Try to delete the parent object\n        with self.assertRaises(RestrictedError):\n            parent.delete()\n", "    def test_cascade_deletion_with_nullable_fields(self):\n        a = create_a()\n        b1 = B1.objects.create(a=a)\n        b2 = B2.objects.create(a=a)\n        b3 = B3.objects.create(a=a)\n        self.assertEqual(B1.objects.count(), 1)\n        self.assertEqual(B2.objects.count(), 1)\n        self.assertEqual(B3.objects.count(), 1)\n        a.delete()\n        self.assertEqual(B1.objects.count(), 0)\n        self.assertEqual(B2.objects.count(), 0)\n        self.assertEqual(B3.objects.count(), 0)\n\n        # Test with nullable fields\n        a = create_a()\n        b1 = B1.objects.create(a=a)\n        b2 = B2.objects.create(a=a, nullable_field=None)\n        b3 = B3.objects.create(a=a)\n        self.assertEqual(B1.objects.count(), 1)\n        self.assertEqual(B2.objects.count(), 1)\n        self.assertEqual(B3.objects.count(), 1)\n        a.delete()\n        self.assertEqual(B1.objects.count(), 0)\n        self.assertEqual(B2.objects.count(), 0)\n        self.assertEqual(B3.objects.count(), 0)\n", "def test_collector_can_fast_delete(self):\n    collector = Collector(using='default')\n    a1 = A.objects.create()\n    a2 = A.objects.create()\n    qs = A.objects.all()\n    self.assertTrue(collector.can_fast_delete(qs))\n    self.assertTrue(collector.can_fast_delete([a1, a2]))\n    self.assertTrue(collector.can_fast_delete(a1))\n    self.assertTrue(collector.can_fast_delete([]))\n\n    # Add a protected foreign key relation to A.\n    r = R.objects.create(a=a1)\n    self.assertFalse(collector.can_fast_delete(qs))\n    self.assertFalse(collector.can_fast_delete([a1, a2]))\n    self.assertFalse(collector.can_fast_delete(a1))\n\n    # Add a protected foreign key relation to A, but it's nullable.\n    mr = MR.objects.create(a=a1)\n    self.assertTrue(collector.can_fast_delete(qs))\n    self.assertTrue(collector.can_fast_delete([a1, a2]))\n    self.assertTrue(collector.can_fast_delete(a1))\n\n    # Add a protected foreign key relation to A that's not nullable.\n    mr.delete()\n    m = M.objects.create(a=a1)\n    self.assertFalse(collector.can_fast_delete(qs))\n    self.assertFalse(collector.can_fast_delete([a1, a2]))\n    self.assertFalse(collector.can_fast_delete(a1))\n", "    def test_on_delete_restricted(self):\n        # Test that a RestrictedError is raised when a model with a RESTRICT\n        # on_delete constraint is deleted and that constraint is violated.\n        a = create_a()\n        b = B1(a=a)\n        b.save()\n        with self.assertRaises(RestrictedError):\n            a.delete()\n\n        # Test that the RestrictedError contains the related objects.\n        a = create_a()\n        b1 = B1(a=a)\n        b1.save()\n        b2 = B2(a=a)\n        b2.save()\n        with self.assertRaises(RestrictedError) as cm:\n            a.delete()\n        self.assertEqual(set(cm.exception.restricted_objects), {b1, b2})\n\n        # Test that the RestrictedError's message contains the model and field\n        # names of the related objects.\n        a = create_a()\n        b = B1(a=a)\n        b.save()\n        with self.assertRaises(RestrictedError) as cm:\n            a.delete()\n        self.assertIn(\"B1.a\", str(cm.exception))\n\n        # Test that a RestrictedError is not raised when a model with a RESTRICT\n        # on_delete constraint is deleted and that constraint is not violated.\n        a = create_a()\n        a.save()\n        a.delete()\n\n        # Test that a RestrictedError is raised when a model with a RESTRICT\n        # on_delete constraint is deleted, that constraint is violated, and\n        # there are other related objects that can be deleted.\n        a = create_a()\n        b1 = B1(a=a)\n        b1.save()\n        b2 = B2(a=a)\n        b2.save()\n        b3 = B3(a=a)\n        b3.save()\n        with self.assertRaises(RestrictedError) as cm:\n            a.delete()\n        self.assertEqual(set(cm.exception.restricted_objects), {b1, b2})\n", "    def test_sort_order_without_transactions(self):\n        \"\"\"\n        Without transactions, the sort order is determined by the dependency\n        order, to avoid constraint errors. This tests that the correct order is\n        used.\n\n        The objects in this test case are ordered as follows:\n        A -> B1 -> B2 -> B3.\n        The models A, B1, B2, B3 are the concrete models of Base, B1, B2, B3.\n        \"\"\"\n        with connection.constraint_checks_disabled():\n            # Ensure that the dependencies are set up in the model's Meta.\n            A._meta.concrete_model._meta.dependencies = {B1._meta.concrete_model}\n            B1._meta.concrete_model._meta.dependencies = {B2._meta.concrete_model}\n            B2._meta.concrete_model._meta.dependencies = {B3._meta.concrete_model}\n            collector = Collector(using='default')\n            collector.collect([A], source=None, nullable=False, collect_related=True)\n            # Ensure that the instances are collected in the correct order.\n            self.assertEqual(\n                [model.__name__ for model, _ in collector.instances_with_model()],\n                ['A', 'B1', 'B2', 'B3'],\n            )\n            collector.sort()\n            # Ensure that the models are ordered according to their dependencies.\n            self.assertEqual(\n                [model.__name__ for model in collector.data],\n                ['B3', 'B2', 'B1', 'A'],\n            )\n"], "sample_71": ["def test_use():\n    \"\"\"Test using style specifications.\"\"\"\n    # Test str style specification\n    with temp_style('test'):\n        style.use('test')\n        assert mpl.rcParams[PARAM] == VALUE\n\n    # Test dict style specification\n    style.use(DUMMY_SETTINGS)\n    assert mpl.rcParams[PARAM] == VALUE\n\n    # Test Path style specification\n    with temp_style('test'):\n        style.use(Path(USER_LIBRARY_PATHS[-1]) / 'test.%s' % STYLE_EXTENSION)\n        assert mpl.rcParams[PARAM] == VALUE\n\n    # Test list of style specifications\n    with temp_style('test1'), temp_style('test2', settings={'image.cmap': 'viridis'}):\n        style.use(['test1', 'test2'])\n        assert mpl.rcParams[PARAM] != VALUE\n\n    # Test default style\n    style.use('default')\n    assert mpl.rcParams[PARAM] != VALUE\n\n    # Test unknown style\n    with pytest.raises(IOError):\n        style.use('unknown')\n\n    # Test deprecated seaborn style\n    with pytest.warns(UserWarning):\n        style.use('seaborn')\n", "def test_context_manager(tmpdir):\n    \"\"\"Test the style context manager.\"\"\"\n    style_name = 'test_style'\n    mpl.rcParams[PARAM] = 'not_%s' % VALUE\n\n    with temp_style(style_name):\n        with style.context(style_name):\n            assert mpl.rcParams[PARAM] == VALUE\n\n        # After context is exited, rcParams should be reset.\n        assert mpl.rcParams[PARAM] != VALUE\n\n    # Ensure that original rcParams are still the same.\n    assert mpl.rcParams[PARAM] != VALUE\n\n", "def test_use():\n    # Test applying a single style name\n    with temp_style('test_style'):\n        style.use('test_style')\n        assert mpl.rcParams[PARAM] == VALUE\n\n    # Test applying a single style dictionary\n    style.use(DUMMY_SETTINGS)\n    assert mpl.rcParams[PARAM] == VALUE\n\n    # Test applying a single style file path\n    with temp_style('test_style'):\n        style.use(Path(USER_LIBRARY_PATHS[-1]) / 'test_style.mplstyle')\n        assert mpl.rcParams[PARAM] == VALUE\n\n    # Test applying a list of style specifications\n    with temp_style('test_style1'), temp_style('test_style2', settings={PARAM: 'blue'}):\n        style.use(['test_style1', 'test_style2'])\n        assert mpl.rcParams[PARAM] == 'blue'\n\n    # Test applying a deprecated seaborn style\n    with pytest.warns(UserWarning, match=_DEPRECATED_SEABORN_MSG):\n        style.use('seaborn')\n        assert mpl.rcParams[PARAM] != VALUE\n\n    # Test applying the 'default' style\n    style.use('default')\n    assert mpl.rcParams[PARAM] != VALUE\n\n    # Test applying an invalid style name\n    with pytest.raises(IOError):\n        style.use('nonexistent_style')\n\n    # Test applying a style with blacklisted parameters\n    settings = {PARAM: 'pink', 'backend': 'agg'}\n    with pytest.warns(UserWarning, match=\"Style includes a parameter\"):\n        style.use(settings)\n        assert mpl.rcParams[PARAM] == 'pink'\n        assert mpl.rcParams['backend'] != 'agg'\n", "def test_available_styles():\n    \"\"\"Test that available styles are correctly listed.\"\"\"\n    initial_available = set(style.available)\n    with temp_style('my_style'):\n        assert 'my_style' in style.available\n        assert len(style.available) == len(initial_available) + 1\n    assert 'my_style' not in style.available\n\n", "def test_context_after_reset():\n    with temp_style('temp_style'):\n        # Change the style settings so we can check that it gets reset.\n        plt.style.use('seaborn')\n        # Create a figure so we can check the rcParams.\n        fig = plt.figure()\n        assert mpl.rcParams['image.cmap'] != VALUE\n        # Apply the context after resetting to default.\n        with plt.style.context('temp_style', after_reset=True):\n            assert mpl.rcParams['image.cmap'] == VALUE\n        # Check that the style settings were reset after the context was exited.\n        assert mpl.rcParams['image.cmap'] != VALUE\n"], "sample_10": ["    def test_in_lookup_with_float_values(self):\n        # Create a few Games.\n        self.g1 = Game.objects.create(sport='Tennis', price=10.5)\n        self.g2 = Game.objects.create(sport='Football', price=20.7)\n        self.g3 = Game.objects.create(sport='Cricket', price=30.9)\n\n        # Test __in lookup with float values.\n        games = Game.objects.filter(price__in=[10.5, 20.7])\n        self.assertEqual(games.count(), 2)\n        self.assertQuerysetEqual(games, [self.g1, self.g2], attrgetter('sport'))\n\n        games = Game.objects.filter(price__in=[10.4, 20.6])\n        self.assertEqual(games.count(), 0)\n\n        # Test __in lookup with float values and using math.ceil.\n        games = Game.objects.filter(price__in=[10.4, 20.6, 31.0])\n        self.assertEqual(games.count(), 1)\n        self.assertQuerysetEqual(games, [self.g3], attrgetter('sport'))\n", "def test_lookup_bilateral_transforms(self):\n    # Create a Game instance.\n    game = Game.objects.create(name='Game 1', players=5)\n    # Create a Player instance.\n    player = Player.objects.create(name='Player 1', game=game)\n\n    # Test that bilateral transforms are applied to the lookup's RHS.\n    transform = Substr('name', 1, 2)\n    lookup = player.game.players__name__startswith__overlap(transform)\n    self.assertEqual(lookup.get_bilateral_transforms(), [transform.__class__])\n\n    # Test that bilateral transforms from the LHS are combined with the\n    # lookup's bilateral transforms.\n    bilateral_lhs = player.game.players__name__overlap\n    lookup = bilateral_lhs__startswith__overlap(transform)\n    self.assertEqual(lookup.get_bilateral_transforms(), [bilateral_lhs.__class__, transform.__class__])\n", "def test_in_lookup_with_floats(self):\n    # Create an Author with a float field value.\n    self.au1.rating = 3.7\n    self.au1.save()\n\n    # Test exact lookup with a float.\n    self.assertEqual(Author.objects.filter(rating__exact=3.7).count(), 1)\n    self.assertEqual(Author.objects.filter(rating__exact=3.6).count(), 0)\n    self.assertEqual(Author.objects.filter(rating__exact=3.8).count(), 0)\n\n    # Test gt/lt/gte/lte lookups with a float.\n    self.assertEqual(Author.objects.filter(rating__gt=3.7).count(), 0)\n    self.assertEqual(Author.objects.filter(rating__lt=3.7).count(), 0)\n    self.assertEqual(Author.objects.filter(rating__gte=3.7).count(), 1)\n    self.assertEqual(Author.objects.filter(rating__lte=3.7).count(), 1)\n\n    # Test range lookup with a float.\n    self.assertEqual(Author.objects.filter(rating__range=(3.6, 3.8)).count(), 1)\n\n    # Test in lookup with a float.\n    self.assertEqual(Author.objects.filter(rating__in=[3.7]).count(), 1)\n    self.assertEqual(Author.objects.filter(rating__in=[3.6]).count(), 0)\n", "def test_regex_lookups(self):\n    articles = Article.objects.filter(headline__regex=r'^Article \\d$')\n    self.assertEqual(len(articles), 0)\n    articles = Article.objects.filter(headline__regex=r'^Article [1-7]$')\n    self.assertEqual(len(articles), 7)\n    articles = Article.objects.filter(headline__iregex=r'article [1-7]')\n    self.assertEqual(len(articles), 7)\n", "def test_lookup_year(self):\n    # Test year lookups.\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year=2005),\n        Article.objects.filter(pub_date__year__exact=2005),\n        attrgetter('pk'),\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gt=2005),\n        [self.a5, self.a6, self.a7],\n        attrgetter('pk'),\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gte=2005),\n        [self.a1, self.a2, self.a3, self.a4, self.a5, self.a6, self.a7],\n        attrgetter('pk'),\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lt=2005),\n        [],\n        attrgetter('pk'),\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lte=2005),\n        [self.a1, self.a2, self.a3, self.a4],\n        attrgetter('pk'),\n    )\n"], "sample_25": ["def test_altered_model_options(self):\n    \"\"\"\n    Test that changes to model options (like permissions) are detected.\n    \"\"\"\n    before_state = [\n        self.author_with_options,\n    ]\n    after_state = [\n        ModelState(\"testapp\", \"Author\", [\n            (\"id\", models.AutoField(primary_key=True)),\n        ], {\n            \"permissions\": [('can_fire', 'Can fire')],\n            \"verbose_name\": \"Authorius\",\n        }),\n    ]\n    changes = self.get_changes(before_state, after_state)\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n\n    before_state = [\n        self.author_with_options,\n    ]\n    after_state = [\n        ModelState(\"testapp\", \"Author\", [\n            (\"id\", models.AutoField(primary_key=True)),\n        ]),\n    ]\n    changes = self.get_changes(before_state, after_state)\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n\n    before_state = [\n        ModelState(\"testapp\", \"Author\", [\n            (\"id\", models.AutoField(primary_key=True)),\n        ]),\n    ]\n    after_state = [\n        self.author_with_options,\n    ]\n    changes = self.get_changes(before_state, after_state)\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n", "def test_altered_fields_with_regex_validators(self):\n    \"\"\"\n    Test the autodetector's ability to detect changes in a field's validators.\n    \"\"\"\n    state1 = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, validators=[RegexValidator(\"^[a-zA-Z]+$\")])),\n    ])\n    state2 = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, validators=[RegexValidator(\"^[a-zA-Z0-9]+$\")])),\n    ])\n    changes = MigrationAutodetector(self.make_project_state([state1]), self.make_project_state([state2]))._detect_changes()\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, validators=[(\"^[a-zA-Z0-9]+$\",)])\n", "def test_detect_changes_through_model(self):\n    before_state = [\n        self.contract,\n        self.publisher,\n    ]\n    after_state = [\n        self.contract_renamed,\n        self.publisher,\n        self.author_with_renamed_m2m_through,\n    ]\n    changes = self.get_changes(before_state, after_state)\n    self.assertNumberMigrations(changes, \"testapp\", 3)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"RenameModel\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, old_name=\"Contract\", new_name=\"Deal\")\n    self.assertOperationTypes(changes, \"testapp\", 1, [\"RemoveField\", \"AddField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 1, 0, model_name=\"Author\", name=\"publishers\")\n    self.assertOperationAttributes(changes, \"testapp\", 1, 1, model_name=\"Author\", name=\"publishers\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 1, 1, max_length=100, null=True, blank=True, through=\"testapp.Deal\")\n    self.assertOperationTypes(changes, \"testapp\", 2, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 2, 0, model_name=\"Deal\", name=\"author\")\n    self.assertOperationAttributes(changes, \"testapp\", 2, 1, model_name=\"Deal\", name=\"publisher\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 2, 0, related_model=\"testapp.Author\", to_field=\"id\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 2, 1, related_model=\"testapp.Publisher\", to_field=\"id\")\n", "def test_custom_field_validation(self):\n    class CustomValidator(RegexValidator):\n            super().__init__(regex=regex)\n\n    author_with_custom_validation = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, validators=[CustomValidator(regex='^hello')]))\n    ])\n\n    changes = self.get_changes([self.author_empty], [author_with_custom_validation])\n\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, ['CreateModel', 'AddField'])\n    self.assertOperationAttributes(changes, 'testapp', 0, 1, name='name', model_name='author', field=models.CharField(max_length=200))\n    self.assertOperationFieldAttributes(changes, 'testapp', 0, 1, validators=[CustomValidator(regex='^hello')])\n", "    def test_deconstructible_list_with_ellipsis(self):\n        # Test with ellipsis in the list\n        state1 = ModelState(\"testapp\", \"Author\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=200, default=[DeconstructibleObject(), Ellipsis])),\n        ])\n        state2 = ModelState(\"testapp\", \"Author\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=200, default=[DeconstructibleObject(), Ellipsis])),\n        ])\n        changes = MigrationAutodetector(\n            self.make_project_state([state1]),\n            self.make_project_state([state2])\n        )._detect_changes()\n        self.assertNumberMigrations(changes, \"testapp\", 0)\n"], "sample_9": ["    def test_tick(self, mock_time):\n        reloader = autoreload.StatReloader()\n        ticker = reloader.tick()\n        for _ in range(5):\n            ticker.send(None)\n            mock_time.sleep.assert_called_once_with(1)\n            mock_time.reset_mock()\n", "    def test_single_root(self):\n        paths = [Path('/tmp/a.py'), Path('/tmp/b.py')]\n        expected_roots = (Path('/tmp'),)\n        self.assertEqual(autoreload.common_roots(paths), expected_roots)\n", "    def test_empty_input(self):\n        self.assertEqual(autoreload.common_roots([]), ())\n", "    def test_check_errors_decorator(self):\n        @autoreload.check_errors\n            raise Exception('Test error')\n\n        with self.assertRaises(Exception):\n            raise_error()\n", "    def test_tick(self):\n        reloader = autoreload.StatReloader()\n        ticker = reloader.tick()\n        reloader.watch_file(self.temporary_file('test.py'))\n        next(ticker)\n        reloader.stop()\n        with self.assertRaises(StopIteration):\n            next(ticker)\n"], "sample_96": ["def test_ridge_classifier_cv_multilabel():\n    # Test RidgeClassifierCV with multilabel data\n    X, y = make_multilabel_classification(n_samples=50, n_features=10,\n                                          n_classes=3, n_labels=2,\n                                          random_state=0)\n    clf = RidgeClassifierCV(alphas=[1.0], fit_intercept=True)\n    clf.fit(X, y)\n\n    assert_array_equal(clf.classes_, [0, 1, 2])\n    assert_array_almost_equal(clf.coef_.shape, (3, 10))\n\n    y_pred = clf.predict(X)\n    assert_array_almost_equal(y_pred.shape, (50, 3))\n\n    scorer = get_scorer('accuracy')\n    score = scorer(clf, X, y)\n    assert_greater(score, 0.5)\n", "def test_ridge_regression_sparse_cg():\n    X = np.random.rand(100, 10)\n    y = np.random.rand(100)\n    X_sparse = sp.csr_matrix(X)\n\n    # Test sparse_cg solver with a square matrix\n    coef_dense = ridge_regression(X, y, alpha=1.0, solver='cholesky')\n    coef_sparse_cg = ridge_regression(X_sparse, y, alpha=1.0, solver='sparse_cg')\n    assert_array_almost_equal(coef_dense, coef_sparse_cg, 4)\n\n    # Test sparse_cg solver with a non-square matrix\n    X = np.random.rand(100, 5)\n    y = np.random.rand(100)\n    X_sparse = sp.csr_matrix(X)\n    coef_dense = ridge_regression(X, y, alpha=1.0, solver='cholesky')\n    coef_sparse_cg = ridge_regression(X_sparse, y, alpha=1.0, solver='sparse_cg')\n    assert_array_almost_equal(coef_dense, coef_sparse_cg, 4)\n", "def test_ridge_regression_with_sparse_kernel():\n    # Test with a sparse kernel matrix\n    n_samples = 10\n    n_features = 5\n    X = sp.random(n_samples, n_features, density=0.1, format=\"csr\")\n    y = np.random.rand(n_samples)\n    alpha = 1.0\n    sample_weight = np.random.rand(n_samples)\n\n    # Compare the results with the standard ridge regression\n    coef_sparse_kernel = _solve_cholesky_kernel(X.dot(X.T), y, alpha, sample_weight)\n    coef_standard = _solve_cholesky(X, y, alpha)\n    assert_array_almost_equal(coef_sparse_kernel, coef_standard)\n", "def test_ridge_gcv_sparse():\n    # test that RidgeGCV works with sparse matrices\n    ridge_gcv = _RidgeGCV(alphas=[1.0], fit_intercept=True, normalize=False,\n                           scoring=None, store_cv_values=False)\n    X = sp.csr_matrix(X_diabetes)\n    y = y_diabetes\n    ridge_gcv.fit(X, y)\n    assert_array_almost_equal(ridge_gcv.dual_coef_.T.dot(X_diabetes), y)\n", "def test_ridge_classifier_cv_sparse():\n    X = X_iris\n    y = y_iris\n    filter = SPARSE_FILTER\n\n    ridge = RidgeClassifierCV(alphas=[1.0], store_cv_values=True)\n    ridge.fit(X, y)\n\n    assert_equal(ridge.coef_.shape, (3, 4))\n    assert_equal(ridge.intercept_.shape, (3,))\n\n    y_pred = ridge.predict(X)\n    assert_equal(y_pred.shape, (150,))\n    assert_array_equal(y_pred, ridge.predict(filter(X)))\n\n    y_pred_proba = ridge.predict_proba(X)\n    assert_equal(y_pred_proba.shape, (150, 3))\n    assert_array_equal(y_pred_proba, ridge.predict_proba(filter(X)))\n\n    assert_greater(mean_squared_error(y, y_pred), 0.0)\n\n    # test multi-label classification\n    X, y = make_multilabel_classification(n_samples=100, n_features=10,\n                                          n_labels=2, n_classes=3,\n                                          random_state=0)\n    X, y = X[:, :2], y[:, :2]  # 2 features, 2 labels\n\n    ridge = RidgeClassifierCV(alphas=[1.0])\n    ridge.fit(X, y)\n    assert_raises(ValueError, ridge.fit, X, y)\n\n    # test that RidgeClassifierCV handles different scoring functions\n    scoring = make_scorer(mean_squared_error, greater_is_better=False)\n    RidgeClassifierCV(alphas=[1.0], scoring=scoring).fit(X, y)\n    RidgeClassifierCV(alphas=[1.0], scoring='neg_mean_squared_error').fit(X, y)\n\n    # test error for unknown scoring function\n    scoring = 'unknown'\n    msg = \"Scoring function %s not among known scorers or string\" % scoring\n    assert_raise_message(ValueError, msg, RidgeClassifierCV(alphas=[1.0],\n                                                           scoring=scoring).fit, X, y)\n"], "sample_94": ["def test_Source_deindent():\n    source = Source(\"  a = 1\\n  b = 2\")\n    deindented_source = source.deindent()\n    assert deindented_source.lines == [\"a = 1\", \"b = 2\"]\n", "def test_Source_deindent():\n    source = Source(\"def foo():\\n  pass\")\n    assert source.deindent().lines == [\"def foo():\", \"  pass\"]\n\n    source = Source([\"    def foo():\", \"      pass\"])\n    assert source.deindent().lines == [\"def foo():\", \"    pass\"]\n", "def test_getstatementrange_ast():\n    # Create a test source code\n    source_code = textwrap.dedent(\"\"\"\n            if True:\n                pass\n            else:\n                pass\n\n            for i in range(10):\n                print(i)\n    \"\"\")\n    source = Source(source_code)\n\n    # Test getstatementrange_ast with a lineno in the middle of a statement\n    lineno = 3\n    astnode, start, end = getstatementrange_ast(lineno, source)\n    assert isinstance(astnode, ast.Module)\n    assert start == 0\n    assert end == 5\n\n    # Test getstatementrange_ast with a lineno at the end of a statement\n    lineno = 5\n    astnode, start, end = getstatementrange_ast(lineno, source)\n    assert isinstance(astnode, ast.Module)\n    assert start == 0\n    assert end == 5\n\n    # Test getstatementrange_ast with a lineno in a nested block\n    lineno = 7\n    astnode, start, end = getstatementrange_ast(lineno, source)\n    assert isinstance(astnode, ast.Module)\n    assert start == 6\n    assert end == 8\n\n    # Test getstatementrange_ast with a lineno in a for loop\n    lineno = 8\n    astnode, start, end = getstatementrange_ast(lineno, source)\n    assert isinstance(astnode, ast.Module)\n    assert start == 6\n    assert end == 9\n\n    # Test getstatementrange_ast with a lineno out of range\n    lineno = 20\n    with pytest.raises(IndexError):\n        getstatementrange_ast(lineno, source)\n", "def test_getstatementrange_ast():\n    # Create a sample source code with multiple statements\n    source = Source([\n        \"def foo():\",\n        \"    pass\",\n        \"\",\n        \"def bar():\",\n        \"    x = 1\",\n        \"    y = 2\",\n        \"    if x > 0:\",\n        \"        print('x is positive')\",\n        \"\",\n        \"print('end of code')\",\n    ])\n\n    # Test getstatementrange_ast with a statement in the middle\n    astnode, start, end = getstatementrange_ast(5, source)\n    assert start == 4\n    assert end == 8\n\n    # Test getstatementrange_ast with a statement at the end\n    astnode, start, end = getstatementrange_ast(9, source)\n    assert start == 8\n    assert end == 9\n\n    # Test getstatementrange_ast with a statement with multiple lines\n    source = Source([\n        \"def foo():\",\n        \"    x = (\",\n        \"        1 +\",\n        \"        2\",\n        \"    )\",\n    ])\n    astnode, start, end = getstatementrange_ast(2, source)\n    assert start == 1\n    assert end == 4\n\n    # Test getstatementrange_ast with a statement that is a comment\n    source = Source([\n        \"# This is a comment\",\n        \"def foo():\",\n        \"    pass\",\n    ])\n    astnode, start, end = getstatementrange_ast(0, source)\n    assert start == 0\n    assert end == 1\n\n    # Test getstatementrange_ast with a statement that is empty\n    source = Source([\n        \"\",\n        \"def foo():\",\n        \"    pass\",\n    ])\n    astnode, start, end = getstatementrange_ast(0, source)\n    assert start == 0\n    assert end == 1\n\n    # Test getstatementrange_ast with a statement that is a decorator\n    source = Source([\n        \"@decorator\",\n        \"def foo():\",\n        \"    pass\",\n    ])\n    astnode, start, end = getstatementrange_ast(1, source)\n    assert start == 0\n    assert end == 2\n", "def test_Source_getstatementrange():\n    # Test that getstatementrange works correctly for different types of statements\n        x = 5\n        if x > 0:\n            print(\"x is positive\")\n        else:\n            print(\"x is negative\")\n        try:\n            y = 5 / 0\n        except ZeroDivisionError:\n            print(\"Cannot divide by zero!\")\n\n    source, _ = findsource(test_func)\n    assert source.getstatementrange(0) == (0, 2)  # function definition\n    assert source.getstatementrange(1) == (0, 2)  # function body\n    assert source.getstatementrange(2) == (2, 5)  # if statement\n    assert source.getstatementrange(3) == (2, 5)  # if statement body\n    assert source.getstatementrange(4) == (2, 5)  # else statement\n    assert source.getstatementrange(5) == (2, 5)  # else statement body\n    assert source.getstatementrange(6) == (6, 9)  # try-except block\n    assert source.getstatementrange(7) == (6, 9)  # try block\n    assert source.getstatementrange(8) == (6, 9)  # except block\n"], "sample_0": ["    def test_value_from_datadict_for_hidden_input(self):\n        form = NotRequiredBandForm(data={'band': ''})\n        field = form.fields['band']\n        widget = field.widget\n        self.assertIsNone(widget.value_from_datadict(form.data, form.files, field.name))\n\n        form = RequiredBandForm(data={'band': ''})\n        field = form.fields['band']\n        widget = field.widget\n        self.assertIsNone(widget.value_from_datadict(form.data, form.files, field.name))\n\n        form = NotRequiredBandForm(data={'band': '1'})\n        field = form.fields['band']\n        widget = field.widget\n        self.assertEqual(widget.value_from_datadict(form.data, form.files, field.name), '1')\n\n        form = RequiredBandForm(data={'band': '1'})\n        field = form.fields['band']\n        widget = field.widget\n        self.assertEqual(widget.value_from_datadict(form.data, form.files, field.name), '1')\n", "    def test_multiwidget_decompress(self):\n        widget = SplitDateTimeWidget()\n        datetime_value = datetime.datetime(2022, 1, 1, 12, 0, 0)\n        decompressed = widget.decompress(datetime_value)\n        self.assertEqual(decompressed, [datetime.date(2022, 1, 1), datetime.time(12, 0, 0)])\n        \n        widget = SplitDateTimeWidget(date_format='%d %B %Y', time_format='%H:%M')\n        datetime_value = datetime.datetime(2022, 1, 1, 12, 0, 0)\n        decompressed = widget.decompress(datetime_value)\n        self.assertEqual(decompressed, [datetime.date(2022, 1, 1), datetime.time(12, 0, 0)])\n        \n        widget = SplitDateTimeWidget(date_format='%d %B %Y', time_format='%H:%M')\n        datetime_value = None\n        decompressed = widget.decompress(datetime_value)\n        self.assertEqual(decompressed, [None, None])\n", "    def test_select_date_widget_rendering(self):\n        widget = SelectDateWidget()\n        date = datetime.date(2022, 7, 25)\n        html = widget.render('date', date)\n        self.assertHTMLEqual(html, \"\"\"\n            <select name=\"date_year\" id=\"id_date_year\">\n                <option value=\"\" selected>---</option>\n                <option value=\"2022\">2022</option>\n                ...\n            </select>\n            <select name=\"date_month\" id=\"id_date_month\">\n                <option value=\"\" selected>---</option>\n                <option value=\"1\">January</option>\n                ...\n                <option value=\"7\" selected>July</option>\n                ...\n            </select>\n            <select name=\"date_day\" id=\"id_date_day\">\n                <option value=\"\" selected>---</option>\n                <option value=\"1\">1</option>\n                ...\n                <option value=\"25\" selected>25</option>\n                ...\n            </select>\n        \"\"\")\n\n        # Test with empty label\n        widget = SelectDateWidget(empty_label=\"Not set\")\n        html = widget.render('date', date)\n        self.assertHTMLEqual(html, \"\"\"\n            <select name=\"date_year\" id=\"id_date_year\">\n                <option value=\"\" selected>Not set</option>\n                <option value=\"2022\">2022</option>\n                ...\n            </select>\n            <select name=\"date_month\" id=\"id_date_month\">\n                <option value=\"\" selected>Not set</option>\n                <option value=\"1\">January</option>\n                ...\n                <option value=\"7\" selected>July</option>\n                ...\n            </select>\n            <select name=\"date_day\" id=\"id_date_day\">\n                <option value=\"\" selected>Not set</option>\n                <option value=\"1\">1</option>\n                ...\n                <option value=\"25\" selected>25</option>\n                ...\n            </select>\n        \"\"\")\n\n        # Test with list of empty labels\n        widget = SelectDateWidget(empty_label=[\"Not set year\", \"Not set month\", \"Not set day\"])\n        html = widget.render('date', date)\n        self.assertHTMLEqual(html, \"\"\"\n            <select name=\"date_year\" id=\"id_date_year\">\n                <option value=\"\" selected>Not set year</option>\n                <option value=\"2022\">2022</option>\n                ...\n            </select>\n           ", "    def test_select_date_widget_rendering(self):\n        class TestForm(forms.Form):\n            date = forms.DateField(widget=SelectDateWidget)\n\n        form = TestForm()\n        html = form.as_p()\n        self.assertIn('select', html)\n        self.assertIn('day', html)\n        self.assertIn('month', html)\n        self.assertIn('year', html)\n\n        form = TestForm({'date': '2022-07-26'})\n        html = form.as_p()\n        self.assertIn('selected', html)\n\n        form = TestForm({'date_year': '2022', 'date_month': '7', 'date_day': '26'})\n        html = form.as_p()\n        self.assertIn('selected', html)\n", "    def test_required_attribute_not_used_for_empty_option(self):\n        form = RequiredBandForm()\n        html = form.as_p()\n        self.assertInHTML('<select name=\"band\" class=\"my-class\">', html)\n        self.assertIn(self.empty_option, html)\n        self.assertNotIn('required', html)\n"], "sample_27": ["    def test_make_token(self):\n        user = User.objects.create_user(username='testuser', email='test@example.com')\n        token_generator = PasswordResetTokenGenerator()\n        token = token_generator.make_token(user)\n        self.assertIsNotNone(token)\n        self.assertTrue(token_generator.check_token(user, token))\n", "    def test_make_token_with_timestamp_legacy(self):\n        user = User.objects.create_user(username='testuser', email='testuser@example.com')\n        timestamp = self._num_seconds(datetime(2022, 1, 1))\n        generator = PasswordResetTokenGenerator()\n        token = generator._make_token_with_timestamp(user, timestamp, legacy=True)\n        self.assertEqual(len(token), 17)\n", "def test_check_token_legacy(self):\n    with ignore_warnings(category=RemovedInDjango40Warning):\n        # Create a user\n        user = User.objects.create_user(username='testuser', email='test@example.com')\n\n        # Create a token generator with a mock now\n        now = datetime.now()\n        token_generator = MockedPasswordResetTokenGenerator(now)\n\n        # Generate a token\n        token = token_generator.make_token(user)\n\n        # Check the token is valid\n        self.assertTrue(token_generator.check_token(user, token))\n\n        # Check the token is invalid for a different user\n        self.assertFalse(token_generator.check_token(User.objects.create_user(username='testuser2'), token))\n\n        # Check the token is invalid if the user's password changes\n        user.set_password('newpassword')\n        user.save()\n        self.assertFalse(token_generator.check_token(user, token))\n\n        # Check the token is invalid if the user's last_login changes\n        user.last_login = now + timedelta(days=1)\n        user.save()\n        self.assertFalse(token_generator.check_token(user, token))\n\n        # Check the token is invalid if the user's email changes\n        user.email = 'newemail@example.com'\n        user.save()\n        self.assertFalse(token_generator.check_token(user, token))\n\n        # Check the token is invalid if the timestamp is tampered with\n        tampered_token = f\"{int_to_base36(now.timestamp() + 1000)}-{token.split('-')[1]}\"\n        self.assertFalse(token_generator.check_token(user, tampered_token))\n\n        # Check the token is invalid if the hash is tampered with\n        tampered_token = f\"{int_to_base36(now.timestamp())}-tampered\"\n        self.assertFalse(token_generator.check_token(user, tampered_token))\n", "    def test_make_token(self):\n        now = datetime.now()\n        token_generator = MockedPasswordResetTokenGenerator(now)\n        user = User()\n        token = token_generator.make_token(user)\n        self.assertIsNotNone(token)\n        self.assertRegex(token, r'^\\d{6}-[0-9a-f]{20}$')\n", "    def test_make_token(self):\n        \"\"\"\n        Test the generation of a password reset token.\n        \"\"\"\n        now = datetime(2023, 1, 1, 0, 0, 0)\n        generator = MockedPasswordResetTokenGenerator(now)\n        user = User.objects.create_user('testuser', 'test@example.com', 'password')\n        token = generator.make_token(user)\n\n        # Check that the token is a string\n        self.assertIsInstance(token, str)\n\n        # Check that the token has the correct format (timestamp-hash)\n        parts = token.split('-')\n        self.assertEqual(len(parts), 2)\n\n        # Check that the timestamp is in base 36\n        try:\n            base36_to_int(parts[0])\n        except ValueError:\n            self.fail(\"Invalid base 36 timestamp\")\n\n        # Check that the hash is a hexadecimal string\n        try:\n            int(parts[1], 16)\n        except ValueError:\n            self.fail(\"Invalid hexadecimal hash\")\n"], "sample_145": ["def test_latex_DiracDelta():\n    # Test of LaTeX formatting of DiracDelta\n    delta = DiracDelta(x, 0)\n    assert latex(delta) == r\"\\delta\\left(x\\right)\"\n    delta = DiracDelta(x, 1)\n    assert latex(delta) == r\"\\delta^{\\left( 1 \\right)}\\left( x \\right)\"\n", "def test_latex_printer():\n    # Test LaTeX printer\n    latex = LatexPrinter()\n\n    # Test _deal_with_super_sub\n    assert latex._deal_with_super_sub('alpha') == 'alpha'\n    assert latex._deal_with_super_sub('alpha1') == 'alpha^{1}'\n    assert latex._deal_with_super_sub('alpha_1') == 'alpha_{1}'\n    assert latex._deal_with_super_sub('alpha1_2') == 'alpha^{1}_{2}'\n    assert latex._deal_with_super_sub('alpha_1^2') == 'alpha_{1}^{2}'\n\n    # Test _hprint_Function\n    assert latex._hprint_Function('sin') == '\\sin'\n    assert latex._hprint_Function('Sin') == '\\operatorname{Sin}'\n    assert latex._hprint_Function('SIN') == '\\operatorname{SIN}'\n\n    # Test _print_Function\n    assert latex._print_Function(Symbol('sin')) == 'sin'\n    assert latex._print_Function(Symbol('Sin')) == '\\operatorname{Sin}'\n    assert latex._print_Function(Symbol('SIN')) == '\\operatorname{SIN}'\n\n    # Test _print_Rational\n    assert latex._print(Rational(1, 2)) == '\\frac{1}{2}'\n\n    # Test _print_Integer\n    assert latex._print(1) == '1'\n\n    # Test _print_Float\n    assert latex._print(Float(1.2)) == '1.2'\n\n    # Test _print_Symbol\n    assert latex._print(Symbol('x')) == 'x'\n\n    # Test _print_Symbols\n    assert latex._print(Symbols('x y')) == 'x, y'\n\n    # Test _print_Pow\n    assert latex._print(Pow(x, 2)) == 'x^{2}'\n\n    # Test _print_Mul\n    assert latex._print(Mul(x, 2)) == '2 x'\n\n    # Test _print_Add\n    assert latex._print(Add(x, 2)) == '2 + x'\n\n    # Test _print_Derivative\n    assert latex._print(Derivative(x, x)) == '\\frac{d}{d x} x'\n\n    # Test _print_Integral\n    assert latex._print(Integral(x, x)) == '\\int x \\, dx'\n\n    # Test _print_Limit\n    assert", "def test_print_latex():\n    raises(ValueError, lambda: latex(x, mode='wrong_mode'))\n\n    # Test latex() function with some input\n    assert latex(x) == 'x'\n    assert latex(1) == '1'\n    assert latex(x**2) == 'x^{2}'\n    assert latex(2*x) == '2 x'\n    assert latex(2*x**2) == '2 x^{2}'\n    assert latex(x*y) == 'x y'\n    assert latex(1+x) == 'x + 1'\n    assert latex(1+x**2) == 'x^{2} + 1'\n    assert latex(1-x**2) == '1 - x^{2}'\n    assert latex(x**2-1) == 'x^{2} - 1'\n    assert latex(-x**2-1) == '- x^{2} - 1'\n    assert latex(-x**2+1) == '1 - x^{2}'\n    assert latex(-1-x**2) == '- x^{2} - 1'\n    assert latex(x**-1) == 'x^{-1}'\n    assert latex(x**-2) == 'x^{-2}'\n    assert latex(1/x) == '\\\\frac{1}{x}'\n    assert latex(2*x**-1) == '\\\\frac{2}{x}'\n    assert latex(2*x**-2) == '\\\\frac{2}{x^{2}}'\n    assert latex(x**-1 + 1) == 'x^{-1} + 1'\n    assert latex(x**-2 + 1) == 'x^{-2} + 1'\n    assert latex(1 + x**-1) == '1 + x^{-1}'\n    assert latex(1 + x**-2) == '1 + x^{-2}'\n    assert latex(x**-1 - 1) == 'x^{-1} - 1'\n    assert latex(x**-2 - 1) == 'x^{-2} - 1'\n    assert latex(1 - x**-1) == '1 - x^{-1}'\n    assert latex(1 - x**-2) == '1 - x^{-2}'\n    assert latex(x**-1*x) == '1'\n    assert latex(x*x**-1) == '1'\n    assert latex(x**-2*x**2) == '1", "def test_get_latex_str():\n    u = symbols('u')\n    expr = S.Half + S.Half\n    assert latex(expr) == '1'\n    expr = 2 * expr\n    assert latex(expr) == '2'\n\n    expr = u**2\n    assert latex(expr) == 'u^{2}'\n\n    expr = (u**2)**2\n    assert latex(expr) == 'u^{4}'\n\n    expr = 2 * u**2\n    assert latex(expr) == '2 u^{2}'\n\n    expr = -2 * u**2\n    assert latex(expr) == '-2 u^{2}'\n\n    expr = 2 * u**-2\n    assert latex(expr) == '2 u^{-2}'\n\n    expr = -2 * u**-2\n    assert latex(expr) == '-\\frac{2}{u^{2}}'\n\n    expr = (2 * u)**-2\n    assert latex(expr) == '\\frac{1}{4 u^{2}}'\n\n    expr = -(2 * u)**-2\n    assert latex(expr) == '-\\frac{1}{4 u^{2}}'\n\n    expr = -(2 * u**2)**-2\n    assert latex(expr) == '-\\frac{1}{4 u^{4}}'\n\n    expr = (u**2)**S.Half\n    assert latex(expr) == 'u'\n\n    expr = -(u**2)**S.Half\n    assert latex(expr) == '-u'\n\n    expr = -u**S.Half\n    assert latex(expr) == '-\\sqrt{u}'\n\n    expr = -u**-S.Half\n    assert latex(expr) == '-\\frac{1}{\\sqrt{u}}'\n\n    expr = -2 * u**-S.Half\n    assert latex(expr) == '-\\frac{2}{\\sqrt{u}}'\n\n    expr = -2 * u**S.Half\n    assert latex(expr) == '-2 \\sqrt{u}'\n\n    expr = -(2 * u)**S.Half\n    assert latex(expr) == '-\\sqrt{2 u}'\n\n    expr = -(2 * u**2)**S.Half\n    assert latex(expr) == '-\\sqrt{2} u'\n\n    expr = -(2 * u**-2)**S.Half\n    assert latex(expr) == '-\\frac{\\sqrt", "def testlatex():\n    # coverage for latex.py\n    from sympy.printing.latex import LatexPrinter\n    p = LatexPrinter()\n    assert p._print(p._print(Pow(x,2)**(S(3)/2))) == p._print(Pow(x,3))\n    assert p._print(Pow(x,-2)) == p._print(1/Pow(x,2))\n    assert p._print(Pow(x,2)**(S(3)/2)) == p._print(Pow(x,3))\n    assert p._print(Pow(x,3)**(S(2)/3)) == p._print(Pow(x,2))\n    assert p._print(Pow(x,2)**(S(4)/3)) == p._print(Pow(x,8/3))\n    assert p._print(Pow(x,3)**(S(1)/2)) == p._print(Pow(x,S(3)/2))\n    assert p._print(Pow(x,S(2)/3)) == p._print(Pow(x,S(2)/3))\n    assert p._print(Pow(x,S(2)/3)**3) == p._print(Pow(x,2))\n    assert p._print(Pow(x,S(2)/3)**(S(3)/2)) == p._print(Pow(x,S(3)/2))\n    assert p._print(Pow(x,S(2)/3)**(S(4)/3)) == p._print(Pow(x,S(8)/9))\n    assert p._print(Pow(x,2)**(S(3)/2)) == p._print(Pow(x,3))\n    assert p._print(Pow(x,3)**(S(3)/4)) == p._print(Pow(x,S(9)/4))\n    assert p._print(Pow(x,S(3)/4)**(S(3)/2)) == p._print(Pow(x,S(9)/8))\n    assert p._print(Pow(x,S(3)/4)**(S(4)/3)) == p._print(Pow(x,S(4)/4))\n    assert p._print(Pow(x,S(3)/2)**(S(4)/3)) == p._print(Pow(x,2))\n    assert p._print(Pow(x,S(3)/2)**(S(4)/3)) == p._print(Pow(x"], "sample_1": ["def test_read_table_qdp_with_table_id():\n    data = \"\"\"", "def test_read_table_qdp():\n    data = \"\"\"\n        ! Initial comment line 1\n        ! Initial comment line 2\n        READ TERR 1\n        READ SERR 3\n        ! Table 0 comment\n        !a a(pos) a(neg) b be c d\n        53000.5   0.25  -0.5   1  1.5  3.5 2\n        54000.5   1.25  -1.5   2  2.5  4.5 3\n        NO NO NO NO NO\n        ! Table 1 comment\n        !a a(pos) a(neg) b be c d\n        54000.5   2.25  -2.5   NO  3.5  5.5 5\n        55000.5   3.25  -3.5   4  4.5  6.5 nan\n    \"\"\"\n    table = _read_table_qdp(data)\n    assert len(table) == 2\n    assert table[0].colnames == ['col1', 'col1_perr', 'col1_nerr', 'col2', 'col3', 'col3_err', 'col4']\n    assert np.allclose(table[0].col1, [53000.5, 54000.5])\n    assert np.allclose(table[0].col1_perr, [0.25, 1.25])\n    assert np.allclose(table[0].col1_nerr, [-0.5, -1.5])\n    assert np.allclose(table[0].col2, [1, 2])\n    assert np.allclose(table[0].col3, [1.5, 2.5])\n    assert np.allclose(table[0].col3_err, [3.5, 4.5])\n    assert np.allclose(table[0].col4, [2, 3])\n    assert table[1].colnames == ['col1', 'col1_perr', 'col1_nerr', 'col2', 'col3', 'col3_err', 'col4']\n    assert np.allclose(table[1].col1, [54000.5, 55000.5])\n    assert np.allclose(table[1].", "def test_read_table_qdp_with_table_id():\n    # Create a test QDP file with two tables\n    test_file = \"test.qdp\"\n    with open(test_file, \"w\") as f:\n        f.write(\"! Initial comment line 1\\n\")\n        f.write(\"! Initial comment line 2\\n\")\n        f.write(\"READ TERR 1\\n\")\n        f.write(\"READ SERR 3\\n\")\n        f.write(\"! Table 0 comment\\n\")\n        f.write(\"!a a(pos) a(neg) b be c d\\n\")\n        f.write(\"53000.5   0.25  -0.5   1  1.5  3.5 2\\n\")\n        f.write(\"54000.5   1.25  -1.5   2  2.5  4.5 3\\n\")\n        f.write(\"NO NO NO NO NO\\n\")\n        f.write(\"! Table 1 comment\\n\")\n        f.write(\"!a a(pos) a(neg) b be c d\\n\")\n        f.write(\"54000.5   2.25  -2.5   NO  3.5  5.5 5\\n\")\n        f.write(\"55000.5   3.25  -3.5   4  4.5  6.5 nan\\n\")\n\n    # Read the second table\n    table = _read_table_qdp(test_file, table_id=1, names=['a', 'b', 'c', 'd'])\n\n    # Check the table contents\n    assert len(table) == 2\n    assert table[0][0] == 54000.5\n    assert table[0][1] == 2.25\n    assert table[0][2] == -2.5\n    assert np.ma.is_masked(table[0][3])\n    assert table[0][4] == 3.5\n    assert table[0][5] == 5.5\n    assert table[0][6] == 5\n\n    # Check the comments\n    assert table.meta['initial_comments'] == ['! Initial comment line 1', '! Initial comment line 2']\n    assert table.meta['comments'] == ['! Table 1 comment']\n\n    # Clean up\n    import os\n    os.remove(test_file)\n", "def test_read_table_qdp():\n    # Test with a QDP file string\n    qdp_file = \"\"\"", "def test_get_lines_from_file():\n    # Test with string containing newline characters\n    qdp_file = \"line1\\nline2\\nline3\"\n    lines = _get_lines_from_file(qdp_file)\n    assert lines == [\"line1\", \"line2\", \"line3\"]\n\n    # Test with file path\n    import tempfile\n    with tempfile.NamedTemporaryFile(mode='w') as tmp:\n        tmp.write(\"line1\\nline2\\nline3\")\n        tmp.flush()\n        lines = _get_lines_from_file(tmp.name)\n        assert lines == [\"line1\", \"line2\", \"line3\"]\n\n    # Test with iterable of lines\n    qdp_file = [\"line1\", \"line2\", \"line3\"]\n    lines = _get_lines_from_file(qdp_file)\n    assert lines == [\"line1\", \"line2\", \"line3\"]\n\n    # Test with invalid input\n    with pytest.raises(ValueError):\n        _get_lines_from_file(123)\n"], "sample_156": ["def test_parse_mathematica():\n    parser = MathematicaParser()\n    assert parser.parse(\"a + b\") == sympify(\"a + b\")\n    assert parser.parse(\"a * b\") == sympify(\"a * b\")\n    assert parser.parse(\"a / b\") == sympify(\"a / b\")\n    assert parser.parse(\"a ^ b\") == sympify(\"a ** b\")\n    assert parser.parse(\"Sin[x]\") == sin(x)\n    assert parser.parse(\"Cos[x]\") == cos(x)\n    assert parser.parse(\"Tan[x]\") == sympify(\"tan(x)\")\n    assert parser.parse(\"Cot[x]\") == sympify(\"cot(x)\")\n    assert parser.parse(\"Sec[x]\") == sympify(\"sec(x)\")\n    assert parser.parse(\"Csc[x]\") == sympify(\"csc(x)\")\n    assert parser.parse(\"ArcSin[x]\") == sympify(\"asin(x)\")\n    assert parser.parse(\"ArcCos[x]\") == sympify(\"acos(x)\")\n    assert parser.parse(\"ArcTan[x]\") == sympify(\"atan(x)\")\n    assert parser.parse(\"ArcCot[x]\") == sympify(\"acot(x)\")\n    assert parser.parse(\"ArcSec[x]\") == sympify(\"asec(x)\")\n    assert parser.parse(\"ArcCsc[x]\") == sympify(\"acsc(x)\")\n    assert parser.parse(\"Sinh[x]\") == sympify(\"sinh(x)\")\n    assert parser.parse(\"Cosh[x]\") == sympify(\"cosh(x)\")\n    assert parser.parse(\"Tanh[x]\") == sympify(\"tanh(x)\")\n    assert parser.parse(\"Coth[x]\") == sympify(\"coth(x)\")\n    assert parser.parse(\"Sech[x]\") == sympify(\"sech(x)\")\n    assert parser.parse(\"Csch[x]\") == sympify(\"csch(x)\")\n    assert parser.parse(\"ArcSinh[x]\") == sympify(\"asinh(x)\")\n    assert parser.parse(\"ArcCosh[x]\") == sympify(\"acosh(x)\")\n    assert parser.parse(\"ArcTanh[x]\") == sympify(\"atanh(x)\")\n    assert parser.parse(\"ArcCoth[x]\") == sympify(\"acoth(x)\")\n    assert parser.parse(\"ArcSech[x]\") == sympify(\"asech(x)\")\n    assert parser.parse(\"ArcCsch[x]\") == sympify(\"acsch(x)\")\n    assert parser.parse(\"Exp[x]\") == sympify(\"exp(x)\")\n    assert parser.parse(\"Log[x]\") == sympify(\"log(x", "def test_parse_mathematica():\n    assert parse_mathematica('Sin[x]') == sin(x)\n    assert parse_mathematica('f[x_] := x^2') == Function('f')(Function('Pattern')(symbols('x'), symbols('Blank')()))\n    assert parse_mathematica('f[x_, y_] := x^2 + y') == Function('f')(Function('Pattern')(symbols('x'), symbols('Blank')()), Function('Pattern')(symbols('y'), symbols('Blank')()))\n    assert parse_mathematica('f[x_List] := x^2') == Function('f')(Function('Pattern')(symbols('x'), symbols('BlankSequence')()))\n    assert parse_mathematica('f[x__] := x^2') == Function('f')(Function('Pattern')(symbols('x'), symbols('BlankNullSequence')()))\n    assert parse_mathematica('f[___] := x^2') == Function('f')(Function('Pattern')(symbols('x'), symbols('BlankNullSequence')()))\n    assert parse_mathematica('f[opts___Rule] := x^2') == Function('f')(Function('Pattern')(symbols('opts'), symbols('BlankNullSequence')(symbols('Rule'))))\n    assert parse_mathematica('f[x_, opts___Rule] := x^2') == Function('f')(Function('Pattern')(symbols('x'), symbols('Blank')()), Function('Pattern')(symbols('opts'), symbols('BlankNullSequence')(symbols('Rule'))))\n    assert parse_mathematica('f[x_, y_, opts___Rule] := x^2') == Function('f')(Function('Pattern')(symbols('x'), symbols('Blank')()), Function('Pattern')(symbols('y'), symbols('Blank')()), Function('Pattern')(symbols('opts'), symbols('BlankNullSequence')(symbols('Rule'))))\n\n    assert parse_mathematica('Sin[x]^2 Tan[y]') == sin(x)**2 * tan(y)\n    assert parse_mathematica('2 Sin[x]^2 Tan[y]') == 2*sin(x)**2 * tan(y)\n    assert parse_mathematica('Sin[x]^2 + Tan[y]') == sin(x)**2 + tan(y)\n    assert parse_mathematica('Sin[x]^2 - Tan[y]') == sin(x)**2 - tan(y)\n    assert parse_mathematica('Sin[x]^2 * Tan[y]') == sin(x)**2 * tan(y)\n    assert", "def test_mathematica_parser():\n    parser = MathematicaParser()\n\n    # Test with some examples\n    assert parser.parse(\"x + y\") == sympify(\"x + y\")\n    assert parser.parse(\"x * y\") == sympify(\"x * y\")\n    assert parser.parse(\"x ^ y\") == sympify(\"x ** y\")\n    assert parser.parse(\"Sin[x]\") == sin(x)\n    assert parser.parse(\"Cos[x]\") == cos(x)\n\n    # Test with some invalid inputs\n    raises(SyntaxError, lambda: parser.parse(\"{x, y}\"))\n    raises(SyntaxError, lambda: parser.parse(\"(x y)\"))\n\n    # Test with some edge cases\n    assert parser.parse(\"x_\") == sympify(\"x\")\n    assert parser.parse(\"x_.\") == sympify(\"Optional(Pattern(x, Blank()))\")\n    assert parser.parse(\"x__\") == sympify(\"Pattern(x, BlankSequence())\")\n    assert parser.parse(\"x___\") == sympify(\"Pattern(x, BlankNullSequence())\")\n\n    # Test with some function definitions\n    assert parser.parse(\"f[x_] := x^2\") == sympify(\"SetDelayed(Function(x), x ** 2)\")\n    assert parser.parse(\"f[x_, y_] := x^2 + y^2\") == sympify(\"SetDelayed(Function(x, y), x ** 2 + y ** 2)\")\n\n    # Test with some lambda functions\n    assert parser.parse(\"#^2 &\") == sympify(\"Function(Lambda(x, x ** 2))\")\n    assert parser.parse(\"#^2 &@x\") == sympify(\"Function(Lambda(x, x ** 2))(x)\")\n\n    # Test with some pattern matching\n    assert parser.parse(\"f[x_: 0]\") == sympify(\"Function(Pattern(x, 0))\")\n    assert parser.parse(\"f[x_: 0, y_: 1]\") == sympify(\"Function(Pattern(x, 0), Pattern(y, 1))\")\n\n    # Test with some conditionals\n    assert parser.parse(\"x /; x > 0\") == sympify(\"Condition(x, x > 0)\")\n\n    # Test with some repeated expressions\n    assert parser.parse(\"x..\") == sympify(\"Repeated(x)\")\n    assert parser.parse(\"x...\") == sympify(\"RepeatedNull(x)\")\n\n    # Test with some alternatives\n    assert parser.parse(\"x|y\") == sympify(\"Alternatives", "def test_parse_mathematica():\n    parser = MathematicaParser()\n\n    # Test some basic expressions\n    assert parse_mathematica(\"2 + 3\") == 2 + 3\n    assert parse_mathematica(\"2 * 3\") == 2 * 3\n    assert parse_mathematica(\"2 ^ 3\") == 2 ** 3\n\n    # Test some Mathematica functions\n    assert parse_mathematica(\"Sin[x]\") == sin(x)\n    assert parse_mathematica(\"Cos[x]\") == cos(x)\n    assert parse_mathematica(\"Exp[x]\") == sympify(\"exp(x)\")\n    assert parse_mathematica(\"Log[x]\") == sympify(\"log(x)\")\n    assert parse_mathematica(\"Sqrt[x]\") == sympify(\"sqrt(x)\")\n\n    # Test some more complex expressions\n    assert parse_mathematica(\"2 * Sin[x] + 3 * Cos[y]\") == 2 * sin(x) + 3 * cos(y)\n    assert parse_mathematica(\"x ^ 2 + y ^ 2\") == x ** 2 + y ** 2\n\n    # Test parsing of Mathematica's FullForm\n    assert parse_mathematica(\"Times[2, 3]\") == 2 * 3\n    assert parse_mathematica(\"Power[2, 3]\") == 2 ** 3\n\n    # Test parsing of Mathematica's patterns\n    a = Function(\"a\")\n    assert parse_mathematica(\"a[x_, y_]\").func == a\n    assert parse_mathematica(\"a[x_, y_]\").args == (Dummy('x'), Dummy('y'))\n\n    # Test parsing of Mathematica's slots\n    assert parse_mathematica(\"#\") == Dummy('x')\n    assert parse_mathematica(\"#1\") == Dummy('x')\n\n    # Test parsing of Mathematica's function definitions\n    assert parse_mathematica(\"f[x_] := x ^ 2\") == Lambda(Dummy('x'), Dummy('x')**2)\n\n    # Test parsing of Mathematica's lists\n    assert parse_mathematica(\"{1, 2, 3}\") == (1, 2, 3)\n\n    # Test parsing of Mathematica's rules\n    assert parse_mathematica(\"x_ -> y\") == (Dummy('x'), Dummy('y'))\n", "def test_mathematica_parser():\n    parser = MathematicaParser()\n    # Test basic math\n    assert parser.parse(\"1+2*3\") == sympify(\"1+2*3\")\n    assert parser.parse(\"1 + 2 * 3\") == sympify(\"1+2*3\")\n    assert parser.parse(\"(1 + 2) * 3\") == sympify(\"(1+2)*3\")\n    # Test functions\n    assert parser.parse(\"Sin[x]\") == sin(x)\n    assert parser.parse(\"Cos[x]\") == cos(x)\n    # Test unknown functions\n    f = Function(\"f\")\n    assert parser.parse(\"f[x]\") == f(x)\n    # Test variables\n    assert parser.parse(\"x\") == x\n    assert parser.parse(\"x_\") == symbols(\"x\")\n    # Test replacement\n    x, y = symbols(\"x y\")\n    assert parser.parse(\"x_.\") == y\n    parser = MathematicaParser({\"x_\": \"y\"})\n    assert parser.parse(\"x_.\") == y\n    # Test math built-in functions\n    assert parser.parse(\"Log[x]\") == log(x)\n    assert parser.parse(\"Log2[x]\") == log(x, 2)\n    assert parser.parse(\"Log10[x]\") == log(x, 10)\n    assert parser.parse(\"Exp[x]\") == exp(x)\n    assert parser.parse(\"Sqrt[x]\") == sqrt(x)\n    assert parser.parse(\"Im[x]\") == im(x)\n    assert parser.parse(\"Re[x]\") == sympify(\"re(x)\")\n    assert parser.parse(\"Expand[x]\") == expand(x)\n    assert parser.parse(\"Cancel[x]\") == cancel(x)\n    assert parser.parse(\"TrigExpand[x]\") == expand_trig(x)\n    assert parser.parse(\"Sign[x]\") == sign(x)\n    assert parser.parse(\"Simplify[x]\") == simplify(x)\n    assert parser.parse(\"Defer[x]\") == UnevaluatedExpr(x)\n    assert parser.parse(\"Identity[x]\") == sympify(\"IdentityFunction(x)\")\n    assert parser.parse(\"Mod[x,y]\") == Mod(x, y)\n    assert parser.parse(\"Max[x,y]\") == Max(x, y)\n    assert parser.parse(\"Min[x,y]\") == Min(x, y)\n    assert parser.parse(\"Pochhammer[x,y]\") == sympy.rf(x, y)\n    assert parser.parse(\"ExpIntegralEi[x]\") == sympy.Ei(x)\n    assert parser.parse(\"Sin"], "sample_143": ["def test_tensor_indices():\n    T = TensorHead('T', [TensorIndexType('Lorentz')])\n    indices = tensor_indices('i', TensorIndexType('Lorentz'), 'j', TensorIndexType('Lorentz'))\n    t = T(*indices)\n    pform = upretty(t)\n    assert pform.height() == 3\n    assert pform.width() == 5\n    assert pform.baseline == 2\n", "def test_tensor_indices():\n    # pretty printing of Tensor indices\n    i, j = tensor_indices('i', 'j', TensorIndexType('Lorentz'))\n    assert pretty(i) == r'\\nu'\n    assert pretty(-i) == r'-\\nu'\n\n    i, j = tensor_indices('i', 'j', TensorIndexType('spacetime'))\n    assert pretty(i) == r'i'\n    assert pretty(-i) == r'-i'\n\n    i, j = tensor_indices('i', 'j', TensorIndexType('spacetime', dummy_name='i'))\n    assert pretty(i) == r'\\overline{i}'\n    assert pretty(-i) == r'-\\overline{i}'\n\n    i, j = tensor_indices('i', 'j', TensorIndexType('Lorentz', dummy_name='i'))\n    assert pretty(i) == r'\\overline{\\nu}'\n    assert pretty(-i) == r'-\\overline{\\nu}'\n", "def test_tensor_head():\n    i = symbols('i', integer=True, positive=True)\n    j = symbols('j', integer=True, positive=True)\n    k = symbols('k', integer=True, positive=True)\n    l = symbols('l', integer=True, positive=True)\n    m = symbols('m', integer=True, positive=True)\n\n    t1 = TensorHead('T', [TensorIndexType('Lorentz')]*4)\n    t2 = TensorHead('T', [TensorIndexType('Lorentz')]*4)\n    assert pretty(t1(i, j, k, l)) == upretty(t1(i, j, k, l)) == 'T_{ijkl}'\n    assert pretty(t1(i, j, k, l)*t2(k, l, m, i)) == upretty(t1(i, j, k, l)*t2(k, l, m, i)) == 'T_{ijkl}*T_{klmi}'\n    assert pretty(t1(i, j, k, l)*t2(l, k, i, j)) == upretty(t1(i, j, k, l)*t2(l, k, i, j)) == 'T_{ijkl}*T_{lkij}'\n    assert pretty(t1(i, j, k, l)*t2(i, j, k, l)) == upretty(t1(i, j, k, l)*t2(i, j, k, l)) == 'T_{ijkl}*T_{ijkl}'\n\n    t3 = TensorHead('T', [TensorIndexType('Lorentz')]*2)\n    assert pretty(t1(i, j, k, l)*t3(j, l)) == upretty(t1(i, j, k, l)*t3(j, l)) == 'T_{ijkl}*T_{jl}'\n    assert pretty(t1(i, j, k, l)*t3(i, k)) == upretty(t1(i, j, k, l)*t3(i, k)) == 'T_{ijkl}*T_{ik}'\n    assert pretty(t1(i, j, k, l)*t3(i, l)) == upretty(t1(i, j, k, l)*t3(i, l)) == 'T_{ijkl}*T_{il}'\n    assert pretty(t1(i, j, k, l)*t3(j, k)) == upretty(t1(i, j, k", "def test_transfer_function():\n    s = Symbol('s')\n    tf = TransferFunction(s**2 + 1, s**2 + 2*s + 1, s)\n    assert upretty(tf) == '     2\\ns  + 1\\n-----\\ns  + 2s + 1'\n", "def test_FourierSeries():\n    s = fourier_series(sin(x), (x, -pi, pi))\n    assert pretty(s) == \"        oo\\n       _____\\n        \\\\   2*\\n        >   --\\n       /__   \\ \\n       |  |  | sin(k*pi)\\n       |  |  ---------\\n       |  >  k=1    2*k\\n       | /  -------------------\\n       |/   pi*(1 - (-1)**k)\\n       |\\n        \\n        \\n    + 1/2\\n\"\n\n"], "sample_106": ["def test_nca_warm_start():\n    # Test warm start with different input dimensionality\n    nca = NeighborhoodComponentsAnalysis(n_components=2, warm_start=True)\n    nca.fit(iris_data, iris_target)\n    with assert_warns_message(UserWarning, \"The new inputs dimensionality\"):\n        nca.fit(np.c_[iris_data, np.random.rand(iris_data.shape[0])], iris_target)\n", "def test_nca_callback():\n    # Test that the callback is called after every iteration.\n        callbacks.append(n_iter)\n\n    callbacks = []\n    nca = NeighborhoodComponentsAnalysis(callback=callback, max_iter=10,\n                                        tol=1e-10)\n    nca.fit(iris_data, iris_target)\n\n    assert_equal(len(callbacks), nca.n_iter_)\n", "def test_nca_init_random_state():\n    # Test that a random initialization is reproducible with a given seed\n    nca1 = NeighborhoodComponentsAnalysis(init='random', random_state=42)\n    nca1.fit(iris_data, iris_target)\n    components1 = nca1.components_\n    nca2 = NeighborhoodComponentsAnalysis(init='random', random_state=42)\n    nca2.fit(iris_data, iris_target)\n    components2 = nca2.components_\n    assert_array_equal(components1, components2)\n\n    # Test that a random initialization with different seeds gives different results\n    nca3 = NeighborhoodComponentsAnalysis(init='random', random_state=43)\n    nca3.fit(iris_data, iris_target)\n    components3 = nca3.components_\n    assert not np.array_equal(components1, components3)\n", "def test_nca_verbose():\n    \"\"\"Check that the verbose parameter works correctly.\"\"\"\n    nca = NeighborhoodComponentsAnalysis(verbose=1, random_state=rng)\n    with pytest.raises(AssertionError, match=\"The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\"):\n        assert nca.fit(iris_data, iris_target)\n\n    nca = NeighborhoodComponentsAnalysis(verbose=0, random_state=rng)\n    assert nca.fit(iris_data, iris_target) is not None\n\n    nca = NeighborhoodComponentsAnalysis(verbose=2, random_state=rng)\n    assert nca.fit(iris_data, iris_target) is not None\n", "def test_nca_init():\n    # Test initialization methods\n    nca = NeighborhoodComponentsAnalysis(n_components=2, random_state=0)\n    X, y = iris_data[:3], iris_target[:3]\n    nca.fit(X, y)\n    assert_array_almost_equal(nca.components_, [[-0.948683, -0.3162255, -0.104825, 0.064233],\n                                               [0.266265, -0.895466, -0.366737, -0.136245]])\n\n    nca = NeighborhoodComponentsAnalysis(n_components=2, init='pca')\n    nca.fit(X, y)\n    assert_array_almost_equal(nca.components_, [[-0.778639, -0.629255, 0.281362, 0.5288104],\n                                               [0.490074, 0.754583, -0.435489, -0.072627]])\n\n    nca = NeighborhoodComponentsAnalysis(n_components=2, init='lda')\n    nca.fit(X, y)\n    assert_array_almost_equal(nca.components_, [[-0.469471, 0.670816, -0.239675, -0.596907],\n                                               [0.625449, 0.248352, 0.740794, 0.098204]])\n\n    nca = NeighborhoodComponentsAnalysis(n_components=2, init='identity')\n    nca.fit(X, y)\n    assert_array_almost_equal(nca.components_, [[1, 0, 0, 0], [0, 1, 0, 0]])\n\n    nca = NeighborhoodComponentsAnalysis(n_components=2, init=np.array([[1, 0, 0, 0], [0, 1, 0, 0]]))\n    nca.fit(X, y)\n    assert_array_almost_equal(nca.components_, [[-0.224082, -0.974118, -0.104824, 0.064234],\n                                               [0.266265, -0.895466, -0.366737, -0.136245]])\n"], "sample_103": ["def test_compute_mi_cd():\n    # Test _compute_mi_cd with a simple example\n    c = np.array([1, 2, 3, 4, 5])\n    d = np.array([0, 0, 1, 1, 1])\n    mi = _compute_mi_cd(c, d, n_neighbors=3)\n    assert_almost_equal(mi, 0.577, decimal=3)\n\n    # Test _compute_mi_cd with a case where there's only one discrete value\n    d = np.array([0, 0, 0, 0, 0])\n    mi = _compute_mi_cd(c, d, n_neighbors=3)\n    assert_almost_equal(mi, 0.0, decimal=3)\n\n    # Test _compute_mi_cd with a case where there are no discrete values\n    d = np.array([1, 2, 3, 4, 5])\n    with assert_raises(ValueError):\n        _compute_mi_cd(c, d, n_neighbors=3)\n", "def test_compute_mi_cd():\n    # Test computation of mutual information between continuous and discrete\n    # variables\n    rng = check_random_state(0)\n    c = rng.rand(100)\n    d = np.repeat([0, 1], 50)\n    mi = _compute_mi_cd(c, d, n_neighbors=3)\n    assert_greater(mi, 0)\n\n    # Test that MI is 0 for independent variables\n    c = rng.rand(100)\n    d = rng.randint(0, 2, 100)\n    mi = _compute_mi_cd(c, d, n_neighbors=3)\n    assert_almost_equal(mi, 0, decimal=3)\n\n    # Test that MI is 1 for identical variables\n    c = np.repeat([0, 1], 50)\n    d = c\n    mi = _compute_mi_cd(c, d, n_neighbors=3)\n    assert_almost_equal(mi, 1, decimal=3)\n", "def test_mutual_info_continuous():\n    # Test mutual information between two continuous variables\n    rng = check_random_state(0)\n    x = rng.randn(100)\n    y = x + rng.randn(100) / 10.0\n    mi = _compute_mi(x, y, False, False, 3)\n    assert_greater(mi, 0)\n", "def test_mutual_info_regression():\n    # Test that the MI regression is symmetric\n    rng = check_random_state(0)\n    X = rng.rand(10, 3)\n    y = rng.rand(10)\n    mi_xy = mutual_info_regression(X, y, discrete_features=False, n_neighbors=3, random_state=0)\n    mi_yx = mutual_info_regression(y[:, np.newaxis], X, discrete_features=False, n_neighbors=3, random_state=0)\n    assert_almost_equal(mi_xy, mi_yx)\n\n", "def test_mutual_info_classif():\n    # Test for discrete features\n    rng = check_random_state(0)\n    X = rng.randint(0, 2, size=(100, 3))\n    y = rng.randint(0, 2, size=100)\n    mi = mutual_info_classif(X, y, discrete_features=True)\n    assert_almost_equal(mi, np.array([0.0117609, 0.0243866, 0.0137053]))\n\n    # Test for continuous features\n    X = rng.rand(100, 3)\n    mi = mutual_info_classif(X, y, discrete_features=False)\n    assert_almost_equal(mi, np.array([0.0155035, 0.0261531, 0.0138933]))\n\n    # Test for mixed features\n    X[:, 0] = rng.randint(0, 2, size=100)\n    mi = mutual_info_classif(X, y, discrete_features=[True, False, False])\n    assert_almost_equal(mi, np.array([0.0117609, 0.0261531, 0.0138933]))\n\n    # Test for sparse matrix\n    X_sparse = csr_matrix(X)\n    mi_sparse = mutual_info_classif(X_sparse, y, discrete_features=[True, False, False])\n    assert_almost_equal(mi_sparse, mi)\n\n    # Test for ValueError\n    assert_raises(ValueError, mutual_info_classif, X_sparse, y,\n                 discrete_features=[True, False, True])\n\n    # Test for ValueError\n    assert_raises(ValueError, mutual_info_classif, X, y, discrete_features='invalid')\n"], "sample_113": ["def test_make_column_selector():\n    df = pd.DataFrame({\n        \"A\": [1, 2, 3],\n        \"B\": [1.0, 2.0, 3.0],\n        \"C\": [\"a\", \"b\", \"c\"],\n        \"D\": [True, False, True]\n    })\n\n    selector = make_column_selector(dtype_include=np.number)\n    assert_array_equal(selector(df), [\"A\", \"B\"])\n\n    selector = make_column_selector(dtype_exclude=np.number)\n    assert_array_equal(selector(df), [\"C\", \"D\"])\n\n    selector = make_column_selector(pattern=\"A\")\n    assert_array_equal(selector(df), [\"A\"])\n\n    selector = make_column_selector(dtype_include=np.number, pattern=\"A\")\n    assert_array_equal(selector(df), [\"A\"])\n\n    selector = make_column_selector(dtype_exclude=np.number, pattern=\"A\")\n    assert_array_equal(selector(df), [])\n\n    selector = make_column_selector(dtype_include=np.number, dtype_exclude=np.int64)\n    assert_array_equal(selector(df), [\"B\"])\n\n    with pytest.raises(ValueError):\n        selector = make_column_selector()\n        selector(np.array([[1, 2], [3, 4]]))\n", "def test_transformer_weights():\n    X = np.array([[1, 2], [3, 4]])\n    transformer_weights = {\"scaler\": 2.0, \"encoder\": 3.0}\n    ct = ColumnTransformer(\n        transformers=[\n            (\"scaler\", StandardScaler(), [0]),\n            (\"encoder\", OneHotEncoder(), [1]),\n        ],\n        transformer_weights=transformer_weights,\n    )\n    X_t = ct.fit_transform(X)\n\n    # StandardScaler is weighted by 2.0\n    assert_allclose(X_t[:, 0], np.array([2 * -1, 2 * 1]))\n\n    # OneHotEncoder is weighted by 3.0\n    assert_allclose(X_t[:, 1:], np.array([[0.0, 0.0], [3.0, 0.0]]))\n", "def test_make_column_selector():\n    # Test that make_column_selector is correctly selecting columns\n    X = np.array([[1, 2, 3], [4, 5, 6]])\n    df = pd.DataFrame(X, columns=[\"a\", \"b\", \"c\"])\n\n    selector = make_column_selector(dtype_include=np.number)\n    assert selector(df) == [\"a\", \"b\", \"c\"]\n\n    selector = make_column_selector(dtype_exclude=np.number)\n    assert selector(df) == []\n\n    selector = make_column_selector(pattern=\"a\")\n    assert selector(df) == [\"a\"]\n\n    selector = make_column_selector(dtype_include=np.number, pattern=\"a\")\n    assert selector(df) == [\"a\"]\n\n    selector = make_column_selector(dtype_exclude=np.number, pattern=\"a\")\n    assert selector(df) == []\n\n    # Test that make_column_selector is correctly handling edge cases\n    selector = make_column_selector(dtype_include=None, dtype_exclude=None)\n    assert selector(df) == [\"a\", \"b\", \"c\"]\n\n    selector = make_column_selector(pattern=None)\n    assert selector(df) == [\"a\", \"b\", \"c\"]\n\n    selector = make_column_selector(dtype_include=None, pattern=None)\n    assert selector(df) == [\"a\", \"b\", \"c\"]\n\n    # Test that make_column_selector raises an error when given a non-DataFrame\n    with pytest.raises(ValueError):\n        selector(X)\n\n    # Test that make_column_selector raises an error when given a non-string pattern\n    with pytest.raises(TypeError):\n        make_column_selector(pattern=123)\n\n    # Test that make_column_selector raises an error when given a non-list dtype_include\n    with pytest.raises(TypeError):\n        make_column_selector(dtype_include=123)\n\n    # Test that make_column_selector raises an error when given a non-list dtype_exclude\n    with pytest.raises(TypeError):\n        make_column_selector(dtype_exclude=123)\n", "def test_transformer_weights():\n    # Test that transformer weights are correctly applied.\n    transformers = [(\"a\", StandardScaler(), [0, 1]), (\"b\", StandardScaler(), [2, 3])]\n    X = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n    ct = ColumnTransformer(transformers, transformer_weights={\"a\": 2, \"b\": 0.5})\n    ct.fit(X)\n    transformed = ct.transform(X)\n    expected = np.concatenate(\n        (\n            StandardScaler().fit_transform(X[:, :2]) * 2,\n            StandardScaler().fit_transform(X[:, 2:]) * 0.5,\n        ),\n        axis=1,\n    )\n    assert_allclose_dense_sparse(transformed, expected)\n\n    # Test that transformer weights are correctly applied when remainder is \"passthrough\".\n    transformers = [(\"a\", StandardScaler(), [0, 1])]\n    remainder = \"passthrough\"\n    X = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n    ct = ColumnTransformer(\n        transformers, remainder=remainder, transformer_weights={\"a\": 2}\n    )\n    ct.fit(X)\n    transformed = ct.transform(X)\n    expected = np.concatenate(\n        (StandardScaler().fit_transform(X[:, :2]) * 2, X[:, 2:]), axis=1\n    )\n    assert_allclose_dense_sparse(transformed, expected)\n\n    # Test that an exception is raised when transformer weights are provided for unknown transformers.\n    transformers = [(\"a\", StandardScaler(), [0, 1])]\n    X = np.array([[1, 2], [3, 4]])\n    with pytest.raises(ValueError):\n        ColumnTransformer(transformers, transformer_weights={\"a\": 2, \"b\": 0.5})\n\n    # Test that an exception is raised when transformer weights are provided for \"remainder\".\n    transformers = [(\"a\", StandardScaler(), [0, 1])]\n    remainder = \"passthrough\"\n    X = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n    with pytest.raises(ValueError):\n        ColumnTransformer(\n            transformers, remainder=remainder, transformer_weights={\"remainder\": 2}\n        )\n\n    # Test that a warning is raised when transformer weights are provided for \"drop\".\n    transformers = [(\"a", "def test_transformer_weights():\n    # test that transformer weights are applied correctly\n    X = np.array([[1, 2, 3], [4, 5, 6]])\n\n    transformer = make_column_transformer(\n        (DoubleTrans(), [0]),\n        (DoubleTrans(), [1]),\n        (DoubleTrans(), [2]),\n    )\n\n    transformer.fit(X)\n\n    X_t = transformer.transform(X)\n\n    expected = np.array([[2, 4, 6], [8, 10, 12]])\n\n    assert_allclose(X_t, expected)\n\n    transformer.set_params(transformer_weights={\"doubletrans\": 0.5})\n\n    X_t_weighted = transformer.transform(X)\n\n    expected_weighted = np.array([[1, 2, 3], [4, 5, 6]])\n\n    assert_allclose(X_t_weighted, expected_weighted)\n"], "sample_97": ["def test_multilabel_binarizer_inverse_transform_sparse_input():\n    mlb = MultiLabelBinarizer()\n    y = [[1, 2], [3]]\n    y_sparse = csr_matrix(toarray(mlb.fit_transform(y)))\n    y_inv = mlb.inverse_transform(y_sparse)\n    assert_array_equal(y, y_inv)\n    assert_true(issparse(y_sparse))\n    assert_false(issparse(y_inv))\n", "def test_inverse_binarize_thresholding_multilabel_indicator():\n    # Test that the inverse_binarize_thresholding function correctly\n    # handles the multilabel-indicator case\n    y = np.array([[0, 1, 1], [1, 0, 0]])\n    classes = np.array([0, 1, 2])\n    y_pred = label_binarize(y, classes)\n    y_inv = _inverse_binarize_thresholding(y_pred, 'multilabel-indicator',\n                                           classes, threshold=0.5)\n    assert_array_equal(y, y_inv)\n", "def test_inverse_binarize_multiclass():\n    # Test multiclass case\n    y = np.array([[0, 0, 1],\n                  [0, 1, 0],\n                  [1, 0, 0],\n                  [1, 0, 0]])\n    classes = np.array([1, 2, 3])\n    assert_array_equal(_inverse_binarize_multiclass(y, classes), np.array([3, 2, 1, 1]))\n\n    # Test multiclass case with non-contiguous classes\n    y = np.array([[0, 0, 1],\n                  [0, 1, 0],\n                  [1, 0, 0],\n                  [1, 0, 0]])\n    classes = np.array([5, 2, 1])\n    assert_array_equal(_inverse_binarize_multiclass(y, classes), np.array([1, 2, 5, 5]))\n\n    # Test multiclass case with non-contiguous classes and sparse input\n    y = csr_matrix(np.array([[0, 0, 1],\n                             [0, 1, 0],\n                             [1, 0, 0],\n                             [1, 0, 0]]))\n    classes = np.array([5, 2, 1])\n    assert_array_equal(_inverse_binarize_multiclass(y, classes), np.array([1, 2, 5, 5]))\n\n    # Test binary case\n    y = np.array([[0, 1]])\n    classes = np.array([1, 2])\n    assert_array_equal(_inverse_binarize_multiclass(y, classes), np.array([2]))\n\n    # Test binary case with non-contiguous classes\n    y = np.array([[0, 1]])\n    classes = np.array([5, 2])\n    assert_array_equal(_inverse_binarize_multiclass(y, classes), np.array([2]))\n\n    # Test binary case with non-contiguous classes and sparse input\n    y = csr_matrix(np.array([[0, 1]]))\n    classes = np.array([5, 2])\n    assert_array_equal(_inverse_binarize_multiclass(y, classes), np.array([2]))\n\n    # Test single class case\n    y = np.array([[1]])\n    classes = np.array([1])\n    assert_array_equal(_inverse_binarize_multiclass(y, classes), np.array([1", "def test_label_binarizer_sparse_input():\n    lb = LabelBinarizer()\n    y = np.array([1, 2, 6, 4, 2])\n    y_sparse = csr_matrix(y)\n\n    lb.fit(y_sparse)\n    lb.fit_transform(y_sparse)\n    assert_array_equal(lb.classes_, np.array([1, 2, 4, 6]))\n\n    y_new = np.array([1, 6, 1, 4])\n    y_new_sparse = csr_matrix(y_new)\n\n    y_trans = lb.transform(y_new_sparse)\n    assert_true(issparse(y_trans))\n    assert_array_equal(toarray(y_trans), np.array([[1, 0, 0, 0],\n                                                   [0, 0, 0, 1],\n                                                   [1, 0, 0, 0],\n                                                   [0, 0, 1, 0]]))\n\n    y_inv = lb.inverse_transform(y_trans)\n    assert_array_equal(y_inv, np.array([1, 6, 1, 4]))\n\n    lb_sparse = LabelBinarizer(sparse_output=True)\n    y_trans_sparse = lb_sparse.fit_transform(y_sparse)\n    assert_true(issparse(y_trans_sparse))\n    assert_array_equal(toarray(y_trans_sparse), np.array([[1, 0, 0, 0],\n                                                          [0, 1, 0, 0],\n                                                          [0, 0, 0, 1],\n                                                          [0, 1, 0, 0],\n                                                          [0, 1, 0, 0]]))\n\n    y_inv_sparse = lb_sparse.inverse_transform(y_trans_sparse)\n    assert_array_equal(y_inv_sparse, np.array([1, 2, 6, 2, 2]))\n", "def test_label_binarizer_multilabel():\n    # Test the LabelBinarizer on multilabel data\n    y_multilabel = np.array([[1, 0, 0], [0, 1, 1]])\n    y_multilabel_2 = np.array([[1, 1, 0], [0, 1, 0]])\n\n    lb = LabelBinarizer(sparse_output=True)\n    y = lb.fit_transform(y_multilabel)\n    assert_true(issparse(y))\n    y = lb.transform(y_multilabel_2)\n    assert_true(issparse(y))\n\n    lb = LabelBinarizer(sparse_output=False)\n    y = lb.fit_transform(y_multilabel)\n    assert_true(not issparse(y))\n    y = lb.transform(y_multilabel_2)\n    assert_true(not issparse(y))\n\n    lb = LabelBinarizer(neg_label=-1, pos_label=1, sparse_output=True)\n    y = lb.fit_transform(y_multilabel)\n    assert_true(issparse(y))\n    y = lb.transform(y_multilabel_2)\n    assert_true(issparse(y))\n\n    lb = LabelBinarizer(neg_label=-1, pos_label=1, sparse_output=False)\n    y = lb.fit_transform(y_multilabel)\n    assert_true(not issparse(y))\n    y = lb.transform(y_multilabel_2)\n    assert_true(not issparse(y))\n\n    # Test the inverse transform\n    y_inv = lb.inverse_transform(y.toarray())\n    assert_array_equal(y_inv, y_multilabel_2)\n"], "sample_26": ["    def test_create_test_db(self):\n        \"\"\"\n        Tests create_test_db method of BaseDatabaseCreation class.\n        \"\"\"\n        test_connection = get_connection_copy()\n        creation = BaseDatabaseCreation(test_connection)\n\n        # Test create_test_db when the test database does not exist\n        creation._create_test_db.return_value = 'test_database'\n        test_database_name = creation.create_test_db(verbosity=1, autoclobber=False, serialize=True, keepdb=False)\n        self.assertEqual(test_database_name, 'test_database')\n\n        # Test create_test_db when the test database already exists and autoclobber is False\n        creation._create_test_db.side_effect = Exception('Test database already exists')\n        with mock.patch('builtins.input', return_value='yes'):\n            test_database_name = creation.create_test_db(verbosity=1, autoclobber=False, serialize=True, keepdb=False)\n            self.assertEqual(test_database_name, 'test_database')\n\n        # Test create_test_db when the test database already exists and autoclobber is True\n        creation._create_test_db.side_effect = Exception('Test database already exists')\n        test_database_name = creation.create_test_db(verbosity=1, autoclobber=True, serialize=True, keepdb=False)\n        self.assertEqual(test_database_name, 'test_database')\n\n        # Test create_test_db when keepdb is True\n        creation._create_test_db.return_value = 'test_database'\n        test_database_name = creation.create_test_db(verbosity=1, autoclobber=False, serialize=True, keepdb=True)\n        self.assertEqual(test_database_name, 'test_database')\n\n        # Test create_test_db when serialize is False\n        creation._create_test_db.return_value = 'test_database'\n        test_database_name = creation.create_test_db(verbosity=1, autoclobber=False, serialize=False, keepdb=False)\n        self.assertEqual(test_database_name, 'test_database')\n", "def test_test_db_signature(self):\n    \"\"\"\n    Ensure the test_db_signature method returns the correct values.\n    \"\"\"\n    test_connection = get_connection_copy()\n    creation = BaseDatabaseCreation(test_connection)\n\n    # Ensure the signature is correctly calculated\n    signature = creation.test_db_signature()\n    expected_signature = (\n        test_connection.settings_dict['HOST'],\n        test_connection.settings_dict['PORT'],\n        test_connection.settings_dict['ENGINE'],\n        TEST_DATABASE_PREFIX + test_connection.settings_dict['NAME'],\n    )\n    self.assertEqual(signature, expected_signature)\n\n    # Ensure the signature is different if the host, port, or engine change\n    test_connection.settings_dict['HOST'] = 'example.com'\n    self.assertNotEqual(creation.test_db_signature()[0], expected_signature[0])\n    test_connection.settings_dict['HOST'] = test_connection.settings_dict['HOST']\n    test_connection.settings_dict['PORT'] = 5432\n    self.assertNotEqual(creation.test_db_signature()[1], expected_signature[1])\n    test_connection.settings_dict['PORT'] = test_connection.settings_dict['PORT']\n    test_connection.settings_dict['ENGINE'] = 'django.db.backends.sqlite3'\n    self.assertNotEqual(creation.test_db_signature()[2], expected_signature[2])\n    test_connection.settings_dict['ENGINE'] = test_connection.settings_dict['ENGINE']\n\n    # Ensure the signature is different if the test database name changes\n    test_connection.settings_dict['TEST']['NAME'] = 'my_test_database'\n    self.assertNotEqual(creation.test_db_signature()[3], expected_signature[3])\n", "    def setUp(self):\n        self.connection = get_connection_copy()\n", "    def test_clone_test_db(self):\n        test_connection = get_connection_copy()\n        creation = BaseDatabaseCreation(test_connection)\n        with self.assertRaises(NotImplementedError):\n            creation._clone_test_db(suffix='clone', verbosity=1, keepdb=False)\n        with self.assertRaises(NotImplementedError):\n            creation.clone_test_db(suffix='clone', verbosity=1, keepdb=False)\n", "def test_test_db_signature(self):\n    \"\"\"\n    Test that test_db_signature returns a tuple of identifying elements\n    that can be used to determine if two connections are referring to\n    the same database.\n    \"\"\"\n    test_connection = get_connection_copy()\n    base_creation = BaseDatabaseCreation(test_connection)\n    signature = base_creation.test_db_signature()\n\n    # Check that test_db_signature returns a tuple of identifying elements\n    self.assertIsInstance(signature, tuple)\n    self.assertEqual(len(signature), 4)\n\n    # Check that test_db_signature returns elements in the correct order\n    settings_dict = test_connection.settings_dict\n    self.assertEqual(signature[0], settings_dict['HOST'])\n    self.assertEqual(signature[1], settings_dict['PORT'])\n    self.assertEqual(signature[2], settings_dict['ENGINE'])\n    self.assertEqual(signature[3], base_creation._get_test_db_name())\n\n    # Check that test_db_signature is unaffected by changes to the connection\n    # settings\n    test_connection.settings_dict['HOST'] = 'new_host'\n    new_signature = base_creation.test_db_signature()\n    self.assertEqual(signature[0], new_signature[0])\n    self.assertEqual(signature[1], new_signature[1])\n    self.assertEqual(signature[2], new_signature[2])\n    self.assertEqual(signature[3], new_signature[3])\n\n    # Check that test_db_signature is different for different connections\n    different_connection = get_connection_copy()\n    different_connection.settings_dict['HOST'] = 'different_host'\n    base_creation = BaseDatabaseCreation(different_connection)\n    different_signature = base_creation.test_db_signature()\n    self.assertNotEqual(signature, different_signature)\n"], "sample_50": ["def test_not_finished_sentinel(self):\n    \"\"\"\n    Verify that the not_finished sentinel is handled correctly.\n    \"\"\"\n    storage = self.get_storage()\n    messages = [Message(constants.DEBUG, 'message 1'), Message(constants.INFO, 'message 2')]\n    set_cookie_data(storage, messages + [CookieStorage.not_finished])\n    loaded_messages, all_retrieved = storage._get()\n    self.assertEqual(loaded_messages, messages)\n    self.assertFalse(all_retrieved)\n    response = self.get_response()\n    self.assertEqual(stored_cookie_messages_count(storage, response), len(messages))\n", "    def test_cookie_storage_max_size(self):\n        storage = self.get_storage()\n        # Generate a large number of messages to exceed the max cookie size\n        messages = [Message(constants.DEBUG, get_random_string(100)) for _ in range(50)]\n        response = self.get_response()\n        storage._store(messages, response)\n        self.assertLess(stored_cookie_messages_count(storage, response), len(messages))\n        self.assertIn(CookieStorage.not_finished, storage._decode(response.cookies[CookieStorage.cookie_name].value))\n", "def test_get_and_store(self):\n    storage = self.get_storage()\n    messages = [Message(constants.INFO, 'Message 1'), Message(constants.WARNING, 'Message 2')]\n    set_cookie_data(storage, messages)\n    retrieved_messages, all_retrieved = storage._get()\n    self.assertEqual(retrieved_messages, messages)\n    self.assertTrue(all_retrieved)\n    response = self.get_response()\n    stored_messages = storage._store(messages, response)\n    self.assertEqual(stored_messages, [])\n", "def test_storage_truncation(self):\n    storage = self.get_storage()\n    messages = [Message(constants.DEBUG, 'Message %d' % i) for i in range(10)]\n    encoded_data = storage._encode(messages)\n    self.assertLessEqual(len(encoded_data), storage.max_cookie_size)\n\n    # Make sure that the messages that didn't fit were removed from the encoded data\n    decoded_messages = storage._decode(encoded_data)\n    self.assertLess(len(decoded_messages), len(messages))\n\n    # Make sure that the not_finished sentinel was added to the encoded data\n    self.assertEqual(decoded_messages[-1], CookieStorage.not_finished)\n\n    # Make sure that the messages that didn't fit are returned\n    unstored_messages = storage._store(messages, self.response)\n    self.assertEqual(len(unstored_messages), len(messages) - len(decoded_messages))\n", "def test_not_finished_sentinel(self):\n    storage = self.get_storage()\n    messages = [Message(constants.DEBUG, 'Message 1'), Message(constants.DEBUG, 'Message 2')]\n    encoded_data = storage._encode(messages + [CookieStorage.not_finished])\n    self.assertTrue(encoded_data)\n    decoded_messages = storage._decode(encoded_data)\n    self.assertEqual(len(decoded_messages), 2)\n    self.assertEqual(decoded_messages[0].message, 'Message 1')\n    self.assertEqual(decoded_messages[1].message, 'Message 2')\n"], "sample_90": ["    def test_MarkEvaluator_istrue(self, condition, expected_result):\n        class MockItem:\n                return [Mark(\"mark_name\", kwargs={\"condition\": condition})]\n\n        evaluator = MarkEvaluator(MockItem(), \"mark_name\")\n        assert evaluator.istrue() == expected_result\n", "    def test_mark_evaluator_istrue_with_invalid_condition(self):\n        evaluator = MarkEvaluator(Node(), \"test_mark\")\n        mark = Mark(\"test_mark\", (\"condition\",), {\"condition\": \"invalid_condition\"}, {})\n        with mock.patch.object(evaluator, \"_get_marks\", return_value=[mark]):\n            assert not evaluator.istrue()\n            assert hasattr(evaluator, \"exc\")\n", "    def test_mark_evaluator_invalidraise(self, pytestconfig):\n        # Create a mock item and mark\n        item = Collector.from_parent(Node(\"test_item\"))\n        mark = Mark(\"raises\", (\"Exception\",))\n        item.keywords._markers[\"raises\"] = mark\n\n        # Create a MarkEvaluator instance\n        evaluator = MarkEvaluator(item, \"raises\")\n\n        # Test with a valid exception\n        assert evaluator.invalidraise(Exception()) is False\n\n        # Test with an invalid exception\n        assert evaluator.invalidraise(ZeroDivisionError()) is True\n\n        # Test with no raises parameter\n        mark = Mark(\"raises\")\n        item.keywords._markers[\"raises\"] = mark\n        evaluator = MarkEvaluator(item, \"raises\")\n        assert evaluator.invalidraise(Exception()) is None\n", "def test_mark_evaluator_istrue(expr, expected_result, tmp_path):\n    class MockItem:\n            self.config = mock.Mock()\n            self.iter_markers = mock.Mock(\n                return_value=[Mark(\"dummy\", kwargs={\"condition\": expr})]\n            )\n\n    evaluator = MarkEvaluator(MockItem(), \"dummy\")\n    assert evaluator.istrue() == expected_result\n", "    def test_mark_evaluator_invalid_raise(self, tmp_path):\n        class MockItem:\n                self.keywords = {\"marks\": marks}\n                self.iter_markers = mock.Mock(return_value=marks)\n\n                return self.keywords[\"marks\"]\n\n        mark = Mark(\"raises\", (RuntimeError,))\n        item = MockItem([mark])\n        evaluator = MarkEvaluator(item, \"raises\")\n        assert evaluator.invalidraise(RuntimeError(\"Mock error\")) is False\n        assert evaluator.invalidraise(ValueError(\"Mock error\")) is True\n"], "sample_125": ["def test_mpf_norm():\n    assert mpf_norm(mpf_norm((0, 1, -10, 2), 5), 5) == mpf_norm((0, 2, -10, 2), 5)\n    assert mpf_norm(mpf_norm((1, 1, -10, 2), 5), 5) == mpf_norm((1, 2, -10, 2), 5)\n    assert mpf_norm(mpf_norm((0, 0, -10, 2), 5), 5) == mpf_norm((0, 0, 0, 2), 5)\n    assert mpf_norm(mpf_norm((1, 0, -10, 2), 5), 5) == mpf_norm((1, 0, 0, 2), 5)\n    assert mpf_norm(mpf_norm((0, 1, 10, 2), 5), 5) == mpf_norm((0, 2, 10, 2), 5)\n    assert mpf_norm(mpf_norm((1, 1, 10, 2), 5), 5) == mpf_norm((1, 2, 10, 2), 5)\n    assert mpf_norm(mpf_norm((0, 0, 10, 2), 5), 5) == mpf_norm((0, 0, 0, 2), 5)\n    assert mpf_norm(mpf_norm((1, 0, 10, 2), 5), 5) == mpf_norm((1, 0, 0, 2), 5)\n    assert mpf_norm(mpf_norm((0, 1, 0, 2), 5), 5) == mpf_norm((0, 1, 0, 2), 5)\n    assert mpf_norm(mpf_norm((1, 1, 0, 2), 5), 5) == mpf_norm((1, 1, 0, 2), 5)\n    assert mpf_norm(mpf_norm((0, 0, 0, 2), 5), 5) == mpf_norm((0, 0, 0, 2), 5)\n    assert mpf_norm(mpf_norm", "def test_numbers():\n    assert Rational(0.1).limit_denominator() == Rational(1, 10)\n    assert Rational('0.1').limit_denominator() == Rational(1, 10)\n    assert Rational('0.0001').limit_denominator() == Rational(1, 10000)\n    assert Rational(0.0001).limit_denominator() == Rational(1, 10000)\n    assert Rational(1).limit_denominator(5) == Rational(1)\n    assert Rational(3).limit_denominator(2) == Rational(3)\n    assert Rational(3).limit_denominator(10) == Rational(3)\n    assert Rational(1, 2).limit_denominator(4) == Rational(1, 2)\n    assert Rational(1, 4).limit_denominator(3) == Rational(1, 4)\n    assert Rational(3, 4).limit_denominator(2) == Rational(3, 4)\n    assert Rational(3, 4).limit_denominator(10) == Rational(3, 4)\n    assert Rational(1, 3).limit_denominator(3) == Rational(1)\n    assert Rational(1, 3).limit_denominator(4) == Rational(1, 3)\n    assert Rational(2, 3).limit_denominator(3) == Rational(1)\n    assert Rational(2, 3).limit_denominator(4) == Rational(2, 3)\n    assert Rational(3, 4).limit_denominator(3) == Rational(1)\n    assert Rational(3, 4).limit_denominator(4) == Rational(3, 4)\n    assert Rational(1, 5).limit_denominator(2) == Rational(0)\n    assert Rational(1, 5).limit_denominator(3) == Rational(1, 3)\n    assert Rational(1, 5).limit_denominator(4) == Rational(1, 4)\n    assert Rational(1, 5).limit_denominator(5) == Rational(1, 5)\n    assert Rational(1, 5).limit_denominator(6) == Rational(1, 5)\n    assert Rational(1, 5).limit_denominator(10) == Rational(1, 5)\n    assert Rational(3, 5).limit_denominator(2", "def test_comp():\n    # Integer comparisons\n    assert comp(1, 1) is True\n    assert comp(1, 2) is True\n    assert comp(1, 0) is False\n    assert comp(0, 0) is True\n    assert comp(0, 1) is False\n\n    # Rational comparisons\n    assert comp(Rational(1, 2), Rational(1, 2)) is True\n    assert comp(Rational(1, 2), Rational(1, 3)) is True\n    assert comp(Rational(1, 2), Rational(2, 3)) is False\n    assert comp(Rational(1, 2), 0) is False\n\n    # Float comparisons\n    assert comp(1.2, 1.2, 0.01) is True\n    assert comp(1.2, 1.3, 0.01) is False\n    assert comp(1.2, 1.3, 0.1) is True\n    assert comp(1.2, 1.2, 0) is True  # 0 tolerance means exact match\n    assert comp(1.2, 1.2, '') is True  # null string means significant digits\n    assert comp(1.2, 1.2, 0.01) is True\n    assert comp(1.2, 1.3, 0.01) is False\n\n    # Float vs float comparisons\n    assert comp(1.2, 1.2) is True\n    assert comp(1.2, 1.3) is True\n    assert comp(1.2, 0) is False\n    assert comp(0, 0) is True\n    assert comp(0, 1) is False\n\n    # Float vs Rational comparisons\n    assert comp(Rational(1, 2), 0.5) is True\n    assert comp(Rational(1, 2), 0.6) is True\n\n    # Float vs String comparisons\n    assert comp(Rational(1, 2), '0.5') is True\n    assert comp(Rational(1, 2), '0.6') is True\n    assert comp(Rational(1, 2), 'one half') is False\n", "def test_igcd():\n    assert igcd(12, 15) == 3\n    assert igcd(4, 6) == 2\n    assert igcd(5, 7) == 1\n    assert igcd(13, 17) == 1\n    assert igcd(8, 15) == 1\n    assert igcd(24, 30) == 6\n    assert igcd(100, 24) == 4\n    assert igcd(30, 105) == 15\n", "def test_float_evalf():\n    # see issue 5536\n    assert srepr((1 + Float('1.2',2)).evalf(4)) == \"Float('1.30', 4, 4)\"\n\n    assert srepr(sympify('0.2').evalf(4)) == \"Float('0.2500', 4, 4)\"\n    assert srepr(sympify('1e-05').evalf(4)) == \"Float('0.0001', 4, 4)\"\n\n    assert (Float(1) + Float(1e-25)).evalf(25) == Float(1, 25)\n    assert (Float(1) + Float(-1e-25)).evalf(25) == Float(1, 25)\n\n    # issue 5045\n    assert Float(-1.2, 30) == Float(-6/5, 30)\n\n    # issue 4296\n    assert (0.2 + 1).evalf(10) == 1.2\n    assert (1 + 0.2).evalf(10) == 1.2\n\n    # Float precision during Pow\n    assert 1.5**2 == Float('2.25')\n    assert (Float('1.5')**2).evalf(10) == 2.25\n\n    # issue 4941\n    assert (Float('1.1') + Float('1.2')).evalf(2) == 2.3\n\n    assert S.Zero.evalf(10) == 0.0\n    assert S.One.evalf(10) == 1.0\n    assert S.Half.evalf(10) == 0.5\n\n    assert S.Infinity.evalf(10) == oo\n    assert S.NegativeInfinity.evalf(10) == -oo\n\n    assert (I + I).evalf(10) == 2*I\n    assert (Float(2)*I).evalf(10) == 2*I\n\n    assert (Float(1)/I).evalf(10) == -I\n\n    assert (Float(1) + Float(1)*I).evalf(10) == 1 + I\n    assert (Float(1) - Float(1)*I).evalf(10) == 1 - I\n\n    assert (Float"], "sample_129": ["def test_Cycle():\n    p = Cycle(1, 2, 3)\n    assert latex(p) == r\"\\left( 1\\; 2\\; 3 \\right)\"\n    p = Cycle(1, 2, 3, 4)\n    assert latex(p) == r\"\\left( 1\\; 2\\; 3\\; 4 \\right)\"\n", "def test_latex_tensorproduct():\n    from sympy.tensor.array import tensorproduct\n    n = Symbol('n')\n    v = Symbol('v')\n    f = tensorproduct(n, v)\n    assert latex(f) == r\"\\mathbf{n} \\otimes \\mathbf{v}\"\n", "def test_Dict():\n    d = Dict({x: 1, y: 2, z: 3})\n    s = latex(d)\n    assert s == r\"\\left \\{ x : 1, \\  y : 2, \\  z : 3\\right \\}\"\n    d = Dict({1: x, 2: y, 3: z})\n    s = latex(d)\n    assert s == r\"\\left \\{ 1 : x, \\  2 : y, \\  3 : z\\right \\}\"\n", "def test_latex_LatexPrinter():\n    latexprinter = LatexPrinter()\n    assert latexprinter._deal_with_super_sub(\"alpha\") == r\"\\alpha\"\n    assert latexprinter._deal_with_super_sub(\"alphahatdotprime\") == r\"{\\dot{\\hat{\\alpha}}}'\"\n    assert latexprinter._deal_with_super_sub(\"xhat\") == r\"\\hat{x}\"\n    assert latexprinter._deal_with_super_sub(\"xhatdot\") == r\"\\dot{\\hat{x}}\"\n    assert latexprinter._deal_with_super_sub(\"xhatdotdot\") == r\"\\ddot{\\hat{x}}\"\n    assert latexprinter._deal_with_super_sub(\"xhatddot\") == r\"\\ddot{\\hat{x}}\"\n    assert latexprinter._deal_with_super_sub(\"xhatdddot\") == r\"\\dddot{\\hat{x}}\"\n    assert latexprinter._deal_with_super_sub(\"xhatddddot\") == r\"\\ddddot{\\hat{x}}\"\n    assert latexprinter._deal_with_super_sub(\"xhatprime\") == r\"{\\hat{x}}'\"\n    assert latexprinter._deal_with_super_sub(\"xhatprimeprime\") == r\"{\\hat{x}}''\"\n    assert latexprinter._deal_with_super_sub(\"xhatprm\") == r\"{\\hat{x}}'\"\n    assert latexprinter._deal_with_super_sub(\"xhatprmprm\") == r\"{\\hat{x}}''\"\n    assert latexprinter._deal_with_super_sub(\"xhatprmprmprm\") == r\"{\\hat{x}}'''\"\n    assert latexprinter._deal_with_super_sub(\"xhatprmprmprmprm\") == r\"{\\hat{x}}''''\"\n    assert latexprinter._deal_with_super_sub(\"xhatprmprmprmprmprm\") == r\"{\\hat{x}}'''''\"\n    assert latexprinter._deal_with_super_sub(\"xhatprmprmprmprmprmprm\") == r\"{\\hat{x}}''''''\"\n    assert latexprinter._deal_with_super_sub(\"xhatprmprmprmprmprmprmprm\") == r\"{\\hat{x}}''''''\"\n\n    assert latexprinter._hprint_Function(\"cos\") == r\"\\cos\"\n    assert latexprinter._hprint_Function(\"x\") == r\"x\"\n    assert latexprinter._hprint_Function(\"FooBar\") == r\"\\operatorname{FooBar}\"\n\n    assert latexprinter._print_Function(cos(x)) == r\"\\cos{\\left ( x \\right )}\"\n    assert latexprinter._print_Function", "def test_LatexPrinter():\n    # Test inherited notation for the lowergamma function\n    p = LatexPrinter()\n    assert (p._print_Function(lowergamma(x), exp=None) == r'\\gamma\\left(%s\\right)' % p._print(x))\n\n    # Test LaTeX for various classes\n    for func in [S.ImageSet, S.ConditionSet, S.ComplexRegion, S.AccumBounds,\n        S.Complement, S.EmptySet, S.FiniteSet, S.Interval, S.Intersection,\n        S.Naturals, S.Naturals0, S.Integers, S.Reals, S.Complexes, S.Union,\n        S.ProductSet, S.SymmetricDifference, S.Contains]:\n        s = func()\n        latex = LatexPrinter().doprint(s)\n        assert latex != '', func\n        assert '{' in latex and '}' in latex, latex\n\n    # Test latex for DiracDelta\n    expr = DiracDelta(x, y)\n    assert latex(expr) == r\"\\delta^{\\left( y \\right)}\\left( x \\right)\"\n\n    # Test latex for Heaviside\n    assert latex(Heaviside(x)) == r\"\\theta\\left( x \\right)\"\n\n    # Test latex for KroneckerDelta\n    expr = KroneckerDelta(1, 2)\n    assert latex(expr) == r'\\delta_{1, 2}'\n\n    # Test latex for LeviCivita\n    expr = LeviCivita(1, 2, 3)\n    assert latex(expr) == r'\\varepsilon_{1 2 3}'\n\n    # Test latex for SetExpr\n    s = SetExpr(x, y)\n    latex = LatexPrinter().doprint(s)\n    assert latex != '', s\n    assert '{' in latex and '}' in latex, latex\n\n    # Test latex for Cross, Curl and Divergence\n    C = CoordSys3D('C')\n    v1 = C.i + 2*C.j\n    v2 = C.i - C.j\n    v = C.i + C.j + C.k\n\n    assert latex(v1) == r'\\mathbf{i} + 2 \\mathbf{j}'\n\n    assert latex(Cross(v1, v2)) == r'\\mathbf{i} \\times \\left( \\mathbf{i} -  \\mathbf{j} \\"], "sample_70": ["def test_legend_with_fancy_bbox():\n    fig, ax = plt.subplots()\n    line1, = ax.plot([1, 2, 3], label='Line 1')\n    line2, = ax.plot([1, 3, 2], label='Line 2')\n    ax.legend(fancybox=True)\n    return fig\n", "def test_best_position():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], label='Line')\n    ax.add_patch(mpl.patches.Rectangle((0.5, 0.5), 0.1, 0.1, color='blue',\n                                      label='Patch'))\n    ax.legend(loc='best')\n    ax.set_xlim(0, 4)\n    ax.set_ylim(0, 4)\n", "def test_edgecolor_inherit():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], label='test')\n    leg = ax.legend(edgecolor='inherit')\n    assert leg.get_frame().get_edgecolor() == ax.get_edgecolor()\n\n    with rc_context(rc={'axes.edgecolor': 'red'}):\n        fig, ax = plt.subplots()\n        ax.plot([1, 2, 3], label='test')\n        leg = ax.legend(edgecolor='inherit')\n        assert leg.get_frame().get_edgecolor() == 'red'\n\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], label='test')\n    leg = ax.legend(edgecolor='blue')\n    assert leg.get_frame().get_edgecolor() == 'blue'\n\n    with rc_context(rc={'axes.edgecolor': 'red'}):\n        fig, ax = plt.subplots()\n        ax.plot([1, 2, 3], label='test')\n        leg = ax.legend(edgecolor='blue')\n        assert leg.get_frame().get_edgecolor() == 'blue'\n", "def test_draggable_legend():\n    fig, ax = plt.subplots()\n    line1, = ax.plot([1, 2, 3], label='Line 1')\n    line2, = ax.plot([2, 3, 4], label='Line 2')\n    ax.legend([line1, line2], ['Line 1', 'Line 2'], loc='upper right',\n              bbox_to_anchor=(0.8, 0.8), draggable=True)\n\n    # draw the figure, so that the legend is placed\n    fig.canvas.draw()\n\n    # check that the legend is draggable\n    assert ax.legend_.get_draggable() is not None\n\n    # check that the legend's bbox_to_anchor can be updated\n    ax.legend_.set_bbox_to_anchor((0.7, 0.7))\n    fig.canvas.draw()\n    assert ax.legend_.get_bbox_to_anchor().x0 < ax.legend_.get_bbox_to_anchor().x1\n\n    # check that the legend's loc can be updated\n    ax.legend_.set_loc('upper left')\n    fig.canvas.draw()\n    assert ax.legend_.get_loc() == 'upper left'\n\n    # check that the legend can be set to not be draggable\n    ax.legend_.set_draggable(False)\n    assert ax.legend_.get_draggable() is None\n\n    return fig\n", "def test_custom_handler():\n    # Test a custom handler that handles a tuple of handles.\n    class HandlerTupleTest(HandlerTuple):\n            super().__init__(**kwargs)\n            self._default_handler_map = {\n                tuple: HandlerTupleTest(),\n                mlines.Line2D: mlegend.HandlerLine2D(),\n                mcollections.PatchCollection: mlegend.HandlerPatchCollection()\n            }\n\n                           xdescent, ydescent, width, height, fontsize,\n                           trans):\n            artists = []\n            for handle in orig_handle:\n                handler = self.get_legend_handler(\n                    self._default_handler_map, handle)\n                a_list = handler.create_artists(legend, handle,\n                                                xdescent, ydescent, width,\n                                                height, fontsize, trans)\n                artists.extend(a_list)\n            return artists\n\n    # Create a figure and axis.\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [1, 2], 'bo', label='Line1')\n    collection = ax.scatter([3, 4], [3, 4], label='Scatter1')\n    ax.plot([5, 6], [5, 6], label='Line2')\n\n    # Create a tuple of handles and labels.\n    handles = (ax.lines[0], collection)\n    labels = ['Line1', 'Scatter1']\n\n    # Create a legend with the custom handler.\n    with rc_context({'legend.fancybox': False,\n                     'legend.edgecolor': 'black'}):\n        ax.legend(handles, labels, handler_map={tuple: HandlerTupleTest()},\n                  loc='upper center', bbox_to_anchor=(0.5, -0.2),\n                  ncol=2, framealpha=1, fontsize='medium')\n\n    # Set limits to avoid clipping.\n    ax.set_xlim([0, 7])\n    ax.set_ylim([0, 7])\n"], "sample_3": ["def test_is_separable():\n    # Test the is_separable function with various models\n    assert np.allclose(is_separable(sh1 & sh2 | scl1 & scl2),\n                       np.array([True, True]))\n    assert np.allclose(is_separable(sh1 & sh2 | rot),\n                       np.array([False, False]))\n    assert np.allclose(is_separable(sh1 & sh2 | map1 | p2 & p22),\n                       np.array([False, False]))\n    assert np.allclose(is_separable(sh1 & sh2 | map1),\n                       np.array([True, True, True, True]))\n", "def test_separable():\n    assert is_separable(sh1 & sh2) == np.array([True, True])\n    assert separability_matrix(sh1 & sh2) == np.array([[True, False], [False, True]])\n    assert is_separable(scl1 & scl2) == np.array([True, True])\n    assert separability_matrix(scl1 & scl2) == np.array([[True, False], [False, True]])\n    assert is_separable(rot) == np.array([False, False])\n    assert separability_matrix(rot) == np.array([[True, True], [True, True]])\n    assert is_separable(p1) == np.array([True])\n    assert separability_matrix(p1) == np.array([[True]])\n    assert is_separable(p2) == np.array([True, True])\n    assert separability_matrix(p2) == np.array([[True, False], [False, True]])\n", "def test_coord_matrix():\n    # Test _coord_matrix for simple models\n    assert np.allclose(_coord_matrix(sh1, 'left', sh1.n_outputs),\n                       np.array([[1]]))\n    assert np.allclose(_coord_matrix(scl1, 'left', scl1.n_outputs),\n                       np.array([[1]]))\n    assert np.allclose(_coord_matrix(map3, 'left', map3.n_outputs),\n                       np.array([[1, 0], [0, 1]]))\n    assert np.allclose(_coord_matrix(rot, 'left', rot.n_outputs),\n                       np.array([[1, 1]]))\n\n    # Test _coord_matrix for compound models\n    cm = sh1 & sh2\n    assert np.allclose(_coord_matrix(cm, 'left', cm.n_outputs),\n                       np.array([[1, 0], [0, 1]]))\n\n    cm = sh1 | scl1\n    assert np.allclose(_coord_matrix(cm, 'left', cm.n_outputs),\n                       np.array([[1, 1]]))\n\n    # Test _coord_matrix for mapping model\n    assert np.allclose(_coord_matrix(map1, 'left', map1.n_outputs),\n                       np.array([[1, 0, 1, 0], [0, 1, 0, 1]]))\n", "def test_separable():\n    @custom_model\n        return x + y\n\n    cm = custom_model()\n\n    is_sep = is_separable(cm)\n    sep_mat = separability_matrix(cm)\n\n    assert np.all(is_sep == np.array([False]))\n    assert np.all(sep_mat == np.array([[True, True]]))\n", "def test_separability_matrix():\n    # Test that separability_matrix returns the expected results\n    for name, (model, expected) in compound_models.items():\n        is_sep, sep_matrix = expected\n        result = separability_matrix(model)\n        assert_allclose(result, sep_matrix)\n"], "sample_157": ["def test_tensor_product_simp():\n    e = TP(A, B) * TP(C, D)\n    assert tensor_product_simp(e) == TP(A * C, B * D)\n    e = (TP(A, B) * TP(C, D)) ** 2\n    assert tensor_product_simp(e) == TP(A * C, B * D) ** 2\n    e = TP(A, B) + TP(C, D)\n    assert tensor_product_simp(e) == TP(A, B) + TP(C, D)\n    e = Comm(TP(A, B), TP(C, D))\n    assert tensor_product_simp(e) == Comm(TP(A * C, B * D), TP(A * D, B * C))\n", "def test_tensor_product_simp():\n    # Test tensor product simplification with qubits\n    assert tensor_product_simp(TensorProduct(Qubit(0), Qubit(1)) * TensorProduct(Qubit(0), Qubit(1))) == TensorProduct(Qubit(0)**2, Qubit(1)**2)\n    \n    # Test tensor product simplification with operators\n    op1 = OuterProduct(QubitBra(0), Qubit(0))\n    op2 = OuterProduct(QubitBra(1), Qubit(1))\n    assert tensor_product_simp(TensorProduct(op1, op2) * TensorProduct(op1, op2)) == TensorProduct(op1**2, op2**2)\n    \n    # Test tensor product simplification with mixed states\n    mixed_state1 = Density(Qubit(0))\n    mixed_state2 = Density(Qubit(1))\n    assert tensor_product_simp(TensorProduct(mixed_state1, mixed_state2) * TensorProduct(mixed_state1, mixed_state2)) == TensorProduct(mixed_state1**2, mixed_state2**2)\n    \n    # Test tensor product simplification with mixed operators and states\n    assert tensor_product_simp(TensorProduct(op1, mixed_state2) * TensorProduct(op1, mixed_state2)) == TensorProduct(op1**2, mixed_state2**2)\n", "def test_tensor_product_simp_Mul():\n    # Test that the function works for a Mul of TensorProducts\n    e = TP(A, B) * TP(C, D)\n    assert tensor_product_simp_Mul(e) == TP(A*C, B*D)\n\n    # Test that the function works for a Mul of TensorProducts and scalars\n    e = 2 * TP(A, B) * TP(C, D)\n    assert tensor_product_simp_Mul(e) == 2 * TP(A*C, B*D)\n\n    # Test that the function works for a Mul of TensorProducts with multiple scalars\n    e = 2 * TP(A, B) * 3 * TP(C, D)\n    assert tensor_product_simp_Mul(e) == 6 * TP(A*C, B*D)\n\n    # Test that the function works for a Mul of TensorProducts and other non-commutative symbols\n    e = TP(A, B) * C * TP(D, E)\n    assert tensor_product_simp_Mul(e) == TP(A*D*C, B*E)\n", "def test_tensor_product_simp():\n    assert tensor_product_simp(TP(A, B)*TP(C, D)) == TP(A*C, B*D)\n    assert tensor_product_simp(TP(A, B)*TP(C, D)**2) == TP(A*C**2, B*D**2)\n    assert tensor_product_simp(Comm(TP(A, B), TP(C, D))) == Comm(TP(A*C, B*D), TP(I, I))\n    assert tensor_product_simp(Comm(TP(A, B), TP(C, D)**2)) == Comm(TP(A*C**2, B*D**2), TP(I, I))\n    assert tensor_product_simp(A*TP(B, C)) == TP(A*B, C)\n    assert tensor_product_simp(TP(A, B)*C) == TP(A*C, B)\n    assert tensor_product_simp(A*TP(B, C)*D) == TP(A*B*D, C)\n    assert tensor_product_simp(Comm(TP(A, B), TP(C, D)*E)) == Comm(TP(A*C*E, B*D*E), TP(I, I))\n    assert tensor_product_simp(Comm(TP(A, B), TP(C, D)**2*E)) == Comm(TP(A*C**2*E, B*D**2*E), TP(I, I))\n    assert tensor_product_simp(TP(A+B, C)*TP(D, E)) == TP((A+B)*D, C*E)\n    assert tensor_product_simp(TP(A, B)*TP(C+D, E)) == TP(A*(C+D), B*E)\n    assert tensor_product_simp(TP(A+B, C+D)*TP(E, F)) == TP((A+B)*E, (C+D)*F)\n", "def test_tensor_product_simp_Mul():\n    # Test simplification of a Mul of TensorProducts\n    tp1 = TensorProduct(A, B)\n    tp2 = TensorProduct(C, D)\n    expr = tp1 * tp2\n    assert expr == AxB*CxD\n    assert tensor_product_simp_Mul(expr) == (A*C)x(B*D)\n\n    # Test simplification of a Mul of TensorProducts with scalars\n    expr = 2 * tp1 * tp2\n    assert tensor_product_simp_Mul(expr) == 2*((A*C)x(B*D))\n\n    # Test simplification of a Mul of TensorProducts with powers\n    expr = (tp1 * tp2) ** 2\n    assert tensor_product_simp_Mul(expr) == ((A*C)x(B*D))**2\n"], "sample_139": ["def test_polar_lift():\n    x = Symbol('x')\n    p = Symbol('p', polar=True)\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(I + 2) == polar_lift(2 + I)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*p) == 4*p\n", "def test_polar_lift():\n    from sympy import Symbol, polar_lift, I, pi\n    p = Symbol('p', polar=True)\n    x = Symbol('x')\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(I + 2) == polar_lift(2 + I)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*p) == 4*p\n", "def test_polar_lift():\n    x = Symbol('x', real=True)\n    p = Symbol('p', polar=True)\n    z = Symbol('z', polar=True)\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(I + 2) == polar_lift(2 + I)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*p) == 4*p\n    assert polar_lift(x) == polar_lift(x)  # issue 4907\n    assert polar_lift(z) == z\n    assert polar_lift(0) == 0\n    assert polar_lift(1) == 1\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(I*pi/2)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(exp_polar(pi*I)) == exp_polar(pi*I)\n    assert polar_lift(exp_polar(pi*I)*3) == 3*exp_polar(pi*I)\n    assert polar_lift(pi) == pi*exp_polar(0)\n    assert polar_lift(-pi) == pi*exp_polar(I*pi)\n    assert polar_lift(pi*I) == exp_polar(I*pi/2)*pi\n    assert polar_lift(-pi*I) == exp_polar(-I*pi/2)*pi\n", "def test_re():\n    x = Symbol('x', real=True)\n    assert re(x + I) == x\n    assert re(2*I) == 0\n    assert re(-I) == 0\n    assert re(5) == 5\n", "def test_polar_lift():\n    x = Symbol('x', real=True)\n    y = Symbol('y', positive=True)\n    p = Symbol('p', polar=True)\n    z = Symbol('z', complex=True)\n\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(I + 2) == polar_lift(2 + I)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*p) == 4*p\n    assert polar_lift(x) == polar_lift(x)\n    assert polar_lift(y) == y\n    assert polar_lift(z) == polar_lift(z)\n\n    assert unpolarify(polar_lift(1 + I)) == (1 + I)\n    assert unpolarify(polar_lift(x)) == x\n    assert unpolarify(polar_lift(4*x)) == (4*x)\n    assert unpolarify(polar_lift(-x)) == -x\n    assert unpolarify(polar_lift(x + 2)) == (x + 2)\n    assert unpolarify(polar_lift(I + x)) == (I + x)\n\n    assert polarify(1 + I, subs=True, lift=False) == ((1 + I), {})\n    assert polarify(x, subs=True, lift=False) == ((x), {})\n    assert polarify(4*x, subs=True, lift=False) == ((4*x), {})\n    assert polarify(-x, subs=True, lift=False) == ((-_x*exp_polar(I*pi)), {_x: x})\n    assert polarify(x + 2, subs=True, lift=False) == ((x + 2), {})\n    assert polarify(I + x, subs=True, lift=False) == ((I + x), {})\n\n    assert polarify(1 + I, subs=True, lift=True) == ((1 + I), {})\n    assert polarify(x, subs=True, lift=True) == (polar_lift(x), {})\n    assert polarify(4*x, subs=True, lift=True) == (4*polar_lift(x), {})\n    assert polarify(-x, subs=True, lift=True) == (polar_lift(-x), {})\n    assert polarify(x + 2, subs=True, lift"], "sample_95": ["def test_pyfunc_call_async(testdir):\n    \"\"\"Test that async functions are properly skipped.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import asyncio\n\n        @pytest.mark.asyncio\n        async def test_async_function():\n            assert 1\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\"*async def functions are not natively supported and have been skipped.*\"]\n    )\n", "    def test_function_repr_failure(self, pytester: Pytester) -> None:\n        test_file = textwrap.dedent(\n            \"\"\"\n            import pytest\n\n                x = 1 / 0\n        \"\"\"\n        )\n        pytester.makepyfile(test_file)\n        result = pytester.runpytest()\n        result.assert_outcomes(passed=0, failed=1)\n        result.stdout.fnmatch_lines([\"*ZeroDivisionError: division by zero*\"])\n        assert (\n            \"def test_foo():\" in result.stdout.lines\n        ), \"function definition should be included in failure message\"\n", "def test_parametrize_ids_with_bytes_values(testdir):\n    \"\"\"Test that parametrize ids with bytes values are handled correctly.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"arg1\", [b\"bytes_value1\", b\"bytes_value2\"], ids=[\"id1\", \"id2\"])\n            assert arg1 in [b\"bytes_value1\", b\"bytes_value2\"]\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.assert_outcomes(passed=2)\n", "def test_parametrize_id_function(tmp_path, pytestconfig):\n    \"\"\"Test that the pytest_make_parametrize_id hook can be used to customize parametrize ids.\n\n    See https://docs.pytest.org/en/stable/customize.html#pytest-make-parametrize-id\n    \"\"\"\n    pytestconfig.cache.set(\"parametrize_ids\", [1, 2, 3])\n    test_file = tmp_path / \"test_parametrize_id.py\"\n    test_file.write_text(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n\n            pytest_plugins = [\"custom\"]\n\n            @pytest.mark.parametrize(\"x\", [1, 2, 3], ids=lambda x: str(x * 2))\n                pass\n            \"\"\"\n        )\n    )\n\n    # Create a conftest.py file with the custom hook\n    conftest_file = tmp_path / \"conftest.py\"\n    conftest_file.write_text(\n        textwrap.dedent(\n            \"\"\"\\\n                ids = config.cache.get(\"parametrize_ids\", [])\n                return str(ids[len(ids) - 1])\n            \"\"\"\n        )\n    )\n\n    result = pytest.main([str(test_file), \"-v\"])\n    assert result == 0\n    result.assert_outcomes(passed=3)\n", "    def test_repr_failure_short_style(self, pytestconfig):\n        test_code = \"\"\"\n                assert 1 == 1\n        \"\"\"\n        run_node = pytestconfig.getini(\"addopts\")\n        if \"-vv\" not in run_node:\n            run_node.append(\"-vv\")\n\n            1 / 0\n\n        myfunc()\n        result = pytestconfig.hook.pytest_runtest_makereport(item=None, call=myfunc)\n        result = runtestprotocol.PytestReprFailureResult.fromrepr(result)\n        result.reprcrash.style = \"short\"\n        result.reprcrash.message = \"Traceback (most recent call last):\"\n        result.reprcrash.path = \"/path/to/test_file.py\"\n        result.reprcrash.lineno = 1\n        result.reprcrash.msg = \"division by zero\"\n\n            return result\n\n        with pytest.monkeypatch.context() as mp:\n            mp.setattr(Function, \"repr_failure\", fake_repr_failure)\n            testdir = Pytester()\n            testdir.makepyfile(test_code)\n            result = testdir.runpytest()\n            assert \"division by zero\" in result.stdout.str()\n"], "sample_44": ["    def test_ModelChoiceIterator(self):\n        field = forms.ModelChoiceField(queryset=Category.objects.all())\n        iterator = ModelChoiceIterator(field)\n        self.assertEqual(len(iterator), 3)\n        choices = list(iterator)\n        self.assertEqual(choices[0][0].value, self.c1.pk)\n        self.assertEqual(choices[0][1], str(self.c1))\n        self.assertEqual(choices[1][0].value, self.c2.pk)\n        self.assertEqual(choices[1][1], str(self.c2))\n        self.assertEqual(choices[2][0].value, self.c3.pk)\n        self.assertEqual(choices[2][1], str(self.c3))\n\n        field = forms.ModelChoiceField(queryset=Category.objects.all(), empty_label=\"Select\")\n        iterator = ModelChoiceIterator(field)\n        self.assertEqual(len(iterator), 4)\n        choices = list(iterator)\n        self.assertEqual(choices[0][0], \"\")\n        self.assertEqual(choices[0][1], \"Select\")\n        self.assertEqual(choices[1][0].value, self.c1.pk)\n        self.assertEqual(choices[1][1], str(self.c1))\n        self.assertEqual(choices[2][0].value, self.c2.pk)\n        self.assertEqual(choices[2][1], str(self.c2))\n        self.assertEqual(choices[3][0].value, self.c3.pk)\n        self.assertEqual(choices[3][1], str(self.c3))\n\n        field = forms.ModelChoiceField(queryset=Category.objects.none())\n        iterator = ModelChoiceIterator(field)\n        self.assertEqual(len(iterator), 0)\n        choices = list(iterator)\n        self.assertEqual(choices, [])\n\n        field = forms.ModelChoiceField(queryset=Category.objects.none(), empty_label=\"Select\")\n        iterator = ModelChoiceIterator(field)\n        self.assertEqual(len(iterator), 1)\n        choices = list(iterator)\n        self.assertEqual(choices[0][0], \"\")\n        self.assertEqual(choices[0][1], \"Select\")\n\n        field = forms.ModelChoiceField(queryset=Category.objects.all(), to_field_name='name')\n        iterator = ModelChoiceIterator(field)\n        self.assertEqual(len(iterator), 3)\n        choices = list(iterator)\n        self.assertEqual(choices[0][0].value, self.c1.name)\n        self.assertEqual(choices[0][1], str(self.c1))\n        self.assertEqual(choices[1][0].value, self.c2.name)\n        self.assertEqual(choices[1][1], str(self.c2))\n        self.assertEqual(choices[2][0].value", "    def setUpTestData(cls):\n        cls.a1 = Author.objects.create(name='John')\n        cls.a2 = Author.objects.create(name='Jane')\n        cls.a3 = Author.objects.create(name='Jim')\n", "    def test_model_multiple_choice_field(self):\n        class CategoryForm(forms.Form):\n            categories = forms.ModelMultipleChoiceField(Category.objects.all())\n\n        form = CategoryForm({'categories': [self.c1.pk, self.c2.pk]})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(len(form.cleaned_data['categories']), 2)\n        self.assertEqual(form.cleaned_data['categories'][0].pk, self.c1.pk)\n        self.assertEqual(form.cleaned_data['categories'][1].pk, self.c2.pk)\n\n        form = CategoryForm({'categories': [self.c1.pk, self.c3.pk, 'invalid']})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(len(form.errors), 1)\n\n        form = CategoryForm({'categories': ['invalid']})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(len(form.errors), 1)\n\n        form = CategoryForm({'categories': [self.c1.pk]})\n        form.fields['categories'].widget = CheckboxSelectMultiple()\n        form.fields['categories'].queryset = Category.objects.filter(name='Invalid')\n        self.assertFalse(form.is_valid())\n        self.assertEqual(len(form.errors), 1)\n\n        form = CategoryForm({'categories': [self.c1.pk]})\n        form.fields['categories'].queryset = Category.objects.filter(name='Entertainment')\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['categories'][0].pk, self.c1.pk)\n\n        # Test limit_choices_to\n        class CategoryForm(forms.Form):\n            categories = forms.ModelMultipleChoiceField(Category.objects.all(), limit_choices_to={'name': 'Entertainment'})\n\n        form = CategoryForm({'categories': [self.c1.pk]})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['categories'][0].pk, self.c1.pk)\n\n        form = CategoryForm({'categories': [self.c2.pk]})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(len(form.errors), 1)\n\n        # Test limit_choices_to callable\n            return {'name': 'Entertainment'}\n\n        class CategoryForm(forms.Form):\n            categories = forms.ModelMultipleChoiceField(Category.objects.all(), limit_choices_to=limit_choices)\n\n        form = CategoryForm({'categories': [self.c1.pk]})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['categories'][0].pk, self.c1.pk)\n\n        form = CategoryForm({'categories': [self.c2.pk]})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(len(form.errors), ", "    def test_model_choice_field_multiple_choice(self):\n        class TestForm(forms.Form):\n            categories = forms.ModelMultipleChoiceField(\n                queryset=Category.objects.all(),\n                widget=CheckboxSelectMultiple,\n            )\n\n        form = TestForm(data={'categories': [self.c1.pk, self.c2.pk]})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['categories'].count(), 2)\n\n        form = TestForm(data={'categories': [self.c1.pk, self.c2.pk, '1000']})\n        self.assertFalse(form.is_valid())\n\n        form = TestForm(data={})\n        self.assertFalse(form.is_valid())\n\n        # Test that field does not fail with multiple=False\n        form = TestForm(data={'categories': self.c1.pk})\n        self.assertFalse(form.is_valid())\n\n        class TestForm(forms.Form):\n            categories = forms.ModelMultipleChoiceField(\n                queryset=Category.objects.all(),\n                widget=CheckboxSelectMultiple,\n                multiple=False,\n            )\n\n        form = TestForm(data={'categories': self.c1.pk})\n        self.assertFalse(form.is_valid())\n\n        class TestForm(forms.Form):\n            categories = forms.ModelMultipleChoiceField(\n                queryset=Category.objects.all(),\n                widget=forms.SelectMultiple,\n            )\n\n        form = TestForm(data={'categories': [self.c1.pk, self.c2.pk]})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['categories'].count(), 2)\n", "def test_modelchoiceiterator(self):\n    class FakeField:\n        queryset = Category.objects.all()\n        empty_label = None\n\n    iterator = ModelChoiceIterator(FakeField())\n    self.assertEqual(len(iterator), 3)\n\n    template = Template(\"{{ iterator|length }}\")\n    self.assertEqual(template.render(Context({'iterator': iterator})), \"3\")\n\n    # Test iterator is not consumed by len()\n    self.assertEqual(len(iterator), 3)\n\n    # Test iterator is consumed by iterating over it\n    iterated = list(iterator)\n    self.assertEqual(len(iterated), 3)\n    self.assertIsInstance(iterated[0][0], ModelChoiceIteratorValue)\n    self.assertIsInstance(iterated[0][1], str)\n\n    # Test iterator is re-evaluated on subsequent iterations\n    Category.objects.create(name='New Category', slug='new-category', url='new-category')\n    self.assertEqual(len(iterator), 4)\n\n    # Test iterator is re-evaluated if queryset is None\n    FakeField.queryset = None\n    iterator = ModelChoiceIterator(FakeField())\n    self.assertEqual(len(iterator), 0)\n\n    # Test boolean conversion\n    FakeField.queryset = Category.objects.none()\n    iterator = ModelChoiceIterator(FakeField())\n    self.assertFalse(iterator)\n    FakeField.queryset = Category.objects.all()\n    iterator = ModelChoiceIterator(FakeField())\n    self.assertTrue(iterator)\n"], "sample_76": ["def test_polyfit_call(self, df):\n    \"\"\"Test that PolyFit.__call__ returns a DataFrame with the correct shape.\"\"\"\n    polyfit = PolyFit()\n    result = polyfit(df, by=\"group\", orient=None, scales=None)\n    assert isinstance(result, pd.DataFrame)\n    assert result.shape == (2 * polyfit.gridsize, 2)\n", "    def test_polyfit(self, df, order):\n\n        fit = PolyFit(order=order)\n        result = fit(df, \"group\", \"x\", {\"x\": \"linear\", \"y\": \"linear\"})\n\n        assert len(result) == len(df[\"group\"].unique()) * fit.gridsize\n        assert result[\"x\"].notna().all()\n        assert result[\"y\"].notna().all()\n", "    def test_polyfit(self, df, order):\n        \"\"\"Test that PolyFit works with different polynomial orders.\"\"\"\n        fit = PolyFit(order=order)\n        res = fit(df, GroupBy(column=\"color\"), orient=None, scales=None)\n        assert len(res) == len(df[\"color\"].unique())\n        for _, group in res.items():\n            assert len(group) == fit.gridsize\n", "    def test_polyfit_linear(self, df):\n        \"\"\"Test PolyFit with linear data.\"\"\"\n        df[\"y\"] = df[\"x\"]\n\n        result = PolyFit()(df, GroupBy(columns=[\"color\"]), None, None)\n        expected = pd.DataFrame({\n            \"x\": np.linspace(df[\"x\"].min(), df[\"x\"].max(), 100),\n            \"y\": np.linspace(df[\"x\"].min(), df[\"x\"].max(), 100),\n        })\n        expected[\"group\"] = \"color\"\n        expected = pd.concat([expected.assign(group=c) for c in df[\"color\"].unique()])\n        assert_frame_equal(result, expected)\n\n", "    def test_polyfit_single_group(self, df):\n        \"\"\"Test that PolyFit works with a single group.\"\"\"\n        stat = PolyFit()\n        fit_df = stat(df, GroupBy(columns=\"color\"), \"x\", \"y\")\n\n        assert len(fit_df) == len(df[\"color\"].unique()) * stat.gridsize\n        assert fit_df.columns.tolist() == [\"color\", \"x\", \"y\"]\n"], "sample_24": ["    def test_hash_with_error_dict(self, mock_attrgetter):\n        error_dict = {'field1': ['error1', 'error2'], 'field2': ['error3']}\n        validation_error = ValidationError(error_dict)\n        validation_error.__hash__()\n        mock_attrgetter.assert_called_once_with('message')\n", "    def test_hashable_validation_error(self):\n        error1 = ValidationError('Error message', code='error_code', params={'param': 'value'})\n        error2 = ValidationError('Error message', code='error_code', params={'param': 'value'})\n\n        self.assertEqual(hash(error1), hash(error2))\n\n        error3 = ValidationError('Error message', code='error_code', params={'param': 'different_value'})\n        self.assertNotEqual(hash(error1), hash(error3))\n", "    def test_validation_error_init_message_as_list(self):\n        error_list = ['error1', 'error2']\n        validation_error = ValidationError(error_list)\n        self.assertEqual(len(validation_error.error_list), 2)\n        self.assertEqual(validation_error.error_list[0].message, 'error1')\n        self.assertEqual(validation_error.error_list[1].message, 'error2')\n", "def test_error_dict_property(self):\n    # Create a ValidationError with an error_dict\n    error_dict = {'field1': ['Error 1', 'Error 2'], 'field2': ['Error 3']}\n    validation_error = ValidationError(error_dict)\n\n    # Check that the error_dict property returns the correct dictionary\n    self.assertEqual(validation_error.message_dict, error_dict)\n\n    # Create a ValidationError without an error_dict\n    validation_error = ValidationError('Error message')\n\n    # Check that accessing the error_dict property raises an AttributeError\n    with self.assertRaises(AttributeError):\n        validation_error.message_dict\n", "def test_validation_error_eq_hash(self):\n    error1 = ValidationError('Error message', code='error_code')\n    error2 = ValidationError('Error message', code='error_code')\n    error3 = ValidationError('Different error message', code='error_code')\n    self.assertEqual(hash(error1), hash(error2))\n    self.assertNotEqual(hash(error1), hash(error3))\n\n    error_dict1 = ValidationError({'field1': 'Error message'}, code='error_code')\n    error_dict2 = ValidationError({'field1': 'Error message'}, code='error_code')\n    error_dict3 = ValidationError({'field2': 'Error message'}, code='error_code')\n    self.assertEqual(hash(error_dict1), hash(error_dict2))\n    self.assertNotEqual(hash(error_dict1), hash(error_dict3))\n\n    error_list1 = ValidationError(['Error message1', 'Error message2'], code='error_code')\n    error_list2 = ValidationError(['Error message1', 'Error message2'], code='error_code')\n    error_list3 = ValidationError(['Error message1', 'Different error message'], code='error_code')\n    self.assertEqual(hash(error_list1), hash(error_list2))\n    self.assertNotEqual(hash(error_list1), hash(error_list3))\n"], "sample_36": ["def test_q_or(self):\n    q1 = Q(a=1)\n    q2 = Q(b=2)\n    q3 = q1 | q2\n    self.assertIsInstance(q3, Q)\n    self.assertEqual(q3.connector, Q.OR)\n    self.assertEqual(len(q3.children), 2)\n    self.assertEqual(q3.children[0], q1)\n    self.assertEqual(q3.children[1], q2)\n", "def test_q_negation(self):\n    q1 = Q(foo='bar')\n    q2 = ~q1\n    self.assertEqual(q2.connector, Q.AND)\n    self.assertEqual(q2.negated, True)\n    self.assertEqual(q2.children, [q1])\n", "def test_q_combine(self):\n    q1 = Q(a=1)\n    q2 = Q(b=2)\n    q_combined = q1 & q2\n    self.assertEqual(q_combined.connector, Q.AND)\n    self.assertEqual(q_combined.children, [(q1,), (q2,)])\n\n    q_combined = q1 | q2\n    self.assertEqual(q_combined.connector, Q.OR)\n    self.assertEqual(q_combined.children, [(q1,), (q2,)])\n\n    q_empty = Q()\n    q_combined = q1 & q_empty\n    self.assertEqual(q_combined.connector, Q.AND)\n    self.assertEqual(q_combined.children, [(q1,)])\n\n    q_combined = q_empty & q1\n    self.assertEqual(q_combined.connector, Q.AND)\n    self.assertEqual(q_combined.children, [(q1,)])\n\n    q_combined = q1 | q_empty\n    self.assertEqual(q_combined.connector, Q.OR)\n    self.assertEqual(q_combined.children, [(q1,)])\n\n    q_combined = q_empty | q1\n    self.assertEqual(q_combined.connector, Q.OR)\n    self.assertEqual(q_combined.children, [(q1,)])\n\n    q_combined = ~q1\n    self.assertEqual(q_combined.connector, Q.AND)\n    self.assertEqual(q_combined.negated, True)\n    self.assertEqual(q_combined.children, [(q1,)])\n\n    q_combined = ~(q1 & q2)\n    self.assertEqual(q_combined.connector, Q.OR)\n    self.assertEqual(q_combined.negated, True)\n    self.assertEqual(q_combined.children, [(q1,), (q2,)])\n\n    q_combined = ~(q1 | q2)\n    self.assertEqual(q_combined.connector, Q.AND)\n    self.assertEqual(q_combined.negated, True)\n    self.assertEqual(q_combined.children, [(q1,), (q2,)])\n", "    def test_q_combination(self):\n        q1 = Q(age__gt=20)\n        q2 = Q(age__lt=30)\n        combined_q = q1 & q2\n\n        self.assertIsInstance(combined_q, Q)\n        self.assertEqual(combined_q.connector, Q.AND)\n        self.assertEqual(len(combined_q.children), 2)\n        self.assertEqual(combined_q.children[0], ('age__gt', 20))\n        self.assertEqual(combined_q.children[1], ('age__lt', 30))\n\n        q3 = ~Q(age__gt=20)\n        self.assertIsInstance(q3, Q)\n        self.assertTrue(q3.negated)\n        self.assertEqual(q3.connector, Q.AND)\n        self.assertEqual(len(q3.children), 1)\n        self.assertEqual(q3.children[0], ('age__gt', 20))\n\n        q4 = Q()\n        q5 = q1 & q4\n        self.assertEqual(q5, q1)\n\n        q6 = q4 & q1\n        self.assertEqual(q6, q1)\n", "def test_q_or(self):\n    q1 = Q(name='John')\n    q2 = Q(age=30)\n    q_or = q1 | q2\n    self.assertEqual(q_or.connector, Q.OR)\n    self.assertEqual(len(q_or.children), 2)\n    self.assertIn(q1, q_or.children)\n    self.assertIn(q2, q_or.children)\n"], "sample_67": ["def test_enum_serialization(self):\n    # Test Text Enum\n    enum_value = TextEnum.A\n    expected_output = (\"TextEnum.A\", set())\n    serializer = serializer_factory(enum_value)\n    self.assertEqual(serializer.serialize(), expected_output)\n\n    # Test Text Translated Enum\n    enum_value = TextTranslatedEnum.A\n    expected_output = (\"TextTranslatedEnum.A\", set())\n    serializer = serializer_factory(enum_value)\n    self.assertEqual(serializer.serialize(), expected_output)\n\n    # Test Binary Enum\n    enum_value = BinaryEnum.A\n    expected_output = (\"BinaryEnum.A\", set())\n    serializer = serializer_factory(enum_value)\n    self.assertEqual(serializer.serialize(), expected_output)\n\n    # Test Int Enum\n    enum_value = IntEnum.A\n    expected_output = (\"IntEnum.A\", set())\n    serializer = serializer_factory(enum_value)\n    self.assertEqual(serializer.serialize(), expected_output)\n\n    # Test Int Flag Enum\n    enum_value = IntFlagEnum.A | IntFlagEnum.B\n    expected_output = (\"IntFlagEnum.A | IntFlagEnum.B\", set())\n    serializer = serializer_factory(enum_value)\n    self.assertEqual(serializer.serialize(), expected_output)\n", "    def test_functools_partial(self):\n            return a + b\n\n        partial = functools.partial(add, 1)\n        serializer = serializer_factory(partial)\n        serialized, imports = serializer.serialize()\n        self.assertEqual(serialized, \"functools.partial(add, 1)\")\n        self.assertEqual(imports, {\"import functools\"})\n", "    def test_settings_reference(self):\n        ref = SettingsReference(\"SECRET_KEY\", \"default\")\n        serializer = serializer_factory(ref)\n        self.assertIsInstance(serializer, SettingsReferenceSerializer)\n        serialized, imports = serializer.serialize()\n        self.assertEqual(serialized, \"settings.SECRET_KEY\")\n        self.assertEqual(imports, {\"from django.conf import settings\"})\n", "    def test_register_unregister_serializer(self):\n        class TestSerializer(BaseSerializer):\n                return \"serialized\", set()\n\n        Serializer.register(int, TestSerializer)\n        self.assertEqual(Serializer._registry[int], TestSerializer)\n        Serializer.unregister(int)\n        with self.assertRaises(ValueError):\n            serializer_factory(1)\n", "    def test_serializer_factory_for_models_Field(self):\n        field = models.IntegerField()\n        serializer = serializer_factory(field)\n        self.assertIsInstance(serializer, ModelFieldSerializer)\n"], "sample_5": ["    def test_collector_can_fast_delete(self):\n        collector = Collector(using='default')\n        qs = A.objects.all()\n        self.assertTrue(collector.can_fast_delete(qs))\n\n        qs = A.objects.all().select_related('r')\n        self.assertFalse(collector.can_fast_delete(qs))\n\n        a = A.objects.create()\n        self.assertTrue(collector.can_fast_delete(a))\n\n        collector.add_field_update(A._meta.get_field('r'), None, [a])\n        self.assertFalse(collector.can_fast_delete(a))\n\n        signals.post_delete.connect(lambda **kwargs: None, sender=A)\n        self.assertFalse(collector.can_fast_delete(a))\n        signals.post_delete.disconnect(lambda **kwargs: None, sender=A)\n\n        a.r = create_a()\n        self.assertFalse(collector.can_fast_delete(a))\n", "def test_collector_get_del_batches(self):\n    collector = Collector(using=connection.alias)\n    batch_size = ceil(GET_ITERATOR_CHUNK_SIZE / 2)\n    r = R()\n    batches = collector.get_del_batches([r] * batch_size, R._meta.get_field('id'))\n    self.assertEqual(len(batches), 1)\n    batches = collector.get_del_batches([r] * (batch_size + 1), R._meta.get_field('id'))\n    self.assertEqual(len(batches), 2)\n", "    def test_collector_add_field_update(self):\n        # Create a new collector\n        collector = Collector(using='default')\n\n        # Create some objects\n        obj1 = R()\n        obj2 = R()\n        obj3 = R()\n\n        # Create a field and value\n        field = R._meta.get_field('id')\n        value = 10\n\n        # Add the field update\n        collector.add_field_update(field, value, [obj1, obj2, obj3])\n\n        # Check that the field update is added correctly\n        self.assertEqual(collector.field_updates, {R: {(field, value): {obj1, obj2, obj3}}})\n\n        # Add the same field update again\n        collector.add_field_update(field, value, [obj1, obj2])\n\n        # Check that the field update is updated correctly\n        self.assertEqual(collector.field_updates, {R: {(field, value): {obj1, obj2, obj3}}})\n", "    def test_collector_add_field_update(self):\n        collector = Collector(using='default')\n        field = models.Field(name='test_field')\n        objs = [A(), A()]\n        collector.add_field_update(field, 'test_value', objs)\n        self.assertEqual(collector.field_updates, {A: {('test_field', 'test_value'): {objs[0], objs[1]}}})\n", "    def test_delete_in_transaction(self):\n        \"\"\"\n        Deleting a model in a transaction should only send signals and delete\n        the objects when the transaction is committed.\n        \"\"\"\n        with transaction.atomic():\n            create_a()\n            a = A.objects.get()\n            a.delete()\n\n        self.assertEqual(A.objects.count(), 0)\n\n        with transaction.atomic():\n            create_a()\n            a = A.objects.get()\n            transaction.set_rollback(True)\n            a.delete()\n\n        self.assertEqual(A.objects.count(), 1)\n"], "sample_98": ["def test_check_non_negative():\n    # Test check_non_negative with numpy arrays\n    assert_raises_regex(ValueError, \"Negative values in data passed to .*\",\n                        check_non_negative, np.array([-1, 2, 3]), \"some_func\")\n    assert_no_warnings(check_non_negative, np.array([1, 2, 3]), \"some_func\")\n\n    # Test check_non_negative with scipy sparse matrices\n    sparse_matrix = sp.csr_matrix([-1, 2, 3])\n    assert_raises_regex(ValueError, \"Negative values in data passed to .*\",\n                        check_non_negative, sparse_matrix, \"some_func\")\n    sparse_matrix = sp.csr_matrix([1, 2, 3])\n    assert_no_warnings(check_non_negative, sparse_matrix, \"some_func\")\n", "def test_check_is_fitted():\n    # test fitted\n    clf = KNeighborsClassifier()\n    clf.fit(np.array([[1, 2], [3, 4]]), np.array([1, 2]))\n    check_is_fitted(clf, 'n_neighbors')\n\n    # test not fitted\n    clf = KNeighborsClassifier()\n    assert_raise_message(\n        NotFittedError,\n        \"This KNeighborsClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.\",\n        check_is_fitted, clf, 'n_neighbors'\n    )\n\n    # test fitted with multiple attributes\n    clf = ARDRegression()\n    clf.fit(np.array([[1, 2], [3, 4]]), np.array([1, 2]))\n    check_is_fitted(clf, ['alpha_', 'lambda_'])\n\n    # test not fitted with multiple attributes\n    clf = ARDRegression()\n    assert_raise_message(\n        NotFittedError,\n        \"This ARDRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.\",\n        check_is_fitted, clf, ['alpha_', 'lambda_']\n    )\n\n    # test all_or_any parameter\n    clf = RandomForestRegressor()\n    clf.fit(np.array([[1, 2], [3, 4]]), np.array([1, 2]))\n    check_is_fitted(clf, ['estimators_', 'n_features_'], all_or_any=any)\n\n    # test custom error message\n    clf = SVR()\n    assert_raise_message(\n        NotFittedError,\n        \"Estimator, SVR, must be fitted before sparsifying\",\n        check_is_fitted, clf, 'support_vectors_', msg=\"Estimator, %(name)s, must be fitted before sparsifying\"\n    )\n", "def test_check_X_y():\n    # test with numpy arrays\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([1, 2])\n    X, y = check_X_y(X, y)\n    assert_true(isinstance(X, np.ndarray))\n    assert_true(isinstance(y, np.ndarray))\n    assert_array_equal(X, np.array([[1, 2], [3, 4]]))\n    assert_array_equal(y, np.array([1, 2]))\n\n    # test with sparse matrices\n    X = sp.csr_matrix(np.array([[1, 2], [3, 4]]))\n    y = np.array([1, 2])\n    X, y = check_X_y(X, y, accept_sparse=True)\n    assert_true(isinstance(X, sp.csr_matrix))\n    assert_true(isinstance(y, np.ndarray))\n    assert_array_equal(X.toarray(), np.array([[1, 2], [3, 4]]))\n    assert_array_equal(y, np.array([1, 2]))\n\n    # test with list\n    X = [[1, 2], [3, 4]]\n    y = [1, 2]\n    X, y = check_X_y(X, y)\n    assert_true(isinstance(X, np.ndarray))\n    assert_true(isinstance(y, np.ndarray))\n    assert_array_equal(X, np.array([[1, 2], [3, 4]]))\n    assert_array_equal(y, np.array([1, 2]))\n\n    # test with single element\n    X = 1\n    y = 1\n    with assert_raises(ValueError):\n        check_X_y(X, y)\n\n    # test with mismatched lengths\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([1, 2, 3])\n    with assert_raises(ValueError):\n        check_X_y(X, y)\n\n    # test with non-numeric y\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array(['a', 'b'])\n    with assert_raises(ValueError):\n        check_X_y(X, y, y_numeric=True)\n\n    # test with multi-output y\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([[1, 2], [3, 4]])\n    X, y = check_X_y(X, y,", "def test_check_symmetric():\n    # test square matrix\n    arr = np.array([[1, 2], [2, 1]])\n    assert_array_equal(check_symmetric(arr), arr)\n\n    # test non-square matrix\n    arr = np.array([[1, 2], [3, 4], [5, 6]])\n    with assert_raises(ValueError):\n        check_symmetric(arr)\n\n    # test symmetric sparse matrix\n    arr = sp.csr_matrix(np.array([[1, 2], [2, 1]]))\n    assert_array_equal(check_symmetric(arr).toarray(), arr.toarray())\n\n    # test non-symmetric sparse matrix\n    arr = sp.csr_matrix(np.array([[1, 2], [3, 4]]))\n    with assert_warns_message(UserWarning, \"Array is not symmetric, and will be converted \"\n                        \"to symmetric by average with its transpose.\"):\n        arr_sym = check_symmetric(arr)\n    assert_array_equal(arr_sym.toarray(), np.array([[2, 2.5], [2.5, 4]]))\n\n    # test symmetric matrix with tol\n    arr = np.array([[1, 2], [1.999999999999, 1]])\n    with assert_warns_message(UserWarning, \"Array is not symmetric, and will be converted \"\n                        \"to symmetric by average with its transpose.\"):\n        arr_sym = check_symmetric(arr, tol=1E-10)\n    assert_array_equal(arr_sym, np.array([[1, 2], [2, 1]])\n\n    # test symmetric matrix with raise_exception=True\n    arr = np.array([[1, 2], [1.999999999999, 1]])\n    with assert_raises(ValueError):\n        check_symmetric(arr, tol=1E-10, raise_exception=True)\n", "def test_check_is_fitted():\n    # Test check_is_fitted with a fitted estimator\n    estimator = ARDRegression()\n    estimator.fit(np.array([[1], [2], [3]]), np.array([1, 2, 3]))\n    check_is_fitted(estimator, [\"coef_\", \"sigma_\"])\n\n    # Test check_is_fitted with an unfitted estimator\n    estimator = ARDRegression()\n    with pytest.raises(NotFittedError):\n        check_is_fitted(estimator, [\"coef_\", \"sigma_\"])\n\n    # Test check_is_fitted with a fitted estimator with multiple attributes\n    estimator = ARDRegression()\n    estimator.fit(np.array([[1], [2], [3]]), np.array([1, 2, 3]))\n    check_is_fitted(estimator, [\"coef_\", \"sigma_\", \"n_iter_\"])\n\n    # Test check_is_fitted with an estimator that is not fitted but has attribute\n    class FakeEstimator:\n            self.coef_ = None\n            self.sigma_ = None\n    estimator = FakeEstimator()\n    with pytest.raises(NotFittedError):\n        check_is_fitted(estimator, [\"coef_\", \"sigma_\"])\n\n    # Test check_is_fitted with a string message\n    estimator = ARDRegression()\n    with pytest.raises(NotFittedError) as exc:\n        check_is_fitted(estimator, [\"coef_\", \"sigma_\"],\n                        msg=\"This estimator must be fitted before use.\")\n    assert str(exc.value) == \"This estimator must be fitted before use.\"\n\n    # Test check_is_fitted with all_or_any\n    estimator = ARDRegression()\n    check_is_fitted(estimator, [\"coef_\", \"sigma_\"], all_or_any=any)\n    with pytest.raises(NotFittedError):\n        check_is_fitted(estimator, [\"coef_\", \"sigma_\"], all_or_any=all)\n\n    # Test check_is_fitted with a non-estimator\n    with pytest.raises(TypeError):\n        check_is_fitted(\"not an estimator\", [\"coef_\", \"sigma_\"])\n"], "sample_120": ["def test_MatrixElement():\n    A = MatrixSymbol('A', 3, 3)\n    B = MatrixElement(A, 0, 0)\n    C = MatrixElement(A, 1, 1)\n    assert B.parent == A\n    assert B.i == 0\n    assert B.j == 0\n    assert B.doit() == A[0, 0]\n    assert diff(B, C) == KroneckerDelta(0, 1)*KroneckerDelta(0, 1)\n", "def test_matrix_element_derivative():\n    i, j = symbols('i j')\n    expr = MatrixElement(MatrixSymbol('A', 2, 2), i, j)\n    assert diff(expr, MatrixElement(MatrixSymbol('A', 2, 2), i, j)) == KroneckerDelta(i, i)*KroneckerDelta(j, j)\n    assert diff(expr, MatrixElement(MatrixSymbol('B', 2, 2), i, j)) == S.Zero\n", "def test_matrix_symbol():\n    A = MatrixSymbol('A', n, m)\n    assert A.rows == n\n    assert A.cols == m\n    assert A.name == 'A'\n    assert A.free_symbols == {A}\n    assert A.shape == (n, m)\n", "def test_matrix_symbol():\n    M = MatrixSymbol('M', 3, 3)\n    assert M.shape == (3, 3)\n    assert M.name == 'M'\n    assert M._hashable_content() == ('M', (3, 3))\n\n    M2 = MatrixSymbol('M2', n, n)\n    assert M2.shape == (n, n)\n    assert M2.name == 'M2'\n\n    assert M2.free_symbols == {M2, n}\n    assert M.free_symbols == {M}\n\n    M3 = M2.subs(n, 3)\n    assert M3.shape == (3, 3)\n\n    raises(ShapeError, lambda: M**0.5)\n    raises(ShapeError, lambda: M**(S.Half))\n    raises(ShapeError, lambda: M**(S.Rational(1, 2)))\n\n    raises(ValueError, lambda: ZeroMatrix(3, 3)**-1)\n", "def test_matrixexpr():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, n)\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', n, n)\n    Z = ZeroMatrix(n, m)\n    I = Identity(n)\n    X = MatrixSymbol('X', n, 1)\n\n    # Test MatrixExpr\n    assert isinstance(A, MatrixExpr)\n    assert not A._iterable\n    assert A._op_priority == 11.0\n    assert A.is_Matrix\n    assert A.is_MatrixExpr\n    assert not A.is_Identity\n    assert not A.is_Inverse\n    assert not A.is_Transpose\n    assert not A.is_ZeroMatrix\n    assert not A.is_MatAdd\n    assert not A.is_MatMul\n    assert not A.is_commutative\n\n    # Test __neg__\n    assert -A == MatMul(S.NegativeOne, A).doit()\n\n    # Test __abs__\n    raises(NotImplementedError, lambda: abs(A))\n\n    # Test __add__ and __radd__\n    assert A + B == MatAdd(A, B).doit()\n    assert B + A == MatAdd(B, A).doit()\n\n    # Test __sub__ and __rsub__\n    assert A - B == MatAdd(A, -B).doit()\n    assert B - A == MatAdd(B, -A).doit()\n\n    # Test __mul__, __rmul__, and __matmul__, __rmatmul__\n    assert A * B == MatMul(A, B).doit()\n    assert B * A == MatMul(B, A).doit()\n    assert A @ B == MatMul(A, B).doit()\n    assert B @ A == MatMul(B, A).doit()\n\n    # Test __pow__\n    assert A ** S.NegativeOne == Inverse(A)\n    assert A ** S.Zero == Identity(n)\n    assert A ** S.One == A\n    raises(ShapeError, lambda: A ** 2)\n\n    # Test __truediv__ and __rtruediv__\n    assert A / B == A * B ** S.NegativeOne\n    raises(NotImplementedError, lambda: B / A)\n\n    # Test __getitem__\n    assert A.valid_index(0, 0)\n    raises(IndexError, lambda"], "sample_104": ["def test_pprint_estimator_max_elements_to_show():\n    # Test that the n_max_elements_to_show parameter is taken into account for\n    # estimators.\n    params = {\n        'param_{}'.format(i): i for i in range(100)\n    }\n    estimator = LogisticRegression(**params)\n    p = _EstimatorPrettyPrinter(n_max_elements_to_show=5)\n    text = p.pformat(estimator)\n    assert ', ...' in text\n\n    p = _EstimatorPrettyPrinter(n_max_elements_to_show=100)\n    text = p.pformat(estimator)\n    assert ', ...' not in text\n\n    # Check that it also affects the number of items in a dict\n    params = {\n        'param_{}'.format(i): i for i in range(100)\n    }\n    p = _EstimatorPrettyPrinter(n_max_elements_to_show=5)\n    text = p.pformat(params)\n    assert ', ...' in text\n\n    p = _EstimatorPrettyPrinter(n_max_elements_to_show=100)\n    text = p.pformat(params)\n    assert ', ...' not in text\n", "def test_pprint_estimator_with_changed_params():\n    # Test that only changed params are printed\n    set_config(print_changed_only=True)\n    estimator = LogisticRegression(penalty='l1', random_state=0)\n    printer = _EstimatorPrettyPrinter(indent=4, width=80, depth=5)\n    expected = r\"LogisticRegression\\(\\n    penalty='l1',\\n    random_state=0\\n\\)\"\n    result = printer.pformat(estimator)\n    assert re.fullmatch(expected, result)\n\n    # Test that all params are printed when changed_only=False\n    set_config(print_changed_only=False)\n    estimator = LogisticRegression(penalty='l1', random_state=0)\n    printer = _EstimatorPrettyPrinter(indent=4, width=80, depth=5)\n    expected = r\"LogisticRegression\\(\\n    C=1\\.0,\\n    class_weight=None,\\n    dual=False,\\n    fit_intercept=True,\\n    intercept_scaling=1,\\n    l1_ratio=None,\\n    max_iter=100,\\n    multi_class='warn',\\n    n_jobs=None,\\n    penalty='l1',\\n    random_state=0,\\n    solver='warn',\\n    tol=0\\.001,\\n    verbose=0,\\n    warm_start=False\\n\\)\"\n    result = printer.pformat(estimator)\n    assert re.fullmatch(expected, result)\n\n    # Test that changed params are printed with non-default values\n    estimator = LogisticRegression(penalty='l1', random_state=42)\n    printer = _EstimatorPrettyPrinter(indent=4, width=80, depth=5)\n    expected = r\"LogisticRegression\\(\\n    penalty='l1',\\n    random_state=42\\n\\)\"\n    result = printer.pformat(estimator)\n    assert re.fullmatch(expected, result)\n\n    # Test that changed params are printed with default values\n    estimator = LogisticRegression(penalty='l2', random_state=None)\n    printer = _EstimatorPrettyPrinter(indent=4, width=80, depth=5)\n    expected = r\"LogisticRegression\\(\\n    penalty='l2',\\n    random_state=None\\n\\)\"\n    result = printer.pformat(estimator)\n    assert re.fullmatch(expected, result)\n", "def test_pprint_key_val_tuple():\n    # Test that KeyValTuple and KeyValTupleParam are rendered correctly\n    printer = _EstimatorPrettyPrinter(indent_at_name=False)\n\n    # Test KeyValTuple\n    k = \"key\"\n    v = \"value\"\n    tuple_obj = KeyValTuple((k, v))\n    printer._pprint_key_val_tuple(tuple_obj, io.StringIO(), 0, 0, {}, 0)\n    printer._pprint_key_val_tuple(tuple_obj, io.StringIO(), 10, 0, {}, 0)\n\n    # Test KeyValTupleParam\n    k = \"key\"\n    v = \"value\"\n    tuple_obj = KeyValTupleParam((k, v))\n    printer._pprint_key_val_tuple(tuple_obj, io.StringIO(), 0, 0, {}, 0)\n    printer._pprint_key_val_tuple(tuple_obj, io.StringIO(), 10, 0, {}, 0)\n", "def test_n_max_elements_to_show():\n    # test that n_max_elements_to_show limits the number of elements printed\n    # in a list, dict or tuple\n    pp = _EstimatorPrettyPrinter(indent=1, width=80, depth=None,\n                                 n_max_elements_to_show=3)\n\n    # list\n    lst = [1, 2, 3, 4, 5]\n    s = pp.pformat(lst)\n    assert len(s.split(',')) == 4\n    assert '...' in s\n\n    # dict\n    d = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\n    s = pp.pformat(d)\n    assert len(s.split(',')) == 4\n    assert '...' in s\n\n    # tuple\n    tup = (1, 2, 3, 4, 5)\n    s = pp.pformat(tup)\n    assert len(s.split(',')) == 4\n    assert '...' in s\n\n    # estimator parameters\n    set_config(print_changed_only=False)\n    logistic = LogisticRegression(penalty='l2', dual=False, tol=1e-4, C=1.0,\n                                 fit_intercept=True, intercept_scaling=1,\n                                 class_weight=None, random_state=None,\n                                 solver='warn', max_iter=100,\n                                 multi_class='warn', verbose=0,\n                                 warm_start=False, n_jobs=None, l1_ratio=None)\n    logistic.penalty = 'l1'\n    s = pp.pformat(logistic)\n    assert len(s.split(',')) == 15\n    assert '...' in s\n\n    # test that n_max_elements_to_show=None means no limit\n    pp = _EstimatorPrettyPrinter(indent=1, width=80, depth=None,\n                                 n_max_elements_to_show=None)\n    lst = [1, 2, 3, 4, 5]\n    s = pp.pformat(lst)\n    assert len(s.split(',')) == 5\n    assert '...' not in s\n", "def test_pprint_estimator_long_params():\n    # Test that a long list of params does not break the pprinting\n    estimator = LogisticRegression(penalty='l2', dual=False, tol=1e-4, C=1.0,\n                                  fit_intercept=True, intercept_scaling=1,\n                                  class_weight=None, random_state=None,\n                                  solver='warn', max_iter=100, multi_class='warn',\n                                  verbose=0, warm_start=False, n_jobs=None,\n                                  l1_ratio=None)\n\n    estimator.set_params(**{f'param_{i}': i for i in range(50)})\n\n    pp = _EstimatorPrettyPrinter(width=100)\n    output = pp.pformat(estimator)\n    assert re.match(r'LogisticRegression\\(\\n.*\\)', output), output\n"], "sample_87": ["def test_in_venv(tmp_path):\n    venv_dir = tmp_path / \"venv\"\n    venv_dir.mkdir()\n    bindir = venv_dir / \"bin\" if sys.platform != \"win32\" else venv_dir / \"Scripts\"\n    bindir.mkdir()\n    activate = bindir / \"activate\"\n    activate.touch()\n\n    assert _in_venv(venv_dir)\n\n    venv_dir2 = tmp_path / \"venv2\"\n    venv_dir2.mkdir()\n    assert not _in_venv(venv_dir2)\n", "def test_session_init(tmpdir):\n    class DummyConfig:\n            self.rootdir = tmpdir\n            self.invocation_dir = tmpdir\n            self.pluginmanager = DummyPluginManager()\n            self.hook = DummyHook()\n\n    session = Session(DummyConfig())\n    assert session.testsfailed == 0\n    assert session.testscollected == 0\n    assert session.shouldstop is False\n    assert session.shouldfail is False\n    assert session._initialpaths == frozenset()\n\n", "    def test_in_venv(self, monkeypatch):\n        test_dir = py.path.local(__file__).dirpath()\n        venv_dir = test_dir.join(\"venv\")\n        activate_script = venv_dir.join(\"bin\", \"activate\")\n        venv_dir.ensure_dir()\n        activate_script.ensure()\n        \n        assert _in_venv(venv_dir)\n        \n        # Test that _in_venv returns False if the directory does not contain an activate script\n        activate_script.remove()\n        assert not _in_venv(venv_dir)\n\n        # Test that _in_venv returns False if the directory does not exist\n        venv_dir.remove()\n        assert not _in_venv(venv_dir)\n\n        # Test that _in_venv returns False if the directory is not a directory\n        venv_file = test_dir.join(\"venv\")\n        venv_file.ensure()\n        assert not _in_venv(venv_file)\n        venv_file.remove()\n", "def test_session_init_with_rootdir(tmpdir):\n    config = pytest.config.getconfig()\n    config.rootdir = tmpdir\n    session = Session(config)\n    assert session.startdir == config.invocation_dir\n    assert session._initialpaths == frozenset()\n    assert session._node_cache == {}\n    assert session._pkg_roots == {}\n", "    def test_in_venv(self):\n        # Check we correctly identify the base directory of a virtualenv\n        venv_dir = py.path.local(getattr(sys, \"_TESTEXE\", sys.executable)).dirpath()\n        assert _in_venv(venv_dir)\n        # And that we don't think other directories are virtualenvs\n        assert not _in_venv(py.path.local(\"/usr/bin\"))\n"], "sample_78": ["def test_load_dotenv(monkeypatch, tmp_path):\n    # Test loading a .env file in the current working directory\n    env_file = tmp_path / \".env\"\n    env_file.write_text(\"TEST_VAR=hello\")\n    with monkeypatch.context() as m:\n        m.setattr(os, \"curdir\", str(tmp_path))\n        assert load_dotenv() is True\n        assert os.environ.get(\"TEST_VAR\") == \"hello\"\n\n    # Test loading a .flaskenv file in the current working directory\n    env_file = tmp_path / \".flaskenv\"\n    env_file.write_text(\"TEST_VAR=hello\")\n    with monkeypatch.context() as m:\n        m.setattr(os, \"curdir\", str(tmp_path))\n        assert load_dotenv() is True\n        assert os.environ.get(\"TEST_VAR\") == \"hello\"\n\n    # Test loading a .env file in the instance folder\n    instance_path = tmp_path / \"instance\"\n    instance_path.mkdir()\n    env_file = instance_path / \".env\"\n    env_file.write_text(\"TEST_VAR=hello\")\n    with monkeypatch.context() as m:\n        m.setattr(os, \"curdir\", str(tmp_path))\n        m.setenv(\"INSTANCE_PATH\", str(instance_path))\n        assert load_dotenv() is True\n        assert os.environ.get(\"TEST_VAR\") == \"hello\"\n\n    # Test loading a .flaskenv file in the instance folder\n    env_file = instance_path / \".flaskenv\"\n    env_file.write_text(\"TEST_VAR=hello\")\n    with monkeypatch.context() as m:\n        m.setattr(os, \"curdir\", str(tmp_path))\n        m.setenv(\"INSTANCE_PATH\", str(instance_path))\n        assert load_dotenv() is True\n        assert os.environ.get(\"TEST_VAR\") == \"hello\"\n\n    # Test that loading a non-existent file returns False\n    with monkeypatch.context() as m:\n        m.setattr(os, \"curdir\", str(tmp_path))\n        assert load_dotenv(\"non_existent_file\") is False\n\n    # Test that loading a non-existent file in the instance folder returns False\n    with monkeypatch.context() as m:\n        m.setattr(os, \"curdir\", str(tmp_path))\n        m.setenv(\"INSTANCE_PATH\", str(instance_path))\n        assert load_dotenv(\"non_existent_file\") is False\n\n    # Test that loading a file with no .env or .flaskenv extension returns", "def test_find_best_app(runner):\n    # Create a temporary module file with an application instance\n    app_path = test_path / \"app.py\"\n    with app_path.open(\"w\") as f:\n        f.write(\"from flask import Flask\\napp = Flask(__name__)\\n\")\n\n    # Test finding the application by name\n    with runner.isolated_filesystem():\n        os.chdir(test_path)\n        module = import_string(\"app\")\n        app = find_best_app(module)\n        assert app.name == \"app\"\n\n    # Test finding the application by instance\n    with app_path.open(\"w\") as f:\n        f.write(\n            \"from flask import Flask\\n\"\n            \"app1 = Flask(__name__)\\n\"\n            \"app2 = Flask(__name__)\\n\"\n        )\n    with runner.isolated_filesystem():\n        os.chdir(test_path)\n        module = import_string(\"app\")\n        with pytest.raises(NoAppException):\n            find_best_app(module)\n\n    # Test finding the application by factory function\n    with app_path.open(\"w\") as f:\n        f.write(\n            \"from flask import Flask\\n\"\n            \"def create_app():\\n\"\n            \"    return Flask(__name__)\\n\"\n        )\n    with runner.isolated_filesystem():\n        os.chdir(test_path)\n        module = import_string(\"app\")\n        app = find_best_app(module)\n        assert app.name == \"app\"\n\n    # Test finding the application with incorrect function signature\n    with app_path.open(\"w\") as f:\n        f.write(\n            \"from flask import Flask\\n\"\n            \"def create_app(arg):\\n\"\n            \"    return Flask(__name__)\\n\"\n        )\n    with runner.isolated_filesystem():\n        os.chdir(test_path)\n        module = import_string(\"app\")\n        with pytest.raises(NoAppException):\n            find_best_app(module)\n", "def test_find_best_app_no_app_found():\n    \"\"\"Test that find_best_app raises an exception when no app is found\"\"\"\n    mod = types.ModuleType(\"test_module\")\n    with pytest.raises(NoAppException):\n        find_best_app(mod)\n\n", "def test_load_dotenv_env_file_path(runner):\n    env_file_path = test_path / \".env\"\n    env_file_path.write_text(\"TEST_VAR=env_file\")\n\n    result = runner.invoke(run_command, [\"--env-file\", str(env_file_path)])\n\n    assert result.exit_code == 0\n    assert os.environ.get(\"TEST_VAR\") == \"env_file\"\n\n", "def test_load_dotenv_env_file(monkeypatch):\n    \"\"\"Test loading environment variables from a file.\"\"\"\n    monkeypatch.setenv(\"FLASK_SKIP_DOTENV\", \"1\")\n\n    # Test loading a file specified by path.\n    file_path = test_path / \"env.txt\"\n    file_path.write_text(\"FOO=bar\\n\")\n    assert load_dotenv(file_path) is True\n    assert os.environ[\"FOO\"] == \"bar\"\n\n    # Test loading a file from the current directory.\n    assert load_dotenv() is True\n    assert os.environ[\"FOO\"] == \"bar\"\n\n    # Test loading a file with encoding.\n    file_path.write_text(\"FOO=\u00e4\u00f6\u00fc\\n\", encoding=\"utf-8\")\n    assert load_dotenv(file_path) is True\n    assert os.environ[\"FOO\"] == \"\u00e4\u00f6\u00fc\"\n\n    # Test that the current directory is not changed.\n    assert Path.cwd() == cwd\n\n    # Cleanup.\n    del os.environ[\"FOO\"]\n"], "sample_92": ["def test_evaluate_xfail_marks_runxfail_with_run_and_strict(testdir: Testdir) -> None:\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.xfail(run=True, strict=True)\n            assert 1 == 2\n        \"\"\"\n    )\n\n    result = testdir.runpytest(\"--runxfail\")\n    result.assert_outcomes(passed=1)\n    assert \"XPASS\" not in result.stdout.str()\n", "def test_evaluate_xfail_marks_with_strict_and_run_true(testdir: Testdir) -> None:\n    \"\"\"Test that xfail marks with strict=True and run=True are correctly evaluated.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.xfail(strict=True, run=True)\n            assert False\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 1\n    assert \"1 failed\" in result.stdout.str()\n    assert \"XPASS\" not in result.stdout.str()\n    assert \"XFAIL\" not in result.stdout.str()\n\n", "def test_evaluate_xfail_marks_condition_is_not_run(testdir: Testdir) -> None:\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.xfail(condition=False, reason=\"some reason\", run=False)\n            assert True\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.assert_outcomes(passed=0, skipped=0, failed=0)\n\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.xfail(condition=True, reason=\"some reason\", run=False)\n            assert True\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.assert_outcomes(skipped=1)\n", "    def test_xfail_marks_with_runxfail(self, testdir: Testdir) -> None:\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.xfail(reason=\"my reason\", run=True)\n                assert 1 == 2\n        \"\"\"\n        )\n        result = testdir.runpytest(\"--runxfail\")\n        result.assert_outcomes(passed=1, failed=1)\n        result.stdout.fnmatch_lines(\n            [\"*test_function*AssertionError*\", \"*my reason*\"]\n        )\n", "def test_evaluate_xfail_marks_with_strict_run_and_raises(testdir: Testdir) -> None:\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.xfail(strict=True, run=True, raises=ZeroDivisionError)\n            1 / 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-v\", \"-p\", \"no:pytester\")\n    result.assert_outcomes(xfailed=1)\n\n    # verify that we don't add an extra traceback frame\n    result.assert_outcomes(passed=0, failed=0, skipped=0)\n    result.stdout.fnmatch_lines(\n        [\n            \"*def test_strict_run_and_raises():*\",\n            \"*1 / 0*\",\n            \"*ZeroDivisionError: division by zero*\",\n            \"*1 failed, 1 xfailed in *\",\n        ]\n    )\n"], "sample_107": ["def test_logistic_regression_multinomial_solvers():\n    # Ensure that multinomial solvers behave the same as one-vs-rest\n    solvers = ['newton-cg', 'sag', 'lbfgs', 'liblinear']\n    X, y = iris.data, iris.target\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.5, random_state=0\n    )\n\n    for solver in solvers:\n        ovr = LogisticRegression(solver=solver, multi_class='ovr')\n        ovr.fit(X_train, y_train)\n        multinomial = LogisticRegression(solver=solver, multi_class='multinomial')\n        multinomial.fit(X_train, y_train)\n\n        ovr_pred = ovr.predict(X_test)\n        multinomial_pred = multinomial.predict(X_test)\n\n        assert_array_equal(ovr_pred, multinomial_pred)\n\n        ovr_prob = ovr.predict_proba(X_test)\n        multinomial_prob = multinomial.predict_proba(X_test)\n\n        assert_array_almost_equal(ovr_prob, multinomial_prob)\n", "def test_logistic_regression_cv():\n    # Test that LogisticRegressionCV can fit and predict data with different solvers\n    X, y = iris.data, iris.target\n    for solver in ['lbfgs', 'liblinear', 'sag', 'saga']:\n        clf = LogisticRegressionCV(solver=solver)\n        with ignore_warnings(category=ConvergenceWarning):\n            check_predictions(clf, X, y)\n\n", "def test_logistic_regression_cv_refit():\n    # Test that refitting LogisticRegressionCV model works.\n    X, y = iris.data, iris.target\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5,\n                                                        random_state=42)\n    clf = LogisticRegressionCV(Cs=[1], cv=2, penalty='l1', tol=1e-4,\n                              solver='liblinear', max_iter=1000,\n                              random_state=42, refit=True, n_jobs=1)\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    assert_array_equal(clf.classes_, np.unique(y_train))\n    assert_array_equal(y_pred, clf.predict(X_test))\n\n    # Ensure refit works with string penalty.\n    clf = LogisticRegressionCV(Cs=[1], cv=2, penalty='l2', tol=1e-4,\n                              solver='liblinear', max_iter=1000,\n                              random_state=42, refit=True, n_jobs=1)\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    assert_array_equal(clf.classes_, np.unique(y_train))\n    assert_array_equal(y_pred, clf.predict(X_test))\n\n    # Ensure refit works with None penalty.\n    clf = LogisticRegressionCV(Cs=[1], cv=2, penalty=None, tol=1e-4,\n                              solver='liblinear', max_iter=1000,\n                              random_state=42, refit=True, n_jobs=1)\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    assert_array_equal(clf.classes_, np.unique(y_train))\n    assert_array_equal(y_pred, clf.predict(X_test))\n", "def test_logistic_regression_cv_elastic_net():\n    X, y = make_classification(n_samples=50, n_features=100, n_informative=10,\n                               n_redundant=0, n_classes=2, random_state=0)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5,\n                                                        random_state=0)\n\n    clf = LogisticRegressionCV(penalty='elasticnet', solver='saga', max_iter=100,\n                              l1_ratios=[0.2, 0.5, 0.8], Cs=[1, 0.1, 0.01],\n                              cv=3, random_state=0)\n\n    with ignore_warnings(category=ConvergenceWarning):\n        clf.fit(X_train, y_train)\n\n    assert clf.score(X_test, y_test) > 0.5\n\n    # Test that the refit works\n    assert clf.coef_.shape == (1, X.shape[1])\n    assert clf.intercept_.shape == (1,)\n    assert clf.C_.shape == (1,)\n    assert clf.l1_ratio_.shape == (1,)\n\n    # Test with GridSearchCV\n    param_grid = {'l1_ratios': [0.5, 0.9]}\n    gs = GridSearchCV(clf, param_grid, cv=3)\n    with ignore_warnings(category=ConvergenceWarning):\n        gs.fit(X_train, y_train)\n\n    assert gs.best_score_ > 0.5\n\n    # Test scoring parameter\n    scoring = get_scorer('log_loss')\n    clf_scoring = LogisticRegressionCV(penalty='elasticnet', solver='saga',\n                                       max_iter=100, l1_ratios=[0.2, 0.5],\n                                       scoring=scoring, cv=3, random_state=0)\n    with ignore_warnings(category=ConvergenceWarning):\n        clf_scoring.fit(X_train, y_train)\n    assert clf_scoring.score(X_test, y_test) < 0.7  # log loss\n\n    # Test class_weight parameter\n    le = LabelEncoder()\n    y = le.fit_transform(y)\n    class_weight = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n    class_weight = dict(enumerate(class_weight))\n    clf_class_weight = LogisticRegressionCV(penalty='elasticnet', solver='saga',\n                                           max", "def test_logistic_regression_predict_proba(solver):\n    \"\"\"Check that predict_proba sums to 1 for logistic regression\"\"\"\n    X = [[-1, 0], [0, 1], [1, 1]]\n    Y = [0, 1, 1]\n\n    logreg = LogisticRegression(solver=solver).fit(X, Y)\n\n    Y_proba = logreg.predict_proba(X)\n    assert_array_almost_equal(Y_proba.sum(axis=1), np.ones(3))\n\n"], "sample_45": ["    def test_decorator_from_middleware_with_args(self):\n        class CacheMiddleware:\n                self.view_func = view_func\n                self.timeout = timeout\n\n                return None\n\n                return response\n\n        cache_page = decorator_from_middleware_with_args(CacheMiddleware)\n        decorated_view = cache_page(3600)(fully_decorated)\n\n        self.assertEqual(decorated_view.timeout, 3600)\n        self.assertEqual(decorated_view.view_func.__name__, 'fully_decorated')\n", "def test_method_decorator(TestCase):\n\n    class TestClass:\n            pass\n\n            return func(*args, **kwargs)\n        return wrapper\n\n    decorated_class = method_decorator(decorator, name='test_method')(TestClass)\n\n    self.assertEqual(getattr(decorated_class, 'test_method').__name__, 'wrapper')\n    self.assertEqual(getattr(decorated_class, 'test_method').__doc__, None)\n\n    decorated_class = method_decorator(decorator, name='test_method')(TestClass)\n    self.assertEqual(getattr(decorated_class, 'test_method').__name__, 'wrapper')\n    self.assertEqual(getattr(decorated_class, 'test_method').__dict__, {})\n\n    with self.assertRaises(ValueError):\n        method_decorator(decorator, name='wrong_method')(TestClass)\n\n    with self.assertRaises(TypeError):\n        class TestClass:\n            test_method = 'string'\n        method_decorator(decorator, name='test_method')(TestClass)\n", "def test_multi_decorate(self):\n    # Test that _multi_decorate() can handle multiple decorators\n            return func(*args, **kwargs) + ' dec1'\n        return wrapper\n\n            return func(*args, **kwargs) + ' dec2'\n        return wrapper\n\n        return 'original'\n\n    decorated = _multi_decorate([dec1, dec2], original)\n    response = decorated(None)\n    self.assertEqual(response, 'original dec1 dec2')\n\n    # Test that _multi_decorate() can handle a single decorator\n    decorated = _multi_decorate(dec1, original)\n    response = decorated(None)\n    self.assertEqual(response, 'original dec1')\n\n    # Test that _multi_decorate() preserves the original function's docstring\n    self.assertEqual(decorated.__doc__, original.__doc__)\n\n    # Test that _multi_decorate() preserves the original function's attributes\n    original.anything = \"Expected __dict__\"\n    decorated = _multi_decorate(dec1, original)\n    self.assertEqual(decorated.anything, original.anything)\n", "    def test_method_decorator_preserves_attributes(self):\n                return func(*args, **kwargs)\n            return wrapper\n\n        class TestClass:\n                \"\"\"Method docstring\"\"\"\n                pass\n            test_method.anything = \"Expected __dict__\"\n\n        method_decorator(decorator, 'test_method')(TestClass)\n\n        self.assertEqual(TestClass.test_method.__doc__, \"Method docstring\")\n        self.assertEqual(TestClass.test_method.anything, \"Expected __dict__\")\n", "def test_multi_decorate_preserves_attributes(TestCase):\n            return func(*args, **kwargs)\n        wrapper.anything = \"Expected __dict__\"\n        wrapper.__doc__ = \"Expected __doc__\"\n        return wrapper\n\n    @decorator\n        \"\"\"Original __doc__\"\"\"\n        pass\n    decorated_func.anything = \"Expected __dict__\"\n\n    self.assertEqual(decorated_func.__doc__, \"Expected __doc__\")\n    self.assertEqual(decorated_func.anything, \"Expected __dict__\")\n\n        pass\n    _update_method_wrapper(_wrapper, decorator)\n    self.assertEqual(_wrapper.__doc__, \"Expected __doc__\")\n    self.assertEqual(_wrapper.anything, \"Expected __dict__\")\n\n"], "sample_100": ["def test_ordinal_encoder_inverse_transform():\n    # Test inverse_transform with different dtypes\n    enc = OrdinalEncoder(categories='auto')\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    \n    Xt = enc.transform(X)\n    X_inv = enc.inverse_transform(Xt)\n\n    assert_array_equal(X_inv, np.array(X, dtype=object))\n    assert X_inv.dtype == object\n\n    Xt_int = Xt.astype(int)\n    X_inv_int = enc.inverse_transform(Xt_int)\n    assert_array_equal(X_inv_int, np.array(X, dtype=object))\n    assert X_inv_int.dtype == object\n\n    Xt_float = Xt.astype(float)\n    X_inv_float = enc.inverse_transform(Xt_float)\n    assert_array_equal(X_inv_float, np.array(X, dtype=object))\n    assert X_inv_float.dtype == object\n", "def test_ordinal_encoder():\n    # test with categorical data\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), [[0, 0], [1, 2], [1, 1]])\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), X)\n\n    # test with numerical data\n    X = [[1, 2], [3, 4], [3, 5]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), [[0, 0], [1, 1], [1, 2]])\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), X)\n\n    # test with categorical and numerical data\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), [[0, 0], [1, 2], [1, 1]])\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), X)\n\n    # test with missing values\n    X = [['Male', 1], ['Female', 3], [None, 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), [[0, 0], [1, 2], [np.nan, 1]])\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), X)\n\n    # test with unknown categories\n    X = [['Male', 1], ['Female', 3], ['Other', 2]]\n    enc.fit(X)\n    assert_raises(ValueError, enc.transform, X)\n\n    # test fit_transform\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    assert_array_equal(enc.fit_transform(X), [[0, 0], [1, 2], [1, 1]])\n\n    # test get_params and set_params\n    enc = OrdinalEncoder()\n    params = enc.get_params()\n    assert_equal(params, {'categories': 'auto', 'dtype': np.float64})\n    enc.set_params(dtype=np.int64)\n    assert_equal(enc.dtype, np.int64)\n", "def test_base_encoder_fit():\n    \"\"\"Check that _BaseEncoder._fit handles different inputs correctly.\"\"\"\n    X = np.array([['a', 'b'], ['a', 'c'], ['b', 'b']])\n\n    encoder = _BaseEncoder()\n    with pytest.raises(NotImplementedError):\n        encoder._fit(X)\n\n    encoder._categories = [[1, 2, 3], ['a', 'b']]\n    with pytest.raises(ValueError):\n        encoder._fit(X)\n\n    encoder._categories = [['a', 'b'], [1, 2, 3]]\n    with pytest.raises(ValueError):\n        encoder._fit(X)\n\n    encoder._categories = 'auto'\n    encoder._fit(X)\n\n    assert encoder.categories_ == [['a', 'b'], ['b', 'c']]\n\n    X = np.array([[1, 2], [1, 3], [2, 2]])\n    encoder._categories = 'auto'\n    encoder._fit(X)\n    assert encoder.categories_ == [[1, 2], [2, 3]]\n\n    X = np.array([['a', 'b'], ['a', 'c'], ['b', 'b']])\n    encoder._categories = [['a', 'b'], ['a', 'b']]\n    encoder._fit(X, handle_unknown='error')\n    assert encoder.categories_ == [['a', 'b'], ['a', 'b']]\n\n    with pytest.raises(ValueError):\n        encoder._fit(X, handle_unknown='error')\n", "def test_ordinal_encoder():\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n\n    assert_array_equal(enc.transform(X), np.array([[0., 2.], [1., 0.], [1., 1.]]))\n\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), toarray(np.array(X)))\n\n    # Check that OrdinalEncoder can handle a single feature\n    X = [['Male'], ['Female'], ['Female']]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0.], [1.], [1.]]))\n\n    # Check that OrdinalEncoder raises an error if the data contains NaN\n    X = [['Male', np.nan], ['Female', 3], ['Female', 2]]\n    with pytest.raises(ValueError, match=\"Input contains NaN\"):\n        enc.fit(X)\n\n    # Check that OrdinalEncoder raises an error if the data contains unknown\n    # categories during transform\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    with pytest.raises(ValueError, match=\"Found unknown categories\"):\n        enc.transform([['Unknown', 1]])\n\n    # Check that OrdinalEncoder can handle categorical features\n    X = [['A', 'B'], ['B', 'C'], ['A', 'B']]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 1.], [0., 0.]]))\n\n    # Check that OrdinalEncoder can handle categorical features with missing values\n    X = [['A', 'B'], ['B', None], ['A', 'B']]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., np.nan], [0., 0.]]))\n\n    # Check that OrdinalEncoder can handle categorical features with missing values\n    # during transform\n    X = [['A', 'B'], ['B', 'C'], ['A', 'B']]\n    enc.fit(X)\n    assert_array_equal(enc.transform([['A', None]]), np.array([[0., np.nan]]))\n\n    # Check that OrdinalEncoder can handle integer values\n    X = [[1, 2], [2, 3], [1, 2]]\n    enc", "def test_ordinal_encoder():\n    X = np.array([['Male', 'Male', 'Female'],\n                  [1, 2, 3]]).T\n\n    enc = OrdinalEncoder()\n    with assert_no_warnings():\n        enc.fit(X)\n\n    assert_array_equal(enc.categories_, [np.array(['Female', 'Male'], dtype=object),\n                                        np.array([1, 2, 3], dtype=object)])\n\n    X_tr = enc.transform(X)\n    assert_array_equal(X_tr, np.array([[0., 0.],\n                                       [1., 1.]]))\n\n    X_tr_inv = enc.inverse_transform(X_tr)\n    assert_array_equal(X_tr_inv, X)\n\n    # Test that the transformer raises an error when an unknown category is\n    # encountered\n    X_new = np.array([['Male', 'Female', 'Unknown'],\n                      [1, 2, 3]]).T\n    with assert_raises_regex(ValueError, 'Found unknown categories'):\n        enc.transform(X_new)\n\n    # Test that the transformer can handle unknown categories\n    enc = OrdinalEncoder()\n    enc.fit(X)\n    X_new = np.array([['Male', 'Female', 'Unknown'],\n                      [1, 2, 3]]).T\n    enc.transform(X_new)\n\n    # Test that categories are not mixed between features\n    X_mixed = np.array([['Male', 1], ['Female', 2]]).T\n    with assert_raises_regex(ValueError, 'mix strings and numeric values'):\n        OrdinalEncoder().fit(X_mixed)\n\n    # Test that categories are sorted when numeric\n    X_unsorted = np.array([['Female', 'Male'], [2, 1]]).T\n    with assert_raises_regex(ValueError, 'Unsorted categories'):\n        OrdinalEncoder(categories=[['Female', 'Male'], [2, 1]]).fit(X_unsorted)\n\n    # Test that OrdinalEncoder can handle a 1D array\n    X = np.array(['Male', 'Male', 'Female'])\n    enc = OrdinalEncoder()\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([0, 0, 1]))\n"], "sample_77": ["    def x(self):\n        return pd.Series([\"a\", \"b\", \"c\", \"b\", \"a\"], name=\"x\")\n", "    def x(self):\n        return pd.Series([\"a\", \"b\", \"c\"], name=\"x\")\n", "    def x(self):\n        return pd.Series([\"a\", \"b\", \"c\"], name=\"x\", dtype=object)\n", "    def x(self):\n        return pd.Series(\n            pd.date_range(\"2022-01-01\", periods=3),\n            name=\"x\",\n        )\n", "    def dates(self):\n        return pd.Series(pd.date_range(\"2022-01-01\", \"2022-01-31\"), name=\"date\", dtype=\"datetime64[ns]\")\n"], "sample_68": ["    def test_bulk_update_with_select_for_update(self):\n        # Test for ticket #27317\n        countries = [\n            Country(name=\"France\", iso_two_letter=\"FR\"),\n            Country(name=\"Italy\", iso_two_letter=\"IT\"),\n            Country(name=\"Spain\", iso_two_letter=\"ES\"),\n        ]\n        Country.objects.bulk_create(countries)\n        countries[0].name = \"France (updated)\"\n        countries[1].name = \"Italy (updated)\"\n        updated_rows = Country.objects.select_for_update().filter(\n            iso_two_letter__in=[\"FR\", \"IT\"]\n        ).bulk_update([countries[0], countries[1]], fields=[\"name\"])\n        self.assertEqual(updated_rows, 2)\n        self.assertEqual(\n            list(Country.objects.values_list(\"name\", flat=True)),\n            [\"France (updated)\", \"Italy (updated)\", \"Spain\"],\n        )\n", "def test_bulk_create_with_unique_fields(self):\n    # Test bulk_create with unique fields\n    # Arrange\n    unique_fields = ['name', 'iso_two_letter']\n    update_fields = ['name']\n    data = [\n        Country(name=\"United States of America\", iso_two_letter=\"US\"),\n        Country(name=\"The Netherlands\", iso_two_letter=\"NL\"),\n        Country(name=\"Germany\", iso_two_letter=\"DE\"),\n        Country(name=\"Czech Republic\", iso_two_letter=\"CZ\"),\n    ]\n\n    # Act and Assert\n    with self.assertRaises(NotSupportedError):\n        Country.objects.bulk_create(data, unique_fields=unique_fields, update_fields=update_fields)\n\n    # Test with a database that supports update conflicts with unique fields\n    with self.settings(DATABASES={\n        'default': {\n            'ENGINE': 'django.db.backends.sqlite3',\n            'NAME': 'test_database',\n            'OPTIONS': {\n                'timeout': 20,  # in seconds\n            }\n        }\n    }):\n        data = [\n            Country(name=\"United States of America\", iso_two_letter=\"US\"),\n            Country(name=\"The Netherlands\", iso_two_letter=\"NL\"),\n            Country(name=\"Germany\", iso_two_letter=\"DE\"),\n            Country(name=\"Czech Republic\", iso_two_letter=\"CZ\"),\n        ]\n        created_countries = Country.objects.bulk_create(data)\n        data[0].name = 'USA'\n        updated_countries = Country.objects.bulk_create(data, update_conflicts=True, unique_fields=unique_fields, update_fields=update_fields)\n        self.assertEqual(len(updated_countries), 4)\n        self.assertEqual(Country.objects.count(), 4)\n", "def test_bulk_create_with_unique_fields(self):\n    data = [\n        UpsertConflict(unique_field=\"unique1\", conflicting_field=\"conflict1\"),\n        UpsertConflict(unique_field=\"unique2\", conflicting_field=\"conflict2\"),\n    ]\n    with self.assertRaisesMessage(\n        ValueError,\n        \"bulk_create() can only be used with concrete fields in unique_fields.\",\n    ):\n        UpsertConflict.objects.bulk_create(\n            data, unique_fields=[\"nonexistent_field\"], update_fields=[\"conflicting_field\"]\n        )\n\n    with self.assertRaisesMessage(\n        ValueError,\n        \"bulk_create() can only be used with concrete fields in unique_fields.\",\n    ):\n        UpsertConflict.objects.bulk_create(\n            data, unique_fields=[\"unique_field\", \"nonexistent_field\"], update_fields=[\"conflicting_field\"]\n        )\n\n    with self.assertRaisesMessage(\n        ValueError, \"bulk_create() can only be used with concrete fields in update_fields.\"\n    ):\n        UpsertConflict.objects.bulk_create(\n            data,\n            unique_fields=[\"unique_field\"],\n            update_fields=[\"nonexistent_field\", \"conflicting_field\"],\n        )\n\n    UpsertConflict.objects.bulk_create(\n        data,\n        unique_fields=[\"unique_field\"],\n        update_fields=[\"conflicting_field\"],\n        update_conflicts=True,\n    )\n    self.assertEqual(UpsertConflict.objects.count(), 2)\n\n    data.append(UpsertConflict(unique_field=\"unique1\", conflicting_field=\"conflict3\"))\n    with self.assertRaisesMessage(\n        NotSupportedError,\n        \"This database backend does not support updating conflicts with specifying unique fields that can trigger the upsert.\",\n    ):\n        UpsertConflict.objects.bulk_create(\n            data,\n            unique_fields=[\"unique_field\"],\n            update_fields=[\"conflicting_field\"],\n            update_conflicts=True,\n        )\n\n    with self.assertRaisesMessage(\n        ValueError,\n        \"bulk_create() cannot be used with primary keys in unique_fields.\",\n    ):\n        class UpsertConflictWithPK(UpsertConflict):\n            unique_fields = [\"id\"]\n\n        UpsertConflictWithPK.objects.bulk_create(\n            data, unique_fields=[\"unique_field\"], update_fields=[\"conflicting_field\"]\n        )\n", "    def test_bulk_create_ignore_conflicts_with_unique_fields(self):\n        \"\"\"\n        bulk_create() with ignore_conflicts=True and unique_fields specified works.\n        \"\"\"\n        fields = ['name', 'iso_two_letter']\n        unique_fields = ['iso_two_letter']\n        batch_size = ceil(len(self.data) / 2)\n        Country.objects.bulk_create(\n            self.data, batch_size=batch_size, ignore_conflicts=True, unique_fields=unique_fields\n        )\n        self.assertEqual(Country.objects.count(), len(self.data))\n\n        # Try to bulk create again with same data to trigger conflicts\n        with self.assertRaises(IntegrityError):\n            Country.objects.bulk_create(\n                self.data, batch_size=batch_size, unique_fields=unique_fields\n            )\n\n        # Now ignore conflicts\n        Country.objects.bulk_create(\n            self.data, batch_size=batch_size, ignore_conflicts=True, unique_fields=unique_fields\n        )\n        self.assertEqual(Country.objects.count(), len(self.data))\n\n        # Check that it works when the unique field is the first field.\n        Country.objects.all().delete()\n        fields = ['iso_two_letter', 'name']\n        unique_fields = ['iso_two_letter']\n        Country.objects.bulk_create(\n            [Country(**d) for d in self.data], batch_size=batch_size, unique_fields=unique_fields\n        )\n        self.assertEqual(Country.objects.count(), len(self.data))\n\n        # Check that it works when the unique field is not the primary key.\n        Country.objects.all().delete()\n        fields = ['iso_two_letter', 'name']\n        unique_fields = ['name']\n        Country.objects.bulk_create(\n            [Country(**d) for d in self.data], batch_size=batch_size, unique_fields=unique_fields\n        )\n        self.assertEqual(Country.objects.count(), len(self.data))\n\n        # Check that it works with multiple unique fields.\n        Country.objects.all().delete()\n        fields = ['iso_two_letter', 'name']\n        unique_fields = ['iso_two_letter', 'name']\n        Country.objects.bulk_create(\n            [Country(**d) for d in self.data], batch_size=batch_size, unique_fields=unique_fields\n        )\n        self.assertEqual(Country.objects.count(), len(self.data))\n", "def test_annotate(self):\n    values = Country.objects.annotate(is_active=Value(True))\n    self.assertEqual(\n        values.query.annotations.keys(),\n        {\"is_active\"},\n    )\n\n    # Testing that annotations with the same name are overridden\n    values = Country.objects.annotate(is_active=Value(True)).annotate(is_active=Value(False))\n    self.assertEqual(\n        values.query.annotations[\"is_active\"].value,\n        False,\n    )\n\n    # Testing that annotations can be added to a filtered queryset\n    values = Country.objects.filter(name=\"United States of America\").annotate(\n        is_active=Value(True)\n    )\n    self.assertEqual(\n        values.query.annotations.keys(),\n        {\"is_active\"},\n    )\n    self.assertEqual(values.query.children[0].annotations.keys(), set())\n\n    # Testing that annotations can be added to a queryset with an existing annotation\n    values = (\n        Country.objects.annotate(is_active=Value(True))\n        .filter(name=\"United States of America\")\n        .annotate(is_secure=Value(True))\n    )\n    self.assertEqual(\n        values.query.annotations.keys(),\n        {\"is_active\", \"is_secure\"},\n    )\n    self.assertEqual(values.query.children[0].annotations.keys(), {\"is_active\"})\n\n    # Testing that annotations can be added to a queryset with multiple children\n    values = (\n        Country.objects.annotate(is_active=Value(True))\n        .filter(name=\"United States of America\")\n        .annotate(is_secure=Value(True))\n        .filter(is_secure=True)\n    )\n    self.assertEqual(\n        values.query.annotations.keys(),\n        {\"is_active\", \"is_secure\"},\n    )\n    self.assertEqual(values.query.children[0].annotations.keys(), {\"is_active\"})\n    self.assertEqual(values.query.children[1].annotations.keys(), set())\n\n    # Testing that annotations can be added to a queryset with multiple annotations\n    values = (\n        Country.objects.annotate(is_active=Value(True), is_secure=Value(True))\n        .filter(name=\"United States of America\")\n        .annotate(is_available=Value(True))\n    )\n    self.assertEqual(\n        values.query.annotations.keys(),\n        {\"is_active\", \"is_secure\", \"is_available\"},\n    )\n    self.assertEqual(values.query.children[0].annotations.keys(), {\"is_active\", \"is_secure\"})\n\n    # Testing that annotations can be added to a queryset with an annotation of the same name\n    values = (\n        Country.objects.annotate(is_active=Value(True))\n        .filter(name=\"United States of America\")\n        .annotate(is_active=Value(False))\n    )\n    self.assertEqual(\n        values.query.annotations.keys(),\n        {\"is_active\"},\n   "], "sample_14": ["    def test_serializer_factory_models_field(self):\n        field = models.CharField(max_length=255)\n        serializer = serializer_factory(field)\n        self.assertIsInstance(serializer, ModelFieldSerializer)\n", "    def test_serializer_factory_coverage(self):\n        # Test the serializer factory with various types\n        self.assertIsInstance(serializer_factory(1), BaseSimpleSerializer)\n        self.assertIsInstance(serializer_factory(1.0), FloatSerializer)\n        self.assertIsInstance(serializer_factory(True), BaseSimpleSerializer)\n        self.assertIsInstance(serializer_factory(None), BaseSimpleSerializer)\n        self.assertIsInstance(serializer_factory(\"hello\"), BaseSimpleSerializer)\n        self.assertIsInstance(serializer_factory(b\"hello\"), BaseSimpleSerializer)\n        self.assertIsInstance(serializer_factory(datetime.date.today()), DateTimeSerializer)\n        self.assertIsInstance(serializer_factory(datetime.datetime.now()), DatetimeDatetimeSerializer)\n        self.assertIsInstance(serializer_factory(datetime.timedelta(days=1)), DateTimeSerializer)\n        self.assertIsInstance(serializer_factory(decimal.Decimal(\"1.0\")), DecimalSerializer)\n        self.assertIsInstance(serializer_factory(enum.Enum(\"A\", \"B\")), EnumSerializer)\n        self.assertIsInstance(serializer_factory(functools.partial(lambda x: x)), FunctoolsPartialSerializer)\n        self.assertIsInstance(serializer_factory(functools.partialmethod(lambda x: x)), FunctoolsPartialSerializer)\n        self.assertIsInstance(serializer_factory(models.Field()), DeconstructableSerializer)\n        self.assertIsInstance(serializer_factory(models.Manager()), DeconstructableSerializer)\n        self.assertIsInstance(serializer_factory(Operation()), OperationSerializer)\n        self.assertIsInstance(serializer_factory(re.compile(\"hello\")), RegexSerializer)\n        self.assertIsInstance(serializer_factory(uuid.UUID(\"12345678-1234-1234-1234-123456789012\")), UUIDSerializer)\n        self.assertIsInstance(serializer_factory([1, 2, 3]), SequenceSerializer)\n        self.assertIsInstance(serializer_factory((1, 2, 3)), TupleSerializer)\n        self.assertIsInstance(serializer_factory({1, 2, 3}), SetSerializer)\n        self.assertIsInstance(serializer_factory(frozenset([1, 2, 3])), FrozensetSerializer)\n        self.assertIsInstance(serializer_factory({\"a\": 1, \"b\": 2}), DictionarySerializer)\n\n        # Test the serializer factory with deconstructible instances\n        self.assertIsInstance(serializer_factory(DeconstructibleInstances()), DeconstructableSerializer)\n        self.assertIsInstance(serializer_factory(Money(\"1.0\")), DeconstructableSerializer)\n\n        # Test the serializer factory with lazy objects\n        self.assertIsInstance(serializer_factory(SimpleLazyObject(lambda: 1)), BaseSimpleSerializer)\n\n        # Test the serializer factory with promises\n        self.assertIsInstance(serializer_factory(_(\"hello\")), BaseSimpleSerializer)\n", "    def test_frozenset(self):\n        value = frozenset([1, 2, 3])\n        serializer = serializer_factory(value)\n        self.assertIsInstance(serializer, FrozensetSerializer)\n        self.assertEqual(serializer.serialize()[0], \"frozenset([1, 2, 3])\")\n", "    def test_serializer_registry(self):\n        self.assertIsInstance(Serializer._registry, dict)\n        self.assertIn(frozenset, Serializer._registry)\n        self.assertIn(list, Serializer._registry)\n        self.assertIn(set, Serializer._registry)\n        self.assertIn(tuple, Serializer._registry)\n        self.assertIn(dict, Serializer._registry)\n        self.assertIn(models.Choices, Serializer._registry)\n        self.assertIn(enum.Enum, Serializer._registry)\n        self.assertIn(datetime.datetime, Serializer._registry)\n        self.assertIn(SettingsReference, Serializer._registry)\n        self.assertIn(float, Serializer._registry)\n        self.assertIn(decimal.Decimal, Serializer._registry)\n        self.assertIn(functools.partial, Serializer._registry)\n        self.assertIn(types.FunctionType, Serializer._registry)\n        self.assertIn(collections.abc.Iterable, Serializer._registry)\n        self.assertIn(uuid.UUID, Serializer._registry)\n", "    def test_serializer_factory(self):\n        tests = [\n            (datetime.date(2022, 1, 1), 'datetime.date(2022, 1, 1)'),\n            (datetime.time(12, 0), 'datetime.time(12, 0)'),\n            (datetime.timedelta(days=1), 'datetime.timedelta(days=1)'),\n            (decimal.Decimal('1.1'), \"Decimal('1.1')\"),\n            (TextEnum.A, \"TextEnum.A\"),\n            (TextTranslatedEnum.A, \"TextTranslatedEnum.A\"),\n            (BinaryEnum.A, \"BinaryEnum.A\"),\n            (IntEnum.A, \"IntEnum.A\"),\n            (SettingsReference('SETTING'), \"settings.SETTING\"),\n            (functools.partial(lambda x: x), 'functools.partial(<lambda>)'),\n            (functools.partialmethod(lambda self: self), 'functools.partialmethod(<lambda>)'),\n            (lambda x: x, '<function <lambda> at'),\n            (re.compile('pattern'), \"re.compile('pattern')\"),\n            (uuid.UUID('00000000-0000-0000-0000-000000000000'), 'uuid.UUID'),\n            (Money('1.1'), \"Money('1.1')\"),\n            (DeconstructibleInstances(), \"DeconstructibleInstances()\"),\n        ]\n        for value, expected in tests:\n            serializer = serializer_factory(value)\n            serialized, imports = serializer.serialize()\n            self.assertEqual(serialized, expected)\n"], "sample_57": ["def test_management_form_fields(self):\n    formset = self.make_choiceformset()\n    management_form = formset.management_form\n    self.assertIsInstance(management_form.fields[TOTAL_FORM_COUNT], IntegerField)\n    self.assertIsInstance(management_form.fields[TOTAL_FORM_COUNT].widget, HiddenInput)\n    self.assertIsInstance(management_form.fields[INITIAL_FORM_COUNT], IntegerField)\n    self.assertIsInstance(management_form.fields[INITIAL_FORM_COUNT].widget, HiddenInput)\n    self.assertIsInstance(management_form.fields[MIN_NUM_FORM_COUNT], IntegerField)\n    self.assertIsInstance(management_form.fields[MIN_NUM_FORM_COUNT].widget, HiddenInput)\n    self.assertIsInstance(management_form.fields[MAX_NUM_FORM_COUNT], IntegerField)\n    self.assertIsInstance(management_form.fields[MAX_NUM_FORM_COUNT].widget, HiddenInput)\n    self.assertFalse(management_form.fields[MIN_NUM_FORM_COUNT].required)\n    self.assertFalse(management_form.fields[MAX_NUM_FORM_COUNT].required)\n", "def test_formset_factory_custom_form_kwargs(self):\n    class CustomKwargFormset(formset_factory(CustomKwargForm)):\n        pass\n\n    with self.assertRaises(TypeError):\n        CustomKwargFormset()\n\n    formset = CustomKwargFormset(custom_kwarg=\"kwarg\")\n    self.assertEqual(formset.form_kwargs[\"custom_kwarg\"], \"kwarg\")\n", "    def test_management_form_rendering(self):\n        formset = BaseFormSet()\n        management_form = formset.management_form\n        with self.assertWarns(RemovedInDjango50Warning):\n            self.assertEqual(management_form.template_name, \"django/forms/div.html\")\n", "    def test_management_form_invalid(self):\n        formset = self.make_choiceformset(formset_data=[(\"a\", 1), (\"b\", 2)], total_forms=5)\n        formset.management_form.errors = ErrorList([\"Invalid data\"])\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(formset.non_form_errors(), ErrorList([\"Invalid data\"]))\n", "    def test_formset_with_custom_renderer(self):\n        \"\"\"\n        A FormSet should use the renderer specified by the formset_factory.\n        \"\"\"\n        with isolate_lru_cache(get_default_renderer):\n            with mock.patch(\n                \"django.forms.renderers.get_default_renderer\",\n                return_value=mock.Mock(),\n            ) as mock_get_default_renderer:\n                renderer = TemplatesSetting(\"my_renderer\")\n                formset = formset_factory(FavoriteDrinkForm, renderer=renderer)\n                self.assertEqual(formset.renderer, renderer)\n\n                formset_with_custom_renderer = formset(\n                    data={},\n                    renderer=mock.Mock(),\n                )\n                self.assertNotEqual(\n                    formset_with_custom_renderer.renderer, renderer\n                )\n                self.assertEqual(\n                    formset_with_custom_renderer.renderer,\n                    mock_get_default_renderer.return_value,\n                )\n                self.assertEqual(\n                    formset_with_custom_renderer.renderer,\n                    formset_with_custom_renderer.management_form.renderer,\n                )\n"], "sample_151": ["def test_point():\n    # Test construction of points from different types of sequences\n    p1 = Point((1, 2))\n    p2 = Point([1, 2])\n    p3 = Point((1, 2))\n    p4 = Point([1, 2])\n    assert p1 == p2\n    assert p1 == p3\n    assert p1 == p4\n\n    # Test that passing a non-sequence raises TypeError\n    raises(TypeError, lambda: Point(1))\n\n    # Test that passing a sequence of less than 2 elements raises ValueError\n    raises(ValueError, lambda: Point((1,)))\n\n    # Test that passing a sequence of more than 3 elements creates a Point instance\n    p = Point((1, 2, 3, 4))\n    assert isinstance(p, Point)\n    assert len(p) == 4\n\n    # Test that passing a Point instance with a different dimension raises ValueError\n    p1 = Point((1, 2))\n    p2 = Point((1, 2, 3))\n    raises(ValueError, lambda: p1 + p2)\n\n    # Test that adding points with the same dimension works correctly\n    p1 = Point((1, 2))\n    p2 = Point((2, 3))\n    p3 = p1 + p2\n    assert p3 == Point((3, 5))\n\n    # Test that subtracting points with the same dimension works correctly\n    p1 = Point((1, 2))\n    p2 = Point((2, 3))\n    p3 = p1 - p2\n    assert p3 == Point((-1, -1))\n\n    # Test that multiplying a point by a scalar works correctly\n    p = Point((1, 2))\n    p2 = p * 2\n    assert p2 == Point((2, 4))\n\n    # Test that dividing a point by a scalar works correctly\n    p = Point((2, 4))\n    p2 = p / 2\n    assert p2 == Point((1, 2))\n\n    # Test that the dot product of two points works correctly\n    p1 = Point((1, 2))\n    p2 = Point((2, 3))\n    assert p1.dot(p2) == 8\n\n    # Test that the length of a point is 0\n    p = Point((1, 2))\n   ", "def test_point_class():\n    # Test the Point class\n    p1 = Point(1, 2, 3, evaluate=False)\n    p2 = Point(1, 2, 3, evaluate=False)\n    assert p1 == p2\n    assert p1.distance(p2) == 0\n    p3 = Point(1, 2, 3)\n    p4 = Point(1.0, 2.0, 3.0)\n    assert p3 == p4\n    p5 = Point(1, 2)\n    p6 = Point(1, 2, 0)\n    assert p5 == p6\n\n    # Test that the ambient dimension is correctly set\n    assert Point(1, 2, 3).ambient_dimension == 3\n    assert Point(1, 2).ambient_dimension == 2\n\n    # Test the is_concyclic method\n    p1, p2, p3 = Point(1, 0), Point(0, 1), Point(-1, 0)\n    assert Point.is_concyclic(p1, p2, p3)\n    p4 = Point(1, 1)\n    assert not Point.is_concyclic(p1, p2, p3, p4)\n\n    # Test the is_collinear method\n    p1, p2, p3 = Point(1, 1), Point(2, 2), Point(3, 3)\n    assert Point.is_collinear(p1, p2, p3)\n    p4 = Point(1, 2)\n    assert not Point.is_collinear(p1, p2, p3, p4)\n\n    # Test the canberra_distance method\n    p1, p2 = Point(1, 1), Point(3, 3)\n    assert p1.canberra_distance(p2) == 1\n    p3, p4 = Point(0, 0), Point(3, 3)\n    assert p3.canberra_distance(p4) == 2\n\n    # Test the orthogonal_direction method\n    p1 = Point(1, 2, 3)\n    p2 = p1.orthogonal_direction\n    assert p1.dot(p2) == 0\n", "def test_point():\n    p = Point3D(1, 2, 3)\n    m = Matrix([[0, -1, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n    assert p.transform(m) == Point3D(-2, 1, 3)\n    p = Point2D(0, 1)\n    m = Matrix([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n    assert p.transform(m) == Point2D(-1, 0)\n    m = Matrix([[1, 0, 1], [0, 1, 0], [0, 0, 1]])\n    assert p.transform(m) == Point2D(1, 1)\n    raises(ValueError, lambda: Point3D(1, 2, 3).transform(m))\n    raises(ValueError, lambda: Point2D(0, 1).transform(Matrix([[0, -1], [1, 0]])))\n", "def test_point_collision():\n    p1, p2 = Point2D(0, 0), Point2D(2, 2)\n    p3, p4 = Point2D(0, 0), Point2D(3, 3)\n\n    # Test is_collinear with Point instances\n    assert p1.is_collinear(p2, p3, p4)\n\n    # Test is_collinear with sequences\n    assert Point.is_collinear(p1, (2, 2), (3, 3))\n\n    # Test is_collinear with Point instances and sequences\n    assert p1.is_collinear(p2, (3, 3))\n\n    # Test that points with different ambient dimensions are not collinear\n    p3d = Point3D(1, 2, 3)\n    assert not p1.is_collinear(p3d)\n\n    # Test that collinear points in 3D space are detected\n    p4 = Point3D(0, 0, 0)\n    p5 = Point3D(1, 2, 3)\n    p6 = Point3D(2, 4, 6)\n    assert p4.is_collinear(p5, p6)\n\n    # Test that collinear points in 4D space are detected\n    p7 = Point(0, 0, 0, 0)\n    p8 = Point(1, 2, 3, 4)\n    p9 = Point(2, 4, 6, 8)\n    assert p7.is_collinear(p8, p9)\n", "def test_Point():\n    p = Point(1, 2, 3)\n    assert p == Point([1, 2, 3])\n    p = Point([1, 2, 3])\n    assert p == Point(1, 2, 3)\n    p = Point(1, 2)\n    assert p == Point([1, 2])\n    p = Point([1, 2])\n    assert p == Point(1, 2)\n    assert str(Point(x, y)) == 'Point2D(x, y)'\n    assert repr(Point(x, y)) == 'Point2D(x, y)'\n\n    assert Point(1, 2).dot((3, 4)) == 11\n    assert Point(1, 2).dot(Point(3, 4)) == 11\n\n    assert Point(x, y).dot((3, 4)) == 3*x + 4*y\n\n    assert Point(1, 2, 3).dot((4, 5, 6)) == 32\n    assert Point(1, 2, 3).dot(Point(4, 5, 6)) == 32\n\n    assert Point(x, y, z).dot((3, 4, 5)) == 3*x + 4*y + 5*z\n\n    # issue 11874\n    p = Point(1, 2)\n    assert not p.is_scalar_multiple(p + p)\n\n    assert p.is_scalar_multiple(Point(3, 6))\n    assert Point(3, 6).is_scalar_multiple(p)\n    assert p.is_scalar_multiple(3*p)\n\n    # issue 13533\n    assert Point(0, 0, 0).is_collinear(Point(1, 2, 3), Point(0, 0, 0))\n    assert Point(0, 0, 0).is_collinear(Point(0, 0, 0), Point(0, 0, 0))\n\n    # issue 14071\n    p1 = Point(1, 2, 3)\n    p2 = Point(4, 5, 6)\n    p3 = Point(7, 8, 9)\n    p4 = Point(10, 11, 12)\n    assert Point3D.are_collinear(p1, p2, p3, p4)\n\n"], "sample_43": ["    def test_process_request_validates_model_admin_search_fields(self):\n        with model_admin(Author, admin.ModelAdmin()):\n            request = self.factory.get(self.url, {'term': '', 'app_label': 'tests', 'model_name': 'author', 'field_name': 'id'})\n            request.user = self.user\n            with self.assertRaises(Http404):\n                AutocompleteJsonView.as_view(admin_site=site)(request)\n", "def test_process_request_validates_integrity(self):\n    request = self.factory.get(self.url, data={\n        'term': '',\n        'app_label': 'nonexistent_app',\n        'model_name': 'Answer',\n        'field_name': 'question',\n    })\n    request.user = self.user\n\n    view = AutocompleteJsonView()\n    view.admin_site = self.site\n    with self.assertRaises(PermissionDenied):\n        view.process_request(request)\n\n    request = self.factory.get(self.url, data={\n        'term': '',\n        'app_label': Answer._meta.app_label,\n        'model_name': 'nonexistent_model',\n        'field_name': 'question',\n    })\n    request.user = self.user\n\n    view = AutocompleteJsonView()\n    view.admin_site = self.site\n    with self.assertRaises(PermissionDenied):\n        view.process_request(request)\n\n    request = self.factory.get(self.url, data={\n        'term': '',\n        'app_label': Answer._meta.app_label,\n        'model_name': Answer._meta.model_name,\n        'field_name': 'nonexistent_field',\n    })\n    request.user = self.user\n\n    view = AutocompleteJsonView()\n    view.admin_site = self.site\n    with self.assertRaises(PermissionDenied):\n        view.process_request(request)\n\n    request = self.factory.get(self.url, data={\n        'term': '',\n        'app_label': Answer._meta.app_label,\n        'model_name': Answer._meta.model_name,\n        'field_name': 'question',\n    })\n    request.user = self.user\n\n    view = AutocompleteJsonView()\n    view.admin_site = self.site\n    with self.assertRaises(Http404):\n        with model_admin(Answer, admin.ModelAdmin()):\n            view.process_request(request)\n", "    def test_process_request_validates_term(self):\n        # Test that an empty term does not raise an error.\n        request = self.factory.get(self.url, {'term': '', **self.opts})\n        view = AutocompleteJsonView()\n        view.admin_site = self.as_view_args['admin_site']\n        view.process_request(request)\n\n        # Test that a non-empty term does not raise an error.\n        request = self.factory.get(self.url, {'term': 'test', **self.opts})\n        view = AutocompleteJsonView()\n        view.admin_site = self.as_view_args['admin_site']\n        view.process_request(request)\n", "    def test_serialize_result(self):\n        view = self.view_class(**self.as_view_args)\n        view.term = 'test'\n        view.model_admin = AnswerAdmin(Answer, site)\n        view.source_field = Answer._meta.get_field('question')\n        view.object_list = [Answer.objects.create(question=Question.objects.create(question_text='test'))]\n        response = view.get(self.factory.get(self.url, self.opts))\n        self.assertEqual(response.status_code, 200)\n        data = json.loads(response.content)\n        self.assertEqual(len(data['results']), 1)\n        self.assertEqual(data['results'][0]['id'], str(view.object_list[0].question_id))\n        self.assertEqual(data['results'][0]['text'], str(view.object_list[0].question))\n", "def test_get_paginator(self):\n    \"\"\"Test that the view uses the ModelAdmin's paginator.\"\"\"\n    request = self.factory.get(self.url, self.opts)\n    request.user = self.user\n    view = self.view.as_view(**self.as_view_args)\n    response = view(request, **self.opts)\n    self.assertEqual(response.status_code, 200)\n    self.assertIn('results', response.json())\n    self.assertIn('pagination', response.json())\n    self.assertIn('more', response.json()['pagination'])\n"], "sample_38": ["def test_user_creation_form(self):\n    form_data = {\n        'username': 'newuser',\n        'password1': 'newpassword',\n        'password2': 'newpassword',\n    }\n    form = UserCreationForm(data=form_data)\n    self.assertTrue(form.is_valid())\n    user = form.save()\n    self.assertEqual(user.username, 'newuser')\n    self.assertTrue(user.check_password('newpassword'))\n\n    # Test invalid password\n    form_data['password1'] = 'invalid'\n    form = UserCreationForm(data=form_data)\n    self.assertFalse(form.is_valid())\n\n    # Test password mismatch\n    form_data['password1'] = 'newpassword'\n    form_data['password2'] = 'wrongpassword'\n    form = UserCreationForm(data=form_data)\n    self.assertFalse(form.is_valid())\n\n    # Test username is required\n    form_data['username'] = ''\n    form = UserCreationForm(data=form_data)\n    self.assertFalse(form.is_valid())\n", "    def test_password_mismatch(self):\n        data = {\n            'username': 'testclient',\n            'password1': 'password1',\n            'password2': 'password2',\n        }\n        form = UserCreationForm(data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(len(form.errors), 1)\n        self.assertIn('password2', form.errors)\n", "    def test_clean_password2(self):\n        # Test with matching passwords\n        form_data = {'password1': 'new_password', 'password2': 'new_password'}\n        form = UserCreationForm(data=form_data)\n        self.assertTrue(form.is_valid())\n\n        # Test with non-matching passwords\n        form_data = {'password1': 'new_password', 'password2': 'different_password'}\n        form = UserCreationForm(data=form_data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(len(form.errors), 1)\n        self.assertIn('password2', form.errors)\n\n        # Test with empty passwords\n        form_data = {'password1': '', 'password2': ''}\n        form = UserCreationForm(data=form_data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(len(form.errors), 1)\n        self.assertIn('password2', form.errors)\n\n        # Test with password validation error\n        form_data = {'password1': 'weak', 'password2': 'weak'}\n        form = UserCreationForm(data=form_data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(len(form.errors), 1)\n        self.assertIn('password2', form.errors)\n", "    def test_read_only_password_hash_field(self):\n        field = ReadOnlyPasswordHashField()\n        with self.settings(AUTH_PASSWORD_VALIDATORS=[\n            {'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator'},\n        ]):\n            widget = field.widget\n            value = self.u1.password\n            context = widget.get_context('password', value, attrs={})\n            self.assertIsInstance(context['summary'], list)\n            for item in context['summary']:\n                self.assertIsInstance(item, dict)\n                self.assertIn('label', item)\n                if 'value' in item:\n                    self.assertIsInstance(item['value'], str)\n\n            value = self.u4.password\n            context = widget.get_context('password', value, attrs={})\n            self.assertEqual(len(context['summary']), 1)\n            self.assertEqual(context['summary'][0]['label'], _('No password set.'))\n\n            value = self.u5.password\n            context = widget.get_context('password', value, attrs={})\n            self.assertEqual(len(context['summary']), 1)\n            self.assertEqual(context['summary'][0]['label'], _('Invalid password format or unknown hashing algorithm.'))\n", "    def test_read_only_password_hash_widget(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = 'sha256$PBk9Sc8z$8b9c4e2a8a52a71a6c6e56e4d21d59f4d58e2f3d3956e4d21d59f4d58e2f3d'\n        context = widget.get_context('password', value, attrs=None)\n        self.assertEqual(len(context['summary']), 1)\n"], "sample_79": ["def test_concat_dataset_with_new_dim():\n    # Create test data\n    data = create_test_data()\n    ds1 = Dataset({\"x\": (\"x\", [1, 2, 3])})\n    ds2 = Dataset({\"x\": (\"x\", [4, 5, 6])})\n\n    # Concatenate datasets along a new dimension\n    result = concat([ds1, ds2], dim=\"y\")\n\n    # Check the result\n    expected = Dataset({\"x\": ([\"y\", \"x\"], [[1, 2, 3], [4, 5, 6]])})\n    assert_identical(result, expected)\n\n    # Check that the original datasets are unchanged\n    assert_identical(ds1, Dataset({\"x\": (\"x\", [1, 2, 3])}))\n    assert_identical(ds2, Dataset({\"x\": (\"x\", [4, 5, 6])}))\n", "def test_concat_datasets_with_missing_data():\n    data1 = create_test_data()\n    data2 = deepcopy(data1)\n    data2[\"var1\"] = data2[\"var1\"].where(data2[\"var1\"] > 0)\n    data2[\"var2\"] = data2[\"var2\"].where(data2[\"var2\"] < 0)\n\n    concatenated = concat([data1, data2], dim=\"time\")\n\n    expected = data1.copy()\n    expected[\"var1\"] = np.concatenate([data1[\"var1\"], data2[\"var1\"]])\n    expected[\"var2\"] = np.concatenate([data1[\"var2\"], data2[\"var2\"]])\n\n    assert_identical(concatenated, expected)\n", "def test_concat_dataset_with_fill_value():\n    # create test data\n    data = create_test_data()\n    ds1 = Dataset({\"foo\": (\"x\", [1, 2, 3])}, coords={\"x\": [0, 1, 2]})\n    ds2 = Dataset({\"foo\": (\"x\", [4, 5, 6])}, coords={\"x\": [0, 1, 2]})\n\n    # test with fill_value\n    result = concat([ds1, ds2], dim=\"x\", fill_value=0)\n    expected = Dataset({\"foo\": ((\"x\", \"concat_dim\"), [[1, 2, 3], [4, 5, 6]])}, \n                       coords={\"x\": [0, 1, 2], \"concat_dim\": [0, 1]})\n    assert_equal(result, expected)\n\n    # test with fill_value as a DataArray\n    fill_value = DataArray(0, dims=[])\n    result = concat([ds1, ds2], dim=\"x\", fill_value=fill_value)\n    assert_equal(result, expected)\n\n    # test with fill_value as a numpy array\n    fill_value = np.array(0)\n    result = concat([ds1, ds2], dim=\"x\", fill_value=fill_value)\n    assert_equal(result, expected)\n", "def test_concat():\n    # Create two test datasets with different variables\n    ds1 = create_test_data()\n    ds2 = create_test_data()\n\n    # Add a new variable to the second dataset\n    ds2['new_var'] = ('x', np.arange(3))\n\n    # Concatenate the datasets along the 'time' dimension\n    concatenated = concat([ds1, ds2], dim='time')\n\n    # Check that the new variable is included in the concatenated dataset\n    assert 'new_var' in concatenated.variables\n\n    # Check that the concatenated dataset has the correct shape\n    assert concatenated.dims['time'] == 6\n\n    # Check that the concatenated dataset has the correct values\n    expected_time = pd.date_range('2000-01-01', periods=6, freq='D')\n    assert_array_equal(concatenated['time'], expected_time)\n", "def test_concat_empty_dim_name():\n    # GH: 1427\n    # Test that a concat dimension with an empty string name is handled properly.\n    # This is an edge case that could potentially cause issues.\n\n    ds1 = Dataset()\n    ds2 = Dataset()\n    concat_dim = DataArray(\n        [1], dims=[\"\"], coords={\"\": (\"\", [1])}, name=\"\"\n    )\n    result = concat([ds1, ds2], dim=concat_dim)\n    assert result.dims[\"\"] == 2\n    assert \"\" in result.coords\n"], "sample_135": ["def test_hash():\n    b1 = Basic()\n    b2 = Basic(b1)\n    assert hash(b1) != hash(b2)\n", "def test_free_symbols():\n    x = Symbol('x')\n    a = Basic()\n    assert a.free_symbols == set()\n    assert b1.free_symbols == set()\n    assert b2.free_symbols == set()\n    assert b3.free_symbols == set()\n    assert b21.free_symbols == set()\n    assert (x + b1).free_symbols == {x}\n", "def test_evalf_subs():\n    e = S(1)/2 + sin(pi/2)\n    assert e.subs({pi: 3.0}).evalf(2)._prec == 1\n    assert e.subs({pi: 3.0}, simultaneous=True).evalf(2)._prec == 2\n    assert e.subs({pi: 3.0}, simultaneous=True).evalf(3)._prec == 3\n", "def test_xreplace():\n    from sympy.abc import x, y\n    assert (2*x).xreplace({x: y}) == 2*y\n    assert (x*y).xreplace({x*y: y}) == y\n    assert (x*y).xreplace({x: y, y: x}) == x*y\n    assert (2*x).xreplace({2*x: y}) == y\n    assert (x*(2*y)).xreplace({2*y: 1}) == x\n    assert (x*y).xreplace({x: y, x*y: y}) == y\n", "def test_doit():\n    e = 2*Integral(sin(x), (x, 0, 1)) + Integral(cos(x), (x, 0, 1))\n    assert e.doit() == 2*sin(1) + sin(1)\n"], "sample_159": ["def test_prefix_creation():\n    prefix = Prefix('test', 't', 1)\n    assert prefix.name == 'test'\n    assert prefix.abbrev == 't'\n    assert prefix.scale_factor == 10\n", "def test_prefix():\n    # Test prefix creation\n    p = Prefix('test', 't', 2)\n    assert p.name == 'test'\n    assert p.abbrev == 't'\n    assert p.scale_factor == 100\n\n    # Test prefix multiplication\n    assert kilo * 3 == 3000\n    assert kilo * S.One == 1000\n    assert kilo * x == 1000*x\n\n    # Test prefix division\n    assert kilo / 2 == 500\n    assert kilo / S.One == 1000\n    assert kilo / x == 1000/x\n\n    # Test prefix division with other prefix\n    assert kilo / kilo == S.One\n    assert kilo / (kilo * 2) == S.Half\n\n    # Test rtruediv\n    assert 2 / kilo == S.Half\n    assert S.One / kilo == S.One / 1000\n    assert x / kilo == x / 1000\n\n    # Test prefix_unit function\n    prefixed_units = prefix_unit(meter, PREFIXES)\n    assert len(prefixed_units) == len(PREFIXES)\n    for unit in prefixed_units:\n        assert unit.is_prefixed\n\n    # Test binary prefixes\n    assert kibi.scale_factor == 1024\n    assert kibi * 2 == 2048\n    assert kibi / 2 == 512\n\n    # Test prefix_unit with binary prefixes\n    prefixed_units = prefix_unit(meter, BIN_PREFIXES)\n    assert len(prefixed_units) == len(BIN_PREFIXES)\n    for unit in prefixed_units:\n        assert unit.is_prefixed\n", "def test_prefix():\n    assert kilo.scale_factor == 1000\n    assert kibi.scale_factor == 1024\n    assert kilo.name == 'kilo'\n    assert kibi.name == 'kibi'\n    assert kilo.abbrev == 'k'\n    assert kibi.abbrev == 'Y'\n    assert kilo.base == 10\n    assert kibi.base == 2\n\n    assert isinstance(kilo, Prefix)\n    assert isinstance(kibi, Prefix)\n\n    assert str(kilo) == 'k'\n    assert repr(kilo) == \"Prefix('kilo', 'k', 3)\"\n    assert repr(kibi) == \"Prefix('kibi', 'Y', 10, 2)\"\n\n    assert kilo * kibi == 1024000\n\n    assert kilo / kibi == Rational(1000, 1024)\n\n    assert kibi / kilo == Rational(1024, 1000)\n\n    assert kilo * 2 == 2000\n\n    assert kilo / 2 == 500\n\n    assert 2 * kilo == 2000\n\n    assert 2 / kilo == Rational(1, 500)\n\n    assert kilo * meter == 1000 * meter\n\n    assert kilo / meter == 1000 / meter\n\n    assert meter * kilo == 1000 * meter\n\n    assert meter / kilo == meter / 1000\n\n    assert kilo * (meter * kilo) == 1000000 * meter\n", "def test_prefix():\n    # Testing __mul__ method\n    assert kilo * 10 == 10000\n    assert kilo * S.Half == 500\n    assert kilo * Symbol('x') == kilo.scale_factor * Symbol('x')\n\n    # Testing __truediv__ method\n    assert kilo / 10 == 100\n    assert kilo / S.Half == 2000\n    assert kilo / kilo == S.One\n\n    # Testing __rtruediv__ method\n    assert 10 / kilo == S.One / 10\n    assert S.Half / kilo == S.Half / 1000\n    assert 1 / kilo == 1 / 1000\n\n    # Testing prefix_unit function\n    assert prefix_unit(meter, {'k': kilo}) == [kilo * meter]\n\n    # Testing binary prefixes\n    assert kibi.scale_factor == 1024\n\n    # Testing base attribute\n    assert kilo.base == 10\n\n    # Testing name and abbrev attributes\n    assert kilo.name == 'kilo'\n    assert kilo.abbrev == 'k'\n\n    # Testing latex representation\n    assert kilo._latex(None) == r'\\text{k}'\n\n    # Testing representation\n    assert repr(kilo) == \"Prefix('kilo', 'k', 3)\"\n\n    # Testing str\n    assert str(kilo) == 'k'\n", "def test_prefix_class():\n    p = Prefix(\"name\", \"abbr\", 2)\n    assert p.name == \"name\"\n    assert p.abbrev == \"abbr\"\n    assert p.scale_factor == 100\n    assert p.base == 10\n    assert p._latex(S) == r'\\text{abbr}'\n    assert str(p) == \"abbr\"\n    assert repr(p) == \"Prefix('name', 'abbr', 2)\"\n    assert repr(Prefix(\"name\", \"abbr\", 2, base=2)) == \"Prefix('name', 'abbr', 2, 2)\"\n"], "sample_30": ["    def test_inline_changelink(self):\n        url = reverse('admin:admin_inlines_holder_change', args=(self.holder.pk,))\n        response = self.client.get(url)\n        self.assertContains(response, INLINE_CHANGELINK_HTML)\n        self.assertNotContains(response, 'class=\"inlinechangelink\">Change</a>')\n        url = reverse('admin:admin_inlines_holder_changelist')\n        response = self.client.get(url)\n        self.assertContains(response, INLINE_CHANGELINK_HTML)\n", "def test_changelist_view_with_formset(self):\n    request = self.factory.get(reverse('admin:tests_book_changelist'))\n    ma = ModelAdmin(Book, admin_site)\n    cl = ma.get_changelist_instance(request)\n    cl.formset = ma.get_changelist_formset(request)\n    self.assertIsInstance(cl.formset, type)\n    self.assertEqual(cl.formset.model, Book)\n", "    def test_inline_formfield_for_dbfield(self):\n        request = self.factory.get('/')\n        field = Author._meta.get_field('name')\n        formfield = InlineModelAdmin.formfield_for_dbfield(field, request)\n        self.assertIsInstance(formfield, forms.CharField)\n        self.assertIsInstance(formfield.widget, forms.TextInput)\n\n        field = Author._meta.get_field('email')\n        formfield = InlineModelAdmin.formfield_for_dbfield(field, request)\n        self.assertIsInstance(formfield, forms.EmailField)\n        self.assertIsInstance(formfield.widget, forms.EmailInput)\n\n        field = Author._meta.get_field('books')\n        formfield = InlineModelAdmin.formfield_for_dbfield(field, request)\n        self.assertIsInstance(formfield, forms.ModelMultipleChoiceField)\n        self.assertIsInstance(formfield.widget, widgets.SelectMultiple)\n\n        field = Author._meta.get_field('profile')\n        formfield = InlineModelAdmin.formfield_for_dbfield(field, request)\n        self.assertIsInstance(formfield, forms.ModelChoiceField)\n        self.assertIsInstance(formfield.widget, widgets.Select)\n", "def test_modeladmin_get_exclude(self):\n    class TestAdmin(ModelAdmin):\n        exclude = ('dummy',)\n\n    request = self.factory.get('/')\n    request.user = self.superuser\n    model_admin = TestAdmin(Holder, admin_site)\n    self.assertEqual(model_admin.get_exclude(request), ('dummy',))\n\n    # Test that get_exclude can return None\n    class TestAdminNoneExclude(ModelAdmin):\n        pass\n\n    model_admin_none_exclude = TestAdminNoneExclude(Holder, admin_site)\n    self.assertIsNone(model_admin_none_exclude.get_exclude(request))\n\n    # Test that get_exclude can return a callable\n    class TestAdminCallableExclude(ModelAdmin):\n            return ('dummy',) if obj else None\n\n    model_admin_callable_exclude = TestAdminCallableExclude(Holder, admin_site)\n    self.assertEqual(model_admin_callable_exclude.get_exclude(request, self.holder), ('dummy',))\n    self.assertIsNone(model_admin_callable_exclude.get_exclude(request))\n", "    def test_inline_view_permission(self):\n        # Add permission to view, but not change, the Inner model\n        permission = Permission.objects.get(\n            codename='view_inner',\n            content_type=ContentType.objects.get_for_model(Inner)\n        )\n        self.superuser.user_permissions.add(permission)\n\n        request = self.factory.get(reverse('admin:admin_inlines_holder_changelist'))\n        request.user = self.superuser\n\n        # Make sure the holder's changelist view doesn't raise a permission error\n        admin_view = admin_site._registry[Holder].changelist_view\n        response = admin_view(request)\n        self.assertEqual(response.status_code, 200)\n\n        # Make sure the holder's change view doesn't raise a permission error\n        response = admin_view(request, object_id=self.holder.pk)\n        self.assertEqual(response.status_code, 200)\n\n        # Make sure the inner's changelist view doesn't raise a permission error\n        admin_view = admin_site._registry[Inner].changelist_view\n        response = admin_view(request)\n        self.assertEqual(response.status_code, 200)\n\n        # Make sure the inner's change view raises a permission error\n        with self.assertRaises(PermissionDenied):\n            admin_view(request, object_id=self.inner.pk)\n"], "sample_154": ["def test_lambdify_custom_function():\n    f = implemented_function(Function('f'), lambda x: x**2)\n    lam = lambdify(x, f(x))\n    assert lam(2) == 4\n\n    g = implemented_function(Function('g'), lambda x: x + 1)\n    lam = lambdify(x, g(f(x)))\n    assert lam(2) == 5\n", "def test_lambdify_lambda():\n    # Test that lambdify works with Lambda instances\n    x, y = symbols('x y')\n    lam = Lambda((x, y), x + y)\n    f = lambdify((x, y), lam(x, y), 'numpy')\n    assert f(2, 3) == 5\n", "def test_lambdify_with_scipy():\n    f = lambdify(x, cos(x), 'scipy')\n    assert f(1.0) == math.cos(1.0)\n\n    # Test numpy + scipy\n    f = lambdify(x, cos(x), ['numpy', 'scipy'])\n    assert f(1.0) == math.cos(1.0)\n\n    # Test scipy + numpy\n    f = lambdify(x, cos(x), ['scipy', 'numpy'])\n    assert f(1.0) == math.cos(1.0)\n", "def test_lambdify_with_lambda_function():\n    # Test that lambdify can handle Lambda functions\n    lam = Lambda(x, x**2)\n    f = lambdify(x, lam(x))\n    assert f(2) == 4\n\n    # Test that it also works with multiple variables\n    lam = Lambda((x, y), x + y)\n    f = lambdify((x, y), lam(x, y))\n    assert f(1, 2) == 3\n", "def test_lambdify_with_pow():\n    # This test covers a case that wasn't previously handled\n    f = lambdify(x, x**2, 'numpy')\n    assert f(1.5) == 2.25\n    assert f(2) == 4\n\n    f = lambdify(x, 2**x, 'numpy')\n    assert f(1.5) == 2**1.5\n\n    f = lambdify(x, x**x, 'numpy')\n    assert f(1.5) == 1.5**1.5\n"], "sample_18": ["    def test_recursive_relationship_constant(self):\n        model = mock.Mock(spec=models.Model)\n        model._meta.app_label = 'app_label'\n        model._meta.object_name = 'ModelName'\n        relation = resolve_relation(model, RECURSIVE_RELATIONSHIP_CONSTANT)\n        self.assertEqual(relation, model)\n", "def test_foreignkey_unique_constraint_check(self):\n    with override_settings(DEBUG=True):\n        field = models.ForeignKey(\n            models.Model, on_delete=models.CASCADE, unique=True\n        )\n        errors = field.check()\n        self.assertEqual(len(errors), 1)\n        error = errors[0]\n        self.assertIsInstance(error, DjangoWarning)\n        self.assertEqual(error.id, 'fields.W342')\n", "def test_foreignkey_deconstruct_with_swappable_setting(self):\n    class SwappableModel(models.Model):\n        pass\n\n    class OtherModel(models.Model):\n        fk = models.ForeignKey(SwappableModel, on_delete=models.CASCADE)\n\n    with self.settings(SWAPPABLES={'auth.User': 'path.to.SwappableModel'}):\n        with mock.patch.object(OtherModel._meta, 'swapped', True):\n            name, path, args, kwargs = OtherModel._meta.get_field('fk').deconstruct()\n            self.assertEqual(kwargs['to'], \"path.to.SwappableModel\")\n", "    def test_foreign_object_resolve_related_fields(self):\n        class RelatedModel(models.Model):\n            id = models.AutoField(primary_key=True)\n            unique_field = models.CharField(max_length=10, unique=True)\n            non_unique_field = models.CharField(max_length=10)\n\n        class TestModel(models.Model):\n            related = models.ForeignKey(RelatedModel, on_delete=models.CASCADE, from_fields=['unique_field'], to_fields=['unique_field'])\n\n        with self.assertRaises(ValueError):\n            TestModel._meta.get_field('related').resolve_related_fields()\n\n        with self.assertRaises(ValueError):\n            class TestModel(models.Model):\n                related = models.ForeignKey(RelatedModel, on_delete=models.CASCADE, from_fields=['unique_field', 'non_unique_field'], to_fields=['unique_field'])\n            TestModel._meta.get_field('related').resolve_related_fields()\n\n        with self.assertRaises(exceptions.FieldDoesNotExist):\n            class TestModel(models.Model):\n                related = models.ForeignKey(RelatedModel, on_delete=models.CASCADE, from_fields=['nonexistent_field'], to_fields=['unique_field'])\n            TestModel._meta.get_field('related').resolve_related_fields()\n\n        # Test that the related fields are correctly resolved\n        class TestModel(models.Model):\n            related = models.ForeignKey(RelatedModel, on_delete=models.CASCADE, from_fields=['unique_field'], to_fields=['unique_field'])\n        self.assertEqual(len(TestModel._meta.get_field('related').resolve_related_fields()), 1)\n\n        # Test that the related fields are correctly resolved when using the RECURSIVE_RELATIONSHIP_CONSTANT\n        class TestModel(models.Model):\n            related = models.ForeignKey('self', on_delete=models.CASCADE, from_fields=[RECURSIVE_RELATIONSHIP_CONSTANT], to_fields=['unique_field'])\n        self.assertEqual(len(TestModel._meta.get_field('related').resolve_related_fields()), 1)\n", "    def test_foreign_object_check_unique(self):\n        class TestModel(models.Model):\n            pass\n\n        class TestModelChild(TestModel):\n            fk = models.ForeignKey(TestModel, on_delete=models.CASCADE)\n\n        class TestModelGrandchild(TestModelChild):\n            fk = models.ForeignKey(TestModel, on_delete=models.CASCADE)\n\n        with override_settings(DEBUG=True):\n            with mock.patch('django.db.models.FieldWarning', DjangoWarning) as mock_warning:\n                TestModelGrandchild._meta.get_field('fk').check()\n                mock_warning.assert_called_once_with(\n                    'Setting unique=True on a ForeignKey has the same effect as using a OneToOneField.',\n                    hint='ForeignKey(unique=True) is usually better served by a OneToOneField.',\n                    obj=TestModelGrandchild._meta.get_field('fk'),\n                    id='fields.W342',\n                )\n"], "sample_58": ["def test_settings_to_cmd_args_env(self):\n    settings_dict = {\n        \"HOST\": \"localhost\",\n        \"PORT\": 5432,\n        \"NAME\": \"mydatabase\",\n        \"USER\": \"myuser\",\n        \"PASSWORD\": \"mypassword\",\n        \"OPTIONS\": {\n            \"passfile\": \"/path/to/passfile\",\n            \"service\": \"myservice\",\n            \"sslmode\": \"require\",\n            \"sslrootcert\": \"/path/to/sslrootcert\",\n            \"sslcert\": \"/path/to/sslcert\",\n            \"sslkey\": \"/path/to/sslkey\",\n        },\n    }\n    parameters = [\"-c\", \"SELECT 1;\"]\n    args, env = self.settings_to_cmd_args_env(settings_dict, parameters)\n    self.assertEqual(args, [\n        \"psql\",\n        \"-U\", \"myuser\",\n        \"-h\", \"localhost\",\n        \"-p\", \"5432\",\n        \"-c\", \"SELECT 1;\",\n        \"mydatabase\",\n    ])\n    self.assertEqual(env, {\n        \"PGPASSWORD\": \"mypassword\",\n        \"PGSERVICE\": \"myservice\",\n        \"PGSSLMODE\": \"require\",\n        \"PGSSLROOTCERT\": \"/path/to/sslrootcert\",\n        \"PGSSLCERT\": \"/path/to/sslcert\",\n        \"PGSSLKEY\": \"/path/to/sslkey\",\n        \"PGPASSFILE\": \"/path/to/passfile\",\n    })\n", "    def test_runshell_sigint_handler_restored(self):\n        old_sigint_handler = signal.getsignal(signal.SIGINT)\n        with mock.patch.object(signal, 'signal') as mock_signal:\n            mock_signal.SIGINT = signal.SIGINT\n            mock_signal.SIG_IGN = signal.SIG_IGN\n            mock_signal.signal.side_effect = lambda sig, handler: handler\n            client = DatabaseClient()\n            client.runshell([])\n            self.assertEqual(mock_signal.signal.call_count, 2)\n            mock_signal.signal.assert_any_call(signal.SIGINT, signal.SIG_IGN)\n            mock_signal.signal.assert_any_call(signal.SIGINT, old_sigint_handler)\n", "    def test_settings_to_cmd_args_env_with_options(self):\n        settings_dict = {\n            \"HOST\": \"localhost\",\n            \"PORT\": 5432,\n            \"NAME\": \"testdb\",\n            \"USER\": \"testuser\",\n            \"PASSWORD\": \"testpassword\",\n            \"OPTIONS\": {\n                \"passfile\": \"/path/to/passfile\",\n                \"service\": \"testservice\",\n                \"sslmode\": \"require\",\n                \"sslrootcert\": \"/path/to/sslrootcert\",\n                \"sslcert\": \"/path/to/sslcert\",\n                \"sslkey\": \"/path/to/sslkey\",\n            },\n        }\n        parameters = [\"-c\", \"test_command\"]\n        args, env = self.settings_to_cmd_args_env(settings_dict, parameters)\n        expected_args = [\n            \"psql\",\n            \"-U\",\n            \"testuser\",\n            \"-h\",\n            \"localhost\",\n            \"-p\",\n            \"5432\",\n            \"-c\",\n            \"test_command\",\n            \"testdb\",\n        ]\n        self.assertEqual(args, expected_args)\n        expected_env = {\n            \"PGPASSWORD\": \"testpassword\",\n            \"PGSERVICE\": \"testservice\",\n            \"PGSSLMODE\": \"require\",\n            \"PGSSLROOTCERT\": \"/path/to/sslrootcert\",\n            \"PGSSLCERT\": \"/path/to/sslcert\",\n            \"PGSSLKEY\": \"/path/to/sslkey\",\n            \"PGPASSFILE\": \"/path/to/passfile\",\n        }\n        self.assertEqual(env, expected_env)\n", "    def test_runshell(self):\n        mock_popen = mock.Mock()\n        mock_popen.wait = mock.Mock(return_value=0)\n        with mock.patch('subprocess.Popen', return_value=mock_popen):\n            with mock.patch('signal.getsignal', return_value=None):\n                with mock.patch('signal.signal'):\n                    DatabaseClient().runshell([])\n", "def test_runshell_restores_sigint_handler(self):\n    # Test that the original SIGINT handler is restored after running shell\n    original_sigint_handler = signal.getsignal(signal.SIGINT)\n    mock_sigint_handler = mock.Mock()\n    signal.signal(signal.SIGINT, mock_sigint_handler)\n\n    with mock.patch.object(DatabaseClient, 'runshell') as mock_runshell:\n        client = DatabaseClient()\n        client.runshell([])\n\n    # Verify that the original SIGINT handler was restored\n    self.assertEqual(signal.getsignal(signal.SIGINT), mock_sigint_handler)\n    signal.signal(signal.SIGINT, original_sigint_handler)\n"], "sample_73": ["def test_offsetimage():\n    fig, ax = plt.subplots()\n    arr = np.random.rand(10, 10)\n    offsetbox = OffsetImage(arr, zoom=2)\n    ab = AnnotationBbox(offsetbox, (0.5, 0.5), xycoords='data',\n                        xytext=(0.8, 0.8), textcoords='data',\n                        arrowprops=dict(arrowstyle=\"->\"))\n    ax.add_artist(ab)\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n", "def test_offsetbox_textarea():\n    fig, ax = plt.subplots()\n    area = TextArea(\"TextArea\")\n    ax.add_artist(area)\n    area.set_offset((0.5, 0.5))\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n", "def test_AnnotationBbox():\n    fig, ax = plt.subplots()\n\n    offsetbox = AnchoredOffsetbox(\n        loc='upper center',\n        child=mpatches.Circle((0.5, 0.5), 0.2, fc='blue'),\n        pad=0.,\n        frameon=False,\n        bbox_to_anchor=(0.5, 0.5),\n        bbox_transform=ax.transAxes,\n    )\n    ab = AnnotationBbox(offsetbox, (0.5, 0.5),\n                        xybox=(0.5, 0.5),\n                        xycoords='data',\n                        boxcoords=\"offset points\",\n                        frameon=False,\n                        box_alignment=(.5, .5),\n                        arrowprops=dict(arrowstyle=\"->\"))\n    ax.add_artist(ab)\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect('equal')\n", "def test_padded_box():\n    fig, ax = plt.subplots()\n    box = PaddedBox(OffsetBox())\n    box.add_artist(mpatches.Circle((0.5, 0.5), 0.1))\n    ax.add_artist(box)\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    assert_allclose(box.get_offset(), (0.0, 0.0))\n    assert_allclose(box.get_extent(), (0.2, 0.2, 0.0, 0.0))\n\n    box.set_offset((0.1, 0.1))\n    assert_allclose(box.get_offset(), (0.1, 0.1))\n    assert_allclose(box.get_extent(), (0.2, 0.2, 0.1, 0.1))\n\n    box.set_width(0.5)\n    box.set_height(0.5)\n    assert_allclose(box.get_offset(), (0.1, 0.1))\n    assert_allclose(box.get_extent(), (0.5, 0.5, 0.1, 0.1))\n", "def test_packer():\n    fig, ax = plt.subplots()\n    box1 = TextArea(\"Box 1\")\n    box2 = TextArea(\"Box 2\", multilinebaseline=True)\n    box3 = TextArea(\"Box 3\\nwith multiple lines\")\n\n    packer = VPacker(children=[box1, box2, box3], align=\"center\",\n                     pad=0, sep=5)\n\n    anchored_box = AnchoredOffsetbox(loc='upper right', child=packer,\n                                     pad=0., frameon=False,\n                                     bbox_to_anchor=(0., 0., 1., 1.),\n                                     borderpad=0., bbox_transform=ax.transAxes)\n\n    ax.add_artist(anchored_box)\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n"], "sample_121": ["def test_transpositions():\n    a = Permutation([[1, 3, 2]])\n    t = a.transpositions()\n    assert t == [(1, 3), (1, 2)]\n    p = rmul(*[Permutation([ti], size=4) for ti in t])\n    assert p.cyclic_form == a.cyclic_form\n    p = Permutation(rmul(*[Permutation([ti], size=4) for ti in t]))\n    assert p.cyclic_form == a.cyclic_form\n    a = Permutation([[1, 3, 2], [0, 4]])\n    t = a.transpositions()\n    assert t == [(0, 4), (1, 3), (1, 2)]\n    p = rmul(*[Permutation([ti], size=5) for ti in t])\n    assert p.cyclic_form == a.cyclic_form\n", "def test_af_rmuln():\n    # Check _af_rmuln\n    a = [2, 0, 3, 1]\n    b = [3, 1, 0, 2]\n    c = [1, 3, 2, 0]\n    d = [2, 0, 3, 1]\n    assert _af_rmuln(a, b, c) == [3, 2, 0, 1]\n    assert _af_rmuln(a, b, c, d) == [0, 1, 2, 3]\n    a = []\n    b = [1, 0, 2]\n    c = [0, 2, 1]\n    assert _af_rmuln(a, b, c) == [0, 2, 1]\n    a = [0, 2, 1]\n    b = []\n    c = [1, 0, 2]\n    assert _af_rmuln(a, b, c) == [1, 0, 2]\n    a = [2, 1, 0]\n    b = [1, 0, 2]\n    c = []\n    assert _af_rmuln(a, b, c) == [2, 1, 0]\n", "def test_cycle():\n    assert Cycle(1, 2, 3) == Cycle(2, 3, 1) == Cycle(3, 1, 2)\n    c = Cycle(1, 2)(2, 3)\n    assert c == Cycle(1, 3, 2)\n    c = Cycle(1, 2)\n    assert c.list() == [0, 2, 1]\n    c = Cycle(1, 2)(2, 3)(4, 5)\n    assert c.list() == [0, 2, 1, 4, 5, 3]\n    c = Cycle(1, 2)(2, 3)(3, 1)\n    assert c.list() == [0, 1, 2, 3]\n    c = Cycle(1, 2, 4, 10)(4, 5)\n    assert str(c) == \"(1 5 4 10)\"\n    c = Cycle(1, 2)(4)(5)(10)\n    assert str(c) == \"(1 2)(10)\"\n    c = Cycle(1, 2, 4)(5, 6)\n    assert str(c) == \"(1 2 4)(5 6)\"\n    c = Cycle(1, 2)(2, 3)\n    assert Permutation(c).transpositions() == [(1, 3), (1, 2)]\n    c = Cycle(1, 2, 4, 10)\n    assert Permutation(c.list()).transpositions() == [(1, 10), (1, 4), (1, 2)]\n", "def test_cycles():\n    c1 = Cycle(1, 2)(3, 4)\n    c2 = Cycle(1, 2)(3, 4)\n    assert c1 == c2\n    c3 = Cycle(1, 2)(3, 4)(2, 1)\n    assert c1 != c3\n    c4 = Cycle(2, 1)(4, 3)\n    assert c1 == c4\n    c5 = Cycle(3, 4)(1, 2)\n    assert c1 != c5\n", "def test_cycle():\n    c = Cycle()\n    assert c.list() == []\n    assert c.size == 0\n    assert c == Cycle()\n    assert c() == c\n    assert c(1, 2) == Cycle(1, 2)\n    assert c(1, 2)(3, 4) == Cycle(1, 2)(3, 4)\n    assert Cycle(1, 2)(3, 4) == Cycle(1, 2)(3, 4)\n    c = Cycle(1, 2)\n    assert c() == c\n    assert c(1, 2) == Cycle()\n    assert c(1, 2)(3, 4) == Cycle(3, 4)\n    c = Cycle(1, 2, 4)(2, 3)\n    assert c == Cycle(1, 3, 4, 2)\n    assert c() == c\n    assert c(1, 2) == Cycle(3, 4)\n    assert c(1, 2)(3, 4) == Cycle()\n    assert c(3, 4)(1, 2) == Cycle()\n    assert c(3, 4, 1, 2) == Cycle()\n    c = Cycle(1, 2)(4, 5)\n    assert c == Cycle(1, 2)(4, 5)\n    c = Cycle(3, 1, 2)\n    assert c == Cycle(1, 2, 3)\n    assert c(1, 4) == Cycle(2, 3)(1, 4)\n    c = Cycle(4, 1, 2, 3, 5)\n    assert c == Cycle(4, 1, 2, 3, 5)\n    assert c(4, 3) == Cycle(4, 1, 3, 2, 5)\n    c = Cycle(3, 4, 5)\n    assert c(1, 2) == Cycle(3, 4, 5)(1, 2)\n    assert c(1, 2)(3, 5) == Cycle(1, 2)(4, 5)\n    c = Cycle(1, 3)(3, 4)(1, 2, 4)(1, 3)\n   "], "sample_158": ["def test_get_dimensional_expr():\n    x, y = symbols('x y')\n    us = SI\n    assert us.get_dimensional_expr(x + 2*y) == length\n    assert us.get_dimensional_expr(2*x + y) == length\n    assert us.get_dimensional_expr(x**2) == length**2\n    assert us.get_dimensional_expr(x*y) == length**2\n    assert us.get_dimensional_expr(x/y) == S.One\n    assert us.get_dimensional_expr(x**2 / y**2) == S.One\n    assert us.get_dimensional_expr(2*x**2 + 3*y**2) == length**2\n    assert us.get_dimensional_expr(x.diff(x)) == S.One / length\n    assert us.get_dimensional_expr(diff(y**2, y)) == length\n    assert us.get_dimensional_expr(integrate(x, x)) == length**2\n    assert us.get_dimensional_expr(log(x)) == S.One\n    assert us.get_dimensional_expr(exp(x)) == S.One\n    assert us.get_dimensional_expr(sqrt(x)) == length**(S.Half)\n    assert us.get_dimensional_expr(sin(x)) == S.One\n    assert us.get_dimensional_expr(Abs(x)) == length\n    assert us.get_dimensional_expr(meter) == length\n    assert us.get_dimensional_expr(volt) == energy / charge\n    assert us.get_dimensional_expr(ohm) == energy * time / charge**2\n", "def test_get_dimensional_expr():\n    from sympy.physics.units.quantities import Quantity\n    from sympy.physics.units.systems import UnitSystem\n    from sympy.physics.units.definitions.dimension_definitions import length, time\n    from sympy import symbols\n\n    x, y = symbols('x y')\n\n    # Test a simple expression\n    expr = 2 * meter / second\n    expected = 2 * length / time\n    assert SI.get_dimensional_expr(expr) == expected\n\n    # Test a more complex expression\n    expr = (2 * meter / second) + (3 * kilometer / hour)\n    expected = 2 * length / time\n    assert SI.get_dimensional_expr(expr) == expected\n\n    # Test an expression with a derivative\n    expr = diff(x, y)\n    expected = 1 / (length ** 2)\n    assert SI.get_dimensional_expr(expr) == expected\n\n    # Test an expression with a function\n    expr = sin(x / y)\n    expected = 1\n    assert SI.get_dimensional_expr(expr) == expected\n\n    # Test an expression with a physical constant\n    expr = speed_of_light\n    expected = length / time\n    assert SI.get_dimensional_expr(expr) == expected\n\n    # Test an expression with a dimension\n    expr = length\n    expected = length\n    assert SI.get_dimensional_expr(expr) == expected\n\n    # Test an expression with an unknown unit\n    expr = Quantity('unknown_unit')\n    expected = 1\n    assert SI.get_dimensional_expr(expr) == expected\n", "def test_get_dimensional_expr():\n    t = Symbol('t')\n    x = Symbol('x')\n    dim_system = SI.get_dimension_system()\n    expr = 5 * speed_of_light * t\n    assert SI.get_dimensional_expr(expr) == length.name\n    expr = 3 * meter * t**2 / (2 * second)\n    assert SI.get_dimensional_expr(expr) == length.name\n    expr = 4 * joule / (2 * meter)\n    assert SI.get_dimensional_expr(expr) == energy.name / length.name\n    expr = 5 * kilogram * (meter / second)**2\n    assert SI.get_dimensional_expr(expr) == energy.name\n    expr = diff(x**2, x)\n    assert SI.get_dimensional_expr(expr) == length.name\n    expr = integrate(x**2, x)\n    assert SI.get_dimensional_expr(expr) == length.name**3\n    expr = sin(x)\n    assert SI.get_dimensional_expr(expr) == 1\n    expr = sqrt(x)\n    assert SI.get_dimensional_expr(expr) == length.name**(Rational(1, 2))\n    expr = exp(x)\n    assert SI.get_dimensional_expr(expr) == 1\n    expr = log(x)\n    assert SI.get_dimensional_expr(expr) == 1\n    expr = Abs(x)\n    assert SI.get_dimensional_expr(expr) == length.name\n", "def test_UnitSystem_get_units_non_prefixed():\n    # Create a UnitSystem with some units\n    length = Dimension(name=\"length\")\n    time = Dimension(name=\"time\")\n    velocity = length / time\n    meter = Quantity(\"meter\", abbrev=\"m\", dimension=length, scale_factor=1)\n    second = Quantity(\"second\", abbrev=\"s\", dimension=time, scale_factor=1)\n    meter_per_second = Quantity(\"meter_per_second\", abbrev=\"m/s\", dimension=velocity, scale_factor=1)\n    kilometer = Quantity(\"kilometer\", abbrev=\"km\", dimension=length, scale_factor=1000)\n    system = UnitSystem(base_units=(meter, second), units=(meter_per_second, kilometer))\n\n    # Test that only the unprefixed units are returned\n    assert system.get_units_non_prefixed() == {meter, second, meter_per_second}\n", "def test_unit_system():\n    # test the creation of a unit system\n    us = UnitSystem((length, time, mass, temperature), name=\"SI\")\n    assert us.name == \"SI\"\n    assert us.dim == 4\n\n    # test the addition of a derived unit\n    us._derived_units[energy] = Quantity(\"joule\", length**2*mass/time**2)\n    assert us.derived_units[energy].name == \"joule\"\n\n    # test the extension of a unit system\n    us2 = us.extend((charge,))\n    assert us2.dim == 5\n    assert charge in us2._base_units\n\n    # test the get_dimensional_expr method\n    x = symbols('x')\n    expr = x**2 + 2*x + 1\n    assert us.get_dimensional_expr(expr) == S.One\n\n    # test the get_dimensional_expr method with a physical quantity\n    expr = joule / (kilogram * meter**2 / second**2)\n    assert us.get_dimensional_expr(expr) == S.One\n\n    # test the _collect_factor_and_dimension method\n    expr = 2*joule + 3*kilo*meter**2 / second**2\n    factor, dim = us._collect_factor_and_dimension(expr)\n    assert factor == 5\n    assert dim == energy\n\n    # test the get_units_non_prefixed method\n    assert us.get_units_non_prefixed() == set(us._base_units + [us._derived_units[energy]])\n\n    # test the get_dimension_system method\n    assert isinstance(us.get_dimension_system(), Dimension)\n\n    # test the get_quantity_dimension method\n    assert us.get_quantity_dimension(kilo) == length\n\n    # test the get_quantity_scale_factor method\n    assert us.get_quantity_scale_factor(kilo) == 1000\n\n    # test the get_unit_system method\n    assert UnitSystem.get_unit_system(\"SI\") == us\n\n    # test the get_default_unit_system method\n    assert UnitSystem.get_default_unit_system().name == \"SI\"\n"], "sample_59": ["    def test_formset_factory(self):\n        CustomFormset = formset_factory(CustomKwargForm, extra=5)\n        formset = CustomFormset(custom_kwarg=\"test\")\n        self.assertEqual(len(formset.forms), 5)\n        for form in formset.forms:\n            self.assertEqual(form.custom_kwarg, \"test\")\n", "    def test_formset_min_max_num_validation(self):\n        FormSet = formset_factory(Choice, min_num=2, max_num=2)\n        formset = FormSet([\n            {'choice': 'A', 'votes': 1},\n            {'choice': 'B', 'votes': 2},\n        ])\n        self.assertTrue(formset.is_valid())\n        self.assertEqual(len(formset.errors), 0)\n\n        FormSet = formset_factory(Choice, min_num=3, max_num=3)\n        formset = FormSet([\n            {'choice': 'A', 'votes': 1},\n            {'choice': 'B', 'votes': 2},\n        ])\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(len(formset.errors), 1)\n\n        FormSet = formset_factory(Choice, min_num=1, max_num=1)\n        formset = FormSet([\n            {'choice': 'A', 'votes': 1},\n            {'choice': 'B', 'votes': 2},\n        ])\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(len(formset.errors), 1)\n", "    def test_management_form_validation(self):\n        formset = self.make_choiceformset(\n            formset_data=[(\"Choice 1\", \"10\"), (\"Choice 2\", \"20\")],\n            total_forms=2,\n            initial_forms=2,\n            max_num_forms=1,\n            min_num_forms=1,\n        )\n        with self.assertRaisesMessage(\n            ValidationError,\n            \"ManagementForm data is missing or has been tampered with. Missing fields: choices-INITIAL_FORMS, choices-TOTAL_FORMS. You may need to file a bug report if the issue persists.\",\n        ):\n            formset.management_form.clean()\n", "    def test_add_fields(self):\n        formset = ChoiceFormSet()\n        form = Choice()\n        formset.add_fields(form, 0)\n        self.assertEqual(form.fields, {\"choice\": form.fields[\"choice\"], \"votes\": form.fields[\"votes\"]})\n\n        formset = ChoiceFormSet(can_order=True)\n        form = Choice()\n        formset.add_fields(form, 0)\n        expected_fields = {\"choice\": form.fields[\"choice\"], \"votes\": form.fields[\"votes\"], \"ORDER\": form.fields[\"ORDER\"]}\n        self.assertEqual(form.fields, expected_fields)\n\n        formset = ChoiceFormSet(can_delete=True)\n        form = Choice()\n        formset.add_fields(form, 0)\n        expected_fields = {\"choice\": form.fields[\"choice\"], \"votes\": form.fields[\"votes\"], \"DELETE\": form.fields[\"DELETE\"]}\n        self.assertEqual(form.fields, expected_fields)\n", "    def test_baseformset_get_context(self):\n        formset = ChoiceFormSet()\n        context = formset.get_context()\n        self.assertEqual(context, {\"formset\": formset})\n"], "sample_60": ["    def test_serializer_factory_with_promises(self):\n        value = SimpleLazyObject(lambda: 'Hello, world!')\n        serializer = serializer_factory(value)\n        self.assertIsInstance(serializer, BaseSimpleSerializer)\n        serialized_value, imports = serializer.serialize()\n        self.assertEqual(serialized_value, \"'Hello, world!'\")\n        self.assertEqual(imports, set())\n", "    def test_functools_partial_serializer(self):\n            return x + y\n\n        partial = functools.partial(add, 1, 2)\n        serializer = serializer_factory(partial)\n        serialized, imports = serializer.serialize()\n        self.assertEqual(serialized, \"functools.partial(add, 1, 2)\")\n        self.assertEqual(imports, {\"import functools\"})\n\n            return x\n\n        partial_method = functools.partialmethod(test_func, 1)\n        serializer = serializer_factory(partial_method)\n        serialized, imports = serializer.serialize()\n        self.assertEqual(serialized, \"functools.partialmethod(test_func, 1)\")\n        self.assertEqual(imports, {\"import functools\"})\n", "    def test_serialization_of_lazy_object(self):\n        lazy_object = SimpleLazyObject(lambda: \"Hello, World!\")\n        serializer = serializer_factory(lazy_object)\n        serialized, imports = serializer.serialize()\n        self.assertEqual(serialized, repr(\"Hello, World!\"))\n        self.assertEqual(imports, set())\n", "def test_serializer_factory_coverage(self):\n    # Test serializer_factory with various types\n    test_cases = [\n        (datetime.datetime(2022, 1, 1), DatetimeDatetimeSerializer),\n        (datetime.date(2022, 1, 1), DateTimeSerializer),\n        (datetime.timedelta(days=1), DateTimeSerializer),\n        (datetime.time(12, 0, 0), DateTimeSerializer),\n        (decimal.Decimal('1.2'), DecimalSerializer),\n        (functools.partial(lambda x: x), FunctoolsPartialSerializer),\n        (functools.partialmethod(lambda x: x), FunctoolsPartialSerializer),\n        (TextEnum.A, EnumSerializer),\n        (TextTranslatedEnum.A, EnumSerializer),\n        (BinaryEnum.A, EnumSerializer),\n        (IntEnum.A, EnumSerializer),\n        (IntFlagEnum.A, EnumSerializer),\n        (SettingsReference(\"SETTING_NAME\"), SettingsReferenceSerializer),\n        (uuid.UUID('00000000-0000-0000-0000-000000000000'), UUIDSerializer),\n        (pathlib.Path('/path/to/file'), PathSerializer),\n        (os.PathLike('/path/to/file'), PathLikeSerializer),\n        (re.compile('pattern'), RegexSerializer),\n        (OperationWriterTests, TypeSerializer),\n        (DeconstructibleInstances(), DeconstructableSerializer),\n        (Money('1.2'), DeconstructableSerializer),\n        (TestModel1(), DeconstructableSerializer),\n        (migrations.CreateModel(name='TestModel'), OperationSerializer),\n    ]\n    \n    for value, expected_serializer in test_cases:\n        serializer = serializer_factory(value)\n        self.assertIsInstance(serializer, expected_serializer)\n", "    def test_float_serializer(self):\n        serializer = FloatSerializer(float('inf'))\n        self.assertEqual(serializer.serialize(), ('float(\"inf\")', set()))\n"], "sample_102": ["def test_isolation_forest_sparse_input():\n    # Test that the isolation forest works with sparse input data\n    X_sparse = csc_matrix(iris.data)\n    y_sparse = iris.target\n    X_train_sparse, X_test_sparse, y_train_sparse, y_test_sparse = train_test_split(\n        X_sparse, y_sparse, test_size=0.5, random_state=rng\n    )\n\n    iforest_sparse = IsolationForest(random_state=rng).fit(X_train_sparse)\n    assert_array_equal(iforest_sparse.predict(X_test_sparse), iforest_sparse.predict(X_test_sparse.toarray()))\n\n    # Test with csr_matrix as well\n    X_sparse_csr = csr_matrix(iris.data)\n    iforest_sparse_csr = IsolationForest(random_state=rng).fit(X_train_sparse.toarray())\n    assert_array_equal(iforest_sparse_csr.predict(X_test_sparse_csr), iforest_sparse_csr.predict(X_test_sparse_csr.toarray()))\n", "def test_isolation_forest_contamination_auto():\n    X, y = iris.data, iris.target\n    contamination_values = [0.1, 0.2, 0.3]\n    for contamination in contamination_values:\n        isolation_forest = IsolationForest(contamination=contamination, random_state=rng)\n        isolation_forest.fit(X)\n        scores = isolation_forest.decision_function(X)\n        assert_array_almost_equal(np.percentile(scores, 100*contamination), 0)\n        isolation_forest = IsolationForest(contamination='auto', random_state=rng)\n        isolation_forest.fit(X)\n        scores = isolation_forest.decision_function(X)\n        assert_array_almost_equal(np.percentile(scores, 50), 0)\n", "def test_isolation_forest_sparse_matrices():\n    \"\"\"Check that IsolationForest works with sparse input data\"\"\"\n    # Test with csr_matrix\n    X_sparse = csr_matrix(iris.data)\n    isoforest = IsolationForest(n_estimators=10, random_state=rng)\n    isoforest.fit(X_sparse)\n    assert_array_almost_equal(isoforest.decision_function(X_sparse).shape, \n                              (iris.data.shape[0],))\n    assert_array_almost_equal(isoforest.predict(X_sparse).shape, \n                              (iris.data.shape[0],))\n\n    # Test with csc_matrix\n    X_sparse = csc_matrix(iris.data)\n    isoforest = IsolationForest(n_estimators=10, random_state=rng)\n    isoforest.fit(X_sparse)\n    assert_array_almost_equal(isoforest.decision_function(X_sparse).shape, \n                              (iris.data.shape[0],))\n    assert_array_almost_equal(isoforest.predict(X_sparse).shape, \n                              (iris.data.shape[0],))\n\n    # Test with sparse matrix containing zeros\n    X_sparse = csr_matrix(np.hstack((iris.data, np.zeros((iris.data.shape[0], 1)))))\n    isoforest = IsolationForest(n_estimators=10, random_state=rng)\n    isoforest.fit(X_sparse)\n    assert_array_almost_equal(isoforest.decision_function(X_sparse).shape, \n                              (iris.data.shape[0],))\n    assert_array_almost_equal(isoforest.predict(X_sparse).shape, \n                              (iris.data.shape[0],))\n", "def test_predict_input_type_error():\n    \"\"\"Check that IsolationForest raises a ValueError on non-supported input types.\"\"\"\n    X = [[1, 2], [1, 4], [1, 0], [10, 2]]\n    y = [1, 1, 1, 0]\n\n    # int16 is not supported by IsolationForest\n    X_int16 = np.array(X, dtype=np.int16)\n    with pytest.raises(ValueError):\n        IsolationForest().fit(X_int16, y)\n\n    # datetime64 is not supported by IsolationForest\n    X_datetime = np.array(X, dtype=np.datetime64)\n    with pytest.raises(ValueError):\n        IsolationForest().fit(X_datetime, y)\n\n    # timedelta64 is not supported by IsolationForest\n    X_timedelta = np.array(X, dtype=np.timedelta64)\n    with pytest.raises(ValueError):\n        IsolationForest().fit(X_timedelta, y)\n\n    # object is not supported by IsolationForest\n    X_object = np.array(X, dtype=object)\n    with pytest.raises(ValueError):\n        IsolationForest().fit(X_object, y)\n", "def test_isolation_forest_sparse_matrices():\n    # Isolation Forest should work with sparse matrices\n    iris_csr = csr_matrix(iris.data)\n    iris_csc = csc_matrix(iris.data)\n\n    # fit the model\n    iso = IsolationForest(n_estimators=5, random_state=rng)\n    iso.fit(iris_csr)\n\n    # check that the model has been fitted\n    assert hasattr(iso, \"offset_\")\n    assert hasattr(iso, \"estimators_\")\n\n    # check prediction with csr and csc matrices\n    iso.predict(iris_csr)\n    iso.predict(iris_csc)\n\n    # check that the anomaly score has been computed correctly\n    assert_array_almost_equal(iso.score_samples(iris_csr),\n                              iso.score_samples(iris_csc))\n"], "sample_109": ["def test_leave_one_group_out():\n    # test group-less data\n    logo = LeaveOneGroupOut()\n    assert_raise_message(ValueError, \"The 'groups' parameter should not be None.\",\n                        logo.split, X=np.arange(10), y=np.arange(10))\n\n    # test non-unique groups\n    groups = np.array([1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3])\n    logo = LeaveOneGroupOut()\n    assert len(list(logo.split(X=np.arange(12), y=np.arange(12), groups=groups))) == 3\n    assert logo.get_n_splits(X=np.arange(12), y=np.arange(12), groups=groups) == 3\n    assert logo.get_n_splits(groups=groups) == 3\n    assert logo.get_n_splits() == 3\n\n    # test unique groups\n    groups = np.arange(12)\n    logo = LeaveOneGroupOut()\n    assert len(list(logo.split(X=np.arange(12), y=np.arange(12), groups=groups))) == 12\n    assert logo.get_n_splits(X=np.arange(12), y=np.arange(12), groups=groups) == 12\n    assert logo.get_n_splits(groups=groups) == 12\n    assert logo.get_n_splits() == 12\n", "def test_leave_p_groups_out():\n    # test LeavePGroupsOut\n    X = np.ones(12)\n    y = np.arange(12)\n    groups = np.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4])\n    lpgo = LeavePGroupsOut(n_groups=2)\n    assert lpgo.get_n_splits(X, y, groups) == 6\n    cv = list(lpgo.split(X, y, groups))\n    assert len(cv) == 6\n\n    # check that the returned groups are distinct\n    assert_array_equal(np.unique(groups[cv[0][1]]), [1, 2])\n    assert_array_equal(np.unique(groups[cv[1][1]]), [1, 3])\n    assert_array_equal(np.unique(groups[cv[2][1]]), [1, 4])\n    assert_array_equal(np.unique(groups[cv[3][1]]), [2, 3])\n    assert_array_equal(np.unique(groups[cv[4][1]]), [2, 4])\n    assert_array_equal(np.unique(groups[cv[5][1]]), [3, 4])\n\n    # check that the train/test sizes are correct\n    for train, test in lpgo.split(X, y, groups):\n        assert len(test) == 8\n        assert len(train) == 4\n\n    # test LeavePGroupsOut raises an error when n_groups is larger than\n    # the number of groups\n    with pytest.raises(ValueError):\n        LeavePGroupsOut(n_groups=5).get_n_splits(X, y, groups)\n\n    # test LeavePGroupsOut raises an error when n_groups is larger than\n    # or equal to the number of unique groups\n    with pytest.raises(ValueError):\n        LeavePGroupsOut(n_groups=4).get_n_splits(X, y, groups)\n\n    # test LeavePGroupsOut raises an error when groups is None\n    with pytest.raises(ValueError):\n        LeavePGroupsOut().get_n_splits(X, y, None)\n", "def test_predefinedsplit():\n    # test string input\n    test_fold = np.array(['a', 'a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'c', 'c', 'c'])\n    predefined = PredefinedSplit(test_fold)\n    assert predefined.get_n_splits() == 3\n    assert_array_equal(predefined.unique_folds, np.array(['a', 'b', 'c']))\n\n    # test int input\n    test_fold = np.array([1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3])\n    predefined = PredefinedSplit(test_fold)\n    assert predefined.get_n_splits() == 3\n    assert_array_equal(predefined.unique_folds, np.array([1, 2, 3]))\n\n    # test input with all -1 values\n    test_fold = np.array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n    predefined = PredefinedSplit(test_fold)\n    assert predefined.get_n_splits() == 0\n\n    # test input with only one unique value\n    test_fold = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n    predefined = PredefinedSplit(test_fold)\n    assert predefined.get_n_splits() == 1\n\n    # test folds with -1 values\n    test_fold = np.array([-1, 1, -1, 1, 1, 2, 2, 3, 3, 3, 3, 3])\n    predefined = PredefinedSplit(test_fold)\n    assert predefined.get_n_splits() == 3\n    assert_array_equal(predefined.unique_folds, np.array([1, 2, 3]))\n\n    # test_predefinedsplit_arraylike\n    test_fold = [1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3]\n    predefined = PredefinedSplit(test_fold)\n    assert predefined.get_n_splits() == 3\n    assert_array_equal(predefined.unique_folds, np.array([1, 2, 3", "def test_leave_one_group_out():\n    logo = LeaveOneGroupOut()\n    for groups in test_groups:\n        groups = np.array(groups)\n        for X in [np.ones((len(groups), 3)), np.ones((len(groups), 3, 2))]:\n            for y in [None, np.arange(len(groups))]:\n                splits = list(logo.split(X, y, groups))\n                assert len(splits) == logo.get_n_splits(X, y, groups)\n                for train, test in splits:\n                    assert len(np.unique(groups[test])) == 1\n                    assert len(train) + len(test) == len(groups)\n\n                # Check that the index arrays are not views on the data\n                assert np.may_share_memory(splits[0][0], X) == False\n                assert np.may_share_memory(splits[0][1], X) == False\n\n                # Check that the index arrays are the same when y is None\n                splits_no_y = list(logo.split(X, groups=groups))\n                assert_array_equal(splits, splits_no_y)\n\n                # check that groups parameter is always required\n                with pytest.raises(ValueError,\n                                   match=\"The 'groups' parameter should not \"\n                                         \"be None.\"):\n                    list(logo.split(X, y=y))\n\n            # check that groups parameter is always required for n_splits\n            with pytest.raises(ValueError,\n                               match=\"The 'groups' parameter should not be \"\n                                     \"None.\"):\n                logo.get_n_splits(X, y=y)\n", "def test_leave_p_groups_out():\n    # Ensure that LeavePGroupsOut raises an error with n_groups equal to\n    # the number of unique groups\n    groups = np.array([1, 2, 3])\n    lpgo = LeavePGroupsOut(n_groups=3)\n    with pytest.raises(ValueError):\n        lpgo.split(X=np.ones((3, 3)), y=np.ones(3), groups=groups)\n\n    # Ensure that LeavePGroupsOut raises an error with n_groups larger\n    # than the number of unique groups\n    lpgo = LeavePGroupsOut(n_groups=4)\n    with pytest.raises(ValueError):\n        lpgo.split(X=np.ones((3, 3)), y=np.ones(3), groups=groups)\n\n    # Ensure that LeavePGroupsOut is not able to generate more splits than\n    # the number of unique combinations of groups\n    groups = np.array([1, 1, 2, 2, 2, 3, 3, 3, 3])\n    lpgo = LeavePGroupsOut(n_groups=3)\n    n_splits = lpgo.get_n_splits(groups=groups)\n    assert lpgo.get_n_splits(groups=groups) == 1\n\n    # Ensure that LeavePGroupsOut is able to generate the correct number\n    # of splits\n    groups = np.array([1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4])\n    lpgo = LeavePGroupsOut(n_groups=3)\n    n_splits = lpgo.get_n_splits(groups=groups)\n    assert n_splits == 4\n\n    # Ensure that the leave-p-groups-out object is able to generate the\n    # correct indices for the groups\n    for train, test in lpgo.split(X=np.ones((len(groups), 3)),\n                                 y=np.ones(len(groups)),\n                                 groups=groups):\n        assert len(train) + len(test) == len(groups)\n\n    # Ensure that the leave-p-groups-out object is able to generate the\n    # correct number of splits with a number of groups smaller than the\n    # number of unique groups\n    groups = np.array([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4"], "sample_110": ["def test_affinity_propagation_precomputed():\n    # Test with precomputed affinity matrix\n    S = -euclidean_distances(X, squared=True)\n    clustering = AffinityPropagation(affinity='precomputed').fit(S)\n    assert_array_equal(clustering.labels_, affinity_propagation(S)[1])\n\n    # Test with precomputed affinity matrix and verbose\n    clustering = AffinityPropagation(affinity='precomputed', verbose=True).fit(S)\n\n    # Test with sparse precomputed affinity matrix\n    S_sparse = csr_matrix(S)\n    clustering = AffinityPropagation(affinity='precomputed').fit(S_sparse)\n    assert_array_equal(clustering.labels_, affinity_propagation(S_sparse.toarray())[1])\n\n    # Test with sparse precomputed affinity matrix and verbose\n    clustering = AffinityPropagation(affinity='precomputed', verbose=True).fit(S_sparse)\n", "def test_affinity_propagation_precomputed_symmetric():\n    # Test that affinity propagation can handle symmetric precomputed matrices\n    n_samples = 10\n    similarity_matrix = np.random.rand(n_samples, n_samples)\n    similarity_matrix = similarity_matrix + similarity_matrix.T\n\n    cluster_centers_indices, labels = affinity_propagation(\n        similarity_matrix, preference=None, convergence_iter=15, max_iter=200,\n        damping=0.5, copy=True, verbose=False, return_n_iter=False)\n\n    # Check that the cluster centers are in the set of samples\n    assert_array_equal(np.sort(np.unique(labels)), np.arange(np.max(labels) + 1))\n    assert np.all(np.isin(cluster_centers_indices, np.arange(n_samples)))\n\n    # Test with damping = 0.9\n    cluster_centers_indices, labels = affinity_propagation(\n        similarity_matrix, preference=None, convergence_iter=15, max_iter=200,\n        damping=0.9, copy=True, verbose=False, return_n_iter=False)\n\n    assert_array_equal(np.sort(np.unique(labels)), np.arange(np.max(labels) + 1))\n    assert np.all(np.isin(cluster_centers_indices, np.arange(n_samples)))\n\n    # Test with damping = 0.5 and convergence_iter = 10\n    cluster_centers_indices, labels = affinity_propagation(\n        similarity_matrix, preference=None, convergence_iter=10, max_iter=200,\n        damping=0.5, copy=True, verbose=False, return_n_iter=False)\n\n    assert_array_equal(np.sort(np.unique(labels)), np.arange(np.max(labels) + 1))\n    assert np.all(np.isin(cluster_centers_indices, np.arange(n_samples)))\n", "def test_affinity_propagation_warning():\n    # Test warning when all samples have mutually equal similarities.\n    S = np.full((5, 5), 0.5)\n    assert_warns_message(\n        ConvergenceWarning,\n        \"All samples have mutually equal similarities. Returning arbitrary \"\n        \"cluster center(s).\",\n        affinity_propagation,\n        S=S,\n        preference=0.4\n    )\n", "def test_affinity_propagation_precomputed():\n    # Test that passing precomputed affinity matrix works\n    n_samples = X.shape[0]\n    S = -euclidean_distances(X, squared=True)\n    model = AffinityPropagation(preference=np.median(S))\n    cluster_centers_indices, labels = affinity_propagation(S, max_iter=200)\n    assert_array_equal(affinity_propagation(S, max_iter=200),\n                       model.fit_predict(S))\n\n    # Test that the shape of the affinity matrix is checked\n    S_invalid = np.random.rand(n_samples, n_samples - 1)\n    assert_warns_message(ValueError, \"S must be a square array\",\n                        affinity_propagation, S_invalid)\n\n    # Test that the input to fit is checked\n    model = AffinityPropagation(affinity='precomputed')\n    S_invalid = csr_matrix(np.random.rand(n_samples, n_samples - 1))\n    assert_warns_message(ValueError, \"S must be a square array\",\n                        model.fit, S_invalid)\n\n    # Test that the affinity matrix is stored in the estimator\n    model.fit(S)\n    assert_array_equal(model.affinity_matrix_, S)\n\n    # Test that AffinityPropagation can handle a single sample\n    S_single = np.array([[0]])\n    model = AffinityPropagation()\n    cluster_centers_indices, labels = affinity_propagation(S_single, max_iter=200)\n    assert_array_equal(affinity_propagation(S_single, max_iter=200),\n                       model.fit_predict(S_single))\n", "def test_affinity_propagation_convergence():\n    # Test that affinity propagation warns on non-convergence\n    # and produces a valid cluster assignment in this case.\n    X = np.array([[0], [1]])\n    with assert_warns(ConvergenceWarning):\n        clustering = AffinityPropagation(max_iter=1)\n        clustering.fit(X)\n    assert_array_equal(clustering.labels_, np.array([-1, -1]))\n\n    # Test that affinity propagation does not warn when it converges.\n    X = np.array([[0], [1]])\n    with assert_no_warnings():\n        clustering = AffinityPropagation(max_iter=100)\n        clustering.fit(X)\n    assert_array_equal(clustering.labels_, np.array([0, 1]))\n\n    # Test that the same holds for precomputed affinity\n    with assert_warns(ConvergenceWarning):\n        S = np.array([[0, 1], [1, 0]])\n        clustering = AffinityPropagation(max_iter=1, affinity='precomputed')\n        clustering.fit(S)\n    assert_array_equal(clustering.labels_, np.array([-1, -1]))\n\n    # Test that the same holds for precomputed affinity\n    with assert_no_warnings():\n        S = np.array([[0, 1], [1, 0]])\n        clustering = AffinityPropagation(max_iter=100, affinity='precomputed')\n        clustering.fit(S)\n    assert_array_equal(clustering.labels_, np.array([0, 1]))\n\n    # Test that the warning message is the correct one\n    S = np.array([[0, 1], [1, 0]])\n    with assert_warns_message(\n        ConvergenceWarning,\n        \"Affinity propagation did not converge, this model will not have any \"\n        \"cluster centers.\"):\n        clustering = AffinityPropagation(max_iter=1, affinity='precomputed')\n        clustering.fit(S)\n"], "sample_39": ["    def test_url_pattern_check(self):\n        pattern = URLPattern(\n            RegexPattern(r'^test/'),\n            views.empty_view,\n            name='test-pattern',\n        )\n        self.assertEqual(pattern.check(), [])\n\n        pattern.name = 'test:pattern'\n        self.assertEqual(len(pattern.check()), 1)\n\n        pattern.name = None\n        self.assertEqual(pattern.check(), [])\n", "    def test_urlresolver_match_with_kwargs(self):\n        \"\"\"\n        Ensure that URLResolver.match() can handle keyword arguments correctly.\n        \"\"\"\n        resolver = URLResolver(\n            RegexPattern(r'^/normal/(?P<arg1>\\d+)/(?P<arg2>\\d+)/$'),\n            [\n                URLPattern(RegexPattern(r'^$'), views.empty_view, name='normal-view'),\n            ]\n        )\n        match = resolver.resolve('/normal/42/37/')\n        self.assertEqual(match.url_name, 'normal-view')\n        self.assertEqual(match.args, ())\n        self.assertEqual(match.kwargs, {'arg1': '42', 'arg2': '37'})\n", "    def test_url_resolver_namespace(self):\n        \"\"\"\n        Test that URLResolver handles namespace correctly.\n        \"\"\"\n        resolver = get_resolver('urlpatterns_reverse.namespace_urls')\n        match = resolver.resolve('/test1/inner/42/37/')\n        self.assertEqual(match.view_name, 'test-ns1:urlobject-view')\n        self.assertEqual(match.namespace, 'test-ns1')\n        self.assertEqual(match.app_name, 'testapp')\n", "    def test_reverse_lazy_in_resolver(self):\n        class MyView:\n                self.reverse_lazy_called = False\n\n                self.reverse_lazy_called = True\n                return reverse(viewname, *args, **kwargs)\n\n        my_view = MyView()\n        url_patterns = [\n            path('my_view/', my_view, name='my_view'),\n        ]\n        resolver = URLResolver(None, url_patterns)\n        with self.subTest('reverse_lazy in view function'):\n            resolver.resolve(my_view.reverse_lazy('my_view'))\n            self.assertTrue(my_view.reverse_lazy_called)\n\n        my_view.reverse_lazy_called = False\n        with self.subTest('reverse_lazy in view class'):\n            class ViewClass:\n                    self.reverse_lazy_called = False\n\n                    self.reverse_lazy_called = True\n                    return reverse(viewname, *args, **kwargs)\n\n                    return self.reverse_lazy('my_view')\n            view_class = ViewClass()\n            url_patterns = [\n                path('my_view/', view_class, name='my_view'),\n            ]\n            resolver = URLResolver(None, url_patterns)\n            resolver.resolve('/my_view/')\n            self.assertTrue(view_class.reverse_lazy_called)\n", "    def test_reverse_lazy(self):\n        \"\"\"\n        test_reverse_lazy tests the reverse_lazy function with a URL that contains\n        a lazy reference to a view function.\n        \"\"\"\n        url = reverse_lazy('places', args=[3])\n        self.assertEqual(url, '/places/3/')\n        \n        # Test reverse_lazy with a URL that contains a lazy reference to a view\n        # function and a mix of positional and keyword arguments.\n        url = reverse_lazy('named_optional', kwargs={'arg1': 1, 'arg2': 2})\n        self.assertEqual(url, '/optional/1/2/')\n        \n        # Test reverse_lazy with a URL that contains a lazy reference to a view\n        # function and only keyword arguments.\n        url = reverse_lazy('named_optional', kwargs={'arg1': 1})\n        self.assertEqual(url, '/optional/1/')\n        \n        # Test reverse_lazy with a URL that contains a lazy reference to a view\n        # function and only positional arguments.\n        url = reverse_lazy('named_optional', args=[1])\n        self.assertEqual(url, '/optional/1/')\n        \n        # Test reverse_lazy with a URL that contains a lazy reference to a view\n        # function and no arguments.\n        url = reverse_lazy('named_optional')\n        with self.assertRaises(NoReverseMatch):\n            url.url\n        \n        # Test reverse_lazy with a URL that contains a lazy reference to a view\n        # function and incorrect arguments.\n        with self.assertRaises(NoReverseMatch):\n            reverse_lazy('named_optional', args=[1, 2, 3])\n"]}, "raw_scored_generations": {"sample_3": [true, false, false, false, true], "sample_2": [false, false, false, false, false], "sample_1": [false, false, false, false, false], "sample_0": [false, false, false, false, false], "sample_6": [false, false, false, false, false], "sample_4": [true, false, false, false, false], "sample_5": [false, true, false, false, false], "sample_7": [false, false, false, false, true], "sample_9": [false, false, false, false, false], "sample_8": [true, true, false, true, false], "sample_10": [false, true, true, true, true], "sample_11": [false, false, false, false, false], "sample_13": [false, true, false, true, false], "sample_12": [true, true, true, true, false], "sample_14": [false, false, false, false, false], "sample_15": [true, false, false, false, false], "sample_16": [false, true, false, true, false], "sample_17": [false, false, false, false, true], "sample_18": [false, false, false, false, false], "sample_19": [true, true, false, false, false], "sample_21": [false, false, true, false, false], "sample_20": [false, false, false, false, false], "sample_23": [false, true, true, true, true], "sample_22": [true, false, false, false, false], "sample_24": [false, true, true, false, false], "sample_25": [true, true, true, true, true], "sample_28": [false, false, true, true, false], "sample_26": [false, false, false, true, false], "sample_27": [true, false, false, false, false], "sample_29": [false, false, true, true, false], "sample_31": [false, true, false, false, true], "sample_30": [false, true, false, false, false], "sample_32": [false, false, false, false, false], "sample_33": [false, false, false, false, false], "sample_34": [false, false, false, false, false], "sample_35": [false, false, false, false, false], "sample_36": [false, false, false, true, false], "sample_37": [false, false, false, false, false], "sample_39": [false, false, true, false, false], "sample_38": [false, false, false, true, true], "sample_40": [false, false, false, false, false], "sample_42": [false, false, false, false, false], "sample_41": [false, false, false, true, false], "sample_43": [false, true, false, false, true], "sample_45": [false, false, false, false, false], "sample_44": [false, false, false, false, true], "sample_46": [true, true, true, true, true], "sample_48": [false, false, false, false, false], "sample_47": [false, false, false, false, false], "sample_50": [false, false, false, false, false], "sample_49": [false, false, false, true, false], "sample_51": [true, true, true, false, false], "sample_52": [false, false, false, false, false], "sample_53": [true, true, false, true, false], "sample_55": [false, true, false, false, false], "sample_54": [false, false, false, false, false], "sample_56": [false, false, false, false, false], "sample_58": [true, false, true, false, true], "sample_57": [true, true, false, false, false], "sample_60": [false, false, false, false, false], "sample_59": [false, false, false, false, true], "sample_61": [false, false, false, false, false], "sample_63": [true, true, true, false, false], "sample_62": [false, false, false, false, false], "sample_64": [false, false, false, true, false], "sample_66": [false, false, false, false, true], "sample_65": [false, false, false, false, false], "sample_68": [true, true, true, false, false], "sample_67": [false, false, false, false, false], "sample_69": [false, false, false, false, false], "sample_70": [false, false, false, false, false], "sample_71": [false, true, false, false, false], "sample_72": [false, false, false, false, false], "sample_73": [false, false, false, false, false], "sample_74": [false, false, false, false, false], "sample_75": [false, true, true, false, false], "sample_76": [false, false, false, false, false], "sample_77": [false, false, false, false, false], "sample_78": [false, false, true, false, false], "sample_79": [false, false, false, false, false], "sample_80": [false, true, false, false, false], "sample_82": [false, false, false, false, false], "sample_81": [false, false, false, false, false], "sample_83": [false, false, false, false, false], "sample_84": [false, false, false, false, false], "sample_85": [false, false, false, false, false], "sample_86": [false, false, false, false, false], "sample_87": [false, false, true, false, false], "sample_88": [false, false, false, false, true], "sample_89": [false, false, true, false, false], "sample_90": [false, false, false, false, false], "sample_91": [false, false, false, false, false], "sample_92": [false, false, false, false, false], "sample_93": [false, false, false, false, false], "sample_95": [false, false, false, false, false], "sample_94": [true, false, false, false, false], "sample_96": [false, false, false, false, false], "sample_97": [false, true, false, false, false], "sample_98": [false, false, false, false, false], "sample_99": [false, false, false, false, false], "sample_100": [true, false, false, false, false], "sample_101": [false, false, false, false, false], "sample_102": [false, false, true, false, true], "sample_103": [false, false, true, false, false], "sample_104": [false, false, false, false, false], "sample_105": [false, false, false, false, false], "sample_107": [false, false, false, false, false], "sample_106": [false, false, true, false, false], "sample_108": [true, false, false, true, false], "sample_109": [false, false, false, false, false], "sample_110": [false, true, false, false, false], "sample_111": [true, false, false, false, false], "sample_112": [true, true, false, false, true], "sample_113": [false, false, false, false, false], "sample_114": [false, false, false, true, false], "sample_115": [false, false, false, false, true], "sample_116": [false, false, false, false, false], "sample_117": [false, false, false, false, false], "sample_118": [false, false, true, true, true], "sample_119": [true, false, true, true, false], "sample_120": [true, true, true, false, false], "sample_121": [false, false, false, false, false], "sample_122": [false, false, false, false, true], "sample_123": [false, false, false, false, false], "sample_124": [false, false, false, false, false], "sample_125": [false, false, false, true, false], "sample_126": [false, false, false, false, false], "sample_127": [false, false, false, false, false], "sample_128": [false, false, false, false, false], "sample_129": [false, false, false, false, false], "sample_130": [false, false, true, false, true], "sample_131": [false, false, false, false, true], "sample_132": [false, false, false, false, false], "sample_133": [false, false, false, false, false], "sample_134": [false, false, false, false, false], "sample_135": [true, false, false, false, false], "sample_136": [true, false, false, false, false], "sample_137": [false, false, false, false, false], "sample_138": [true, false, true, false, false], "sample_139": [false, true, false, true, false], "sample_140": [true, false, false, true, true], "sample_142": [false, false, false, false, false], "sample_141": [false, false, false, false, false], "sample_143": [false, false, false, false, false], "sample_144": [false, true, true, false, false], "sample_145": [true, false, false, false, false], "sample_146": [false, false, false, false, false], "sample_147": [false, false, false, false, false], "sample_148": [true, false, false, false, false], "sample_149": [true, false, false, false, false], "sample_150": [false, false, false, false, false], "sample_151": [false, false, false, false, false], "sample_152": [false, false, false, false, false], "sample_153": [false, false, false, false, false], "sample_154": [true, false, false, true, false], "sample_155": [false, false, false, false, false], "sample_156": [false, false, false, false, false], "sample_157": [false, false, false, false, false], "sample_158": [false, false, false, false, false], "sample_159": [false, false, false, false, false]}}