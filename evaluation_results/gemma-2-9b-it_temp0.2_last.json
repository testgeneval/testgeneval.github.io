{"raw_generations": {"sample_108": ["    def test_resolve_value_error_in_to_url_means_no_match(self):\n        @DynamicConverter.register_to_url\n            raise ValueError()\n        with self.assertRaises(Resolver404):\n            resolve('/dynamic/abc/')\n"], "sample_770": ["def test_davies_bouldin_score():\n    assert_raises_on_only_one_label(davies_bouldin_score)\n\n    assert_raises_on_all_points_same_cluster(davies_bouldin_score)\n\n    # Assert the value is 0. when all samples are equals\n    assert_equal(0., davies_bouldin_score(np.ones((10, 2)),\n                [0] * 10))\n\n    # General case (with non numpy arrays)\n    X = ([[0, 0], [1, 1]] * 5 + [[3, 3], [4, 4]] * 5 +\n         [[0, 4], [1, 3]] * 5 + [[3, 1], [4, 0]] * 5)\n    labels = [0] * 10 + [1] * 10 + [2] * 10 + [3] * 10\n    pytest.approx(davies_bouldin_score(X, labels), 0.5)\n"], "sample_1011": ["def test_MatrixElement_printing_with_symbols():\n    A = MatrixSymbol(\"A\", 2, 2)\n    x = Symbol('x')\n    assert mcode(A[0, 0] + x*A[1, 1]) == \"A(1, 1) + x*A(2, 2)\"\n"], "sample_740": ["def test_check_array_sparse_dtype():\n    X_csr = sp.csr_matrix([[1, 2], [3, 4]], dtype=np.float16)\n    X_csc = sp.csc_matrix([[1, 2], [3, 4]], dtype=np.float16)\n    X_coo = sp.coo_matrix([[1, 2], [3, 4]], dtype=np.float16)\n\n    # Test that dtype is preserved for sparse matrices\n    for X in [X_csr, X_csc, X_coo]:\n        X_checked = check_array(X, dtype=np.float32)\n        assert_equal(X_checked.dtype, np.float16)\n        assert_equal(X_checked.format, X.format)\n\n    # Test that dtype is converted for dense arrays\n    X_dense = np.array([[1, 2], [3, 4]], dtype=np.float16)\n    X_checked = check_array(X_dense, dtype=np.float32)\n    assert_equal(X_checked.dtype, np.float32)\n\n\n\n"], "sample_808": ["def test_iforest_sparse_data():\n    \"\"\"Test Isolation Forest with sparse data.\"\"\"\n    rng = check_random_state(0)\n    n_samples = 100\n    n_features = 1000\n    X = rng.rand(n_samples, n_features)\n    X_sparse = csc_matrix(X)\n\n    # Test with different contamination values\n    for contamination in [0.1, 0.2, 0.3]:\n        clf = IsolationForest(contamination=contamination, random_state=rng)\n        clf.fit(X_sparse)\n        clf.predict(X_sparse)\n"], "sample_156": ["    def test_renderer_override(self):\n        class MyForm(Form):\n            name = CharField()\n\n        form = MyForm()\n        custom_renderer = CustomRenderer()\n        form.renderer = custom_renderer\n        self.assertEqual(form.renderer, custom_renderer)\n        self.assertNotEqual(form.renderer, get_default_renderer())\n"], "sample_92": ["    def test_authenticate_with_inactive_user_raises_permission_denied(self):\n        self.assertFalse(self.user.is_active)\n        with self.assertRaises(PermissionDenied):\n            authenticate(**self.user_credentials)\n"], "sample_411": ["    def test_normalize_path_patterns(self):\n        self.assertEqual(\n            normalize_path_patterns([\"foo/bar/baz\", \"baz\", \"foo/bar/baz\"]),\n            [\"foo/bar/baz\", \"baz\"],\n        )\n        self.assertEqual(\n            normalize_path_patterns([\"*/baz\", \"baz\", \"*\"]), [\"*/baz\", \"baz\"]\n        )\n        self.assertEqual(\n            normalize_path_patterns([\"foo/bar/baz\", \"*/baz\", \"baz\"]),\n            [\"*/baz\", \"baz\"],\n        )\n        self.assertEqual(\n            normalize_path_patterns([\"foo/bar/baz\", \"foo/bar/*\"]),\n            [\"foo/bar/baz\", \"foo/bar/*\"],\n        )\n"], "sample_699": ["    def test_is_setup_py_is_a_py_file(tmp_path: Path) -> None:\n        setup_py = tmp_path.joinpath(\"setup.py\")\n        setup_py.write_text(\"print('hello')\", \"utf-8\")\n        assert _is_setup_py(setup_py)\n"], "sample_210": ["    def test_template_params_filtering_with_kwargs(self):\n        class ArtistView(TemplateView):\n            template_name = 'generic_views/about.html'\n\n                context = super().get_context_data(**kwargs)\n                artist = Artist.objects.get(name=artist_name)\n                context['artist'] = artist\n                return context\n\n        artist = Artist.objects.create(name='Rene Magritte')\n        response = ArtistView.as_view()(self.rf.get('/'), artist_name=artist.name, extra_info='extra')\n        self.assertEqual(response.context_data['artist'], artist)\n        self.assertEqual(response.context_data['extra_info'], 'extra')\n"], "sample_498": ["def test_legend_handles_order():\n    fig, ax = plt.subplots()\n    ax.plot([0, 1], [0, 1], label='line1')\n    ax.plot([1, 2], [1, 2], label='line2')\n    ax.plot([2, 3], [2, 3], label='line3')\n    legend = ax.legend()\n    handles = legend.get_legend_handles_labels()\n    assert [h.get_label() for h in handles[0]] == ['line1', 'line2', 'line3']\n"], "sample_120": ["    def test_serialize_custom_field(self):\n        class MyCustomField(models.Field):\n                super().__init__(**kwargs)\n\n                return ('MyCustomField', [], {})\n\n                return 'MyCustomDbType'\n\n        field = MyCustomField()\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(string, \"MyCustomField()\")\n"], "sample_718": ["def test_check_estimators_data_not_an_array():\n    # check that estimators raise an error if data is not an array\n    from sklearn.datasets import load_iris\n    iris = load_iris()\n    X, y = iris.data, iris.target\n    for estimator in [LinearRegression, SVC, RandomForestClassifier]:\n        with ignore_warnings(category=DeprecationWarning):\n            est = estimator()\n        est.fit(X, y)\n        msg = \"Estimator does not raise an error when data is not an array\"\n        assert_raises_regex(TypeError, msg,\n                            est.predict, [1, 2, 3])\n"], "sample_897": ["def test_partial_dependence_display_kind_persistence(\n    pyplot, clf_diabetes, diabetes, kind, expected_kind"], "sample_1185": ["def test_compogen():\n    assert compogen([sin(x), cos(x)], x) == sin(cos(x))\n    assert compogen([x**2 + x + 1, sin(x)], x) == sin(x)**2 + sin(x) + 1\n    assert compogen([sqrt(x), 6*x**2 - 5], x) == sqrt(6*x**2 - 5)\n    assert compogen([sin(x), sqrt(x), cos(x), x**2 + 1], x) == sin(sqrt(cos(x**2 + 1)))\n    assert compogen([Abs(x), x**2 + 3*x - 4, cos(x)], x) == Abs(x**2 + 3*x - 4)\n    assert compogen([x**2 + x - sqrt(3)/2, sin(x)], x) == sin(x)**2 + sin(x) - sqrt(3)/2\n    assert compogen([Abs(x), 3*x + cos(y)**2 - 4, cos(x)], x) == Abs(3*x + cos(y)**2 - 4)\n    assert compogen([x, x], x) == x\n    assert compogen([1, 1], x) == 1\n    assert compogen([Max(3, x), x], x) == Max(3, x)\n"], "sample_195": ["    def test_sql_flush_with_tables(self):\n        with transaction.atomic():\n            Author.objects.create(name='John Doe')\n            Book.objects.create(title='Book 1', author=Author.objects.get(name='John Doe'))\n            sql = connection.ops.sql_flush(no_style(), [Author._meta.db_table, Book._meta.db_table])\n            self.assertEqual(len(sql), 2)\n            self.assertIn(f'DELETE FROM \"{Author._meta.db_table}\"', sql)\n            self.assertIn(f'DELETE FROM \"{Book._meta.db_table}\"', sql)\n"], "sample_641": ["def test__get_pdata_path_empty_path(\n    path: str, recur: int, pylint_home: Path, expected: Path"], "sample_972": ["compilation error"], "sample_540": ["def test_save_count_override_warnings_generator(anim):\n    save_count = 5\n        for i in range(10):\n            yield i\n    match_target = (\n        f'You passed in an explicit {save_count=} '\n        \"which is being ignored in favor of \"\n        f\"{len(list(gen_frames()))=}.\"\n    )\n\n    with pytest.warns(UserWarning, match=re.escape(match_target)):\n        anim = animation.FuncAnimation(\n            **{**anim, 'frames': gen_frames, 'save_count': save_count}\n        )\n\n    assert anim._save_count == len(list(gen_frames()))\n    anim._init_draw()\n"], "sample_579": ["    def test_tree_kws_nested(self):\n        rgb1 = (1, .5, .2)\n        rgb2 = (.2, .5, 1)\n        g = mat.clustermap(self.df_norm, tree_kws=dict(color=[rgb1, rgb2]))\n        tree1, = g.ax_col_dendrogram.collections\n        tree2, = g.ax_row_dendrogram.collections\n        assert tuple(tree1.get_color().squeeze())[:3] == rgb1\n        assert tuple(tree2.get_color().squeeze())[:3] == rgb2\n"], "sample_1068": ["def test_polygamma():\n    assert octave_code(polygamma(n, x)) == 'polygamma(n, x)'\n    assert octave_code(polygamma(n, x, evaluate=False)) == 'polygamma(n, x, \"symbolic\")'\n"], "sample_862": ["compilation error"], "sample_976": ["def test_symbols_with_cls():\n    x = symbols('x', cls=Function)\n    assert isinstance(x, Function)\n    y = symbols('y', cls=Dummy)\n    assert isinstance(y, Dummy)\n    z = symbols('z', cls=Wild)\n    assert isinstance(z, Wild)\n\n    a, b = symbols('a,b', cls=lambda name: type(name) )\n    assert isinstance(a, str)\n    assert isinstance(b, str)\n\n    f = symbols('f', cls=Function)\n    g = symbols('g', cls=Function)\n    assert isinstance(f, Function)\n    assert isinstance(g, Function)\n    assert f != g\n"], "sample_624": ["compilation error"], "sample_445": ["    def test_timeuntil_with_future_date(self):\n        future_date = self.t + self.oneday\n        self.assertEqual(timeuntil(future_date), \"1\\xa0day\")\n"], "sample_995": ["compilation error"], "sample_135": ["    def test_empty_datetime(self):\n        with self.assertRaises(TypeError):\n            dateformat.format(None, 'Y')\n"], "sample_727": ["def test_imputation_sparse_csc_axis_1():\n    # Test imputation with sparse CSC matrix and axis=1\n    X = sparse.csc_matrix(np.random.rand(10, 5))\n    X[::2, :] = np.nan\n\n    imputer = Imputer(missing_values=0, strategy=\"mean\", axis=1)\n    X_imputed = imputer.fit(X).transform(X)\n\n    assert_array_almost_equal(X_imputed.data,\n                              imputer.statistics_,\n                              err_msg=\"Statistics are incorrect for sparse CSC matrix and axis=1\")\n\n    assert_equal(X_imputed.shape, X.shape)\n    assert_equal(X_imputed.dtype, X.dtype)\n\n\n\n"], "sample_481": ["    def test_join09(self):\n        output = self.engine.render_to_string(\n            \"join09\", {\"a\": [\"Alpha\", \"Beta & me\"], \"var\": mark_safe(\" & \")}\n        )\n        self.assertEqual(output, \"Alpha & Beta & me\")\n"], "sample_832": ["compilation error"], "sample_753": ["def test_class_weight_with_sparse_data():\n    # Test class_weight with sparse data\n    rng = np.random.RandomState(42)\n    n_samples = 50\n    n_features = 20\n    X, y = make_classification(n_samples=n_samples, n_features=n_features,\n                               random_state=0)\n    X_sparse = sparse.csr_matrix(X)\n    class_weight = {0: 1, 1: 5}\n\n    lr_sparse = LogisticRegression(class_weight=class_weight,\n                                   solver='saga',\n                                   max_iter=1000, tol=1e-10)\n    lr_sparse.fit(X_sparse, y)\n\n    lr_dense = LogisticRegression(class_weight=class_weight,\n                                   solver='saga',\n                                   max_iter=1000, tol=1e-10)\n    lr_dense.fit(X, y)\n    assert_array_almost_equal(lr_sparse.coef_, lr_dense.coef_)\n"], "sample_1132": ["compilation error"], "sample_1103": ["def test_issue_16499():\n    a, b = symbols('a b', positive=True)\n    assert (a**b).is_positive\n    assert (a**b).is_nonnegative\n    assert (a**b).is_real\n    assert (a**b).is_extended_real\n    assert (a**b).is_nonposneg is None\n    assert (a**b).is_integer is None\n    assert (a**b).is_rational is None\n    assert (a**b).is_complex is None\n    assert (a**b).is_imaginary is None\n    assert (a**b).is_finite is None\n    assert (a**b).is_infinite is None\n"], "sample_269": ["    def test_i18n_with_plural_forms(self):\n        with self.settings(LANGUAGE_CODE='es'), override('es-ar'):\n            response = self.client.get('/jsi18n/')\n            self.assertContains(response, '1 elemento')\n            self.assertContains(response, '455 elementos')\n"], "sample_629": ["def test_expand_modules_simple():\n    files_or_modules = [\"my_module.py\", \"another_module/submodule.py\"]\n    ignore_list = []\n    ignore_list_re = []\n    ignore_list_paths_re = []\n    expected_result = [\n        {\"path\": \"my_module.py\", \"name\": \"my_module\", \"isarg\": True, \"basepath\": \"my_module.py\", \"basename\": \"my_module\"},\n        {\"path\": \"another_module/submodule.py\", \"name\": \"another_module.submodule\", \"isarg\": False, \"basepath\": \"another_module/__init__.py\", \"basename\": \"another_module\"},\n    ]\n    result, errors = expand_modules(\n        files_or_modules, ignore_list, ignore_list_re, ignore_list_paths_re\n    )\n    assert result == expected_result\n    assert errors == []\n"], "sample_581": ["compilation error"], "sample_842": ["def test_kernel_with_missing_data(kernel):\n    # Test behavior of kernels with missing data.\n    X = np.random.RandomState(0).normal(0, 1, (5, 2))\n    X[1, :] = np.nan\n    K = kernel(X)\n    assert np.isnan(K[1, :]).all()\n    assert np.isnan(K[:, 1]).all()\n"], "sample_713": ["def test_ridge_with_categorical_features():\n    from sklearn.preprocessing import OneHotEncoder\n\n    X, y = make_classification(n_samples=100, n_features=5,\n                               n_informative=3, random_state=42)\n    X_categorical = X[:, 2:]\n    X_numerical = X[:, :2]\n\n    encoder = OneHotEncoder(handle_unknown='ignore')\n    X_categorical_encoded = encoder.fit_transform(X_categorical).toarray()\n\n    X_combined = np.hstack((X_numerical, X_categorical_encoded))\n\n    ridge = Ridge()\n    ridge.fit(X_combined, y)\n\n    assert_array_equal(ridge.coef_.shape, (X_numerical.shape[1] +\n                                          X_categorical_encoded.shape[1],))\n"], "sample_715": ["def test_cross_val_predict_with_sparse_data():\n    X, y = make_classification(n_samples=100, n_features=20, random_state=0)\n    X_sparse = csr_matrix(X)\n    y_sparse = csr_matrix(y)\n\n    clf = LogisticRegression()\n    predictions = cross_val_predict(clf, X, y, cv=5)\n    predictions_sparse = cross_val_predict(clf, X_sparse, y_sparse, cv=5)\n    predictions_sparse = predictions_sparse.toarray()\n    assert_array_almost_equal(predictions, predictions_sparse)\n"], "sample_611": ["def test_cftime_range_with_calendar(start, end, periods, freq, closed, calendar):\n    result = cftime_range(\n        start=start,\n        end=end,\n        periods=periods,\n        freq=freq,\n        closed=closed,\n        calendar=calendar,\n    )\n    assert isinstance(result, CFTimeIndex)\n"], "sample_686": ["def test_external_plugins_integrated_with_ini(testdir, plugin):\n    testdir.syspathinsert()\n    testdir.makepyfile(**{plugin: \"\"})\n    testdir.makeini(f\"[{plugin}]\\n\")\n\n    with pytest.warns(pytest.PytestConfigWarning):\n        testdir.parseconfig(\"-p\", plugin)\n"], "sample_1059": ["compilation error"], "sample_469": ["    def test_alias_with_subquery(self):\n        qs = (\n            Book.objects.alias(\n                top_rating_alias=Subquery(\n                    Book.objects.filter(pubdate__year=OuterRef(\"pubdate__year\"))\n                    .order_by(\"-rating\")\n                    .values(\"rating\")[:1]\n                )\n            )\n            .values(\"pubdate__year\", \"top_rating_alias\")\n        )\n        self.assertCountEqual(\n            qs,\n            [\n                {\"pubdate__year\": 1991, \"top_rating_alias\": 5.0},\n                {\"pubdate__year\": 1995, \"top_rating_alias\": 4.0},\n                {\"pubdate__year\": 2007, \"top_rating_alias\": 4.5},\n                {\"pubdate__year\": 2008, \"top_rating_alias\": 4.0},\n                {\"pubdate__year\": 2008, \"top_rating_alias\": 4.0},\n                {\"pubdate__year\": 2008, \"top_rating_alias\": 4.0},\n            ],\n        )\n"], "sample_903": ["def test_early_exaggeration_effect():\n    # Check that early exaggeration has a noticeable effect on the embedding\n    random_state = check_random_state(0)\n    X = random_state.randn(100, 2)\n    tsne_no_exaggeration = TSNE(n_components=2, perplexity=30,\n                                learning_rate=100.0,\n                                random_state=0, method='barnes_hut',\n                                early_exaggeration=1.0)\n    tsne_with_exaggeration = TSNE(n_components=2, perplexity=30,\n                                 learning_rate=100.0,\n                                 random_state=0, method='barnes_hut',\n                                 early_exaggeration=10.0)\n\n    X_embedded_no_exaggeration = tsne_no_exaggeration.fit_transform(X)\n    X_embedded_with_exaggeration = tsne_with_exaggeration.fit_transform(X)\n\n    # Check that the embeddings are different\n    assert_not_equal(np.sum(X_embedded_no_exaggeration),\n                     np.sum(X_embedded_with_exaggeration))\n"], "sample_73": ["    def test_manifest_cache_invalidation(self):\n        # Create files with different content and hash them\n        with open(self._get_filename_path('cached/styles.css'), 'w') as f:\n            f.write('body { background-color: red; }')\n        with open(self._get_filename_path('cached/styles.css'), 'w') as f:\n            f.write('body { background-color: blue; }')\n\n        # Collect static files, this should create a manifest\n        self.run_collectstatic()\n\n        # Check if the manifest has been updated with the new hash\n        manifest = storage.staticfiles_storage.load_manifest()\n        self.assertIn('cached/styles.css', manifest)\n        self.assertNotEqual(manifest['cached/styles.css'], 'deploy12345.css')\n\n        # Modify a file again and collect static files again\n        with open(self._get_filename_path('cached/styles.css'), 'w') as f:\n            f.write('body { background-color: green; }')\n        self.run_collectstatic()\n\n        # Check if the manifest has been updated again\n        manifest = storage.staticfiles_storage.load_manifest()\n        self.assertIn('cached/styles.css', manifest)\n        self.assertNotEqual(manifest['cached/styles.css'], 'deploy12345.css')\n"], "sample_1128": ["def test_point_vel_multiple_frames():\n    q1, q2 = dynamicsymbols('q1 q2')\n    N = ReferenceFrame('N')\n    B = N.orientnew('B', 'Axis', [q1, N.z])\n    O = Point('O')\n    P = O.locatenew('P', 10 * B.x)\n    O.set_vel(N, 5 * N.x)\n    assert P.vel(N) == 5 * N.x + 10 * q1.diff(t) * B.y\n    assert P.vel(B) == 10 * q1.diff(t) * B.y\n\n\n\n"], "sample_1083": ["compilation error"], "sample_329": ["    def test_serialize_custom_serializer(self):\n        class MyCustomSerializer(BaseSerializer):\n                return f\"custom_serializer({value})\", {}\n\n        with self.subTest(\"Custom serializer\"):\n            self.assertSerializedEqual(MyCustomSerializer(123), \"custom_serializer(123)\")\n        with self.subTest(\"Custom serializer with complex object\"):\n            class ComplexObject:\n                    self.value = value\n\n                    return f\"ComplexObject({self.value})\"\n\n            self.assertSerializedEqual(MyCustomSerializer(ComplexObject(456)), \"custom_serializer(ComplexObject(456))\")\n"], "sample_483": ["    def test_check_for_non_existent_fields_in_fieldsets(self):\n        class MyModelAdmin(admin.ModelAdmin):\n            fieldsets = [\n                (None, {\"fields\": [\"nonexistent_field\"]}),\n            ]\n\n        errors = MyModelAdmin(Song, AdminSite()).check()\n        expected = [\n            checks.Error(\n                \"The value of 'fieldsets[0][1]['fields']' contains a field \"\n                \"'nonexistent_field' which is not a field of 'admin_checks.Song'.\",\n                obj=MyModelAdmin,\n                id=\"admin.E009\",\n            )\n        ]\n        self.assertEqual(errors, expected)\n"], "sample_1117": ["def test_matrix_element_sets_transposed():\n    X = MatrixSymbol('X', 4, 4)\n    assert ask(Q.real(X[1, 2]), Q.real(X.T[2, 1]))\n    assert ask(Q.integer(X[1, 2]), Q.integer(X.T[2, 1]))\n    assert ask(Q.complex(X[1, 2]), Q.complex(X.T[2, 1]))\n    assert ask(Q.integer_elements(X.T), Q.integer_elements(X))\n"], "sample_1129": ["def test_loggamma():\n    from sympy import loggamma\n\n    expr = loggamma(x)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr) == 'scipy.special.loggamma(x)'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr) == '  # Not supported in Python with NumPy:\\n  # loggamma\\nloggamma(x)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr) == '  # Not supported in Python:\\n  # loggamma\\nloggamma(x)'\n\n    prntr = MpmathPrinter()\n    assert prntr.doprint(expr) == 'mpmath.loggamma(x)'\n"], "sample_274": ["    def test_modelchoicefield_with_to_field_name(self):\n        ChoiceModel.objects.create(pk=1, name='a', extra_field='extra_value_1')\n        ChoiceModel.objects.create(pk=2, name='b', extra_field='extra_value_2')\n\n        class MyForm(Form):\n            choice = ModelChoiceField(\n                queryset=ChoiceModel.objects.all(),\n                to_field_name='extra_field',\n                error_messages={'invalid_choice': '%(value)s IS INVALID CHOICE'}\n            )\n\n        f = MyForm({'choice': 'invalid_value'})\n        self.assertFormErrors(['INVALID CHOICE'], f.clean, {'choice': 'invalid_value'})\n"], "sample_631": ["    def test_unused_variable_in_loop(self):\n        \"\"\"Ensure unused variables in loops are flagged correctly.\"\"\"\n        node = astroid.parse(\n            \"\"\"\n        for i in range(10):\n            x = i * 2\n        \"\"\"\n        )\n        with self.assertAddsMessages(\n            Message(\"unused-variable\", node=node.body[0].targets[0], args=\"x\")\n        ):\n            self.walk(node)\n\n"], "sample_925": ["compilation error"], "sample_857": ["def test_prune_tree_with_max_leaf_nodes():\n    # Test pruning with max_leaf_nodes\n    X = np.random.RandomState(0).random_sample((100, 10))\n    y = np.random.randint(0, 2, size=100)\n\n    clf = DecisionTreeClassifier(max_leaf_nodes=10, random_state=0)\n    clf.fit(X, y)\n    info = clf.cost_complexity_pruning_path(X, y)\n\n    pruning_path = info.ccp_alphas\n    for ccp_alpha in pruning_path:\n        est = DecisionTreeClassifier(max_leaf_nodes=10, ccp_alpha=ccp_alpha,\n                                     random_state=0).fit(X, y)\n        assert est.tree_.max_leaf_nodes == 10\n        assert_pruning_creates_subtree(DecisionTreeClassifier, X, y,\n                                      pruning_path)\n\n\n\n"], "sample_1005": ["def test_issue_14987():\n    from sympy.tensor.tensor import Tensor\n    a = Tensor('a', (2, 3))\n    b = Tensor('b', (3, 1))\n    c = Tensor('c', (1, 2))\n    assert latex(a * b * c) == r\"a \\otimes b \\otimes c\"\n"], "sample_356": ["    def test_operation_with_no_suggested_name_and_initial_true(self):\n        class Migration(migrations.Migration):\n            initial = True\n            operations = [\n                migrations.RunSQL('SELECT 1 FROM person;'),\n            ]\n\n        migration = Migration('0001_initial', 'test_app')\n        self.assertEqual(migration.suggest_name(), 'initial')\n"], "sample_837": ["def test_show_versions():\n    show_versions()\n    \n    # Assertions should be added here to check the output format and content\n    # of the printed information.\n"], "sample_1038": ["def test_transpose_commutativity():\n    A = MatrixSymbol('A', 2, 3)\n    B = MatrixSymbol('B', 3, 2)\n    assert (A.T * B).doit() == (B.T * A).doit()\n    assert (A.T * B).as_explicit() == (B.T * A).as_explicit()\n\n\n\n"], "sample_987": ["def test_issue_10697():\n    from sympy import integrate, oo\n    assert integrate(1/(x**2 + 1), (x, 0, oo)).evalf() == pi/2\n"], "sample_626": ["    def test_safe_cast_to_index_numeric_arrays(\n        self, array, expected_dtype"], "sample_297": ["    def test_ticket_24605_subquery_with_alias(self):\n        \"\"\"\n        Subquery table names should be quoted even with aliases.\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        self.assertSequenceEqual(\n            Individual.objects.filter(\n                Q(alive=False), Q(related_individual__isnull=True)\n            ).values('pk', 'alive'),\n            [{'pk': i4.pk, 'alive': False}]\n        )\n"], "sample_722": ["def test_sparse_k_means_with_missing_values():\n    from sklearn.datasets import make_sparse_matrix\n    from sklearn.preprocessing import StandardScaler\n\n    X, _ = make_sparse_matrix(n_samples=100, n_features=10, density=0.5, random_state=42)\n    # Introduce some missing values\n    X[::2, ::2] = np.nan\n\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n\n    # Test with different sparse matrix formats\n    for format in ['csr', 'csc']:\n        X_sparse = sp.csr_matrix(X_scaled) if format == 'csr' else sp.csc_matrix(X_scaled)\n        km = MiniBatchKMeans(n_clusters=5, batch_size=32, init='k-means++',\n                            random_state=42)\n        km.fit(X_sparse)\n        assert_equal(km.inertia_, np.isfinite(km.inertia_))\n        assert_equal(km.cluster_centers_.shape[0], 5)\n\n\n\n"], "sample_647": ["    def test_warn_explicit_for(pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n                pass\n\n            @pytest.mark.parametrize(\"arg\", [1, 2])\n                pass\n\n            @pytest.fixture\n                pass\n            \"\"\"\n        )\n        with pytester.raises(warning_types.PytestWarning) as excinfo:\n            warning_types.warn_explicit_for(my_function, warning_types.PytestWarning(\"test\"))\n        assert \"test\" in str(excinfo.value)\n        assert my_function.__module__ in str(excinfo.value)\n        assert my_function.__code__.co_firstlineno in str(excinfo.value)\n        assert \"my_function\" in str(excinfo.value)\n\n        with pytester.raises(warning_types.PytestWarning) as excinfo:\n            warning_types.warn_explicit_for(test_function, warning_types.PytestWarning(\"test\"))\n        assert \"test\" in str(excinfo.value)\n        assert test_function.__module__ in str(excinfo.value)\n        assert test_function.__code__.co_firstlineno in str(excinfo.value)\n        assert \"test_function\" in str(excinfo.value)\n\n        with pytester.raises(warning_types.PytestWarning) as excinfo:\n            warning_types.warn_explicit_for(my_fixture, warning_types.PytestWarning(\"test\"))\n        assert \"test\" in str(excinfo.value)\n        assert my_fixture.__module__ in str(excinfo.value)\n        assert my_fixture.__code__.co_firstlineno in str(excinfo.value)\n        assert \"my_fixture\" in str(excinfo.value)\n"], "sample_964": ["def test_python_python_use_unqualified_type_names_enabled(app, status, warning):\n    app.build()\n    content = (app.outdir / 'index.html').read_text()\n    assert ('<span class=\"n\"><a class=\"reference internal\" href=\"#foo.Name\" title=\"foo.Name\">'\n            '<span class=\"pre\">Name</span></a></span>' in content)\n    assert '<span class=\"n\"><span class=\"pre\">foo.Age</span></span>' in content\n    assert ('<p><strong>name</strong> (<a class=\"reference internal\" href=\"#foo.Name\" '\n            'title=\"foo.Name\"><em>Name</em></a>) \u2013 blah blah</p>' in content)\n    assert '<p><strong>age</strong> (<em>foo.Age</em>) \u2013 blah blah</p>' in content\n"], "sample_823": ["def test_check_pairwise_arrays_sparse_input():\n    # Ensures that checks handle sparse input correctly.\n    rng = np.random.RandomState(0)\n    XA = rng.random_sample((5, 4))\n    XA_sparse = csr_matrix(XA)\n    XB = rng.random_sample((5, 4))\n    XB_sparse = csr_matrix(XB)\n    XA_checked, XB_checked = check_pairwise_arrays(XA_sparse, XB_sparse)\n    assert issparse(XA_checked)\n    assert issparse(XB_checked)\n    assert_array_almost_equal(XA_sparse.toarray(), XA_checked.toarray())\n    assert_array_almost_equal(XB_sparse.toarray(), XB_checked.toarray())\n"], "sample_200": ["    def test_send_messages_with_stopped_server(self):\n        \"\"\"\n        send_messages() raises an exception if the SMTP server is stopped.\n        \"\"\"\n        with self.assertRaises(SMTPException):\n            self.backend.send_messages([EmailMessage('Subject', 'Content', 'from@example.com', ['to@example.com'])])\n"], "sample_346": ["    def test_cache_control_decorator_with_kwargs(self):\n        @cache_control(max_age=3600, must_revalidate=True, no_cache=True)\n            return HttpResponse()\n        r = a_view(HttpRequest())\n        self.assertEqual(\n            set(r.headers['Cache-Control'].split(', ')),\n            {'max-age=3600', 'must-revalidate', 'no-cache'},\n        )\n"], "sample_648": ["    def test_parametrize_with_markers_from_fixture(pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n                return pytest.mark.my_fixture_marker\n\n            @pytest.mark.parametrize(\"arg\", [1, 2, 3], ids=[\"one\", \"two\", \"three\"])\n            @pytest.mark.parametrize(\"marker\", [my_marker], indirect=True)\n                assert arg == 1\n                assert marker.name == \"my_fixture_marker\"\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.assert_outcomes(passed=3)\n"], "sample_437": ["    def test_health_checks_close_at(self):\n        self.patch_settings_dict(conn_health_checks=True)\n        self.assertIsNone(connection.connection)\n        # Newly created connections are considered healthy without performing\n        # the health check.\n        with patch.object(connection, \"is_usable\", side_effect=AssertionError):\n            self.run_query()\n\n        old_connection = connection.connection\n        # Simulate request_finished.\n        connection.close_at = time.time() + 1\n        connection.close_if_unusable_or_obsolete()\n        # Persistent connections are enabled.\n        self.assertIs(old_connection, connection.connection)\n        # Simulate connection health check failing.\n        with patch.object(\n            connection, \"is_usable\", return_value=False\n        ) as mocked_is_usable:\n            self.run_query()\n            new_connection = connection.connection\n            # A new connection is established.\n            self.assertIsNot(new_connection, old_connection)\n            # Only one health check per \"request\" is performed, so the next\n            # query will carry on even if the health check fails. Next query\n            # succeeds because the real connection is healthy and only the\n            # health check failure is mocked.\n            self.run_query()\n            self.assertIs(new_connection, connection.connection)\n        self.assertEqual(mocked_is_usable.call_count, 1)\n        # Simulate request_finished.\n        connection.close_if_unusable_or_obsolete()\n        # The underlying connection is being reused further with health checks\n        # succeeding.\n        self.run_query()\n        self.run_query()\n        self.assertIs(new_connection, connection.connection)\n"], "sample_938": ["def test_man_show_urls(app, status, warning):\n    app.config.man_show_urls = True\n    app.build()\n    content = (app.outdir / 'python.1').read_text()\n    assert r'\\fIhttp://example.com\\fP' in content\n"], "sample_72": ["    def test_serialize_custom_field(self):\n        class MyCustomField(models.Field):\n                super().__init__(*args, **kwargs)\n\n                return ('MyCustomField', [], {})\n\n                return 'MyCustomDbType'\n\n                return forms.CharField(**kwargs)\n\n        field = MyCustomField()\n        string, imports = MigrationWriter.serialize(field)\n        self.assertEqual(string, \"MyCustomField()\")\n        self.assertEqual(imports, {'from migrations.test_writer import MyCustomField'})\n"], "sample_420": ["    def test_setattr_raises_validation_error_field_specific_with_instance(self):\n        form_class = modelform_factory(\n            model=StrictAssignmentFieldSpecific, fields=[\"title\"]\n        )\n        instance = StrictAssignmentFieldSpecific()\n        form = form_class(instance=instance, data={\"title\": \"testing setattr\"}, files=None)\n        # This line turns on the ValidationError; it avoids the model erroring\n        # when its own __init__() is called when creating form.instance.\n        form.instance._should_error = True\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form.errors,\n            {\"title\": [\"Cannot set attribute\", \"This field cannot be blank.\"]},\n        )\n"], "sample_1064": ["def test_tensorflow_derivatives():\n    if not tf:\n        skip(\"TensorFlow not installed\")\n\n    expr = x**2 + y**2\n    assert tensorflow_code(Derivative(expr, x)) == \\\n        \"tensorflow.gradients(x**2 + y**2, x)[0]\"\n    _compare_tensorflow_scalar((x, y), Derivative(expr, x))\n\n    expr = sin(x) * y\n    assert tensorflow_code(Derivative(expr, x)) == \\\n        \"tensorflow.gradients(tensorflow.math.sin(x) * y, x)[0]\"\n    _compare_tensorflow_scalar((x, y), Derivative(expr, x))\n\n    expr = x**2 * y**3\n    assert tensorflow_code(Derivative(expr, y)) == \\\n        \"tensorflow.gradients(x**2 * y**3, y)[0]\"\n    _compare_tensorflow_scalar((x, y), Derivative(expr, y))\n\n    expr = x**2 * y**3\n    assert tensorflow_code(Derivative(expr, x, y)) == \\\n        \"tensorflow.gradients(x**2 * y**3, [x, y])[0]\"\n    _compare_tensorflow_scalar((x, y), Derivative(expr, x, y))\n"], "sample_27": ["compilation error"], "sample_1057": ["compilation error"], "sample_573": ["    def test_polyfit_order(self, df):\n\n        groupby = GroupBy([\"group\"])\n        res_order_1 = PolyFit(order=1, gridsize=100)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n        res_order_2 = PolyFit(order=2, gridsize=100)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n\n        for _, part in res_order_1.groupby(\"group\"):\n            assert part[\"y\"].diff().diff().dropna().abs().gt(0).all()\n\n        for _, part in res_order_2.groupby(\"group\"):\n            assert part[\"y\"].diff().diff().dropna().abs().gt(0).all()\n\n        # Check that the order of the polynomial affects the fitted curve\n        assert_array_almost_equal(res_order_1[\"y\"].values, res_order_2[\"y\"].values, decimal=2)\n"], "sample_265": ["    def test_template_context_processors(self):\n        engine = DjangoTemplates({\n            'DIRS': [],\n            'APP_DIRS': False,\n            'NAME': 'django',\n            'OPTIONS': {\n                'context_processors': [\n                    lambda context: {'extra_context': 'from context_processors'},\n                ],\n            },\n        })\n        template = engine.from_string('{{ extra_context }}')\n        request = self.request_factory.get('/')\n        content = template.render({}, request)\n        self.assertEqual(content, 'from context_processors')\n"], "sample_343": ["    def test_get_content_type_with_instance(self):\n        question = Question.objects.create(text='Who?')\n        answer = Answer.objects.create(question=question, text='Me!')\n\n        self.assertEqual(answer.question.get_content_type(obj=answer), ContentType.objects.get_for_model(Question))\n"], "sample_147": ["    def test_union_with_distinct_and_ordering(self):\n        qs1 = Number.objects.filter(num__lte=1).union(Number.objects.filter(num__gte=8))\n        self.assertNumbersEqual(qs1.distinct().order_by('num'), [0, 1, 8, 9])\n\n"], "sample_1152": ["def test_issue_18376():\n    x, y = symbols('x y', positive=True)\n    assert powsimp(sqrt(x*y)*sqrt(x*y)) == x*y\n    assert powsimp(sqrt(x*y)*sqrt(x*y), combine='all') == x*y\n    assert powsimp(sqrt(x*y)*sqrt(x*y), combine='exp') == x*y\n"], "sample_183": ["    def test_invalid_output_field_type(self):\n        with self.assertRaisesMessage(TypeError, 'Output field must be a Field or None'):\n            Case(\n                When(Q(pk__gt=0), then=Value('1', output_field=str)),\n            )\n"], "sample_1058": ["def test_issue_14283_rational_in_pow():\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(x**Rational(1, 3)) == 'x**(1/3)'\n    assert prntr.doprint(x**Rational(2, 3)) == 'x**(2/3)'\n"], "sample_465": ["    def test_get_form_sets_with_inlines(self):\n        class ConcertInline(TabularInline):\n            model = Concert\n            fk_name = \"main_band\"\n\n        class BandAdmin(ModelAdmin):\n            inlines = [ConcertInline]\n\n        ma = BandAdmin(Band, self.site)\n        request = MockRequest()\n        formsets = ma.get_formsets_with_inlines(request)\n        self.assertEqual(len(formsets), 1)\n        self.assertIsInstance(formsets[0], ConcertInline)\n"], "sample_406": ["    def test_refresh_from_db_with_prefetch_related(self):\n        a = Article.objects.create(headline=\"Parrot programs in Python\", pub_date=datetime(2005, 7, 28))\n        b = Article.objects.create(headline=\"Swallow programs in Python\", pub_date=datetime(2005, 7, 28))\n        f1 = FeaturedArticle.objects.create(article=a)\n        f2 = FeaturedArticle.objects.create(article=b)\n        with self.assertNumQueries(1):\n            a.refresh_from_db(prefetch_related=['featured'])\n        self.assertEqual(len(a.featured.all()), 1)\n        with self.assertNumQueries(0):\n            a.refresh_from_db(prefetch_related=['featured'])\n        self.assertEqual(len(a.featured.all()), 1)\n"], "sample_759": ["def test_one_hot_encoder_sparse_output():\n    X = np.array([['abc', 2, 55], ['def', 1, 55]])\n    enc = OneHotEncoder(sparse=True)\n    X_tr = enc.fit_transform(X)\n    assert isinstance(X_tr, sparse.csr_matrix)\n    assert X_tr.shape == (2, 6)\n\n    enc = OneHotEncoder(sparse=True, handle_unknown='ignore')\n    X_tr = enc.fit_transform(X)\n    assert isinstance(X_tr, sparse.csr_matrix)\n    assert X_tr.shape == (2, 6)\n\n    enc = OneHotEncoder(sparse=True, categories='auto')\n    X_tr = enc.fit_transform(X)\n    assert isinstance(X_tr, sparse.csr_matrix)\n    assert X_tr.shape == (2, 6)\n"], "sample_948": ["def test_build_domain_cpp_template_param_qualified_name(app, status, warning):\n    app.builder.build_all()\n    ws = filter_warnings(warning, \"warn-template-param-qualified-name\")\n    assert len(ws) == 2\n    assert \"WARNING: cpp:type reference target not found: T::typeWarn\" in ws[0]\n    assert \"WARNING: cpp:type reference target not found: T::U::typeWarn\" in ws[1]\n"], "sample_756": ["def test_reachability_distance_calculation():\n    # Test reachability distance calculation with various eps values\n    centers = [[1, 1], [-1, -1], [1, -1]]\n    X, labels_true = make_blobs(n_samples=750, centers=centers,\n                                cluster_std=0.4, random_state=0)\n\n    # Compute OPTICS with different eps values\n    eps_values = [0.1, 0.3, 0.5]\n    for eps in eps_values:\n        clust = OPTICS(min_samples=10, max_eps=eps).fit(X)\n        for i in range(len(X)):\n            for j in range(len(X)):\n                if i != j:\n                    # Check reachability distance calculation\n                    dist = pairwise_distances(X[[i]], X[[j]])\n                    reachability = clust.reachability_[i]\n                    expected_reachability = max(dist, clust.core_distances_[i])\n                    assert_allclose(reachability, expected_reachability, atol=1e-6)\n\n\n\n"], "sample_122": ["    def test_cache_key_with_user(self):\n        request = self.factory.get(self.path)\n        request.user = User.objects.create(username='testuser')\n        template = engines['django'].from_string(\"This is a test\")\n        response = TemplateResponse(request, template)\n        key = get_cache_key(request)\n        self.assertIn('user_id', key)\n        self.assertIn(str(request.user.id), key)\n\n\n\n"], "sample_782": ["compilation error"], "sample_804": ["def test_one_hot_encoder_sparse_output():\n    X = [['abc', 2, 55], ['def', 1, 55]]\n    enc = OneHotEncoder(sparse=True)\n    exp = csr_matrix([[1, 0, 1, 0],\n                      [0, 1, 0, 1]])\n    assert_array_equal(enc.fit_transform(X).toarray(), exp.toarray())\n    assert isinstance(enc.fit_transform(X), csr_matrix)\n\n    enc = OneHotEncoder(sparse=True, handle_unknown='ignore')\n    X2 = [['abc', 2, 55], ['def', 1, 56]]\n    exp = csr_matrix([[1, 0, 1, 0],\n                      [0, 1, 0, 0]])\n    assert_array_equal(enc.fit_transform(X2).toarray(), exp.toarray())\n    assert isinstance(enc.fit_transform(X2), csr_matrix)\n\n\n\n"], "sample_1010": ["def test_Tensor_printing():\n    from sympy.tensor.tensor import Tensor\n    T = Tensor('T', indices='ijk')\n    assert latex(T) == r'T_{ijk}'\n    T = Tensor('T', indices='ij')\n    assert latex(T) == r'T_{ij}'\n    T = Tensor('T', indices='i')\n    assert latex(T) == r'T_{i}'\n    T = Tensor('T', indices='i')\n    assert latex(T) == r'T_{i}'\n"], "sample_1048": ["compilation error"], "sample_1079": ["def test_direction_cosine():\n    p1 = Point3D(1, 0, 0)\n    p2 = Point3D(0, 1, 0)\n    p3 = Point3D(0, 0, 1)\n    assert p1.direction_cosine(p2) == [1, 0, 0]\n    assert p1.direction_cosine(p3) == [0, 0, 1]\n    assert p2.direction_cosine(p3) == [0, 1, 0]\n    assert p1.direction_cosine(Point3D(1, 1, 1)) == [sqrt(1/3), sqrt(1/3), sqrt(1/3)]\n"], "sample_1044": ["def test_issue_10302_2():\n    x = Symbol('x')\n    r = Symbol('r', real=True)\n    u = -(3*2**pi)**(1/pi) + 2*3**(1/pi)\n    i = u + u*I\n    assert (u + i).is_real is None  # w/o simplification this should fail\n    assert (1 + i).is_real is None\n    assert (1 + i).is_imaginary\n    a = Dummy('a', zero=True)\n    assert (a + I).is_imaginary\n    assert (a + r*I).is_imaginary is None\n    assert (a + I + x).is_imaginary is None\n    assert (a + r*I + x).is_imaginary is None\n"], "sample_805": ["def test_regression_multioutput_invalid_multioutput():\n    y_true = [[1, 2], [2.5, -1], [4.5, 3], [5, 7]]\n    y_pred = [[1, 1], [2, -1], [5, 4], [5, 6.5]]\n\n    with pytest.raises(ValueError,\n                       match=\"Allowed 'multioutput' string values are.*\"):\n        mean_squared_error(y_true, y_pred, multioutput='invalid_value')\n\n    with pytest.raises(ValueError,\n                       match=\"Allowed 'multioutput' string values are.*\"):\n        mean_absolute_error(y_true, y_pred, multioutput='invalid_value')\n\n    with pytest.raises(ValueError,\n                       match=\"Allowed 'multioutput' string values are.*\"):\n        r2_score(y_true, y_pred, multioutput='invalid_value')\n\n    with pytest.raises(ValueError,\n                       match=\"Allowed 'multioutput' string values are.*\"):\n        explained_variance_score(y_true, y_pred, multioutput='invalid_value')\n"], "sample_504": ["def test_colorbar_fraction_with_constrained_layout():\n    fig, ax = plt.subplots(constrained_layout=True)\n    pc = ax.imshow(np.random.rand(10, 10))\n    cb = fig.colorbar(pc, ax=ax, fraction=0.05)\n    fig.draw_without_rendering()\n    assert 0.05 <= cb.ax.get_position().height <= 0.06\n"], "sample_246": ["    def test_custom_layout_with_multiple_apps(self):\n        \"\"\"\n        * translations for an app containing a locale folder are stored in that folder\n        * translations outside of that app are in LOCALE_PATHS[0]\n        \"\"\"\n        with override_settings(LOCALE_PATHS=[os.path.join(self.test_dir, 'project_locale')]):\n            management.call_command('makemessages', locale=[LOCALE], verbosity=0)\n            project_de_locale = os.path.join(\n                self.test_dir, 'project_locale', 'de', 'LC_MESSAGES', 'django.po')\n            app1_de_locale = os.path.join(\n                self.test_dir, 'app1', 'locale', 'de', 'LC_MESSAGES', 'django.po')\n            app2_de_locale = os.path.join(\n                self.test_dir, 'app2', 'locale', 'de', 'LC_MESSAGES', 'django.po')\n            self.assertTrue(os.path.exists(project_de_locale))\n            self.assertTrue(os.path.exists(app1_de_locale))\n            self.assertTrue(os.path.exists(app2_de_locale))\n\n            with open(project_de_locale) as fp:\n                po_contents = fp.read()\n                self.assertMsgId('This app has no locale directory', po_contents)\n                self.assertMsgId('This is a project-level string', po_contents)\n            with open(app1_de_locale) as fp:\n                po_contents = fp.read()\n                self.assertMsgId('This app has a locale directory', po_contents)\n            with open(app2_de_locale) as fp:\n                po_contents = fp.read()\n                self.assertMsgId('This app has a locale directory', po_contents)\n"], "sample_1102": ["def test_issue_18205():\n    assert cancel((2 + I)*(3 - I)) == 7 + I\n    assert cancel((2 + I)*(2 - I)) == 5\n"], "sample_443": ["    def test_cache_key_with_user_agent(self):\n        request = self.factory.get(self.path)\n        request.META[\"HTTP_USER_AGENT\"] = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n        template = engines[\"django\"].from_string(\"This is a test\")\n        response = TemplateResponse(HttpRequest(), template)\n        learn_cache_key(request, response)\n        self.assertEqual(\n            get_cache_key(request),\n            \"views.decorators.cache.cache_page.settingsprefix.GET.\"\n            \"Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20Win64%3B%20x64)%20AppleWebKit%2F537.36%20(KHTML%2C%20like%20Gecko)%20Chrome%2F58.0.3029.110%20Safari%2F537.36.d41d8cd98f00b204e9800998ecf8427e\",\n        )\n"], "sample_301": ["    def test_snapshot_files_handles_new_files(self):\n        new_file = self.ensure_file(self.tempdir / 'new_file.py')\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file, new_file]):\n            snapshot1 = dict(self.reloader.snapshot_files())\n            self.assertIn(self.existing_file, snapshot1)\n            self.assertIn(new_file, snapshot1)\n"], "sample_868": ["def test_empty_labels(metric):\n    # Check for empty labels\n    with pytest.raises(ValueError):\n        metric([], [])\n    with pytest.raises(ValueError):\n        metric([], [0])\n    with pytest.raises(ValueError):\n        metric([0], [])\n"], "sample_788": ["def test_fit_transform_with_constant_feature(strategy):\n    X = np.array([[1, 1],\n                  [1, 1],\n                  [1, 1],\n                  [1, 1]])\n    est = KBinsDiscretizer(n_bins=3, strategy=strategy, encode='ordinal')\n    Xt = est.fit_transform(X)\n    assert_array_equal(Xt, np.zeros((X.shape[0], Xt.shape[1])))\n"], "sample_121": ["    def test_check_constraints_with_custom_error_message(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(\n                        check=models.Q(age__gte=18),\n                        name='is_adult',\n                        message='You must be at least 18 years old.'\n                    )\n                ]\n\n        errors = Model.check()\n        expected = [\n            Error(\n                \"You must be at least 18 years old.\",\n                obj=Model,\n                id='models.E028',\n            )\n        ]\n        self.assertCountEqual(errors, expected)\n"], "sample_358": ["    def test_str_with_multiple_references(self):\n        compiler = Person.objects.all().query.get_compiler(connection.alias)\n        expressions = Expressions(\n            table=Person._meta.db_table,\n            expressions=ExpressionList(\n                IndexExpression(F('first_name')),\n                IndexExpression(F('last_name').desc()),\n                IndexExpression(Upper('last_name')),\n            ).resolve_expression(compiler.query),\n            compiler=compiler,\n            quote_value=self.editor.quote_value,\n        )\n        self.expressions.rename_table_references(Person._meta.db_table, 'other')\n        self.expressions.rename_column_references(Person._meta.db_table, 'first_name', 'other_first_name')\n        self.expressions.rename_column_references(Person._meta.db_table, 'last_name', 'other_last_name')\n        expected_str = '(UPPER(%s)), %s, %s' % (\n            self.editor.quote_name('other_last_name'),\n            self.editor.quote_name('other_first_name'),\n            self.editor.quote_name('other_last_name'),\n        )\n        self.assertEqual(str(expressions), expected_str)\n"], "sample_171": ["    def test_squashmigrations_app_name_specified_as_label(self):\n        with self.assertRaisesMessage(CommandError, self.did_you_mean_auth_error):\n            call_command('squashmigrations', 'django.contrib.auth', '0002')\n"], "sample_435": ["    def test_password_too_short(self):\n        user = User.objects.get(username=\"testclient\")\n        data = {\"password1\": \"too\", \"password2\": \"too\"}\n        form = AdminPasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors[\"password1\"], [\n            \"The password must be at least 8 characters long.\"\n        ])\n        self.assertEqual(form.errors[\"password2\"], [\n            \"The password must be at least 8 characters long.\"\n        ])\n        self.assertEqual(form.changed_data, [])\n"], "sample_674": ["def test_get_fslocation_from_item_with_obj():\n    class MyObject:\n            self.filename = filename\n            self.lineno = lineno\n\n    testdir = py.test.ensuretemp(\"test_get_fslocation_from_item\")\n    testdir.mkdir()\n    testfile = testdir.join(\"test.py\")\n    with open(testfile, \"w\") as f:\n        f.write(\n            f\"\"\"\n                pass\n            \"\"\"\n        )\n    item = nodes.Item(\n        name=\"test_something\",\n        parent=None,\n        config=None,\n        session=None,\n        nodeid=None,\n    )\n    item.obj = MyObject(testfile.strpath, 5)\n    assert nodes.get_fslocation_from_item(item) == (testfile.strpath, 5)\n"], "sample_1141": ["def test_matrix_subs():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    D = MatrixSymbol('D', 2, 2)\n    M = A*B + C*D\n    assert M.subs({A: B, C: D}) == B*B + D*D\n    assert M.subs({A: B, C: C}) == B*B + C*C\n    assert M.subs({A: B, D: D}) == B*B + C*D\n    assert M.subs({B: A, C: D}) == A*A + C*D\n    assert M.subs({B: A, C: C}) == A*A + C*C\n    assert M.subs({B: A, D: D}) == A*A + C*D\n    assert M.subs({A: A, B: B, C: C, D: D}) == A*B + C*D\n    raises(ValueError, lambda: M.subs({A: 1}))\n    raises(ValueError, lambda: M.subs({A: 2, B: 3, C: 4}))\n"], "sample_967": ["def test_mathjax_inline_custom(app, status, warning):\n    app.builder.build_all()\n\n    content = (app.outdir / 'index.html').read_text()\n    html = (r'<div class=\"math notranslate nohighlight\">\\s*'\n            r'\\(a\\^2\\+b\\^2=c\\^2\\\\\\)')\n    assert re.search(html, content, re.S)\n"], "sample_973": ["compilation error"], "sample_531": ["compilation error"], "sample_439": ["    def test_custom_renderer_with_form_field_errors(self):\n        class CustomRenderer(DjangoTemplates):\n            form_template_name = \"forms_tests/form_snippet.html\"\n\n        class UserRegistration(Form):\n            username = CharField(max_length=10)\n            password1 = CharField(widget=PasswordInput)\n            password2 = CharField(widget=PasswordInput)\n\n                if (\n                    self.cleaned_data.get(\"password1\")\n                    and self.cleaned_data.get(\"password2\")\n                    and self.cleaned_data[\"password1\"] != self.cleaned_data[\"password2\"]\n                ):\n                    raise ValidationError(\"Please make sure your passwords match.\")\n                return self.cleaned_data\n\n        @override_settings(FORM_RENDERER=\"forms_tests.tests.test_forms.CustomRenderer\")\n            if method == \"POST\":\n                form = UserRegistration(post_data, auto_id=False)\n            else:\n                form = UserRegistration(auto_id=False)\n\n            if form.is_valid():\n                return \"VALID: %r\" % sorted(form.cleaned_data.items())\n\n            return form\n\n        # POST with erroneous data, a redisplayed form, with errors.\n        form = my_function(\"POST\", {\n            \"username\": \"this-is-a-long-username\",\n            \"password1\": \"foo\",\n            \"password2\": \"bar\",\n        })\n        expected = \"\"\"\n        <div class=\"fieldWrapper\"><label for=\"id_username\">Username:</label>\n        <input type=\"text\" name=\"username\" value=\"this-is-a-long-username\" maxlength=\"10\" required id=\"id_username\"></div>\n        <div class=\"fieldWrapper\"><label for=\"id_password1\">Password1:</label>\n        <input type=\"password\" name=\"password1\" required id=\"id_password1\"></div>\n        <div class=\"fieldWrapper\"><label for=\"id_password2\">Password2:</label>\n        <input type=\"password\" name=\"password2\" required id=\"id_password2\"></div>\n        "], "sample_958": ["compilation error"], "sample_286": ["    def test_refresh_with_related_objects(self):\n        a = Article.objects.create(headline='Parrot programs in Python', pub_date=datetime(2005, 7, 28))\n        s1 = SelfRef.objects.create(article=a)\n        s2 = SelfRef.objects.create(article=a)\n        with self.assertNumQueries(1):\n            s1.refresh_from_db()\n        with self.assertNumQueries(1):\n            s2.refresh_from_db()\n        self.assertEqual(s1.article, a)\n        self.assertEqual(s2.article, a)\n"], "sample_1053": ["def test_issue_10841():\n    assert Float('1.234567890123456789012345678901234567890', 100) == Float('1.234567890123456789012345678901234567890', 100)\n"], "sample_289": ["    def test_setdefault(self):\n        self.assertEqual(self.dict1.setdefault('new_key', 'default'), 'default')\n        self.assertEqual(self.dict1['new_key'], 'default')\n        self.assertEqual(self.dict1.setdefault('Accept', 'new_value'), 'application/json')\n        self.assertEqual(self.dict1['Accept'], 'application/json')\n"], "sample_950": ["def test_python_python_use_unqualified_type_names_enabled(app, status, warning):\n    app.build()\n    content = (app.outdir / 'index.html').read_text()\n    assert ('<span class=\"n\"><a class=\"reference internal\" href=\"#Name\" title=\"Name\">'\n            '<span class=\"pre\">Name</span></a></span>' in content)\n    assert '<span class=\"n\"><span class=\"pre\">Age</span></span>' in content\n"], "sample_417": ["    def test_floatformat_with_locale(self):\n        with translation.override(\"de\"):\n            self.assertEqual(floatformat(10000, \"g\"), \"10.000\")\n            self.assertEqual(floatformat(66666.666, \"1g\"), \"66.666,7\")\n        with translation.override(\"fr\"):\n            self.assertEqual(floatformat(10000, \"g\"), \"10 000\")\n            self.assertEqual(floatformat(66666.666, \"1g\"), \"66 666,7\")\n"], "sample_399": ["    def test_aggregation_subquery_annotation_with_distinct(self):\n        subquery_qs = (\n            Author.objects.filter(pk=OuterRef(\"pk\"))\n            .values(\"age\")\n            .annotate(distinct_age=Distinct(\"age\"))\n        )\n        author_qs = Author.objects.annotate(\n            distinct_age=Subquery(subquery_qs),\n        ).values_list(\"name\", \"distinct_age\")\n        self.assertSequenceEqual(\n            author_qs,\n            [\n                (\"Adrian Holovaty\", 1),\n                (\"Jacob Kaplan-Moss\", 1),\n                (\"Brad Dayley\", 1),\n                (\"James Bennett\", 1),\n                (\"Jeffrey Forcier\", 1),\n                (\"Paul Bissex\", 1),\n                (\"Wesley J. Chun\", 1),\n                (\"Stuart Russell\", 1),\n                (\"Peter Norvig\", 1),\n            ],\n        )\n"], "sample_981": ["def test_inversion_vector():\n    p = Permutation([1, 5, 2, 0, 3, 6, 4])\n    assert p.inversion_vector() == [2, 4, 1, 3, 1, 0]\n    assert Permutation([0, 1, 2, 3]).inversion_vector() == [0, 0, 0, 0]\n    assert Permutation([3, 2, 1, 0]).inversion_vector() == [3, 2, 1, 0]\n    assert Permutation([0, 4, 1, 3, 2, 5, 6]).inversion_vector() == [1, 2, 1, 1, 0, 0, 0]\n    assert Permutation([0, 1, 2, 3, 4, 5, 6]).inversion_vector() == [0, 0, 0, 0, 0, 0, 0]\n    assert Permutation([6, 5, 4, 3, 2, 1, 0]).inversion_vector() == [6, 5, 4, 3, 2, 1, 0]\n    assert Permutation([0, 3, 1, 2, 4, 5, 6]).inversion_vector() == [1, 2, 1, 0, 0, 0, 0]\n    assert Permutation([6, 4, 2, 0, 1, 3, 5]).inversion_vector() == [3, 2, 1, 0, 0, 0, 0]\n    assert Permutation([5, 4, 3, 2, 1, 0, 6]).inversion_vector() == [1, 0, 0, 0, 0, 0, 0]\n    assert Permutation([1, 3, 2, 0, 4, 5, 6]).inversion_vector() == [1, 1, 0, 0, 0, 0, 0]\n    assert Permutation([4, 2, 0, "], "sample_605": ["def test_groupby_empty_groups():\n    array = xr.DataArray([1, 2, 3], [(\"x\", [1, 2, 2])])\n    with pytest.raises(ValueError):\n        array.groupby(\"x\").mean()\n"], "sample_600": ["def test_encode_unsigned_from_signed(dtype):\n    signed_dtype = np.dtype(dtype)\n    unsigned_dtype = np.dtype(f\"u{signed_dtype.itemsize}\")\n    original_values = np.array([np.iinfo(signed_dtype).max], dtype=signed_dtype)\n    encoded = xr.Variable(\n        (\"x\",), original_values.astype(unsigned_dtype), attrs={\"_Unsigned\": \"true\"}\n    )\n    coder = variables.UnsignedIntegerCoder()\n    decoded = coder.encode(encoded)\n    assert decoded.dtype == unsigned_dtype\n    assert decoded.values == original_values\n"], "sample_146": ["    def test_consistent_language_settings(self):\n        with self.subTest('en'):\n            self.assertEqual(check_language_settings_consistent(None), [])\n"], "sample_1108": ["compilation error"], "sample_98": ["    def test_broken_pipe_error(self):\n        \"\"\"\n        Broken pipe errors are handled gracefully.\n        \"\"\"\n        conn = HTTPConnection(LiveServerViews.server_thread.host, LiveServerViews.server_thread.port)\n        try:\n            conn.request('GET', '/example_view/')\n            response = conn.getresponse()\n            # Simulate a broken pipe error\n            conn.close()\n            # This should not raise an exception\n            response.read()\n        except BrokenPipeError:\n            pass\n        finally:\n            conn.close()\n"], "sample_1030": ["def test_farthest_points():\n    p = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4)]\n    assert farthest_points(*p) == {(Point2D(1, 1), Point2D(15, 4))}\n    p = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4), (1, 1)]\n    assert farthest_points(*p) == {(Point2D(1, 1), Point2D(15, 4))}\n    p = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4), (1, 1), (1, 1)]\n    assert farthest_points(*p) == {(Point2D(1, 1), Point2D(15, 4))}\n\n\n\n"], "sample_11": ["def test_pixel_to_world_values_with_ellipsis():\n    wcs = WCS_SPECTRAL_CUBE\n    sub = SlicedLowLevelWCS(wcs, np.s_[:, :, :])\n    assert_allclose(sub.pixel_to_world_values(10, 15, 20), (10, 20, 25))\n    assert_allclose(sub.pixel_to_world_values(10, 15, 20), (10, 20, 25))\n    assert_allclose(sub.pixel_to_world_values(10, 15, 20), (10, 20, 25))\n"], "sample_512": ["def test_subplot_projection_reuse_with_kwargs():\n    # check that subplot with projection and kwargs reuse existing axes\n    ax1 = plt.subplot(111, projection='polar')\n    ax2 = plt.subplot(111, projection='polar', theta_offset=0)\n    assert ax1 is ax2\n\n    ax1.remove()\n    ax2 = plt.subplot(111, projection='polar', theta_offset=1)\n    assert ax2 is not ax1\n"], "sample_708": ["def test_multiline_string_in_statement() -> None:\n    source = \"\"\"\\"], "sample_339": ["    def test_modelformset_factory_passes_renderer_to_formset(self):\n        from django.forms.renderers import HTMLRenderer\n        renderer = HTMLRenderer()\n        AuthorFormSet = modelformset_factory(Author, fields='__all__', renderer=renderer)\n        formset = AuthorFormSet()\n        self.assertEqual(formset.renderer, renderer)\n"], "sample_429": ["    def test_validate_image_file_extension_with_message(self):\n        v = FileExtensionValidator(\n            allowed_extensions=[\"jpg\", \"png\"],\n            message=\"Only JPG and PNG files are allowed.\",\n        )\n        with self.assertRaisesMessage(\n            ValidationError, \"Only JPG and PNG files are allowed.\"\n        ):\n            v(ContentFile(\"contents\", name=\"file.txt\"))\n"], "sample_1181": ["def test_scipy_array_sparse_matrix():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    from scipy.sparse import coo_matrix\n    sparse_matrix = coo_matrix([[1, 2], [3, 4]])\n    prntr = SciPyPrinter()\n    assert prntr.doprint(sparse_matrix) == \"scipy.sparse.coo_matrix((array([1, 2, 3, 4]), (array([0, 0, 1, 1]), array([0, 1, 0, 1])))\"\n"], "sample_840": ["def test_sparse_data():\n    from scipy.sparse import csr_matrix\n    d = load_linnerud()\n    X = csr_matrix(d.data)\n    Y = d.target\n    for clf in [pls_.PLSCanonical(), pls_.PLSRegression(),\n                pls_.PLSSVD()]:\n        clf.fit(X, Y)\n"], "sample_41": ["def test_unit_summary_equivalencies():\n    \"\"\"\n    Test for a few units that the unit summary table correctly reports\n    whether or not that unit has equivalencies.\n\n    Regression test for https://github.com/astropy/astropy/issues/3835\n    \"\"\"\n    from astropy.units import astrophys\n\n    for summary in utils._iter_unit_summary(astrophys.__dict__):\n        unit, _, _, equivalencies, _ = summary\n\n        if unit.name == 'pc':\n            assert equivalencies\n        elif unit.name == 'erg':\n            assert equivalencies\n        elif unit.name == 'cycle':\n            assert not equivalencies\n"], "sample_238": ["    def test_aggregation_subquery_annotation_related_field_multiple(self):\n        publisher = Publisher.objects.create(name=self.a9.name, num_awards=2)\n        book = Book.objects.create(\n            isbn='159059999', name='Test book.', pages=819, rating=2.5,\n            price=Decimal('14.44'), contact=self.a9, publisher=publisher,\n            pubdate=datetime.date(2019, 12, 6),\n        )\n        book.authors.add(self.a5, self.a6, self.a7)\n        books_qs = Book.objects.annotate(\n            contact_publisher=Subquery(\n                Publisher.objects.filter(\n                    pk=OuterRef('publisher'),\n                    name=OuterRef('contact__name'),\n                ).values('name')[:1],\n            )\n        ).filter(\n            contact_publisher__isnull=False,\n        ).annotate(count=Count('authors')).order_by('contact_publisher')\n        self.assertSequenceEqual(\n            list(books_qs), [\n                {'contact_publisher': 'Jonno', 'count': 3},\n            ]\n        )\n"], "sample_7": ["def test_masked_column_serialize_method_default():\n    mc = table.MaskedColumn([1., 2., 3.], mask=[True, False, True])\n    assert mc.info.serialize_method['ecsv'] == 'null_value'\n"], "sample_679": ["    def test_pytest_param_id_allows_none_or_string(s):\n        assert pytest.param(id=s)\n"], "sample_24": ["    def test_masked_array_creation_from_masked_ndarray(self):\n        ma = Masked(np.array([1, 2, 3]), mask=[False, True, False])\n        mb = MaskedArray(ma)\n        assert_array_equal(mb.unmasked, ma.unmasked)\n        assert_array_equal(mb.mask, ma.mask)\n"], "sample_978": ["def test_bspline_basis_with_rational_knots():\n    d = 2\n    knots = [Rational(1, 2), Rational(1, 2), Rational(3, 2), Rational(3, 2), Rational(5, 2)]\n    splines = bspline_basis_set(d, knots, x)\n    b0 = Piecewise((x**2/2, Interval(Rational(1, 2), Rational(3, 2)).contains(x)),\n                   (Rational(-3, 2) + 3*x - x**2, Interval(Rational(3, 2), Rational(5, 2)).contains(x)),\n                   (0, True))\n    assert splines[0] == b0\n"], "sample_226": ["    def test_clone_test_db(self, mocked_sync_apps, mocked_migrate, *mocked_objects):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        creation = test_connection.creation_class(test_connection)\n        if connection.vendor == 'oracle':\n            # Don't close connection on Oracle.\n            creation.connection.close = mock.Mock()\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db'):\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n            # Migrations run.\n            mocked_migrate.assert_called()\n            args, kwargs = mocked_migrate.call_args\n            self.assertEqual(args, ([('app_unmigrated', '0001_initial')],))\n            self.assertEqual(len(kwargs['plan']), 1)\n            # App is not synced.\n            mocked_sync_apps.assert_not_called()\n            # Clone the test database\n            creation.clone_test_db(suffix='_clone')\n            # Migrations run again for the clone.\n            mocked_migrate.assert_called_with(\n                [],\n                kwargs={'plan': [('app_unmigrated', '0001_initial')]},\n            )\n            # App is not synced.\n            mocked_sync_apps.assert_not_called()\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n"], "sample_560": ["def test_loc_invalid_string():\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError, match=('loc must be string, coordinate '\n                       'tuple, or an integer 0-10, not \"invalid_string\")):\n        ax.legend(loc=\"invalid_string\")\n"], "sample_625": ["    def test_polyfit_polyval_integration_with_coords(\n        use_dask: bool, x: xr.DataArray, y: xr.DataArray"], "sample_114": ["    def test_add_blank_textfield_and_charfield_with_default(self):\n        \"\"\"\n        #23405 - Adding a NOT NULL and blank `CharField` or `TextField`\n        with a default should not prompt for a default.\n        \"\"\"\n        changes = self.get_changes([self.author_empty], [self.author_with_biography_blank_default])\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0)\n"], "sample_1046": ["compilation error"], "sample_32": ["    def test_de_density_scale(self, cosmo, z):\n        \"\"\"Test :meth:`astropy.cosmology.w0wzCDM.de_density_scale`.\"\"\"\n        scale = cosmo.de_density_scale(z)\n        assert u.allclose(scale, 1.0)\n"], "sample_962": ["def test_stringify_type_hints_TypedDict():\n    from typing import TypedDict  # type: ignore\n    class MyTypedDict(TypedDict):\n        name: str\n        age: int\n    assert stringify(MyTypedDict) == \"tests.test_util_typing.MyTypedDict\"\n"], "sample_911": ["    def check_xref(role, target, expected_output):\n        pattern = r'{role}-role:.*?' \\\n                  r'<a .*?>.*?' \\\n                  r'<strong>{}</strong>.*?' \\\n                  r'</a>'.format(target)\n        result = re.search(pattern, output)\n        assert result, f\"Pattern for role '{role}' with target '{target}' not found in '{test}'\"\n        return result.group(0)\n"], "sample_206": ["    def test_file_field_with_upload_to(self):\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            with override_settings(MEDIA_ROOT=Path(tmp_dir)):\n                document = Document(myfile=temp.NamedTemporaryFile(delete=False).file)\n                document.upload_to = 'uploads/documents/%Y/%m/%d'\n                document.save()\n                self.assertEqual(document.myfile.path, os.path.join(tmp_dir, 'uploads', 'documents', document.myfile.name))\n"], "sample_205": ["    def test_update_error_dict(self):\n        error_dict = {}\n        exception = ValidationError(error_dict)\n        self.assertEqual(error_dict, {})\n        error_dict = {'field1': ['E1', 'E2']}\n        exception = ValidationError(error_dict)\n        self.assertEqual(exception.update_error_dict(error_dict), error_dict)\n        error_dict = {'field2': ['E3', 'E4']}\n        exception = ValidationError(error_dict)\n        self.assertEqual(exception.update_error_dict(error_dict), {'field1': ['E1', 'E2'], 'field2': ['E3', 'E4']})\n        error_dict = {'field1': ['E5', 'E6']}\n        exception = ValidationError(error_dict)\n        self.assertEqual(exception.update_error_dict(error_dict), {'field1': ['E1', 'E2', 'E5', 'E6'], 'field2': ['E3', 'E4']})\n        error_dict = {'field1': ['E7', 'E8']}\n        exception = ValidationError(error_dict)\n        self.assertEqual(exception.update_error_dict(error_dict), {'field1': ['E1', 'E2', 'E5', 'E6', 'E7', 'E8'], 'field2': ['E3', 'E4']})\n        error_dict = {}\n        exception = ValidationError(error_dict)\n        self.assertEqual(exception.update_error_dict(error_dict), {'field1': ['E1', 'E2', 'E5', 'E6', 'E7', 'E8'], 'field2': ['E3', 'E4']})\n        error_dict = {'__all__': ['E9', 'E10']}\n        exception = ValidationError(error_dict)\n        self.assertEqual(exception.update_error_dict(error_dict), {'__all__': ['E9', 'E10']})\n"], "sample_694": ["def test_deprecated_argument_type_str_choice(pytester: Pytester) -> None:\n    with pytest.warns(\n        PytestDeprecationWarning,\n        match=re.escape(\n            \"`type` argument to addoption() is the string {typ!r}, \"\n            \"but when supplied should be a type (for example `str` or `int`). \"\n            \"(options: {names})\"\n        ),\n    ) as record:\n        pytester.makeconftest(\n            \"\"\"\n            from _pytest.config import addoption\n\n            addoption(\n                \"--foo\",\n                type=\"str\",\n                help=\"A string option\",\n            )\n            \"\"\"\n        )\n        pytester.runpytest()\n    assert len(record) == 1\n"], "sample_1071": ["def test_check_dimensions():\n    from sympy.physics.units import meter, second, kilogram, newton\n    with raises(ValueError):\n        check_dimensions(meter + newton)\n    with raises(ValueError):\n        check_dimensions(meter + kilogram)\n    with raises(ValueError):\n        check_dimensions(meter + kilogram*meter/second)\n    assert check_dimensions(meter + meter) == 2*meter\n    assert check_dimensions(meter*second + meter*second) == 2*meter*second\n    assert check_dimensions(meter*second*kilogram + meter*second*kilogram) == 2*meter*second*kilogram\n    assert check_dimensions(meter*second*kilogram + newton) == meter*second*kilogram + newton\n"], "sample_1182": ["def test_hypergeometric_functions():\n    from sympy.functions.special.hypergeometric_functions import (\n        hyper,\n    )\n\n    expr = hyper([1, 2], [3], x)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr) == 'scipy.special.hyperu(1, 2, 3, x)'\n\n    prntr = NumPyPrinter()\n    assert \"Not supported\" in prntr.doprint(expr)\n\n    prntr = PythonCodePrinter()\n    assert \"Not supported\" in prntr.doprint(expr)\n\n    prntr = MpmathPrinter()\n    assert prntr.doprint(expr) == 'mpmath.hyper(1, 2, 3, x)'\n"], "sample_104": ["    def test_manifest_cache_invalidation(self):\n        filename = self._get_filename_path(\"cached/styles.css\")\n        with open(filename, 'w') as f:\n            f.write(\"body { background-image: url('img/background.png'); }\")\n        self.run_collectstatic()\n        # Modify the styles.css file\n        with open(filename, 'a') as f:\n            f.write(\"body { background-image: url('img/background2.png'); }\")\n        self.run_collectstatic(clear=False)\n        with storage.staticfiles_storage.open(self.hashed_file_path(\"cached/styles.css\")) as f:\n            content = f.read()\n        self.assertIn(b\"img/background2.png\", content)\n"], "sample_1023": ["compilation error"], "sample_336": ["    def test_lookahead_and_lookbehind_together(self):\n        test_urls = [\n            ('/lookahead-lookbehind-positive', {'city': 'a-city'}, '/lookahead+/lookbehind+/a-city/'),\n            ('/lookahead-lookbehind-negative', {'city': 'a-city'}, '/lookahead-/lookbehind-/a-city/'),\n        ]\n        for name, kwargs, expected in test_urls:\n            with self.subTest(name=name, kwargs=kwargs):\n                self.assertEqual(reverse(name, kwargs=kwargs), expected)\n"], "sample_244": ["    def test_invalid(self):\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '0',\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': '',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '1',\n        }\n        ChoiceFormSet = formset_factory(Choice)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [{'votes': ['This field is required.']}, {}]\n        self.assertEqual(formset1._errors, expected_errors)\n        self.assertEqual(formset2._errors, expected_errors)\n"], "sample_474": ["    def test_concat(self):\n        authors = Author.objects.annotate(\n            full_name=Concat(\"name\", F(\"alias\"))\n        )\n        self.assertCountEqual(\n            authors.filter(full_name=\"John smith\"), [self.john]\n        )\n        self.assertCountEqual(\n            authors.filter(full_name=\"\u00c9lena elena\"), [self.elena]\n        )\n        self.assertCountEqual(\n            authors.filter(full_name=\"Rhonda\"), [self.rhonda]\n        )\n"], "sample_655": ["compilation error"], "sample_833": ["def test_logistic_regression_path_coefs_sparse():\n    # Make sure that logistic_regression_path works with sparse matrices\n    X, y = make_classification(n_samples=200, n_classes=3, n_informative=2,\n                               n_redundant=0, n_clusters_per_class=1,\n                               random_state=0, n_features=100)\n    X_sparse = sparse.csr_matrix(X)\n    Cs = [.00001, 1, 10000]\n    coefs, _, _ = _logistic_regression_path(X_sparse, y, penalty='l1', Cs=Cs,\n                                            solver='saga', random_state=0,\n                                            multi_class='multinomial')\n\n    assert coefs.shape == (3, len(Cs), 100)\n"], "sample_734": ["def test_fowlkes_mallows_score_with_sparse_matrix():\n    labels_a = np.array([0, 0, 0, 1, 1, 1])\n    labels_b = np.array([0, 0, 1, 1, 2, 2])\n    C = contingency_matrix(labels_a, labels_b, sparse=True)\n    score = fowlkes_mallows_score(labels_a, labels_b, sparse=True)\n    assert_almost_equal(score, fowlkes_mallows_score(labels_a, labels_b), 5)\n"], "sample_320": ["    def test_references_field_by_through_reverse(self):\n        operation = FieldOperation(\n            \"Model\", \"field\", models.ManyToManyField(\"Other\", through=\"Through\")\n        )\n        self.assertIs(\n            operation.references_field(\"Through\", \"reverse_field\", \"migrations\"), True\n        )\n        self.assertIs(\n            operation.references_field(\"Missing\", \"reverse_field\", \"migrations\"), False\n        )\n"], "sample_692": ["    def test_basetemp_with_read_only_directories(pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import os\n            import stat\n\n                dir = tmp_path / 'dir'\n                dir.mkdir()\n                (dir / 'foo.txt').write_text('hello')\n                mode = os.stat(str(dir)).st_mode\n                os.chmod(str(dir), mode & ~stat.S_IREAD)"], "sample_52": ["    def test_model_choice_field_with_empty_label_and_to_field_name(self):\n        f = forms.ModelChoiceField(Category.objects.all(), empty_label=None, to_field_name='slug')\n        self.assertEqual(f.clean(self.c1.slug), self.c1)\n        self.assertEqual(f.clean(self.c1), self.c1)\n"], "sample_772": ["    def test_n_jobs_with_custom_backend(self):\n        # Test if n_jobs works with a custom backend\n        n_jobs = 4\n        backend = MyBackend(n_jobs=n_jobs)\n        est = RandomForestClassifier(n_estimators=10, random_state=0,\n                                     backend=backend)\n        est.fit(X, y)\n        assert_equal(backend.count, n_jobs)\n"], "sample_1204": ["def test_is_solvable():\n    G = AlternatingGroup(4)\n    assert not G.is_solvable\n    G = AlternatingGroup(5)\n    assert not G.is_solvable\n    G = SymmetricGroup(4)\n    assert G.is_solvable\n    G = SymmetricGroup(3)\n    assert G.is_solvable\n    G = DihedralGroup(6)\n    assert G.is_solvable\n    G = AbelianGroup(2, 3, 4)\n    assert G.is_solvable\n    G = CyclicGroup(10)\n    assert G.is_solvable\n    G = PermutationGroup(Permutation(0, 1, 2), Permutation(0, 2, 3))\n    assert G.is_solvable\n"], "sample_196": ["    def test_sql_flush_with_tables(self):\n        with transaction.atomic():\n            Author.objects.create(name='John Doe')\n            Book.objects.create(title='My Book', author=Author.objects.get(name='John Doe'))\n\n        sql_list = connection.ops.sql_flush(no_style(), [\n            Author,\n            Book,\n        ])\n        self.assertGreater(len(sql_list), 0)\n\n        with transaction.atomic():\n            Author.objects.all().delete()\n            Book.objects.all().delete()\n\n        with self.assertRaises(AssertionError):\n            self.assertEqual(connection.ops.sql_flush(no_style(), [\n                Author,\n                Book,\n            ]), [])\n"], "sample_303": ["    def test_runshell(self):\n        with mock.patch.object(BaseDatabaseClient, 'settings_to_cmd_args_env') as mock_settings_to_cmd_args_env:\n            mock_settings_to_cmd_args_env.return_value = (\n                ['some_command', 'arg1', 'arg2'],\n                {'SOME_ENV_VAR': 'some_value'},\n            )\n            self.client.runshell(parameters={'param1': 'value1'})\n            mock_settings_to_cmd_args_env.assert_called_once_with(\n                self.client.connection.settings_dict, {'param1': 'value1'}\n            )\n"], "sample_636": ["    def test_duplicate_code_raw_strings_disable_scope_nested(self) -> None:\n        \"\"\"Tests disabling duplicate-code at an inner scope level in nested scopes.\"\"\"\n        path = join(DATA, \"raw_strings_disable_scope_nested\")\n        expected_output = \"Similar lines in 2 files\"\n        self._test_output(\n            [path, \"--disable=all\", \"--enable=duplicate-code\"],\n            expected_output=expected_output,\n        )\n"], "sample_733": ["def test_vectorizer_empty_vocabulary():\n    # Test that vectorizers handle empty vocabularies gracefully\n    for vec_type in [CountVectorizer, TfidfVectorizer, HashingVectorizer]:\n        # Empty vocabulary\n        vect = vec_type(vocabulary=[])\n        with assert_raises(ValueError):\n            vect.fit(JUNK_FOOD_DOCS)\n        with assert_raises(ValueError):\n            vect.transform(JUNK_FOOD_DOCS)\n\n        # Empty vocabulary with max_features\n        vect = vec_type(vocabulary=[], max_features=1)\n        with assert_raises(ValueError):\n            vect.fit(JUNK_FOOD_DOCS)\n        with assert_raises(ValueError):\n            vect.transform(JUNK_FOOD_DOCS)\n\n\n\n"], "sample_893": ["def test_export_text_with_class_names_and_feature_names():\n    clf = DecisionTreeClassifier(max_depth=2, random_state=0)\n    clf.fit(X, y)\n    expected_report = dedent(\"\"\"\n    |--- feature_1 <= 0.00\n    |   |--- class: -1\n    |--- feature_1 >  0.00\n    |   |--- class: 1\n    \"\"\").lstrip()\n    assert export_text(\n        clf,\n        feature_names=[\"feature_1\"],\n        class_names=[\"class_1\", \"class_2\"],\n    ) == expected_report\n"], "sample_892": ["def test_adaboost_with_sparse_data(algorithm):\n    # Check that AdaBoost works with sparse data\n    from sklearn.datasets import make_classification\n    from sklearn.sparse import csr_matrix\n\n    X, y = make_classification(n_samples=100, n_features=100, random_state=42)\n    X_sparse = csr_matrix(X)\n\n    clf = AdaBoostClassifier(algorithm=algorithm, random_state=42)\n    clf.fit(X_sparse, y)\n    assert clf.score(X_sparse, y) > 0.5\n"], "sample_1061": ["def test_issue_10923():\n    assert Float('1.2345678901234567890123456789012345678901234567890', 100) == Float('1.2345678901234567890123456789012345678901234567890', 100)\n"], "sample_471": ["    def test_integerfield_empty_string(self):\n        f = IntegerField()\n        self.assertIsNone(f.clean(\"\"))\n        self.assertEqual(\"None\", repr(f.clean(\"\")))\n"], "sample_983": ["compilation error"], "sample_767": ["def test_column_transformer_sparse_threshold_with_remainder():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder=SparseMatrixTrans(),\n                           sparse_threshold=0.5)\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n\n    #  SparseMatrixTrans creates 3 features for each column, thus:\n    assert X_trans.shape == (3, 3 + 1)\n    assert_array_equal(X_trans.toarray(), np.hstack(\n        (X_array[:, 0].reshape(-1, 1), np.eye(3))))\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], SparseMatrixTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n\n\n\n"], "sample_673": ["    def test_is_setup_py_is_a_setup_py_with_options(tmpdir):\n        setup_py = tmpdir.join(\"setup.py\")\n        setup_py.write(\n            'from setuptools import setup; setup(name=\"foo\", version=\"0.1\", description=\"test\")'\n        )\n        assert _is_setup_py(setup_py)\n"], "sample_971": ["def test_prefixed_warnings(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    with prefixed_warnings(\"prefix:\"):\n        logger.warning('message')\n\n    assert 'prefix: WARNING: message' in warning.getvalue()\n"], "sample_1207": ["compilation error"], "sample_482": ["    def test_safe_input(self):\n        output = self.engine.render_to_string(\n            \"escapeseq_safe\",\n            {\"a\": [mark_safe(\"x&y\"), mark_safe(\"<p>\")], \"b\": [\"x&y\", \"<p>\"]},\n        )\n        self.assertEqual(output, \"x&y, &lt;p&gt; -- x&y, <p>\")\n"], "sample_812": ["def test_custom_repr():\n    class MyEstimator(BaseEstimator):\n            self.a = a\n            self.b = b\n\n            return f\"MyEstimator(a={self.a}, b={self.b})\"\n\n    estimator = MyEstimator(a=123, b='abc')\n    expected = \"MyEstimator(a=123, b=abc)\"\n    assert estimator.__repr__() == expected\n"], "sample_1120": ["compilation error"], "sample_683": ["def test_capture_with_encoding_errors(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import sys\n            sys.stdout.encoding = 'ascii'\n            sys.stderr.encoding = 'ascii'\n            sys.stdout.write(b'\\xe4')\n            sys.stderr.write(b'\\xe4')\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 1\n    assert \"UnicodeEncodeError\" in result.stdout.str()\n    assert \"UnicodeEncodeError\" in result.stderr.str()\n"], "sample_580": ["def test_categorical_order():\n    s = pd.Series([\"a\", \"b\", \"c\", \"a\"])\n    assert categorical_order(s) == [\"a\", \"b\", \"c\"]\n\n    s = pd.Series([\"a\", \"b\", \"c\", \"a\"], dtype=\"category\")\n    assert categorical_order(s) == [\"a\", \"b\", \"c\"]\n\n    s = pd.Series([1, 2, 3, 1], dtype=\"Int64\")\n    assert categorical_order(s) == [1, 2, 3]\n\n    s = pd.Series([1, 2, 3, 1], dtype=object)\n    assert categorical_order(s) == [1, 2, 3]\n\n    s = pd.Series([np.nan, np.nan, np.nan])\n    assert categorical_order(s) == []\n\n    s = pd.Series([np.nan, 1, 2, np.nan])\n    assert categorical_order(s) == [1, 2]\n\n    s = pd.Series([\"a\", \"b\", \"c\", \"a\"], order=[\"c\", \"a\", \"b\"])\n    assert categorical_order(s, order=[\"c\", \"a\", \"b\"]) == [\"c\", \"a\", \"b\"]\n"], "sample_913": ["def test_module_index_with_version(app):\n    text = (\".. py:module:: docutils\\n\"\n            \"   :version: 0.17\\n\"\n            \".. py:module:: sphinx\\n\"\n            \"   :version: 4.0\\n\")\n    restructuredtext.parse(app, text)\n    index = PythonModuleIndex(app.env.get_domain('py'))\n    assert index.generate() == (\n        [('d', [IndexEntry('docutils', 0, 'index', 'module-docutils', '0.17', '', '')]),\n         ('s', [IndexEntry('sphinx', 0, 'index', 'module-sphinx', '4.0', '', '')])],\n        False\n    )\n"], "sample_136": ["    def test_case_insensitive_headers(self):\n        environ = {\n            'CONTENT_TYPE': 'text/html',\n            'CONTENT_LENGTH': '100',\n            'HTTP_HOST': 'example.com',\n            'HTTP_USER_AGENT': 'python-requests/1.2.0',\n        }\n        headers = HttpHeaders(environ)\n        self.assertEqual(headers['user-agent'], 'python-requests/1.2.0')\n        self.assertEqual(headers['User-Agent'], 'python-requests/1.2.0')\n        self.assertEqual(headers['content-type'], 'text/html')\n        self.assertEqual(headers['Content-Type'], 'text/html')\n"], "sample_366": ["    def test_iso8601_duration(self):\n        test_values = (\n            ('P1D', timedelta(days=1)),\n            ('P1DT2H30M', timedelta(days=1, hours=2, minutes=30)),\n            ('P1DT2H30M1S', timedelta(days=1, hours=2, minutes=30, seconds=1)),\n            ('P1DT2H30M1.123S', timedelta(days=1, hours=2, minutes=30, seconds=1, microseconds=123000)),\n            ('PT2H30M1S', timedelta(hours=2, minutes=30, seconds=1)),\n            ('PT2H30M1.123S', timedelta(hours=2, minutes=30, seconds=1, microseconds=123000)),\n            ('P1Y', timedelta(days=365)),\n            ('P1Y2M', timedelta(days=365, days=60)),\n            ('P1Y2M3D', timedelta(days=365, days=60, days=3)),\n            ('P1Y2M3DT10H30M', timedelta(days=365, days=60, days=3, hours=10, minutes=30)),\n            ('P1Y2M3DT10H30M1S', timedelta(days=365, days=60, days=3, hours=10, minutes=30, seconds=1)),\n            ('P1Y2M3DT10H30M1.123S', timedelta(days=365, days=60, days=3, hours=10, minutes=30, seconds=1, microseconds=123000)),\n            ('PT10H30M1S', timedelta(hours=10, minutes=30, seconds=1)),\n            ('PT10H30M1.123S', timedelta(hours=10, minutes=30, seconds=1, microseconds=123000)),\n            ('P-"], "sample_1169": ["def test_issue_19661_nested():\n    a = Symbol('0')\n    assert latex(Commutator(Bd(a)**2, [B(a), Bd(a)])\n                 ) == '- \\\\left[b_{0}^{2}, \\\\left[b_{0}, b^{\\\\dagger}_{0}\\\\right]\\\\right]'\n"], "sample_26": ["def test_comphdu_header_keywords():\n    \"\"\"\n    Regression test for https://github.com/astropy/astropy/issues/10245\n\n    Ensure that CompImageHDU correctly handles keywords that are\n    present in both the original header and the compressed header.\n    \"\"\"\n\n    data = np.arange(100).reshape((10, 10))\n    header = fits.Header()\n    header[\"TEST_KEYWORD\"] = \"hello\"\n    hdu = fits.CompImageHDU(data, header, compression_type=\"RICE_1\")\n\n    # Write the HDU to a temporary file\n    with fits.open(self.temp(\"test.fits\"), mode=\"update\") as hdul:\n        hdul.append(hdu)\n\n    # Read the HDU back and verify that the keyword is present\n    with fits.open(self.temp(\"test.fits\")) as hdul:\n        assert hdul[1].header[\"TEST_KEYWORD\"] == \"hello\"\n"], "sample_706": ["def test_multiple_idents(expr: str, expected: bool) -> None:\n    matcher = {\"ident1\": True, \"ident2\": True, \"ident3\": True}.__getitem__\n    assert evaluate(expr, matcher) is expected\n"], "sample_887": ["def test_calibration_with_invalid_method(data):\n    X, y = data\n    with pytest.raises(ValueError, match=\"Invalid method\"):\n        CalibratedClassifierCV(estimator=LogisticRegression(), method=\"invalid\").fit(X, y)\n"], "sample_716": ["def test_ridge_with_categorical_features():\n    from sklearn.preprocessing import OneHotEncoder\n\n    X, y = make_classification(n_samples=100, n_features=5,\n                               n_informative=3, random_state=42)\n    X_categorical = X[:, 2:]\n    X_numerical = X[:, :2]\n\n    # Encode categorical features\n    encoder = OneHotEncoder(handle_unknown='ignore')\n    X_categorical_encoded = encoder.fit_transform(X_categorical).toarray()\n\n    # Combine numerical and encoded categorical features\n    X_combined = np.hstack((X_numerical, X_categorical_encoded))\n\n    ridge = Ridge()\n    ridge.fit(X_combined, y)\n\n    # Check that the model has learned from both numerical and categorical features\n    assert_greater(np.sum(ridge.coef_[:X_numerical.shape[1]]), 0)\n    assert_greater(np.sum(ridge.coef_[X_numerical.shape[1]:]), 0)\n"], "sample_377": ["    def test_sensitive_post_parameters_method_decorator(self):\n        class MyClass:\n            @method_decorator(sensitive_post_parameters())\n                return HttpResponse()\n\n        instance = MyClass()\n        response = instance.a_view(HttpRequest())\n        self.assertEqual(response.status_code, 200)\n"], "sample_698": ["def test_coloredlogformatter_with_custom_format_string() -> None:\n    logfmt = \"%(asctime)s - %(levelname)s - %(message)s\"\n\n    record = logging.LogRecord(\n        name=\"dummy\",\n        level=logging.INFO,\n        pathname=\"dummypath\",\n        lineno=10,\n        msg=\"Test Message\",\n        args=(),\n        exc_info=None,\n    )\n\n    tw = TerminalWriter()\n    tw.hasmarkup = True\n    formatter = ColoredLevelFormatter(tw, logfmt)\n    output = formatter.format(record)\n    assert output == (\n        \"Test Message\"\n    )\n"], "sample_1158": ["compilation error"], "sample_633": ["def test_ignore_signatures_class_methods_pass_with_docstrings() -> None:\n    output = StringIO()\n    with redirect_stdout(output), pytest.raises(SystemExit) as ex:\n        similar.Run([\"--ignore-signatures\", SIMILAR_CLS_B, SIMILAR_CLS_A])\n    assert ex.value.code == 0\n    assert (\n        output.getvalue().strip()\n        == \"\"\""], "sample_550": ["def test_toolmanager_add_tool():\n    with pytest.warns(UserWarning, match=_EXPECTED_WARNING_TOOLMANAGER):\n        plt.rcParams['toolbar'] = 'toolmanager'\n    fig = plt.gcf()\n    initial_len = len(fig.canvas.manager.toolmanager.tools)\n    tool_name = 'my_custom_tool'\n    class MyCustomTool:\n            pass\n            pass\n            pass\n    tool = MyCustomTool(fig.canvas)\n    fig.canvas.manager.toolmanager.add_tool(tool_name, tool)\n    assert len(fig.canvas.manager.toolmanager.tools) == initial_len + 1\n    assert fig.canvas.manager.toolmanager.get_tool(tool_name) is tool\n    with pytest.warns(UserWarning, match=\"ToolManager does not control tool 'foo'\"):\n        assert fig.canvas.manager.toolmanager.get_tool('foo') is None\n"], "sample_1040": ["def test_print_matrix_with_entries():\n    A = Matrix([[1, 2], [3, 4]])\n    assert mpp.doprint(A) == '<mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>3</mn></mtd><mtd><mn>4</mn></mtd></mtr></mtable>'\n    assert mp.doprint(A) == '<matrix><row><cn>1</cn><cn>2</cn></row><row><cn>3</cn><cn>4</cn></row></matrix>'\n"], "sample_1025": ["compilation error"], "sample_1042": ["def test_Indexed_subs_with_multiple_indices():\n    i, j, k = symbols('i j k', integer=True)\n    A = IndexedBase('A')\n    B = IndexedBase('B')\n    expr = A[i, j] * B[j, k]\n    assert expr.subs({A[i, j]: 1, B[j, k]: 2}).doit() == 2\n    assert expr.subs({A[i, j]: 1, B[j, k]: 2}).subs({i: 1, j: 2, k: 3}).doit() == 2\n    assert expr.subs({A[i, j]: 1, B[j, k]: 2}).subs({i: 1, j: 2}).doit() == 2\n    assert expr.subs({A[i, j]: 1, B[j, k]: 2}).subs({j: 2}).doit() == 2\n    assert expr.subs({A[i, j]: 1, B[j, k]: 2}).subs({i: 1, j: 2, k: 3}).subs({A[i, j]: 3}).doit() == 6\n    assert expr.subs({A[i, j]: 1, B[j, k]: 2}).subs({i: 1, j: 2, k: 3}).subs({B[j, k]: 3}).doit() == 6\n    assert expr.subs({A[i, j]: 1, B[j, k]: 2}).subs({i: 1, j: 2, k: 3}).subs({A[i, j]: 3, B[j, k]: 3}).doit() == 6\n"], "sample_109": ["    def test_render_options_with_language_setting(self):\n        with translation.override('fr'):\n            beatles = Band.objects.create(name='The Beatles', style='rock')\n            form = AlbumForm(initial={'band': beatles.pk})\n            output = form.as_table()\n            selected_option = '<option value=\"%s\" selected>The Beatles</option>' % beatles.pk\n            self.assertIn(selected_option, output)\n"], "sample_924": ["    def check_xref_consistency(role, tag, expected_classes):\n        classes_found = classes(role, tag)\n        assert classes_found == expected_classes, (\n            f\"Classes found for role '{role}' with tag '{tag}': {classes_found}\"\n            f\" Expected: {expected_classes}\"\n        )\n"], "sample_1018": ["def test_fcode_Piecewise_with_complex_expressions():\n    x, y = symbols('x y')\n    expr = Piecewise((x**2 + y**2, x**2 + y**2 < 1), (sin(x*y), True))\n    assert fcode(expr, standard=95) == (\n        \"      merge(x**2 + y**2, sin(x*y), x**2 + y**2 < 1)\")\n"], "sample_213": ["    def test_file_like_object_from_string(self):\n        \"\"\"\n        Test that FileField can handle file-like objects created from strings.\n        \"\"\"\n        with self.client.post('/upload/', {'file': 'content'}) as response:\n            self.assertEqual(response.status_code, 200)\n            self.assertIn('File uploaded successfully', response.content.decode())\n\n        with open(self.storage.path('uploaded_file'), 'rb') as f:\n            self.assertEqual(f.read(), b'content')\n"], "sample_956": ["compilation error"], "sample_44": ["    def test_log_quantity_from_physical_quantity(self):\n        lq = u.Magnitude(100.*u.Jy)\n        assert lq.physical == 100.*u.Jy\n        lq2 = u.Magnitude(100.*u.Jy, u.Jy)\n        assert lq2.physical == 100.*u.Jy\n        lq3 = u.Magnitude(100.*u.Jy, u.m)\n        with pytest.raises(u.UnitsError):\n            lq3.physical\n        with pytest.raises(u.UnitsError):\n            u.Magnitude(100.*u.Jy, u.m).to(u.Jy)\n\n\n\n"], "sample_1105": ["def test_matmul_with_inverse():\n    A = MatrixSymbol('A', n, n)\n    assert MatMul(A, A.inverse()).doit() == Identity(n)\n    assert MatMul(A.inverse(), A).doit() == Identity(n)\n    assert MatMul(2*A, A.inverse()).doit() == 2*Identity(n)\n    assert MatMul(A.inverse(), 2*A).doit() == 2*Identity(n)\n"], "sample_133": ["    def test_i18n_with_plural_forms(self):\n        with self.settings(LANGUAGE_CODE='de'), override('pl'):\n            response = self.client.get('/jsi18n/')\n            self.assertContains(response, '1 element')\n            self.assertContains(response, '455 elementy')\n"], "sample_116": ["    def test_cache_key_with_user_and_language(self):\n        request = self.factory.get(self.path)\n        user = User.objects.create_user(username='testuser', password='testpassword')\n        request.user = user\n        translation.activate('es')\n        template = engines['django'].from_string(\"This is a test\")\n        response = TemplateResponse(request, template)\n        key = get_cache_key(request)\n        self.assertEqual(\n            key,\n            'views.decorators.cache.cache_page.settingsprefix.GET.'\n            'testuser.es.d41d8cd98f00b204e9800998ecf8427e'\n        )\n"], "sample_594": ["    def test_summarize_attr(self):\n        cases = [\n            (\"key\", \"Short string\", \"    key: Short string\"),\n            (\"key\", 100 * \"Very long string \", \"    key: Very long string ...\"),\n            (\"key\", \"\\n\\n\\n\", \"    key: \\n\\n\\n\"),\n            (\"key\", \"\\t\\t\\t\", \"    key: \\t\\t\\t\"),\n            (\"key\", None, \"    key: None\"),\n            (\"key\", np.array([1, 2, 3]), \"    key: [1 2 3]\"),\n            (\"key\", np.array([1, 2, 3], dtype=\"float64\"), \"    key: [1. 2. 3.]\"),\n            (\"key\", np.array([1, 2, 3], dtype=\"complex128\"), \"    key: [1.+0.j 2.+0.j 3.+0.j]\"),\n        ]\n        for key, value, expected in cases:\n            actual = formatting.summarize_attr(key, value)\n            assert actual == expected\n"], "sample_582": ["compilation error"], "sample_480": ["    def test_key_text_transform_with_nested_lookups(self):\n        qs = NullableJSONModel.objects.annotate(\n            b=KT(\"value__baz__a\"),\n        ).filter(b__contains=\"b\")\n        self.assertSequenceEqual(qs, [self.objs[7]])\n"], "sample_300": ["    def test_filter_conditional_join_with_alias(self):\n        query = Query(Item)\n        query.add_select_related('note')\n        filter_expr = Func('note__note', output_field=BooleanField())\n        where = query.build_where(filter_expr)\n        exact = where.children[0]\n        self.assertIsInstance(exact, Exact)\n        self.assertIsInstance(exact.lhs, Func)\n        self.assertIs(exact.rhs, True)\n"], "sample_717": ["def test_load_fake_lfw_pairs():\n    lfw_pairs = fetch_lfw_pairs(subset='train', data_home=SCIKIT_LEARN_DATA,\n                                download_if_missing=False)\n\n    # The data is croped around the center as a rectangular bounding box\n    # around the face. Colors are converted to gray levels:\n    assert_equal(lfw_pairs.data.shape, (2200, 5828))\n    assert_equal(lfw_pairs.pairs.shape, (2200, 2, 62, 47))\n\n    # the target is array of boolean values\n    assert_array_equal(lfw_pairs.target, [1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n\n    # names of the persons can be found using the target_names array\n    expected_classes = ['Abdelatif Smith', 'Abhati Kepler', 'Onur Lopez']\n    assert_array_equal(lfw_pairs.target_names, expected_classes)\n\n    # It is possible to ask for the original data without any croping or color\n    # conversion and not limit on the number of picture per person\n    lfw_pairs = fetch_lfw_pairs(subset='train', data_home=SCIKIT_LEARN_DATA,\n                                resize=None, slice_=None, color=True,\n                                download_if_missing=False)\n    assert_equal(lfw_pairs.data.shape, (2200, 5828))\n    assert_equal(lfw_pairs.pairs.shape, (2200, 2, 250, 250, 3))\n\n    # the ids and class names are the same as previously\n    assert_array_equal(lfw_pairs.target,\n                       [0, 0, 1, 6, 5, 6, 3, 6, 0, 3, 6, 1, 2, 4, 5, 1, 2])\n    assert_array_equal(lfw_pairs.target_names,\n                       ['Abdelatif"], "sample_980": ["def test_inversions():\n    p = Permutation([0, 2, 1, 3])\n    assert p.inversions() == 2\n    q = Permutation([3, 2, 1, 0])\n    assert q.inversions() == 6\n    r = Permutation([1, 0, 2, 3])\n    assert r.inversions() == 3\n    s = Permutation([0, 1, 2, 3])\n    assert s.inversions() == 0\n    t = Permutation([3, 1, 0, 2])\n    assert t.inversions() == 3\n    u = Permutation([2, 4, 1, 3, 0])\n    assert u.inversions() == 5\n    v = Permutation([0, 1, 3, 2])\n    assert v.inversions() == 1\n    w = Permutation([1, 3, 2, 0])\n    assert w.inversions() == 2\n    x = Permutation([0, 3, 1, 2])\n    assert x.inversions() == 2\n    y = Permutation([2, 0, 1, 3])\n    assert y.inversions() == 3\n    z = Permutation([1, 0, 3, 2])\n    assert z.inversions() == 2\n    assert Permutation([0, 1, 2, 3]).inversions() == 0\n    assert Permutation([3, 2, 1, 0]).inversions() == 6\n    assert Permutation([1, 3, 2, 0]).inversions() == 2\n    assert Permutation([2, 4, 1, 3, 0]).inversions() == 5\n    assert Permutation([0, 3, 1, 2]).inversions() == 2\n    assert Permutation([2, 0, 1, 3]).inversions() == 3\n    assert Permutation([1, 0, 3, 2]).inversions() == 2\n    assert Permutation([0, 2, 1, 3])."], "sample_1031": ["def test_equivalent_dims():\n    ms = UnitSystem((m, s), (c,))\n    assert ms.equivalent_dims(Dimension(ms._system.base_dims))\n    assert not ms.equivalent_dims(Dimension(length, mass, time, velocity))\n    assert not ms.equivalent_dims(Dimension(length, mass, time))\n"], "sample_497": ["    def test_format_string_formatter_with_kwargs(self):\n        # Test that kwargs are passed correctly to the format string\n        fmt = mticker.StrMethodFormatter('{x:05d}-{pos:02d}', kwargs={'pos': 'foo'})\n        assert fmt(2) == '00002-foo'\n"], "sample_963": ["def test_stringify_type_hints_Annotated_with_args():\n    from typing import Annotated  # type: ignore\n    assert stringify(Annotated[str, \"foo\", \"bar\"]) == \"Annotated[str, 'foo', 'bar']\"  # NOQA\n"], "sample_250": ["    def test_format_with_datetime_naive(self):\n        dt = datetime(2009, 5, 16, 5, 30, 30)\n        self.assertEqual(dateformat.format(dt, 'O'), '+0000')\n"], "sample_1016": ["def test_MatrixElement_printing_with_subs():\n    A = MatrixSymbol(\"A\", 2, 2)\n    B = MatrixSymbol(\"B\", 2, 2)\n    C = MatrixSymbol(\"C\", 2, 2)\n    D = MatrixSymbol(\"D\", 2, 2)\n\n    assert mcode(A[0, 0].subs(A, B + C)) == \"B(1, 1) + C(1, 1)\"\n    assert mcode(A[1, 1].subs(A, B + C)) == \"B(2, 2) + C(2, 2)\"\n    assert mcode(A[0, 1].subs(A, B + C)) == \"B(1, 2) + C(1, 2)\"\n    assert mcode(A[1, 0].subs(A, B + C)) == \"B(2, 1) + C(2, 1)\"\n    assert mcode(A[0, 0].subs(A, B + C).subs(C, D)) == \"B(1, 1) + D(1, 1)\"\n"], "sample_678": ["def test_ensure_deletable_dead_lock(tmp_path):\n    path = tmp_path / \"temp-1\"\n    path.mkdir()\n    lock_path = get_lock_path(path)\n    lock_path.touch()\n    # Simulate a lock created a long time ago\n    lock_path.stat().st_mtime = time.time() - LOCK_TIMEOUT * 60 * 60 * 2\n    assert ensure_deletable(path, lock_path.stat().st_mtime - LOCK_TIMEOUT * 60 * 60 * 2)\n    assert not lock_path.is_file()\n"], "sample_71": ["    def test_empty_string(self):\n        self.assertEqual(nformat(''), '')\n        self.assertEqual(nformat('', '.'), '')\n        self.assertEqual(nformat('', '.', decimal_pos=2), '0.00')\n        self.assertEqual(nformat('', '.', grouping=2, thousand_sep=','), '')\n        self.assertEqual(nformat('', '.', grouping=2, thousand_sep=',', force_grouping=True), '')\n"], "sample_182": ["    def test_union_with_distinct_and_order_by(self):\n        qs1 = Number.objects.filter(num__lte=1).distinct()\n        qs2 = Number.objects.filter(num__gte=2, num__lte=3).distinct()\n        self.assertNumbersEqual(qs1.union(qs2).order_by('-num'), [3, 2, 1, 0])\n"], "sample_1130": ["def test_auto_vel_vel_in_different_frames():\n    q1, q2, u1, u2 = dynamicsymbols('q1 q2 u1 u2')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    O = Point('O')\n    O.set_vel(N, u1 * N.x)\n    P = Point('P')\n    P.set_pos(O, q1 * N.x)\n    P.set_vel(B, u2 * B.y)\n    N.orient(B, 'Axis', (q2, B.z))\n    assert P.vel(N) == (u1 + q1.diff(t) * q2.diff(t)) * N.x + u2 * B.y - q1 * q2.diff(t) * B.z\n"], "sample_953": ["def test_quickstart_with_custom_template(tempdir):\n    answers = {\n        'Root path': tempdir,\n        'Project name': 'Custom Template Test',\n        'Author name': 'Georg Brandl',\n        'Project version': '0.1',\n    }\n    qs.term_input = mock_input(answers)\n    d = {}\n    qs.ask_user(d)\n    qs.generate(d, templatedir=tempdir)\n\n    with open(tempdir / 'source' / 'conf.py', 'r') as f:\n        conf_content = f.read()\n\n    assert 'custom_template_variable' in conf_content\n    assert 'Custom Template Value' in conf_content\n"], "sample_327": ["    def test_invalid_json_with_custom_decoder(self):\n        class CustomDecoder(json.JSONDecoder):\n                return super().__init__(object_hook=self.as_uuid, *args, **kwargs)\n\n                if 'uuid' in dct:\n                    dct['uuid'] = uuid.UUID(dct['uuid'])\n                return dct\n\n        field = JSONField(decoder=CustomDecoder)\n        with self.assertRaisesMessage(ValidationError, 'Enter a valid JSON.'):\n            field.clean('{\"uuid\": \"not a uuid\"}')\n"], "sample_653": ["    def test_log_in_pytest_sessionfinish(testdir):\n        log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n        testdir.makeini(\n            \"\"\"\n            [pytest]\n            log_file={}\n            log_file_level = INFO\n            log_cli=true\n            \"\"\".format(\n                log_file\n            )\n        )\n        testdir.makeconftest(\n            \"\"\"\n            import logging\n\n                logging.info('sessionfinish')\n        \"\"\"\n        )\n        testdir.makepyfile(\n            \"\"\"\n                assert True\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        with open(log_file) as rfh:\n            contents = rfh.read()\n            assert \"sessionfinish\" in contents\n"], "sample_751": ["    def test_sample_weight_adaboost_regressor():\n        \"\"\"\n        AdaBoostRegressor should work without sample_weights in the base estimator\n\n        The random weighted sampling is done internally in the _boost method in\n        AdaBoostRegressor.\n        \"\"\"\n        X, y = datasets.make_regression(n_samples=100, n_features=10, random_state=0)\n        \n        # Create a dummy estimator that doesn't use sample_weights\n        class DummyEstimator(BaseEstimator):\n                pass\n\n        # Fit AdaBoostRegressor with the dummy estimator and sample_weights\n        reg = AdaBoostRegressor(base_estimator=DummyEstimator(), random_state=0)\n        reg.fit(X, y, sample_weight=np.ones(len(y)))\n\n        # Check that the weights are not used by the base estimator\n        assert_equal(reg.base_estimator.sample_weight, None)\n\n"], "sample_974": ["def test_ccode_For_loops():\n    from sympy.tensor import IndexedBase, Idx\n    from sympy import symbols\n    n, m = symbols('n m', integer=True)\n    A = IndexedBase('A')\n    x = IndexedBase('x')\n    y = IndexedBase('y')\n    i = Idx('i', m)\n    j = Idx('j', n)\n\n    s = (\n        'for (int i=0; i<m; i++){\\n'\n        '   for (int j=0; j<n; j++){\\n'\n        '      y[i] = A[%s]*x[j] + y[i];\\n' % (i*n + j) +\\\n        '   }\\n'\n        '}'\n    )\n    c = ccode(For(i, 0, m, A[i, j]*x[j] + y[i]), assign_to=y[i])\n    assert c == s\n"], "sample_586": ["    def test_concat_with_different_dims(self):\n        ds1 = Dataset({\"a\": ((\"x\", \"y\"), np.random.random((2, 3))), \"b\": ((\"x\",), np.random.random((2,)))})\n        ds2 = Dataset({\"a\": ((\"x\", \"z\"), np.random.random((2, 3))), \"b\": ((\"x\",), np.random.random((2,)))})\n        with raises_regex(ValueError, \"Dimensions\"):\n            concat([ds1, ds2], dim=\"x\")\n"], "sample_507": ["    def test_plot_mixed_types(self, plotter):\n        ax = plt.figure().subplots()\n        plotter(ax, ['a', 1, 'b'], [1, 2, 3])\n        axis_test(ax.xaxis, ['a', 1, 'b'])\n"], "sample_340": ["    def test_invalid_migration(self):\n        \"\"\"\n        MigrationLoader should raise an error if a migration file is invalid.\n        \"\"\"\n        loader = MigrationLoader(connection)\n        with self.assertRaises(ImportError):\n            loader.load_disk()\n"], "sample_566": ["def test_savefig_metadata_unicode():\n    fig = plt.figure()\n    fig.savefig(io.BytesIO(), format='png', metadata={'title': 'This is a test with unicode:  \u00e9\u00e0\u00e7'})\n"], "sample_919": ["    def check_xref_consistency(role, tag, expected_classes):\n        classes_found = classes(role, tag)\n        assert classes_found == expected_classes, (\n            f\"Classes for role '{role}' with tag '{tag}' do not match:\\n\"\n            f\"Expected: {expected_classes}\\n\"\n            f\"Found: {classes_found}\"\n        )\n"], "sample_784": ["def test_calibration_multiclass_imbalanced():\n    \"\"\"Test calibration for multiclass imbalanced datasets\"\"\"\n    # Test with imbalanced multiclass dataset\n    X, y = make_classification(n_samples=1000, n_features=2,\n                               n_classes=3,\n                               weights=[0.1, 0.8, 0.1],\n                               random_state=42)\n    X_train, y_train = X[::2], y[::2]\n    X_test, y_test = X[1::2], y[1::2]\n\n    clf = RandomForestClassifier(n_estimators=10, random_state=42)\n    clf.fit(X_train, y_train)\n    clf_probs = clf.predict_proba(X_test)\n    loss = log_loss(y_test, clf_probs)\n\n    for method in ['isotonic', 'sigmoid']:\n        cal_clf = CalibratedClassifierCV(clf, method=method, cv=3)\n        cal_clf.fit(X_train, y_train)\n        cal_clf_probs = cal_clf.predict_proba(X_test)\n        cal_loss = log_loss(y_test, cal_clf_probs)\n        assert_greater(loss, cal_loss)\n\n\n\n"], "sample_858": ["def test_estimator_weights_validation():\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    with pytest.raises(ValueError, match=\"Number of estimators and weights must be equal\"):\n        VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)],\n                         weights=[1, 2, 3])\n    with pytest.raises(ValueError, match=\"Number of estimators and weights must be equal\"):\n        VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)],\n                         weights=[1, 2]).fit(X, y)\n    with pytest.raises(ValueError, match=\"Weights must be a list or array-like\"):\n        VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)],\n                         weights={'lr': 1, 'rf': 2})\n"], "sample_1173": ["def test_issue_13587():\n    assert parse_expr('x**y**z') == x**(y**z)\n"], "sample_290": ["    def test_operation_with_no_suggested_name_and_initial_true(self):\n        class Migration(migrations.Migration):\n            initial = True\n            operations = [\n                migrations.RunSQL('SELECT 1 FROM person;'),\n            ]\n\n        migration = Migration('0001_initial', 'test_app')\n        self.assertEqual(migration.suggest_name(), 'initial')\n"], "sample_1161": ["def test_issue_21681():\n    from sympy.physics.quantum import TensorProduct\n    a, b = symbols('a b')\n    t = TensorProduct(a, b)\n    assert str(t) == 'a \u2297 b'\n"], "sample_69": ["    def test_snapshot_files_handles_multiple_files(self):\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file, self.nonexistent_file]):\n            snapshot1 = dict(self.reloader.snapshot_files())\n            self.assertIn(self.existing_file, snapshot1)\n            self.assertNotIn(self.nonexistent_file, snapshot1)\n            self.increment_mtime(self.existing_file)\n            snapshot2 = dict(self.reloader.snapshot_files())\n            self.assertNotEqual(snapshot1[self.existing_file], snapshot2[self.existing_file])\n            self.assertNotIn(self.nonexistent_file, snapshot2)\n"], "sample_450": ["    def test_get_admin_log_template_tag(self):\n        # Create a new user to test the 'for_user' argument\n        user2 = User.objects.create_user(username=\"user2\", password=\"password\")\n        self.client.force_login(self.user)\n\n        # Render the template with the tag\n        response = self.client.get(\n            \"/admin/template_test/?limit=5&varname=admin_log&for_user=user2\"\n        )\n        context = response.context\n        admin_log = context[\"admin_log\"]\n\n        # Assert that the log entries are filtered correctly\n        self.assertEqual(len(admin_log), 5)\n        self.assertEqual(admin_log[0].user, user2)\n\n\n\n"], "sample_1096": ["def test_Indexed_subs_with_functions():\n    A = IndexedBase(\"A\")\n    i, j, k = symbols(\"i,j,k\")\n    f = Function(\"f\")\n    g = Function(\"g\")\n\n    assert Subs(f(A[i]), A[i], A[j]).diff(A[j]) == f(A[j]).diff(A[j])\n    assert Subs(f(A[i]), A[i], A[j]).diff(A[k]) == f(A[j]).diff(A[k])*KroneckerDelta(j, k)\n    assert Subs(g(A[i]), A[i], A[j]).diff(A[j]) == g(A[j]).diff(A[j])\n    assert Subs(g(A[i]), A[i], A[j]).diff(A[k]) == g(A[j]).diff(A[k])*KroneckerDelta(j, k)\n    assert Subs(f(A[i])*g(A[j]), A[i], A[j]).diff(A[j]) == f(A[j])*g(A[j]).diff(A[j]) + f(A[j])*g(A[j]).diff(A[j])\n    assert Subs(f(A[i])*g(A[j]), A[i], A[j]).diff(A[k]) == f(A[j])*g(A[j]).diff(A[k])*KroneckerDelta(j, k) + f(A[j])*g(A[j]).diff(A[k])*KroneckerDelta(j, k)\n"], "sample_535": ["def test_bbox():\n    fig, ax = plt.subplots()\n\n    cellText = [['1'] * 3] * 2\n    table = ax.table(cellText=cellText, loc='center')\n\n    bbox = table.get_bbox()\n    table.set_bbox(bbox)\n    plt.axis('off')\n"], "sample_252": ["    def test_key_transform_with_null_value(self):\n        obj = NullableJSONModel.objects.create(value={'a': None})\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__a=KeyTransform(None, 'value')),\n            [obj],\n        )\n"], "sample_818": ["def test_spectral_clustering_with_precomputed_affinity():\n    X, y = make_blobs(n_samples=20, random_state=0,\n                      centers=[[1, 1], [-1, -1]], cluster_std=0.01)\n    affinity_matrix = pairwise_distances(X, metric='precomputed')\n    sp = SpectralClustering(n_clusters=2, affinity='precomputed',\n                            random_state=0)\n    labels = sp.fit(affinity_matrix).labels_\n    assert adjusted_rand_score(y, labels) == 1\n"], "sample_30": ["def test_timesys_with_units():\n    votable = parse(get_pkg_data_filename(\"data/timesys_with_units.xml\"))\n    _timesys_tests(votable)\n"], "sample_847": ["def test_enet_multioutput_sparse_input():\n    X, y, _, _ = build_dataset(n_samples=50, n_features=20)\n    y = y[:, np.newaxis]\n    X_sparse = sparse.csr_matrix(X)\n    clf = ElasticNet(alpha=0.5, tol=1e-8, precompute=False)\n    clf.fit(X_sparse, y)\n    assert_array_almost_equal(clf.coef_, clf.coef_)\n    assert_almost_equal(clf.intercept_, clf.intercept_)\n"], "sample_36": ["def test_biweight_midcovariance_large_arrays():\n    \"\"\"\n    Test biweight_midcovariance with large arrays to ensure performance\n    and correctness.\n    \"\"\"\n    with NumpyRNGContext(12345):\n        ny = 1000\n        nx = 2000\n        data = normal(5, 2, (ny, nx))\n        cov = biweight_midcovariance(data)\n        assert cov.shape == (ny, nx)\n\n        # Check that the diagonal elements are positive\n        assert (cov.diagonal() > 0).all()\n"], "sample_720": ["def test_power_transformer_y_axis_exception():\n    pt = PowerTransformer(method='box-cox')\n    X = np.abs(X_2d)\n    pt.fit(X)\n\n    # Exceptions should be raised if y_axis is not 0 or 1\n    assert_raises_regex(ValueError, \"Axis should be either 0 or 1\",\n                        pt.transform, X, axis=2)\n"], "sample_1175": ["def test_issue_18345():\n    from sympy.physics.mechanics import Point, ReferenceFrame, inertial\n    O = Point('O')\n    N = ReferenceFrame('N', inertial=True)\n    assert pretty(O.pos_from(N)) == 'O_N'\n    assert upretty(O.pos_from(N)) == 'O_N'\n"], "sample_335": ["    def test_decimalfield_with_empty_string(self):\n        f = DecimalField(max_digits=4, decimal_places=2)\n        self.assertIsNone(f.clean(''))\n"], "sample_1180": ["def test_issue_15720():\n    p = Point3D(1, 2, 3)\n    assert p.transform(Matrix([[1, 0, 0], [0, 1, 0], [0, 0, 1]])) == p\n"], "sample_885": ["compilation error"], "sample_170": ["    def test_sensitive_variables_decorator_with_kwargs(self):\n        @sensitive_variables\n            return password, kwargs\n\n        with self.settings(DEBUG=True):\n            response = self.client.post('/test_view/', data={'password': 'secret', 'other': 'data'})\n            self.assertEqual(response.status_code, 500)\n            self.assertContains(response, 'secret', status_code=500)\n            self.assertNotContains(response, 'other', status_code=500)\n"], "sample_23": ["def test_latitude_out_of_limits_large(value):\n    with pytest.raises(ValueError, match=r\"Latitude angle\\(s\\) must be within.*\"):\n        Latitude(value, u.rad)\n"], "sample_209": ["    def test_ordering_with_related_fields(self):\n        \"\"\"\n        Regression test for #10153: ordering by related fields.\n        \"\"\"\n        dept1 = Department.objects.create(name='IT')\n        dept2 = Department.objects.create(name='HR')\n        worker1 = Worker.objects.create(department=dept1, name='Alice')\n        worker2 = Worker.objects.create(department=dept2, name='Bob')\n        worker3 = Worker.objects.create(department=dept1, name='Charlie')\n\n        # Test ordering by department name\n        self.assertQuerysetEqual(\n            Worker.objects.order_by('department__name'),\n            ['HR', 'IT']\n        )\n\n        # Test ordering by department name in reverse\n        self.assertQuerysetEqual(\n            Worker.objects.order_by('-department__name'),\n            ['IT', 'HR']\n        )\n\n        # Test ordering by department name and then worker name\n        self.assertQuerysetEqual(\n            Worker.objects.order_by('department__name', 'name'),\n            ['HR', 'Bob', 'IT', 'Alice', 'IT', 'Charlie']\n        )\n"], "sample_1149": ["def test_sympify_in_singleton_registry():\n    class MySingleton(Basic, metaclass=Singleton):\n        pass\n\n    assert S(MySingleton()) is S.MySingleton\n"], "sample_216": ["    def test_add_model_with_field_removed_from_base_model(self):\n        \"\"\"\n        Removing a base field takes place before adding a new inherited model\n        that has a field with the same name.\n        \"\"\"\n        before = [\n            ModelState('app', 'readable', [\n                ('id', models.AutoField(primary_key=True)),\n                ('title', models.CharField(max_length=200)),\n            ]),\n        ]\n        after = [\n            ModelState('app', 'readable', [\n                ('id', models.AutoField(primary_key=True)),\n            ]),\n            ModelState('app', 'book', [\n                ('title', models.CharField(max_length=200)),\n            ], bases=('app.readable',)),\n        ]\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'app', 1)\n        self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel'])\n        self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n        self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n"], "sample_1063": ["def test_gamma_scipy():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    f = gamma(x)\n    F = lambdify(x, f, modules='scipy')\n\n    assert abs(gamma(1.3) - F(1.3)) <= 1e-10\n"], "sample_637": ["    def test_regex_codetag(self) -> None:\n        code = \"\"\"a = 1\n                # TODO this is a test\n                \"\"\"\n        with self.assertAddsMessages(\n            MessageTest(msg_id=\"fixme\", line=2, args=\"TODO this is a test\", col_offset=17)\n        ):\n            self.checker.process_tokens(_tokenize_str(code))\n"], "sample_688": ["    def test_import_mode_with_package_and_non_package(self, testdir):\n        \"\"\"Test import mode with both package and non-package modules.\"\"\"\n        testdir.makepyfile(\n            \"tests/package_a/__init__.py\",\n            \"tests/package_a/test_foo.py\": \"def test_foo(): pass\",\n            \"tests/package_b/test_bar.py\": \"def test_bar(): pass\",\n        )\n        result = testdir.runpytest(\"-v\", \"--import-mode=importlib\")\n        result.stdout.fnmatch_lines(\n            [\n                \"tests/package_a/test_foo.py::test_foo *\",\n                \"tests/package_b/test_bar.py::test_bar *\",\n                \"* 2 passed in *\",\n            ]\n        )\n"], "sample_499": ["def test_legend_fontsize_inheritance():\n    fig, axes = plt.subplots(2, 2)\n    axes[0, 0].plot(range(10))\n    axes[0, 0].set_title('Title 1')\n    axes[0, 0].set_xlabel('X Label')\n    axes[0, 0].set_ylabel('Y Label')\n    axes[0, 0].legend(fontsize=12)\n\n    axes[0, 1].plot(range(10))\n    axes[0, 1].set_title('Title 2')\n    axes[0, 1].set_xlabel('X Label')\n    axes[0, 1].set_ylabel('Y Label')\n    axes[0, 1].legend(fontsize=10)\n\n    axes[1, 0].plot(range(10))\n    axes[1, 0].set_title('Title 3')\n    axes[1, 0].set_xlabel('X Label')\n    axes[1, 0].set_ylabel('Y Label')\n    axes[1, 0].legend()  # Default fontsize\n\n    axes[1, 1].plot(range(10))\n    axes[1, 1].set_title('Title 4')\n    axes[1, 1].set_xlabel('X Label')\n    axes[1, 1].set_ylabel('Y Label')\n    axes[1, 1].legend(fontsize=14)\n\n    # Check that legend fontsizes are as expected\n    for ax in axes.flat:\n        leg = ax.legend()\n        for text in leg.get_texts():\n            assert text.get_fontsize() == ax.legend().get_fontsize()\n"], "sample_1092": ["def test_issue_18203_complex():\n    eq = CRootOf(x**5 + 11*x - 2, 0) + CRootOf(x**5 + 11*x - 2, 1) + 1j*CRootOf(x**5 + 11*x - 2, 0)\n    assert cse(eq) == ([], [eq])\n"], "sample_793": ["def test_iforest_oob_score():\n    X = iris.data\n    y = iris.target\n    clf = IsolationForest(n_estimators=100, random_state=0, oob_score=True)\n    clf.fit(X, y)\n    assert hasattr(clf, 'oob_score_')\n    assert 0 <= clf.oob_score_ <= 1\n"], "sample_729": ["def test_enet_multioutput_sparse_data():\n    X, y, _, _ = build_dataset(n_samples=50, n_features=100)\n    y = y[:, np.newaxis]\n    X_sparse = sparse.csr_matrix(X)\n    \n    enet = MultiTaskElasticNet(alpha=0.1, tol=1e-8)\n    enet.fit(X_sparse, y)\n    assert_array_almost_equal(enet.coef_[0], enet.coef_[0])\n    assert_array_almost_equal(enet.intercept_[0], enet.intercept_[0])\n\n    enet = MultiTaskElasticNet(alpha=0.1, tol=1e-8, precompute=True)\n    enet.fit(X_sparse, y)\n    assert_array_almost_equal(enet.coef_[0], enet.coef_[0])\n    assert_array_almost_equal(enet.intercept_[0], enet.intercept_[0])\n"], "sample_47": ["    def test_cleanse_setting_nested_dict(self):\n        data = {\n            'FOOBAR': 'TEST',\n            'PASSWORD': 'super_secret',\n            'OTHER': {'SECRET': 'another_secret'}\n        }\n        cleaned_data = cleanse_setting(data, 'FOOBAR')\n        self.assertEqual(cleaned_data['FOOBAR'], 'TEST')\n        self.assertEqual(cleaned_data['PASSWORD'], CLEANSED_SUBSTITUTE)\n        self.assertEqual(cleaned_data['OTHER'], {'SECRET': CLEANSED_SUBSTITUTE})\n"], "sample_777": ["    def test_gradient_boosting_with_loss(loss):\n        X, y = datasets.make_classification(n_samples=100, random_state=0)\n\n        # Test that GradientBoostingClassifier works with different loss functions\n        gbc = GradientBoostingClassifier(loss=loss, random_state=42)\n        gbc.fit(X, y)\n\n        # Test that GradientBoostingRegressor works with different loss functions\n        gbr = GradientBoostingRegressor(loss=loss, random_state=42)\n        gbr.fit(X, y)\n"], "sample_436": ["    def test_suggestions_with_invalid_settings(self):\n        args = [\"dumpdata\", \"--settings=nonexistent_settings\"]\n        out, err = self.run_django_admin(args)\n        self.assertOutput(err, \"Error: Settings module 'nonexistent_settings' not found.\")\n        self.assertOutput(err, \"Did you mean 'settings'?\")\n"], "sample_19": ["compilation error"], "sample_332": ["    def test_invalid(self):\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '0',\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': '',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '1',\n        }\n        ChoiceFormSet = formset_factory(Choice)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [{'votes': ['This field is required.']}, {}]\n        self.assertEqual(formset1._errors, expected_errors)\n        self.assertEqual(formset2._errors, expected_errors)\n"], "sample_380": ["    def test_aggregation_default_with_subquery(self):\n        with self.assertNumQueries(1):\n            result = Publisher.objects.annotate(\n                avg_rating=Avg('book__rating', default=0),\n                count=Count('book'),\n            ).filter(avg_rating__gt=3.0).values('name', 'avg_rating', 'count')\n        self.assertSequenceEqual(\n            result,\n            [\n                {'name': 'Morgan Kaufmann', 'avg_rating': 4.0, 'count': 2},\n                {'name': 'Prentice Hall', 'avg_rating': 4.0, 'count': 2},\n            ],\n        )\n"], "sample_1075": ["    def test_beta_derivative_with_symbols():\n        x, y = Symbol('x'), Symbol('y')\n        assert diff(beta(x, y), x) == (digamma(x) - digamma(x + y))*beta(x, y)\n        assert diff(beta(x, y), y) == (digamma(y) - digamma(x + y))*beta(x, y)\n"], "sample_583": ["compilation error"], "sample_1171": ["def test_issue_17858_continued():\n    assert 1 in Range(-oo, oo, 2)\n    assert 0 not in Range(-oo, oo, 2)\n    assert -1 in Range(-oo, oo, 2)\n    assert 2 not in Range(-oo, oo, 2)\n    assert 1 in Range(oo, -oo, -2)\n    assert 0 not in Range(oo, -oo, -2)\n    assert -1 not in Range(oo, -oo, -2)\n    assert 2 in Range(oo, -oo, -2)\n"], "sample_448": ["    def test_expressions_with_include(self):\n        msg = (\n            \"UniqueConstraint.include cannot be used with expressions. \"\n            \"Use django.contrib.postgres.indexes.OpClass() instead.\"\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            models.UniqueConstraint(\n                Lower(\"field\"),\n                name=\"test_func_include\",\n                include=[\"other_field\"],\n            )\n"], "sample_456": ["    def test_invalid(self):\n        data = {\n            \"choices-TOTAL_FORMS\": \"2\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Zero\",\n            \"choices-0-votes\": \"\",\n            \"choices-1-choice\": \"One\",\n            \"choices-1-votes\": \"1\",\n        }\n        ChoiceFormSet = formset_factory(Choice)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [\n            {\"choices-0-votes\": [\"This field is required.\"] },\n            {},\n        ]\n        self.assertEqual(formset1._errors, expected_errors)\n        self.assertEqual(formset2._errors, expected_errors)\n"], "sample_3": ["def test_read_complex_with_subtype():\n    txt = \"\"\"\\"], "sample_888": ["def test_iforest_with_sparse_data_and_max_features():\n    \"\"\"Test Isolation Forest with sparse data and max_features.\"\"\"\n    rng = check_random_state(0)\n    X_train = rng.randn(100, 100).astype(np.float32)\n    X_train_sparse = csc_matrix(X_train)\n    X_test = rng.randn(50, 100).astype(np.float32)\n    X_test_sparse = csc_matrix(X_test)\n\n    # Test with max_features=None (all features)\n    iforest = IsolationForest(max_features=None, random_state=0)\n    iforest.fit(X_train_sparse)\n    iforest.predict(X_test_sparse)\n\n    # Test with max_features=0.5\n    iforest = IsolationForest(max_features=0.5, random_state=0)\n    iforest.fit(X_train_sparse)\n    iforest.predict(X_test_sparse)\n\n    # Test with max_features=0.1\n    iforest = IsolationForest(max_features=0.1, random_state=0)\n    iforest.fit(X_train_sparse)\n    iforest.predict(X_test_sparse)\n\n    # Test with max_features=int\n    iforest = IsolationForest(max_features=20, random_state=0)\n    iforest.fit(X_train_sparse)\n    iforest.predict(X_test_sparse)\n"], "sample_419": ["    def test_formset_can_be_instantiated_with_form_class_and_renderer(self):\n        renderer = Jinja2()\n        ChoiceFormSet = formset_factory(Choice, renderer=renderer)\n        formset = ChoiceFormSet()\n        self.assertEqual(formset.renderer, renderer)\n"], "sample_591": ["    def test_merge_preserve_attrs(self):\n        data = xr.Dataset({\"x\": 0, \"y\": 1}, attrs={\"foo\": \"bar\"})\n        ds1 = data.copy()\n        ds2 = data.copy()\n        ds2.attrs[\"baz\"] = \"qux\"\n        merged = ds1.merge(ds2)\n        assert merged.attrs == {\"foo\": \"bar\", \"baz\": \"qux\"}\n\n        merged = ds2.merge(ds1)\n        assert merged.attrs == {\"foo\": \"bar\", \"baz\": \"qux\"}\n\n        merged = xr.merge([ds1, ds2])\n        assert merged.attrs == {\"foo\": \"bar\", \"baz\": \"qux\"}\n\n        with pytest.raises(ValueError):\n            ds1.merge(ds2, compat=\"no_conflicts\")\n"], "sample_59": ["    def test_unique_together_validation(self):\n        NonAutoPK.objects.create(name=\"one\", value=1)\n        with self.assertRaises(ValidationError):\n            NonAutoPK.objects.create(name=\"one\", value=1)\n"], "sample_460": ["    def test_missing_slash_append_slash_true_script_name_without_final_catch_all_view(self):\n        superuser = User.objects.create_user(\n            username=\"staff\",\n            password=\"secret\",\n            email=\"staff@example.com\",\n            is_staff=True,\n        )\n        self.client.force_login(superuser)\n        known_url = reverse(\"admin10:admin_views_article_changelist\")\n        response = self.client.get(known_url[:-1], SCRIPT_NAME=\"/prefix/\")\n        self.assertRedirects(\n            response,\n            \"/prefix\" + known_url,\n            status_code=301,\n            fetch_redirect_response=False,\n        )\n"], "sample_830": ["def test_show_versions():\n    show_versions()\n    \n    # Assertions should be added here to check the output of show_versions\n    # For example, you could assert that the output contains specific strings\n    # related to the system, BLAS, and dependencies.\n"], "sample_1041": ["def test_transpose_commutativity():\n    A = MatrixSymbol('A', n, m)\n    assert (A.T).T == A\n    assert (A + B).T == A.T + B.T\n    assert (A * B).T == B.T * A.T\n    assert (A * 2).T == 2 * A.T\n    assert (A**2).T == A.T**2\n    assert (A**-1).T == (A.T)**-1\n    assert (Transpose(A)).T == A\n    assert (Adjoint(A)).T == Adjoint(A.T)\n\n\n\n"], "sample_447": ["    def test_alias_with_subquery(self):\n        qs = (\n            Book.objects.alias(\n                top_rating_alias=Subquery(\n                    Book.objects.filter(pubdate__year=OuterRef(\"pubdate__year\"))\n                    .order_by(\"-rating\")\n                    .values(\"rating\")[:1]\n                )\n            )\n            .values(\"pubdate__year\", \"top_rating_alias\")\n        )\n        self.assertCountEqual(\n            qs,\n            [\n                {\"pubdate__year\": 1991, \"top_rating_alias\": 5.0},\n                {\"pubdate__year\": 1995, \"top_rating_alias\": 4.0},\n                {\"pubdate__year\": 2007, \"top_rating_alias\": 4.5},\n                {\"pubdate__year\": 2008, \"top_rating_alias\": 4.0},\n                {\"pubdate__year\": 2008, \"top_rating_alias\": 4.0},\n                {\"pubdate__year\": 2008, \"top_rating_alias\": 4.0},\n            ],\n        )\n"], "sample_418": ["    def test_length_is12(self):\n        output = self.engine.render_to_string(\"length_is12\", {\"var\": \"1\"})\n        self.assertEqual(output, \"Not 1\")\n"], "sample_525": ["def test_subplots_adjust_kwargs():\n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 1, 1)\n    fig.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n    assert fig.get_tight_layout() is None\n    fig.subplots_adjust(wspace=0.2, hspace=0.2)\n    assert fig.get_tight_layout() is None\n    plt.close(fig)\n"], "sample_650": ["def test_log_format_with_custom_format(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import logging\n\n        logger = logging.getLogger(__name__)\n\n            logger.warning('text')\n            assert False\n        \"\"\"\n    )\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_format = %(name)s: %(levelname)s - %(message)s\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 1\n    result.stdout.fnmatch_lines(\n        [\"test_log_format_with_custom_format:WARNING - text\"]\n    )\n"], "sample_1107": ["def test_is_partition():\n    assert is_partition([]) is True\n    assert is_partition([1]) is True\n    assert is_partition([1, 2]) is True\n    assert is_partition([1, 1, 2]) is True\n    assert is_partition([1, 2, 3]) is True\n    assert is_partition([1, 2, 2]) is True\n    assert is_partition([1, 2, 3, 3]) is True\n    assert is_partition([1, 2, 3, 4, 5]) is True\n    assert is_partition([1, 1, 2, 2, 3]) is True\n    assert is_partition([1, 1, 1, 2, 2]) is True\n    assert is_partition([1, 1, 1, 1, 2]) is True\n    assert is_partition([1, 1, 1, 1, 1]) is True\n    assert is_partition([1, 2, 3, 4, 5, 6]) is True\n    assert is_partition([1, 2, 3, 4, 5, 6, 7]) is True\n    assert is_partition([1, 2, 3, 4, 5, 6, 7, 8]) is True\n    assert is_partition([1, 2, 3, 4, 5, 6, 7, 8, 9]) is True\n    assert is_partition([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) is True\n    assert is_partition([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) is True\n    assert is_partition([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]) is True\n    assert is_partition([1, 2, 3, 4, 5, 6, 7, 8, "], "sample_603": ["def test_summarize_attrs_empty(dataset):\n    formatted = fh.summarize_attrs({})\n    assert formatted == \"\"\n"], "sample_939": ["    def test_unparse_complex_expression():\n        source = \"\"\"\n        (a + b) * (c - d) // e\n        \"\"\"\n        module = ast.parse(source)\n        expected = \"(a + b) * (c - d) // e\"\n        assert ast.unparse(module.body[0].value, source) == expected\n"], "sample_29": ["    def test_write_latex_empty_cosmology(self, write, tmp_path):\n        \"\"\"Test writing an empty cosmology.\"\"\"\n        fp = tmp_path / \"test_write_latex_empty.tex\"\n        empty_cosmo = Cosmology()\n        write(fp, format=\"latex\", cosmology=empty_cosmo)\n        tbl = QTable.read(fp)\n        assert len(tbl) == 0\n"], "sample_227": ["    def test_emptylistfieldfilter_with_booleanfield(self):\n        class BookAdminWithBooleanFieldListFilter(BookAdmin):\n            list_filter = (\n                ('is_best_seller', EmptyFieldListFilter),\n            )\n\n        modeladmin = BookAdminWithBooleanFieldListFilter(Book, site)\n        request = self.request_factory.get('/')\n        request.user = self.alfred\n        changelist = modeladmin.get_changelist_instance(request)\n        filterspec = changelist.get_filters(request)[0][0]\n        self.assertEqual(filterspec.title, 'is best seller')\n        choices = list(filterspec.choices(changelist))\n        self.assertEqual(len(choices), 3)\n\n        self.assertEqual(choices[0]['display'], 'All')\n        self.assertIs(choices[0]['selected'], True)\n        self.assertEqual(choices[0]['query_string'], '?')\n\n        self.assertEqual(choices[1]['display'], 'Empty')\n        self.assertIs(choices[1]['selected'], False)\n        self.assertEqual(choices[1]['query_string'], '?is_best_seller__isnull=True')\n\n        self.assertEqual(choices[2]['display'], 'Not empty')\n        self.assertIs(choices[2]['selected'], False)\n        self.assertEqual(choices[2]['query_string'], '?is_best_seller__isnull=False')\n"], "sample_996": ["def test_issue_14036_continued():\n    a, n = symbols('a n')\n    assert product(1 - a**2 / (n*pi)**2, [n, 1, oo]).simplify() == \\\n        (1/pi) * (asin(a) / a)\n"], "sample_304": ["    def test_domain_allowlist_warning(self):\n        msg = \"The domain_allowlist attribute is deprecated in favor of allowlist.\"\n        with self.assertRaisesMessage(RemovedInDjango41Warning, msg):\n            EmailValidator().domain_allowlist = ['mydomain']\n"], "sample_67": ["    def test_setattr_raises_validation_error_field_specific_with_instance(self):\n        \"\"\"\n        A model ValidationError using the dict form should put the error\n        message into the correct key of form.errors.\n        \"\"\"\n        form_class = modelform_factory(model=StrictAssignmentFieldSpecific, fields=['title'])\n        instance = StrictAssignmentFieldSpecific(title='testing setattr')\n        form = form_class(instance=instance, data={'title': 'testing setattr'}, files=None)\n        # This line turns on the ValidationError; it avoids the model erroring\n        # when its own __init__() is called when creating form.instance.\n        form.instance._should_error = True\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors, {\n            'title': ['Cannot set attribute', 'This field cannot be blank.']\n        })\n"], "sample_510": ["def test_subplot_projection_reuse_with_kwargs():\n    # create an Axes\n    ax1 = plt.subplot(111)\n    # check that it is current\n    assert ax1 is plt.gca()\n    # make sure we get it back if we ask again\n    assert ax1 is plt.subplot(111)\n    # remove it\n    ax1.remove()\n    # create a polar plot with kwargs\n    ax2 = plt.subplot(111, projection='polar', theta_offset=45)\n    assert ax2 is plt.gca()\n    # this should have deleted the first axes\n    assert ax1 not in plt.gcf().axes\n    # assert we get it back if no extra parameters passed\n    assert ax2 is plt.subplot(111, projection='polar', theta_offset=45)\n    ax2.remove()\n    # now check explicitly setting the projection to rectilinear\n    # makes a new axes\n    ax3 = plt.subplot(111, projection='rectilinear')\n    assert ax3 is plt.gca()\n    assert ax3 is not ax2\n    assert ax2 not in plt.gcf().axes\n"], "sample_917": ["    def check_xref_consistency(role, tag, expected_classes):\n        classes_found = classes(role, tag)\n        assert classes_found == expected_classes, (\n            f\"Classes for role '{role}' with tag '{tag}' do not match. \"\n            f\"Found: {classes_found}, Expected: {expected_classes}\"\n        )\n"], "sample_307": ["    def test_invalid_format_specifiers(self):\n        my_birthday = datetime(1979, 7, 8, 22, 00)\n\n        for specifier in ['x', 'X', 'c', 'D', 'l', 'L', 'n', 'N', 'o', 'W', 'z']:\n            msg = \"Invalid format specifier: '%s'\" % specifier\n            with self.assertRaisesMessage(ValueError, msg):\n                dateformat.format(my_birthday, specifier)\n"], "sample_1153": ["def test_issue_14708():\n    from sympy import Abs, re, im, Symbol\n    x = Symbol('x', real=True)\n    y = Symbol('y', imaginary=True)\n    assert Abs(x + I*y) == sqrt(x**2 + y**2)\n    assert re(x + I*y) == x\n    assert im(x + I*y) == y\n    assert Abs(x + I*y).subs(y, 0) == Abs(x)\n    assert Abs(x + I*y).subs(x, 0) == Abs(y)\n"], "sample_318": ["    def test_lookahead_and_lookbehind_together(self):\n        test_urls = [\n            ('/lookahead-lookbehind-positive', {'city': 'a-city'}, '/lookahead+/lookbehind+/a-city/'),\n            ('/lookahead-lookbehind-negative', {'city': 'a-city'}, '/lookahead-/lookbehind-/a-city/'),\n        ]\n        for name, kwargs, expected in test_urls:\n            with self.subTest(name=name, kwargs=kwargs):\n                self.assertEqual(reverse(name, kwargs=kwargs), expected)\n"], "sample_869": ["def test_balanced_accuracy_score_with_multiclass_labels():\n    y_true = np.array([0, 1, 2, 0, 1, 2])\n    y_pred = np.array([0.1, 0.9, 0.2, 0.8, 0.7, 0.3])\n    balanced = balanced_accuracy_score(y_true, y_pred)\n    assert balanced == pytest.approx(0.75)\n"], "sample_743": ["def test_sparse_metric_callable_with_dense_input():\n        assert_true(issparse(x) and issparse(y))\n        return x.dot(y.T).A.item()\n\n    X = np.random.rand(5, 5)\n    y = np.random.rand(5, 5)\n    with pytest.raises(ValueError):\n        neighbors.KNeighborsClassifier(metric=sparse_metric).fit(X, y)\n"], "sample_323": ["    def test_minimize_rollbacks_circular(self):\n        \"\"\"Minimize rollbacks when there are circular dependencies.\"\"\"\n        a1_impl = FakeMigration('a1')\n        a1 = ('a', '1')\n        a2_impl = FakeMigration('a2')\n        a2 = ('a', '2')\n        b1_impl = FakeMigration('b1')\n        b1 = ('b', '1')\n        graph = MigrationGraph()\n        graph.add_node(a1, a1_impl)\n        graph.add_node(a2, a2_impl)\n        graph.add_node(b1, b1_impl)\n        graph.add_dependency(None, a2, a1)\n        graph.add_dependency(None, b1, a2)\n        graph.add_dependency(None, a1, b1)\n\n        executor = MigrationExecutor(None)\n        executor.loader = FakeLoader(graph, {\n            a1: a1_impl,\n            a2: a2_impl,\n            b1: b1_impl,\n        })\n\n        plan = executor.migration_plan({a1})\n\n        self.assertEqual(plan, [(a2_impl, True), (b1_impl, True)])\n"], "sample_952": ["compilation error"], "sample_558": ["def test_inset_axes_with_colorbar():\n    fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n    ax[0].plot([1, 2, 3], [4, 5, 6])\n    ax[1].plot([1, 2, 3], [4, 5, 6])\n\n    inset_ax = zoomed_inset_axes(ax[0], zoom=2, loc='upper right')\n    inset_ax.plot([1, 2, 3], [4, 5, 6])\n    inset_ax.set_title('Zoomed Inset')\n\n    cbar = fig.colorbar(ax[0].collections[0], ax=ax[0])\n    cbar.set_label('Colorbar Label')\n    cbar.ax.set_ylabel('Colorbar Units')\n\n    fig.tight_layout()\n"], "sample_691": ["def test_timeout_with_pdb(pytester: Pytester) -> None:\n    \"\"\"Test that timeout works correctly when entering pdb.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n    import os, time\n    import faulthandler\n        time.sleep(1 if \"CI\" in os.environ else 0.1)\n        import pdb; pdb.set_trace()\n    \"\"\"\n    )\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        faulthandler_timeout = 0.01\n    \"\"\"\n    )\n    result = pytester.runpytest_subprocess()\n    result.stderr.fnmatch_lines([\"*%s*\" % \"most recent call first\"])\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n    assert result.ret != 0\n"], "sample_632": ["def test_ignore_comments_and_docstrings():\n    output = StringIO()\n    with redirect_stdout(output), pytest.raises(SystemExit) as ex:\n        similar.Run([\"--ignore-comments\", \"--ignore-docstrings\", SIMILAR1, SIMILAR2])\n    assert ex.value.code == 0\n    assert (\n        output.getvalue().strip()\n        == (\n            \"\"\""], "sample_313": ["    def test_get_template_directories_with_duplicate_paths(self):\n        self.assertSetEqual(\n            autoreload.get_template_directories(),\n            {\n                Path.cwd() / 'template_tests/relative_path',\n                Path.cwd() / 'template_tests/relative_path2',\n            }\n        )\n"], "sample_247": ["    def test_alias_with_subquery(self):\n        qs = Book.objects.alias(\n            top_rating=Subquery(\n                Book.objects.filter(pubdate__year=OuterRef('pubdate_alias')).order_by('-rating').values('rating')[:1]\n            )\n        ).annotate(\n            pubdate_alias=F('pubdate'),\n        ).values('pubdate_alias', 'top_rating')\n        self.assertCountEqual(qs, [\n            (datetime.date(1991, 10, 15), 5.0),\n            (datetime.date(1995, 1, 15), 4.0),\n            (datetime.date(2007, 12, 6), 4.5),\n            (datetime.date(2008, 6, 23), 4.0),\n        ])\n"], "sample_288": ["    def test_key_transform_with_subquery(self):\n        subquery_value = NullableJSONModel.objects.filter(pk=OuterRef('pk')).values('value')\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(\n                value__baz__a=KeyTransform('b', subquery_value),\n            ).values_list('id', flat=True),\n            [self.objs[7].id],\n        )\n"], "sample_737": ["def test_vectorizer_empty_vocabulary():\n    # Test for empty vocabulary when fitting on empty data\n    vect = CountVectorizer()\n    assert_raises(ValueError, vect.fit, [])\n    vect = TfidfVectorizer()\n    assert_raises(ValueError, vect.fit, [])\n    vect = HashingVectorizer()\n    assert_raises(ValueError, vect.fit, [])\n"], "sample_291": ["    def test_custom_context_object_name(self):\n        test_view = views.CustomMultipleObjectMixinView()\n        test_view.context_object_name = 'my_objects'\n        context = test_view.get_context_data()\n        self.assertEqual(context['my_objects'], test_view.object_list)\n"], "sample_1143": ["def test_issue_10696():\n    assert Float('1.2345678901234567890123456789012345678901234567890', 100) == Float('1.2345678901234567890123456789012345678901234567890', 100)\n"], "sample_191": ["    def test_snapshot_files_handles_new_files(self):\n        new_file = self.ensure_file(self.tempdir / 'new_file.py')\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file, new_file]):\n            snapshot1 = dict(self.reloader.snapshot_files())\n            self.assertIn(self.existing_file, snapshot1)\n            self.assertIn(new_file, snapshot1)\n"], "sample_173": ["    def test_sql_flush_with_tables(self):\n        Author.objects.create(name='John Doe')\n        Book.objects.create(title='The Book', author=Author.objects.get(name='John Doe'))\n        with transaction.atomic():\n            with self.assertRaises(NotImplementedError) as cm:\n                connection.ops.sql_flush(no_style(), ['django_content_type', 'django_migrations', 'auth_user', 'auth_group', 'auth_permission', 'auth_user_groups', 'auth_user_permissions', 'sessions', 'django_session', 'contenttypes', 'migrations', 'auth_user', 'auth_group', 'auth_permission', 'auth_user_groups', 'auth_user_permissions', 'sessions', 'django_session', 'contenttypes', 'auth_group_permissions', 'auth_user_permissions', 'auth_user_groups', 'auth_user_groups', 'auth_user_permissions', 'auth_user_permissions', 'auth_user_groups', 'auth_user_groups', 'auth_user_permissions', 'auth_user_permissions', 'auth_user_groups', 'auth_user_groups', 'auth_user_permissions', 'auth_user_permissions', 'auth_user_groups', 'auth_user_groups', 'auth_user_permissions', 'auth_user_permissions', 'auth_user_groups', 'auth_user_groups', 'auth_user_permissions', 'auth_user_permissions', 'auth_user_groups', 'auth_user_groups', 'auth_user_permissions', 'auth_user_permissions', 'auth_user_groups', 'auth_user_groups', 'auth_user_permissions', 'auth_user_permissions', 'auth_user_groups', 'auth_user_groups', 'auth_user_permissions', 'auth_user_permissions', 'auth_user_groups', 'auth_user_groups', 'auth_user_permissions', 'auth_user_permissions', 'auth_user_groups', 'auth_user_groups', 'auth_user_permissions', 'auth_user_permissions', 'auth_user_groups', 'auth_user_groups', 'auth_user_permissions', 'auth_user_permissions', 'auth_"], "sample_431": ["    def test_refresh_from_db_with_related_fields(self):\n        a = Article.objects.create(headline=\"Parrot programs in Python\", pub_date=datetime(2005, 7, 28))\n        f = FeaturedArticle.objects.create(article=a)\n        with self.assertNumQueries(1):\n            a.refresh_from_db(fields=[\"headline\", \"featured__headline\"])\n        self.assertEqual(a.headline, \"Parrot programs in Python\")\n        self.assertEqual(a.featured.headline, \"Featured Article\")\n"], "sample_955": ["    def test_unparse_complex_expression():\n        source = \"\"\"\n        a = (b + c) * (d - e)\n        \"\"\"\n        module = ast.parse(source)\n        assert ast.unparse(module.body[0].value, source) == \"a = (b + c) * (d - e)\"\n"], "sample_502": ["def test_subplot_projection_reuse_with_kwargs():\n    ax1 = plt.subplot(projection='polar')\n    ax2 = plt.subplot(projection='polar', theta_offset=np.pi/4)\n    assert ax1 is not ax2\n    assert ax2.theta_offset == np.pi/4\n"], "sample_810": ["def test_pipeline_memory_with_custom_transformer():\n    cachedir = mkdtemp()\n    if LooseVersion(joblib_version) < LooseVersion('0.12'):\n        # Deal with change of API in joblib\n        memory = Memory(cachedir=cachedir, verbose=10)\n    else:\n        memory = Memory(location=cachedir, verbose=10)\n\n    class CustomTransformer:\n            self.cache_key = cache_key\n            self.cached_result = None\n\n            self.cached_result = X * 2\n            return self\n\n            return self.cached_result\n\n    pipeline = Pipeline([\n        ('custom_transf', CustomTransformer(cache_key='custom_key')),\n        ('svc', SVC())\n    ], memory=memory)\n\n    X = np.array([[1, 2]])\n    pipeline.fit(X, y=None)\n    # Check that the transformer's cached result is used\n    assert_array_equal(pipeline.named_steps['custom_transf'].cached_result,\n                       X * 2)\n    # Check that the cached result is used on the second fit\n    pipeline.fit(X, y=None)\n    assert_array_equal(pipeline.named_steps['custom_transf'].cached_result,\n                       X * 2)\n    shutil.rmtree(cachedir)\n"], "sample_794": ["def test_ridge_classifier_multi_output():\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5,\n                               n_classes=3, random_state=42)\n    y = y.reshape(-1, 3)\n    ridge_clf = RidgeClassifier()\n    ridge_clf.fit(X, y)\n    assert_array_equal(ridge_clf.coef_.shape, (3, 10))\n    assert_array_equal(ridge_clf.intercept_.shape, (3,))\n"], "sample_128": ["    def test_covering_index_with_condition_and_opclasses(self):\n        index = Index(\n            name='covering_partial_headline_idx',\n            fields=['headline'],\n            include=['pub_date', 'published'],\n            condition=Q(pub_date__gt=datetime.datetime(2023, 1, 1)),\n            opclasses=['text_pattern_ops'],\n        )\n        with connection.schema_editor() as editor:\n            self.assertIn(\n                '(%s text_pattern_ops) INCLUDE (%s, %s) WHERE %s' % (\n                    editor.quote_name('headline'),\n                    editor.quote_name('pub_date'),\n                    editor.quote_name('published'),\n                    editor.quote_name('pub_date'),\n                ),\n                str(index.create_sql(Article, editor)),\n            )\n            editor.add_index(Article, index)\n            with connection.cursor() as cursor:\n                constraints = connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                )\n                self.assertIn(index.name, constraints)\n                self.assertEqual(\n                    constraints[index.name]['columns'],\n                    ['headline', 'pub_date', 'published'],\n                )\n            editor.remove_index(Article, index)\n            with connection.cursor() as cursor:\n                self.assertNotIn(index.name, connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                ))\n"], "sample_455": ["    def test_expressions_with_include(self):\n        msg = \"UniqueConstraint.include cannot be used with expressions.\"\n        with self.assertRaisesMessage(ValueError, msg):\n            models.UniqueConstraint(\n                Lower(\"field\"),\n                name=\"test_func_include\",\n                include=[\"other_field\"],\n            )\n"], "sample_461": ["    def test_urlfield_clean_with_invalid_port(self):\n        f = URLField()\n        msg = \"'Enter a valid URL.'\"\n        with self.assertRaisesMessage(ValidationError, msg):\n            f.clean(\"http://example.com:1234567890\")\n"], "sample_270": ["    def test_unique_constraint_include_pointing_to_fk(self):\n        class Target(models.Model):\n            pass\n\n        class Model(models.Model):\n            fk_1 = models.ForeignKey(Target, models.CASCADE, related_name='target_1')\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['fk_1_id'],\n                        include=['id'],\n                        name='name',\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n"], "sample_646": ["    def test_traceback_pruning_with_setup_failure(self):\n        pytester.makepyfile(\n            \"\"\"\n            import unittest\n\n            class MyTestCase(unittest.TestCase):\n                    assert False\n\n                    pass\n            \"\"\"\n        )\n        reprec = pytester.inline_run()\n        passed, skipped, failed = reprec.countoutcomes()\n        assert passed == 0\n        assert failed == 1\n        assert reprec.ret == 1\n"], "sample_1176": ["def test_issue_11984():\n    assert Float('1.2345678901234567890123456789012345678901234567890').n(10) == '1.234567890'\n    assert Float('1.2345678901234567890123456789012345678901234567890').n(11) == '1.2345678901'\n    assert Float('1.2345678901234567890123456789012345678901234567890').n(12) == '1.23456789012'\n    assert Float('1.2345678901234567890123456789012345678901234567890').n(13) == '1.234567890123'\n    assert Float('1.2345678901234567890123456789012345678901234567890').n(14) == '1.2345678901234'\n    assert Float('1.2345678901234567890123456789012345678901234567890').n(15) == '1.23456789012345'\n    assert Float('1.23456789012345678901"], "sample_373": ["    def test_field_description_with_placeholders(self):\n        class PlaceholderField(models.CharField):\n            description = \"This field is a %(type)s field with a %(max_length)s character limit.\"\n\n        field = PlaceholderField(max_length=100)\n        self.assertEqual(views.get_readable_field_data_type(field), \"This field is a CharField with a 100 character limit.\")\n"], "sample_296": ["    def test_not_finished_sentinel(self):\n        storage = self.get_storage()\n        response = self.get_response()\n\n        # Store a message list that exceeds the max cookie size.\n        messages = [get_random_string(100) for _ in range(10)]\n        storage.update(response, messages)\n\n        # Retrieve the messages.\n        retrieved_messages = list(storage)\n        self.assertEqual(len(retrieved_messages), 0)\n\n        # Check that the cookie still contains the not_finished sentinel.\n        cookie = response.cookies.get(storage.cookie_name)\n        self.assertIsNotNone(cookie)\n        self.assertEqual(cookie.value, storage._encode(messages, encode_empty=True))\n\n        # Add more messages to the storage, which should now be able to fit\n        # in the cookie.\n        storage.add(constants.INFO, 'test')\n        storage.update(response)\n\n        # Retrieve the messages again.\n        retrieved_messages = list(storage)\n        self.assertEqual(len(retrieved_messages), 1)\n        self.assertEqual(retrieved_messages[0].message, 'test')\n\n        # Check that the cookie no longer contains the not_finished sentinel.\n        cookie = response.cookies.get(storage.cookie_name)\n        self.assertIsNotNone(cookie)\n        self.assertNotEqual(cookie.value, storage._encode(messages, encode_empty=True))\n"], "sample_656": ["compilation error"], "sample_703": ["def test_multiple_idents(expr: str, expected: bool) -> None:\n    matcher = {\"ident1\": True, \"ident2\": True, \"ident3\": False}.__getitem__\n    assert evaluate(expr, matcher) is expected\n"], "sample_197": ["    def test_custom_time_strings(self):\n        custom_time_strings = {\n            'year': 'year ago',\n            'month': 'month ago',\n            'week': 'week ago',\n            'day': 'day ago',\n            'hour': 'hour ago',\n            'minute': 'minute ago',\n        }\n        self.assertEqual(timesince(self.t, self.t + self.oneday, time_strings=custom_time_strings), '1\\xa0day ago')\n"], "sample_161": ["    def test_invalid_field_names_with_related_name(self):\n        \"\"\"\n        Providing invalid field names to ManyToManyField.through_fields\n        triggers validation errors, even if related_name is provided.\n        \"\"\"\n        class Fan(models.Model):\n            pass\n\n        class Event(models.Model):\n            invitees = models.ManyToManyField(\n                Fan,\n                through='Invitation',\n                through_fields=('invalid_field_1', 'invalid_field_2'),\n                related_name='event_invitees'\n            )\n\n        class Invitation(models.Model):\n            event = models.ForeignKey(Event, models.CASCADE)\n            invitee = models.ForeignKey(Fan, models.CASCADE)\n            inviter = models.ForeignKey(Fan, models.CASCADE, related_name='+')\n\n        field = Event._meta.get_field('invitees')\n        self.assertEqual(field.check(from_model=Event), [\n            Error(\n                \"The intermediary model 'invalid_models_tests.Invitation' has no field 'invalid_field_1'.\",\n                hint=\"Did you mean one of the following foreign keys to 'Event': event?\",\n                obj=field,\n                id='fields.E338',\n            ),\n            Error(\n                \"The intermediary model 'invalid_models_tests.Invitation' has no field 'invalid_field_2'.\",\n                hint=\"Did you mean one of the following foreign keys to 'Fan': invitee, inviter?\",\n                obj=field,\n                id='fields.E338',\n            ),\n        ])\n"], "sample_765": ["compilation error"], "sample_1032": ["def test_issue_13576():\n    from sympy.abc import x, y, z\n    assert Min(x, y, z).subs(x=oo).equals(Min(y, z))\n    assert Max(x, y, z).subs(x=oo).equals(Max(y, z))\n    assert Min(x, y, z).subs(y=oo).equals(Min(x, z))\n    assert Max(x, y, z).subs(y=oo).equals(Max(x, z))\n    assert Min(x, y, z).subs(z=oo).equals(Min(x, y))\n    assert Max(x, y, z).subs(z=oo).equals(Max(x, y))\n"], "sample_81": ["    def test_match_with_converters(self):\n        pattern = RoutePattern(_('translated/<int:pk>'))\n        match = pattern.match('/translated/123')\n        self.assertIsNotNone(match)\n        self.assertEqual(match.args, ())\n        self.assertEqual(match.kwargs, {'pk': 123})\n"], "sample_695": ["def test_node_repr_failure_with_fulltrace() -> None:\n    from _pytest.nodes import Node\n    from _pytest.compat import legacy_path\n    from _pytest.traceback import _TracebackStyle\n\n    class MyNode(Node):\n            super().__init__(name, parent=parent, config=config, session=session)\n\n    node = MyNode(\"my_test\", config=None, session=None)\n    excinfo = nodes.ExceptionInfo(\n        type=Exception,\n        value=Exception(\"This is a test exception\"),\n        traceback=[\n            nodes.Traceback(\n                [\n                    nodes.TracebackEntry(\n                        filename=\"test.py\",\n                        lineno=10,\n                        colno=5,\n                        function=\"my_test\",\n                        line=\"def my_test():\",\n                    )\n                ]\n            )\n        ],\n    )\n    with pytest.raises(Exception) as exc:\n        node._repr_failure_py(excinfo, style=_TracebackStyle.long)\n    assert \"This is a test exception\" in str(exc.value)\n    assert \"test.py:10:5\" in str(exc.value)\n\n\n\n"], "sample_1208": ["def test_MatrixStudentT_pdf_symbolic():\n    from sympy.stats import density\n    v = symbols('v', positive=True)\n    n, p = 1, 2\n    Omega = MatrixSymbol('Omega', p, p)\n    Sigma = MatrixSymbol('Sigma', n, n)\n    Location = MatrixSymbol('Location', n, p)\n    Y = MatrixSymbol('Y', n, p)\n    M = MatrixStudentT('M', v, Location, Omega, Sigma)\n\n    exprd = gamma(v/2 + 1)*Determinant(Matrix([[1]]) + Sigma**(-1)*(-Location + Y)*Omega**(-1)*(-Location.T + Y.T))**(-v/2 - 1) / \\\n            (pi*gamma(v/2)*sqrt(Determinant(Omega))*Determinant(Sigma))\n\n    assert density(M)(Y).dummy_eq(exprd)\n"], "sample_1095": ["compilation error"], "sample_854": ["def test_sparse_data_with_precomputed_kernel():\n    # Test that SVC with precomputed kernel works with sparse data\n    from scipy.sparse import csr_matrix\n\n    X = csr_matrix([[1, 0], [0, 1]])\n    y = [0, 1]\n    kernel = np.dot(X, X.T)\n    clf = svm.SVC(kernel='precomputed')\n    clf.fit(kernel, y)\n    assert clf.predict(kernel) == y\n"], "sample_817": ["def test_threshold_zero():\n    # Test VarianceThreshold with threshold=0.\n    for X in [data, csr_matrix(data), csc_matrix(data), bsr_matrix(data)]:\n        sel = VarianceThreshold(threshold=0).fit(X)\n        assert_array_equal(np.arange(len(data[0])), sel.get_support(indices=True))\n"], "sample_62": ["    def test_registration_with_custom_admin_site(self):\n        custom_site = CustomSite()\n        custom_site.register(Person, NameAdmin)\n        self.assertIsInstance(custom_site._registry[Person], NameAdmin)\n        self.assertNotEqual(custom_site._registry[Person], self.default_site._registry.get(Person))\n"], "sample_454": ["    def test_expressions_with_include(self):\n        msg = \"UniqueConstraint.include cannot be used with expressions.\"\n        with self.assertRaisesMessage(ValueError, msg):\n            models.UniqueConstraint(\n                Lower(\"field\"),\n                name=\"test_func_include\",\n                include=[\"other_field\"],\n            )\n"], "sample_354": ["    def test_create_permissions_with_custom_permissions(self):\n        \"\"\"\n        `create_permissions` should respect custom permissions defined in the app config.\n        \"\"\"\n        custom_permissions = [\n            ('my_custom_permission', 'Some custom permission'),\n            ('another_custom_permission', 'Another custom permission'),\n        ]\n        self.app_config.permissions = custom_permissions\n        permission_content_type = ContentType.objects.get_by_natural_key('auth', 'permission')\n        create_permissions(self.app_config, verbosity=0)\n\n        self.assertEqual(Permission.objects.filter(\n            content_type=permission_content_type,\n        ).count(), len(custom_permissions) + 5)  # 5 default + custom permissions\n\n\n\n"], "sample_101": ["    def test_request_class(self):\n        application = get_wsgi_application()\n        environ = self.request_factory._base_environ(\n            PATH_INFO=\"/\",\n            CONTENT_TYPE=\"text/html; charset=utf-8\",\n            REQUEST_METHOD=\"GET\"\n        )\n        request = application(environ, lambda *args: None)[0]\n        self.assertIsInstance(request, WSGIRequest)\n"], "sample_1170": ["def test_issue_22407():\n    from sympy.matrices import Matrix\n    A = Matrix([[1, 2], [3, 4]])\n    assert str(A.T) == 'A.T'\n"], "sample_909": ["    def test_restructuredtext_in_description(self):\n        docstring = \"\"\"\n        Example Function\n\n        This function does something.\n\n        It takes a list of numbers and returns the sum of the squares of the numbers.\n\n        .. math::\n           \\sum_{i=0}^{n-1} x_i^2\n\n        Parameters\n        ----------\n        numbers : list of numbers\n            A list of numbers to sum the squares of.\n\n        Returns\n        -------\n        float\n            The sum of the squares of the numbers.\n        \"\"\"\n        expected = \"\"\""], "sample_1017": ["def test_issue_13206():\n    x, y = symbols('x y')\n    assert (x > 0) & (y > 0).as_set() == Interval(0, oo)*Interval(0, oo)\n    assert (x > 0) | (y > 0).as_set() == S.Reals*S.Reals - \\\n        Interval(-oo, 0, True, True)*Interval(-oo, 0, True, True)\n"], "sample_515": ["def test_colorbar_fraction():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc, ax=ax, fraction=0.2)\n    assert cb.ax.get_position().height == 0.2\n    cb = fig.colorbar(pc, ax=ax, fraction=0.5)\n    assert cb.ax.get_position().height == 0.5\n    cb = fig.colorbar(pc, ax=ax, fraction=0.8)\n    assert cb.ax.get_position().height == 0.8\n"], "sample_848": ["def test_multi_output_classification_partial_fit_with_weights():\n    # weighted classifier\n    Xw = [[1, 2, 3], [4, 5, 6], [1.5, 2.5, 3.5]]\n    yw = [[3, 2], [2, 3], [3, 2]]\n    w = np.asarray([2., 1., 1.])\n    sgd_linear_clf = SGDClassifier(random_state=1, max_iter=20)\n    clf_w = MultiOutputClassifier(sgd_linear_clf)\n    clf_w.partial_fit(Xw[:2], yw[:2], w[:2])\n    clf_w.partial_fit(Xw[2:], yw[2:], w[2:])\n    # unweighted, but with repeated samples\n    X = [[1, 2, 3], [1, 2, 3], [4, 5, 6], [1.5, 2.5, 3.5]]\n    y = [[3, 2], [3, 2], [2, 3], [3, 2]]\n    sgd_linear_clf = SGDClassifier(random_state=1, max_iter=20)\n    clf = MultiOutputClassifier(sgd_linear_clf)\n    clf.fit(X, y)\n    X_test = [[1.5, 2.5, 3.5]]\n    assert_array_almost_equal(clf.predict(X_test), clf_w.predict(X_test))\n"], "sample_776": ["def test_lars_path_with_precompute():\n    # Test the lars_path function with precompute=True\n    X = diabetes.data\n    y = diabetes.target\n    alphas, _, coefs = linear_model.lars_path(X, y, method='lasso',\n                                             precompute=True)\n    assert coefs.shape[0] == len(alphas)\n    assert coefs.shape[1] == X.shape[1]\n"], "sample_852": ["def test_make_classification_weights_array_or_list_ok_with_n_classes():\n    for weights_type in ([.1, .9], np.array([.1, .9]), [0.1, 0.9]):\n        for n_classes in [2, 3, 4]:\n            X1, y1 = make_classification(weights=weights_type,\n                n_classes=n_classes, random_state=0)\n            X2, y2 = make_classification(weights=weights_type,\n                n_classes=n_classes, random_state=0)\n            assert_almost_equal(X1, X2)\n            assert_almost_equal(y1, y2)\n"], "sample_386": ["    def test_mark_safe_with_unicode_characters(self):\n        \"\"\"\n        Test that mark_safe handles unicode characters correctly.\n        \"\"\"\n        text = \"This string contains \u00e9\u00e0\u00e7\u00fc\u00f6\"\n        safe_text = mark_safe(text)\n        self.assertRenderEqual(\"{{ safe_text }}\", text, safe_text=safe_text)\n"], "sample_526": ["def test_date2num_with_tz():\n    tz = dateutil.tz.gettz('America/New_York')\n    dt = datetime.datetime(2023, 1, 1, 12, 0, tzinfo=tz)\n    assert mdates.date2num(dt) == 738949.5\n"], "sample_747": ["def test_power_transformer_y_axis():\n    X = np.abs(X_2d)\n    pt = PowerTransformer(method='box-cox', standardize=True)\n    pt.fit(X)\n\n    # Test that y_axis works as expected\n    X_trans_y_axis = pt.transform(X, y_axis=1)\n    assert X_trans_y_axis.shape == X.shape\n\n    for j in range(X_trans_y_axis.shape[1]):\n        X_expected, lmbda = stats.boxcox(X[:, j].flatten())\n        assert_almost_equal(X_trans_y_axis[:, j], X_expected)\n        assert_almost_equal(lmbda, pt.lambdas_[j])\n\n    # Test that y_axis raises an error if out of bounds\n    assert_raises_regex(ValueError, \"y_axis should be in the range [0, X.shape[1]-1]\",\n                         pt.transform, X, y_axis=X.shape[1])\n\n\n\n"], "sample_444": ["    def test_manifest_hash_with_post_processing(self):\n        # Create a file that will be post-processed.\n        with open(self._get_filename_path(\"test.css\"), \"w\") as f:\n            f.write(\"url(img/test.png)\")\n\n        # Collect static files, which will create a manifest with the initial hash.\n        self.run_collectstatic()\n\n        # Modify the file that was post-processed.\n        with open(self._get_filename_path(\"test.css\"), \"w\") as f:\n            f.write(\"url(img/test2.png)\")\n\n        # Collect static files again, which will update the manifest hash.\n        self.run_collectstatic()\n\n        # Assert that the manifest hash has changed.\n        _, manifest_hash_new = storage.staticfiles_storage.load_manifest()\n        _, manifest_hash_old = storage.staticfiles_storage.load_manifest()\n        self.assertNotEqual(manifest_hash_new, manifest_hash_old)\n\n        # Assert that the file is now using the updated hashed name.\n        relpath = self.hashed_file_path(\"cached/test.css\")\n        with storage.staticfiles_storage.open(relpath) as relfile:\n            content = relfile.read()\n            self.assertIn(b\"img/test2.png\", content)\n"], "sample_1159": ["def test_issue_18050():\n    x = Symbol('x', real=True, nonzero=True)\n    assert (x**2).is_positive is True\n    assert (x**2).is_nonnegative is True\n    assert (x**2).is_nonpositive is False\n    assert (x**2).is_negative is False\n    assert (x**2).is_zero is False\n    assert (x**2).is_integer is None\n    assert (x**2).is_rational is None\n    assert (x**2).is_real is True\n"], "sample_414": ["    def test_clear_button(self):\n        from selenium.webdriver.common.by import By\n\n        self.admin_login(username=\"super\", password=\"secret\", login_url=\"/\")\n        self.selenium.get(\n            self.live_server_url + reverse(\"admin:admin_widgets_event_add\")\n        )\n        main_window = self.selenium.current_window_handle\n\n        # Select a band\n        self.selenium.find_element(By.ID, \"lookup_id_main_band\").click()\n        self.wait_for_and_switch_to_popup()\n        link = self.selenium.find_element(By.LINK_TEXT, \"Bogey Blues\")\n        self.assertIn(\"/band/42/\", link.get_attribute(\"href\"))\n        link.click()\n\n        # The field now contains the selected band's id\n        self.selenium.switch_to.window(main_window)\n        self.wait_for_value(\"#id_main_band\", \"42\")\n\n        # Click the clear button\n        clear_button = self.selenium.find_element(By.ID, \"clear_id_main_band\")\n        clear_button.click()\n\n        # The field is now empty\n        self.assertEqual(\n            self.selenium.find_element(By.ID, \"id_main_band\").get_attribute(\"value\"), \"\"\n        )\n"], "sample_664": ["compilation error"], "sample_39": ["def test_wcs_from_header_with_invalid_ctype():\n    \"\"\"\n    Test handling of invalid CTYPE keywords in the header.\n    \"\"\"\n    invalid_header = \"\"\""], "sample_54": ["    def test_file_response_with_custom_content_type(self):\n        with tempfile.NamedTemporaryFile() as tmp:\n            tmp.write(b'some content')\n            tmp.flush()\n            response = FileResponse(tmp, content_type='text/plain; charset=utf-8')\n        self.assertEqual(response['Content-Type'], 'text/plain; charset=utf-8')\n        self.assertEqual(list(response), [b'some content'])\n"], "sample_46": ["    def test_uuid_pk_ordering(self):\n        u1 = PrimaryKeyUUIDModel.objects.create()\n        u2 = PrimaryKeyUUIDModel.objects.create()\n        u3 = PrimaryKeyUUIDModel.objects.create()\n        qs = PrimaryKeyUUIDModel.objects.all().order_by('pk')\n        self.assertEqual(list(qs), [u1, u2, u3])\n"], "sample_179": ["    def test_deferrable_unique_constraint_required_db_features(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                required_db_features = {'supports_deferrable_unique_constraints'}\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_deferrable',\n                        deferrable=models.Deferrable.DEFERRED,\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n"], "sample_35": ["def test_minversion():\n    assert minversion('astropy', '0.4.4')\n    assert minversion('astropy', '0.12')\n    assert not minversion('astropy', '0.13')\n    assert minversion('astropy', '0.12.0', inclusive=False)\n    assert minversion('astropy', '0.12.1', inclusive=False)\n    assert not minversion('astropy', '0.11.9', inclusive=False)\n    assert minversion('astropy', '0.12.0', version_path='__version_path')\n    with pytest.raises(ImportError):\n        minversion('nonexistent_module', '0.12')\n"], "sample_422": ["    def test_m2m_forward_with_limit(self):\n        authors = Author.objects.all()\n        with self.assertNumQueries(3):\n            books = list(\n                Book.objects.prefetch_related(\n                    Prefetch(\n                        \"authors\",\n                        authors[:2],\n                    ),\n                )\n            )\n        for book in books:\n            with self.subTest(book=book):\n                self.assertEqual(len(book.authors.all()), 2)\n"], "sample_1067": ["def test_issue_6103():\n    x = Symbol('x')\n    a = Wild('a')\n    assert (-I*x*oo).match(I*a*oo) == {a: -x}\n"], "sample_1140": ["def test_issue_18374():\n    from sympy.physics.quantum import TensorProduct\n    a = Symbol('a')\n    b = Symbol('b')\n    c = Symbol('c')\n    psi = TensorProduct(a, b)\n    assert pretty(psi) == 'a \u2297 b'\n    assert upretty(psi) == 'a \u2297 b'\n"], "sample_438": ["    def test_get_object_cache_respects_deleted_objects_with_related_fields(self):\n        question = Question.objects.create(text=\"Who?\")\n        answer = Answer.objects.create(text=\"Answer\", question=question)\n        post = Post.objects.create(title=\"Answer\", parent=question)\n\n        question_pk = question.pk\n        Question.objects.all().delete()\n\n        with self.assertRaises(ObjectDoesNotExist):\n            post.parent  # Should raise an exception since the parent question is deleted\n\n        with self.assertRaises(ObjectDoesNotExist):\n            answer.question  # Should raise an exception since the related question is deleted\n\n\n\n"], "sample_549": ["compilation error"], "sample_262": ["    def test_keep_lazy(self):\n        @keep_lazy(str)\n            return a + b\n\n        self.assertEqual(my_func('hello', 'world'), 'helloworld')\n        self.assertEqual(my_func(lazy(lambda: 'hello'), 'world'), 'helloworld')\n        self.assertEqual(my_func('hello', lazy(lambda: 'world')), 'helloworld')\n        self.assertEqual(my_func(lazy(lambda: 'hello'), lazy(lambda: 'world')), 'helloworld')\n\n        @keep_lazy_text\n            return a + b\n\n        self.assertEqual(my_func_text('hello', 'world'), 'helloworld')\n        self.assertEqual(my_func_text(lazystr('hello'), 'world'), 'helloworld')\n        self.assertEqual(my_func_text('hello', lazystr('world')), 'helloworld')\n        self.assertEqual(my_func_text(lazystr('hello'), lazystr('world')), 'helloworld')\n"], "sample_912": ["def test_module_index_with_options(app):\n    text = (\".. py:module:: docutils\\n\"\n            \"   :platform: any\\n\"\n            \".. py:module:: sphinx\\n\"\n            \"   :platform: linux\\n\"\n            \".. py:module:: sphinx.config\\n\"\n            \"   :platform: windows\\n\")\n    restructuredtext.parse(app, text)\n    index = PythonModuleIndex(app.env.get_domain('py'))\n    assert index.generate() == (\n        [('d', [IndexEntry('docutils', 0, 'index', 'module-docutils', 'any', '', '')]),\n         ('s', [IndexEntry('sphinx', 1, 'index', 'module-sphinx', 'linux', '', ''),\n                IndexEntry('sphinx.config', 2, 'index', 'module-sphinx.config', 'windows', '', '')])],\n        False\n    )\n"], "sample_902": ["def test_pipeline_memory_with_fit_transform():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        memory = Memory(cachedir=cachedir, verbose=10)\n        # Test with Transformer + SVC\n        clf = SVC(probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', clone(transf)), ('svc', clf)])\n        cached_pipe = Pipeline([('transf', transf), ('svc', clf)],\n                               memory=memory)\n\n        # Memoize the transformer at the first fit_transform\n        cached_pipe.fit_transform(X, y)\n        pipe.fit_transform(X, y)\n        # Get the time stamp of the transformer in the cached pipeline\n        ts = cached_pipe.named_steps['transf'].timestamp_\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert_false(hasattr(transf, 'means_'))\n        # Check that we are reading the cache while fitting\n        # a second time\n        cached_pipe.fit_transform(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        "], "sample_564": ["def test_text_3d_rotation(fig_test, fig_ref):\n    ax = fig_ref.add_subplot(projection=\"3d\")\n    txt = Text(0.5, 0.5, r'Foo bar $\\int$', rotation=(30, 45))\n    art3d.text_2d_to_3d(txt, z=1)\n    ax.add_artist(txt)\n\n    ax = fig_test.add_subplot(projection=\"3d\")\n    t3d = art3d.Text3D(0.5, 0.5, 1, r'Foo bar $\\int$', rotation=(30, 45))\n    ax.add_artist(t3d)\n"], "sample_1133": ["    def test_refraction_angle_with_plane():\n        n1, n2 = symbols('n1, n2')\n        r1 = Ray3D(Point3D(-1, -1, 1), Point3D(0, 0, 0))\n        n = Matrix([0, 0, 1])\n        P = Plane(Point3D(0, 0, 0), normal_vector=[0, 0, 1])\n        assert refraction_angle(r1, 1, 1.33, plane=P) == \\\n            Ray3D(Point3D(0, 0, 0), Point3D(1, 1, -1))\n        assert refraction_angle(r1, 1.33, 1, plane=P) == \\\n            Ray3D(Point3D(0, 0, 0), Point3D(1, 1, -1))\n        assert refraction_angle(r1, 1, 1.33, plane=P).direction_ratio == [1, 1, -1]\n        assert refraction_angle(r1, 1.33, 1, plane=P).direction_ratio == [1, 1, -1]\n"], "sample_1119": ["def test_jordan_form():\n    from sympy.matrices.jordan_form import jordan_block\n    from sympy.matrices.densematrix import DenseMatrix\n\n    A = Matrix([[1, 1], [0, 1]])\n    J, P = A.jordan_form()\n    assert J.is_diagonal()\n    assert P.is_invertible()\n    assert (P * J * P.inv()).equals(A)\n\n    B = Matrix([[2, 1], [1, 2]])\n    J, P = B.jordan_form()\n    assert J.is_diagonal()\n    assert P.is_invertible()\n    assert (P * J * P.inv()).equals(B)\n\n    C = jordan_block(2, 3)\n    assert C.is_jordan_block()\n    assert C.shape == (2, 2)\n\n    D = jordan_block(3, 1)\n    assert D.is_jordan_block()\n    assert D.shape == (3, 3)\n\n    E = Matrix([[1, 0, 0], [0, 2, 0], [0, 0, 3]])\n    J, P = E.jordan_form()\n    assert J.is_diagonal()\n    assert P.is_invertible()\n    assert (P * J * P.inv()).equals(E)\n\n    F = Matrix([[1, 1, 0], [0, 2, 1], [0, 0, 3]])\n    J, P = F.jordan_form()\n    assert J.is_diagonal()\n    assert P.is_invertible()\n    assert (P * J * P.inv()).equals(F)\n\n    G = Matrix([[1, 1, 0], [0, 2, 0], [0, 0, 2]])\n    J, P = G.jordan_form()\n    assert J.is_diagonal()\n    assert P.is_invertible()\n    assert (P * J * P.inv()).equals(G)\n\n\n\n"], "sample_53": ["    def test_render_options_with_language(self):\n        with translation.override('es-ES'):\n            beatles = Band.objects.create(name='Los Beatles', style='rock')\n            who = Band.objects.create(name='The Who', style='rock')\n            form = AlbumForm(initial={'band': beatles.pk})\n            output = form.as_table()\n            selected_option = '<option value=\"%s\" selected>Los Beatles</option>' % beatles.pk\n            option = '<option value=\"%s\">The Who</option>' % who.pk\n            self.assertIn(selected_option, output)\n            self.assertNotIn(option, output)\n"], "sample_477": ["    def test_random03(self):\n        output = self.engine.render_to_string(\n            \"random03\", {\"a\": [\"a&b\", \"a&b\"], \"b\": [mark_safe(\"a&b\"), mark_safe(\"a&b\")]}\n        )\n        self.assertEqual(output, \"a&b a&b\")\n"], "sample_325": ["    def test_renderer_overrides_default(self):\n        custom = CustomRenderer()\n        form = Form(renderer=custom)\n        self.assertEqual(form.renderer, custom)\n"], "sample_457": ["    def test_expressions_with_include(self):\n        msg = (\n            \"UniqueConstraint.include cannot be used with expressions. \"\n            \"Use django.contrib.postgres.indexes.OpClass() instead.\"\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            models.UniqueConstraint(\n                Lower(\"field\"),\n                name=\"test_func_include\",\n                include=[\"other_field\"],\n            )\n"], "sample_463": ["    def test_operation_with_custom_name(self):\n        class Migration(migrations.Migration):\n            operations = [\n                migrations.CreateModel(\n                    \"Person\", fields=[], name=\"my_person_model\"\n                )\n            ]\n\n        migration = Migration(\"some_migration\", \"test_app\")\n        self.assertEqual(migration.suggest_name(), \"my_person_model\")\n"], "sample_1116": ["def test_derivative_matrix_lines():\n    A = MatrixSymbol('A', 2, 2)\n    x = symbols('x')\n    lines = A.I._eval_derivative_matrix_lines(x)\n    assert len(lines) == 4\n    for line in lines:\n        assert isinstance(line.first_pointer, Inverse)\n        assert isinstance(line.second_pointer, MatPow)\n"], "sample_644": ["    def test_import_as_rename(self) -> None:\n        module = astroid.MANAGER.ast_from_module_name(\"import_as_rename\", REGR_DATA)\n        import_from = module.body[0]\n\n        msg = MessageTest(\n            msg_id=\"useless-import-alias\",\n            node=import_from.names[0][0],\n            confidence=UNDEFINED,\n            line=1,\n            col_offset=10,\n            end_line=1,\n            end_col_offset=19,\n        )\n        with self.assertAddsMessages(msg):\n            self.checker.visit_importfrom(import_from)\n\n        msg = MessageTest(\n            msg_id=\"consider-using-from-import\",\n            node=import_from.names[1][0],\n            args=(\"my_package\", \"my_module\"),\n            confidence=UNDEFINED,\n            line=2,\n            col_offset=10,\n            end_line=2,\n            end_col_offset=26,\n        )\n        with self.assertAddsMessages(msg):\n            self.checker.visit_importfrom(import_from)\n"], "sample_190": ["    def test_exact_query_rhs_with_selected_columns_multiple_values(self):\n        newest_author1 = Author.objects.create(name='Author 2')\n        newest_author2 = Author.objects.create(name='Author 3')\n        authors_max_ids = Author.objects.filter(\n            name__in=['Author 2', 'Author 3'],\n        ).values(\n            'name',\n        ).annotate(\n            max_id=Max('id'),\n        ).values('max_id')\n        authors = Author.objects.filter(id__in=authors_max_ids)\n        self.assertEqual(set(authors.values_list('name', flat=True)), {'Author 2', 'Author 3'})\n"], "sample_1094": ["def test_rewrite_with_undefined_functions():\n    from sympy.core.function import UndefinedFunction as UndefFunc\n\n    x = symbols('x')\n    f = UndefFunc('f')\n    g = UndefFunc('g')\n\n    assert f(x).rewrite(g) == f(x)\n    assert f(x).rewrite([g]) == f(x)\n    assert f(x).rewrite(g, exp).rewrite(exp, sin) == f(x)\n    assert f(x).rewrite(g, sin).rewrite(sin, exp) == f(x)\n"], "sample_529": ["def test_legend_handles_with_custom_artists():\n    fig, ax = plt.subplots()\n    ax.plot([0, 1], [0, 1], label='line')\n    custom_artist = mpl.patches.Circle((0.5, 0.5), 0.2, color='red')\n    ax.add_artist(custom_artist)\n    handles = [mlines.Line2D([0], [0], label='line'), custom_artist]\n    leg = ax.legend(handles)\n    assert len(leg.legend_handles) == 2\n    assert isinstance(leg.legend_handles[0], mlines.Line2D)\n    assert isinstance(leg.legend_handles[1], mpl.patches.Circle)\n"], "sample_749": ["def test_column_transformer_sparse_remainder_transformer_with_weights():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                           ('trans2', SparseMatrixTrans(), [1])],\n                           remainder=SparseMatrixTrans(),\n                           transformer_weights={'trans1': 0.5, 'trans2': 0.5})\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n\n    #  SparseMatrixTrans creates 3 features for each column, thus:\n    assert X_trans.shape == (3, 3 + 1)\n\n    # weights should be applied correctly\n    exp_array = 0.5 * np.hstack(\n        (X_array[:, 0].reshape(-1, 1), np.eye(3))) + 0.5 * np.hstack(\n            (np.zeros((3, 1)), np.eye(3)))\n    assert_array_equal(X_trans.toarray(), exp_array)\n    assert len(ct.transformers_) == 3\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], SparseMatrixTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n"], "sample_687": ["def test_log_file_path(testdir, caplog):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n            caplog.set_level(logging.INFO)\n            logging.info(\"This message should be written to the log file\")\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file = test.log\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*This message should be written to the log file*\"])\n    assert os.path.exists(\"test.log\")\n    with open(\"test.log\", \"r\") as f:\n        assert f.read().strip() == \"This message should be written to the log file\"\n    os.remove(\"test.log\")\n"], "sample_700": ["compilation error"], "sample_430": ["    def test_operation_with_custom_name(self):\n        class Migration(migrations.Migration):\n            operations = [\n                migrations.CreateModel(\n                    \"Person\", fields=[], name=\"my_person\"\n                ),\n            ]\n\n        migration = Migration(\"some_migration\", \"test_app\")\n        self.assertEqual(migration.suggest_name(), \"my_person\")\n"], "sample_821": ["def test_affinity_propagation_sparse_data():\n    # Test AffinityPropagation with sparse data\n    X_sparse = csr_matrix(np.random.rand(100, 10))\n    af = AffinityPropagation(affinity='euclidean', copy=False)\n    af.fit(X_sparse)\n    assert_array_equal(af.cluster_centers_indices_, np.array(\n        [i for i in range(af.n_iter_)], dtype=int))\n    assert_array_equal(af.labels_, np.array(\n        [i for i in range(af.n_iter_)], dtype=int))\n"], "sample_55": ["    def test_get_formsets_with_inlines_argument(self):\n        response = self.client.get(reverse('admin:admin_views_getformsetswithinlines_add'))\n        self.assertIsNone(response.context['obj'])\n\n        response = self.client.get(reverse('admin:admin_views_getformsetswithinlines_change', args=(1,)))\n        self.assertIsNotNone(response.context['obj'])\n"], "sample_115": ["    def test_sensitive_variables_decorator_with_args(self):\n        @sensitive_variables(exclude=['cooked_eggs'])\n            return password, cooked_eggs\n\n        with self.settings(DEBUG=True):\n            response = self.client.post('/some_url/', {'password': 'secret', 'cooked_eggs': 'scrambled'})\n            self.assertContains(response, 'secret', status_code=500)\n            self.assertContains(response, 'scrambled', status_code=500)\n"], "sample_970": ["compilation error"], "sample_211": ["    def test_object_list_is_empty(self):\n        test_view = views.CustomMultipleObjectMixinView()\n        test_view.queryset = []\n        context = test_view.get_context_data()\n        self.assertEqual(context['object_list'], [])\n"], "sample_760": ["def test_scorer_with_invalid_sample_weight():\n    # Test that scorers raise an error when given invalid sample_weight\n    X, y = make_blobs(random_state=0)\n    estimator = _make_estimators(X, y)\n    for name, scorer in SCORERS.items():\n        with pytest.raises(ValueError, match=\"sample_weight should be a 1D array\"):\n            scorer(estimator[name], X, y, sample_weight=np.array([[1, 2]]))\n        with pytest.raises(ValueError, match=\"sample_weight should have the same length as y\"):\n            scorer(estimator[name], X, y, sample_weight=np.ones(len(X) + 1))\n        with pytest.raises(ValueError, match=\"sample_weight should be non-negative\"):\n            scorer(estimator[name], X, y, sample_weight=np.array([-1, 1]))\n"], "sample_742": ["def test_class_weight_with_sparse_data():\n    # Test that class_weight works correctly with sparse data\n    rng = np.random.RandomState(42)\n    n_samples = 50\n    n_features = 20\n    X, y = make_classification(n_samples=n_samples, n_features=n_features,\n                               random_state=0)\n    X_sparse = sparse.csr_matrix(X)\n    class_weight = {0: 1, 1: 5}\n\n    lr_sparse = LogisticRegression(class_weight=class_weight)\n    lr_sparse.fit(X_sparse, y)\n\n    lr_dense = LogisticRegression(class_weight=class_weight)\n    lr_dense.fit(X, y)\n\n    assert_array_almost_equal(lr_sparse.coef_, lr_dense.coef_)\n"], "sample_928": ["def test_heading():\n    env = Environment()\n    assert heading(env, 'Hello', 1) == 'Hello\\n===='\n    assert heading(env, 'Hello', 2) == 'Hello\\n---'\n    assert heading(env, 'Hello', 3) == 'Hello\\n~~'\n"], "sample_936": ["def test_stringify_type_hints_ForwardRef():\n    from typing import ForwardRef\n\n    class MyClass:\n        pass\n\n    MyClassRef = ForwardRef('MyClass')\n\n    assert stringify(MyClassRef) == 'MyClass'\n"], "sample_341": ["    def test_invalid(self):\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '0',\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': '',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '1',\n        }\n        ChoiceFormSet = formset_factory(Choice)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [{'votes': ['This field is required.']}, {}]\n        self.assertEqual(formset1._errors, expected_errors)\n        self.assertEqual(formset2._errors, expected_errors)\n"], "sample_984": ["def test_Piecewise():\n    from sympy import Piecewise, symbols\n    x = symbols('x')\n    p = Piecewise((x**2, x < 0), (x, x >= 0))\n    assert str(p) == \"Piecewise((x**2, x < 0), (x, x >= 0))\"\n"], "sample_230": ["    def test_invalid_json_input(self):\n        field = JSONField()\n        with self.assertRaisesMessage(ValidationError, 'Enter a valid JSON.'):\n            field.clean('{\"a\": \"b\"')\n        with self.assertRaisesMessage(ValidationError, 'Enter a valid JSON.'):\n            field.clean('{\"a\": b}')\n\n\n\n"], "sample_1002": ["def test_issue_10703():\n    assert Float(1.234567890123456789012345678901234567890123456789, 50) == Float(1.234567890123456789012345678901234567890123456789, 50)\n"], "sample_969": ["def test_stringify_type_hints_Annotated_with_args():\n    from typing import Annotated  # type: ignore\n    assert stringify(Annotated[str, \"foo\", \"bar\"], False) == \"Annotated[str, 'foo', 'bar']\"\n    assert stringify(Annotated[str, \"foo\", \"bar\"], True) == \"~typing.Annotated[str, 'foo', 'bar']\"\n"], "sample_240": ["    def test_token_with_different_user(self):\n        user1 = User.objects.create_user('user1', 'user1@example.com', 'password')\n        user2 = User.objects.create_user('user2', 'user2@example.com', 'password')\n        p0 = PasswordResetTokenGenerator()\n        tk1 = p0.make_token(user1)\n        self.assertIs(p0.check_token(user2, tk1), False)\n"], "sample_528": ["def test_reload_library():\n    original_library = style.library.copy()\n    with temp_style('test', DUMMY_SETTINGS):\n        assert 'test' in style.library\n    style.reload_library()\n    assert style.library == original_library\n"], "sample_806": ["def test_gradient_boosting_with_init_loss(loss):\n    # Check that GradientBoostingClassifier works when init is a sklearn\n    # estimator and loss is specified.\n    X, y = make_classification(random_state=0)\n    init_est = DummyClassifier(strategy='most_frequent')\n    gb = GradientBoostingClassifier(loss=loss, init=init_est)\n    gb.fit(X, y)\n"], "sample_8": ["    def test_masked_array_from_masked_array(self):\n        \"\"\"Check that we can initialize a MaskedArray from a MaskedArray.\"\"\"\n        np_ma = np.ma.MaskedArray(self.ma)\n        masked_array = Masked(np_ma)\n        assert type(masked_array) is Masked\n        assert_array_equal(masked_array.unmasked, self.a)\n        assert_array_equal(masked_array.mask, self.mask_a)\n"], "sample_263": ["    def test_circular_reference_with_m2m(self):\n        management.call_command('loaddata', 'circular_reference_m2m.json', verbosity=0)\n        obj_a = CircularA.objects.get()\n        obj_b = CircularB.objects.get()\n        self.assertEqual(obj_a.other_things.count(), 1)\n        self.assertIn(obj_b, obj_a.other_things.all())\n        self.assertEqual(obj_b.other_things.count(), 1)\n        self.assertIn(obj_a, obj_b.other_things.all())\n        self._dumpdata_assert(\n            ['fixtures'],\n            '[{\"model\": \"fixtures.circulara\", \"pk\": 1, '\n            '\"fields\": {\"key\": \"x\", \"other_things\": [1]}}, '\n            '{\"model\": \"fixtures.circularb\", \"pk\": 1, '\n            '\"fields\": {\"key\": \"y\", \"other_things\": [1]}}]',\n            natural_primary_keys=True,\n            natural_foreign_keys=True,\n        )\n"], "sample_916": ["    def check_xref_consistency(role, tag, expected_classes):\n        classes_found = classes(role, tag)\n        assert classes_found == expected_classes, (\n            f\"Classes for role '{role}' with tag '{tag}' do not match. \"\n            f\"Found: {classes_found}, Expected: {expected_classes}\"\n        )\n"], "sample_1188": ["def test_pretty_print_vector_operations():\n    from sympy.vector import Vector, cross, dot\n\n    N = CoordSys3D('N')\n    v1 = N.i + N.j\n    v2 = N.j + N.k\n    v3 = 2*N.i - N.k\n\n    assert pretty(cross(v1, v2)) == '(-1) i_N + (1) k_N'\n    assert pretty(dot(v1, v2)) == '1'\n    assert pretty(dot(v1, v3)) == '2'\n    assert pretty(cross(v1, v3)) == '(-2) i_N + (1) j_N + (1) k_N'\n"], "sample_15": ["        def test_jv_invalid_units(self, function):\n            with pytest.raises(u.UnitsError):\n                function(1.0 * u.m, 2.0 * u.s)\n"], "sample_947": ["def test_cmacro(app):\n    text = \".. c:macro:: MY_MACRO(a, b)\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1], addnodes.desc, desctype=\"macro\",\n                domain=\"c\", objtype=\"macro\", noindex=False)\n\n    entry = _get_obj(app, 'MY_MACRO')\n    assert entry == ('index', 'c.MY_MACRO', 'macro')\n"], "sample_518": ["def test_default_joinstyle():\n    patch = Patch()\n    assert patch.get_joinstyle() == 'miter'\n"], "sample_385": ["    def test_render_options_with_language_code(self):\n        with translation.override(\"fr\"):\n            beatles = Band.objects.create(name=\"The Beatles\", style=\"rock\")\n            form = AlbumForm()\n            output = form.as_table()\n            self.assertIn(\n                '<option value=\"%s\" selected>The Beatles</option>' % beatles.uuid,\n                output,\n            )\n"], "sample_149": ["    def test_builtin_permission_name_length(self):\n        class Checked(models.Model):\n            class Meta:\n                permissions = [\n                    ('change_checked', 'Can edit permission'),\n                ]\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [])\n"], "sample_908": ["    def test_unparse_arguments():\n        source = \"\"\"\n            pass\n        \"\"\"\n        module = ast.parse(source)\n        args = module.body[0].args\n        assert ast.unparse_arguments(args) == \"a, b=1, *args, c, **kwargs\"\n"], "sample_1035": ["def test_apply_grover():\n    numqubits = 3\n    basis_states = superposition_basis(numqubits)\n    v = OracleGate(numqubits, lambda qubits: qubits == IntQubit(4, nqubits=numqubits))\n    expected = IntQubit(4, nqubits=numqubits)\n    result = apply_grover(basis_states, v)\n    assert qapply(result) == expected\n"], "sample_779": ["def test_check_estimator_sparse_matrix_handling():\n    # check that estimators handle sparse matrices correctly\n    from sklearn.datasets import make_sparse_matrix\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.svm import SVC\n    from sklearn.neighbors import KNeighborsClassifier\n    from sklearn.ensemble import RandomForestClassifier\n    from sklearn.decomposition import PCA\n\n    for Estimator in [LogisticRegression, SVC, KNeighborsClassifier,\n                      RandomForestClassifier, PCA]:\n        X, y = make_sparse_matrix(100, 10, density=0.1)\n        est = Estimator()\n        set_checking_parameters(est)\n        set_random_state(est)\n        est.fit(X, y)\n        # check that the fit method doesn't raise any errors\n        # and that the estimator can predict on the same sparse matrix\n        est.predict(X)\n"], "sample_365": ["    def test_keep_lazy(self):\n            return a + b\n\n        @keep_lazy(int)\n            return a + b\n\n        self.assertEqual(my_func(1, 2), lazy_func(1, 2))\n        self.assertEqual(my_func(1, 2), lazy_func(lazy(lambda: 1, int), 2))\n        self.assertEqual(my_func(1, lazy(lambda: 2, int)), lazy_func(1, lazy(lambda: 2, int)))\n        self.assertEqual(my_func(lazy(lambda: 1, int), lazy(lambda: 2, int)), lazy_func(lazy(lambda: 1, int), lazy(lambda: 2, int)))\n\n        with self.assertRaises(TypeError):\n            keep_lazy()(1, 2)\n"], "sample_890": ["def test_custom_scoring(direction):\n    X, y = make_classification(n_samples=100, n_features=10, random_state=0)\n    sfs = SequentialFeatureSelector(\n        KNeighborsClassifier(),\n        n_features_to_select=\"auto\",\n        direction=direction,\n        scoring=\"accuracy\",\n        cv=2,\n    )\n    sfs.fit(X, y)\n    assert sfs.transform(X).shape[1] <= X.shape[1]\n\n\n\n"], "sample_66": ["    def test_case_insensitive(self):\n        environ = {\n            'CONTENT_TYPE': 'text/html',\n            'CONTENT_LENGTH': '100',\n            'HTTP_HOST': 'example.com',\n            'HTTP_USER_AGENT': 'python-requests/1.2.0',\n        }\n        headers = HttpHeaders(environ)\n        self.assertEqual(headers['user-agent'], 'python-requests/1.2.0')\n        self.assertEqual(headers['User-Agent'], 'python-requests/1.2.0')\n        self.assertEqual(headers['content-type'], 'text/html')\n        self.assertEqual(headers['Content-Length'], '100')\n"], "sample_402": ["    def test_etag_not_modified_gzip_response(self):\n        \"\"\"\n        GZipMiddleware allows 304 Not Modified responses even when the response\n        is already gzipped.\n        \"\"\"\n\n            response = HttpResponse(self.compressible_string)\n            response.headers[\"ETag\"] = '\"eggs\"'\n            response.headers[\"Content-Encoding\"] = \"gzip\"\n            return response\n\n        request = self.rf.get(\"/\", HTTP_ACCEPT_ENCODING=\"gzip, deflate\")\n        response = GZipMiddleware(get_response)(request)\n        gzip_etag = response.headers[\"ETag\"]\n        next_request = self.rf.get(\n            \"/\", HTTP_ACCEPT_ENCODING=\"gzip, deflate\", HTTP_IF_NONE_MATCH=gzip_etag\n        )\n        next_response = GZipMiddleware(get_response)(next_request)\n        self.assertEqual(next_response.status_code, 304)\n"], "sample_595": ["def test_isnumeric_unicode():\n    values = xr.DataArray([\"A\", \"3\", \"\u00bc\", \"\u2605\", \"\u1378\", \"\uff13\", \"four\"])\n    numeric_e = [False, True, False, False, True, True, False]\n    assert_equal(values.str.isnumeric(), xr.DataArray(numeric_e))\n\n\n"], "sample_918": ["    def test_pyfunction_signature_full_py38(app):\n        # case: separator at head\n        text = \".. py:function:: hello(*, a)\"\n        doctree = restructuredtext.parse(app, text)\n        assert_node(doctree[1][0][1],\n                    [desc_parameterlist, ([desc_parameter, desc_sig_operator, \"*\"],\n                    [desc_parameter, desc_sig_name, \"a\"])])\n\n        # case: separator in the middle\n        text = \".. py:function:: hello(a, /, b, *, c)\"\n        doctree = restructuredtext.parse(app, text)\n        assert_node(doctree[1][0][1],\n                    [desc_parameterlist, ([desc_parameter, desc_sig_name, \"a\"],\n                    [desc_parameter, desc_sig_operator, \"/\"],\n                    [desc_parameter, desc_sig_name, \"b\"],\n                    [desc_parameter, desc_sig_operator, \"*\"],\n                    [desc_parameter, desc_sig_name, \"c\"])])\n\n        # case: separator in the middle (2)\n        text = \".. py:function:: hello(a, /, *, b)\"\n        doctree = restructuredtext.parse(app, text)\n        assert_node(doctree[1][0][1],\n                    [desc_parameterlist, ([desc_parameter, desc_sig_name, \"a\"],\n                    [desc_parameter, desc_sig_operator, \"/\"],\n                    [desc_parameter, desc_sig_operator, \"*\"],\n                    [desc_parameter, desc_sig_name, \"b\"])])\n\n        # case: separator at tail\n        text = \".. py:function:: hello(a, /)\"\n        doctree = restructuredtext.parse(app, text)\n        assert_node(doctree[1][0][1],\n                    [desc_parameterlist, ([desc_parameter, desc_sig_name, \"a\"],\n                    [desc_parameter, desc_sig_operator,"], "sample_223": ["    def test_ticket_24605_subquery_ordering(self):\n        \"\"\"\n        Subqueries should be ordered correctly.\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        # Test ordering with subquery\n        self.assertSequenceEqual(\n            Individual.objects.filter(\n                Q(alive=True),\n                Q(related_individual__related__pk__in=Individual.objects.filter(alive=False).order_by('pk').values_list('pk', flat=True))\n            ).order_by('pk'),\n            [i1]\n        )\n"], "sample_1199": ["def test_tensor_product_trace():\n    assert Tr(TP(A, B)) == Tr(A) * Tr(B)\n    assert Tr(TP(A, TP(B, C))) == Tr(A) * Tr(B) * Tr(C)\n    assert Tr(TP(A, B)*TP(C, D)) == Tr(A*C) * Tr(B*D)\n"], "sample_157": ["    def test_clone_test_db(self, mocked_migrate, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            creation.clone_test_db('suffix_1', verbosity=0, autoclobber=True)\n            cloned_settings = creation.get_test_db_clone_settings('suffix_1')\n            self.assertEqual(cloned_settings['NAME'], old_database_name + '_suffix_1')\n            mocked_migrate.assert_called_once()\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n"], "sample_988": ["def test_issue_14187():\n    x = symbols('x')\n    y = symbols('y')\n    assert (x > y).subs(x, y) == S.false\n    assert (x < y).subs(x, y) == S.false\n    assert (x >= y).subs(x, y) == S.true\n    assert (x <= y).subs(x, y) == S.true\n    assert (x == y).subs(x, y) == S.true\n    assert (x != y).subs(x, y) == S.false\n"], "sample_142": ["    def test_check_for_invalid_fk_fields(self):\n        class SongAdmin(admin.ModelAdmin):\n            fields = ['album', 'invalid_fk']\n\n        errors = SongAdmin(Song, AdminSite()).check()\n        expected = [\n            checks.Error(\n                \"The value of 'fields[1]' is not a callable, an attribute \"\n                \"of 'SongAdmin', or an attribute of 'admin_checks.Song'.\",\n                obj=SongAdmin,\n                id='admin.E002',\n            )\n        ]\n        self.assertEqual(errors, expected)\n"], "sample_914": ["    def test_unparse_function_definition(source, expected):\n        module = ast.parse(source)\n        assert ast.unparse(module.body[0]) == expected\n"], "sample_589": ["def test_interpolate_na_method_errors(da_time):\n    with raises_regex(ValueError, \"method must be one of\"):\n        da_time.interpolate_na(\"t\", method=\"foo\")\n"], "sample_871": ["def test_silhouette_samples_with_sample_size():\n    # Test silhouette_samples with sample_size parameter\n    dataset = datasets.load_iris()\n    X = dataset.data\n    y = dataset.target\n\n    # Test with sample_size = 1\n    score_sample_size_1 = silhouette_samples(X, y, sample_size=1)\n    assert np.all(np.isnan(score_sample_size_1))\n\n    # Test with sample_size = len(X)\n    score_sample_size_all = silhouette_samples(X, y, sample_size=len(X))\n    assert np.all(score_sample_size_all == silhouette_samples(X, y))\n\n    # Test with sample_size = int(len(X) / 2)\n    score_sample_size_half = silhouette_samples(X, y, sample_size=int(len(X) / 2))\n    assert np.allclose(score_sample_size_half, silhouette_samples(X, y))\n\n    # Test with sample_size = 0\n    with pytest.raises(ValueError, match=\"sample_size must be positive\"):\n        silhouette_samples(X, y, sample_size=0)\n"], "sample_48": ["    def test_expression_on_aggregation_with_distinct(self):\n        class Greatest(Func):\n            function = 'GREATEST'\n\n                return f\"GREATEST({self.get_source_expressions()[0]}, {self.get_source_expressions()[1]})\"\n\n        qs = Book.objects.values('rating').annotate(\n            greatest_rating=Greatest('rating', F('rating') + 1)\n        ).distinct().order_by('greatest_rating')\n        self.assertEqual(list(qs), [\n            {'rating': 4, 'greatest_rating': 5},\n            {'rating': 4, 'greatest_rating': 5},\n            {'rating': 4, 'greatest_rating': 5},\n            {'rating': 5, 'greatest_rating': 6},\n        ])\n"], "sample_761": ["def test_missing_indicator_sparse_with_add_indicator():\n    X = sparse.csr_matrix([[1, 2, 3],\n                           [4, np.nan, 6],\n                           [7, 8, np.nan]])\n    mi = MissingIndicator(features='all', missing_values=np.nan, add_indicator=True)\n    X_trans = mi.fit_transform(X)\n    assert X_trans.shape[1] == X.shape[1] + 1\n    assert X_trans.getnnz() == X.getnnz() + X.shape[0]\n\n\n\n"], "sample_360": ["    def test_cache_key_with_user(self):\n        request = self.factory.get(self.path)\n        request.user = User.objects.create_user(username='testuser')\n        template = engines['django'].from_string(\"This is a test\")\n        response = TemplateResponse(request, template)\n        learn_cache_key(request, response)\n        self.assertIn('user_id', get_cache_key(request))\n"], "sample_1004": ["def test_CondSet_subs_with_dummy_symbol():\n    c = ConditionSet(x, x < 1, {x, y})\n    assert c.subs(x, y) == ConditionSet(y, y < 1, {y, z})\n    assert c.subs(x, Symbol('new_x')) == ConditionSet(Symbol('new_x'),\n                                                    Symbol('new_x') < 1,\n                                                    {Symbol('new_x'), y})\n"], "sample_640": ["def test_is_overload_stub() -> None:\n    code = astroid.extract_node(\n        \"\"\"\n    from typing import overload\n    @overload\n        ...\n    \"\"\"\n    )\n    assert utils.is_overload_stub(code[0])\n    code = astroid.extract_node(\n        \"\"\"\n        ...\n    \"\"\"\n    )\n    assert not utils.is_overload_stub(code[0])\n"], "sample_394": ["    def test_final_catch_all_view_disabled(self):\n        admin_site = AdminSite(name=\"admin10\")\n        admin_site.final_catch_all_view = None\n        with override_settings(ADMIN_SITE=admin_site):\n            unknown_url = \"/test_admin/admin10/unknown/\"\n            response = self.client.get(unknown_url)\n            self.assertEqual(response.status_code, 404)\n"], "sample_613": ["    def test_resample_with_multiple_coords(self):\n        times = pd.date_range(\"2000-01-01\", freq=\"6H\", periods=10)\n        lat = np.arange(5)\n        lon = np.arange(3)\n        ds = Dataset(\n            {\n                \"data\": ([\"time\", \"lat\", \"lon\"], np.random.randn(10, 5, 3)),\n                \"time\": times,\n                \"lat\": lat,\n                \"lon\": lon,\n            }\n        )\n        actual = ds.resample(time=\"1D\").mean()\n        expected = ds.isel(time=[0, 4, 8]).mean()\n        assert_identical(actual, expected)\n"], "sample_617": ["def test_polyval_invalid_input():\n    x = xr.DataArray([1, 2, 3], dims=\"x\")\n    coeffs = xr.DataArray([2, 3, 4], dims=\"degree\", coords={\"degree\": [0, 1, 2]})\n    with pytest.raises(TypeError):\n        xr.polyval(x, coeffs.astype(object))\n    with pytest.raises(TypeError):\n        xr.polyval(x, 1)\n    with pytest.raises(ValueError):\n        xr.polyval(x, coeffs.isel(degree=[0, 2]))\n    with pytest.raises(ValueError):\n        xr.polyval(x, coeffs.isel(degree=[0, 1, 2, 3]))\n"], "sample_707": ["def test_node_repr_failure_with_fulltrace() -> None:\n    with pytest.raises(Exception) as excinfo:\n        raise Exception(\"This is a test exception\")\n\n    item = nodes.Item(\"test_name\", session=None)\n    item.config.getoption(\"fulltrace\", False) = True\n    repr_failure = item._repr_failure_py(excinfo)\n    assert \"Traceback\" in repr_failure\n"], "sample_578": ["    def test_baseline(self, x, y):\n\n        p = Plot(x, y).add(Bars(baseline=2)).plot()\n        ax = p._figure.axes[0]\n        paths = ax.collections[0].get_paths()\n        for i, path in enumerate(paths):\n            verts = path.vertices\n            assert verts[0, 1] == pytest.approx(y[i] - 2)\n            assert verts[3, 1] == pytest.approx(y[i] - 2 + y[i])\n"], "sample_404": ["    def test_template_localtime(self):\n        engine = self._engine()\n        t = engine.from_string(\"{{ now|localtime }}\")\n        context = Context()\n        rendered = t.render(context)\n        self.assertIsInstance(rendered, str)\n"], "sample_628": ["    def test_docstring_lines_that_look_like_comments_6(self):\n        stmt = astroid.extract_node(\n            '''def f():"], "sample_532": ["def test_contour_with_masked_data():\n    x = np.arange(10)\n    y = np.arange(10)\n    X, Y = np.meshgrid(x, y)\n    Z = np.sin(X * Y)\n    mask = np.zeros_like(Z, dtype=bool)\n    mask[5, 5] = True\n    Z = np.ma.array(Z, mask=mask)\n\n    fig, ax = plt.subplots()\n    cs = ax.contour(X, Y, Z)\n    assert isinstance(cs._contour_generator, contourpy.ContourGenerator)\n"], "sample_979": ["def test_transpose_identity():\n    assert Transpose(Identity(n)).doit() == Identity(n)\n    assert Transpose(ZeroMatrix(n, m)).doit() == ZeroMatrix(m, n)\n    assert Transpose(MatMul(A, B)).doit() == MatMul(Transpose(B), Transpose(A))\n    assert Transpose(MatAdd(A, B)).doit() == MatAdd(Transpose(B), Transpose(A))\n\n\n\n"], "sample_275": ["    def test_delete_related_objects_with_prefetch_related(self):\n        \"\"\"\n        Deleting an object with prefetched related objects should delete\n        the related objects correctly.\n\n        Refs #20097.\n        \"\"\"\n        person = Person.objects.create(name='Alice')\n        award = Award.objects.create(name='Nobel', content_object=person)\n        AwardNote.objects.create(note='a peace prize', award=award)\n\n        with self.assertNumQueries(1):\n            person.delete()\n\n        self.assertEqual(Person.objects.count(), 0)\n        self.assertEqual(Award.objects.count(), 0)\n        self.assertEqual(AwardNote.objects.count(), 0)\n"], "sample_951": ["compilation error"], "sample_392": ["    def test_contains_contained_by_with_key_transform_complex(self):\n        obj = NullableJSONModel.objects.create(\n            value={\n                \"a\": {\"b\": {\"c\": \"d\"}},\n                \"e\": {\"f\": \"g\"},\n            }\n        )\n        tests = [\n            (\"value__a__b__contains\", \"d\"),\n            (\"value__a__b__contained_by\", {\"c\": \"d\"}),\n            (\"value__e__f__contains\", \"g\"),\n            (\"value__contains\", KeyTransform(\"a__b__c\", \"value\")),\n            (\"value__contains\", F(\"value__a__b__c\")),\n        ]\n        for lookup, value in tests:\n            with self.subTest(lookup=lookup, value=value):\n                self.assertIs(\n                    NullableJSONModel.objects.filter(\n                        **{lookup: value},\n                    ).exists(),\n                    True,\n                )\n"], "sample_795": ["def test_check_estimator_sparse_matrix_input():\n    # check that estimator handles sparse matrix input correctly\n    from sklearn.datasets import make_sparse_toy\n    from sklearn.linear_model import LogisticRegression\n    X, y = make_sparse_toy(n_samples=100, n_features=10, random_state=42)\n    est = LogisticRegression()\n    check_estimator(est)\n    est.fit(X, y)\n    check_estimator(est)\n"], "sample_799": ["def test_score_with_custom_scorer():\n    X, y = make_classification(n_samples=30, random_state=0)\n    clf = SVC(kernel=\"linear\", random_state=0)\n    train, test = next(ShuffleSplit().split(X))\n    clf.fit(X[train], y[train])\n\n        return np.mean(estimator.predict(X) == y)\n\n    score = _score(clf, X[test], y[test], custom_scorer)\n    assert isinstance(score, float)\n"], "sample_1109": ["def test_issue_18689():\n    assert floor(floor(floor(x)) + 3) == floor(x) + 3\n    assert ceiling(ceiling(ceiling(x)) + 1) == ceiling(x) + 1\n    assert ceiling(ceiling(floor(x)) + 3) == floor(x) + 3\n"], "sample_1137": ["def test_issue_15497():\n    from sympy.physics.units import Quantity, meter, second\n    q1 = Quantity('q1', dimension=meter/second)\n    q2 = Quantity('q2', dimension=meter/second)\n    q1.set_global_relative_scale_factor(1, meter/second)\n    q2.set_global_relative_scale_factor(2, meter/second)\n    assert (q1 + q2).convert_to(meter/second) == 3*meter/second\n"], "sample_214": ["    def test_key_transform_with_nested_lookup(self):\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(\n                value__d__0__contains=KeyTransform('f', 'value'),\n            ),\n            [self.objs[4]],\n        )\n"], "sample_1194": ["def test_julia_indexed_symbols():\n    from sympy.core import IndexedBase, Idx\n    x = IndexedBase('x')\n    i = Idx('i', 5)\n    A = IndexedBase('A')\n    assert julia_code(A[i]) == \"A[i]\"\n    assert julia_code(A[i] + x[i]) == \"A[i] + x[i]\"\n    assert julia_code(A[i] * x[i]) == \"A[i] .* x[i]\"\n    assert julia_code(A[i] / x[i]) == \"A[i] ./ x[i]\"\n    assert julia_code(A[i]**2) == \"A[i] .^ 2\"\n    assert julia_code(A[i] + x[i] + A[i + 1]) == \"A[i] + x[i] + A[i + 1]\"\n    assert julia_code(A[i:i+2]) == \"A[i:i + 1]\"\n    assert julia_code(A[i, i+1]) == \"A[i, i + 1]\"\n"], "sample_965": ["compilation error"], "sample_97": ["    def test_snapshot_files_handles_new_files(self):\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file]):\n            snapshot1 = dict(self.reloader.snapshot_files())\n            self.assertIn(self.existing_file, snapshot1)\n            new_file = self.ensure_file(self.tempdir / 'new_file.py')\n            snapshot2 = dict(self.reloader.snapshot_files())\n            self.assertIn(new_file, snapshot2)\n"], "sample_543": ["def test_polygon_selector_reset(ax, draw_bounding_box):\n    verts = [(50, 50), (150, 50), (50, 150)]\n    event_sequence = [\n        *polygon_place_vertex(*verts[0]),\n        *polygon_place_vertex(*verts[1]),\n        *polygon_place_vertex(*verts[2]),\n        *polygon_place_vertex(*verts[0]),\n    ]\n\n    tool = widgets.PolygonSelector(ax, onselect=noop, draw_bounding_box=draw_bounding_box)\n    for (etype, event_args) in event_sequence:\n        do_event(tool, etype, **event_args)\n\n    tool.reset()\n    assert tool.verts == []\n"], "sample_1206": ["def test_issue_11707():\n    assert Float('1.1') != Rational(11, 10)\n    assert Rational(11, 10) != Float('1.1')\n"], "sample_891": ["def test_label_ranking_average_precision_score_with_ties():\n    # Test that label_ranking_average_precision_score handles ties correctly.\n    y_true = np.array([[1, 0, 0], [0, 1, 1], [0, 0, 1]])\n    y_score = np.array([[0.5, 0.5, 0.5], [0.2, 0.8, 0.8], [0.1, 0.3, 0.9]])\n    result = label_ranking_average_precision_score(y_true, y_score)\n    assert result == pytest.approx(0.6666666666666666)\n"], "sample_864": ["def test_meanshift_large_bandwidth():\n    # Test MeanShift with a large bandwidth, should cluster all points\n    X, _ = make_blobs(n_samples=300, n_features=2, centers=centers,\n                      cluster_std=0.4, shuffle=True, random_state=11)\n    ms = MeanShift(bandwidth=5)\n    labels = ms.fit(X).labels_\n    assert np.all(labels == 0)\n"], "sample_408": ["    def test_operation_with_custom_name(self):\n        class Migration(migrations.Migration):\n            operations = [\n                migrations.CreateModel(\n                    \"Person\", fields=[], name=\"my_person_model\"\n                ),\n            ]\n\n        migration = Migration(\"some_migration\", \"test_app\")\n        self.assertEqual(migration.suggest_name(), \"my_person_model\")\n"], "sample_616": ["compilation error"], "sample_78": ["    def test_normalize_path_patterns(self):\n        self.assertEqual(normalize_path_patterns(['foo/bar/baz', 'baz', '*/baz']), ['foo/bar/baz', 'baz', '*/baz'])\n        self.assertEqual(normalize_path_patterns(['foo/bar/baz', 'baz', '*/baz', '**/baz']), ['foo/bar/baz', 'baz', '**/baz'])\n        self.assertEqual(normalize_path_patterns(['foo/bar/baz', 'baz', '*/baz', '*'],), ['foo/bar/baz', 'baz', '*/baz', '*'])\n        self.assertEqual(normalize_path_patterns(['foo/bar/baz', 'baz', '*/baz', '**/baz', '*']), ['foo/bar/baz', 'baz', '**/baz', '*'])\n"], "sample_829": ["def test_incremental_pca_sparse_whitening():\n    # Test that whitening works correctly with sparse input.\n    rng = np.random.RandomState(1999)\n    n_samples = 1000\n    n_features = 100\n    X = sparse.csr_matrix(rng.randn(n_samples, n_features))\n    ipca = IncrementalPCA(whiten=True, n_components=10, batch_size=100)\n    ipca.fit(X)\n    Xt = ipca.transform(X)\n    assert_almost_equal(np.sum(Xt**2, axis=1), np.ones(n_samples))\n"], "sample_1167": ["def test_unicode_characters():\n    assert latex(u'\u4f60\u597d') == r'\\text{\u4f60\u597d}'\n    assert latex(u'\u4e16\u754c') == r'\\text{\u4e16\u754c}'\n    assert latex(u'\u03c0') == r'\\pi'\n    assert latex(u'\u03b1') == r'\\alpha'\n    assert latex(u'\u03b2') == r'\\beta'\n    assert latex(u'\u03b3') == r'\\gamma'\n    assert latex(u'\u03b4') == r'\\delta'\n    assert latex(u'\u03b5') == r'\\epsilon'\n    assert latex(u'\u03b6') == r'\\zeta'\n    assert latex(u'\u03b7') == r'\\eta'\n    assert latex(u'\u03b8') == r'\\theta'\n    assert latex(u'\u03b9') == r'\\iota'\n    assert latex(u'\u03ba') == r'\\kappa'\n    assert latex(u'\u03bb') == r'\\lambda'\n    assert latex(u'\u03bc') == r'\\mu'\n    assert latex(u'\u03bd') == r'\\nu'\n    assert latex(u'\u03be') == r'\\xi'\n    assert latex(u'\u03bf') == r'\\omicron'\n    assert latex(u'\u03c0') == r'\\pi'\n    assert latex(u'\u03c1') == r'\\rho'\n    assert latex(u'\u03c3') == r'\\sigma'\n    assert latex(u'\u03c4') == r'\\tau'\n    assert latex(u'\u03c5') == r'\\upsilon'\n    assert latex(u'\u03c6') == r'\\phi'\n    assert latex(u'\u03c7') == r'\\chi'\n    assert latex(u'\u03c8') == r'\\psi'\n    assert latex(u'\u03c9') == r'\\omega'\n"], "sample_462": ["    def test_choicefield_empty_values(self):\n        f = ChoiceField(choices=[(\"1\", \"One\"), (\"2\", \"Two\")], empty_values=[\"\", None])\n        self.assertEqual(\"\", f.clean(\"\"))\n        self.assertEqual(None, f.clean(None))\n        self.assertEqual(\"1\", f.clean(1))\n        self.assertEqual(\"1\", f.clean(\"1\"))\n        msg = \"'Select a valid choice. 3 is not one of the available choices.'\"\n        with self.assertRaisesMessage(ValidationError, msg):\n            f.clean(\"3\")\n"], "sample_1000": ["def test_matrix_operations():\n    A = Matrix([[1, 2], [3, 4]])\n    B = Matrix([[5, 6], [7, 8]])\n    C = A + B\n    assert mcode(C) == \"A + B\"\n    C = A - B\n    assert mcode(C) == \"A - B\"\n    C = A * B\n    assert mcode(C) == \"A.*B\"\n    C = A / B\n    assert mcode(C) == \"A./B\"\n    C = A**2\n    assert mcode(C) == \"A.^2\"\n    C = A**B\n    assert mcode(C) == \"A.^B\"\n    C = A.transpose()\n    assert mcode(C) == \"A.'\"\n    C = A.inv()\n    assert mcode(C) == \"inv(A)\"\n    C = A.det()\n    assert mcode(C) == \"det(A)\"\n    C = A.eigenvals()\n    assert mcode(C) == \"eig(A)\"\n    C = A.eigenvects()\n    assert mcode(C) == \"eig(A)\"\n"], "sample_609": ["compilation error"], "sample_896": ["def test_nmf_sparse_input_with_custom_init():\n    # Test that NMF works correctly with sparse input and custom initialization.\n    rng = np.random.mtrand.RandomState(42)\n    n_samples = 20\n    n_features = 10\n    n_components = 5\n\n    # Create a sparse matrix\n    X = sp.csr_matrix(rng.randn(n_samples, n_features))\n\n    # Create custom initialization for W and H\n    W_init = rng.randn(n_samples, n_components)\n    H_init = rng.randn(n_components, n_features)\n\n    # Fit NMF with custom initialization\n    nmf = NMF(n_components=n_components, init=\"custom\", random_state=0)\n    nmf.fit(X, W=W_init, H=H_init)\n\n    # Check that the fitted W and H have the correct shape\n    assert nmf.components_.shape == (n_components, n_features)\n    assert nmf.transform(X).shape == (n_samples, n_components)\n"], "sample_110": ["    def test_pickle_in_lookup_with_related_field(self):\n        \"\"\"\n        Test pickling and unpickling a QuerySet with an __in=inner_qs lookup\n        that involves a related field.\n        \"\"\"\n        groups = Group.objects.filter(name__startswith='Group')\n        events = Event.objects.filter(group__in=groups)\n\n        with self.assertNumQueries(0):\n            dumped = pickle.dumps(events.query)\n\n        with self.assertNumQueries(0):\n            reloaded = pickle.loads(dumped)\n            reloaded_events = Event.objects.none()\n            reloaded_events.query = reloaded\n\n        self.assertSequenceEqual(reloaded_events, [self.e1])\n"], "sample_565": ["def test_inset_axes_with_colorbar():\n    fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n    ax[0].plot([1, 2, 3], [4, 5, 6])\n    ax[1].plot([1, 2, 3], [4, 5, 6])\n\n    inset_ax = zoomed_inset_axes(ax[0], zoom=2, loc='lower right')\n    inset_ax.plot([1, 2, 3], [4, 5, 6])\n    inset_ax.set_xlabel(\"X Label\")\n    inset_ax.set_ylabel(\"Y Label\")\n    inset_ax.set_title(\"Inset Axes\")\n\n    cbar = fig.colorbar(ax[0].collections[0], ax=ax[0])\n    cbar.set_label(\"Colorbar Label\")\n"], "sample_665": ["compilation error"], "sample_139": ["    def test_dynamic_list_filter_with_related_fields(self):\n        \"\"\"\n        Regression tests for ticket #17646: dynamic list_filter support\n        with related fields.\n        \"\"\"\n        parent = Parent.objects.create(name='parent')\n        for i in range(10):\n            child = Child.objects.create(name='child %s' % i, parent=parent)\n            child.related_field = RelatedField.objects.create(name='related %s' % i)\n        user_noparents = self._create_superuser('noparents')\n        user_parents = self._create_superuser('parents')\n\n        # Test with user 'noparents'\n        m = DynamicListFilterChildAdmin(Child, custom_site)\n        request = self._mocked_authenticated_request('/child/', user_noparents)\n        response = m.changelist_view(request)\n        self.assertEqual(response.context_data['cl'].list_filter, ['name', 'age'])\n\n        # Test with user 'parents'\n        m = DynamicListFilterChildAdmin(Child, custom_site)\n        request = self._mocked_authenticated_request('/child/', user_parents)\n        response = m.changelist_view(request)\n        self.assertEqual(response.context_data['cl'].list_filter, ('parent', 'name', 'age', 'related_field__name'))\n\n\n\n"], "sample_1001": ["def test_issue_14707():\n    from sympy.physics.mechanics import Point, ReferenceFrame, inertial\n    O = Point('O')\n    A = Point('A')\n    N = ReferenceFrame('N')\n    N = inertial(N)\n    assert latex(A.pos_from(O, N)) == r\"\\overrightarrow{O A}\"\n"], "sample_202": ["    def test_not_finished_sentinel(self):\n        storage = self.get_storage()\n        response = self.get_response()\n\n        # Add messages to the storage, exceeding the max_cookie_size\n        messages = [\n            Message(constants.INFO, 'message 1'),\n            Message(constants.INFO, 'message 2'),\n            Message(constants.INFO, 'message 3'),\n            Message(constants.INFO, 'message 4'),\n            Message(constants.INFO, 'message 5'),\n            Message(constants.INFO, 'message 6'),\n        ]\n        storage.update(response, messages)\n\n        # Retrieve messages from the storage\n        retrieved_messages = list(storage)\n        self.assertEqual(len(retrieved_messages), 4)\n        self.assertEqual(retrieved_messages[-1].message, 'message 4')\n        self.assertEqual(retrieved_messages[-1].level, constants.INFO)\n        self.assertTrue(storage.used)\n\n        # Retrieve the remaining messages\n        retrieved_messages = list(storage)\n        self.assertEqual(len(retrieved_messages), 2)\n        self.assertEqual(retrieved_messages[0].message, 'message 5')\n        self.assertEqual(retrieved_messages[1].message, 'message 6')\n        self.assertFalse(storage.used)\n\n\n\n"], "sample_576": ["    def test_legend_handles_empty_series(self, xy):\n\n        p = Plot(**xy, color=pd.Series(dtype=\"object\")).add(MockMark()).plot()\n        assert not p._legend_contents\n"], "sample_785": ["        def __repr__(self):\n            return f\"MockSplitter(a={self.a}, b={self.b}, c={self.c})\"\n"], "sample_544": ["def test_imshow_masked_array():\n    data = np.ma.masked_array(np.arange(9).reshape((3, 3)),\n                              mask=np.array([[False, True, False],\n                                            [True, False, True],\n                                            [False, False, False]]))\n    fig, ax = plt.subplots()\n    ax.imshow(data, cmap='viridis')\n    fig.canvas.draw()\n    assert ax.images[0].get_array() is data.filled(0)\n"], "sample_934": ["        def assert_classes(self, tag, expected_classes):\n            assert self.content_classes[tag] == expected_classes, (\n                f\"Classes for role '{self.name}' and tag '{tag}' \"\n                f\"should be {expected_classes}, but are \"\n                f\"{self.content_classes[tag]}\"\n            )\n"], "sample_957": ["def test_stringify_type_hints_Callable_args(annotation: Callable[..., Any]):\n    assert stringify(annotation) == f\"Callable[[{', '.join(str(arg) for arg in annotation.__args__)}], int]\"\n"], "sample_245": ["    def test_custom_locale_paths_with_relative_paths(self):\n        \"\"\"\n        Tests that relative paths in LOCALE_PATHS are resolved correctly.\n        \"\"\"\n        with override_settings(LOCALE_PATHS=['locale', 'other_locale']):\n            management.call_command('makemessages', locale=[LOCALE], verbosity=0)\n            project_de_locale = os.path.join(\n                self.test_dir, 'locale', 'de', 'LC_MESSAGES', 'django.po')\n            other_locale_de_locale = os.path.join(\n                self.test_dir, 'other_locale', 'de', 'LC_MESSAGES', 'django.po')\n            self.assertTrue(os.path.exists(project_de_locale))\n            self.assertTrue(os.path.exists(other_locale_de_locale))\n"], "sample_726": ["compilation error"], "sample_167": ["    def test_naturaltime_with_microseconds(self):\n        test_list = [\n            now - datetime.timedelta(microseconds=123456),\n            now - datetime.timedelta(microseconds=500000),\n            now - datetime.timedelta(microseconds=999999),\n            now + datetime.timedelta(microseconds=123456),\n            now + datetime.timedelta(microseconds=500000),\n            now + datetime.timedelta(microseconds=999999),\n        ]\n        result_list = [\n            'now',\n            'now',\n            'now',\n            'now',\n            'now',\n            'now',\n        ]\n        with translation.override('en'):\n            self.humanize_tester(test_list, result_list, 'naturaltime')\n"], "sample_827": ["def test_csc_row_median_errors():\n    X = [[0, -2], [-1, -1], [1, 0], [2, 1]]\n    csc = sp.csc_matrix(X)\n    assert_raises(ValueError, csc_median_axis_0, csc, axis=1)\n"], "sample_945": ["def test_python_python_use_unqualified_type_names_enabled(app, status, warning):\n    app.build()\n    content = (app.outdir / 'index.html').read_text()\n    assert ('<span class=\"n\"><a class=\"reference internal\" href=\"#foo.Name\" title=\"foo.Name\">'\n            '<span class=\"pre\">Name</span></a></span>' in content)\n    assert '<span class=\"n\"><span class=\"pre\">foo.Age</span></span>' in content\n"], "sample_702": ["def test_testdir_makefile_ext_empty_string_makes_file(testdir) -> None:\n    \"\"\"For backwards compat #8192\"\"\"\n    p1 = testdir.makefile(\"\", \"\")\n    assert \"test_testdir_makefile\" in str(p1)\n"], "sample_451": ["    def test_parse_rst_with_metadata(self):\n        docstring = \"\"\"\n        Display an individual :model:`myapp.MyModel`.\n\n        **Context**\n\n        ``RequestContext``\n\n        ``mymodel``\n            An instance of :model:`myapp.MyModel`.\n\n        **Template:**\n\n        :template:`myapp/my_template.html` (DESCRIPTION)\n\n        some_metadata: some data\n        another_metadata: another value\n        \"\"\"\n        title, description, metadata = parse_docstring(docstring)\n        output = parse_rst(description, \"model\", \"model:admindocs\")\n        self.assertIn('<p>some_metadata: some data</p>', output)\n        self.assertIn('<p>another_metadata: another value</p>', output)\n"], "sample_787": ["def test_balanced_accuracy_score_empty_classes():\n    assert_equal(balanced_accuracy_score(y_true=[], y_pred=[]), 0.0)\n    assert_equal(balanced_accuracy_score(y_true=[0], y_pred=[0]), 1.0)\n    assert_equal(balanced_accuracy_score(y_true=[0, 1], y_pred=[0, 0]), 1.0)\n    assert_equal(balanced_accuracy_score(y_true=[0, 1, 2], y_pred=[0, 1, 2]), 1.0)\n"], "sample_775": ["def test_changed_only_with_nested_estimators():\n    # Test changed_only with nested estimators\n    from sklearn.pipeline import Pipeline\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.svm import SVC\n\n    pipeline = Pipeline([\n        ('scaler', StandardScaler()),\n        ('classifier', LogisticRegression(C=999))\n    ])\n\n    # Make changes to the classifier\n    pipeline.named_steps['classifier'].C = 1000\n\n    expected = \"\"\""], "sample_403": ["    def test_references_field_by_through_m2m_reverse(self):\n        operation = FieldOperation(\n            \"Model\", \"field\", models.ManyToManyField(\"Other\", through=\"Through\")\n        )\n        self.assertIs(\n            operation.references_field(\"Through\", \"reverse_field\", \"migrations\"), True\n        )\n        self.assertIs(\n            operation.references_field(\"Missing\", \"reverse_field\", \"migrations\"), False\n        )\n"], "sample_1155": ["compilation error"], "sample_1209": ["def test_prefix_latex():\n    assert PREFIXES['m']._latex(None) == r'\\text{m}'\n    assert PREFIXES['k']._latex(None) == r'\\text{k}'\n    assert PREFIXES['m']._latex(None) == r'\\text{m}'\n    assert PREFIXES['k']._latex(None) == r'\\text{k}'\n    assert PREFIXES['mu']._latex(None) == r\"\\mu\"\n"], "sample_12": ["def test_angle_with_invalid_units():\n    with pytest.raises(ValueError):\n        Angle('1d', unit='invalid')\n    with pytest.raises(ValueError):\n        Angle('1d', unit='invalid')\n    with pytest.raises(ValueError):\n        Longitude('1d', unit='invalid')\n    with pytest.raises(ValueError):\n        Latitude('1d', unit='invalid')\n"], "sample_1187": ["def test_hyperplane_parameters():\n    triangle = Polygon(Point(0, 3), Point(5, 3), Point(1, 1))\n    a, b = hyperplane_parameters(triangle)\n    assert a == -1\n    assert b == 3\n"], "sample_1179": ["def test_issue_23451():\n    from sympy.tensor import Tensor, tensor_indices\n    a = Tensor('a', (2, 3))\n    b = Tensor('b', (3, 1))\n    c = Tensor('c', (1, 2))\n    d = Tensor('d', (2, 1))\n    assert str(a * b * c * d) == 'a*b*c*d'\n    assert str(a[tensor_indices(a, 0, 1)] * b[tensor_indices(b, 0)]) == 'a[0, 1]*b[0]'\n"], "sample_203": ["    def test_file_extension_validator(self):\n        class MyForm(forms.Form):\n            file = forms.FileField()\n\n        form = MyForm({'file': SimpleUploadedFile('test.txt', b'content', content_type='text/plain')})\n        self.assertTrue(form.is_valid())\n\n        form = MyForm({'file': SimpleUploadedFile('test.jpg', b'content', content_type='image/jpeg')})\n        self.assertTrue(form.is_valid())\n\n        form = MyForm({'file': SimpleUploadedFile('test.exe', b'content', content_type='application/octet-stream')})\n        with self.assertRaises(ValidationError):\n            form.is_valid()\n"], "sample_1196": ["def test_contains_with_boolean_expressions():\n    x = Symbol('x')\n    assert Contains(x, FiniteSet(Eq(x, 1), Eq(x, 2))).as_set() == FiniteSet(1, 2)\n"], "sample_423": ["    def test_operation_with_custom_name(self):\n        class Migration(migrations.Migration):\n            operations = [\n                migrations.CreateModel(\n                    \"Person\", fields=[], name=\"my_person_model\"\n                )\n            ]\n\n        migration = Migration(\"some_migration\", \"test_app\")\n        self.assertEqual(migration.suggest_name(), \"my_person_model\")\n"], "sample_816": ["def test_vectorizer_empty_vocabulary(Estimator):\n    vec = Estimator(vocabulary=[])\n    assert_raises(ValueError, vec.fit_transform, ['hello world'])\n    assert_raises(ValueError, vec.transform, ['hello world'])\n"], "sample_663": ["compilation error"], "sample_337": ["    def test_https_good_referer_matches_cookie_domain_with_different_port(self):\n        \"\"\"\n        A POST HTTPS request with a good referer should be accepted from a\n        subdomain that's allowed by CSRF_COOKIE_DOMAIN and a non-443 port.\n        \"\"\"\n        req = self._get_POST_request_with_token()\n        req._is_secure_override = True\n        req.META['HTTP_HOST'] = 'foo.example.com'\n        req.META['HTTP_REFERER'] = 'https://foo.example.com'\n        req.META['SERVER_PORT'] = '8443'\n        mw = CsrfViewMiddleware(post_form_view)\n        self.assertIsNone(mw.process_view(req, post_form_view, (), {}))\n"], "sample_56": ["    def test_check_for_invalid_field_types(self):\n        class SongAdmin(admin.ModelAdmin):\n            fields = ['title', 'invalid_field']\n\n        errors = SongAdmin(Song, AdminSite()).check()\n        expected = [\n            checks.Error(\n                \"The value of 'fields[1]' is not a callable, an attribute \"\n                \"of 'SongAdmin', or an attribute of 'admin_checks.Song'.\",\n                obj=SongAdmin,\n                id='admin.E035',\n            )\n        ]\n        self.assertEqual(errors, expected)\n"], "sample_681": ["        def test_bad_log_with_exception(monkeypatch):\n            monkeypatch.setattr(logging, 'raiseExceptions', False)\n            try:\n                logging.error('oops', 'first', 2)\n            except Exception as e:\n                assert str(e) == \"Exception occurred during logging\""], "sample_285": ["    def test_nonexistent_directory_in_staticfiles_dirs(self):\n        with self.settings(STATICFILES_DIRS=['/path/to/nonexistent/directory']):\n            self.assertEqual(check_finders(None), [\n                Warning(\n                    f\"The directory '/path/to/nonexistent/directory' in the STATICFILES_DIRS setting \"\n                    f\"does not exist.\",\n                    id='staticfiles.W004',\n                )\n            ])\n"], "sample_492": ["    def test_serialize_custom_field(self):\n        class MyCustomField(models.Field):\n                super().__init__(*args, **kwargs)\n\n                return \"MyCustomDbType\"\n\n                return \"MyCustomInternalType\"\n\n                return super().formfield(**kwargs)\n\n        field = MyCustomField()\n        string, imports = MigrationWriter.serialize(field)\n        self.assertEqual(string, \"MyCustomField()\")\n        self.assertEqual(imports, {\"from . import MyCustomField\"})\n"], "sample_255": ["    def test_close_connection(self):\n        request = WSGIRequest(self.request_factory.get('/').environ)\n        request.makefile = lambda *args, **kwargs: BytesIO()\n        handler = WSGIRequestHandler(request, '192.168.0.2', None)\n\n        # Simulate a request that doesn't close the connection\n        handler.close_connection = False\n        handler.handle_one_request()\n\n        # Assert that the connection wasn't closed\n        self.assertTrue(handler.connection.is_open())\n\n        # Simulate a request that closes the connection\n        handler.close_connection = True\n        handler.handle_one_request()\n\n        # Assert that the connection was closed\n        self.assertFalse(handler.connection.is_open())\n"], "sample_824": ["def test_check_pairwise_arrays_with_empty_arrays():\n    # Ensures that checks handle empty arrays correctly.\n    XA = np.array([])\n    XB = np.array([])\n    XA_checked, XB_checked = check_pairwise_arrays(XA, XB)\n    assert XA_checked.size == 0\n    assert XB_checked.size == 0\n\n    XA = np.array([])\n    XB = np.array([1, 2, 3])\n    XA_checked, XB_checked = check_pairwise_arrays(XA, XB)\n    assert XA_checked.size == 0\n    assert XB_checked.size == 3\n\n    XA = np.array([1, 2, 3])\n    XB = np.array([])\n    XA_checked, XB_checked = check_pairwise_arrays(XA, XB)\n    assert XA_checked.size == 3\n    assert XB_checked.size == 0\n"], "sample_1024": ["compilation error"], "sample_434": ["    def test_redirect_view_works(self):\n        class RedirectViewTest(RedirectView):\n            url = \"/some/other/url\"\n\n        request_factory = RequestFactory()\n        request = request_factory.get(\"/\")\n        view = RedirectViewTest.as_view()\n        response = view(request)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response[\"Location\"], \"/some/other/url\")\n"], "sample_219": ["    def test_output_field_override(self):\n        expr = ExpressionWrapper(F('field'), output_field=CharField())\n        self.assertEqual(expr.output_field, CharField())\n"], "sample_476": ["    def test_multiple_assignments(self):\n        p = self.PersonModel()\n        p.mugshot = self.file1\n        p.mugshot = self.file2\n        self.check_dimensions(p, 8, 4, \"mugshot\")\n        p.headshot = self.file1\n        p.headshot = self.file2\n        self.check_dimensions(p, 8, 4, \"mugshot\")\n        self.check_dimensions(p, 8, 4, \"headshot\")\n"], "sample_606": ["compilation error"], "sample_883": ["def test_bayesian_ridge_ard_fit_intercept(Estimator):\n    # Test fit_intercept=False behavior\n    X = np.array([[1, 0], [0, 0]])\n    y = np.array([0, 0])\n    model = Estimator(fit_intercept=False)\n    model.fit(X, y)\n    assert model.intercept_ is None\n"], "sample_693": ["    def test_do_cleanups_on_teardown_failure(self):\n        testpath = pytester.makepyfile(\n            \"\"\"\n            import unittest\n            class MyTestCase(unittest.TestCase):\n                values = []\n                        self.values.append(1)\n                    self.addCleanup(cleanup)\n                    pass\n                    assert False\n                assert MyTestCase.values == [1]\n            \"\"\"\n        )\n        reprec = pytester.inline_run(testpath)\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == 1\n        assert passed == 1\n"], "sample_100": ["    def test_snapshot_files_handles_new_files(self):\n        new_file = self.ensure_file(self.tempdir / 'new_file.py')\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file, new_file]):\n            snapshot1 = dict(self.reloader.snapshot_files())\n            self.assertIn(self.existing_file, snapshot1)\n            self.assertIn(new_file, snapshot1)\n"], "sample_231": ["    def test_sensitive_variables_decorator_with_args(self):\n        @sensitive_variables\n            return password + secret_key\n\n        with self.settings(DEBUG=True):\n            response = self.client.post('/sensitive_view/', data={'password': 'password123', 'secret_key': 'secret123'})\n            self.assertContains(response, 'password123secret123', status_code=500)\n\n        with self.settings(DEBUG=False):\n            response = self.client.post('/sensitive_view/', data={'password': 'password123', 'secret_key': 'secret123'})\n            self.assertNotContains(response, 'password123secret123', status_code=500)\n"], "sample_266": ["    def test_loading_squashed_complex_multi_apps_mixed_order(self):\n        loader = MigrationLoader(connection)\n        recorder = MigrationRecorder(connection)\n        recorder.record_applied('app1', '1_auto')\n        recorder.record_applied('app2', '1_squashed_2')\n        loader.build_graph()\n\n        plan = set(loader.graph.forwards_plan(('app1', '4_auto')))\n        plan = plan - loader.applied_migrations.keys()\n        expected_plan = {\n            ('app1', '2_squashed_3'),\n            ('app1', '3_auto'),\n            ('app1', '4_auto'),\n        }\n\n        self.assertEqual(plan, expected_plan)\n"], "sample_111": ["    def test_list_display_links_with_custom_template(self):\n        class CustomListDisplayLinksAdmin(admin.ModelAdmin):\n            list_display = ('name', 'age')\n            list_display_links = ('name',)\n            list_display_links_template = 'admin_changelist/custom_list_display_links.html'\n\n        custom_site = admin.AdminSite(name='custom_site')\n        custom_site.register(Child, CustomListDisplayLinksAdmin)\n        m = CustomListDisplayLinksAdmin(Child, custom_site)\n\n        # Render the list display links template\n        request = self._mocked_authenticated_request('/child/', self.superuser)\n        response = m.changelist_view(request)\n        rendered_content = response.rendered_content\n\n        # Assert that the custom template is used\n        self.assertIn('<div class=\"list-display-links\">', rendered_content)\n        self.assertIn('custom_list_display_links.html', rendered_content)\n\n        # Assert that the list display links are rendered correctly\n        self.assertIn('<a href=\"/admin/child/1/\">child 0</a>', rendered_content)\n        self.assertNotIn('<a href=\"/admin/child/1/\">child 1</a>', rendered_content)\n\n\n\n"], "sample_530": ["def test_offsetbox_with_transform():\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100)\n    ab = AnchoredOffsetbox(loc='center', child=da,\n                          transform=ax.transAxes)\n    ax.add_artist(ab)\n\n    # Check that the transform is applied correctly\n    bbox = ab.get_window_extent(fig.canvas.get_renderer())\n    assert bbox.width == 1.0\n    assert bbox.height == 1.0\n"], "sample_314": ["    def test_password_too_short(self):\n        user = User.objects.get(username='testclient')\n        data = {'password1': 'abc', 'password2': 'abc'}\n        form = AdminPasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertIn('password1', form.errors)\n        self.assertIn('password2', form.errors)\n        self.assertIn(\n            'This password is too short. It must contain at least 8 characters.',\n            form.errors['password1'],\n        )\n        self.assertIn(\n            'This password is too short. It must contain at least 8 characters.',\n            form.errors['password2'],\n        )\n"], "sample_766": ["def test_sparse_coder_partial_fit():\n    n_components = 12\n    rng = np.random.RandomState(0)\n    V = rng.randn(n_components, n_features)  # random init\n    V /= np.sum(V ** 2, axis=1)[:, np.newaxis]\n    coder = SparseCoder(dictionary=V, transform_algorithm='lasso_lars',\n                       transform_alpha=0.001)\n    coder.partial_fit(X[0:10])\n    coder.partial_fit(X[10:20])\n    code = coder.transform(X)\n    assert_array_almost_equal(code, sparse_encode(X, V,\n                                                algorithm='lasso_lars',\n                                                alpha=0.001),\n                              decimal=2)\n"], "sample_620": ["compilation error"], "sample_932": ["compilation error"], "sample_666": ["compilation error"], "sample_943": ["    def test_package_file_with_docstring(tempdir):\n        outdir = path(tempdir)\n        (outdir / 'testpkg').makedirs()\n        (outdir / 'testpkg' / '__init__.py').write_text('')\n        (outdir / 'testpkg' / 'example.py').write_text(\n            \"\"\"\n            \"\"\"\n            \"\"\"\n            This is a test package.\n            \"\"\"\n                pass\n            \"\"\")\n        apidoc_main(['-o', tempdir, tempdir / 'testpkg'])\n        assert (outdir / 'testpkg.rst').exists()\n\n        content = (outdir / 'testpkg.rst').read_text()\n        assert content.startswith(\"testpkg package\\n===============\\n\\n\")\n        assert \"This is a test package.\" in content\n"], "sample_91": ["    def test_permission_denied_template_context(self):\n        request = self.request_factory.get('/forbidden/')\n        response = permission_denied(request, Exception('Permission denied!'))\n        self.assertContains(response, 'Permission denied!', status_code=403)\n"], "sample_660": ["        def test_skip():\n            pass"], "sample_475": ["    def test_actions_with_permissions(self):\n        @admin.action(permissions=[\"custom\"])\n            pass\n\n        class BandAdmin(ModelAdmin):\n            actions = (custom_permission_action,)\n\n        self.assertIsInvalid(\n            BandAdmin,\n            Band,\n            \"BandAdmin must define a has_custom_permission() method for the \"\n            \"custom_permission_action action.\",\n            id=\"admin.E129\",\n        )\n\n\n"], "sample_5": ["def test_models_evaluate_magunits_with_units(model):\n    if not HAS_SCIPY and model['class'] in SCIPY_MODELS:\n        pytest.skip()\n\n    m = model['class'](**model['parameters'])\n    for args in model['evaluation']:\n        assert_quantity_allclose(m(*args[:-1]), args[-1])\n"], "sample_376": ["    def test_not_finished_sentinel(self):\n        storage = self.get_storage()\n        response = self.get_response()\n\n        # Store a few messages, then add the sentinel value.\n        storage.add(constants.INFO, 'message 1')\n        storage.add(constants.INFO, 'message 2')\n        storage.add(constants.INFO, 'message 3')\n        storage.add(constants.INFO, CookieStorage.not_finished)\n\n        # Update the cookie and check that the sentinel value is removed.\n        unstored_messages = storage.update(response)\n        self.assertEqual(len(unstored_messages), 0)\n        self.assertEqual(stored_cookie_messages_count(storage, response), 3)\n\n        # Now retrieve the messages and check that the sentinel value is not present.\n        messages = list(storage)\n        self.assertEqual(messages, ['message 1', 'message 2', 'message 3'])\n"], "sample_599": ["def test_CFScaleOffsetCoder_decode_with_offset():\n    original = xr.Variable((\"x\",), [0.0, 1.0, 2.0], encoding=dict(add_offset=5.0))\n    coder = variables.CFScaleOffsetCoder()\n    encoded = coder.encode(original)\n    roundtripped = coder.decode(encoded)\n    assert_allclose(roundtripped.data, np.array([5.0, 6.0, 7.0]))\n"], "sample_682": ["compilation error"], "sample_468": ["    def test_context_processors_return_none(self):\n        engine = Engine(\n            loaders=[\n                (\n                    \"django.template.loaders.locmem.Loader\",\n                    {\n                        \"child\": '{{ var|default:\"none\" }}',\n                    },\n                ),\n            ]\n        )\n        request = self.request_factory.get(\"/\")\n        ctx = RequestContext(request, {}, processors=[context_process_returning_none])\n        self.assertEqual(engine.from_string('{% include \"child\" %}').render(ctx), \"none\")\n"], "sample_503": ["def test_marker_size_scaling():\n    fig, ax = plt.subplots()\n    x = np.linspace(0, 2*np.pi, 10)\n    y = np.sin(x)\n\n    for i in range(3):\n        ax.plot(x, y + i, marker='o', markersize=10 * (i + 1),\n                label=f'Marker size: {10 * (i + 1)}')\n\n    ax.legend()\n"], "sample_212": ["            def process_response(self, request, response):\n                return response\n"], "sample_82": ["    def test_invalid_date_format(self):\n        self.assertEqual(self.widget.format_value('invalid'), {'day': None, 'month': None, 'year': None})\n        self.assertEqual(self.widget.format_value('2000-13-1'), {'day': None, 'month': None, 'year': None})\n        self.assertEqual(self.widget.format_value('2000-01-32'), {'day': None, 'month': None, 'year': None})\n        self.assertEqual(self.widget.format_value('2000-00-1'), {'day': None, 'month': None, 'year': None})\n        self.assertEqual(self.widget.format_value('abc-1-1'), {'day': None, 'month': None, 'year': None})\n"], "sample_796": ["def test_huber_with_sparse_data():\n    # Test HuberRegressor with sparse data\n    n_samples = 100\n    n_features = 1000\n    X = sparse.csr_matrix(np.random.rand(n_samples, n_features))\n    y = np.random.rand(n_samples)\n\n    huber = HuberRegressor(fit_intercept=True, alpha=0.01, max_iter=100)\n    huber.fit(X, y)\n    assert_array_almost_equal(huber.coef_, huber.coef_, 3)\n    assert_greater(huber.n_iter_, 0)\n"], "sample_1121": ["def test_issue_16394():\n    from sympy import symbols, sin, cos, pi\n    x, y = symbols('x y')\n    assert sin(x + y).expand(trig=True) == sin(x)*cos(y) + cos(x)*sin(y)\n    assert cos(x + y).expand(trig=True) == cos(x)*cos(y) - sin(x)*sin(y)\n    assert sin(x - y).expand(trig=True) == sin(x)*cos(y) - cos(x)*sin(y)\n    assert cos(x - y).expand(trig=True) == cos(x)*cos(y) + sin(x)*sin(y)\n    assert sin(x + pi/2).expand(trig=True) == cos(x)\n    assert cos(x + pi/2).expand(trig=True) == -sin(x)\n    assert sin(x - pi/2).expand(trig=True) == -cos(x)\n    assert cos(x - pi/2).expand(trig=True) == sin(x)\n"], "sample_813": ["compilation error"], "sample_50": ["    def test_empty_params(self):\n        self.assertEqual(\n            self._run_it({}), (\n                ['psql'],\n                None,\n            )\n        )\n"], "sample_614": ["    def test_diff_dataset_repr_identical_with_attrs(self) -> None:\n        ds_a = xr.Dataset(\n            data_vars={\"var1\": ((\"x\", \"y\"), np.array([[1, 2, 3], [4, 5, 6]], dtype=\"int64\"))},\n            coords={\"x\": [\"a\", \"b\"], \"y\": [1, 2, 3]},\n            attrs={\"units\": \"m\", \"description\": \"desc\"},\n        )\n\n        ds_b = xr.Dataset(\n            data_vars={\"var1\": ((\"x\", \"y\"), np.array([[1, 2, 3], [4, 5, 6]], dtype=\"int64\"))},\n            coords={\"x\": [\"a\", \"b\"], \"y\": [1, 2, 3]},\n            attrs={\"units\": \"m\", \"description\": \"desc\"},\n        )\n\n        expected = dedent(\n            \"\"\"\\\n        Left and right Dataset objects are identical\n        \"\"\"\n        )\n\n        actual = formatting.diff_dataset_repr(ds_a, ds_b, \"identical\")\n        assert actual == expected\n"], "sample_750": ["def test_omp_path_with_tol():\n    path = orthogonal_mp(X, y, n_nonzero_coefs=5, tol=0.1, return_path=True)\n    last = orthogonal_mp(X, y, n_nonzero_coefs=5, tol=0.1, return_path=False)\n    assert_equal(path.shape, (n_features, n_targets, 5))\n    assert_array_almost_equal(path[:, :, -1], last)\n    path = orthogonal_mp_gram(G, Xy, n_nonzero_coefs=5, tol=0.1, return_path=True)\n    last = orthogonal_mp_gram(G, Xy, n_nonzero_coefs=5, tol=0.1, return_path=False)\n    assert_equal(path.shape, (n_features, n_targets, 5))\n    assert_array_almost_equal(path[:, :, -1], last)\n"], "sample_1122": ["def test_issue_15037():\n    from sympy import Abs, re, im, Symbol, pi\n    x = Symbol('x', real=True)\n    y = Symbol('y', imaginary=True)\n    z = Symbol('z', real=True)\n    assert Abs(x + I*y) == sqrt(x**2 + y**2)\n    assert Abs(x + I*y).subs(x, 1).subs(y, 2) == sqrt(5)\n    assert re(x + I*y) == x\n    assert im(x + I*y) == y\n    assert Abs(x + I*y).subs(x, 1).subs(y, 2) == sqrt(5)\n    assert Abs(z + I*y) == sqrt(z**2 + y**2)\n    assert Abs(x + I*y + z) == sqrt((x + z)**2 + y**2)\n    assert Abs(x + I*y).rewrite(exp) == sqrt(exp(2*I*atan(y/x)))\n    assert Abs(x + I*y).rewrite(exp).subs(x, 1).subs(y, 2) == sqrt(exp(2*I*atan(2)))\n    assert Abs(x + I*y).rewrite(exp).subs(x, 1).subs(y, 2) == sqrt(exp(2*I*atan(2)))\n    assert Abs(x + I*y).rewrite(exp).subs(x, 0).subs(y, 1) == sqrt(exp(I*pi/2))\n    assert Abs(x + I*y).rewrite(exp).subs(x, 0).subs(y, 1) == sqrt(exp(I*pi/2))\n    assert Abs(x + I*y).rewrite(exp).subs(x, 1).subs(y, 0) == sqrt(exp(0))\n    assert Abs(x + I*y).rewrite(exp).subs(x, 1).subs(y, 0) == sqrt(exp(0))\n    assert Abs(x + I*y).rewrite(exp).subs(x, 0).subs(y,"], "sample_1055": ["def test_bg_public_key():\n    assert 186 == bg_public_key(23, 31)\n    assert 127 == bg_public_key(13, 17)\n    raises(ValueError, lambda: bg_public_key(8, 16))\n    raises(ValueError, lambda: bg_public_key(8, 8))\n    raises(ValueError, lambda: bg_public_key(13, 17))\n"], "sample_1049": ["compilation error"], "sample_391": ["    def test_create_model_add_field_with_default(self):\n        managers = [(\"objects\", EmptyManager())]\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[(\"name\", models.CharField(max_length=255))],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n                migrations.AddField(\n                    \"Foo\", \"age\", models.IntegerField(default=42),\n                ),\n            ],\n            [\n                migrations.CreateModel(\n                    name=\"Foo\",\n                    fields=[\n                        (\"name\", models.CharField(max_length=255)),\n                        (\"age\", models.IntegerField(default=42)),\n                    ],\n                    options={\"verbose_name\": \"Foo\"},\n                    bases=(UnicodeModel,),\n                    managers=managers,\n                ),\n            ],\n        )\n"], "sample_867": ["def test_search_cv_with_preprocessor():\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.linear_model import LogisticRegression\n\n    X, y = make_classification(n_samples=100, n_features=10, random_state=0)\n    preprocessor = StandardScaler()\n    estimator = LogisticRegression(random_state=0)\n    param_grid = {'C': [0.1, 1, 10]}\n\n    gs = GridSearchCV(estimator, param_grid, cv=5, pre_dispatch='2*n_jobs',\n                      preprocessor=preprocessor)\n    gs.fit(X, y)\n\n    assert isinstance(gs.best_estimator_.steps[0][1], StandardScaler)\n    assert isinstance(gs.best_estimator_.steps[1][1], LogisticRegression)\n\n\n\n"], "sample_898": ["compilation error"], "sample_258": ["    def test_receiver_dispatch_uid(self):\n        @receiver(a_signal, dispatch_uid=\"uid\")\n            self.state.append(val)\n        self.state = []\n        a_signal.connect(f, dispatch_uid=\"uid\")\n        a_signal.send(sender=self, val=True)\n        self.assertEqual(self.state, [True])\n        a_signal.disconnect(dispatch_uid=\"uid\")\n        a_signal.send(sender=self, val=False)\n        self.assertEqual(self.state, [True])\n"], "sample_588": ["    def test_auto_combine_with_missing_coords(self):\n        objs = [\n            Dataset({\"foo\": (\"x\", [0])}, coords={\"x\": (\"x\", [0])}),\n            Dataset({\"foo\": (\"x\", [1])}),  # Missing 'x' coord\n        ]\n        with pytest.warns(FutureWarning, match=\"missing coordinates\"):\n            auto_combine(objs)\n"], "sample_669": ["def test_encodedfile_writelines_with_bytes(tmpfile: BinaryIO) -> None:\n    ef = capture.EncodedFile(tmpfile, encoding=\"utf-8\")\n    ef.writelines([b\"line1\", b\"line2\"])\n    ef.flush()\n    tmpfile.seek(0)\n    assert tmpfile.read() == b\"line1\\nline2\"\n    tmpfile.close()\n"], "sample_567": ["def test_text_bbox_clip():\n    fig, ax = plt.subplots()\n    text = ax.text(0.5, 0.5, 'This text is clipped', clip_on=True)\n    fig.canvas.draw()\n    bbox = text.get_window_extent()\n    assert bbox.width > 0 and bbox.height > 0\n\n    text = ax.text(0.5, 0.5, 'This text is clipped', clip_on=False)\n    fig.canvas.draw()\n    bbox = text.get_window_extent()\n    assert bbox.width > 0 and bbox.height > 0\n\n    # Test clipping with a larger text size\n    text = ax.text(0.5, 0.5, 'This text is clipped', clip_on=True, fontsize=20)\n    fig.canvas.draw()\n    bbox = text.get_window_extent()\n    assert bbox.width > 0 and bbox.height > 0\n\n    text = ax.text(0.5, 0.5, 'This text is clipped', clip_on=False, fontsize=20)\n    fig.canvas.draw()\n    bbox = text.get_window_extent()\n    assert bbox.width > 0 and bbox.height > 0\n\n    # Test clipping with a rotated text\n    text = ax.text(0.5, 0.5, 'This text is clipped', clip_on=True, rotation=45)\n    fig.canvas.draw()\n    bbox = text.get_window_extent()\n    assert bbox.width > 0 and bbox.height > 0\n\n    text = ax.text(0.5, 0.5, 'This text is clipped', clip_on=False, rotation=45)\n    fig.canvas.draw()\n    bbox = text.get_window_extent()\n    assert bbox.width > 0 and bbox.height > 0\n"], "sample_920": ["    def test_unicode_characters(self):\n        docstring = \"\"\""], "sample_401": ["    def test_non_valid(self):\n        data = {\n            \"choices-TOTAL_FORMS\": \"2\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Zero\",\n            \"choices-0-votes\": \"\",\n            \"choices-1-choice\": \"One\",\n            \"choices-1-votes\": \"1\",\n        }\n        ChoiceFormSet = formset_factory(Choice)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [\n            {\"choices-0-votes\": [\"This field is required.\"] },\n            {},\n        ]\n        self.assertEqual(formset1._errors, expected_errors)\n        self.assertEqual(formset2._errors, expected_errors)\n"], "sample_863": ["        def fit(self, X, y=None, **fit_params):\n            if fit_params != {'a': 0}:\n                raise ValueError\n            return self\n"], "sample_1198": ["def test_mathematica_special_functions():\n    d = {\n        \"Sin[x]\": \"sin(x)\",\n        \"Cos[x]\": \"cos(x)\",\n        \"Tan[x]\": \"tan(x)\",\n        \"Cot[x]\": \"cot(x)\",\n        \"Sec[x]\": \"sec(x)\",\n        \"Csc[x]\": \"csc(x)\",\n        \"Sinh[x]\": \"sinh(x)\",\n        \"Cosh[x]\": \"cosh(x)\",\n        \"Tanh[x]\": \"tanh(x)\",\n        \"Coth[x]\": \"coth(x)\",\n        \"Sech[x]\": \"sech(x)\",\n        \"Csch[x]\": \"csch(x)\",\n        \"ArcSin[x]\": \"asin(x)\",\n        \"ArcCos[x]\": \"acos(x)\",\n        \"ArcTan[x]\": \"atan(x)\",\n        \"ArcCot[x]\": \"acot(x)\",\n        \"ArcSec[x]\": \"asec(x)\",\n        \"ArcCsc[x]\": \"acsc(x)\",\n        \"Exp[x]\": \"exp(x)\",\n        \"Log[x]\": \"log(x)\",\n        \"Log[x, y]\": \"log(x, y)\",\n        \"Sqrt[x]\": \"sqrt(x)\",\n        \"Abs[x]\": \"abs(x)\",\n        \"Floor[x]\": \"floor(x)\",\n        \"Ceiling[x]\": \"ceil(x)\",\n        \"Round[x]\": \"round(x)\",\n        \"Sign[x]\": \"sign(x)\",\n        \"Re[x]\": \"re(x)\",\n        \"Im[x]\": \"im(x)\",\n        \"N[x]\": \"N(x)\",\n        \"ComplexExpand[x]\": \"ComplexExpand(x)\",\n        \"Simplify[x]\": \"simplify(x)\",\n        \"Expand[x]\": \"expand(x)\",\n        \"Factor[x]\": \"factor(x)\",\n        \"FullSimplify[x]\": \"FullSimplify(x)\",\n        \"FullSimplify[x, Assumptions -> {"], "sample_690": ["compilation error"], "sample_10": ["def test_remove_columns_with_generator_invalid_names():\n    t = table.table_helpers.simple_table(1)\n    with pytest.raises(KeyError, match='column \"d\" does not exist'):\n        t.remove_columns(col for col in ['a', 'b', 'd'])\n"], "sample_604": ["compilation error"], "sample_467": ["    def test_empty_string_input(self):\n        self.assertEqual(self.widget.value_from_datadict({}, {}, \"field\"), None)\n        self.assertEqual(self.widget.format_value(\"\"), None)\n\n"], "sample_94": ["    def test_create_permissions_with_custom_permissions(self):\n        custom_permissions = [\n            ('my_custom_permission', 'Some custom permission'),\n            ('another_custom_permission', 'Another custom permission'),\n        ]\n        Permission._meta.permissions = custom_permissions\n        create_permissions(self.app_config, verbosity=0)\n\n        self.assertEqual(Permission.objects.count(), len(custom_permissions))\n        for permission_name, permission_label in custom_permissions:\n            self.assertTrue(Permission.objects.filter(\n                content_type=ContentType.objects.get_for_model(Permission),\n                codename=permission_name,\n            ).exists())\n\n\n\n"], "sample_838": ["def test_column_transformer_sparse_threshold_with_remainder():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).astype('float').T\n\n    ct = ColumnTransformer([('trans1', StandardScaler(), [0])],\n                           remainder=SparseMatrixTrans(),\n                           sparse_threshold=0.5)\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n    assert X_trans.getnnz(axis=1).max() < X_array.shape[1] * 0.5\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], SparseMatrixTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n"], "sample_87": ["    def test_snapshot_files_handles_multiple_files(self):\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file, self.nonexistent_file]):\n            snapshot1 = dict(self.reloader.snapshot_files())\n            self.assertIn(self.existing_file, snapshot1)\n            self.assertNotIn(self.nonexistent_file, snapshot1)\n            self.increment_mtime(self.existing_file)\n            snapshot2 = dict(self.reloader.snapshot_files())\n            self.assertNotEqual(snapshot1[self.existing_file], snapshot2[self.existing_file])\n            self.assertNotIn(self.nonexistent_file, snapshot2)\n"], "sample_555": ["def test_arc_transform():\n    fig, ax = plt.subplots()\n    arc = Arc((0, 0), 1, 1, theta1=0, theta2=90)\n    transform = ax.transData\n    transformed_arc = arc.get_path().transformed(transform)\n    assert transformed_arc.vertices.shape[0] > 0\n"], "sample_1126": ["def test_bra_ket():\n    from sympy.physics.quantum.state import Ket, Bra\n    a = symbols('a')\n    b = symbols('b')\n    assert Dagger(Ket(a)) == Bra(a)\n    assert Dagger(Bra(b)) == Ket(b)\n"], "sample_533": ["def test_contour_with_masked_array():\n    x = np.arange(10)\n    y = np.arange(10)\n    X, Y = np.meshgrid(x, y)\n    data = np.sin(np.sqrt(X**2 + Y**2))\n    mask = np.zeros_like(data, dtype=bool)\n    mask[5:8, 5:8] = True\n    masked_data = np.ma.masked_array(data, mask=mask)\n\n    fig, ax = plt.subplots()\n    cs = ax.contour(X, Y, masked_data)\n    assert cs.get_paths() is not None\n    assert all(p.vertices is not None for p in cs.get_paths())\n"], "sample_1090": ["compilation error"], "sample_144": ["    def test_update_parent_field_with_pk_set_to_none(self):\n        p1 = Profile.objects.create(username='john')\n        p2 = User.objects.get(pk=p1.user_ptr_id).profile\n        p2.pk = None\n        p2.user_ptr_id = None\n        p2.username = 'bill'\n        p2.save()\n        self.assertEqual(Profile.objects.count(), 2)\n        self.assertEqual(User.objects.get(pk=p1.user_ptr_id).username, 'john')\n        p2.user_ptr_id = 1\n        p2.save()\n        self.assertEqual(Profile.objects.count(), 2)\n        self.assertEqual(User.objects.get(pk=p2.user_ptr_id).username, 'bill')\n"], "sample_1088": ["def test_viete():\n    assert viete(x**2 + 2*x + 1, [r1, r2], x) == [(r1 + r2, -2), (r1*r2, 1)]\n    assert viete(x**3 - 6*x**2 + 11*x - 6, [r1, r2, r3], x) == \\\n        [(r1 + r2 + r3, 6), (r1*r2 + r1*r3 + r2*r3, -11), (r1*r2*r3, 6)]\n    assert viete(x**2 + 1, [r1, r2], x) == [(r1 + r2, 0), (r1*r2, 1)]\n    assert viete(x**3 + 1, [r1, r2, r3], x) == [(r1 + r2 + r3, 0), (r1*r2 + r1*r3 + r2*r3, 1), (r1*r2*r3, -1)]\n    assert viete(x**4 + 1, [r1, r2, r3, r4], x) == \\\n        [(r1 + r2 + r3 + r4, 0), (r1*r2 + r1*r3 + r1*r4 + r2*r3 + r2*r4 + r3*r4, 0),\n         (r1*r2*r3 + r1*r2*r4 + r1*r3*r4 + r2*r3*r4, 0), (r1*r2*r3*r4, -1)]\n    assert viete(a*x**2 + b*x + c, [r1, r2], x) == [(r1 + r2, -b/a), (r1*r2, c/a)]\n    assert viete(a*x**3 + b*x**2 + c*x + d, [r1, r2, r3], x) == \\\n        [(r1 + r2 + r3,"], "sample_106": ["    def test_different_aliases(self):\n        \"\"\"\n        Requesting different aliases should yield different instances.\n        \"\"\"\n        cache1 = caches['default']\n        cache2 = caches['other']\n\n        self.assertIsNot(cache1, cache2)\n"], "sample_312": ["    def test_add_squash_single_child(self):\n        node1 = Node(connector='AND')\n        node2 = Node(children=[('a', 1)])\n        result = node1.add(node2, 'AND', squash=True)\n        self.assertEqual(result, node2)\n        self.assertEqual(str(node1), \"(AND: ('a', 1))\")\n"], "sample_1022": ["compilation error"], "sample_905": ["compilation error"], "sample_493": ["    def test_aggregate_with_filter_on_related_object(self):\n        with CaptureQueriesContext(connection) as ctx:\n            aggregate = Publisher.objects.annotate(\n                avg_rating=Avg(\"book__rating\", filter=Q(book__pages__gt=500))\n            ).aggregate(avg_rating=Avg(\"avg_rating\"))\n        sql = ctx.captured_queries[0][\"sql\"].lower()\n        self.assertEqual(sql.count(\"select\"), 2, \"Subquery wrapping required\")\n        self.assertEqual(aggregate[\"avg_rating\"], 3.75)\n"], "sample_597": ["    def test_merge_dataset_update(self):\n        data = create_test_data()\n        ds1 = data[[\"var1\", \"var2\"]]\n        ds2 = data[[\"var3\"]]\n        ds3 = ds1.update(ds2)\n        assert ds3.identical(data)\n\n        ds3 = ds2.update(ds1)\n        assert ds3.identical(data)\n\n        ds1 = data.copy(deep=True)\n        ds2 = data.copy(deep=True)\n        ds1[\"var1\"][:, :5] = np.nan\n        ds2[\"var1\"][:, 5:] = np.nan\n        ds1[\"var2\"][:4, :] = np.nan\n        ds2[\"var2\"][4:, :] = np.nan\n        ds3 = ds1.update(ds2)\n        assert data.equals(ds3)\n\n        ds3 = ds2.update(ds1)\n        assert data.equals(ds3)\n\n        with pytest.raises(ValueError):\n            ds1.update(ds2.rename({\"var3\": \"var1\"}))\n\n        with raises_regex(ValueError, \"should be coordinates or not\"):\n            data.reset_coords().update(data)\n        with raises_regex(ValueError, \"should be coordinates or not\"):\n            data.update(data.reset_coords())\n"], "sample_1101": ["compilation error"], "sample_338": ["    def test_operation_with_no_suggested_name_and_initial_true(self):\n        class Migration(migrations.Migration):\n            initial = True\n            operations = [\n                migrations.RunSQL('SELECT 1 FROM person;'),\n            ]\n\n        migration = Migration('0001_initial', 'test_app')\n        self.assertEqual(migration.suggest_name(), 'initial')\n"], "sample_1156": ["compilation error"], "sample_645": ["def test_caplog_handles_nested_calls(caplog):\n    caplog.set_level(logging.INFO)\n    logger.info(\"Outer level\")\n\n    with caplog.at_level(logging.DEBUG):\n        logger.debug(\"Inner level 1\")\n        with caplog.at_level(logging.WARNING):\n            logger.warning(\"Inner level 2\")\n        logger.debug(\"Inner level 3\")\n\n    assert \"Outer level\" in caplog.text\n    assert \"Inner level 1\" in caplog.text\n    assert \"Inner level 2\" not in caplog.text\n    assert \"Inner level 3\" in caplog.text\n"], "sample_40": ["def test_spectral_density_equivalencies():\n    from astropy.units import u\n    from astropy.constants import c, h\n\n    # Test conversion between different spectral density units\n    nu = 143 * u.GHz\n    f_nu = 1 * u.Jy\n    f_lambda = f_nu.to(u.erg / (u.cm**2 * u.s * u.Angstrom))\n    assert_allclose(f_lambda.value, f_nu.to_value(u.erg / (u.cm**2 * u.s * u.Angstrom)))\n\n    # Test conversion with equivalencies\n    f_nu_equivalencies = u.spectral_density(nu)\n    f_lambda_equivalencies = f_nu.to(u.erg / (u.cm**2 * u.s * u.Angstrom), equivalencies=f_nu_equivalencies)\n    assert_allclose(f_lambda_equivalencies.value, f_lambda.value)\n\n    # Test conversion with different spectral density units\n    f_lambda_erg = f_lambda.to(u.erg / (u.cm**2 * u.s * u.Angstrom))\n    f_lambda_phot = f_lambda.to(u.photons / (u.cm**2 * u.s * u.Angstrom))\n    assert_allclose(f_lambda_erg.value, f_lambda.value)\n    assert_allclose(f_lambda_phot.value, f_lambda.to_value(u.photons / (u.cm**2 * u.s * u.Angstrom)))\n\n    # Test conversion with Planck's constant\n    f_nu_planck = f_nu.to(u.erg / (u.cm**2 * u.s * u.Hz), equivalencies=u.spectral_density(nu, h=h))\n    assert_allclose(f_nu_planck.value, f_nu.to_value(u.erg / (u.cm**2 * u.s * u.Hz)))\n\n    # Test conversion with speed of light\n    f_nu_speed = f_nu.to(u.erg / (u.cm**2 *"], "sample_22": ["def test_matrix_product():\n    m1 = rotation_matrix(45 * u.deg, \"x\")\n    m2 = rotation_matrix(45 * u.deg, \"y\")\n    m3 = rotation_matrix(45 * u.deg, \"z\")\n    \n    result = matrix_product(m1, m2, m3)\n    expected = rotation_matrix(90 * u.deg, \"z\")\n    assert_allclose(result, expected, atol=1e-12)\n\n    # Test with stacks of matrices\n    m1_stack = np.tile(m1, (2, 1, 1))\n    m2_stack = np.tile(m2, (2, 1, 1))\n    m3_stack = np.tile(m3, (2, 1, 1))\n    result_stack = matrix_product(m1_stack, m2_stack, m3_stack)\n    expected_stack = np.tile(expected, (2, 1, 1))\n    assert_allclose(result_stack, expected_stack, atol=1e-12)\n"], "sample_234": ["    def test_union_with_different_models(self):\n        class OtherModel(models.Model):\n            id = models.AutoField(primary_key=True)\n            value = models.IntegerField()\n\n        OtherModel.objects.create(value=10)\n        qs1 = Number.objects.filter(num=1).values('num')\n        qs2 = OtherModel.objects.values('value')\n        self.assertEqual(list(qs1.union(qs2).order_by('num')), [1, 10])\n"], "sample_1127": ["compilation error"], "sample_744": ["def test_power_transformer_y_axis():\n    X = np.abs(X_2d)\n    pt = PowerTransformer(method='box-cox')\n    pt.fit(X)\n\n    # Test that y_axis argument works as expected\n    for axis in [0, 1]:\n        X_trans = pt.transform(X, axis=axis)\n        assert X_trans.shape[axis] == X.shape[axis]\n        assert X_trans.shape[1 - axis] == 1\n"], "sample_508": ["        def set_myparam3(self, val):\n            pass\n"], "sample_220": ["    def test_delete_cookie_path(self):\n        response = HttpResponse()\n        response.set_cookie('c', path='/path/to/cookie')\n        response.delete_cookie('c', path='/another/path')\n        self.assertEqual(response.cookies['c']['path'], '/')\n"], "sample_561": ["def test_marker_get_size(marker, size, expected):\n    new_marker = marker.scaled(size)\n    assert new_marker.get_size() == expected\n"], "sample_470": ["    def test_keep_lazy_with_lazy_args(self):\n        @lazy(int)\n            return x + 1\n\n        @lazy(int)\n            return x * 2\n\n        @keep_lazy(int)\n            return add_one(x) + double(y)\n\n        self.assertEqual(sum_and_double(1, 2), 7)\n"], "sample_680": ["compilation error"], "sample_851": ["def test_regression_multioutput_invalid_multioutput():\n    y_true = [[1, 2], [2.5, -1], [4.5, 3], [5, 7]]\n    y_pred = [[1, 1], [2, -1], [5, 4], [5, 6.5]]\n\n    with pytest.raises(ValueError,\n                       match=\"Allowed 'multioutput' string values are 'raw_values', 'uniform_average', or 'variance_weighted'. You provided multioutput='invalid_value'\"):\n        r2_score(y_true, y_pred, multioutput='invalid_value')\n"], "sample_150": ["    def test_check_migrations_no_migrations(self, mock_migration_plan):\n        mock_migration_plan.return_value = []\n        from django.core.management.base import BaseCommand\n        command = BaseCommand()\n        command.check_migrations()\n        self.assertFalse(self.stdout.getvalue())\n\n\n\n"], "sample_319": ["    def test_operation_with_custom_name(self):\n        class Migration(migrations.Migration):\n            operations = [\n                migrations.CreateModel(\n                    name=\"Person\",\n                    fields=[],\n                    options={\"custom_name\": \"my_person\"},\n                )\n            ]\n\n        migration = Migration(\"some_migration\", \"test_app\")\n        self.assertEqual(migration.suggest_name(), \"my_person\")\n"], "sample_542": ["def test_text_bbox_with_transform():\n    fig, ax = plt.subplots()\n    text = ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    bbox = text.get_bbox()\n    assert bbox.width > 0\n    assert bbox.height > 0\n"], "sample_28": ["    def test_header_comment_order(self):\n        h = fits.Header()\n        h.set(\"COMMENT\", \"This is a comment\")\n        h.set(\"COMMENT\", \"This is another comment\")\n        assert h[\"COMMENT\"] == [\"This is a comment\", \"This is another comment\"]\n        h.set(\"HISTORY\", \"This is a history comment\")\n        assert h[\"COMMENT\"] == [\"This is a comment\", \"This is another comment\"]\n        assert h[\"HISTORY\"] == [\"This is a history comment\"]\n"], "sample_1021": ["def test_quaternion_multiplication():\n    q1 = Quaternion(1, 2, 3, 4)\n    q2 = Quaternion(5, 6, 7, 8)\n    q3 = Quaternion(9, 10, 11, 12)\n\n    assert q1 * q2 == Quaternion(-26, 4, 50, 2)\n    assert q2 * q1 == Quaternion(-26, 4, 50, 2)\n    assert (q1 * q2) * q3 == q1 * (q2 * q3) \n    assert q1 * q1 == Quaternion(-15, 0, 0, 0)\n    assert q1 * Quaternion(0, 0, 0, 0) == Quaternion(0, 0, 0, 0)\n    assert q1 * 2 == Quaternion(2*q1.a, 2*q1.b, 2*q1.c, 2*q1.d)\n    assert 2 * q1 == Quaternion(2*q1.a, 2*q1.b, 2*q1.c, 2*q1.d)\n\n\n\n"], "sample_299": ["    def test_relative_path(self):\n        with self.settings(CACHES={\n            'default': {\n                'BACKEND': 'django.core.cache.backends.filebased.FileBasedCache',\n                'LOCATION': 'cache',\n            },\n        }):\n            self.assertEqual(check_file_based_cache_is_absolute(None), [\n                Warning(\n                    f\"Your 'default' cache LOCATION path is relative. Use an \"\n                    f\"absolute path instead.\",\n                    id='caches.W003',\n                ),\n            ])\n"], "sample_900": ["def test_validation_fraction():\n    # Test validation_fraction parameter.\n    X = X_digits_binary[:100]\n    y = y_digits_binary[:100]\n\n    for fraction in [0.1, 0.2, 0.3, 0.5]:\n        mlp = MLPClassifier(hidden_layer_sizes=5, solver='lbfgs',\n                            validation_fraction=fraction, random_state=1)\n        with ignore_warnings(category=ConvergenceWarning):\n            mlp.fit(X, y)\n        assert mlp.validation_scores_ is not None\n        assert len(mlp.validation_scores_) == mlp.n_iter_\n\n\n\n"], "sample_915": ["    def decorated_meth(cls):\n        \"\"\"Decorated docstring.\"\"\"\n        return cls.meth()\n"], "sample_710": ["    def test_do_cleanups_with_multiple_addcleanup(pytester: Pytester) -> None:\n        testpath = pytester.makepyfile(\n            \"\"\"\n            import unittest\n            class MyTestCase(unittest.TestCase):\n                values = []\n                        self.values.append(1)\n                        self.values.append(2)\n                    self.addCleanup(cleanup1)\n                    self.addCleanup(cleanup2)\n                    pass\n                assert MyTestCase.values == [2, 1]\n            \"\"\"\n        )\n        reprec = pytester.inline_run(testpath)\n        passed, skipped, failed = reprec.countoutcomes()\n        assert failed == 0\n        assert passed == 2\n"], "sample_649": ["        def test_logger_propagation_to_parent_with_disabled_child(caplog):\n            parent_logger = logging.getLogger(\"parent\")\n            child_logger = parent_logger.getChild(\"child\")\n            child_logger.setLevel(logging.ERROR)\n            with caplog.at_level(logging.DEBUG):\n                parent_logger.warning(\"some parent logger message\")\n                child_logger.warning(\"some child logger message\")\n                assert len(caplog.record_tuples) == 1\n                assert caplog.record_tuples[0][0] == \"parent\"\n                assert caplog.record_tuples[0][2] == \"some parent logger message\""], "sample_381": ["    def test_operation_with_custom_name(self):\n        class Migration(migrations.Migration):\n            operations = [\n                migrations.CreateModel(\n                    name='CustomModel',\n                    fields=[],\n                ),\n            ]\n\n        migration = Migration('some_migration', 'test_app')\n        self.assertEqual(migration.suggest_name(), 'custom_model')\n"], "sample_2": ["def test_read_image_with_invalid_wcs():\n    # Test reading an image with an invalid WCS header.\n    # This should raise an error.\n    data_file = get_pkg_data_filename('data/invalid_wcs.fits')\n    with pytest.raises(astropy.wcs.WCSError):\n        CCDData.read(data_file)\n"], "sample_1060": ["def test_indexed_base():\n    p = IndexedBase(\"p\")\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n"], "sample_271": ["    def test_snapshot_files_handles_new_files(self):\n        new_file = self.ensure_file(self.tempdir / 'new_file.py')\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file, new_file]):\n            snapshot1 = dict(self.reloader.snapshot_files())\n            self.assertIn(self.existing_file, snapshot1)\n            self.assertIn(new_file, snapshot1)\n"], "sample_520": ["def test_text3d_alignment():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection=\"3d\")\n    text = ax.text3d(0.5, 0.5, 0.5, 'Hello',\n                     horizontalalignment='center',\n                     verticalalignment='center',\n                     zdir='z')\n    assert text.get_position_3d() == (0.5, 0.5, 0.5)\n\n    text = ax.text3d(0.5, 0.5, 0.5, 'Hello',\n                     horizontalalignment='left',\n                     verticalalignment='top',\n                     zdir='z')\n    assert text.get_position_3d() == (0.5, 0.5, 0.5)\n\n    text = ax.text3d(0.5, 0.5, 0.5, 'Hello',\n                     horizontalalignment='right',\n                     verticalalignment='bottom',\n                     zdir='z')\n    assert text.get_position_3d() == (0.5, 0.5, 0.5)\n"], "sample_1028": ["def test_issue_14392_continued():\n    assert (cos(zoo)**2).as_real_imag() == (nan, nan)\n    assert (tan(zoo)**2).as_real_imag() == (nan, nan)\n    assert (exp(zoo)**2).as_real_imag() == (nan, nan)\n    assert (log(zoo)**2).as_real_imag() == (nan, nan)\n"], "sample_881": ["def test_label_ranking_avg_precision_score_with_ties():\n    # Test handling of ties in y_true\n    y_true = np.array([[1, 0, 1], [0, 1, 0], [1, 1, 0]])\n    y_score = np.array([[0.5, 0.9, 0.6], [0.2, 0.8, 0.1], [0.7, 0.3, 0.2]])\n    result = label_ranking_average_precision_score(y_true, y_score)\n    assert result == pytest.approx(0.6666666666666666)\n"], "sample_68": ["    def test_cleanse_setting_nested_dict(self):\n        data = {\n            'FOOBAR': 'TEST',\n            'PASSWORD': 'super_secret',\n            'OTHER': {'SECRET': 'dont_show_this'}\n        }\n        cleaned_data = cleanse_setting_recursive(data)\n        self.assertEqual(cleaned_data['FOOBAR'], 'TEST')\n        self.assertEqual(cleaned_data['PASSWORD'], CLEANSED_SUBSTITUTE)\n        self.assertEqual(cleaned_data['OTHER'], {'SECRET': CLEANSED_SUBSTITUTE})\n"], "sample_112": ["    def test_cell_count(self):\n        inline_admin_form = self.create_inline_admin_form()\n        cell_count = cell_count(inline_admin_form)\n        self.assertEqual(cell_count, 5)  # Assuming 4 fields + delete checkbox\n"], "sample_166": ["    def test_get_random_string_length(self):\n        self.assertEqual(get_random_string(length=20), ''.join(secrets.choice(\n            'abcdefghijklmnopqrstuvwxyz'\n            'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n        ) for i in range(20)))\n"], "sample_93": ["    def test_subquery_annotation_with_distinct(self):\n        distinct_authors_qs = Author.objects.filter(\n            pk=OuterRef('pk')\n        ).values('name').annotate(\n            count=Count('id', distinct=True)\n        )\n        publisher_qs = Publisher.objects.annotate(\n            distinct_author_count=Subquery(distinct_authors_qs)\n        ).annotate(total=Count('book'))\n        with self.assertNumQueries(1) as ctx:\n            list(publisher_qs)\n        self.assertEqual(ctx[0]['sql'].count('SELECT'), 2)\n        self.assertEqual(dict(publisher_qs), {\n            1: {'distinct_author_count': 1, 'total': 1},\n            2: {'distinct_author_count': 2, 'total': 2},\n            3: {'distinct_author_count': 3, 'total': 3},\n            4: {'distinct_author_count': 1, 'total': 1},\n        })\n"], "sample_284": ["    def test_manifest_file_permissions(self):\n        call_command('collectstatic', interactive=False, verbosity=0)\n        static_root = Path(settings.STATIC_ROOT)\n        manifest_path = static_root / 'manifest.json'\n        manifest_mode = manifest_path.stat().st_mode & 0o777\n        self.assertEqual(manifest_mode, 0o644 & ~self.umask)\n"], "sample_95": ["    def test_cache_control_decorator(self):\n        @cache_control(private=True, max_age=3600, must_revalidate=True)\n            return HttpResponse()\n        r = a_view(HttpRequest())\n        self.assertEqual(\n            set(r['Cache-Control'].split(', ')),\n            {'private', 'max-age=3600', 'must-revalidate'},\n        )\n\n\n"], "sample_487": ["    def test_actions_with_permissions(self):\n        @admin.action(permissions=[\"custom_permission\"])\n            pass\n\n        class BandAdmin(ModelAdmin):\n            actions = (custom_action,)\n\n        self.assertIsInvalid(\n            BandAdmin,\n            Band,\n            \"BandAdmin must define a has_custom_permission() method for the \"\n            \"custom_action action.\",\n            id=\"admin.E129\",\n        )\n"], "sample_732": ["compilation error"], "sample_375": ["    def test_proxy_with_fk(self):\n        A = self.create_model(\"A\")\n        B = self.create_model(\"B\", bases=(A,), proxy=True)\n        C = self.create_model(\"C\", foreign_keys=[models.ForeignKey('B', models.CASCADE)])\n        self.assertRelated(A, [B, C])\n        self.assertRelated(B, [C])\n        self.assertRelated(C, [B])\n"], "sample_975": ["def test_unrad_trivial():\n    from sympy import sqrt, symbols\n    x = symbols('x')\n    eq = sqrt(x) + 2\n    eq, cov = unrad(eq)\n    assert eq == x + 4\n    assert cov is None\n"], "sample_138": ["    def test_manifest_cache_integrity(self):\n        # Create a file that will be hashed.\n        with open(self._get_filename_path('test.css'), 'w') as f:\n            f.write('body { background-color: red; }')\n\n        # Collect static files, this will create the manifest.\n        self.run_collectstatic()\n\n        # Read the manifest and assert it contains the hashed filename.\n        manifest = storage.staticfiles_storage.load_manifest()\n        self.assertIn(\n            self.hashed_file_path('test.css'),\n            manifest,\n        )\n\n        # Modify the file content.\n        with open(self._get_filename_path('test.css'), 'w') as f:\n            f.write('body { background-color: blue; }')\n\n        # Collect static files again, this should update the manifest.\n        self.run_collectstatic()\n\n        # Read the manifest again and assert the hashed filename is different.\n        manifest = storage.staticfiles_storage.load_manifest()\n        self.assertIn(\n            self.hashed_file_path('test.css'),\n            manifest,\n        )\n        self.assertNotEqual(\n            manifest[self.hashed_file_path('test.css')],\n            manifest[self.hashed_file_path('test.css')]\n        )\n"], "sample_1033": ["def test_issue_14392_continued():\n    assert (cos(zoo)**2).as_real_imag() == (nan, nan)\n    assert (tan(zoo)**2).as_real_imag() == (nan, nan)\n    assert (exp(zoo)).as_real_imag() == (nan, nan)\n    assert (log(zoo)).as_real_imag() == (nan, nan)\n"], "sample_1190": ["def test_issue_23057():\n    from sympy.physics.units import Quantity, meter, second\n    q1 = Quantity('q1')\n    q2 = Quantity('q2')\n    SI.set_quantity_dimension(q1, meter/second)\n    SI.set_quantity_dimension(q2, meter/second)\n    q1.set_global_relative_scale_factor(1, meter/second)\n    q2.set_global_relative_scale_factor(2, meter/second)\n    expr = q1 + q2\n    assert SI._collect_factor_and_dimension(expr) == (3, meter/second)\n"], "sample_51": ["    def test_iso8601_duration(self):\n        test_values = (\n            ('P1D', timedelta(days=1)),\n            ('P1DT2H', timedelta(days=1, hours=2)),\n            ('P1DT2H30M', timedelta(days=1, hours=2, minutes=30)),\n            ('P1DT2H30M15S', timedelta(days=1, hours=2, minutes=30, seconds=15)),\n            ('P1DT2H30M15.123S', timedelta(days=1, hours=2, minutes=30, seconds=15, microseconds=123000)),\n            ('PT2H30M15S', timedelta(hours=2, minutes=30, seconds=15)),\n            ('PT2H30M15.123S', timedelta(hours=2, minutes=30, seconds=15, microseconds=123000)),\n            ('P-1D', timedelta(days=-1)),\n            ('P-1DT-2H', timedelta(days=-1, hours=-2)),\n            ('P-1DT-2H-30M', timedelta(days=-1, hours=-2, minutes=-30)),\n            ('P-1DT-2H-30M-15S', timedelta(days=-1, hours=-2, minutes=-30, seconds=-15)),\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self.assertEqual(parse_duration(source), expected)\n"], "sample_773": ["def test_logistic_regression_path_coefs_sparse():\n    # Make sure that logistic_regression_path works with sparse input data\n    n_samples = 500\n    n_features = 1000\n    X = sp.csr_matrix(np.random.rand(n_samples, n_features))\n    y = np.random.randint(0, 2, n_samples)\n    Cs = np.logspace(-3, 2, 4)\n    coefs, _, _ = _logistic_regression_path(X, y, penalty='l1', Cs=Cs,\n                solver='saga', random_state=0, multi_class='ovr')\n    assert coefs.shape == (len(Cs), n_features)\n"], "sample_134": ["    def test_serialize_custom_field(self):\n        class MyCustomField(models.Field):\n                super().__init__(**kwargs)\n\n                return 'MyCustomFieldType'\n\n                return 'MyCustomFieldType'\n\n                return forms.CharField(**kwargs)\n\n        field = MyCustomField()\n        string, imports = MigrationWriter.serialize(field)\n        self.assertEqual(string, \"MyCustomField()\")\n        self.assertEqual(imports, {'from migrations.test_writer import MyCustomField'})\n"], "sample_584": ["    def test_auto_combine_with_multiple_coords(self):\n        objs = [Dataset({'a': ('x', [0]), 'b': ('y', [0])},\n                        coords={'x': ('x', [1]), 'y': ('y', [0, 1])}),\n                Dataset({'a': ('x', [1]), 'b': ('y', [1])},\n                        coords={'x': ('x', [2]), 'y': ('y', [1, 2])})]\n        with pytest.warns(FutureWarning, match=\"`auto_combine`\"):\n            auto_combine(objs)\n"], "sample_575": ["    def test_label_formatter_with_custom_format(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%b %Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"Sep 1972\"\n"], "sample_452": ["    def test_references_field_by_through_reverse(self):\n        operation = FieldOperation(\n            \"Model\", \"field\", models.ManyToManyField(\"Other\", through=\"Through\")\n        )\n        self.assertIs(\n            operation.references_field(\"Through\", \"reverse_field\", \"migrations\"), True\n        )\n        self.assertIs(\n            operation.references_field(\"Missing\", \"reverse_field\", \"migrations\"), False\n        )\n"], "sample_894": ["def test_sparse_data_with_missing_values(monkeypatch):\n    from sklearn.ensemble import RandomForestClassifier\n    from sklearn.datasets import make_classification\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.impute import SimpleImputer\n\n    # Create a dataset with missing values\n    X, y = make_classification(n_samples=100, n_features=20, random_state=0)\n    X_with_missing = X.copy()\n    X_with_missing[::2, 1] = np.nan\n\n    # Impute missing values\n    imputer = SimpleImputer(strategy='mean')\n    X_with_missing = imputer.fit_transform(X_with_missing)\n\n    # Scale the data\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X_with_missing)\n\n    # Create a RandomForestClassifier instance\n    clf = RandomForestClassifier(n_estimators=10, random_state=0)\n\n    # Test with sparse data\n    clf.fit(csr_matrix(X_scaled), y)\n\n    # Test with dense data\n    clf.fit(X_scaled, y)\n\n    # Assert that the model fits successfully\n    assert clf.n_features_ == X_scaled.shape[1]\n"], "sample_1097": ["def test_block_collapse_irregular():\n    A = MatrixSymbol('A', 2, 3)\n    B = MatrixSymbol('B', 3, 2)\n    C = MatrixSymbol('C', 2, 2)\n    D = MatrixSymbol('D', 2, 3)\n    X = BlockMatrix([[A, B], [C, D]])\n    assert block_collapse(X).shape == (4, 5)\n    assert block_collapse(X).blockshape == (2, 2)\n\n    assert block_collapse(X*X).shape == (4, 5)\n    assert block_collapse(X*X).blockshape == (2, 2)\n\n\n\n"], "sample_137": ["    def test_replace_named_groups(self):\n        self.assertEqual(replace_named_groups('^(?P<a>\\w+)/b/(\\w+)$'), '^<a>/b/(\\w+)$')\n        self.assertEqual(replace_named_groups('^(?P<a>\\w+)/b/(?P<c>\\w+)/$'), '^<a>/b/<c>/$')\n        self.assertEqual(replace_named_groups('^(?P<a>\\w+)/b/(\\w+)'), '^<a>/b/(\\w+)')\n        self.assertEqual(replace_named_groups('^(?P<a>\\w+)/b/(?P<c>\\w+)'), '^<a>/b/<c>')\n        self.assertEqual(replace_named_groups('^a/(?P<b>\\w+)$'), '^a/<b>$')\n        self.assertEqual(replace_named_groups('^a/(?P<b>\\w+)/b/'), '^a/<b>/b/')\n"], "sample_998": ["def test_issue_14671():\n    from sympy.tensor.tensor import Tensor\n    t = Tensor('t', indices='ij')\n    assert latex(t) == r't_{ij}'\n    t = Tensor('t', indices='ijk')\n    assert latex(t) == r't_{ijk}'\n"], "sample_1125": ["def test_differential_operator():\n    from sympy.physics.quantum.state import Wavefunction\n    from sympy.physics.quantum.operator import DifferentialOperator\n    from sympy import Symbol, Function, Derivative\n\n    x = Symbol('x')\n    f = Function('f')\n    d = DifferentialOperator(Derivative(f(x), x), f(x))\n    w = Wavefunction(x**2, x)\n    assert qapply(d*w) == Wavefunction(2*x, x)\n"], "sample_315": ["    def test_url_with_language_code_in_path(self):\n        response = self.client.get('/en/account/register/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.headers['content-language'], 'en')\n        self.assertEqual(response.context['LANGUAGE_CODE'], 'en')\n\n        response = self.client.get('/nl/profiel/registreren/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.headers['content-language'], 'nl')\n        self.assertEqual(response.context['LANGUAGE_CODE'], 'nl')\n\n        response = self.client.get('/pt-br/conta/registre-se/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.headers['content-language'], 'pt-br')\n        self.assertEqual(response.context['LANGUAGE_CODE'], 'pt-br')\n"], "sample_949": ["def test_man_show_urls(app, status, warning):\n    app.config.man_show_urls = True\n    app.build()\n    content = (app.outdir / 'python.1').read_text()\n    assert r'\\fIhttps://www.sphinx-doc.org/\\fP' in content\n"], "sample_1146": ["def test_latex_unicode_symbols():\n    from sympy import symbols, pi, exp, sqrt, oo\n    x, y = symbols('x y')\n    assert latex(pi) == r'\\pi'\n    assert latex(exp(1)) == r'e'\n    assert latex(sqrt(2)) == r'\\sqrt{2}'\n    assert latex(oo) == r'\\infty'\n    assert latex(x**2 + y**2) == r'x^{2} + y^{2}'\n    assert latex(x**2 + y**2, use_unicode=False) == r'x^{2} + y^{2}'\n"], "sample_194": ["    def test_opclasses_length(self):\n        msg = 'UniqueConstraint.fields and UniqueConstraint.opclasses must have the same number of elements.'\n        with self.assertRaisesMessage(ValueError, msg):\n            models.UniqueConstraint(\n                name='uniq_opclasses',\n                fields=['field1', 'field2'],\n                opclasses=['opclass1'],\n            )\n"], "sample_344": ["    def test_proxy_with_fk(self):\n        A = self.create_model(\"A\")\n        B = self.create_model(\"B\", bases=(A,), proxy=True)\n        C = self.create_model(\"C\", foreign_keys=[models.ForeignKey('B', models.CASCADE)])\n        self.assertRelated(A, [B, C])\n        self.assertRelated(B, [C])\n        self.assertRelated(C, [B])\n"], "sample_523": ["def test_legend_title_fontsize_with_units():\n    fig, ax = plt.subplots()\n    ax.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize='12pt')\n    leg = plt.legend(title='Aardvark', title_fontsize=12)\n    assert leg.get_title().get_fontsize() == 12\n"], "sample_882": ["def test_mlp_validation_fraction_with_partial_fit():\n    \"\"\"Check that validation fraction works correctly with partial_fit.\"\"\"\n    mlp = MLPClassifier(\n        hidden_layer_sizes=(5,), random_state=0, validation_fraction=0.2, max_iter=10\n    )\n    X = X_digits[:100]\n    y = y_digits[:100]\n    X_train = X[:80]\n    y_train = y[:80]\n    X_val = X[80:]\n    y_val = y[80:]\n\n    mlp.partial_fit(X_train, y_train)\n    mlp.partial_fit(X_train, y_train)\n    mlp.partial_fit(X_train, y_train)\n\n    with pytest.warns(UserWarning):\n        mlp.partial_fit(X_val, y_val)\n\n    assert len(mlp.validation_scores_) > 0\n"], "sample_931": ["def test_module_index_with_options(app):\n    text = (\".. py:module:: docutils\\n\"\n            \".. py:module:: sphinx\\n\"\n            \".. py:module:: sphinx\\n\"\n            \"   :noindex:\\n\"\n            \".. py:module:: sphinx.config\\n\")\n    restructuredtext.parse(app, text)\n    index = PythonModuleIndex(app.env.get_domain('py'))\n    assert index.generate() == (\n        [('d', [IndexEntry('docutils', 0, 'index', 'module-docutils', '', '', '')]),\n         ('s', [IndexEntry('sphinx', 1, 'index', 'module-sphinx', '', '', '')])],\n        False\n    )\n"], "sample_105": ["    def test_template_params_with_kwargs(self):\n        \"\"\"A generic template view passes kwargs as context.\"\"\"\n        response = self.client.get('/template/simple/bar/baz/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.context['foo'], 'bar')\n        self.assertEqual(response.context['baz'], 'baz')\n        self.assertIsInstance(response.context['view'], View)\n"], "sample_162": ["    def test_custom_locale_paths_with_app_locale(self):\n        \"\"\"\n        * translations for an app containing a locale folder are stored in that folder\n        * translations outside of that app are in LOCALE_PATHS[0]\n        \"\"\"\n        with override_settings(LOCALE_PATHS=[os.path.join(self.test_dir, 'project_locale'),\n                                                os.path.join(self.test_dir, 'app_with_locale', 'locale')]):\n            management.call_command('makemessages', locale=[LOCALE], verbosity=0)\n            project_de_locale = os.path.join(\n                self.test_dir, 'project_locale', 'de', 'LC_MESSAGES', 'django.po')\n            app_de_locale = os.path.join(\n                self.test_dir, 'app_with_locale', 'locale', 'de', 'LC_MESSAGES', 'django.po')\n            self.assertTrue(os.path.exists(project_de_locale))\n            self.assertTrue(os.path.exists(app_de_locale))\n\n            with open(project_de_locale) as fp:\n                po_contents = fp.read()\n                self.assertMsgId('This app has no locale directory', po_contents)\n                self.assertMsgId('This is a project-level string', po_contents)\n            with open(app_de_locale) as fp:\n                po_contents = fp.read()\n                self.assertMsgId('This app has a locale directory', po_contents)\n"], "sample_935": ["        def assert_classes(self, expected_classes):\n            assert self.classes == expected_classes, (\n                f\"Expected classes for role '{self.name}' to be {expected_classes}, \"\n                f\"but found {self.classes}\"\n            )\n            for tag, expected_tag_classes in expected_classes.items():\n                assert self.content_classes.get(tag, set()) == expected_tag_classes, (\n                    f\"Expected classes for role '{self.name}' with tag '{tag}' to be \"\n                    f\"{expected_tag_classes}, but found {self.content_classes.get(tag, set())}\"\n                )\n"], "sample_1070": ["def test_log_issue_11637():\n    x = Symbol('x', positive=True)\n    assert log(x**x).expand() == x*log(x)\n    assert log(x**x, evaluate=False).expand() == x*log(x)\n"], "sample_372": ["    def test_lookahead_and_lookbehind_together(self):\n        test_urls = [\n            ('/lookahead+/lookbehind+/a-city/', {'city': 'a-city'}),\n            ('/lookbehind+/lookahead+/a-city/', {'city': 'a-city'}),\n        ]\n        for test_url, kwargs in test_urls:\n            with self.subTest(url=test_url):\n                self.assertEqual(resolve(test_url).kwargs, kwargs)\n"], "sample_174": ["    def test_sql_flush_with_tables(self):\n        Author.objects.create(name='John Doe')\n        Book.objects.create(title='My Book', author=Author.objects.get(name='John Doe'))\n\n        with transaction.atomic():\n            sql_list = connection.ops.sql_flush(no_style(), ['auth_user', 'auth_group', 'auth_permission', 'auth_user_groups', 'auth_user_permissions', 'contenttypes', 'sessions', 'django_migrations', 'django_content_type', 'django_session', 'books', 'authors'])\n            connection.ops.execute_sql_flush(sql_list)\n\n        self.assertEqual(Author.objects.count(), 0)\n        self.assertEqual(Book.objects.count(), 0)\n"], "sample_342": ["    def test_autocomplete_with_related_model_search_fields(self):\n        class RelatedModelAdmin(admin.ModelAdmin):\n            search_fields = ['name']\n\n        with model_admin(Employee, RelatedModelAdmin):\n            self.selenium.get(self.live_server_url + reverse('autocomplete_admin:admin_views_workhour_add'))\n            elem = self.selenium.find_element_by_css_selector('.select2-selection')\n            elem.click()  # Open the autocomplete dropdown.\n            results = self.selenium.find_element_by_css_selector('.select2-results')\n            self.assertTrue(results.is_displayed())\n            search = self.selenium.find_element_by_css_selector('.select2-search__field')\n            search.send_keys('Frida')\n            with self.select2_ajax_wait():\n                results = self.selenium.find_elements_by_css_selector('.select2-results__option')\n                self.assertEqual(len(results), 1)\n            search.send_keys(Keys.RETURN)\n"], "sample_1076": ["def test_sympy_printing_of_tensor_nodes():\n    from sympy.tensor import IndexedBase, TensorIndexType\n    from sympy.codegen.matrix_nodes import MatrixSolve\n\n    x = IndexedBase('x')\n    y = IndexedBase('y')\n    i = TensorIndexType('i')\n    j = TensorIndexType('j')\n    expr = MatrixSolve(x[i, j] + y[i, j], x[i, j])\n    prntr = SymPyPrinter()\n    assert prntr.doprint(expr) == 'sympy.solve(x[i, j] + y[i, j], x[i, j])'\n"], "sample_622": ["def test_decode_cf_variable_with_invalid_units(self) -> None:\n    var = Variable([\"t\"], [1, 2, 3], {\"units\": \"invalid\"})\n    with pytest.raises(ValueError, match=r\"unable to decode units\"):\n        conventions.decode_cf_variable(\"t\", var)\n"], "sample_165": ["    def test_modelchoicefield_empty_label(self):\n        # ModelChoiceField\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': 'INVALID CHOICE',\n        }\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(),\n                             empty_label=None,\n                             error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID CHOICE'], f.clean, '4')\n\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(),\n                             empty_label='---------',\n                             error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID CHOICE'], f.clean, '4')\n"], "sample_853": ["def test_transform_target_regressor_pipeline():\n    X, y = friedman\n    pipeline = Pipeline([\n        ('transformer', StandardScaler()),\n        ('regressor', LinearRegression())\n    ])\n    ttr = TransformedTargetRegressor(regressor=pipeline)\n    ttr.fit(X, y)\n    assert isinstance(ttr.transformer_, StandardScaler)\n    assert isinstance(ttr.regressor_, Pipeline)\n    assert isinstance(ttr.regressor_.steps[1][1], LinearRegression)\n"], "sample_501": ["def test_legend_title_fontsize_from_rcParams():\n    # test the legend title fontsize from rcParams\n    mpl.rcParams['legend.title_fontsize'] = 14\n    fig, ax = plt.subplots()\n    ax.plot(range(10))\n    leg = ax.legend(title='Aardvark')\n    assert leg.get_title().get_fontsize() == 14\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg = ax.legend(title='Aardvark')\n    assert leg.get_title().get_fontsize() == mpl.rcParams['font.size']\n"], "sample_961": ["def test_python_python_use_unqualified_type_names_enabled(app, status, warning):\n    app.build()\n    content = (app.outdir / 'index.html').read_text()\n    assert ('<span class=\"n\"><span class=\"pre\">Name</span></span>' in content)\n    assert ('<span class=\"n\"><span class=\"pre\">Age</span></span>' in content)\n    assert ('<p><strong>name</strong> (<span class=\"n\"><span class=\"pre\">Name</span></span>) \u2013 blah blah</p>' in content)\n    assert '<p><strong>age</strong> (<span class=\"n\"><span class=\"pre\">Age</span></span>) \u2013 blah blah</p>' in content\n"], "sample_1111": ["def test_constant():\n    x = Symbol('x')\n    lines = [\n        '      1 |-------------------------------------------------------',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '    0.4 |-------------------------------------------------------',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '   -0.2 |_______________________________________________________',\n        '         -10                        0                          10'\n    ]\n    assert lines == list(textplot_str(2, -10, 10))\n"], "sample_357": ["    def test_operation_with_no_suggested_name_and_initial_true(self):\n        class Migration(migrations.Migration):\n            initial = True\n            operations = [\n                migrations.RunSQL('SELECT 1 FROM person;'),\n            ]\n\n        migration = Migration('0001_initial', 'test_app')\n        self.assertEqual(migration.suggest_name(), 'initial')\n"], "sample_1177": ["def test_issue_22189_continued():\n    x = Symbol('x')\n    for a in (sqrt(7 - 2*x) + 2, 1 + x):\n        assert Abs(a) - Abs(-a) == 0, a\n"], "sample_635": ["    def test_missing_return_type_docstring_sphinx(self) -> None:\n        \"\"\"Example of a function missing return type documentation in a Sphinx style docstring\n        \"\"\"\n        node = astroid.extract_node(\n            \"\"\"\n        class Foo(object):\n                '''docstring ...\n\n                :param arg: An argument.\n                :type arg: int\n                '''\n                pass\n        \"\"\"\n        )\n        with self.assertAddsMessages(\n            MessageTest(msg_id=\"missing-return-type-doc\", node=node.body[0])\n        ):\n            self.checker.visit_functiondef(node.body[0])\n"], "sample_1027": ["def test_issue_13569():\n    # Test for issue 13569: Poly.subs() should handle\n    # substitutions with multiple variables correctly\n    p = Poly(x**2 + y**2, x, y)\n    assert p.subs({x: 2*z, y: z}) == Poly(5*z**2, z)\n"], "sample_164": ["    def test_server_formatter_uses_request_data(self):\n        server_time = '2016-09-25 10:20:30'\n        log_msg = 'log message'\n        request = RequestFactory().get('/')\n        request.META['REMOTE_ADDR'] = '127.0.0.1'\n        logger = logging.getLogger('django.server')\n\n        @contextmanager\n            old_stream = logger.handlers[0].stream\n            new_stream = StringIO()\n            logger.handlers[0].stream = new_stream\n            yield new_stream\n            logger.handlers[0].stream = old_stream\n\n        with patch_django_server_logger() as logger_output:\n            logger.info(log_msg, extra={'server_time': server_time, 'request': request})\n            self.assertIn(f'[{server_time}] {log_msg} (internal)', logger_output.getvalue())\n"], "sample_803": ["def test_ranking_loss_with_sample_weight():\n    y_true = np.array([[1, 0, 0, 0], [1, 0, 0, 1], [0, 0, 0, 0]],\n                      dtype=np.bool)\n    y_score = np.array([[0.3, 0.4, 0.2, 0.1], [0.1, 0.2, 0.3, 0.4],\n                        [0.4, 0.3, 0.2, 0.1]])\n    sample_weight = np.array([1.0, 1.0, 0.0])\n    expected_loss = (0.5 * 1 + 0.75 * 1 + 0 * 0) / (1 + 1 + 0)\n    assert_almost_equal(label_ranking_loss(y_true, y_score,\n                                          sample_weight=sample_weight),\n                        expected_loss)\n"], "sample_1029": ["def test_Reals():\n    sT(S.Reals, \"Reals\")\n"], "sample_355": ["    def test_authenticate_with_inactive_user_and_password_hashing(self):\n        \"\"\"\n        Inactive users may authenticate with the AllowAllUsersModelBackend\n        even if password hashing is enabled.\n        \"\"\"\n        from django.contrib.auth.hashers import make_password\n        self.user.password = make_password(self.user.password)\n        self.user.save()\n        self.assertFalse(self.user.is_active)\n        self.assertEqual(authenticate(**self.user_credentials), self.user)\n"], "sample_630": ["def test_get_annotation_assignattr(init_method, label):\n    \"\"\"AssignAttr\"\"\"\n    assign = rf\"\"\"\n        class A:\n            {init_method}\n    \"\"\"\n    node = astroid.extract_node(assign)\n    instance_attrs = node.instance_attrs\n    for _, assign_attrs in instance_attrs.items():\n        for assign_attr in assign_attrs:\n            got = get_annotation(assign_attr).name\n            assert isinstance(assign_attr, astroid.AssignAttr)\n            assert got == label, f\"got {got} instead of {label} for value {node}\"\n"], "sample_369": ["    def test_operation_with_custom_name(self):\n        class Migration(migrations.Migration):\n            operations = [\n                migrations.CreateModel('Person', fields=[]),\n                migrations.RenameModel('Person', 'User'),\n            ]\n\n        migration = Migration('some_migration', 'test_app')\n        self.assertEqual(migration.suggest_name(), 'rename_person_to_user')\n"], "sample_1110": ["def test_sympy_printing():\n    from sympy import (\n        Symbol,\n        MatrixSymbol,\n        Matrix,\n        eye,\n        zeros,\n        ones,\n        diag,\n        rand,\n        rand_like,\n        transpose,\n        det,\n        inv,\n        logdet,\n        simplify,\n        sqrt,\n        sin,\n        cos,\n        tan,\n        exp,\n        log,\n        abs,\n        sign,\n        Heaviside,\n        Piecewise,\n        Rational,\n        oo,\n        zoo,\n        S,\n        Function,\n        diff,\n        integrate,\n        limit,\n    )\n\n    x, y, z = Symbol('x y z')\n    a, b = symbols('a b')\n    A = MatrixSymbol(\"A\", 2, 2)\n    B = MatrixSymbol(\"B\", 2, 2)\n    C = MatrixSymbol(\"C\", 1, 5)\n    D = MatrixSymbol(\"D\", 3, 4)\n\n    prntr = SymPyPrinter()\n\n    assert prntr.doprint(x + y) == 'x + y'\n    assert prntr.doprint(x**2) == 'x**2'\n    assert prntr.doprint(sqrt(x)) == 'sqrt(x)'\n    assert prntr.doprint(sin(x)) == 'sin(x)'\n    assert prntr.doprint(cos(x)) == 'cos(x)'\n    assert prntr.doprint(tan(x)) == 'tan(x)'\n    assert prntr.doprint(exp(x)) == 'exp(x)'\n    assert prntr.doprint(log(x)) == 'log(x)'\n    assert prntr.doprint(abs(x)) == 'abs(x)'\n    assert prntr.doprint(sign(x)) == 'sign(x)'\n    assert prntr.doprint(Heaviside(x)) == 'Heaviside(x)'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)), (2, x > 6))) == '(1 if x == 0 else 2 if x > 6 else None)'\n    "], "sample_217": ["    def test_merge_css_media_types(self):\n        widget1 = Media(css={'screen': ['a.css'], 'print': ['b.css']})\n        widget2 = Media(css={'screen': ['c.css'], 'all': ['d.css']})\n        merged = widget1 + widget2\n        self.assertEqual(merged._css, {'screen': ['a.css', 'c.css'], 'print': ['b.css'], 'all': ['d.css']})\n\n        widget3 = Media(css={'all': ['e.css']})\n        merged = merged + widget3\n        self.assertEqual(merged._css, {'screen': ['a.css', 'c.css'], 'print': ['b.css'], 'all': ['d.css', 'e.css']})\n"], "sample_585": ["def test_da_groupby_empty_group():\n    array = xr.DataArray([1, 2, 3], [('x', [1, 1, 2])])\n    empty_group = array.groupby('x').get_group(3)\n    assert empty_group.size == 0\n"], "sample_459": ["    def test_enum_choices_raises_error_on_invalid_input(self):\n        f = models.IntegerField(choices=self.Choices.choices)\n        with self.assertRaises(ValidationError):\n            f.clean(\"a\", None)\n"], "sample_432": ["    def test_save_with_changes_does_not_warn_on_no_pending_action(self):\n        from selenium.webdriver.common.by import By\n\n        Parent.objects.create(name=\"parent\")\n\n        self.admin_login(username=\"super\", password=\"secret\")\n        self.selenium.get(\n            self.live_server_url + reverse(\"admin:admin_changelist_parent_changelist\")\n        )\n\n        name_input = self.selenium.find_element(By.ID, \"id_form-0-name\")\n        name_input.clear()\n        name_input.send_keys(\"other name\")\n        self.selenium.find_element(By.NAME, \"_save\").click()\n        alert = self.selenium.switch_to.alert\n        try:\n            self.assertFalse(alert.is_displayed())\n        finally:\n            alert.dismiss()\n"], "sample_547": ["def test_offsetbox_clip_children_outside():\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100, clip=True)\n    bg = mpatches.Rectangle((0, 0), 100, 100,\n                            facecolor='#CCCCCC',\n                            edgecolor='None',\n                            linewidth=0)\n    line = mlines.Line2D([-100, 100], [0, 0],\n                         color='black',\n                         linewidth=10)\n    anchored_box = AnchoredOffsetbox(\n        loc='center',\n        child=da,\n        pad=0.,\n        frameon=False,\n        bbox_to_anchor=(.5, .5),\n        bbox_transform=ax.transAxes,\n        borderpad=0.)\n\n    da.add_artist(bg)\n    da.add_artist(line)\n    ax.add_artist(anchored_box)\n\n    fig.canvas.draw()\n"], "sample_225": ["    def test_unregister_model(self):\n        class MyModelAdmin(admin.ModelAdmin):\n            pass\n        model = type('MyModel', (models.Model,), {})\n        self.site.register(model, MyModelAdmin)\n        self.assertIn(model, self.site._registry)\n        self.site.unregister(model)\n        self.assertNotIn(model, self.site._registry)\n"], "sample_1045": ["def test_issue_10708():\n    assert (S.Half + S.Half).n(10) == 1.0\n    assert (S.Half + S.Half).n(5) == 1.0\n    assert (S.Half + S.Half).n(1) == 1.0\n    assert (S.Half + S.Half).n(0) == 1.0\n"], "sample_754": ["def test_sparse_pca_with_missing_data(norm_comp):\n    rng = np.random.RandomState(0)\n    n_samples = 100\n    n_features = 10\n    n_components = 3\n    Y = rng.randn(n_samples, n_features)\n    # Introduce some missing data\n    missing_ratio = 0.2\n    mask = np.random.rand(n_samples, n_features) < missing_ratio\n    Y[mask] = np.nan\n\n    spca = SparsePCA(n_components=n_components,\n                     random_state=rng, normalize_components=norm_comp)\n    spca.fit(Y)\n    \n    # Check that the components are not NaN\n    assert_true(not np.any(np.isnan(spca.components_)))\n"], "sample_907": ["compilation error"], "sample_322": ["    def test_minimize_rollbacks_circular(self):\n        \"\"\"Minimize rollbacks when there are circular dependencies.\"\"\"\n        a1_impl = FakeMigration('a1')\n        a1 = ('a', '1')\n        a2_impl = FakeMigration('a2')\n        a2 = ('a', '2')\n        b1_impl = FakeMigration('b1')\n        b1 = ('b', '1')\n        graph = MigrationGraph()\n        graph.add_node(a1, a1_impl)\n        graph.add_node(a2, a2_impl)\n        graph.add_node(b1, b1_impl)\n        graph.add_dependency(None, a2, a1)\n        graph.add_dependency(None, b1, a2)\n        graph.add_dependency(None, a1, b1)\n\n        executor = MigrationExecutor(None)\n        executor.loader = FakeLoader(graph, {})\n\n        plan = executor.migration_plan({a1})\n\n        self.assertEqual(plan, [(a2_impl, True), (b1_impl, True)])\n"], "sample_233": ["    def test_token_with_different_user(self):\n        user1 = User.objects.create_user('user1', 'user1@example.com', 'password')\n        user2 = User.objects.create_user('user2', 'user2@example.com', 'password')\n        p0 = PasswordResetTokenGenerator()\n        tk1 = p0.make_token(user1)\n        self.assertIs(p0.check_token(user2, tk1), False)\n"], "sample_187": ["    def test_camel_case_to_spaces(self):\n        self.assertEqual(text.camel_Case_to_spaces('camelCase'), 'camel Case')\n        self.assertEqual(text.camel_case_to_spaces('CamelCase'), 'Camel Case')\n        self.assertEqual(text.camel_case_to_spaces('camelCaseWords'), 'camel Case Words')\n        self.assertEqual(text.camel_case_to_spaces('camelCaseWithNumbers'), 'camel Case With Numbers')\n        self.assertEqual(text.camel_case_to_spaces('snake_case'), 'snake case')\n        self.assertEqual(text.camel_case_to_spaces('snake_Case'), 'snake Case')\n        self.assertEqual(text.camel_case_to_spaces('snake_Case_Words'), 'snake Case Words')\n        self.assertEqual(text.camel_case_to_spaces('snake_Case_With_Numbers'), 'snake Case With Numbers')\n"], "sample_239": ["    def test_invalid(self):\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '0',\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': '',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '1',\n        }\n        ChoiceFormSet = formset_factory(Choice)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [{'votes': ['This field is required.']}, {}]\n        self.assertEqual(formset1._errors, expected_errors)\n        self.assertEqual(formset2._errors, expected_errors)\n"], "sample_999": ["def test_TensorProduct_printing_with_symbols():\n    from sympy.tensor.functions import TensorProduct\n    a = symbols('a')\n    b = symbols('b')\n    c = symbols('c')\n    A = TensorProduct(a, b)\n    B = TensorProduct(c, a)\n    assert latex(A) == r\"a \\otimes b\"\n    assert latex(B) == r\"c \\otimes a\"\n    assert latex(A * B) == r\"(a \\otimes b) \\otimes (c \\otimes a)\"\n"], "sample_1081": ["compilation error"], "sample_548": ["def test_colorbar_fraction_size():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cb = fig.colorbar(im, fraction=0.2, pad=0.05)\n    cb = fig.colorbar(im, fraction=0.2, pad=0.05)\n    cb.ax.set_ylabel('Units')\n\n\n\n"], "sample_388": ["    def test_email_header_missing(self):\n        \"\"\"\n        If the REMOTE_EMAIL header is missing, the user's email address should\n        not be set.\n        \"\"\"\n        num_users = User.objects.count()\n        response = self.client.get(\n            \"/remote_user/\",\n            **{\n                self.header: \"newuser\",\n            },\n        )\n        self.assertEqual(response.context[\"user\"].username, \"newuser\")\n        self.assertEqual(response.context[\"user\"].email, \"\")\n        self.assertEqual(User.objects.count(), num_users + 1)\n        newuser = User.objects.get(username=\"newuser\")\n        self.assertEqual(newuser.email, \"\")\n"], "sample_351": ["    def test_limit_choices_to_callable(self):\n            return Category.objects.filter(name__startswith='A')\n\n        f = forms.ModelChoiceField(Category.objects.all(), limit_choices_to=get_limited_categories)\n        self.assertEqual(len(f.choices), 2)\n        self.assertEqual(list(f.choices), [\n            ('', '---------'),\n            (self.c2.pk, 'A test'),\n        ])\n\n        # Ensure the callable is actually called when choices are accessed.\n        with self.assertNumQueries(2):\n            list(f.choices)\n            f.clean(self.c2.pk)\n"], "sample_870": ["compilation error"], "sample_659": ["    def test_raises_with_custom_exception_class(self):\n        class MyCustomException(Exception):\n            pass\n\n        with pytest.raises(MyCustomException):\n            raise MyCustomException(\"Custom exception message\")\n"], "sample_1162": ["def test_nfloat_dict():\n    from sympy.core.symbol import Symbol\n    x = Symbol('x')\n    expr = {x: x**2, 2: 3}\n    nfloat_expr = nfloat(expr)\n    assert isinstance(nfloat_expr, dict)\n    assert nfloat_expr[x] == x**2\n    assert isinstance(nfloat_expr[2], float)\n    assert nfloat_expr[2] == 3.0\n\n    nfloat_expr_dkeys = nfloat(expr, dkeys=True)\n    assert isinstance(nfloat_expr_dkeys, dict)\n    assert isinstance(nfloat_expr_dkeys[x], float)\n    assert nfloat_expr_dkeys[x] == x**2\n    assert isinstance(nfloat_expr_dkeys[2], float)\n    assert nfloat_expr_dkeys[2] == 3.0\n"], "sample_819": ["def test_voting_classifier_with_custom_estimator():\n    class CustomClassifier(BaseEstimator, ClassifierMixin):\n            pass\n\n            return np.zeros(len(X))\n\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = CustomClassifier()\n    eclf = VotingClassifier(estimators=[('lr', clf1), ('custom', clf2)],\n                            voting='soft')\n    eclf.fit(X, y)\n    assert_array_equal(eclf.predict(X), clf1.predict(X))\n    assert_array_almost_equal(eclf.predict_proba(X), clf1.predict_proba(X))\n"], "sample_992": ["def test_custom_printing():\n    p = PythonCodePrinter()\n    obj = CustomPrintedObject()\n    assert p.doprint(obj) == 'numpy'\n    p = MpmathPrinter()\n    assert p.doprint(obj) == 'mpmath'\n"], "sample_820": ["def test_voting_with_different_output_shapes():\n    \"\"\"Check VotingClassifier handling of estimators with different output shapes.\"\"\"\n    clf1 = LogisticRegression(random_state=123, multi_class='multinomial',\n                              solver='lbfgs', random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    clf3 = GaussianNB()\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([0, 1, 2])\n\n    eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n                            voting='soft')\n    eclf.fit(X, y)\n\n    # Check that predict_proba works correctly\n    assert_array_almost_equal(eclf.predict_proba(X),\n                              eclf.predict_proba(X))\n\n"], "sample_140": ["    def test_sensitive_variables_decorator_with_args(self):\n        @sensitive_variables(exclude=['cooked_eggs'])\n            return password, cooked_eggs, scrambled\n\n        with self.settings(DEBUG=True):\n            result = test_func('secret', 'eggs', 'yes')\n            self.assertEqual(result, ('secret', CLEANSED_SUBSTITUTE, 'yes'))\n"], "sample_374": ["    def test_nested_prefetch_related_with_filter(self):\n        with self.assertNumQueries(3):\n            rooms = Room.objects.filter(house__name='Big house').prefetch_related(\n                Prefetch(\n                    'house',\n                    queryset=House.objects.filter(address__contains='Main'),\n                ),\n            )\n        with self.assertNumQueries(0):\n            self.assertEqual(rooms[0].house.address, '123 Main St')\n"], "sample_88": ["    def test_server_stopped_during_send(self):\n        \"\"\"\n        Sending a message while the SMTP server is stopped raises an exception.\n        \"\"\"\n        self.server.stop()\n        email = EmailMessage('Subject', 'Content', 'from@example.com', ['to@example.com'])\n        with self.assertRaises(SMTPException):\n            self.backend.send_messages([email])\n"], "sample_441": ["    def test_password_too_short(self):\n        user = User.objects.get(username=\"testclient\")\n        data = {\"password1\": \"a\", \"password2\": \"a\"}\n        form = AdminPasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form.errors[\"password1\"],\n            [\n                \"Password must be at least 8 characters long.\",\n            ],\n        )\n        self.assertEqual(form.errors[\"password2\"], [\n            \"Password must be at least 8 characters long.\"\n        ])\n        self.assertEqual(form.changed_data, [])\n"], "sample_514": ["def test_colorbar_fraction_with_subplots():\n    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n    for i in range(2):\n        for j in range(2):\n            axes[i, j].pcolormesh(np.random.randn(10, 10))\n            fig.colorbar(axes[i, j].collections[0], ax=axes[i, j], fraction=0.05)\n    fig.tight_layout()\n    fig.show()\n"], "sample_168": ["    def test_include_stale_apps_true(self):\n        \"\"\"\n        When include_stale_apps is True, stale content types from removed apps are deleted.\n        \"\"\"\n        ContentType.objects.create(app_label='empty_models', model='Fake 1')\n        with self.assertNumQueries(0):\n            apps.unregister_app('empty_models')\n        with mock.patch('builtins.input', return_value='yes'):\n            with captured_stdout() as stdout:\n                call_command('remove_stale_contenttypes', include_stale_apps=True, verbosity=2)\n        self.assertNotIn(\n            \"Deleting stale content type 'contenttypes_tests.Fake'\",\n            stdout.getvalue(),\n        )\n        self.assertIn(\n            \"Deleting stale content type 'empty_models | Fake 1'\",\n            stdout.getvalue(),\n        )\n        self.assertEqual(ContentType.objects.count(), self.before_count)\n"], "sample_306": ["    def test_iso8601_duration(self):\n        test_values = (\n            ('P1D', timedelta(days=1)),\n            ('P1DT2H30M', timedelta(days=1, hours=2, minutes=30)),\n            ('P1DT2H30M1S', timedelta(days=1, hours=2, minutes=30, seconds=1)),\n            ('P1DT2H30M1.123S', timedelta(days=1, hours=2, minutes=30, seconds=1, microseconds=123000)),\n            ('PT2H30M1S', timedelta(hours=2, minutes=30, seconds=1)),\n            ('PT2H30M1.123S', timedelta(hours=2, minutes=30, seconds=1, microseconds=123000)),\n            ('P-1D', timedelta(days=-1)),\n            ('P-1DT2H30M', timedelta(days=-1, hours=2, minutes=30)),\n            ('P-1DT2H30M1S', timedelta(days=-1, hours=2, minutes=30, seconds=1)),\n            ('P-1DT2H30M1.123S', timedelta(days=-1, hours=2, minutes=30, seconds=1, microseconds=123000)),\n            ('PT-2H30M1S', timedelta(hours=-2, minutes=-30, seconds=-1)),\n            ('PT-2H30M1.123S', timedelta(hours=-2, minutes=-30, seconds=-1, microseconds=-123000)),\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self.assertEqual(parse_duration(source), expected)\n"], "sample_378": ["    def test_related_object_with_pk_field(self):\n        parent = RelatedObject.objects.create()\n        child = SingleObject.objects.create(pk=10)\n        parent.single = child\n        parent.save()\n        RelatedObject.objects.bulk_update([parent], fields=['single'])\n        self.assertEqual(parent.single_id, child.pk)\n"], "sample_1054": ["def test_issue_12010():\n    from sympy.abc import x, y\n    a = Interval(0, 1)\n    b = Interval(1, 2)\n    c = Interval(2, 3)\n    cr1 = ComplexRegion(a * a)\n    cr2 = ComplexRegion(b * b)\n    cr3 = ComplexRegion(c * c)\n    assert Intersection(cr1, cr2) == S.EmptySet\n    assert Intersection(cr1, cr3) == S.EmptySet\n    assert Intersection(cr2, cr3) == S.EmptySet\n    assert Union(cr1, cr2) == ComplexRegion(Interval(0, 4))\n    assert Union(cr1, cr3) == ComplexRegion(Interval(0, 9))\n    assert Union(cr2, cr3) == ComplexRegion(Interval(1, 9))\n    cr4 = ComplexRegion(a * b)\n    cr5 = ComplexRegion(b * c)\n    assert Intersection(cr4, cr5) == S.EmptySet\n    assert Union(cr4, cr5) == ComplexRegion(Interval(1, 3))\n    cr6 = ComplexRegion(a * c)\n    assert Intersection(cr6, cr4) == S.EmptySet\n    assert Union(cr6, cr4) == ComplexRegion(Interval(0, 3))\n    cr7 = ComplexRegion(a * b * c)\n    assert Intersection(cr7, cr4) == S.EmptySet\n    assert Union(cr7, cr4) == ComplexRegion(Interval(0, 3))\n    cr8 = ComplexRegion(a * b * c * a)\n    assert Intersection(cr8, cr4) == S.EmptySet\n    assert Union(cr8, cr4) == ComplexRegion(Interval(0, 3))\n    cr9 = ComplexRegion(a * b * c * b)\n    assert Intersection(cr9, cr4) == S.EmptySet\n    assert Union(cr9, cr4) == ComplexRegion(Interval(1, 3))\n    cr10 = ComplexRegion(a * b * c * c)\n    assert Intersection(cr10, cr4) == S.Empty"], "sample_160": ["    def test_empty_string(self):\n        self.assertEqual(nformat('', '.'), '')\n        self.assertEqual(nformat('', '.', decimal_pos=2), '')\n        self.assertEqual(nformat('', '.', grouping=2, thousand_sep=','), '')\n        self.assertEqual(nformat('', '.', grouping=2, thousand_sep=',', force_grouping=True), '')\n"], "sample_1150": ["def test_issue_17858_continued():\n    assert 1 in Range(1, oo)\n    assert 0 not in Range(1, oo)\n    assert oo in Range(1, oo)\n    assert -oo not in Range(1, oo)\n    assert 1 in Range(-oo, 1)\n    assert 0 not in Range(-oo, 1)\n    assert -oo in Range(-oo, 1)\n    assert 1 not in Range(-oo, 1, -1)\n    assert 0 in Range(-oo, 1, -1)\n    assert -oo not in Range(-oo, 1, -1)\n"], "sample_84": ["    def test_parsing_invalid_date(self):\n        with self.assertRaises(ValueError):\n            parse_http_date('invalid date')\n"], "sample_64": ["    def test_invalid_samesite(self):\n        with self.assertRaises(ValueError):\n            SimpleCookie('name=value; samesite=invalid')\n"], "sample_79": ["    def test_invalid_input(self):\n        self.assertEqual(pluralize(True), '')\n        self.assertEqual(pluralize(False), '')\n        self.assertEqual(pluralize(None), '')\n        self.assertEqual(pluralize(1.5), 's')\n        self.assertEqual(pluralize(Decimal(1.5)), 's')\n"], "sample_1039": ["def test_print_matrix_symbol_with_dimensions():\n    A = MatrixSymbol('A', 2, 3)\n    assert mpp.doprint(A) == '<mi>A</mi>'\n    assert mp.doprint(A) == '<ci>A</ci>'\n    assert mathml(A, printer='presentation', mat_symbol_style=\"bold\" )== '<mi mathvariant=\"bold\">A</mi>'\n    assert mathml(A, mat_symbol_style=\"bold\" )== '<ci>A</ci>' # No effect in content printer\n"], "sample_705": ["compilation error"], "sample_607": ["def test_guess_engine_with_matching_engine():\n    dummy_pkg_entrypoint = pkg_resources.EntryPoint.parse(\n        \"cfgrib = xarray.tests.test_plugins:backend_1\"\n    )\n    backend_entrypoints = plugins.build_engines([dummy_pkg_entrypoint])\n    engine = plugins.guess_engine(\"not-valid\")\n    assert engine == \"cfgrib\"\n"], "sample_229": ["    def test_union_with_different_field_names(self):\n        ReservedName.objects.create(name='a', order=2)\n        qs1 = ReservedName.objects.values('name', 'order', 'id')\n        qs2 = ReservedName.objects.values('id', 'order', 'name')\n        self.assertEqual(len(list(qs1.union(qs2))), 1)\n        self.assertEqual(list(qs1.union(qs2).values_list('name', 'order', 'id')), [('a', 2, 1)])\n"], "sample_790": ["def test_kernel_pca_copy_X():\n    rng = np.random.RandomState(0)\n    X = rng.rand(10, 10)\n    kpca = KernelPCA(copy_X=False)\n    kpca.fit(X)\n    X_transformed = kpca.transform(X)\n    # Modify X after fitting\n    X[:, 0] = 666\n    X_transformed2 = kpca.transform(X)\n    assert_array_almost_equal(X_transformed, X_transformed2)\n"], "sample_997": ["def test_issue_11264():\n    assert parse_expr('(1 + 2) * (3 + 4)', evaluate=False) == \\\n        Mul(Add(1, 2), Add(3, 4))\n"], "sample_735": ["def test_predict_proba_with_missing_data():\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng, scale=7, n_components=3)\n    n_features, n_components = rand_data.n_features, rand_data.n_components\n\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        # Introduce some missing values\n        X_missing = np.copy(X)\n        X_missing[:, 1] = np.nan\n\n        gmm = GaussianMixture(n_components=n_components,\n                              covariance_type=covar_type, random_state=rng)\n        gmm.fit(X)\n\n        # Check that predict_proba raises an error with missing data\n        assert_raise_message(ValueError,\n                             \"Input contains missing values\",\n                             gmm.predict_proba, X_missing)\n\n        # Impute the missing values\n        X_imputed = SimpleImputer(strategy='mean').fit_transform(X_missing)\n\n        # Now predict_proba should work\n        probs = gmm.predict_proba(X_imputed)\n        assert_equal(probs.shape, (X_imputed.shape[0], n_components))\n"], "sample_400": ["    def test_operation_with_custom_name(self):\n        class Migration(migrations.Migration):\n            operations = [\n                migrations.CreateModel(\n                    \"Person\", fields=[], name=\"my_person_model\"\n                )\n            ]\n\n        migration = Migration(\"some_migration\", \"test_app\")\n        self.assertEqual(migration.suggest_name(), \"my_person_model\")\n"], "sample_927": ["        def assert_classes(self, tag, expected_classes):\n            assert self.content_classes[tag] == expected_classes, (\n                f\"Classes for role '{self.name}' with tag '{tag}' \"\n                f\"should be {expected_classes}, but are \"\n                f\"{self.content_classes[tag]}\"\n            )\n"], "sample_709": ["compilation error"], "sample_75": ["    def test_read_prefetched_objects_cache(self):\n        with self.assertNumQueries(2):\n            books = Book.objects.filter(title__in=['Les confessions Volume I', 'Candide']).prefetch_related('authors')\n        book1, book2 = list(books)\n\n        with self.assertNumQueries(0):\n            self.assertEqual(book1.authors.all(), [self.author1])\n            self.assertEqual(book2.authors.all(), [self.author2])\n\n            # Test that the cache is cleared when an object is modified\n            self.author1.age = 71\n            self.author1.save()\n            self.assertEqual(book1.authors.all()[0].age, 71)\n\n            # Test that the cache is cleared when a related object is removed\n            book1.authors.remove(self.author1)\n            with self.assertNumQueries(1):\n                self.assertEqual(book1.authors.all(), [])\n\n\n\n"], "sample_1003": ["def test_allowed_flags():\n    allowed_flags({'domain': ZZ}, [])\n    raises(FlagError, lambda: allowed_flags({'domain': ZZ, 'frac': True}, []))\n    allowed_flags({'domain': ZZ, 'frac': True}, ['frac'])\n"], "sample_989": ["def test_issue_10494():\n    assert Float(10**100).as_mpf() == mpf(10**100)\n"], "sample_828": ["def test_check_pairwise_arrays_with_missing_values():\n    # Ensure that checks handle missing values correctly.\n    rng = np.random.RandomState(0)\n    XA = rng.random_sample((5, 4))\n    XA[1, 2] = np.nan\n    XB = rng.random_sample((5, 4))\n    XB[2, 3] = np.nan\n    XA_checked, XB_checked = check_pairwise_arrays(XA, XB)\n    assert_array_equal(XA, XA_checked)\n    assert_array_equal(XB, XB_checked)\n"], "sample_261": ["    def test_iso8601_duration(self):\n        test_values = (\n            ('P1D', timedelta(days=1)),\n            ('P1DT2H30M', timedelta(days=1, hours=2, minutes=30)),\n            ('P1DT2H30M1.5S', timedelta(days=1, hours=2, minutes=30, seconds=1, microseconds=500000)),\n            ('PT2H30M1.5S', timedelta(hours=2, minutes=30, seconds=1, microseconds=500000)),\n            ('P-1D', timedelta(days=-1)),\n            ('P-1DT2H30M', timedelta(days=-1, hours=2, minutes=30)),\n            ('P1D2H30M', timedelta(days=1, hours=2, minutes=30)),\n            ('P1DT2H30M1.5S', timedelta(days=1, hours=2, minutes=30, seconds=1, microseconds=500000)),\n            ('P1DT2H30M1.5S', timedelta(days=1, hours=2, minutes=30, seconds=1, microseconds=500000)),\n            ('PT2H30M1.5S', timedelta(hours=2, minutes=30, seconds=1, microseconds=500000)),\n            ('P1Y', timedelta(days=365)),\n            ('P1Y2M', timedelta(days=365, days=60)),\n            ('P1Y2M3D', timedelta(days=365, days=60, days=3)),\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self.assertEqual(parse_duration(source), expected)\n"], "sample_835": ["def test_sample_weight_validation():\n    # Test that sample_weights are validated correctly\n    for algo in ['SAMME', 'SAMME.R']:\n        clf = AdaBoostClassifier(algorithm=algo)\n        # Valid sample weights\n        sample_weights = np.ones(10)\n        clf.fit(X, y_class, sample_weight=sample_weights)\n\n        # Invalid sample weights\n        invalid_weights = np.array([1, 2, 3, 4, 5, 0, 0, 0, 0, 0])\n        assert_raises(ValueError, clf.fit, X, y_class, sample_weight=invalid_weights)\n\n        # Test with regression\n        reg = AdaBoostRegressor(algorithm=algo)\n        reg.fit(X, y_regr, sample_weight=sample_weights)\n        invalid_weights = np.array([1, 2, 3, 4, 5, 0, 0, 0, 0, 0])\n        assert_raises(ValueError, reg.fit, X, y_regr, sample_weight=invalid_weights)\n\n\n\n"], "sample_221": ["    def test_in_lookup_with_related_object_queryset_evaluation(self):\n        \"\"\"\n        Neither pickling nor unpickling a QuerySet.query with an __in=inner_qs\n        lookup should evaluate inner_qs, even when inner_qs is related to\n        the current QuerySet.\n        \"\"\"\n        events = Event.objects.filter(group__in=Group.objects.filter(name__startswith='Group'))\n\n        with self.assertNumQueries(0):\n            dumped = pickle.dumps(events.query)\n\n        with self.assertNumQueries(0):\n            reloaded = pickle.loads(dumped)\n            reloaded_events = Event.objects.none()\n            reloaded_events.query = reloaded\n\n        self.assertSequenceEqual(reloaded_events, [self.e1])\n"], "sample_1168": ["compilation error"], "sample_317": ["    def test_feed_with_custom_feed_generator(self):\n        response = self.client.get('/syndication/custom_feed/')\n        doc = minidom.parseString(response.content)\n        feed = doc.getElementsByTagName('feed')[0]\n        self.assertEqual(feed.getAttribute('django'), 'rocks')\n        self.assertEqual(feed.getElementsByTagName('title')[0].firstChild.wholeText, 'My blog')\n        self.assertEqual(feed.getElementsByTagName('description')[0].firstChild.wholeText, 'A more thorough description of my blog.')\n        self.assertEqual(feed.getElementsByTagName('link')[0].firstChild.wholeText, 'http://example.com/blog/')\n"], "sample_554": ["def test_text_bbox_transform():\n    fig, ax = plt.subplots()\n    text = ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    bbox = text.get_window_extent()\n    transformed_bbox = bbox.transformed(ax.transData)\n    assert transformed_bbox.width != bbox.width\n    assert transformed_bbox.height != bbox.height\n"], "sample_1178": ["def test_FunctionCall__with_keyword_arguments():\n    fc = FunctionCall('power', {'x': x, 'n': 3})\n    assert fc.function_args == (x, 3)\n    assert fc.keyword_arguments == {'x': x, 'n': 3}\n    assert fc == FunctionCall('power', {'x': x, 'n': 3})\n    assert fc != FunctionCall('power', {'x': y, 'n': 3})\n    assert fc != FunctionCall('power', {'x': x, 'n': 4})\n    assert fc.func(*fc.args) == fc\n\n    fc2 = FunctionCall('fma', {'a': 2, 'b': 3, 'c': 4})\n    assert fc2.function_args == (2, 3, 4)\n    assert fc2.keyword_arguments == {'a': 2, 'b': 3, 'c': 4}\n    assert str(fc2) in ( # not sure if QuotedString is a better default...\n        'FunctionCall(fma, function_args=(2, 3, 4), keyword_arguments={'a': 2, 'b': 3, 'c': 4})',\n        'FunctionCall(\"fma\", function_args=(2, 3, 4), keyword_arguments={'a': 2, 'b': 3, 'c': 4})',\n    )\n"], "sample_427": ["    def test_formset_with_non_form_errors_is_invalid(self):\n        class ChoiceFormSetWithNonFormError(BaseFormSet):\n                raise ValidationError(\"This is a non-form error\")\n\n        ChoiceFormSetWithNonFormError = formset_factory(\n            Choice, formset=ChoiceFormSetWithNonFormError\n        )\n        formset = ChoiceFormSetWithNonFormError(\n            data={\"form-TOTAL_FORMS\": \"1\"}, prefix=\"choices\"\n        )\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(formset.errors, [{\"\": [\"This is a non-form error\"]}])\n"], "sample_367": ["    def test_cache_control_decorator_kwargs(self):\n        @cache_control(public=True, max_age=3600)\n            return HttpResponse()\n\n        response = a_view(HttpRequest())\n        self.assertEqual(response.headers['Cache-Control'], 'public, max-age=3600')\n"], "sample_1051": ["def test_custom_styles():\n    styles = [(Basic, {'color': 'red', 'shape': 'circle'}),\n              (Expr, {'color': 'green', 'shape': 'square'})]\n    text = dotprint(x + 2, styles=styles)\n    assert 'color=\"red\"' in text\n    assert 'shape=\"circle\"' in text\n"], "sample_129": ["    def test_nan(self):\n        self.assertEqual(floatformat(float('nan')), 'nan')\n"], "sample_235": ["    def test_hook_with_arguments(self):\n            self.assertEqual(arg1, 1)\n            self.assertEqual(arg2, 'hello')\n            self.notify((arg1, arg2))\n\n        with transaction.atomic():\n            transaction.on_commit(on_commit, args=(1, 'hello'))\n\n        self.assertDone([(1, 'hello')])\n\n"], "sample_671": ["compilation error"], "sample_874": ["def test_step_parameter():\n    sel = StepSelector(step=3)\n    Xt_actual = sel.fit(X, y).transform(X)\n    expected_Xt = np.arange(0, 20, 3).reshape(2, 5)\n    assert_array_equal(expected_Xt, Xt_actual)\n\n    with pytest.raises(ValueError):\n        sel = StepSelector(step=0)\n        sel.fit(X, y)\n"], "sample_667": ["    def test_tmpdir_is_absolute(tmpdir):\n        assert tmpdir.resolve() == tmpdir\n"], "sample_1078": ["def test_Indexed_subs_with_functions():\n    i, j, k = symbols(\"i,j,k\")\n    A = IndexedBase(\"A\")\n    f = Function(\"f\")\n    g = Function(\"g\")\n\n    assert Subs(f(A[i]), A[i], A[j]).diff(A[j]) == f(A[j]).diff(A[j])\n    assert Subs(g(A[i]), A[i], A[j]).diff(A[j]) == g(A[j]).diff(A[j])\n    assert Subs(f(A[i]) + g(A[i]), A[i], A[j]).diff(A[j]) == f(A[j]).diff(A[j]) + g(A[j]).diff(A[j])\n    assert Subs(f(A[i]) * g(A[i]), A[i], A[j]).diff(A[j]) == f(A[j]) * g(A[j]).diff(A[j]) + g(A[j]) * f(A[j]).diff(A[j])\n    assert Subs(f(A[i]) * g(A[i]), A[i], A[j]).diff(A[k]) == f(A[j]) * g(A[j]).diff(A[k]) + g(A[j]) * f(A[j]).diff(A[k])\n    assert Subs(f(A[i]) / g(A[i]), A[i], A[j]).diff(A[j]) == (g(A[j]) * f(A[j]).diff(A[j]) - f(A[j]) * g(A[j]).diff(A[j])) / g(A[j])**2\n"], "sample_658": ["    def test_doctest_missing_module(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n                '''\n                >>> import missing_module\n                '''\n        \"\"\"\n        )\n        result = testdir.runpytest(\"--doctest-modules\")\n        result.stdout.fnmatch_lines(\n            [\n                \"*ImportError: No module named missing_module*\",\n                \"*1 failed in*\",\n            ]\n        )\n"], "sample_1013": ["def test_lambdify_with_matrices():\n    if not numpy:\n        skip(\"numpy not installed\")\n    A = Matrix([[1, 2], [3, 4]])\n    B = Matrix([[5, 6], [7, 8]])\n    f = lambdify((A, B), A*B)\n    assert f(A, B) == Matrix([[19, 22], [43, 50]])\n"], "sample_725": ["    def test_check_array_sparse_matrix_dtype():\n        X_csr = sp.csr_matrix([[1, 2], [3, 4]], dtype=np.float64)\n        X_checked = check_array(X_csr, dtype=np.float32, accept_sparse=True)\n        assert_equal(X_checked.dtype, np.float32)\n        assert_equal(X_checked.format, 'csr')\n"], "sample_350": ["    def test_union_with_subquery_ordering(self):\n        qs1 = Number.objects.filter(num__lt=5).order_by('num')\n        qs2 = Number.objects.filter(num__gt=5).order_by('-num')\n        self.assertNumbersEqual(qs1.union(qs2).order_by('num'), [0, 1, 2, 3, 4, 6, 7, 8, 9])\n\n"], "sample_875": ["def test_balanced_accuracy_score_empty_arrays():\n    with pytest.raises(ValueError):\n        balanced_accuracy_score([], [])\n    with pytest.raises(ValueError):\n        balanced_accuracy_score([1, 2], [])\n    with pytest.raises(ValueError):\n        balanced_accuracy_score([], [1, 2])\n"], "sample_294": ["    def test_bare_secret_accepted_and_replaced_with_session(self):\n        \"\"\"\n        The csrf token is reset from a bare secret and stored in the session.\n        \"\"\"\n        req = self._get_POST_bare_secret_csrf_cookie_request_with_token()\n        mw = CsrfViewMiddleware(token_view)\n        mw.process_request(req)\n        resp = mw.process_view(req, token_view, (), {})\n        self.assertIsNone(resp)\n        csrf_cookie = req.session[CSRF_SESSION_KEY]\n        self._check_token_present(resp, csrf_id=csrf_cookie)\n\n"], "sample_696": ["def test_argument_percent_default(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import argparse\n\n            parser = argparse.ArgumentParser()\n            parser.add_argument('--foo', type=str, default=\"%default\")\n            args = parser.parse_args()\n            print(args.foo)\n\n        if __name__ == \"__main__\":\n            main()\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: pytest now uses argparse.*\",\n            \"*%default* should be changed to *%(default)s*\",\n        ]\n    )\n"], "sample_382": ["    def test_get_template_directories_with_multiple_dirs(self):\n        self.assertSetEqual(\n            autoreload.get_template_directories(),\n            {\n                Path(__file__).parent / 'templates',\n                Path(__file__).parent / 'templates_extra',\n            }\n        )\n"], "sample_728": ["def test_make_checkerboard_with_noise():\n    X, rows, cols = make_checkerboard(\n        shape=(100, 100), n_clusters=(20, 5), noise=0.1,\n        shuffle=True, random_state=0)\n    assert_equal(X.shape, (100, 100), \"X shape mismatch\")\n    assert_equal(rows.shape, (100, 100), \"rows shape mismatch\")\n    assert_equal(cols.shape, (100, 100,), \"columns shape mismatch\")\n    for i in range(X.shape[0]):\n        for j in range(X.shape[1]):\n            assert_almost_equal(X[i, j], 1,\n                                err_msg=\"Point is not on expected unit circle\")\n"], "sample_85": ["    def test_fast_delete_with_signals(self):\n            pass\n\n        signals = [\n            models.signals.pre_delete,\n            models.signals.post_delete,\n        ]\n        for signal_name in signals:\n            with self.subTest(signal=signal_name):\n                signal = getattr(models.signals, signal_name)\n                signal.connect(receiver, sender=User)\n                u = User.objects.create()\n                self.assertNumQueries(2, u.delete)\n                signal.disconnect(receiver, sender=User)\n\n\n\n"], "sample_486": ["    def test_inlineformset_factory_nulls_default_pks_auto_parent_auto_child(self):\n        \"\"\"\n        #24958 - Variant of test_inlineformset_factory_nulls_default_pks for\n        the case of both parent and child objects having AutoField primary keys.\n        \"\"\"\n        FormSet = inlineformset_factory(\n            AutoPKParent, AutoPKChildOfUUIDPKParent, fields=\"__all__\"\n        )\n        formset = FormSet()\n        self.assertIsNone(formset.forms[0].fields[\"parent\"].initial)\n"], "sample_968": ["def test_python_python_use_unqualified_type_names_enabled(app, status, warning):\n    app.build()\n    content = (app.outdir / 'index.html').read_text()\n    assert ('<span class=\"n\"><span class=\"pre\">Name</span></span>' in content)\n    assert ('<span class=\"n\"><span class=\"pre\">Age</span></span>' in content)\n    assert ('<p><strong>name</strong> (<span class=\"n\"><span class=\"pre\">Name</span></span>) \u2013 blah blah</p>' in content)\n    assert '<p><strong>age</strong> (<span class=\"n\"><span class=\"pre\">Age</span></span>) \u2013 blah blah</p>' in content\n"], "sample_397": ["    def test_template_loaders_with_custom_loaders(self):\n        engine = DjangoTemplates(\n            {\n                \"DIRS\": [],\n                \"APP_DIRS\": False,\n                \"NAME\": \"django\",\n                \"OPTIONS\": {\n                    \"loaders\": [\n                        (\"my_custom_loader\", [\"my_custom_loader_arg\"]),\n                        (\"django.template.loaders.filesystem.Loader\",),\n                    ]\n                },\n            }\n        )\n        self.assertEqual(\n            engine.engine.template_loaders,\n            [\n                self.find_template_loader(\n                    (\"my_custom_loader\", [\"my_custom_loader_arg\"])\n                ),\n                self.find_template_loader(\n                    (\"django.template.loaders.filesystem.Loader\",)\n                ),\n            ],\n        )\n\n\n\n"], "sample_1163": ["def test_issue_14238():\n    # doesn't cause recursion error\n    r = Symbol('r', real=True)\n    assert Abs(r + Piecewise((0, r > 0), (1 - r, True)))\n"], "sample_704": ["def test_node_iter_markers_with_name(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.xfail\n            pass\n\n        @pytest.mark.skip\n            pass\n\n        @pytest.mark.parametrize(\"a\", [1, 2])\n            pass\n    \"\"\"\n    )\n    items = pytester.getitems()\n    for item in items:\n        for marker in item.iter_markers(\"xfail\"):\n            assert marker.name == \"xfail\"\n        for marker in item.iter_markers(\"skip\"):\n            assert marker.name == \"skip\"\n        for marker in item.iter_markers(\"parametrize\"):\n            assert marker.name == \"parametrize\"\n\n\n\n"], "sample_425": ["    def test_serialize_custom_serializer(self):\n        class MyCustomSerializer(BaseSerializer):\n                return f\"custom({obj})\", {}\n\n        with mock.patch(\n            \"django.db.migrations.writer.BaseSerializer\",\n            new_callable=Mock,\n        ) as mock_base_serializer:\n            mock_base_serializer.return_value.serialize.return_value = (\n                \"base_serialized(%r)\" % obj,\n                {},\n            )\n            field = models.CharField(\n                default=MyCustomSerializer(),\n                max_length=100,\n            )\n            string, imports = MigrationWriter.serialize(field)\n            self.assertEqual(string, \"models.CharField(default=custom(None), max_length=100)\")\n            self.assertEqual(imports, {\"from migrations.test_writer import MyCustomSerializer\"})\n"], "sample_176": ["    def test_mti_inheritance_model_removal_with_fk(self):\n        \"\"\"\n        #23316 - Removing an MTI model with a FK to a non-deleted parent\n        model should work correctly.\n        \"\"\"\n        Owner = ModelState('app', 'Owner', [\n            (\"id\", models.AutoField(primary_key=True)),\n        ])\n        Pet = ModelState('app', 'Pet', [], bases=('app.Owner',))\n        changes = self.get_changes([Owner, Pet], [Owner])\n        self.assertNumberMigrations(changes, 'app', 1)\n        self.assertOperationTypes(changes, 'app', 0, ['DeleteModel'])\n        self.assertOperationAttributes(changes, 'app', 0, 0, name='Pet')\n"], "sample_990": ["compilation error"], "sample_745": ["def test_sparse_matrix_input():\n    X_sparse = sparse.csr_matrix([[1, 2], [3, 4]])\n\n    # Test that sparse matrix input is handled correctly\n    F = FunctionTransformer(np.sum, accept_sparse=True)\n    assert_array_equal(F.transform(X_sparse), np.array([3, 7]))\n\n    # Test that an error is raised if accept_sparse is False\n    with pytest.raises(ValueError):\n        F = FunctionTransformer(np.sum, accept_sparse=False)\n        F.transform(X_sparse)\n"], "sample_496": ["    def test_suggestions_with_extra_arguments(self):\n        args = ['rnserver', '--settings=test_project.settings', '--port=8000']\n        out, err = self.run_django_admin(args)\n        self.assertNoOutput(out)\n        self.assertOutput(err, \"Unknown command: 'rnserver'. Did you mean runserver?\")\n"], "sample_1086": ["def test_issue_16029():\n    from sympy.matrices import Matrix\n    A = Matrix([[1, 2], [3, 4]])\n    assert str(A.transpose()) == \"Matrix([[1, 3], [2, 4]])\"\n"], "sample_293": ["    def test_lookahead_and_lookbehind_together(self):\n        test_urls = [\n            ('/lookahead-/lookbehind-/a-city/', {'city': 'a-city'}),\n            ('/lookahead+/lookbehind+/a-city/', {'city': 'a-city'}),\n        ]\n        for test_url, kwargs in test_urls:\n            with self.subTest(url=test_url):\n                self.assertEqual(resolve(test_url).kwargs, kwargs)\n"], "sample_668": ["def test_funcargnames_deprecation(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            pass\n\n            assert funcargnames == {'my_fixture'}\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*The `funcargnames` attribute was an alias for `fixturenames`, \"\n            \"since pytest 2.3 - use the newer attribute instead.*\",\n        ]\n    )\n"], "sample_1080": ["        def _eval_refine(self, assumptions):\n            return self\n"], "sample_801": ["def test_repr_with_custom_estimator():\n    class MyCustomEstimator(BaseEstimator):\n            self.a = a\n            self.b = b\n\n            return self\n\n            return X * self.a + self.b\n\n    estimator = MyCustomEstimator(a=2, b=3)\n    expected = \"\"\""], "sample_155": ["    def test_file_response_with_custom_content_type(self):\n        with tempfile.NamedTemporaryFile(suffix='.txt') as tmp:\n            tmp.write(b'This is some test content')\n            tmp.flush()\n            response = FileResponse(tmp, content_type='text/plain; charset=utf-8')\n        self.assertEqual(response['Content-Type'], 'text/plain; charset=utf-8')\n        self.assertEqual(list(response), [b'This is some test content'])\n"], "sample_985": ["def test_evalf():\n    x = symbols('x')\n    assert b21.evalf() == b21\n    assert b21.evalf(subs={b2: 2, b1: 3}) == 5\n    assert b21.evalf(prec=3) == b21\n    assert sin(x).evalf(subs={x: pi/4}) == 0.707\n    assert exp(x).evalf(subs={x: 1}, prec=2) == 2.72\n    assert (x**2 + 1).evalf(subs={x: 2}, prec=3) == 5.000\n    assert (x**2 + 1).evalf(subs={x: 2}, method='mpmath') == 5.0000000000000004\n    assert (x**2 + 1).evalf(subs={x: 2}, method='numpy') == 5.0\n    assert (x**2 + 1).evalf(subs={x: 2}, method='decimal') == 5.0000000000000004\n    assert (x**2 + 1).evalf(subs={x: 2}, method='default') == 5.0000000000000004\n    assert (x**2 + 1).evalf(subs={x: 2}, method='default', prec=3) == 5.000\n    assert (x**2 + 1).evalf(subs={x: 2}, method='default', prec=10) == 5.0000000000\n    assert (x**2 + 1).evalf(subs={x: 2}, method='default', prec=100) == 5.0000000000000004\n\n\n\n"], "sample_178": ["    def test_invalid(self):\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '0',\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': 'invalid',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '1',\n        }\n        ChoiceFormSet = formset_factory(Choice)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [{'votes': ['Enter a valid number.']}, {}]\n        self.assertEqual(formset1._errors, expected_errors)\n        self.assertEqual(formset2._errors, expected_errors)\n"], "sample_1091": ["def test_issue_17438():\n    x, y = symbols('x y')\n    assert simplify(Eq(x + y, x - y)) == False\n    assert simplify(Eq(x + y, x - y, evaluate=False)) == False\n    assert simplify(Eq(x + y, x - y, evaluate=True)) == False\n"], "sample_856": ["def test_time_series_cv_with_groups():\n    X = np.arange(10).reshape((10, 1))\n    groups = np.array([0, 0, 1, 1, 1, 2, 2, 2, 2, 3])\n    tscv = TimeSeriesSplit(n_splits=3)\n    splits = tscv.split(X, groups=groups)\n    for train, test in splits:\n        assert all(groups[i] == groups[j] for i, j in zip(train, test))\n"], "sample_811": ["def test_check_pairwise_arrays_with_sparse_and_dense():\n    # Ensures that checks handle mixed sparse and dense arrays correctly.\n    rng = np.random.RandomState(0)\n    XA = rng.random_sample((5, 4))\n    XA_sparse = csr_matrix(XA)\n    XB = rng.random_sample((5, 4))\n    XB_sparse = csr_matrix(XB)\n    XA_checked, XB_checked = check_pairwise_arrays(XA_sparse, XB)\n    assert issparse(XA_checked)\n    assert_array_equal(XA_sparse.todense(), XA_checked)\n    assert_array_equal(XB, XB_checked)\n\n    XA_checked, XB_checked = check_pairwise_arrays(XA, XB_sparse)\n    assert_array_equal(XA, XA_checked)\n    assert issparse(XB_checked)\n    assert_array_equal(XB_sparse.todense(), XB_checked)\n\n    XA_checked, XB_checked = check_pairwise_arrays(XA_sparse, XB_sparse)\n    assert issparse(XA_checked)\n    assert_array_equal(XA_sparse.todense(), XA_checked)\n    assert issparse(XB_checked)\n    assert_array_equal(XB_sparse.todense(), XB_checked)\n"], "sample_850": ["def test_nystroem_sparse_data():\n    # Test Nystroem with sparse data\n    rnd = np.random.RandomState(42)\n    n_samples = 1000\n    n_features = 100\n    X = rnd.rand(n_samples, n_features)\n    X_sparse = csr_matrix(X)\n\n    nystroem = Nystroem(n_components=100, random_state=42)\n    X_transformed = nystroem.fit_transform(X_sparse)\n    assert X_transformed.shape == (n_samples, 100)\n\n    # Test that the sparse data is handled correctly\n    assert isinstance(X_transformed, np.ndarray)\n    assert X_transformed.shape == (n_samples, 100)\n"], "sample_83": ["    def test_tag_compile_function(self):\n            return Node()\n        self.library.tag('name', compile_function)\n        self.assertEqual(self.library.tags['name'], compile_function)\n"], "sample_1147": ["def test_issue_18187():\n    from sympy import Matrix, symbols, eye\n    x, y = symbols('x y')\n    A = Matrix([[x, y], [y, x]])\n    assert latex(A) == r'\\begin{bmatrix} x & y \\\\ y & x \\end{bmatrix}'\n    assert latex(eye(2)) == r'\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}'\n"], "sample_199": ["    def test_annotation_with_subquery_filter_ordering(self):\n        long_books_qs = Book.objects.filter(\n            publisher=OuterRef('pk'),\n            pages__gt=400,\n        ).values('publisher').annotate(count=Count('pk')).values('count')\n        publisher_books_qs = Publisher.objects.annotate(\n            total_books=Count('book'),\n        ).filter(\n            total_books=Subquery(long_books_qs, output_field=IntegerField()),\n        ).order_by('total_books').values('name')\n        self.assertCountEqual(publisher_books_qs, [{'name': 'Sams'}, {'name': 'Morgan Kaufmann'}])\n"], "sample_940": ["compilation error"], "sample_876": ["def test_mlp_early_stopping_with_validation_split(MLPEstimator):\n    X, y = X_digits, y_digits\n    n_samples = len(X)\n    test_size = int(0.2 * n_samples)\n    X_train, X_test = X[:n_samples - test_size], X[n_samples - test_size:]\n    y_train, y_test = y[:n_samples - test_size], y[n_samples - test_size:]\n\n    mlp = MLPEstimator(\n        early_stopping=True, validation_split=0.2, random_state=0, max_iter=100\n    )\n    mlp.fit(X_train, y_train)\n    assert mlp.best_loss_ is not None\n    assert isinstance(mlp.validation_scores_, list)\n    assert len(mlp.validation_scores_) > 0\n    y_pred = mlp.predict(X_test)\n    assert mlp.score(X_test, y_test) > 0.85\n"], "sample_736": ["def test_logreg_l1_penalty_with_class_weight():\n    # Test that class weights are correctly applied with l1 penalty\n    rng = np.random.RandomState(42)\n    n_samples = 50\n    n_features = 20\n    X, y = make_classification(n_samples=n_samples, n_features=n_features,\n                               random_state=0)\n    y[y == 1] = 0  # Binary classification\n    class_weight = {0: 0.5, 1: 2}\n\n    lr_l1 = LogisticRegression(penalty=\"l1\", C=1.0, solver='liblinear',\n                               fit_intercept=False, class_weight=class_weight)\n    lr_l1.fit(X, y)\n\n    assert_array_almost_equal(lr_l1.coef_[0, :], lr_l1.coef_[0, :])\n"], "sample_836": ["def test_ovr_decision_function():\n    # Test with simple binary classifiers\n    predictions = np.array([[0, 1], [1, 0], [0, 1], [1, 0]])\n    confidences = np.array([[0.8, 0.2], [0.3, 0.7], [0.9, 0.1], [0.1, 0.9]])\n    n_classes = 2\n    decision_function = _ovr_decision_function(predictions, confidences, n_classes)\n    expected_decision_function = np.array([[-0.2, 0.2],\n                                           [0.3, -0.3],\n                                           [-0.1, 0.1],\n                                           [-0.9, 0.9]])\n    assert_array_almost_equal(decision_function, expected_decision_function)\n\n    # Test with multi-class case\n    predictions = np.array([[0, 1, 2], [1, 2, 0], [2, 0, 1]])\n    confidences = np.array([[0.8, 0.1, 0.1], [0.3, 0.6, 0.1], [0.1, 0.2, 0.7]])\n    n_classes = 3\n    decision_function = _ovr_decision_function(predictions, confidences, n_classes)\n    expected_decision_function = np.array([[-0.2, 0.2, -0.2],\n                                           [0.3, -0.3, 0.3],\n                                           [-0.1, 0.1, -0.1]])\n    assert_array_almost_equal(decision_function, expected_decision_function)\n"], "sample_859": ["    def test_lassoCV_precompute_default(self):\n        X, y, _, _ = build_dataset()\n        lasso_cv = LassoCV(n_alphas=10, eps=1e-3, precompute='auto')\n        lasso_cv.fit(X, y)\n        assert lasso_cv.precompute is not None\n"], "sample_752": ["def test_iforest_oob_score():\n    # Test that oob_score is not supported\n    X = iris.data\n    with pytest.raises(NotImplementedError):\n        IsolationForest(oob_score=True).fit(X)\n"], "sample_672": ["def test_circular_references():\n    class A:\n            self.b = b\n\n    class B:\n            self.a = a\n\n    a = A(B(a))\n    assert saferepr(a)\n"], "sample_596": ["    def test_concat_non_matching_dims(self):\n        da1 = DataArray([1, 2], dims=\"x\")\n        da2 = DataArray([3, 4, 5], dims=\"y\")\n        with raises_regex(ValueError, \"Dimensions 'x' and 'y' are not compatible\"):\n            concat([da1, da2], dim=\"z\")\n"], "sample_923": ["    def check_xref_consistency(role, tag, expected_classes):\n        classes_found = classes(role, tag)\n        assert classes_found == expected_classes, (\n            f\"Classes found for role '{role}' with tag '{tag}': {classes_found}\"\n            f\"Expected: {expected_classes}\"\n        )\n"], "sample_569": ["    def test_lmplot_facet_kws_with_hue(self):\n\n        g = lm.lmplot(\n            data=self.df, x=\"x\", y=\"y\", hue=\"h\", col=\"g\",\n            facet_kws={\"xlim\": (-3, 3), \"ylim\": (-5, 5)}\n        )\n        for ax in g.axes.flat:\n            assert ax.get_xlim() == (-3, 3)\n            assert ax.get_ylim() == (-5, 5)\n"], "sample_413": ["    def test_template_tags_with_same_library_name_and_different_module_paths(self):\n        with self.settings(\n            TEMPLATES=[\n                self.get_settings(\n                    \"same_tags\", \"same_tags_app_1.templatetags.same_tags\"\n                ),\n                self.get_settings(\n                    \"same_tags\", \"same_tags_app_2.templatetags.different_same_tags\"\n                ),\n            ]\n        ):\n            self.assertEqual(\n                check_for_template_tags_with_the_same_name(None),\n                [\n                    Error(\n                        E003.msg.format(\n                            \"'same_tags'\",\n                            \"'check_framework.template_test_apps.same_tags_app_1.\"\n                            \"templatetags.same_tags', \"\n                            \"'check_framework.template_test_apps.same_tags_app_2.\"\n                            \"templatetags.different_same_tags'\",\n                        ),\n                        id=E003.id,\n                    )\n                ],\n            )\n"], "sample_724": ["def test_imputation_sparse_missing_values_zero():\n    # Test imputation with sparse matrices and missing_values=0.\n    X = sparse.csc_matrix(\n        [[1, 0, 0],\n         [0, np.nan, 0],\n         [0, 0, 1]])\n\n    X_true = sparse.csc_matrix(\n        [[1, 0, 0],\n         [0, 0, 0],\n         [0, 0, 1]])\n\n    _check_statistics(X, X_true, \"mean\", [1, 0, 1], 0)\n    _check_statistics(X, X_true, \"median\", [1, 0, 1], 0)\n    _check_statistics(X, X_true, \"most_frequent\", [1, 0, 1], 0)\n"], "sample_1123": ["def test_CondSet_subs_with_dummy():\n    c = ConditionSet(x, x < 1, {x, y})\n    assert c.subs(c.sym, y) == ConditionSet(y, y < 1, {y, z})\n    assert c.subs(c.sym, z) == ConditionSet(z, z < 1, {z, y})\n    assert c.subs(c.sym, L) == ConditionSet(L, L < 1, {L, y})\n"], "sample_9": ["def test_write_table_html_fill_values_masked_multi_dimensional():\n    \"\"\"\n    Test that passing masked values in fill_values should only replace\n    masked columns or values for multidimensional tables\n    \"\"\"\n    buffer_output = StringIO()\n    t = Table([[1, 2, 3], [np.ma.masked, 'a', 3]], names=('a', 'b', 'c'))\n    ascii.write(t, buffer_output, fill_values=[(ascii.masked, 'MASKED')],\n                format='html')\n\n    t_expected = Table([[1, 2, 3], [ascii.masked, 'MASKED', 3]], names=('a', 'b', 'c'))\n    buffer_expected = StringIO()\n    ascii.write(t_expected, buffer_expected, format='html')\n    assert buffer_output.getvalue() == buffer_expected.getvalue()\n"], "sample_348": ["    def test_actions_with_permissions(self):\n        @admin.action(permissions=['custom_permission'])\n            pass\n\n        class BandAdmin(ModelAdmin):\n            actions = (custom_action,)\n\n        self.assertIsInvalid(\n            BandAdmin, Band,\n            'BandAdmin must define a has_custom_permission() method for the '\n            'custom_action action.',\n            id='admin.E129',\n        )\n"], "sample_283": ["    def test_empty_settings(self):\n        self.assertEqual(\n            self.settings_to_cmd_args_env({}),\n            (['psql', 'postgres'], {}),\n        )\n"], "sample_942": ["def test_py_exception_signature(app):\n    text = (\".. py:exception:: MyException\\n\"\n            \"   :base: Exception\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"MyException\"],\n                                                    [desc_annotation, (\": \",\n                                                                       [pending_xref, \"Exception\"])])],\n                                  desc_content)]))\n    assert 'MyException' in domain.objects\n    assert domain.objects['MyException'] == ('index', 'MyException', 'exception', False)\n"], "sample_198": ["    def test_output_field_in_group_by(self):\n        expr = ExpressionWrapper(Value(3), output_field=IntegerField())\n        self.assertEqual(expr.get_group_by_cols(alias=None), [])\n"], "sample_906": ["compilation error"], "sample_316": ["    def test_spooled_temp_file_seek(self):\n        with tempfile.SpooledTemporaryFile() as temp:\n            temp.write(b\"foo bar baz quux\\n\")\n            temp.seek(0)\n            temp.seek(6)\n            self.assertEqual(temp.read(), b\" bar baz quux\\n\")\n"], "sample_1026": ["def test_issue_16645():\n    from sympy import symbols, sin, cos, pi\n    x = symbols('x')\n    f = lambdify(x, sin(x) + cos(x), 'numpy')\n    assert f(pi/2) == 1 + 0\n    assert f(pi) == 0 + (-1)\n"], "sample_873": ["def test_get_feature_names_out():\n    sel = StepSelector()\n    sel.fit(X, y)\n    assert_array_equal(feature_names_t, sel.get_feature_names_out(input_features=feature_names))\n"], "sample_721": ["    def test_check_array_dtype_warning_with_sparse():\n        X_csr = sp.csr_matrix([[1, 2], [3, 4]])\n        X_float64 = np.asarray(X_csr.toarray(), dtype=np.float64)\n        X_float32 = np.asarray(X_csr.toarray(), dtype=np.float32)\n\n        # Check that the warning message includes the name of the Estimator\n        X_checked = assert_warns_message(DataConversionWarning, 'KNeighborsClassifier',\n                                        check_array, X_csr,\n                                        dtype=np.float64, accept_sparse=True,\n                                        warn_on_dtype=True, estimator=KNeighborsClassifier())\n        assert_equal(X_checked.dtype, np.float64)\n\n        # Check that the warning message includes the name of the Estimator\n        X_checked = assert_warns_message(DataConversionWarning, 'SomeEstimator',\n                                        check_array, X_csr,\n                                        dtype=[np.float64, np.float32],\n                                        accept_sparse=True,\n                                        warn_on_dtype=True,\n                                        estimator='SomeEstimator')\n        assert_equal(X_checked.dtype, np.float64)\n\n        # Check that the warning message includes the name of the Estimator\n        X_checked = assert_warns_message(DataConversionWarning, 'SomeEstimator',\n                                        check_array, X_csr,\n                                        dtype=[np.float64, np.float32],\n                                        accept_sparse=['csr', 'dok'],\n                                        copy=True,\n                                        warn_on_dtype=True,\n                                        estimator='SomeEstimator')\n        assert_equal(X_checked.dtype, np.float64)\n\n        # Check that the warning message includes the name of the Estimator\n        X_checked = assert_warns_message(DataConversionWarning, 'SomeEstimator',\n                                        check_array, X_csr,\n                                        dtype=[np.float64, np.float32],\n                                        accept_sparse=['csr', 'dok'],\n                                        copy=False,\n                                        "], "sample_1087": ["def test_fateman_poly_F_3():\n    f, g, h = fateman_poly_F_3(1)\n    F, G, H = dmp_fateman_poly_F_3(1, ZZ)\n\n    assert [ t.rep.rep for t in [f, g, h] ] == [F, G, H]\n\n    f, g, h = fateman_poly_F_3(3)\n    F, G, H = dmp_fateman_poly_F_3(3, ZZ)\n\n    assert [ t.rep.rep for t in [f, g, h] ] == [F, G, H]\n"], "sample_65": ["    def test_i18n_with_plural_forms(self):\n        with self.settings(LANGUAGE_CODE='de'), override('es'):\n            response = self.client.get('/jsi18n/')\n            self.assertContains(response, '1 Element')\n            self.assertContains(response, '455 Elemente')\n"], "sample_416": ["    def test_empty_settings(self):\n        self.assertEqual(\n            self.settings_to_cmd_args_env({}),\n            ([\"psql\", \"postgres\"], None),\n        )\n"], "sample_311": ["    def test_missing_slash_append_slash_true_non_staff_user_without_final_catch_all_view(self):\n        user = User.objects.create_user(\n            username='user',\n            password='secret',\n            email='user@example.com',\n            is_staff=False,\n        )\n        self.client.force_login(user)\n        known_url = reverse('admin10:admin_views_article_changelist')\n        response = self.client.get(known_url[:-1])\n        self.assertRedirects(response, '/test_admin/admin10/login/?next=/test_admin/admin10/admin_views/article')\n"], "sample_169": ["    def test_key_transform_with_subquery(self):\n        subquery = Subquery(\n            NullableJSONModel.objects.filter(value__a='b').values('value__c')\n        )\n        qs = NullableJSONModel.objects.annotate(\n            key=KeyTransform('c', subquery)\n        ).filter(key__gt=10)\n        self.assertSequenceEqual(qs, [self.objs[3]])\n"], "sample_1047": ["def test_issue_10302_2():\n    x = Symbol('x')\n    r = Symbol('r', real=True)\n    u = -(3*2**pi)**(1/pi) + 2*3**(1/pi)\n    i = u + u*I\n    assert (u + i).is_zero is None\n    assert (1 + i).is_zero is False\n    a = Dummy('a', zero=True)\n    assert (a + I).is_zero is False\n    assert (a + r*I).is_zero is None\n    assert (a + I).is_imaginary\n    assert (a + x + I).is_imaginary is None\n    assert (a + r*I + I).is_imaginary is None\n"], "sample_618": ["def test_polyval_invalid_input():\n    x = xr.DataArray([1, 2, 3], dims=\"x\")\n    coeffs = xr.DataArray([2, 3, 4], dims=\"degree\", coords={\"degree\": [0, 1, 2]})\n    with pytest.raises(TypeError):\n        xr.polyval(x, coeffs.astype(str))\n    with pytest.raises(TypeError):\n        xr.polyval(x, 1)\n    with pytest.raises(ValueError):\n        xr.polyval(x, coeffs.where(coeffs > 10))\n    with pytest.raises(ValueError):\n        xr.polyval(x, coeffs.where(coeffs > 10, other=10))\n    with pytest.raises(ValueError):\n        xr.polyval(x, coeffs.where(coeffs > 10, other=xr.DataArray([1, 2, 3], dims=\"degree\")))\n"], "sample_723": ["def test_imputation_sparse_csr_axis_1():\n    # Test imputation with sparse CSR matrix and axis=1\n    X = sparse.csr_matrix([\n        [1, 2, 3],\n        [np.nan, 5, 6],\n        [7, np.nan, 9],\n    ])\n\n    imputer = SimpleImputer(missing_values=0, strategy=\"mean\", axis=1)\n    imputer.fit(X)\n\n    X_imputed = imputer.transform(X)\n\n    # Expected values\n    X_expected = sparse.csr_matrix([\n        [1, 2, 3],\n        [3, 5, 6],\n        [7, 6, 9],\n    ])\n\n    assert_array_equal(X_imputed.toarray(), X_expected.toarray())\n\n\n\n"], "sample_421": ["    def test_when_output_field_type_mismatch(self):\n        with self.assertRaises(TypeError):\n            Case(\n                When(Q(pk__in=[]), then=IntegerField()),\n                default=Value(\"default\"),\n                output_field=CharField(),\n            )\n"], "sample_151": ["    def test_add_blank_textfield_and_charfield_with_default(self, mocked_ask_method):\n        \"\"\"\n        #23405 - Adding a NOT NULL and blank `CharField` or `TextField`\n        with a default should not prompt for a default.\n        \"\"\"\n        changes = self.get_changes([self.author_empty], [self.author_with_biography_blank_default])\n        self.assertEqual(mocked_ask_method.call_count, 0)\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0)\n"], "sample_259": ["    def test_prefetch_object_with_nested_prefetch(self):\n        book1 = Book.objects.get(id=self.book1.id)\n        with self.assertNumQueries(2):\n            prefetch_related_objects([book1], Prefetch('authors',\n                                                     Prefetch('first_book')))\n\n        with self.assertNumQueries(0):\n            for author in book1.authors.all():\n                self.assertEqual(author.first_book, self.book1)\n"], "sample_407": ["    def test_reverse_foreign_key_instance_to_field_caching_with_to_field(self):\n        parent = ParentStringPrimaryKey.objects.create(name=\"a\")\n        ToFieldChildStringPrimaryKey.objects.create(parent=parent)\n        child = parent.to_field_children.get()\n        with self.assertNumQueries(0):\n            self.assertIs(child.parent, parent)\n"], "sample_180": ["    def test_unique_constraint_with_duplicate_name(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(fields=['age'], name='unique_age'),\n                    models.UniqueConstraint(fields=['age'], name='unique_age'),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"Duplicate constraint name 'unique_age' found.\",\n                obj=Model,\n                id='models.E014',\n            ),\n        ])\n"], "sample_466": ["    def test_serialize_custom_field(self):\n        class CustomField(models.Field):\n                super().__init__(**kwargs)\n\n                return \"CustomField\"\n\n                return models.CharField(\n                    max_length=255, **kwargs\n                )\n\n                return value\n\n        class CustomModel(models.Model):\n            field = CustomField()\n\n        with self.subTest(\"CustomField\"):\n            self.assertSerializedResultEqual(\n                CustomField(),\n                (\n                    \"migrations.test_writer.CustomField\",\n                    {\"import migrations.test_writer\"},\n                ),\n            )\n        with self.subTest(\"CustomModel\"):\n            self.assertSerializedResultEqual(\n                CustomModel,\n                (\n                    \"migrations.test_writer.CustomModel\",\n                    {\"import migrations.test_writer\"},\n                ),\n            )\n"], "sample_855": ["def test_dummy_regressor_with_missing_data():\n    X = [[0, None], [1, 2], [None, 4], [5, None]]\n    y = [2, 2, 2, 2]\n\n    reg = DummyRegressor(strategy=\"mean\")\n    reg.fit(X, y)\n    y_pred = reg.predict(X)\n    assert_array_equal(y_pred, y)\n\n    reg = DummyRegressor(strategy=\"median\")\n    reg.fit(X, y)\n    y_pred = reg.predict(X)\n    assert_array_equal(y_pred, y)\n\n    reg = DummyRegressor(strategy=\"quantile\", quantile=0.5)\n    reg.fit(X, y)\n    y_pred = reg.predict(X)\n    assert_array_equal(y_pred, y)\n\n    reg = DummyRegressor(strategy=\"constant\", constant=0)\n    reg.fit(X, y)\n    y_pred = reg.predict(X)\n    assert_array_equal(y_pred, [0, 0, 0, 0])\n"], "sample_273": ["    def test_explicit_pk_with_custom_field(self):\n        class MyIntegerField(models.IntegerField):\n            pass\n\n        class Model(models.Model):\n            id = MyIntegerField(primary_key=True)\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n"], "sample_489": ["    def test_update_conflicts_with_target_unsupported(self):\n        msg = (\n            \"This database backend does not support updating conflicts with \"\n            \"specifying a target field.\"\n        )\n        with self.assertRaisesMessage(NotSupportedError, msg):\n            UpsertConflict.objects.bulk_create(\n                [\n                    UpsertConflict(number=1, rank=1, name=\"John\"),\n                    UpsertConflict(number=2, rank=2, name=\"Mary\"),\n                    UpsertConflict(number=3, rank=3, name=\"Hannah\"),\n                ],\n                update_conflicts=True,\n                update_fields=[\"name\", \"rank\"],\n                unique_fields=[\"number\"],\n                target_field=\"rank\",\n            )\n"], "sample_1034": ["def test_apply_grover():\n    numqubits = 2\n    oracle = return_one_on_two\n    result = apply_grover(oracle, numqubits)\n    assert qapply(result) == IntQubit(2, nqubits=numqubits)\n"], "sample_677": ["def test_nested_parentheses(expr: str, expected: bool) -> None:\n    matcher = {\"true\": True, \"false\": False}.__getitem__\n    assert evaluate(expr, matcher) is expected\n"], "sample_774": ["def test_one_hot_encoder_sparse_output():\n    X = [['abc', 2, 55], ['def', 1, 55]]\n    enc = OneHotEncoder(sparse=True)\n    X_tr = enc.fit_transform(X)\n    assert isinstance(X_tr, sparse.csr_matrix)\n    assert X_tr.shape == (2, 6)\n\n    enc = OneHotEncoder(sparse=True, handle_unknown='ignore')\n    X2 = [['abc', 2, 55], ['def', 1, 56]]\n    X_tr2 = enc.fit_transform(X2)\n    assert isinstance(X_tr2, sparse.csr_matrix)\n    assert X_tr2.shape == (2, 6)\n\n    enc = OneHotEncoder(sparse=False)\n    X_tr3 = enc.fit_transform(X)\n    assert not isinstance(X_tr3, sparse.csr_matrix)\n    assert X_tr3.shape == (2, 6)\n"], "sample_1135": ["def test_issue_16820():\n    from sympy import symbols, sin, cos, pi\n    x, y = symbols('x y')\n    assert sin(x + y).expand() == sin(x)*cos(y) + cos(x)*sin(y)\n    assert cos(x + y).expand() == cos(x)*cos(y) - sin(x)*sin(y)\n    assert sin(x - y).expand() == sin(x)*cos(y) - cos(x)*sin(y)\n    assert cos(x - y).expand() == cos(x)*cos(y) + sin(x)*sin(y)\n    assert sin(x + pi/2).expand() == cos(x)\n    assert cos(x + pi/2).expand() == -sin(x)\n    assert sin(x - pi/2).expand() == -cos(x)\n    assert cos(x - pi/2).expand() == sin(x)\n"], "sample_537": ["    def test_psd_onesided_norm_complex(self):\n        u = np.array([0, 1, 2, 3, 1, 2, 1]) + 1j * np.array([0, 0.5, 1, 0.5, 0, 0.5, 1])\n        dt = 1.0\n        Su = np.abs(np.fft.fft(u) * dt)**2 / (dt * u.size)\n        P, f = mlab.psd(u, NFFT=u.size, Fs=1/dt, window=mlab.window_none,\n                        detrend=mlab.detrend_none, noverlap=0, pad_to=None,\n                        scale_by_freq=None,\n                        sides='onesided')\n        Su_1side = np.append([Su[0]], Su[1:4] + Su[4:][::-1])\n        assert_allclose(P, Su_1side, atol=1e-06)\n"], "sample_37": ["def test_sip_with_missing_coefficients():\n    \"\"\"\n    Test handling of SIP headers with missing coefficients.\n    \"\"\"\n    hdr = get_pkg_data_contents(\"data/sip-missing.hdr\")\n    w = wcs.WCS(hdr)\n    assert w.sip is not None\n    assert w.sip.a_order == 4\n    assert w.sip.b_order == 4\n    assert w.sip.ap_order == 0\n    assert w.sip.bp_order == 0\n    assert_array_equal(w.sip.crpix, [2048., 1024.])\n"], "sample_295": ["    def test_output_field_with_group_by(self):\n        expr = ExpressionWrapper(\n            F('cost') + F('tax'), output_field=IntegerField()\n        )\n        self.assertEqual(expr.get_group_by_cols(alias=None), ['cost', 'tax'])\n"], "sample_661": ["def test_unicode_issue368_with_junit_family_xunit2(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        junit_family = xunit2\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            record_xml_attribute(\"bar\", 1)\n            record_xml_attribute(\"foo\", \"\u0412\u041d\u0418!\")\n    \"\"\"\n    )\n    result, dom = runandparse(testdir, \"-rw\")\n    node = dom.find_first_by_tag(\"testsuite\")\n    tnode = node.find_first_by_tag(\"testcase\")\n    tnode.assert_attr(bar=\"1\")\n    tnode.assert_attr(foo=\"\u0412\u041d\u0418!\")\n    result.stdout.fnmatch_lines(\n        [\"*test_unicode_issue368_with_junit_family_xunit2.py:6:*record_xml_attribute is an experimental feature\"]\n    )\n"], "sample_878": ["def test_column_transformer_with_missing_remainder_transformers(\n    remainder, verbose_feature_names_out"], "sample_398": ["    def test_user_change_password_with_empty_password(self):\n        url = reverse(\n            \"auth_test_admin:auth_user_password_change\", args=(self.admin.pk,)\n        )\n        response = self.client.post(url, {\"password1\": \"\", \"password2\": \"\"})\n        self.assertContains(response, \"Password cannot be blank.\")\n"], "sample_730": ["def test_enet_multioutput_sparse_input():\n    X, y, _, _ = build_dataset(n_samples=50, n_features=20)\n    X_sparse = sparse.csr_matrix(X)\n    y_multi = np.hstack((y[:, np.newaxis], y[:, np.newaxis]))\n\n    clf = ElasticNet(alpha=0.1, l1_ratio=0.5, tol=1e-8)\n    clf.fit(X_sparse, y_multi)\n    assert_array_almost_equal(clf.coef_[0], clf.coef_[1])\n    assert_array_almost_equal(clf.intercept_[0], clf.intercept_[1])\n\n    clf = MultiTaskElasticNet(alpha=0.1, l1_ratio=0.5, tol=1e-8)\n    clf.fit(X_sparse, y_multi)\n    assert_array_almost_equal(clf.coef_[0], clf.coef_[1])\n    assert_array_almost_equal(clf.intercept_[0], clf.intercept_[1])\n\n\n\n"], "sample_1093": ["def test_sympy_printer_matrix_operations():\n    from sympy import Matrix, eye, zeros, ones, diag, MatrixSymbol, transpose, det, inv\n    from sympy.codegen.matrix_nodes import MatrixSolve\n\n    prntr = SymPyPrinter()\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    x = MatrixSymbol('x', 2, 1)\n    y = MatrixSymbol('y', 2, 1)\n\n    assert prntr.doprint(eye(3)) == 'sympy.eye(3)'\n    assert prntr.doprint(zeros(2, 3)) == 'sympy.zeros((2, 3))'\n    assert prntr.doprint(ones(2, 3)) == 'sympy.ones((2, 3))'\n    assert prntr.doprint(diag([1, 2, 3])) == 'sympy.diag([1, 2, 3])'\n    assert prntr.doprint(transpose(A)) == 'A.T'\n    assert prntr.doprint(det(A)) == 'sympy.det(A)'\n    assert prntr.doprint(inv(A)) == 'sympy.inv(A)'\n    assert prntr.doprint(MatrixSolve(A, x)) == 'sympy.solve(A, x)'\n    assert prntr.doprint(MatrixSolve(A, x) + y) == 'sympy.solve(A, x) + y'\n\n\n\n"], "sample_1172": ["compilation error"], "sample_1099": ["def test_eval_partial_derivative_mixed_derivatives():\n    tau, alpha = symbols(\"tau alpha\")\n\n    expr1 = A(i)*H(-i, j) + A(i)*A(-i)*A(j) + tau**alpha*A(j)\n\n    # mixed derivative test\n    mixed_derivative = PartialDerivative(expr1, (A(k), H(l, m)))._perform_derivative()\n\n    assert mixed_derivative == 0\n"], "sample_513": ["def test_legend_handles_from_patches():\n    fig, ax = plt.subplots()\n    patches = [plt.Rectangle((0, 0), 1, 1, facecolor='red', label='patch1'),\n               plt.Rectangle((2, 2), 1, 1, facecolor='blue', label='patch2')]\n    ax.add_patch(patches[0])\n    ax.add_patch(patches[1])\n    legend = ax.legend()\n    assert len(legend.legendHandles) == len(patches)\n    for i in range(len(patches)):\n        assert legend.legendHandles[i].get_facecolor() == patches[i].get_facecolor()\n"], "sample_1065": ["def test_binomial_series():\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True)\n\n    assert binomial(n, k).series(n, 0, 3) == \\\n        binomial(n, k) + O(n**2)\n    assert binomial(n, k).series(k, 0, 3) == \\\n        binomial(n, k) + O(k**2)\n\n\n\n"], "sample_675": ["        def test_bad_log():\n            logging.warning('oops', 'first', 2)"], "sample_719": ["def test_vectorizer_custom_analyzer():\n        return [word.upper() for word in text.split()]\n\n    vect = CountVectorizer(analyzer=custom_analyzer)\n    X = vect.fit_transform(JUNK_FOOD_DOCS)\n    assert_array_equal(\n        X.toarray(),\n        [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n    )\n"], "sample_1195": ["def test_kahane_simplify_mixed_indices():\n    i0,i1,i2,i3,i4,i5,i6,i7,i8,i9,i10,i11,i12,i13,i14,i15 = tensor_indices('i0:16', LorentzIndex)\n    mu, nu, rho, sigma = tensor_indices(\"mu, nu, rho, sigma\", LorentzIndex)\n    D = 4\n    t = G(i0)*G(i1)*G(-i0)*G(mu)\n    r = kahane_simplify(t)\n    assert r.equals(-2*G(i1)*G(mu))\n\n    t = G(i0)*G(i1)*G(-i0)*G(mu)*G(-mu)\n    r = kahane_simplify(t)\n    assert r.equals(-2*G(i1)*G(mu)*G(-mu))\n\n    t = G(i0)*G(i1)*G(-i0)*G(mu)*G(nu)\n    r = kahane_simplify(t)\n    assert r.equals(-2*G(i1)*G(mu)*G(nu))\n\n    t = G(i0)*G(i1)*G(-i0)*G(mu)*G(nu)*G(-nu)\n    r = kahane_simplify(t)\n    assert r.equals(-2*G(i1)*G(mu)*G(nu)*G(-nu))\n\n    t = G(i0)*G(i1)*G(-i0)*G(mu)*G(nu)*G(-nu)*G(rho)\n    r = kahane_simplify(t)\n    assert r.equals(-2*G(i1)*G(mu)*G(nu)*G(-nu)*G(rho))\n\n    t = G(i0)*G(i1)*G(-i0)*G(mu)*G(nu)*G(-nu)*G(rho)*G(-rho)\n    r = kahane_simplify(t)\n    assert r.equals(-2*G(i1)*G(mu)*G(nu)*G(-nu)*G(rho"], "sample_966": ["def test_python_python_use_unqualified_type_names_enabled(app, status, warning):\n    app.build()\n    content = (app.outdir / 'index.html').read_text()\n    assert ('<span class=\"n\"><span class=\"pre\">Name</span></span>' in content)\n    assert ('<span class=\"n\"><span class=\"pre\">Age</span></span>' in content)\n    assert ('<p><strong>name</strong> (<span class=\"n\"><span class=\"pre\">Name</span></span>) \u2013 blah blah</p>' in content)\n    assert '<p><strong>age</strong> (<span class=\"n\"><span class=\"pre\">Age</span></span>) \u2013 blah blah</p>' in content\n"], "sample_248": ["    def test_stdin_read_empty(self, select):\n        with captured_stdin() as stdin, captured_stdout() as stdout:\n            stdin.write('')\n            stdin.seek(0)\n            call_command('shell')\n        self.assertEqual(stdout.getvalue().strip(), '')\n"], "sample_1007": ["def test_binomial_expand():\n    x = Symbol('x')\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True)\n    assert binomial(n, 0).expand() == 1\n    assert binomial(n, 1).expand() == n*x\n    assert binomial(n, 2).expand() == n*(n - 1)*x**2/2\n    assert binomial(n, 3).expand() == n*(n - 1)*(n - 2)*x**3/6\n    assert binomial(n, n).expand() == x**n\n    assert binomial(n, n - 1).expand() == n*x**(n - 1)\n    assert binomial(n, k).expand(func=True) == \\\n        sum(binomial(n, i)*x**i for i in range(k + 1))\n    assert binomial(n, k).expand(func=True) == \\\n        sum(binomial(n, i)*x**i for i in range(k + 1))\n    assert binomial(n, k).expand(func=True) == \\\n        sum(binomial(n, i)*x**i for i in range(k + 1))\n    assert binomial(n, k).expand(func=True) == \\\n        sum(binomial(n, i)*x**i for i in range(k + 1))\n    assert binomial(n, k).expand(func=True) == \\\n        sum(binomial(n, i)*x**i for i in range(k + 1))\n    assert binomial(n, k).expand(func=True) == \\\n        sum(binomial(n, i)*x**i for i in range(k + 1))\n    assert binomial(n, k).expand(func=True) == \\\n        sum(binomial(n, i)*x**i for i in range(k + 1))\n    assert binomial(n, k).expand(func=True) == \\\n        sum(binomial(n, i)*x**i for i in range(k + 1))\n    assert binomial(n, k).expand(func=True) =="], "sample_177": ["    def test_proxy_with_fk(self):\n        A = self.create_model(\"A\")\n        B = self.create_model(\"B\", bases=(A,), proxy=True)\n        C = self.create_model(\"C\", foreign_keys=[models.ForeignKey('B', models.CASCADE)])\n        self.assertRelated(A, [B, C])\n        self.assertRelated(B, [C])\n        self.assertRelated(C, [B])\n\n"], "sample_424": ["    def test_references_field_by_related_name(self):\n        operation = FieldOperation(\n            \"Model\",\n            \"field\",\n            models.ForeignKey(\"Other\", models.CASCADE, related_name=\"related_field\"),\n        )\n        self.assertIs(\n            operation.references_field(\"Other\", \"related_field\", \"migrations\"), True\n        )\n        self.assertIs(operation.references_field(\"Other\", \"whatever\", \"migrations\"), False)\n"], "sample_807": ["    def predict_proba(self, X):\n        return np.random.rand(X.shape[0], len(self.classes_))\n"], "sample_982": ["compilation error"], "sample_1052": ["compilation error"], "sample_188": ["    def test_output_field_with_group_by(self):\n        expr = ExpressionWrapper(Value(3), output_field=IntegerField())\n        self.assertEqual(expr.get_group_by_cols(alias=None), [])\n        expr = ExpressionWrapper(F('id'), output_field=IntegerField())\n        self.assertEqual(expr.get_group_by_cols(alias=None), ['id'])\n"], "sample_77": ["    def test_urlize_with_trim_url_limit(self):\n        items = (\n            (\n                'This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-trim_url_limit-30',\n                'This is a long URL: <a href=\"http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-trim_url_limit-30\">http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-trim_url_limit-30...</a>',\n                30\n            ),\n            (\n                'This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-trim_url_limit-20',\n                'This is a long URL: <a href=\"http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-trim_url_limit-20\">http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-trim_url_limit-20...</a>',\n                20\n            ),\n        )\n        for value, output, limit in items:\n            with self.subTest(value=value, output=output, limit=limit):\n                self.assertEqual(urlize(value, trim_url_limit=limit), output)\n"], "sample_731": ["compilation error"], "sample_834": ["def test_nca_with_precomputed_transform():\n    rng = np.random.RandomState(42)\n    X = rng.randn(10, 5)\n    y = rng.randint(0, 2, size=10)\n    nca = NeighborhoodComponentsAnalysis(n_components=3,\n                                        init='precomputed',\n                                        random_state=rng)\n    init = rng.randn(5, 3)\n    nca.components_ = init\n    nca.fit(X, y)\n    assert_array_almost_equal(nca.transform(X),\n                              np.dot(X, nca.components_.T))\n"], "sample_148": ["    def test_quote(self):\n        self.assertEqual(quote(\"Hello\"), \"'Hello'\")\n        self.assertEqual(quote(\"Hello world\"), \"'Hello world'\")\n        self.assertEqual(quote(\"Hello'\"), \"'Hello\\\\'\\\"'\")\n        self.assertEqual(quote(\"Hello\\\"world\"), \"'Hello\\\\\\\"world'\")\n        self.assertEqual(quote(\"Hello\\nworld\"), \"'Hello\\\\nworld'\")\n        self.assertEqual(quote(\"Hello\\tworld\"), \"'Hello\\\\tworld'\")\n"], "sample_592": ["    def test_summarize_attr(self):\n        cases = [\n            (\"key\", \"Short string\", \"    key: Short string\"),\n            (\"key\", 100 * \"Very long string \", \"    key: Very long string ...\"),\n            (\"key\", \"\\n\\n\\n\", \"    key: \\n\\n\\n\"),\n            (\"key\", \"\\t\\t\\t\", \"    key: \\t\\t\\t\"),\n            (\"key\", None, \"    key: None\"),\n            (\"key\", np.array([1, 2, 3]), \"    key: [1 2 3]\"),\n            (\"key\", np.array([1, 2, 3], dtype=\"float64\"), \"    key: [1. 2. 3.]\"),\n            (\"key\", pd.Timestamp(\"2023-10-26T10:00:00\"), \"    key: 2023-10-26T10:00:00\"),\n            (\"key\", pd.Timedelta(\"1 day 2 hours\"), \"    key: 1 days 02:00:00\"),\n        ]\n        for key, value, expected in cases:\n            actual = formatting.summarize_attr(key, value)\n            assert actual == expected\n"], "sample_1056": ["def test_custom_printed_object():\n    obj = CustomPrintedObject()\n    assert lambdarepr(obj) == 'lambda'\n    assert lambdarepr(obj, method='tensorflow') == 'tensorflow'\n    assert lambdarepr(obj, method='numpy') == 'numpy'\n    assert lambdarepr(obj, method='numexpr') == 'numexpr'\n    assert lambdarepr(obj, method='mpmath') == 'mpmath'\n    with raises(TypeError):\n        lambdarepr(obj, method='garbage')\n"], "sample_426": ["    def test_timeuntil_with_future_date(self):\n        future_date = self.t + self.oneday\n        self.assertEqual(timeuntil(future_date), \"1\\xa0day\")\n"], "sample_1197": ["def test_issue_24062_with_quantity_dimension():\n    from sympy.core.numbers import E\n    from sympy.physics.units import impedance, capacitance, time, ohm, farad, second\n    from sympy.physics.units.systems.si import dimsys_SI\n\n    R = Quantity('R')\n    C = Quantity('C')\n    T = Quantity('T')\n    SI.set_quantity_dimension(R, impedance)\n    SI.set_quantity_dimension(C, capacitance)\n    SI.set_quantity_dimension(T, time)\n    R.set_global_relative_scale_factor(1, ohm)\n    C.set_global_relative_scale_factor(1, farad)\n    T.set_global_relative_scale_factor(1, second)\n    expr = T / (R * C)\n    dim = SI._collect_factor_and_dimension(expr)[1]\n    assert dimsys_SI.get_dimensional_dependencies(dim) == {time: 1, impedance: -1, capacitance: -1}\n"], "sample_334": ["    def test_renderer_overrides_default(self):\n        class CustomForm(Form):\n            default_renderer = DjangoTemplates()\n\n        form = CustomForm(renderer=CustomRenderer())\n        self.assertEqual(form.renderer, CustomRenderer())\n"], "sample_959": ["compilation error"], "sample_241": ["    def test_output_field_override(self):\n        expr = ExpressionWrapper(F('name'), output_field=CharField(max_length=10))\n        self.assertEqual(expr.output_field, CharField(max_length=10))\n"], "sample_1144": ["compilation error"], "sample_541": ["def test_polygon_selector_reset(ax, draw_bounding_box):\n    verts = [(50, 50), (150, 50), (50, 150)]\n    event_sequence = [\n        *polygon_place_vertex(*verts[0]),\n        *polygon_place_vertex(*verts[1]),\n        *polygon_place_vertex(*verts[2]),\n        *polygon_place_vertex(*verts[0]),\n    ]\n\n    tool = widgets.PolygonSelector(ax, onselect=noop, draw_bounding_box=draw_bounding_box)\n    for (etype, event_args) in event_sequence:\n        do_event(tool, etype, **event_args)\n\n    tool.reset()\n    assert tool.verts == []\n"], "sample_1145": ["def test_refine_matrixelement_non_symmetric():\n    from sympy.matrices.expressions.matexpr import MatrixSymbol\n    X = MatrixSymbol('X', 3, 3)\n    assert refine_matrixelement(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine_matrixelement(X[1, 0], Q.symmetric(X)) == X[0, 1]\n"], "sample_362": ["    def test_operation_with_custom_name(self):\n        class Migration(migrations.Migration):\n            operations = [\n                migrations.CreateModel(\n                    name='MyCustomModel', model_name='MyCustomModel', fields=[]\n                ),\n            ]\n\n        migration = Migration('some_migration', 'test_app')\n        self.assertEqual(migration.suggest_name(), 'mycustommodel')\n"], "sample_657": ["    def test_pytest_param_id_raises_for_non_string(s):\n        with pytest.raises(TypeError) as excinfo:\n            pytest.param(id=s)\n        msg, = excinfo.value.args\n        assert msg == \"Expected id to be a string, got <class 'int'>: 1\"\n"], "sample_623": ["    def test_respect_chunk_size(self, shape, pref_chunks, req_chunks):\n        \"\"\"Respect the backend's preferred chunks when opening a dataset.\"\"\"\n        initial = self.create_dataset(shape, pref_chunks)\n        final = xr.open_dataset(\n            initial,\n            engine=PassThroughBackendEntrypoint,\n            chunks=dict(zip(initial[self.var_name].dims, req_chunks)),\n        )\n        self.check_dataset(initial, final, explicit_chunks(pref_chunks, shape))\n"], "sample_38": ["def test_wcs_from_fits_with_missing_crval():\n    \"\"\"\n    Test handling of FITS files with missing CRVAL keywords.\n    \"\"\"\n    hdr = get_pkg_data_contents(\"data/missing_crval.fits\", encoding='binary')\n    w = wcs.WCS(hdr)\n    assert w.wcs.crval is None\n    assert w.wcs.naxis == 2\n    assert w.wcs.ctype == ['RA---TAN', 'DEC--TAN']\n\n    # Check that pix2world and world2pix still work\n    x, y = w.wcs_pix2world([100, 100], 0)\n    assert np.isnan(x) and np.isnan(y)\n\n    x, y = w.wcs_world2pix([100, 100], 0)\n    assert np.isnan(x) and np.isnan(y)\n"], "sample_1200": ["def test_issue_25061():\n    from sympy.physics.units import Quantity, meter, second, kilogram\n    from sympy.physics.units.definitions import (\n        Dimension, mass, length, time\n    )\n\n    q1 = Quantity(\"q1\")\n    q2 = Quantity(\"q2\")\n    SI.set_quantity_dimension(q1, length*mass/time)\n    SI.set_quantity_dimension(q2, length**2/time)\n    q1.set_global_relative_scale_factor(1, meter*kilogram/second)\n    q2.set_global_relative_scale_factor(1, meter**2/second)\n\n    expr = q1 + q2\n    assert SI._collect_factor_and_dimension(expr) == (\n        1,\n        Dimension(length*mass/time + length**2/time)\n    )\n"], "sample_993": ["def test_FreeGroupElm_cyclic_conjugates():\n    w = x*y*x*y*x\n    assert len(w.cyclic_conjugates()) == 5\n    assert w in w.cyclic_conjugates()\n    assert x*y*x*y*x in w.cyclic_conjugates()\n    assert x*y*x*y*x*x in w.cyclic_conjugates()\n    assert x*y*x*y*x*x*x in w.cyclic_conjugates()\n    assert x*y*x*y*x*x*x*x in w.cyclic_conjugates()\n    assert x*y*x*y*x*x*x*x*x in w.cyclic_conjugates()\n    assert x*y*x*y*x*x*x*x*x*x in w.cyclic_conjugates()\n    assert x*y*x*y*x*x*x*x*x*x*x in w.cyclic_conjugates()\n    assert x*y*x*y*x*x*x*x*x*x*x*x in w.cyclic_conjugates()\n    assert x*y*x*y*x*x*x*x*x*x*x*x*x in w.cyclic_conjugates()\n    assert x*y*x*y*x*x*x*x*x*x*x*x*x*x in w.cyclic_conjugates()\n    assert x*y*x*y*x*x*x*x*x*x*x*x*x*x*x in w.cyclic_conjugates()\n    assert x*y*x*y*x*x*x*x*x*x*x*x*x*x*x*x in w.cyclic_conjugates()\n    assert x*y*x*y*x*x*x*x*x*x*x*x*x*x*x*x*x in w.cyclic_conjugates()\n    assert x*y*x*y*x*x*x*x*x*x*x*x*x*x*x*x*x*x in w."], "sample_762": ["def test_pickle_version_warning_is_issued_with_different_version_and_no_getstate():\n    iris = datasets.load_iris()\n    tree = TreeNoVersion().fit(iris.data, iris.target)\n    tree_pickle_noversion = pickle.dumps(tree)\n    message = pickle_error_message.format(estimator=\"TreeNoVersion\",\n                                          old_version=\"pre-0.18\",\n                                          current_version=sklearn.__version__)\n    assert_warns_message(UserWarning, message, pickle.loads,\n                         tree_pickle_noversion)\n"], "sample_31": ["    def test_write_latex_no_overwrite(self, write, tmp_path, format):\n        fp = tmp_path / \"test_write_latex_no_overwrite.tex\"\n        write(fp, format=format, overwrite=False)\n        with pytest.raises(FileExistsError, match=\"File exists\"):\n            write(fp, format=format, overwrite=False)\n"], "sample_559": ["def test_inset_axes_bbox_transform():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], [4, 5, 6])\n\n    inset_ax = zoomed_inset_axes(ax, zoom=2, loc='upper right')\n    inset_ax.plot([1, 2, 3], [4, 5, 6])\n\n    # Test that the bbox_transform is applied correctly\n    bbox = inset_ax.get_tight_bbox(fig.canvas.get_renderer())\n    assert bbox.x0 > 0\n    assert bbox.y0 > 0\n    assert bbox.x1 < ax.bbox.width\n    assert bbox.y1 < ax.bbox.height\n"], "sample_593": ["def test_summarize_attrs_empty(dataset):\n    dataset_no_attrs = dataset.copy()\n    dataset_no_attrs.attrs = {}\n    formatted = fh.summarize_attrs(dataset_no_attrs.attrs)\n    assert formatted == \"\"\n"], "sample_860": ["def test_check_sparse_matrix_dtype():\n    X = sp.csr_matrix([[1, 2], [3, 4]], dtype=np.float32)\n    assert check_sparse_matrix_dtype(X, dtype=np.float32) is None\n    assert_raises_regex(ValueError,\n                        r\"Sparse matrix dtype mismatch: expected np\\.float32, got np\\.int64\",\n                        check_sparse_matrix_dtype,\n                        X.astype(np.int64),\n                        dtype=np.float32)\n    assert_raises_regex(ValueError,\n                        r\"Sparse matrix dtype mismatch: expected np\\.float32, got object\",\n                        check_sparse_matrix_dtype,\n                        X.astype(object),\n                        dtype=np.float32)\n\n\n\n"], "sample_201": ["    def test_not_finished_sentinel(self):\n        storage = self.get_storage()\n        response = self.get_response()\n\n        # Add a few messages to the storage\n        for i in range(5):\n            storage.add(constants.INFO, f'Message {i}')\n\n        # Update the response and check that the cookie contains all messages\n        storage.update(response)\n        self.assertEqual(stored_cookie_messages_count(storage, response), 5)\n\n        # Remove some messages from the storage\n        for i in range(3):\n            storage.pop()\n\n        # Update the response again and check that the cookie contains the remaining messages\n        storage.update(response)\n        self.assertEqual(stored_cookie_messages_count(storage, response), 2)\n\n        # Check that the cookie contains the sentinel value indicating that not all messages were stored\n        cookie = response.cookies.get(storage.cookie_name)\n        self.assertEqual(cookie.value, storage._encode(storage.get_messages() + [storage.not_finished], encode_empty=True))\n\n        # Remove the sentinel value and check that the cookie is empty\n        storage.update(response)\n        self.assertEqual(stored_cookie_messages_count(storage, response), 0)\n"], "sample_642": ["def test_preprocess_options_no_match() -> None:\n    \"\"\"Test that options with no match are passed through.\"\"\"\n    with tempdir() as chroot:\n        with fake_home():\n            chroot_path = Path(chroot)\n            testutils.create_files([\"a/b/c/d/__init__.py\"])\n            os.chdir(chroot_path / \"a/b/c\")\n            args = [\"--unknown-option\", \"value\", \"script.py\"]\n            processed_args = _preprocess_options(Run(), args)\n            assert processed_args == args\n"], "sample_428": ["    def test_empty_string(self):\n        self.assertEqual(nformat(\"\"), \"\")\n        self.assertEqual(nformat(\"\", \".\"), \"\")\n        self.assertEqual(nformat(\"\", \".\", decimal_pos=2), \"0.00\")\n        self.assertEqual(nformat(\"\", \".\", grouping=2, thousand_sep=\",\"), \"\")\n        self.assertEqual(\n            nformat(\"\", \".\", grouping=2, thousand_sep=\",\", force_grouping=True), \"\"\n        )\n"], "sample_768": ["        def __repr__(self):\n            return f\"{self.__class__.__name__}(a={self.a}, b={self.b}, c={self.c})\"\n"], "sample_42": ["def test_equivalency_context_manager_with_custom_equivalencies():\n    with u.set_enabled_equivalencies(\n        equivalencies=[(u.m, u.km), (u.s, u.ms)]\n    ):\n        m = 10 * u.m\n        assert m.to(u.km).value == 0.01\n        s = 5 * u.s\n        assert s.to(u.ms).value == 5000\n"], "sample_556": ["compilation error"], "sample_1012": ["def test_print_complex():\n    assert pycode(1 + 2j) == '1 + 2j'\n    assert pycode(complex(1, 2)) == '1 + 2j'\n"], "sample_412": ["    def test_urlize_with_trim_url_limit(self):\n        items = (\n            (\"This is a long URL: http://www.example.com/this-is-a-very-long-url-that-will-be-truncated\",\n             \"This is a long URL: <a href=\\\"http://www.example.com/this-is-a-very-long-url-that-will-be-truncated\\\">http://www.example.com/this-is-a-very-long-url-that-will-be-truncated...</a>\"),\n            (\"This is a short URL: http://www.example.com/short\",\n             \"This is a short URL: <a href=\\\"http://www.example.com/short\\\">http://www.example.com/short</a>\"),\n        )\n        for value, output in items:\n            with self.subTest(value=value):\n                self.assertEqual(urlize(value, trim_url_limit=50), output)\n"], "sample_783": ["def test_imputation_constant_object_errors(X_data, missing_value):\n    # Test imputation using the constant strategy on objects with errors\n    X = np.full((3, 5), X_data, dtype=object)\n    X[0, 0] = missing_value\n\n    with pytest.raises(ValueError, match=\"imputing numerical\"):\n        imputer = SimpleImputer(missing_values=missing_value,\n                                strategy=\"constant\",\n                                fill_value=\"x\")\n        imputer.fit_transform(X)\n"], "sample_516": ["def test_text_rotation():\n    fig, ax = plt.subplots()\n    ax.text(0.5, 0.5, 'Rotated Text', ha='center', va='center', rotation=45)\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n"], "sample_124": ["    def test_renderer_overrides_default(self):\n        class CustomForm(Form):\n            default_renderer = DjangoTemplates()\n\n        form = CustomForm(renderer=CustomRenderer())\n        self.assertEqual(form.renderer, CustomRenderer())\n"], "sample_277": ["    def test_resolve_expression(self):\n        q = Q(id=1)\n        clause, joins = q.resolve_expression()\n        self.assertEqual(clause, 'id=1')\n        self.assertEqual(joins, [])\n"], "sample_90": ["    def test_setattr_raises_validation_error_field_specific_with_instance(self):\n        \"\"\"\n        A model ValidationError using the dict form should put the error\n        message into the correct key of form.errors, even when an instance\n        is provided.\n        \"\"\"\n        form_class = modelform_factory(model=StrictAssignmentFieldSpecific, fields=['title'])\n        instance = StrictAssignmentFieldSpecific(title='testing setattr')\n        form = form_class(data={'title': 'testing setattr'}, files=None, instance=instance)\n        # This line turns on the ValidationError; it avoids the model erroring\n        # when its own __init__() is called when creating form.instance.\n        form.instance._should_error = True\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors, {\n            'title': ['Cannot set attribute', 'This field cannot be blank.']\n        })\n"], "sample_1151": ["def test_issue_19003():\n    from sympy import symbols, sin, cos, pi\n    x, y = symbols('x y')\n    assert sin(x + y).expand(trig=True) == sin(x)*cos(y) + cos(x)*sin(y)\n    assert cos(x + y).expand(trig=True) == cos(x)*cos(y) - sin(x)*sin(y)\n    assert sin(x - y).expand(trig=True) == sin(x)*cos(y) - cos(x)*sin(y)\n    assert cos(x - y).expand(trig=True) == cos(x)*cos(y) + sin(x)*sin(y)\n    assert sin(x + pi/2).expand(trig=True) == cos(x)\n    assert cos(x + pi/2).expand(trig=True) == -sin(x)\n    assert sin(x - pi/2).expand(trig=True) == -cos(x)\n    assert cos(x - pi/2).expand(trig=True) == sin(x)\n"], "sample_538": ["compilation error"], "sample_545": ["compilation error"], "sample_347": ["    def test_localtime_naive_with_tz(self):\n        naive = datetime.datetime(2015, 1, 1, 0, 0, 1)\n        with self.assertRaisesMessage(ValueError, 'localtime() cannot be applied to a naive datetime'):\n            timezone.localtime(naive, timezone=EAT)\n"], "sample_208": ["    def test_add_field_to_model_with_same_name_in_base_model(self):\n        \"\"\"\n        Adding a field to a model with a field of the same name in its base\n        model should use a unique name.\n        \"\"\"\n        before = [\n            ModelState('app', 'readable', [\n                ('id', models.AutoField(primary_key=True)),\n                ('title', models.CharField(max_length=200)),\n            ]),\n        ]\n        after = [\n            ModelState('app', 'readable', [\n                ('id', models.AutoField(primary_key=True)),\n                ('title', models.CharField(max_length=200)),\n            ]),\n            ModelState('app', 'book', [\n                ('title', models.CharField(max_length=200)),\n            ], bases=('app.readable',)),\n        ]\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'app', 1)\n        self.assertOperationTypes(changes, 'app', 0, ['AddField'])\n        self.assertOperationAttributes(changes, 'app', 0, 0, name='book_title', model_name='book')\n"], "sample_1139": ["def test_issue_17858_continued():\n    assert 1 in Range(1, oo)\n    assert 0 not in Range(1, oo)\n    assert oo in Range(1, oo)\n    assert -oo not in Range(1, oo)\n    assert 1 in Range(-oo, 1)\n    assert 0 not in Range(-oo, 1)\n    assert -oo in Range(-oo, 1)\n    assert 1 not in Range(-oo, 1, -1)\n    assert 0 in Range(-oo, 1, -1)\n    assert -oo not in Range(-oo, 1, -1)\n"], "sample_371": ["    def test_sensitive_post_parameters_method_decorator(self):\n        class MyClass:\n            @method_decorator(sensitive_post_parameters())\n                return HttpResponse()\n\n        instance = MyClass()\n        response = instance.a_view(HttpRequest())\n        self.assertEqual(response.status_code, 200)\n"], "sample_553": ["def test_save_count_override_warnings_no_length(anim):\n    save_count = 5\n    frames = iter(range(5))\n    match_target = (\n        f\"You passed in an explicit {save_count=} \"\n        \"which is being ignored in favor of \"\n        f\"{len(frames)=}.\"\n    )\n\n    with pytest.warns(UserWarning, match=re.escape(match_target)):\n        anim = animation.FuncAnimation(\n            **{**anim, 'frames': frames, 'save_count': save_count}\n        )\n\n    assert anim._save_count == len(frames)\n    anim._init_draw()\n"], "sample_1": ["    def model_b(x):\n        return x * x\n"], "sample_446": ["    def test_floatformat_with_decimal(self):\n        with self.settings(USE_THOUSAND_SEPARATOR=True, NUMBER_GROUPING=3, THOUSAND_SEPARATOR=\"!\"):\n            self.assertEqual(floatformat(Decimal(\"12345.6789\"), 2), \"12!345.68\")\n            self.assertEqual(floatformat(Decimal(\"12345.6789\"), 3), \"12!345.679\")\n            self.assertEqual(floatformat(Decimal(\"12345.6789\"), 0), \"12346\")\n            self.assertEqual(floatformat(Decimal(\"12345.6789\"), -2), \"12345.68\")\n"], "sample_308": ["    def test_invalid_format_specifiers(self):\n        my_birthday = datetime(1979, 7, 8, 22, 00)\n        for specifier in ['X', 'x', 'B', 'c', 'D', 'e', 'F', 'g', 'G', 'h', 'H', 'i', 'j', 'l', 'L', 'm', 'M', 'n', 'N', 'o', 'p', 'r', 's', 't', 'u', 'w', 'W', 'y', 'Y', 'z']:\n            msg = (\n                \"Invalid format specifier: '%s'\"\n            ) % specifier\n            with self.assertRaisesMessage(ValueError, msg):\n                dateformat.format(my_birthday, specifier)\n"], "sample_113": ["    def test_field_description_is_used(self):\n        class DescriptionField(models.CharField):\n            description = \"This is a description\"\n\n        self.assertEqual(views.get_readable_field_data_type(DescriptionField()), 'CharField: This is a description')\n"], "sample_809": ["def test_mutual_info_regression_sparse():\n    X = csr_matrix([[1, 2, 3],\n                    [4, 5, 6],\n                    [7, 8, 9]])\n    y = np.array([1, 2, 3])\n\n    mi = mutual_info_regression(X, y, random_state=0)\n    assert_array_equal(np.argsort(-mi), np.array([0, 1, 2]))\n"], "sample_845": ["def test_vectorizer_with_empty_input(Estimator):\n    if issubclass(Estimator, HashingVectorizer):\n        pytest.xfail('HashingVectorizer is not supported on PyPy')\n    with pytest.raises(ValueError, match=\"Input contains no documents\"):\n        Estimator().fit_transform([])\n"], "sample_1113": ["def test_block_matrix_equality():\n    A = BlockMatrix([[1, 2], [3, 4]])\n    B = BlockMatrix([[1, 2], [3, 4]])\n    C = BlockMatrix([[1, 3], [2, 4]])\n    D = BlockMatrix([[1, 2], [3, 5]])\n    assert A == B\n    assert A != C\n    assert A != D\n    assert A.equals(B)\n    assert not A.equals(C)\n    assert not A.equals(D)\n\n    E = BlockMatrix([[1, 2], [3, 4]])\n    F = BlockMatrix([[1, 2], [3, 4]])\n    assert E.structural_equal(F)\n    G = BlockMatrix([[1, 3], [2, 4]])\n    assert not E.structural_equal(G)\n\n    H = BlockMatrix([[1, 2], [3, 4]])\n    I = BlockMatrix([[1, 2], [3, 4]])\n    assert H.is_structurally_symmetric == I.is_structurally_symmetric\n    J = BlockMatrix([[1, 2], [3, 4]])\n    K = BlockMatrix([[1, 2], [4, 3]])\n    assert J.is_structurally_symmetric != K.is_structurally_symmetric\n\n    L = BlockMatrix([[1, 2], [3, 4]])\n    M = BlockMatrix([[1, 2], [3, 4]])\n    assert L.is_Identity == M.is_Identity\n    N = BlockMatrix([[1, 0], [0, 1]])\n    O = BlockMatrix([[1, 2], [3, 4]])\n    assert N.is_Identity != O.is_Identity\n\n\n\n"], "sample_393": ["    def test_po_updated_when_changed(self):\n        \"\"\"PO files are updated when there are new changes.\"\"\"\n        # Modify the source file to introduce a new translatable string\n        with open(os.path.join(self.test_dir, \"app_with_locale\", \"templates\", \"test.html\"), \"a\") as f:\n            f.write(\"<p>This is a new string to be translated.</p>\")\n\n        _, po_contents = self._run_makemessages()\n        self.assertNotEqual(po_contents, self.original_po_contents)\n"], "sample_449": ["    def test_close_connection(self):\n            start_response(\"200 OK\", [])\n            return [b\"Hello World\"]\n\n        rfile = BytesIO(b\"GET / HTTP/1.0\\r\\n\")\n        rfile.seek(0)\n\n        wfile = UnclosableBytesIO()\n\n            if mode == \"rb\":\n                return rfile\n            elif mode == \"wb\":\n                return wfile\n\n        request = Stub(makefile=makefile)\n        server = Stub(base_environ={}, get_app=lambda: test_app)\n\n        handler = WSGIRequestHandler(request, \"192.168.0.2\", server)\n        handler.close_connection = True\n        handler.handle()\n        wfile.seek(0)\n        lines = list(wfile.readlines())\n        self.assertEqual(lines[0], b\"HTTP/1.0 200 OK\\r\\n\")\n        self.assertIn(b\"Connection: close\\r\\n\", lines)\n"], "sample_132": ["    def test_sensitive_variables_decorator_with_args(self):\n        @sensitive_variables(exclude=['cooked_eggs'])\n            return password, cooked_eggs\n\n        with self.settings(DEBUG=True):\n            response = self.client.post('/sensitive_view/', data={'password': 'super_secret', 'cooked_eggs': 'scrambled'})\n            self.assertContains(response, 'super_secret', status_code=500)\n            self.assertContains(response, 'scrambled', status_code=500)\n"], "sample_771": ["def test_power_transformer_sparse_matrix():\n    X_sparse = sparse.csr_matrix([[1, 2], [3, 4], [5, 6]])\n    for method in ['box-cox', 'yeo-johnson']:\n        pt = PowerTransformer(method=method)\n        X_trans = pt.fit_transform(X_sparse)\n        assert isinstance(X_trans, sparse.csr_matrix)\n        X_inv = pt.inverse_transform(X_trans)\n        assert isinstance(X_inv, sparse.csr_matrix)\n        assert_array_almost_equal(X_sparse.toarray(), X_inv.toarray())\n\n\n\n"], "sample_1014": ["def test_reshape_with_symbolic_indices():\n    x, y = symbols(\"x y\")\n    md = ImmutableDenseNDimArray([[x, y], [x, y]])\n    reshaped = md.reshape(2, 2)\n    assert reshaped.shape == (2, 2)\n    assert reshaped[0, 0] == x\n    assert reshaped[0, 1] == y\n    assert reshaped[1, 0] == x\n    assert reshaped[1, 1] == y\n\n    reshaped_symbolic = md.reshape(x, y)\n    assert reshaped_symbolic.shape == (x, y)\n    assert reshaped_symbolic[0, 0] == x\n    assert reshaped_symbolic[0, 1] == y\n    assert reshaped_symbolic[1, 0] == x\n    assert reshaped_symbolic[1, 1] == y\n"], "sample_1074": ["compilation error"], "sample_619": ["def test_decode_cf_datetime_with_invalid_calendar() -> None:\n    units = \"days since 2000-01-01\"\n    num_dates = np.array([1, 2, 3])\n    with pytest.raises(ValueError, match=\"Invalid calendar\"):\n        decode_cf_datetime(num_dates, units, calendar=\"invalid_calendar\")\n"], "sample_574": ["    def test_label_format(self, t, fmt, expected):\n\n        s = Temporal().label(fmt)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == expected\n"], "sample_119": ["    def test_related_lookups(self):\n        query = Query(Author)\n        where = query.build_where(Q(book__title__icontains='django'))\n        lookup = where.children[0]\n        self.assertIsInstance(lookup, Q)\n        self.assertEqual(lookup.children[0].connector, OR)\n        self.assertEqual(lookup.children[0].children[0].lhs.target, Book._meta.get_field('title'))\n        self.assertEqual(lookup.children[0].children[0].rhs, 'django')\n"], "sample_1184": ["compilation error"], "sample_739": ["compilation error"], "sample_409": ["    def test_percent_formatting_in_blocktranslate_with_context(self):\n        t = self.get_template(\n            \"{% load i18n %}{% blocktranslate context 'comment_count' %}\"\n            \"There are %(num_comments)s comments{% endblocktranslate %}\"\n        )\n        with translation.override(\"de\"):\n            self.assertEqual(\n                t.render(Context({\"num_comments\": 42})),\n                \"Es gibt %(num_comments)s Kommentare\",\n            )\n"], "sample_714": ["def test_log_loss_with_multilabel_data():\n    y_true = np.array([[0, 1, 1], [1, 0, 1], [0, 1, 0]])\n    y_pred = np.array([[0.1, 0.8, 0.9], [0.9, 0.2, 0.3], [0.6, 0.4, 0.1]])\n    loss = log_loss(y_true, y_pred, normalize=True)\n    assert_almost_equal(loss, 0.9999999)\n"], "sample_280": ["    def test_aggregation_default_using_float_from_python(self):\n        result = Book.objects.filter(rating__lt=3.0).aggregate(\n            value=Sum('pages', default=3.14),\n        )\n        self.assertEqual(result['value'], 3.14)\n"], "sample_415": ["    def test_expressions_with_include(self):\n        msg = \"UniqueConstraint.include cannot be used with expressions.\"\n        with self.assertRaisesMessage(ValueError, msg):\n            models.UniqueConstraint(\n                Lower(\"field\"),\n                name=\"test_func_include\",\n                include=[\"other_field\"],\n            )\n"], "sample_1166": ["compilation error"], "sample_143": ["    def test_format_lazy(self):\n        with self.subTest(format_lazy):\n            self.assertEqual(format_lazy('Hello, {name}!', name='world'), 'Hello, world!')\n            self.assertEqual(format_lazy('Hello, {name}!', name=lazystr('world')), 'Hello, world!')\n            self.assertEqual(format_lazy('Hello, {name}!', name=None), 'Hello, !')\n            self.assertEqual(format_lazy('Hello, {name}!', name=123), 'Hello, 123!')\n"], "sample_159": ["    def test_builtin_permission_name_length(self):\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'some ridiculously long verbose name that is out of control' * 5\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The verbose_name of model 'auth_tests.Checked' must be at most 244 \"\n                \"characters for its builtin permission names to be at most 255 characters.\",\n                obj=Checked,\n                id='auth.E007',\n            ),\n        ])\n"], "sample_570": ["    def test_errorbar_kwargs(self, long_df):\n        agg = EstimateAggregator(\"mean\", \"ci\", level=99, n_boot=10000, seed=0)\n        out = agg(long_df, \"y\")\n        assert out[\"ymin\"] == pytest.approx(\n            np.percentile(long_df[\"y\"], 0.5 + (1 - 0.99) / 2), abs=1e-2\n        )\n        assert out[\"ymax\"] == pytest.approx(\n            np.percentile(long_df[\"y\"], 0.5 + (0.99 - 0.5) / 2), abs=1e-2\n        )\n\n        agg = EstimateAggregator(\"mean\", \"ci\", level=95, n_boot=10000, seed=0)\n        out = agg(long_df, \"y\")\n        assert out[\"ymin\"] == pytest.approx(\n            np.percentile(long_df[\"y\"], 0.5 + (1 - 0.95) / 2), abs=1e-2\n        )\n        assert out[\"ymax\"] == pytest.approx(\n            np.percentile(long_df[\"y\"], 0.5 + (0.95 - 0.5) / 2), abs=1e-2\n        )\n"], "sample_326": ["    def test_urlize_trim_url_limit(self):\n        long_url = 'https://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-trim_url_limit-parameter'\n        trimmed_url = 'https://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-trim_url_limit-parameter...'\n\n        self.assertEqual(urlize(long_url, trim_url_limit=30),\n                         f'<a href=\"{trimmed_url}\">...</a>')\n"], "sample_511": ["def test_subplot_projection_reuse_with_kwargs():\n    fig = plt.figure()\n    ax1 = plt.subplot(111, projection='polar')\n    ax2 = plt.subplot(111, projection='polar', theta_offset=0)\n    assert ax1 is ax2\n    ax3 = plt.subplot(111, projection='polar', theta_offset=1)\n    assert ax1 is not ax3\n    assert ax2 is not ax3\n"], "sample_383": ["    def test_ticket_24605_subquery_ordering(self):\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        # Test ordering with subquery\n        self.assertSequenceEqual(\n            Individual.objects.filter(\n                Q(alive=False), Q(related_individual__isnull=True)\n            ).order_by(\"pk\"),\n            [i4],\n        )\n"], "sample_877": ["def test_isotonic_regression_with_missing_values():\n    # Test handling of missing values in input data\n    X = np.array([1, 2, np.nan, 4, 5])\n    y = np.array([2, 4, 1, 6, 7])\n\n    # Test with IsotonicRegression\n    ir = IsotonicRegression()\n    with pytest.raises(ValueError, match=\"Input contains missing values\"):\n        ir.fit(X, y)\n\n    # Test with imputation\n    from sklearn.impute import SimpleImputer\n    imputer = SimpleImputer(strategy=\"mean\")\n    X_imputed = imputer.fit_transform(X.reshape(-1, 1))\n    ir = IsotonicRegression()\n    ir.fit(X_imputed, y)\n    assert not np.isnan(ir.predict(X_imputed)).any()\n\n\n\n"], "sample_712": ["def test_one_hot_encoder_sparse_output():\n    X = np.array([['abc', 2, 55], ['def', 1, 55]])\n    enc = OneHotEncoder(sparse=True)\n    X_tr = enc.fit_transform(X)\n    assert isinstance(X_tr, sparse.csr_matrix)\n    assert X_tr.shape == (2, 6)\n    assert_array_equal(X_tr.toarray(), check_categorical_onehot(X))\n"], "sample_563": ["def test_offsetbox_padding():\n    fig, ax = plt.subplots()\n\n    # Test padding with different units\n    for pad in [1, 2.5, 10, 10.5]:\n        da = DrawingArea(10, 10)\n        ab = AnnotationBbox(da, (0.5, 0.5), xycoords='data',\n                            boxcoords='axes fraction', pad=pad)\n        ax.add_artist(ab)\n\n    fig.canvas.draw()\n"], "sample_684": ["    def test_reprfuncargs_with_none(self) -> None:\n        args = [(\"arg1\", None), (\"arg2\", 123)]\n        r = ReprFuncArgs(args)\n        with pytest.raises(TypeError) as e:\n            r.toterminal(None)\n        assert \"NoneType\" in str(e)\n"], "sample_364": ["    def test_reverse_type_error_propagates(self):\n        @DynamicConverter.register_to_url\n            raise TypeError('This type error propagates.')\n        with self.assertRaisesMessage(TypeError, 'This type error propagates.'):\n            reverse('dynamic', kwargs={'value': object()})\n"], "sample_500": ["def test_colorbar_orientation_with_fraction():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[1, 2], [3, 4]])\n    cbar = fig.colorbar(im, orientation='horizontal', fraction=0.2)\n    assert cbar.ax.get_orientation() == 'horizontal'\n    assert cbar.ax.get_position().width == 0.2\n    cbar = fig.colorbar(im, orientation='vertical', fraction=0.3)\n    assert cbar.ax.get_orientation() == 'vertical'\n    assert cbar.ax.get_position().height == 0.3\n"], "sample_921": ["compilation error"], "sample_125": ["    def test_delete_cookie_with_path(self):\n        response = HttpResponse()\n        response.set_cookie('c', path='/admin')\n        response.delete_cookie('c', path='/admin')\n        cookie = response.cookies.get('c')\n        self.assertIsNone(cookie)\n"], "sample_741": ["def test_grid_search_with_preprocessor():\n    X, y = make_classification(n_samples=100, random_state=42)\n    preprocessor = StandardScaler()\n    clf = LogisticRegression()\n    grid_search = GridSearchCV(\n        Pipeline([('preprocessor', preprocessor), ('classifier', clf)]),\n        {'classifier__C': [0.1, 1, 10]}, cv=5)\n    grid_search.fit(X, y)\n    assert_true(hasattr(grid_search.best_estimator_, 'preprocessor'))\n    assert_true(hasattr(grid_search.best_estimator_, 'classifier'))\n    best_params = grid_search.best_params_\n    assert_equal(best_params['classifier__C'], grid_search.best_estimator_\n                 .get_params()['classifier']['C'])\n\n\n\n"], "sample_260": ["    def test_optimize_through_fields_with_fk(self):\n        \"\"\"\n        field-level through checking is working. This should manage to collapse\n        model Foo to nonexistence, and model Bar to a single IntegerField\n        called \"width\".\n        \"\"\"\n        self.assertOptimizesTo(\n            [\n                migrations.CreateModel(\"Foo\", [(\"name\", models.CharField(max_length=255))]),\n                migrations.CreateModel(\"Bar\", [(\"size\", models.IntegerField())]),\n                migrations.AddField(\"Foo\", \"age\", models.IntegerField()),\n                migrations.AddField(\"Bar\", \"width\", models.IntegerField()),\n                migrations.AddField(\"Foo\", \"bar\", models.ForeignKey(\"migrations.Bar\", models.CASCADE)),\n                migrations.AlterField(\"Foo\", \"age\", models.IntegerField()),\n                migrations.RenameField(\"Bar\", \"size\", \"dimensions\"),\n                migrations.RemoveField(\"Foo\", \"age\"),\n                migrations.RenameModel(\"Foo\", \"Phou\"),\n                migrations.RemoveField(\"Bar\", \"dimensions\"),\n                migrations.RemoveField(\"Phou\", \"bar\"),\n                migrations.RenameModel(\"Phou\", \"Fou\"),\n                migrations.DeleteModel(\"Fou\"),\n            ],\n            [\n                migrations.CreateModel(\"Bar\", [(\"width\", models.IntegerField())]),\n            ],\n        )\n"], "sample_268": ["    def test_snapshot_files_handles_new_files(self):\n        new_file = self.ensure_file(self.tempdir / 'new_file.py')\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file, new_file]):\n            snapshot1 = dict(self.reloader.snapshot_files())\n            self.assertIn(self.existing_file, snapshot1)\n            self.assertIn(new_file, snapshot1)\n"], "sample_175": ["    def test_fast_delete_with_signals(self):\n        deleted_count = 0\n            nonlocal deleted_count\n            deleted_count += 1\n\n        models.signals.post_delete.connect(receiver, sender=Avatar)\n        a = Avatar.objects.create()\n        a.delete()\n        self.assertEqual(deleted_count, 1)\n        self.assertFalse(Avatar.objects.exists())\n        models.signals.post_delete.disconnect(receiver, sender=Avatar)\n"], "sample_879": ["def test_ordinal_encoder_categories_dtype_object():\n    \"\"\"Check that categories are always stored as object dtype.\"\"\"\n    X = np.array([[\"a\", \"b\"], [\"c\", \"a\"], [\"b\", \"c\"]], dtype=object)\n    oe = OrdinalEncoder()\n    oe.fit(X)\n\n    assert oe.categories_[0].dtype == object\n    assert oe.categories_[1].dtype == object\n"], "sample_1069": ["def test_polygamma_printing():\n    assert octave_code(polygamma(n, x)) == 'polygamma(n, x)'\n    assert octave_code(polygamma(n, x, evaluate=False)) == 'polygamma(n, x)'\n"], "sample_185": ["    def test_resets_cache_with_mo_files_and_active_language(self):\n        gettext_module._translations = {'foo': 'bar'}\n        trans_real._translations = {'foo': 'bar'}\n        trans_real._default = 1\n        trans_real._active = 'en'\n        path = Path('test.mo')\n        self.assertIs(translation_file_changed(None, path), True)\n        self.assertEqual(gettext_module._translations, {})\n        self.assertEqual(trans_real._translations, {})\n        self.assertIsNone(trans_real._default)\n        self.assertIsInstance(trans_real._active, Local)\n"], "sample_587": ["    def test_merge_explicit_coords(self):\n        ds1 = xr.Dataset({\"x\": 0, \"y\": (\"x\", [1, 2])})\n        ds2 = xr.Dataset({\"z\": 1, \"y\": (\"x\", [3, 4])})\n        expected = xr.Dataset({\"x\": 0, \"y\": (\"x\", [1, 2, 3, 4]), \"z\": 1})\n        actual = ds1.merge(ds2, explicit_coords=[\"y\"])\n        assert expected.identical(actual)\n\n        actual = ds2.merge(ds1, explicit_coords=[\"y\"])\n        assert expected.identical(actual)\n\n        with pytest.raises(ValueError):\n            ds1.merge(ds2, explicit_coords=[\"x\"])\n\n        with pytest.raises(ValueError):\n            ds1.merge(ds2, explicit_coords=[\"w\"])\n"], "sample_324": ["    def test_https_good_referer_different_port(self):\n        \"\"\"\n        A POST HTTPS request with a good referer from a different port should be accepted.\n        \"\"\"\n        req = self._get_POST_request_with_token()\n        req._is_secure_override = True\n        req.META['HTTP_HOST'] = 'www.example.com'\n        req.META['HTTP_REFERER'] = 'https://www.example.com:8443/'\n        req.META['SERVER_PORT'] = '443'\n        mw = CsrfViewMiddleware(post_form_view)\n        self.assertIsNone(mw.process_view(req, post_form_view, (), {}))\n"], "sample_738": ["def test_vectorizer_empty_vocabulary():\n    # Test for empty vocabulary after fitting\n    vect = CountVectorizer()\n    vect.fit([])\n    assert_equal(len(vect.vocabulary_), 0)\n    assert_equal(vect.transform([]).shape, (0, 0))\n\n    vect = TfidfVectorizer()\n    vect.fit([])\n    assert_equal(len(vect.vocabulary_), 0)\n    assert_equal(vect.transform([]).shape, (0, 0))\n\n    vect = HashingVectorizer()\n    vect.fit([])\n    assert_equal(vect.transform([]).shape, (0, 2 ** vect.n_features))\n"], "sample_839": ["def test_vectorizer_with_empty_input(Estimator):\n    if issubclass(Estimator, HashingVectorizer):\n        pytest.xfail('HashingVectorizer is not supported on PyPy')\n    with pytest.raises(ValueError, match=\"Input contains no documents\"):\n        Estimator().fit_transform([])\n"], "sample_57": ["    def test_password_too_short(self):\n        user = User.objects.get(username='testclient')\n        data = {'password1': 'abc', 'password2': 'abc'}\n        form = AdminPasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertIn('password1', form.errors)\n        self.assertIn('password2', form.errors)\n        self.assertIn('This password is too short. It must contain at least 8 characters.', form.errors['password1'][0])\n        self.assertIn('This password is too short. It must contain at least 8 characters.', form.errors['password2'][0])\n"], "sample_215": ["    def test_sensitive_variables_decorator_with_kwargs(self):\n        @sensitive_variables\n            return password, kwargs\n\n        with self.settings(DEBUG=True):\n            response = self.client.post('/test_view/', data={'password': 'secret', 'other': 'value'})\n            self.assertEqual(response.status_code, 500)\n            self.assertNotIn('secret', response.content)\n            self.assertIn('other', response.content)\n"], "sample_521": ["def test_scatter_3d_custom_cmap():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    x = np.random.rand(100)\n    y = np.random.rand(100)\n    z = np.random.rand(100)\n    cmap = plt.cm.get_cmap('viridis')\n    sc = ax.scatter(x, y, z, c=x, cmap=cmap)\n    fig.colorbar(sc)\n    fig.canvas.draw()\n"], "sample_689": ["def test_strict_option_is_deprecated(testdir: Testdir) -> None:\n    with pytest.warns(pytest.PytestDeprecationWarning, match=\"The `--strict` option is deprecated\"):\n        result = testdir.runpytest(\"--strict\")\n    result.stdout.fnmatch_lines([\"*The `--strict` option is deprecated\"])\n"], "sample_1205": ["compilation error"], "sample_305": ["    def test_annotate_on_related_manager(self):\n        qs = Book.objects.annotate(\n            avg_price=Avg('price'),\n            publisher_name=F('publisher__name')\n        ).filter(avg_price__gt=25)\n        self.assertEqual(qs.count(), 3)\n        self.assertEqual(qs[0].avg_price, 30.00)\n        self.assertEqual(qs[0].publisher_name, \"Apress\")\n"], "sample_58": ["    def test_renderer_overrides_default(self):\n        custom = CustomRenderer()\n        form = Form(renderer=custom)\n        self.assertEqual(form.renderer, custom)\n"], "sample_946": ["def test_python_python_use_unqualified_type_names_enabled(app, status, warning):\n    app.build()\n    content = (app.outdir / 'index.html').read_text()\n    assert ('<span class=\"n\"><a class=\"reference internal\" href=\"#foo.Name\" title=\"foo.Name\">'\n            '<span class=\"pre\">Name</span></a></span>' in content)\n    assert '<span class=\"n\"><span class=\"pre\">foo.Age</span></span>' in content\n"], "sample_572": ["    def test_bootstrap_errorbars(self, long_df):\n\n        agg = EstimateAggregator(\"mean\", \"ci\", n_boot=1000, seed=0)\n        out = agg(long_df, \"y\")\n\n        agg_ref = EstimateAggregator(\"mean\", (\"se\", 1.96))\n        out_ref = agg_ref(long_df, \"y\")\n\n        assert out[\"ymin\"] == pytest.approx(out_ref[\"ymin\"], abs=1e-2)\n        assert out[\"ymax\"] == pytest.approx(out_ref[\"ymax\"], abs=1e-2)\n"], "sample_396": ["    def test_ticket_24605_complex_subquery(self):\n        i1 = Individual.objects.create(alive=True)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i1)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        # Test a more complex subquery with multiple conditions\n        qs = Individual.objects.filter(\n            Q(alive=True)\n            & Q(\n                related_individual__isnull=False\n            )\n            & ~Q(\n                related_individual__related__pk__in=Individual.objects.filter(\n                    alive=False\n                ).values_list(\"pk\", flat=True)\n            )\n        )\n        self.assertSequenceEqual(qs, [i1])\n"], "sample_800": ["def test_check_estimator_sparse_matrix_input_handling():\n    # check that estimator handles sparse matrix input gracefully\n    # when it is expected to handle sparse matrices\n    class SparseMatrixHandlingEstimator(BaseEstimator):\n            if sp.issparse(X):\n                return self\n            else:\n                raise ValueError(\"This estimator only accepts sparse matrices\")\n\n    check_estimator(SparseMatrixHandlingEstimator())\n"], "sample_899": ["def test_check_estimator_sparse_matrix_input():\n    # check that estimator handles sparse matrix input correctly\n    from sklearn.datasets import make_sparse_matrix\n    from sklearn.linear_model import LogisticRegression\n\n    X, y = make_sparse_matrix(n_samples=100, n_features=10, density=0.1)\n    est = LogisticRegression()\n    check_estimator(est)\n    est.fit(X, y)\n    check_estimator(est)\n"], "sample_390": ["    def test_was_modified_since_empty_header(self):\n        mtime = 1343416141\n        self.assertTrue(was_modified_since(header=None, mtime=mtime))\n"], "sample_861": ["def test_random_search_with_n_iter_less_than_n_splits():\n    # Test that n_iter is respected when less than n_splits\n    X, y = make_classification(n_samples=50, random_state=0)\n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n    param_grid = {'C': [0.1, 1, 10]}\n    rs = RandomizedSearchCV(SVC(), param_grid, cv=cv, n_iter=2)\n    rs.fit(X, y)\n    assert len(rs.cv_results_) == 2\n    assert len(rs.best_params_) == 1\n    assert len(rs.best_estimator_) == 1\n\n\n\n"], "sample_1112": ["def test_is_palindromic():\n    assert is_palindromic(121)\n    assert is_palindromic(121, 8)\n    assert not is_palindromic(123, 10)\n    assert not is_palindromic(123, 8)\n    assert is_palindromic(0o121, 8)\n    assert not is_palindromic(0o121, 10)\n    assert is_palindromic(88, 10)\n    assert not is_palindromic(88, 8)\n"], "sample_6": ["def test_array_coordinate_repr():\n    c = ICRS(np.array([1, 2])*u.deg, np.array([3, 4])*u.deg)\n    assert repr(c).startswith('ICRS(ra=[1.0, 2.0 deg], dec=[3.0, 4.0 deg])')\n    \n    c = ICRS(ra=np.array([1, 2, 3])*u.deg, dec=np.array([4, 5, 6])*u.deg, distance=np.array([7, 8, 9])*u.kpc)\n    assert repr(c).startswith('ICRS(ra=[1.0, 2.0, 3.0 deg], dec=[4.0, 5.0, 6.0 deg], distance=[7.0, 8.0, 9.0 kpc])')\n"], "sample_267": ["    def test_concurrent_transactions(self):\n            with transaction.atomic():\n                Object.objects.create()\n        thread1 = threading.Thread(target=create_object_in_transaction)\n        thread2 = threading.Thread(target=create_object_in_transaction)\n        thread1.start()\n        thread2.start()\n        thread1.join()\n        thread2.join()\n        self.assertEqual(Object.objects.count(), 2)\n"], "sample_1160": ["def test_issue_17858_continued():\n    assert 1 in Range(1, oo)\n    assert 0 not in Range(1, oo)\n    assert oo in Range(1, oo)\n    assert -oo not in Range(1, oo)\n    assert 1 in Range(-oo, 1)\n    assert 0 not in Range(-oo, 1)\n    assert -oo in Range(-oo, 1)\n    assert 1 not in Range(-oo, 1, -1)\n    assert 0 in Range(-oo, 1, -1)\n    assert -oo not in Range(-oo, 1, -1)\n"], "sample_697": ["compilation error"], "sample_654": ["compilation error"], "sample_181": ["    def test_filtered_aggregate_with_order_by(self):\n        agg = Sum('age', filter=Q(name__startswith='test'))\n        qs = Author.objects.order_by('name').aggregate(age=agg)\n        self.assertEqual(qs['age'], 200)\n\n"], "sample_1008": ["def test_dcm_from_rotation_matrix():\n    from sympy.physics.vector import ReferenceFrame, Matrix\n    N = ReferenceFrame('N')\n    R = Matrix([[1, 0, 0], [0, cos(pi/4), -sin(pi/4)], [0, sin(pi/4), cos(pi/4)]])\n    A = N.orientnew('A', 'DCM', R)\n    assert A.dcm(N) == R\n"], "sample_524": ["compilation error"], "sample_49": ["    def test_merge_css_three_way(self):\n        \"\"\"\n        The relative order of stylesheets is preserved in a three-way merge.\n        \"\"\"\n        # custom_widget.css doesn't depend on jquery.css.\n        widget1 = Media(css={'all': ['custom_widget.css']})\n        widget2 = Media(css={'all': ['jquery.css', 'uses_jquery.css']})\n        form_media = widget1 + widget2\n        # The relative ordering of custom_widget.css and jquery.css has been\n        # established (but without a real need to).\n        self.assertEqual(form_media._css['all'], ['custom_widget.css', 'jquery.css', 'uses_jquery.css'])\n        # The inline also uses custom_widget.css. This time, it's at the end.\n        inline_media = Media(css={'all': ['jquery.css', 'also_jquery.css']}) + Media(css={'all': ['custom_widget.css']})\n        merged = form_media + inline_media\n        self.assertEqual(merged._css['all'], ['custom_widget.css', 'jquery.css', 'uses_jquery.css', 'also_jquery.css'])\n"], "sample_780": ["def test_lda_subsampling():\n    # Test LDA perplexity with subsampling\n    n_components, X = _build_sparse_mtx()\n    lda = LatentDirichletAllocation(n_components=n_components, max_iter=10,\n                                    random_state=0)\n    lda.fit(X)\n    perp_subsampling = lda.perplexity(X, sub_sampling=True)\n    perp_no_subsampling = lda.perplexity(X)\n    assert_greater_equal(perp_subsampling, perp_no_subsampling)\n"], "sample_131": ["    def test_migrate_test_setting_true(self, mocked_migrate, mocked_ensure_connection):\n        creation = connection.creation_class(connection)\n        saved_settings = copy.deepcopy(connection.settings_dict)\n        try:\n            connection.settings_dict['TEST']['MIGRATE'] = True\n            with mock.patch.object(creation, '_create_test_db'):\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n            mocked_migrate.assert_called_once()\n        finally:\n            connection.settings_dict = saved_settings\n"], "sample_789": ["compilation error"], "sample_889": ["def test_calibration_with_invalid_method(data):\n    X, y = data\n    with pytest.raises(ValueError, match=\"Invalid method\"):\n        CalibratedClassifierCV(estimator=LogisticRegression(), method=\"invalid\").fit(X, y)\n"], "sample_825": ["def test_pls_with_missing_values():\n    d = load_linnerud()\n    X = d.data\n    Y = d.target\n\n    # Introduce some missing values\n    X[0, 1] = np.nan\n    X[2, 3] = np.nan\n\n    for clf in [pls_.PLSCanonical(), pls_.PLSRegression(),\n                pls_.PLSSVD()]:\n        clf.fit(X, Y)\n        assert_array_almost_equal(clf.predict(X), clf.predict(X), decimal=4)\n"], "sample_781": ["def test_max_samples_fraction(name):\n    X, y = hastie_X, hastie_y\n    ForestEstimator = FOREST_ESTIMATORS[name]\n    for frac in np.linspace(0.1, 1, 5):\n        est = ForestEstimator(max_samples=frac, random_state=0)\n        est.fit(X, y)\n        assert_almost_equal(len(est.estimators_),\n                            int(len(X) * frac))\n"], "sample_152": ["    def test_fast_delete_with_signals(self):\n        deleted_count = 0\n            nonlocal deleted_count\n            deleted_count += 1\n        models.signals.pre_delete.connect(pre_delete, sender=User)\n        u = User.objects.create()\n        u.delete()\n        models.signals.pre_delete.disconnect(pre_delete, sender=User)\n        self.assertEqual(deleted_count, 1)\n"], "sample_904": ["def test_labeled_rubric_with_title(app):\n    text = (\".. _label:\\n\"\n            \".. rubric:: blah *blah* blah\\n\"\n            \"   This is a rubric title\\n\")\n    restructuredtext.parse(app, text)\n\n    domain = app.env.get_domain(\"std\")\n    assert 'label' in domain.labels\n    assert domain.labels['label'] == ('index', 'label', 'blah blah blah', 'This is a rubric title')\n"], "sample_153": ["    def test_database_checks_called_with_specific_databases(self, mocked_check):\n        check_database_backends(databases=['default'])\n        self.assertTrue(mocked_check.called)\n        mocked_check.reset_mock()\n        check_database_backends(databases=['other'])\n        self.assertTrue(mocked_check.called)\n"], "sample_621": ["    def test_isel(self, indexes) -> None:\n        with pytest.raises(ValueError, match=r\"cannot select multi-index with scalar\"):\n            indexes.isel({\"z\": 0})\n        \n        with pytest.raises(ValueError, match=r\"cannot select multi-index with scalar\"):\n            indexes.isel({\"one\": 0})\n\n        with pytest.raises(ValueError, match=r\"cannot select multi-index with scalar\"):\n            indexes.isel({\"x\": 1, \"y\": 2})\n\n        with pytest.raises(ValueError, match=r\"cannot select multi-index with scalar\"):\n            indexes.isel({\"x\": slice(0, 1), \"y\": slice(1, 2)})\n\n        with pytest.raises(ValueError, match=r\"cannot select multi-index with scalar\"):\n            indexes.isel({\"x\": [0, 1], \"y\": [2]})\n\n        with pytest.raises(ValueError, match=r\"cannot select multi-index with scalar\"):\n            indexes.isel({\"x\": [0, 1], \"y\": [2, 3]})\n\n        with pytest.raises(ValueError, match=r\"cannot select multi-index with scalar\"):\n            indexes.isel({\"x\": slice(0, 1), \"y\": [2]})\n\n        with pytest.raises(ValueError, match=r\"cannot select multi-index with scalar\"):\n            indexes.isel({\"x\": [0, 1], \"y\": slice(1, 2)})\n\n        with pytest.raises(ValueError, match=r\"cannot select multi-index with scalar\"):\n            indexes.isel({\"x\": slice(0, 1), \"y\": slice(1, 2)})\n\n        with pytest.raises(ValueError, match=r\"cannot select multi-index with scalar\"):\n            indexes.isel({\"x\": [0, 1], \"y\": [2, 3]})\n\n        with pytest.raises(ValueError, match=r\"cannot select multi-index with scalar\"):\n            indexes.isel({\"x\": slice(0, 1), \"y\": [2, 3]})\n\n        with pytest.raises(ValueError, match=r\"cannot select multi-index with scalar\"):\n            indexes.isel({\"x\": [0, 1], \"y\": slice"], "sample_522": ["def test_colorbar_label_position():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc, ax=ax, label='My Label')\n    fig.draw_without_rendering()\n    # check that the label is positioned correctly\n    assert cb.ax.get_xlabel() == 'My Label'\n    assert cb.ax.get_xlabel_position() == 'right'\n    # check that the label is positioned correctly when using\n    # different orientations\n    cb = fig.colorbar(pc, ax=ax, orientation='horizontal', label='My Label')\n    fig.draw_without_rendering()\n    assert cb.ax.get_ylabel() == 'My Label'\n    assert cb.ax.get_ylabel_position() == 'top'\n\n\n\n"], "sample_844": ["def test_xi_parameter_effect():\n    # Test the effect of xi parameter on clustering\n    rng = np.random.RandomState(0)\n    n_points_per_cluster = 50\n    C1 = [0, 0] + 0.8 * rng.randn(n_points_per_cluster, 2)\n    C2 = [4, -1] + 0.1 * rng.randn(n_points_per_cluster, 2)\n    X = np.vstack((C1, C2))\n\n    # Test with xi = 0.1\n    clust1 = OPTICS(min_samples=5, xi=0.1).fit(X)\n    labels1 = clust1.labels_\n\n    # Test with xi = 0.5\n    clust2 = OPTICS(min_samples=5, xi=0.5).fit(X)\n    labels2 = clust2.labels_\n\n    # Check that xi=0.5 results in more clusters\n    assert len(np.unique(labels1)) <= len(np.unique(labels2))\n\n\n"], "sample_895": ["compilation error"], "sample_791": ["def test_one_hot_encoder_sparse_output():\n    X = [['abc', 2, 55], ['def', 1, 55], ['abc', 3, 55]]\n    enc = OneHotEncoder(sparse=True)\n    X_tr = enc.fit_transform(X)\n    assert isinstance(X_tr, sparse.csr_matrix)\n    assert X_tr.shape == (3, 6)\n\n    enc = OneHotEncoder(sparse=True, handle_unknown='ignore')\n    X2 = [['abc', 2, 56], ['def', 1, 55], ['abc', 3, 56]]\n    X_tr2 = enc.fit_transform(X2)\n    assert isinstance(X_tr2, sparse.csr_matrix)\n    assert X_tr2.shape == (3, 6)\n\n\n\n"], "sample_539": ["def test_polygon_selector_reset(ax, draw_bounding_box):\n    verts = [(50, 50), (150, 50), (50, 150)]\n    event_sequence = [\n        *polygon_place_vertex(*verts[0]),\n        *polygon_place_vertex(*verts[1]),\n        *polygon_place_vertex(*verts[2]),\n        *polygon_place_vertex(*verts[0]),\n    ]\n\n    tool = widgets.PolygonSelector(ax, onselect=noop, draw_bounding_box=draw_bounding_box)\n    for (etype, event_args) in event_sequence:\n        do_event(tool, etype, **event_args)\n\n    tool.reset()\n    assert tool.verts == []\n"], "sample_331": ["    def test_iso8601_duration(self):\n        test_values = (\n            ('P1D', timedelta(days=1)),\n            ('P1DT2H', timedelta(days=1, hours=2)),\n            ('P1DT2H30M', timedelta(days=1, hours=2, minutes=30)),\n            ('P1DT2H30M15S', timedelta(days=1, hours=2, minutes=30, seconds=15)),\n            ('P1DT2H30M15S.123456789', timedelta(days=1, hours=2, minutes=30, seconds=15, microseconds=123456789)),\n            ('PT2H30M15S', timedelta(hours=2, minutes=30, seconds=15)),\n            ('PT2H30M15S.123456789', timedelta(hours=2, minutes=30, seconds=15, microseconds=123456789)),\n            ('P1DT2H30M15S.123456789Z', timedelta(days=1, hours=2, minutes=30, seconds=15, microseconds=123456789)),\n            ('P-1D', timedelta(days=-1)),\n            ('P-1DT2H', timedelta(days=-1, hours=2)),\n            ('P-1DT2H30M', timedelta(days=-1, hours=2, minutes=30)),\n            ('P-1DT2H30M15S', timedelta(days=-1, hours=2, minutes=30, seconds=15)),\n            ('P-1DT2H30M15S.123456789', timedelta(days=-1, hours=2, minutes=30, seconds=15, microseconds=123456789)),\n            ('PT-2H30M15S', timedelta(hours=-2, minutes=-30, seconds=-15)),\n            ('PT-2H30"], "sample_13": ["def test_angle_from_string_with_units():\n    \"\"\"\n    Test that Angle can be created from strings with units\n    \"\"\"\n    a1 = Angle('10d', unit=u.deg)\n    assert a1.value == 10.0\n    assert a1.unit == u.deg\n\n    a2 = Angle('10h', unit=u.hourangle)\n    assert a2.value == 10.0\n    assert a2.unit == u.hourangle\n\n    a3 = Angle('10m', unit=u.arcminute)\n    assert a3.value == 10.0 / 60.0\n    assert a3.unit == u.deg\n\n    a4 = Angle('10s', unit=u.arcsecond)\n    assert a4.value == 10.0 / 3600.0\n    assert a4.unit == u.deg\n\n    a5 = Angle('10d 10m 10s', unit=u.deg)\n    assert a5.value == 10.166666666666667\n    assert a5.unit == u.deg\n\n    a6 = Angle('10h 10m 10s', unit=u.hourangle)\n    assert a6.value == 10.166666666666667\n    assert a6.unit == u.hourangle\n\n    with pytest.raises(ValueError):\n        Angle('10d 10m 10s', unit=u.rad)\n"], "sample_977": ["def test_Sum():\n    assert mcode(Sum(x**n, (n, 0, 5))) == \"Hold[Sum[x^n, {n, 0, 5}]]\"\n    assert mcode(Sum(x**n, (n, 1, oo))) == \"Hold[Sum[x^n, {n, 1, Infinity}]]\"\n"], "sample_534": ["def test_contour_with_masked_array():\n    x = np.arange(10)\n    y = np.arange(10)\n    X, Y = np.meshgrid(x, y)\n    mask = np.zeros_like(X, dtype=bool)\n    mask[2:6, 2:6] = True\n    z = np.sin(X * Y)\n    z = np.ma.masked_array(z, mask=mask)\n\n    fig, ax = plt.subplots()\n    cs = ax.contour(X, Y, z)\n    assert isinstance(cs._contour_generator, contourpy.Mpl2005ContourGenerator)\n    ax.clabel(cs)\n"], "sample_321": ["    def test_https_good_referer_matches_cookie_domain_with_different_port(self):\n        \"\"\"\n        A POST HTTPS request with a good referer should be accepted from a\n        subdomain that's allowed by CSRF_COOKIE_DOMAIN and a non-4443 port.\n        \"\"\"\n        req = self._get_POST_request_with_token()\n        req._is_secure_override = True\n        req.META['HTTP_HOST'] = 'www.example.com'\n        req.META['HTTP_REFERER'] = 'https://foo.example.com:4443/'\n        req.META['SERVER_PORT'] = '443'\n        mw = CsrfViewMiddleware(post_form_view)\n        self.assertIsNone(mw.process_view(req, post_form_view, (), {}))\n"], "sample_126": ["    def test_add_blank_textfield_and_charfield_with_default(self):\n        \"\"\"\n        #23405 - Adding a NOT NULL and blank `CharField` or `TextField`\n        with a default should not prompt for a default.\n        \"\"\"\n        changes = self.get_changes([self.author_empty], [self.author_with_biography_blank_default])\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0)\n"], "sample_328": ["    def test_jsonfield_nullable(self):\n        json_fields = [\n            JSONFieldNullable.objects.create(\n                data={'key': 'value'}\n            )\n            for _ in range(10)\n        ]\n        for json_field in json_fields:\n            json_field.data = {'key': 'updated_value'}\n        JSONFieldNullable.objects.bulk_update(json_fields, ['data'])\n        self.assertCountEqual(\n            JSONFieldNullable.objects.values_list('data', flat=True),\n            [{'key': 'updated_value'} for _ in range(10)]\n        )\n"], "sample_615": ["compilation error"], "sample_70": ["    def test_fast_delete_with_related_objects(self):\n        a = A.objects.create()\n        r = R.objects.create()\n        a.r = r\n        a.save()\n        # 1 query to delete a, 1 to fast-delete r\n        self.assertNumQueries(2, a.delete)\n        self.assertFalse(A.objects.exists())\n        self.assertFalse(R.objects.exists())\n"], "sample_1084": ["def test_issue_17008():\n    assert imageset(Lambda(x, x**2), S.Complexes).is_subset(S.Reals)\n"], "sample_1157": ["def test_issue_14089():\n    x = Symbol('x')\n    assert parse_expr('x**2 + 2*x + 1', evaluate=False) == x**2 + 2*x + 1\n    assert parse_expr('x**2 + 2*x + 1', evaluate=False).equals(x**2 + 2*x + 1)\n"], "sample_1114": ["def test_issue_17858_continued():\n    assert 1 in Range(1, oo)\n    assert 0 not in Range(1, oo)\n    assert oo in Range(1, oo)\n    assert -oo not in Range(1, oo)\n    assert 1 in Range(-oo, 1)\n    assert 0 not in Range(-oo, 1)\n    assert -oo in Range(-oo, 1)\n    assert 1 not in Range(-oo, 1, -1)\n    assert 0 in Range(-oo, 1, -1)\n    assert -oo not in Range(-oo, 1, -1)\n"], "sample_353": ["    def test_create_permissions_with_custom_permissions(self):\n        custom_permissions = [\n            ('my_custom_permission', 'Some custom permission'),\n            ('another_custom_permission', 'Another custom permission'),\n        ]\n        Permission._meta.permissions = custom_permissions\n        create_permissions(self.app_config, verbosity=0)\n\n        self.assertEqual(Permission.objects.count(), len(custom_permissions))\n        for permission in Permission.objects.all():\n            self.assertIn(permission.name, [p[0] for p in custom_permissions])\n            self.assertEqual(permission.codename, p[1] for p in custom_permissions)\n"], "sample_204": ["    def test_invalid_migration(self):\n        \"\"\"\n        Tests that invalid migrations are caught during loading.\n        \"\"\"\n        with self.assertRaises(ImportError):\n            MigrationLoader(connection)\n"], "sample_464": ["    def test_content_disposition_buffer_with_special_characters(self):\n        response = FileResponse(\n            io.BytesIO(b\"binary content\"),\n            as_attachment=True,\n            filename=\"file with special characters.txt\",\n        )\n        self.assertEqual(\n            response.headers[\"Content-Disposition\"],\n            'attachment; filename=\"file with special characters.txt\"',\n        )\n"], "sample_941": ["def test_stringify_type_hints_ForwardRef():\n    from typing import ForwardRef  # type: ignore\n    assert stringify(ForwardRef(\"myint\")) == \"myint\"\n"], "sample_384": ["    def test_related_object_update(self):\n        food = Food.objects.create(name=\"Food A\")\n        article = Article.objects.create(name=\"Article A\", food=food)\n        food.name = \"Updated Food A\"\n        Article.objects.bulk_update([article], fields=[\"food\"])\n        article.refresh_from_db()\n        self.assertEqual(article.food.name, \"Updated Food A\")\n"], "sample_639": ["compilation error"], "sample_184": ["    def test_unique_constraint_include_pointing_to_fk(self):\n        class Target(models.Model):\n            pass\n\n        class Model(models.Model):\n            fk_1 = models.ForeignKey(Target, models.CASCADE, related_name='target_1')\n            fk_2 = models.ForeignKey(Target, models.CASCADE, related_name='target_2')\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['fk_1_id', 'fk_2'],\n                        include=['fk_1'],\n                        name='name',\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n"], "sample_1131": ["def test_log1p():\n    from sympy import log1p\n\n    expr = log1p(x)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr) == 'scipy.special.log1p(x)'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr) == 'numpy.log1p(x)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr) == 'math.log(1 + x)'\n\n    prntr = MpmathPrinter()\n    assert prntr.doprint(expr) == 'mpmath.log1p(x)'\n"], "sample_458": ["    def test_floatformat_with_decimal(self):\n        with self.settings(USE_THOUSAND_SEPARATOR=True, NUMBER_GROUPING=3, THOUSAND_SEPARATOR=\"!\"):\n            self.assertEqual(floatformat(Decimal(\"12345.6789\"), 2), \"12!345.68\")\n            self.assertEqual(floatformat(Decimal(\"12345.6789\"), 3), \"12!345.679\")\n            self.assertEqual(floatformat(Decimal(\"12345.6789\"), 0), \"12346\")\n            self.assertEqual(floatformat(Decimal(\"12345.6789\"), -2), \"12345.68\")\n            self.assertEqual(floatformat(Decimal(\"12345.6789\"), 10), \"12!345.678900\")\n"], "sample_99": ["    def test_trunc_func_with_timezone_and_output_field(self):\n        start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n        end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n        start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n        end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n        self.create_model(start_datetime, end_datetime)\n        melb = pytz.timezone('Australia/Melbourne')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated_date=TruncDate('start_datetime', output_field=DateField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, start_datetime.date()),\n                (end_datetime, end_datetime.date()),\n            ],\n            lambda m: (m.start_datetime, m.truncated_date)\n        )\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated_time=TruncTime('start_datetime', output_field=TimeField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, start_datetime.time()),\n                (end_datetime, end_datetime.time()),\n            ],\n            lambda m: (m.start_datetime, m.truncated_time)\n        )\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated_hour=TruncHour('start_datetime', output_field=TimeField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, start_datetime.replace(minute=0, second=0, microsecond=0)),\n                (end_datetime, end_datetime.replace(minute=0, second=0, microsecond=0)),\n            ],\n            lambda m: (m.start_datetime, m"], "sample_937": ["    def test_unparse_starred_arguments():\n        source = \"\"\"\n            pass\n        \"\"\"\n        module = ast.parse(source)\n        args = module.body[0].args\n        assert ast.unparse(args) == \"a, *args, b, **kwargs\"\n"], "sample_1154": ["def test__linsolve_sparse():\n    eqs = [\n        Eq(x + y + z, 1),\n        Eq(x - y + 2*z, 2),\n        Eq(2*x + y - z, 3)\n    ]\n    sol = {x: 1, y: 0, z: 0}\n    assert _linsolve(eqs, (x, y, z)) == sol\n"], "sample_14": ["def test_angle_from_string_with_unit_and_sign():\n    \"\"\"\n    Test that Angle can be created from a string with unit and sign\n    \"\"\"\n    a = Angle('-10d', unit=u.deg)\n    assert a.value == -10.0\n    assert a.unit == u.deg\n\n    a = Angle('+10d', unit=u.deg)\n    assert a.value == 10.0\n    assert a.unit == u.deg\n\n    a = Angle('-10h', unit=u.hourangle)\n    assert a.value == -10.0\n    assert a.unit == u.hourangle\n\n    a = Angle('+10h', unit=u.hourangle)\n    assert a.value == 10.0\n    assert a.unit == u.hourangle\n"], "sample_746": ["def test_log_loss_multiclass_with_missing_labels():\n    y_true = [0, 1, 2, 2, 3]\n    y_pred = np.array([\n        [+0.36, -0.17, -0.58, -0.99],\n        [-0.55, -0.38, -0.48, -0.58],\n        [-1.45, -0.58, -0.38, -0.17],\n        [-0.55, -0.38, -0.48, -0.58],\n        [-2.36, -0.79, -0.27, +0.24]\n    ])\n    labels = np.array([0, 1, 2, 3, 4])\n    dummy_losses = np.array([\n        1 - pred_decision[0][0] + pred_decision[0][1],\n        1 - pred_decision[1][1] + pred_decision[1][2],\n        1 - pred_decision[2][2] + pred_decision[2][3],\n        1 - pred_decision[3][1] + pred_decision[3][2],\n        1 - pred_decision[4][3] + pred_decision[4][2]\n    ])\n    dummy_losses[dummy_losses <= 0] = 0\n    dummy_hinge_loss = np.mean(dummy_losses)\n    assert_equal(log_loss(y_true, y_pred, labels=labels),\n                 dummy_hinge_loss)\n"], "sample_814": ["    def test_gradient_boosting_with_init_estimator_with_params():\n        # Check that GradientBoostingRegressor works when init is a sklearn\n        # estimator with parameters\n        X, y = make_regression(random_state=0)\n        init_est = LinearRegression(fit_intercept=False)\n        gb = GradientBoostingRegressor(init=init_est)\n        gb.fit(X, y)\n        assert_equal(gb.init_.coef_.shape, init_est.coef_.shape)\n"], "sample_509": ["def test_date_ticker_factory_large_span():\n    locator, _ = mdates.date_ticker_factory(10000)\n    assert isinstance(locator, mdates.YearLocator)\n"], "sample_608": ["    def test_repr_large_dataset(self) -> None:\n        large_dataset = xr.Dataset(\n            {\n                \"var1\": ((\"x\", \"y\"), np.random.randn(1000, 1000)),\n                \"var2\": ((\"x\", \"y\"), np.random.randn(1000, 1000)),\n                \"var3\": ((\"x\", \"y\"), np.random.randn(1000, 1000)),\n            },\n            coords={\n                \"x\": np.arange(1000),\n                \"y\": np.arange(1000),\n            },\n        )\n\n        with xr.set_options(display_expand_data=False):\n            actual = formatting.dataset_repr(large_dataset)\n            assert len(actual.splitlines()) < 100\n"], "sample_748": ["def test_grid_search_with_preprocessor():\n    from sklearn.pipeline import Pipeline\n    from sklearn.preprocessing import StandardScaler\n\n    X = np.arange(20).reshape(5, -1)\n    y = [0, 0, 1, 1, 1]\n\n    preprocessor = Pipeline([\n        ('scaler', StandardScaler()),\n    ])\n    clf = MockClassifier()\n    grid_search = GridSearchCV(\n        Pipeline([('preprocessor', preprocessor), ('classifier', clf)]),\n        {'classifier__foo_param': [1, 2, 3]}, cv=2)\n    grid_search.fit(X, y)\n    assert_equal(grid_search.best_estimator_.steps[0][1].__class__.__name__,\n                  'StandardScaler')\n    assert_equal(grid_search.best_estimator_.steps[1][1].__class__.__name__,\n                  'MockClassifier')\n"], "sample_601": ["def test_cftime_round_accessor(cftime_rounding_dataarray, cftime_date_type, use_dask):\n    import dask.array as da\n\n    freq = \"D\"\n    expected = xr.DataArray(\n        [\n            [cftime_date_type(1, 1, 1, 0), cftime_date_type(1, 1, 1, 0)],\n            [cftime_date_type(1, 1, 1, 0), cftime_date_type(1, 1, 2, 0)],\n        ],\n        name=\"round\",\n    )\n\n    if use_dask:\n        chunks = {\"dim_0\": 1}\n        # Currently a compute is done to inspect a single value of the array\n        # if it is of object dtype to check if it is a cftime.datetime (if not\n        # we raise an error when using the dt accessor).\n        with raise_if_dask_computes(max_computes=1):\n            result = cftime_rounding_dataarray.chunk(chunks).dt.round(freq)\n        expected = expected.chunk(chunks)\n        assert isinstance(result.data, da.Array)\n        assert result.chunks == expected.chunks\n    else:\n        result = cftime_rounding_dataarray.dt.round(freq)\n\n    assert_identical(result, expected)\n"], "sample_145": ["    def test_actions_not_callable(self):\n        class BandAdmin(ModelAdmin):\n            actions = ('not_callable',)\n\n        self.assertIsInvalid(\n            BandAdmin, Band,\n            \"The value of 'actions[0]' must be a callable.\",\n            id='admin.E131',\n        )\n"], "sample_1020": ["def test_Sum():\n    assert mcode(Sum(x**n, (n, 0, 10))) == \"Hold[Sum[x^n, {n, 0, 10}]]\"\n"], "sample_1072": ["def test_issue_11207_continued():\n    assert floor(x + 1) == floor(x) + 1\n    assert ceiling(x + 1) == ceiling(x) + 1\n    assert floor(x - 1) == floor(x) - 1\n    assert ceiling(x - 1) == ceiling(x) - 1\n"], "sample_228": ["    def test_invalid(self):\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '0',\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': 'invalid',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '1',\n        }\n        ChoiceFormSet = formset_factory(Choice)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [{'votes': ['Enter a valid number.']}, {}]\n        self.assertEqual(formset1._errors, expected_errors)\n        self.assertEqual(formset2._errors, expected_errors)\n"], "sample_757": ["def test_encoder_sparse_output():\n    X = np.array([[1, 2], [3, 4]])\n    enc = OneHotEncoder(sparse=True)\n    X_tr = enc.fit_transform(X)\n    assert isinstance(X_tr, sparse.csr_matrix)\n    assert X_tr.shape == (2, 4)\n    assert_array_equal(X_tr.toarray(), np.array([[1., 0., 1., 0.],\n                                                [0., 1., 0., 1.]])\n    \n    enc = OrdinalEncoder(sparse=True)\n    X_tr = enc.fit_transform(X)\n    assert isinstance(X_tr, sparse.csr_matrix)\n    assert X_tr.shape == (2, 2)\n    assert_array_equal(X_tr.toarray(), np.array([[0., 1.],\n                                                [1., 0.]])\n"], "sample_764": ["def test_column_transformer_sparse_threshold_with_remainder():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder=SparseMatrixTrans(),\n                           sparse_threshold=0.5)\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n\n    #  SparseMatrixTrans creates 3 features for each column, thus:\n    assert X_trans.shape == (3, 3)\n    assert_array_equal(X_trans.toarray(), np.eye(3))\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], SparseMatrixTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n\n\n\n"], "sample_994": ["def test_issue_10584():\n    assert Float(1.23456789012345678901234567890123, 100) == Float(1.23456789012345678901234567890123, 100)\n    assert Float(1.23456789012345678901234567890123, 100) != Float(1.23456789012345678901234567890124, 100)\n"], "sample_257": ["    def test_contains_contained_by_with_key_transform_subquery(self):\n        obj = NullableJSONModel.objects.create(\n            value={'d': [{'f': 'g'}, {'h': 'i'}]},\n        )\n        self.assertIs(\n            NullableJSONModel.objects.filter(\n                value__d__contains=Subquery(\n                    NullableJSONModel.objects.filter(pk=OuterRef('pk')).values('value__d__0__f')\n                )\n            ).exists(),\n            True,\n        )\n        self.assertIs(\n            NullableJSONModel.objects.filter(\n                value__d__contained_by=Subquery(\n                    NullableJSONModel.objects.filter(pk=OuterRef('pk')).values('value__d__0')\n                )\n            ).exists(),\n            True,\n        )\n"], "sample_141": ["    def test_datetime_encoding(self):\n        dt = datetime.datetime(2023, 10, 26, 10, 30, 0)\n        self.assertEqual(\n            json.dumps({'dt': dt}, cls=DjangoJSONEncoder),\n            '{\"dt\": \"2023-10-26T10:30:00\"}'\n        )\n"], "sample_494": ["    def test_serialize_custom_serializer(self):\n        class MyCustomSerializer(BaseSerializer):\n                return f\"custom_value({value})\", {\"from . import MyCustomSerializer\"}\n\n        with self.subTest(\"custom serializer\"):\n            self.assertSerializedResultEqual(\n                MyCustomSerializer(value=\"hello\"),\n                (\"custom_value('hello')\", {\"from . import MyCustomSerializer\"}),\n            )\n\n"], "sample_1066": ["compilation error"], "sample_74": ["    def test_empty_db_name(self):\n        with self.assertRaises(subprocess.CalledProcessError):\n            self._run_it({\n                'database': '',\n                'user': 'someuser',\n                'password': 'somepassword',\n                'host': 'somehost',\n                'port': '444',\n            })\n"], "sample_61": ["    def test_ascii_validator(self):\n        valid_usernames = ['joe', 'john_doe', 'johndoe123']\n        invalid_usernames = ['Ren\u00e9', '\u0391\u03bb\u03ba\u03b7\u03c2', '\u0391\u03bb\u03ba\u03b7\u03c2', 'johnd\u00f6e']\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n"], "sample_926": ["        def assert_classes(self, tag, expected_classes):\n            assert self.content_classes[tag] == expected_classes, (\n                f\"Classes for role '{self.name}' with tag '{tag}' \"\n                f\"should be {expected_classes}, but are \"\n                f\"{self.content_classes[tag]}\"\n            )\n"], "sample_43": ["def test_events_fitness_p0_prior():\n    rng = np.random.RandomState(0)\n    t = rng.rand(100)\n    x = np.ones_like(t)\n\n    # Test that p0_prior is used when ncp_prior is not specified\n    with pytest.raises(ValueError):\n        bayesian_blocks(t, x, fitness='events', ncp_prior=0.5)\n    with pytest.raises(ValueError):\n        bayesian_blocks(t, x, fitness='events', gamma=0.5)\n\n    bins = bayesian_blocks(t, x, fitness='events', p0=0.1)\n    assert_allclose(bins, [0, 0.5, 1])\n"], "sample_1191": ["compilation error"], "sample_96": ["    def test_actions_callable(self):\n        class BandAdmin(ModelAdmin):\n            actions = ('not_callable',)\n\n        self.assertIsInvalid(\n            BandAdmin, Band,\n            \"The value of 'actions[0]' must be a callable.\",\n            id='admin.E131',\n        )\n"], "sample_158": ["    def test_invalid_related_name(self):\n        class Fan(models.Model):\n            pass\n\n        class Event(models.Model):\n            invitees = models.ManyToManyField(Fan, through='Invitation', through_fields=('invitee', 'event'), related_name='invalid_related_name')\n\n        class Invitation(models.Model):\n            event = models.ForeignKey(Event, models.CASCADE)\n            invitee = models.ForeignKey(Fan, models.CASCADE)\n            inviter = models.ForeignKey(Fan, models.CASCADE, related_name='+')\n\n        field = Event._meta.get_field('invitees')\n        self.assertEqual(field.check(from_model=Event), [\n            Error(\n                \"Related name 'invalid_related_name' for 'Event.invitees' is invalid. \"\n                \"It should be a valid Python identifier.\",\n                hint=\"Please choose a valid Python identifier for the related name.\",\n                obj=field,\n                id='fields.E311',\n            ),\n        ])\n\n\n\n"], "sample_102": ["    def test_union_with_distinct_and_order_by(self):\n        qs1 = Number.objects.filter(num__lte=1).distinct()\n        qs2 = Number.objects.filter(num__gte=2, num__lte=3).distinct()\n        self.assertNumbersEqual(qs1.union(qs2).order_by('-num'), [3, 2, 1, 0])\n"], "sample_352": ["    def test_ticket_24605_with_subquery(self):\n        \"\"\"\n        Subquery table names should be quoted even when nested.\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        self.assertSequenceEqual(\n            Individual.objects.filter(\n                Q(alive=True) & Q(related_individual__related__pk__in=Individual.objects.filter(alive=False).values('pk'))\n            ),\n            [i1]\n        )\n"], "sample_815": ["def test_balanced_accuracy_score_with_multiclass_labels():\n    y_true = np.array([0, 1, 2, 0, 1, 2])\n    y_pred = np.array([0.1, 0.9, 0.2, 0.8, 0.6, 0.3])\n    balanced = balanced_accuracy_score(y_true, y_pred)\n    assert_almost_equal(balanced, 0.6666667)\n"], "sample_1189": ["def test_issue_23458():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    x = symbols('x')\n    f = lambdify(x, gamma(x), modules='scipy')\n    assert abs(f(1.5) - 0.886226925452758) < 1e-10\n"], "sample_189": ["    def test_cache_key_with_user(self):\n        request = self.factory.get(self.path)\n        request.user = User.objects.create(username='testuser')\n        template = engines['django'].from_string(\"This is a test\")\n        response = TemplateResponse(request, template)\n        key = get_cache_key(request)\n        self.assertIn('user_testuser', key)\n"], "sample_281": ["    def test_autocomplete_with_related_model_ordering(self):\n        class OrderingQuestionAdmin(QuestionAdmin):\n            ordering = ['-question']\n\n        with model_admin(Question, OrderingQuestionAdmin):\n            Question.objects.bulk_create(\n                Question(question=f'Question {i}') for i in range(PAGINATOR_SIZE + 10)\n            )\n            self.selenium.get(self.live_server_url + reverse('autocomplete_admin:admin_views_answer_add'))\n            elem = self.selenium.find_element_by_css_selector('.select2-selection')\n            elem.click()  # Open the autocomplete dropdown.\n            results = self.selenium.find_element_by_css_selector('.select2-results')\n            self.assertTrue(results.is_displayed())\n            results = results.find_elements_by_css_selector('.select2-results__option')\n            self.assertEqual([result.text for result in results], [\n                f'Question {i}' for i in range(PAGINATOR_SIZE + 10)\n            ][::-1])\n\n\n\n"], "sample_846": ["def test_column_transformer_sparse_remainder_transformer_with_sparse_threshold():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).astype('float').T\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder=SparseMatrixTrans(),\n                           sparse_threshold=0.5)\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n\n    # SparseMatrixTrans creates 3 features for each column, thus:\n    assert X_trans.shape == (3, 3)\n    assert_array_equal(X_trans.toarray(), np.eye(3))\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], SparseMatrixTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n\n\n\n"], "sample_1104": ["def test_MatrixPow():\n    A = MatrixSymbol('A', 2, 2)\n    assert str(A**2) == 'A**2'\n    assert str(A**-1) == 'A**(-1)'\n    assert str(A**(1/2)) == 'A**(1/2)'\n"], "sample_4": ["    def test_readwrite_html_table_metadata(self, cosmo, read, write, tmp_path, add_cu):\n        \"\"\"Test metadata handling.\"\"\"\n        fp = tmp_path / \"test_readwrite_html_table_metadata.html\"\n\n        # ------------\n        # To Table\n\n        write(fp, format=\"ascii.html\", **cosmo.meta)\n\n        # some checks on the saved file\n        tbl = QTable.read(fp)\n        assert tbl.meta == cosmo.meta\n\n        # ------------\n        # From Table\n\n        # read with mismatching parameters errors\n        with pytest.raises(TypeError, match=\"there are unused parameters\"):\n            read(fp, format=\"ascii.html\")\n\n        # unless mismatched are moved to meta\n        got = read(fp, format=\"ascii.html\", move_to_meta=True)\n        assert got == cosmo\n        assert got.meta == cosmo.meta\n"], "sample_442": ["    def test_compress(self):\n        signer = signing.Signer(key=\"predictable-secret\")\n        data = b\"This is a long string to test compression\" * 100\n        compressed_signed = signer.sign_object(data, compress=True)\n        uncompressed_signed = signer.sign_object(data, compress=False)\n        self.assertTrue(len(compressed_signed) < len(uncompressed_signed))\n        self.assertEqual(signer.unsign_object(compressed_signed), data)\n        self.assertEqual(signer.unsign_object(uncompressed_signed), data)\n"], "sample_33": ["def test_OrderedDescriptorContainer_inheritance():\n    class Point2D(metaclass=misc.OrderedDescriptorContainer):\n        x = misc.TypedAttribute((float, int))\n        y = misc.TypedAttribute((float, int))\n\n    class Point3D(Point2D):\n        z = misc.TypedAttribute((float, int))\n        _inherit_descriptors_ = (misc.TypedAttribute,)\n\n    p2d = Point2D(1.0, 2.0)\n    p3d = Point3D(1.0, 2.0, 3.0)\n\n    assert len(Point2D.typed_attributes) == 2\n    assert len(Point3D.typed_attributes) == 3\n"], "sample_86": ["    def test_keep_lazy(self):\n        @keep_lazy(str)\n            return text.upper()\n\n        lazy_text = lazy(lambda: \"hello\")\n        result = my_func(lazy_text)\n        self.assertEqual(result, \"HELLO\")\n\n        result = my_func(\"world\")\n        self.assertEqual(result, \"WORLD\")\n\n"], "sample_249": ["    def test_object_reference_with_null_field(self):\n        # serialize_db_to_string() and deserialize_db_from_string() handles\n        # ObjectReference with null field.\n        obj = Object.objects.create(pk=1)\n        obj_ref = ObjectReference.objects.create(obj=obj)\n        obj_ref.obj = None\n        obj_ref.save()\n        # Serialize objects.\n        with mock.patch('django.db.migrations.loader.MigrationLoader') as loader:\n            # serialize_db_to_string() serializes only migrated apps, so mark\n            # the backends app as migrated.\n            loader_instance = loader.return_value\n            loader_instance.migrated_apps = {'backends'}\n            data = connection.creation.serialize_db_to_string()\n        Object.objects.all().delete()\n        ObjectReference.objects.all().delete()\n        # Deserialize objects.\n        connection.creation.deserialize_db_from_string(data)\n        obj_ref = ObjectReference.objects.get()\n        self.assertIsNone(obj_ref.obj)\n\n\n\n"], "sample_1203": ["compilation error"], "sample_359": ["    def test_references_field_by_through_with_fields(self):\n        operation = FieldOperation(\n            'Model', 'field', models.ManyToManyField('Other', through='Through', through_fields=('field1', 'field2'), related_name='related_name')\n        )\n        self.assertIs(operation.references_field('Other', 'field1', 'migrations'), True)\n        self.assertIs(operation.references_field('Other', 'field2', 'migrations'), True)\n        self.assertIs(operation.references_field('Through', 'field1', 'migrations'), True)\n        self.assertIs(operation.references_field('Through', 'field2', 'migrations'), True)\n        self.assertIs(operation.references_field('Missing', 'whatever', 'migrations'), False)\n"], "sample_484": ["    def test_negative_length(self):\n        with self.assertRaisesMessage(ValueError, \"'length' must be greater than 0\"):\n            Author.objects.annotate(raises=Right(\"name\", -5))\n"], "sample_34": ["def test_unit_with_custom_format():\n    class MyUnit(u.UnitBase):\n            super().__init__(value, format_name=format_name)\n\n    my_unit = MyUnit(1, format_name='custom')\n    assert my_unit.get_format_name() == 'custom'\n    assert str(my_unit) == '1 custom'\n\n\n\n"], "sample_298": ["    def test_token_with_different_algorithm(self):\n        user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n        p0 = PasswordResetTokenGenerator()\n        p0.algorithm = 'sha512'\n        tk0 = p0.make_token(user)\n        p1 = PasswordResetTokenGenerator()\n        p1.algorithm = 'sha256'\n        tk1 = p1.make_token(user)\n        self.assertIs(p0.check_token(user, tk0), True)\n        self.assertIs(p1.check_token(user, tk1), True)\n        self.assertIs(p0.check_token(user, tk1), False)\n        self.assertIs(p1.check_token(user, tk0), False)\n"], "sample_243": ["    def test_join_promotion(self):\n        query = Query(Author)\n        query.add_join(Item, 'author', 'id', 'id', 'INNER')\n        query.add_where(Q(item__name='foo'))\n        query.add_where(Q(num__gt=2))\n        query.promote_joins(set())\n        query.demote_joins(set())\n        self.assertEqual(query.alias_map['item'].join_type, 'INNER')\n"], "sample_1050": ["def test_indexed_base():\n    p = IndexedBase(\"p\")\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n"], "sample_769": ["compilation error"], "sample_933": ["def test_gettext_custom_domain(app):\n    app.builder.build(['index_entries'])\n\n    _msgid_getter = re.compile(r'msgid \"(.*)\"').search\n\n        m = _msgid_getter(msgid)\n        if m:\n            return m.groups()[0]\n        return None\n\n    pot = (app.outdir / 'index_entries.pot').read_text()\n    msgids = [_f for _f in map(msgid_getter, pot.splitlines()) if _f]\n\n    expected_msgids = [\n        \"i18n with index entries\",\n        \"index target section\",\n        \"this is :index:`Newsletter` target paragraph.\",\n        \"various index entries\",\n        \"That's all.\",\n        \"Mailing List\",\n        \"Newsletter\",\n        \"Recipients List\",\n        \"First\",\n        \"Second\",\n        \"Third\",\n        \"Entry\",\n        \"See\",\n        \"Module\",\n        \"Keyword\",\n        \"Operator\",\n        \"Object\",\n        \"Exception\",\n        \"Statement\",\n        \"Builtin\",\n    ]\n    for expect in expected_msgids:\n        assert expect in msgids\n        msgids.remove(expect)\n\n    # unexpected msgid existent\n    assert msgids == []\n"], "sample_193": ["    def test_proxy_with_fk(self):\n        A = self.create_model(\"A\")\n        B = self.create_model(\"B\", bases=(A,), proxy=True)\n        C = self.create_model(\"C\", foreign_keys=[models.ForeignKey('B', models.CASCADE)])\n        self.assertRelated(A, [B, C])\n        self.assertRelated(B, [C])\n        self.assertRelated(C, [B])\n"], "sample_1098": ["def test_appellf1_limits():\n    a, b1, b2, c, x, y = symbols('a b1 b2 c x y')\n    assert limit(appellf1(a, b1, b2, c, x, 0), x, 0) == 1\n    assert limit(appellf1(a, b1, b2, c, x, y), y, 0) == 1\n    assert limit(appellf1(a, b1, b2, c, x, y), x, 1) == \\\n        appellf1(a, b1, b2, c, 1, y)\n    assert limit(appellf1(a, b1, b2, c, x, y), y, 1) == \\\n        appellf1(a, b1, b2, c, x, 1)\n"], "sample_186": ["    def test_check_for_invalid_field_types(self):\n        class SongAdmin(admin.ModelAdmin):\n            fields = ['title', 'invalid_field']\n\n        errors = SongAdmin(Song, AdminSite()).check()\n        expected = [\n            checks.Error(\n                \"The value of 'fields[1]' is not a callable, an attribute \"\n                \"of 'SongAdmin', or an attribute of 'admin_checks.Song'.\",\n                obj=SongAdmin,\n                id='admin.E035',\n            )\n        ]\n        self.assertEqual(errors, expected)\n"], "sample_831": ["compilation error"], "sample_232": ["    def test_key_transform_with_null_value(self):\n        obj = NullableJSONModel.objects.create(value={'a': None})\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__a=KeyTransform(None, 'value')),\n            [obj],\n        )\n"], "sample_662": ["    def test_report_sections(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n                print(\"This is a test\")\n                assert False\n        \"\"\"\n        )\n        reprec = testdir.inline_run()\n        reports = reprec.getreports(\"pytest_runtest_logreport\")\n        assert len(reports) == 3\n        test_a_call = reports[1]\n        assert len(test_a_call.sections) == 1\n        assert test_a_call.sections[0][0] == \"Captured stdout\"\n        assert \"This is a test\" in test_a_call.sections[0][1]\n"], "sample_1089": ["compilation error"], "sample_922": ["def test_module_index_with_options(app):\n    text = (\".. py:module:: docutils\\n\"\n            \"   :platform: any\\n\"\n            \".. py:module:: sphinx\\n\"\n            \"   :platform: linux\\n\")\n    restructuredtext.parse(app, text)\n    index = PythonModuleIndex(app.env.get_domain('py'))\n    assert index.generate() == (\n        [('d', [IndexEntry('docutils', 0, 'index', 'module-docutils', '', '', '')]),\n         ('s', [IndexEntry('sphinx', 1, 'index', 'module-sphinx', '', '', '')])],\n        False\n    )\n"], "sample_1115": ["compilation error"], "sample_479": ["    def test_rename_index_with_field_change(self):\n        self.assertOptimizesTo(\n            [\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"mid_name\", old_fields=(\"weight\", \"pink\")\n                ),\n                migrations.AlterField(\"Pony\", \"weight\", models.FloatField()),\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"new_name\", old_name=\"mid_name\"\n                ),\n            ],\n            [\n                migrations.RenameIndex(\n                    \"Pony\", new_name=\"new_name\", old_fields=(\"weight\", \"pink\")\n                ),\n            ],\n        )\n"], "sample_363": ["    def test_clear_button(self):\n        from selenium.webdriver.common.by import By\n        self.admin_login(username='super', password='secret', login_url='/')\n        self.selenium.get(self.live_server_url + reverse('admin:admin_widgets_event_add'))\n        main_window = self.selenium.current_window_handle\n\n        # Select a band\n        self.selenium.find_element(By.ID, 'lookup_id_main_band').click()\n        self.wait_for_and_switch_to_popup()\n        link = self.selenium.find_element(By.LINK_TEXT, 'Bogey Blues')\n        self.assertIn('/band/42/', link.get_attribute('href'))\n        link.click()\n        self.selenium.switch_to.window(main_window)\n        self.wait_for_value('#id_main_band', '42')\n\n        # Click the clear button\n        self.selenium.find_element(By.ID, 'clear_id_main_band').click()\n\n        # The field is now empty\n        self.assertEqual(self.selenium.find_element(By.ID, 'id_main_band').get_attribute('value'), '')\n"], "sample_282": ["    def test_partially_required_field(self):\n        form = PartiallyRequiredForm({'f': ''})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['f'], None)\n\n        form = PartiallyRequiredForm({'f': 'some,text'})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['f'], 'some,text')\n\n        form = PartiallyRequiredForm({'f': 'some,text,other'})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors['f'], [ValidationError(\"This field is required.\" )])\n"], "sample_1073": ["def test_sqrtdenest_complex():\n    assert sqrtdenest(sqrt(2 + 3*I)) == sqrt(2 + 3*I)\n    assert sqrtdenest(sqrt(2 + 3*I) + sqrt(2 - 3*I)) == sqrt(4)\n    assert sqrtdenest(sqrt(2 + 3*I) - sqrt(2 - 3*I)) == I*sqrt(6)\n    assert sqrtdenest(sqrt(2 + 3*I) + sqrt(2 - 3*I) + 1) == sqrt(4) + 1\n    assert sqrtdenest(sqrt(2 + 3*I) - sqrt(2 - 3*I) + 1) == I*sqrt(6) + 1\n    assert sqrtdenest(sqrt(2 + 3*I) + sqrt(2 - 3*I) + I) == sqrt(4) + I\n    assert sqrtdenest(sqrt(2 + 3*I) - sqrt(2 - 3*I) + I) == I*sqrt(6) + I\n"], "sample_602": ["def test_to_netcdf_with_compute_false():\n    ds = xr.Dataset(\n        data_vars={\"a\": ((\"x\", \"y\"), np.arange(12).reshape(3, 4))},\n        coords={\"x\": np.arange(3), \"y\": np.arange(4)},\n    )\n\n        assert isinstance(result, bytes)\n        ds_loaded = xr.open_dataset(io.BytesIO(result))\n        assert_identical(ds, ds_loaded)\n\n    result = ds.to_netcdf(\n        \"fake_filename\", compute=False\n    )\n    assert isinstance(result, dask.delayed.Delayed)\n    result.compute()\n    _check_delayed_result(result.compute())\n"], "sample_1043": ["def test_user_functions():\n    known_functions = {\n        \"myfunc\": [(lambda x: True, \"MyFunc[x]\")\n    }\n    \n    class MyFunc(Function):\n            super().__init__(\"myfunc\", *args)\n    \n    with mcode.settings(user_functions=known_functions):\n        assert mcode(MyFunc(x)) == \"MyFunc[x]\"\n"], "sample_1136": ["def test_issue_19794():\n    p = Poly(x**2 + y**2, x, y)\n    assert p.as_expr() == x**2 + y**2\n    assert p.as_expr(deep=True) == x**2 + y**2\n"], "sample_1138": ["compilation error"], "sample_778": ["def test_nmf_sparse_input_with_custom_init():\n    # Smoke test for sparse input with custom initialization\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(rng.randn(10, 5))\n    A[:, 2 * np.arange(5)] = 0\n    A_sparse = csc_matrix(A)\n\n    n_components = 3\n    W_init = np.abs(rng.randn(10, n_components))\n    H_init = np.abs(rng.randn(n_components, 5))\n\n    est1 = NMF(solver='mu', n_components=n_components, init='custom',\n               random_state=0, tol=1e-2)\n    est1.fit_transform(A_sparse, W=W_init, H=H_init)\n\n    est2 = NMF(solver='mu', n_components=n_components, init='custom',\n               random_state=0, tol=1e-2)\n    est2.fit_transform(A, W=W_init, H=H_init)\n\n    assert_array_almost_equal(est1.components_, est2.components_)\n"], "sample_929": ["def test_module_index_with_options(app):\n    text = (\".. py:module:: docutils\\n\"\n            \".. py:module:: sphinx\\n\"\n            \".. py:module:: sphinx\\n\"\n            \"   :noindex:\\n\"\n            \".. py:module:: sphinx.config\\n\")\n    restructuredtext.parse(app, text)\n    index = PythonModuleIndex(app.env.get_domain('py'))\n    assert index.generate() == (\n        [('d', [IndexEntry('docutils', 0, 'index', 'module-docutils', '', '', '')]),\n         ('s', [IndexEntry('sphinx', 1, '', '', '', '', '')])],\n        False\n    )\n"], "sample_25": ["    def test_header_update_with_duplicate_keywords(self):\n        h = fits.Header()\n        h[\"FOO\"] = 1\n        h[\"FOO\"] = 2\n        assert h[\"FOO\"] == 2\n        h[\"BAR\"] = \"baz\"\n        h[\"BAR\"] = \"qux\"\n        assert h[\"BAR\"] == \"qux\"\n"], "sample_506": ["def test_spines_circular():\n    fig, ax = plt.subplots()\n    ax.spines['top'].set_patch_circle((0.5, 0.5), 0.2)\n    ax.spines['bottom'].set_patch_circle((0.5, 0.5), 0.2)\n    ax.spines['left'].set_patch_circle((0.5, 0.5), 0.2)\n    ax.spines['right'].set_patch_circle((0.5, 0.5), 0.2)\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n"], "sample_1100": ["def test_issue_16201():\n    x, y = symbols('x y', real=True)\n    assert (x + y)**2 == x**2 + 2*x*y + y**2\n    assert (x - y)**2 == x**2 - 2*x*y + y**2\n    assert (x + y)**3 == x**3 + 3*x**2*y + 3*x*y**2 + y**3\n    assert (x - y)**3 == x**3 - 3*x**2*y + 3*x*y**2 - y**3\n"], "sample_379": ["    def test_mark_safe_with_unicode_characters(self):\n        s = mark_safe('a\\u00e9b')\n        self.assertRenderEqual('{{ s }}', 'a\u00e9b', s=s)\n"], "sample_1037": ["def test_transpose_simplify():\n    A = MatrixSymbol('A', 2, 3)\n    assert simplify(A.T.T) == A\n    assert simplify(A.T + A.T.T) == 2*A.T\n    assert simplify(A.T*A.T.T) == A.T*A\n    assert simplify(A.T*A) == A.T*A\n    assert simplify(A.T*A.T) == A.T*A.T\n    assert simplify(A.T*A.T.T) == A.T*A\n\n\n\n"], "sample_276": ["    def test_field_with_description_interpolation(self):\n        class CustomFieldWithInterpolation(models.Field):\n            description = \"The %(name)s field\"\n\n        field = CustomFieldWithInterpolation()\n        self.assertEqual(views.get_readable_field_data_type(field), \"The %(name)s field\")\n"], "sample_488": ["    def test_namespace_package_with_init(self):\n        \"\"\"\n        A namespace package with an __init__.py file in its root directory\n        can be an app.\n        \"\"\"\n        with extend_sys_path(os.path.join(self.base_location, \"with_init\")):\n            with self.settings(INSTALLED_APPS=[\"nsapp.with_init\"]):\n                app_config = apps.get_app_config(\"nsapp.with_init\")\n                self.assertEqual(app_config.path, os.path.join(self.base_location, \"with_init\"))\n"], "sample_89": ["    def test_snapshot_files_handles_non_existent_files(self):\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.nonexistent_file]):\n            snapshot = dict(self.reloader.snapshot_files())\n        self.assertNotIn(self.nonexistent_file, snapshot)\n"], "sample_798": ["def test_ridge_multi_output_classification():\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5,\n                               n_classes=3, random_state=42)\n    y = y.reshape(-1, 3)\n\n    ridge = RidgeClassifier(multi_class='multinomial')\n    ridge.fit(X, y)\n    assert_array_almost_equal(ridge.coef_.shape, (3, 10))\n    assert_array_almost_equal(ridge.intercept_.shape, (3,))\n\n    y_pred = ridge.predict(X)\n    assert_array_equal(y_pred.shape, (100, 3))\n\n    # Test with class_weight\n    class_weights = {0: 1, 1: 2, 2: 1}\n    ridge = RidgeClassifier(multi_class='multinomial', class_weight=class_weights)\n    ridge.fit(X, y)\n    assert_array_almost_equal(ridge.coef_.shape, (3, 10))\n    assert_array_almost_equal(ridge.intercept_.shape, (3,))\n"], "sample_251": ["    def test_alias_with_subquery(self):\n        qs = Book.objects.alias(\n            top_rating=Subquery(\n                Book.objects.filter(pubdate__year=OuterRef('pubdate_alias')).order_by('-rating').values('rating')[:1]\n            )\n        ).annotate(\n            pubdate_alias=F('pubdate'),\n        ).values('top_rating', 'pubdate_alias')\n        self.assertCountEqual(qs, [\n            (5.0, datetime.date(1991, 10, 15)),\n            (4.5, datetime.date(2007, 12, 6)),\n            (4.0, datetime.date(1995, 1, 15)),\n            (4.0, datetime.date(2008, 6, 23)),\n        ])\n"], "sample_590": ["    def test_concat_different_coords(self):\n        ds1 = Dataset({\"a\": ((\"x\", \"y\"), np.random.random((2, 3))), \"x\": [0, 1]})\n        ds2 = Dataset({\"a\": ((\"x\", \"y\"), np.random.random((2, 3))), \"x\": [2, 3]})\n        with raises_regex(ValueError, \"conflicting values\"):\n            concat([ds1, ds2], dim=\"x\", coords=\"minimal\")\n\n        with raises_regex(ValueError, \"conflicting values\"):\n            concat([ds1, ds2], dim=\"x\", coords=[\"x\"])\n\n        with raises_regex(ValueError, \"conflicting values\"):\n            concat([ds1, ds2], dim=\"x\", coords=[\"y\"])\n\n        with raises_regex(ValueError, \"conflicting values\"):\n            concat([ds1, ds2], dim=\"x\", coords=[\"z\"])\n\n        with raises_regex(ValueError, \"conflicting values\"):\n            concat([ds1, ds2], dim=\"x\", coords={\"x\": [0, 1, 2, 3]})\n\n\n\n"], "sample_872": ["def test_label_ranking_avg_precision_score_with_ties():\n    # Test that label_ranking_avg_precision_score handles ties correctly.\n    y_true = np.array([[1, 0, 0], [0, 1, 1]])\n    y_score = np.array([[0.5, 0.5, 0.6], [0.4, 0.5, 0.6]])\n    result = label_ranking_average_precision_score(y_true, y_score)\n    assert result == pytest.approx(1.0 / 3)\n"], "sample_287": ["    def test_check_for_invalid_field_types(self):\n        class SongAdmin(admin.ModelAdmin):\n            fields = ['title', 'nonexistent_field']\n\n        errors = SongAdmin(Song, AdminSite()).check()\n        expected = [\n            checks.Error(\n                \"The value of 'fields[1]' is not a callable, an attribute \"\n                \"of 'SongAdmin', or an attribute of 'admin_checks.Song'.\",\n                obj=SongAdmin,\n                id='admin.E035',\n            )\n        ]\n        self.assertEqual(errors, expected)\n"], "sample_21": ["def test_read_write_with_err_specs(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3]))\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0], name=\"b\", mask=[False, False, True]\n        )\n    )\n    t1.write(test_file, format=\"ascii.qdp\", err_specs={\"serr\": [1]})\n    t2 = Table.read(test_file, format=\"ascii.qdp\", table_id=0, names=[\"a\", \"b\"])\n    assert np.allclose(t2[\"a\"], t1[\"a\"])\n    assert np.allclose(t2[\"b_err\"], [0, 0, 0])\n"], "sample_330": ["    def test_can_reference_non_existent_with_error(self):\n        with self.assertRaises(Object.DoesNotExist):\n            ObjectReference.objects.create(obj_id=12345)\n"], "sample_349": ["    def test_render_options_with_language_setting(self):\n        translation.activate('fr')\n        beatles = Band.objects.create(name='The Beatles', style='rock')\n        form = AlbumForm(initial={'band': beatles.uuid})\n        output = form.as_table()\n        self.assertIn('<option value=\"%s\" selected>The Beatles</option>' % beatles.uuid, output)\n        translation.deactivate()\n"], "sample_16": ["    def test_all_wrapped_are_in_helpers(self):\n        assert all_wrapped.issubset(\n            SUBCLASS_SAFE_FUNCTIONS\n            | UNSUPPORTED_FUNCTIONS\n            | set(FUNCTION_HELPERS.keys())\n            | set(DISPATCHED_FUNCTIONS.keys())\n        )\n"], "sample_1164": ["def test_braket():\n    f = Function('f')\n    x = symbols('x')\n    bra = Bra(Mul(Rational(1, 2), Symbol('x')))\n    ket = Ket(Mul(Rational(1, 2), Symbol('x')))\n    assert str(braket(bra, ket)) == '<x/2|x/2>'\n    ascii_str = \\"], "sample_278": ["    def test_output_field_override(self):\n        expr = ExpressionWrapper(F('cost'), output_field=FloatField())\n        self.assertIsInstance(expr.output_field, FloatField)\n"], "sample_60": ["    def test_get_formset_kwargs_with_custom_form(self):\n        class CustomMediaForm(ModelForm):\n            class Meta:\n                model = Media\n                fields = ['url', 'description']\n\n        class MediaInline(GenericTabularInline):\n            form = CustomMediaForm\n            model = Media\n\n        class EpisodeAdmin(admin.ModelAdmin):\n            inlines = [MediaInline]\n\n        ma = EpisodeAdmin(Episode, self.site)\n        formset = ma.get_formset(request)\n        self.assertEqual(formset.fields, ['url', 'description'])\n"], "sample_345": ["    def test_snapshot_files_handles_new_files(self):\n        new_file = self.ensure_file(self.tempdir / 'new_file.py')\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file, new_file]):\n            snapshot1 = dict(self.reloader.snapshot_files())\n            self.assertIn(self.existing_file, snapshot1)\n            self.assertIn(new_file, snapshot1)\n"], "sample_841": ["def test_ridge_with_sparse_data():\n    rng = np.random.RandomState(42)\n    n_samples, n_features = 100, 50\n    X = rng.randn(n_samples, n_features)\n    y = rng.randn(n_samples)\n\n    # Create a sparse matrix\n    X_sparse = sp.csr_matrix(X)\n\n    # Fit Ridge with sparse data\n    ridge = Ridge(alpha=1.0)\n    ridge.fit(X_sparse, y)\n\n    # Check that the coefficients are correctly estimated\n    assert_allclose(ridge.coef_, ridge.fit(X, y).coef_)\n"], "sample_901": ["def test_minibatch_kmeans_n_init_with_sparse_data():\n    # Test n_init with sparse data\n    X_csr = sp.csr_matrix(X)\n    mb_kmeans = MiniBatchKMeans(n_clusters=n_clusters, n_init=10,\n                                batch_size=10, random_state=42)\n    mb_kmeans.fit(X_csr)\n    assert mb_kmeans.inertia_ is not None\n"], "sample_763": ["        def __len__(self):\n            return 10\n"], "sample_638": ["def test_run_with_no_arguments(mock_writer, capsys):\n    \"\"\"Test that the script exits with an error message if no arguments are provided.\"\"\"\n    with pytest.raises(SystemExit) as wrapped_sysexit:\n        main.Run([])\n    assert wrapped_sysexit.value.code == 1\n    assert \"usage: pyreverse [options] <packages>\" in capsys.readouterr().out\n"], "sample_986": ["def test_issue_10904():\n    from sympy import sin, cos, pi\n    assert sin(pi/2).evalf(chop=True) == 1\n    assert cos(pi/2).evalf(chop=True) == 0\n    assert sin(pi/2).evalf(chop=100) == 1.0000000000000002\n    assert cos(pi/2).evalf(chop=100) == 0.0000000000000002\n"], "sample_473": ["    def test_get_script_name_trailing_slash(self):\n        \"\"\"\n        Trailing slash in SCRIPT_URL should be preserved in SCRIPT_NAME (#17133).\n        \"\"\"\n        script_name = get_script_name({\"SCRIPT_URL\": \"/mst/milestones/\"},)\n        self.assertEqual(script_name, \"/mst/milestones/\")\n"], "sample_18": ["    def test_structured_quantity_copy(self):\n        q_copy1 = self.q.copy()\n        assert_info_equal(q_copy1, self.q)\n        q_copy2 = copy.copy(self.q)\n        assert_info_equal(q_copy2, self.q)\n        q_copy3 = copy.deepcopy(self.q)\n        assert_info_equal(q_copy3, self.q)\n"], "sample_1183": ["def test_Domain_is_zero():\n    I = S.ImaginaryUnit\n    a, b = [CC.convert(x) for x in (2 + I, 0)]\n    assert CC.is_zero(a) == False\n    assert CC.is_zero(b) == True\n"], "sample_792": ["def test_discrete_nb_with_missing_values():\n    # Test handling of missing values in discrete Naive Bayes\n    X = np.array([[1, 0, None], [0, 1, 1], [1, None, 0]])\n    y = np.array([0, 1, 0])\n\n    for cls in [BernoulliNB, MultinomialNB]:\n        clf = cls()\n        with pytest.raises(ValueError):\n            clf.fit(X, y)\n\n        # Test with imputation\n        X_imputed = X.copy()\n        X_imputed[:, 2] = np.mean(X[:, 2])\n        clf = cls()\n        clf.fit(X_imputed, y)\n        assert_array_equal(clf.predict(X_imputed), [0, 1, 0])\n\n\n\n"], "sample_786": ["def test_ignored_features():\n    X = np.array([[1, 2, 3],\n                  [4, 5, 6],\n                  [7, 8, 9]])\n    kbd = KBinsDiscretizer(n_bins=3, ignore_features=[1], encode='ordinal')\n    kbd.fit(X)\n    Xt = kbd.transform(X)\n    assert Xt.shape[1] == 2\n    assert_array_equal(Xt[:, 0], np.array([0, 1, 2]))\n    assert_array_equal(Xt[:, 1], np.array([0, 1, 2]))\n"], "sample_256": ["    def test_password_validation_errors(self):\n        user = User.objects.get(username='testclient')\n        data = {\n            'password1': 'password',\n            'password2': 'password123',\n        }\n        form = AdminPasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertIn('password_mismatch', form.errors)\n        self.assertIn('password_too_short', form.errors['password1'])\n\n\n\n"], "sample_865": ["def test_prune_tree_with_sparse_data():\n    X_sparse = csc_matrix(np.random.random((10, 5)))\n    y = np.random.randint(0, 2, size=10)\n    clf = DecisionTreeClassifier(random_state=0)\n    info = clf.cost_complexity_pruning_path(X_sparse, y)\n    pruning_path = info.ccp_alphas\n    for ccp_alpha in pruning_path:\n        est = DecisionTreeClassifier(\n            max_leaf_nodes=20, ccp_alpha=ccp_alpha, random_state=0)\n        est.fit(X_sparse, y)\n        assert_is_subtree(est.tree_, clf.tree_)\n\n\n\n"], "sample_45": ["    def test_trunc_func_with_timezone_and_output_field(self):\n        start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n        end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n        start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n        end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n        self.create_model(start_datetime, end_datetime)\n\n        melb = pytz.timezone('Australia/Melbourne')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated_date=TruncDate('start_datetime', output_field=DateField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, start_datetime.date()),\n                (end_datetime, end_datetime.date()),\n            ],\n            lambda m: (m.start_datetime, m.truncated_date)\n        )\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated_time=TruncTime('start_datetime', output_field=TimeField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, start_datetime.time()),\n                (end_datetime, end_datetime.time()),\n            ],\n            lambda m: (m.start_datetime, m.truncated_time)\n        )\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated_hour=TruncHour('start_datetime', output_field=TimeField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, start_datetime.replace(minute=0, second=0, microsecond=0)),\n                (end_datetime, end_datetime.replace(minute=0, second=0, microsecond=0)),\n            ],\n            lambda m: (m.start_datetime, m"], "sample_154": ["    def test_database_connection_used(self, mock_connections):\n        mock_connections.return_value = {'default': mock.MagicMock()}\n        issues = check_database_backends(databases=['default'])\n        self.assertEqual(len(issues), 0)\n"], "sample_370": ["    def test_nested_prefetch_with_filter(self):\n        with self.assertNumQueries(3):\n            rooms = Room.objects.filter(house__name='Big house').prefetch_related(\n                Prefetch(\n                    'house',\n                    queryset=House.objects.filter(address='123 Main St'),\n                )\n            )\n        with self.assertNumQueries(0):\n            self.assertSequenceEqual(rooms, [self.room])\n            self.assertEqual(rooms[0].house.name, 'Big house')\n"], "sample_634": ["    def test_expand_modules_with_ignore_paths(\n        self, files_or_modules, ignore_paths, expected"], "sample_472": ["    def test_paginating_with_custom_ordering(self):\n        paginator = Paginator(Article.objects.order_by('-pub_date'), 5)\n        p = paginator.page(1)\n        self.assertSequenceEqual(p.object_list, reversed(self.articles)[:5])\n"], "sample_172": ["    def test_clear_button(self):\n        self.admin_login(username='super', password='secret', login_url='/')\n        self.selenium.get(self.live_server_url + reverse('admin:admin_widgets_event_add'))\n        main_window = self.selenium.current_window_handle\n\n        # No value has been selected yet\n        self.assertEqual(self.selenium.find_element_by_id('id_main_band').get_attribute('value'), '')\n\n        # Open the popup window and click on a band\n        self.selenium.find_element_by_id('lookup_id_main_band').click()\n        self.wait_for_and_switch_to_popup()\n        link = self.selenium.find_element_by_link_text('Bogey Blues')\n        self.assertIn('/band/42/', link.get_attribute('href'))\n        link.click()\n\n        # The field now contains the selected band's id\n        self.selenium.switch_to.window(main_window)\n        self.wait_for_value('#id_main_band', '42')\n\n        # Click the clear button\n        self.selenium.find_element_by_id('clear_id_main_band').click()\n\n        # The field is now empty\n        self.assertEqual(self.selenium.find_element_by_id('id_main_band').get_attribute('value'), '')\n"], "sample_485": ["    def test_urlize_with_trim_url_limit(self):\n        tests = (\n            (\n                \"This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit\",\n                \"This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit...\",\n            ),\n            (\n                \"This is a short URL: http://www.example.com/short\",\n                \"This is a short URL: http://www.example.com/short\",\n            ),\n        )\n        for value, output in tests:\n            with self.subTest(value=value):\n                self.assertEqual(urlize(value, trim_url_limit=30), output)\n"], "sample_536": ["def test_polygon_selector_reset(ax, draw_bounding_box):\n    verts = [(50, 50), (150, 50), (50, 150)]\n    event_sequence = [\n        *polygon_place_vertex(*verts[0]),\n        *polygon_place_vertex(*verts[1]),\n        *polygon_place_vertex(*verts[2]),\n        *polygon_place_vertex(*verts[0]),\n    ]\n\n    tool = widgets.PolygonSelector(ax, onselect=noop, draw_bounding_box=draw_bounding_box)\n    for (etype, event_args) in event_sequence:\n        do_event(tool, etype, **event_args)\n\n    tool.reset()\n    assert tool.verts == []\n"], "sample_1148": ["def test_matrix_element_subs():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    a = A[0, 0]\n    b = B[1, 1]\n    c = C[0, 1]\n\n    assert a.subs({A: B}) == B[0, 0]\n    assert a.subs({A: C}) == C[0, 0]\n    assert b.subs({B: A}) == A[1, 1]\n    assert c.subs({C: B}) == B[0, 1]\n\n    assert (A[0, 1] + B[1, 0]).subs({A: C, B: A}) == (C[0, 1] + A[1, 0])\n    assert (A[0, 1] + B[1, 0]).subs({A: C, B: C}) == (C[0, 1] + C[1, 0])\n    assert (A[0, 1] + B[1, 0]).subs({A: A, B: B}) == (A[0, 1] + B[1, 0])\n\n    raises(ValueError, lambda: a.subs({A: B, B: C}))\n    raises(ValueError, lambda: a.subs({A: B, C: C}))\n"], "sample_826": ["def test_one_hot_encoder_sparse_output():\n    X = [['abc', 2, 55], ['def', 1, 55]]\n    enc = OneHotEncoder(sparse=True)\n    exp = sparse.csr_matrix([[1, 0, 1, 0],\n                            [0, 1, 0, 1]])\n    assert_array_equal(enc.fit_transform(X).toarray(), exp.toarray())\n    assert isinstance(enc.fit_transform(X), sparse.csr_matrix)\n"], "sample_272": ["    def test_minimize_rollbacks_circular(self):\n        \"\"\"Minimize rollbacks when target has circular dependencies.\"\"\"\n        a1_impl = FakeMigration('a1')\n        a1 = ('a', '1')\n        a2_impl = FakeMigration('a2')\n        a2 = ('a', '2')\n        b1_impl = FakeMigration('b1')\n        b1 = ('b', '1')\n        graph = MigrationGraph()\n        graph.add_node(a1, a1_impl)\n        graph.add_node(a2, a2_impl)\n        graph.add_node(b1, b1_impl)\n        graph.add_dependency(None, a2, a1)\n        graph.add_dependency(None, b1, a2)\n        graph.add_dependency(None, a1, b1)\n\n        executor = MigrationExecutor(None)\n        executor.loader = FakeLoader(graph, {\n            a1: a1_impl,\n            b1: b1_impl,\n            a2: a2_impl,\n        })\n\n        plan = executor.migration_plan({a1})\n\n        self.assertEqual(plan, [(a2_impl, True), (b1_impl, True)])\n"], "sample_610": ["def test_infer_freq_mixed_types():\n    cf_indx = xr.cftime_range(\"2000-01-01\", periods=3, freq=\"D\")\n    pd_indx = pd.date_range(\"2000-01-01\", periods=3, freq=\"D\")\n    mixed_array = xr.DataArray(np.concatenate([cf_indx.asi8, pd_indx.asi8]))\n    assert xr.infer_freq(mixed_array) == \"D\"\n"], "sample_1082": ["compilation error"], "sample_107": ["    def test_cleanse_setting_nested_dict(self):\n        data = {'key1': 'value1', 'key2': {'sensitive_key': 'secret'}}\n        cleaned_data = cleanse_setting(data, 'sensitive_key')\n        self.assertEqual(cleaned_data['key1'], 'value1')\n        self.assertEqual(cleaned_data['key2'], {'sensitive_key': CLEANSED_SUBSTITUTE})\n"], "sample_279": ["    def test_opclasses_length(self):\n        msg = 'UniqueConstraint.fields and UniqueConstraint.opclasses must have the same number of elements.'\n        with self.assertRaisesMessage(ValueError, msg):\n            models.UniqueConstraint(\n                name='uniq_opclasses',\n                fields=['field1', 'field2'],\n                opclasses=['text_pattern_ops'],\n            )\n\n"], "sample_1186": ["def test_array_shape_mismatch():\n    for ArrayType in mutable_array_types:\n        a = ArrayType([[1, 2], [3, 4]])\n        b = ArrayType([[1, 2, 3], [4, 5, 6]])\n        raises(ValueError, lambda: a + b)\n        raises(ValueError, lambda: a - b)\n        raises(ValueError, lambda: a * b)\n        raises(ValueError, lambda: a / b)\n"], "sample_302": ["    def test_runshell_handles_sigint(self):\n        with mock.patch('django.db.backends.base.client.BaseDatabaseClient.runshell') as mock_runshell:\n            client = DatabaseClient(connection=connection)\n            client.runshell([])\n            mock_runshell.assert_called_once()\n"], "sample_495": ["    def test_paginator_with_custom_page_class(self):\n        class CustomPage(Page):\n                return f\"<Page {self.number} of {self.paginator.num_pages}>\"\n\n        paginator = Paginator(Article.objects.order_by('id'), 5, Page=CustomPage)\n        p = paginator.page(1)\n        self.assertEqual(\"<Page 1 of 2>\", str(p))\n"], "sample_612": ["    def test_resample_with_multiple_coords(self):\n        times = pd.date_range(\"2000-01-01\", freq=\"6H\", periods=10)\n        lat = np.arange(3)\n        lon = np.arange(4)\n        ds = Dataset(\n            {\n                \"data\": ([\"time\", \"lat\", \"lon\"], np.random.randn(10, 3, 4)),\n                \"time\": times,\n                \"lat\": lat,\n                \"lon\": lon,\n            }\n        )\n\n        resampled_ds = ds.resample(time=\"1D\").mean()\n        assert len(resampled_ds.coords) == 3\n        assert \"time\" in resampled_ds.coords\n        assert \"lat\" in resampled_ds.coords\n        assert \"lon\" in resampled_ds.coords\n"], "sample_1174": ["def test_issue_16375():\n    from sympy import Abs, re, im, Symbol\n    x = Symbol('x', real=True)\n    y = Symbol('y', imaginary=True)\n    assert Abs(x + I*y) == sqrt(x**2 + y**2)\n    assert re(x + I*y) == x\n    assert im(x + I*y) == y\n    assert Abs(x + I*y).subs(x, 1).subs(y, 2) == sqrt(5)\n    assert re(x + I*y).subs(x, 1).subs(y, 2) == 1\n    assert im(x + I*y).subs(x, 1).subs(y, 2) == 2\n"], "sample_1134": ["        def _print(self, expr):\n            pass\n"], "sample_0": ["def test_self_conversion_via_variance_not_supported(UncertClass):\n    uncert = np.arange(1, 11).reshape(2, 5) * u.adu\n    start_uncert = UncertClass(uncert)\n    with pytest.raises(IncompatibleUncertaintiesException):\n        start_uncert.represent_as(UncertClass)\n"], "sample_264": ["    def test_not_finished_sentinel(self):\n        storage = self.get_storage()\n        response = self.get_response()\n\n        # Add a few messages, then add the sentinel value.\n        storage.add(constants.INFO, 'message 1')\n        storage.add(constants.INFO, 'message 2')\n        storage.add(constants.INFO, 'message 3')\n        storage.add(constants.INFO, CookieStorage.not_finished)\n\n        # Update the cookie and check that the sentinel was removed.\n        storage.update(response)\n        messages = stored_cookie_messages_count(storage, response)\n        self.assertEqual(messages, 3)\n\n        # Now, add more messages, ensuring the sentinel is not added again.\n        storage.add(constants.INFO, 'message 4')\n        storage.add(constants.INFO, 'message 5')\n        storage.update(response)\n        messages = stored_cookie_messages_count(storage, response)\n        self.assertEqual(messages, 5)\n"], "sample_546": ["def test_toolmanager_add_tool():\n    with pytest.warns(UserWarning, match=_EXPECTED_WARNING_TOOLMANAGER):\n        plt.rcParams['toolbar'] = 'toolmanager'\n    fig = plt.gcf()\n    initial_len = len(fig.canvas.manager.toolmanager.tools)\n    tool_name = 'my_custom_tool'\n    class MyCustomTool(object):\n        pass\n    fig.canvas.manager.toolmanager.add_tool(tool_name, MyCustomTool())\n    assert len(fig.canvas.manager.toolmanager.tools) == initial_len + 1\n    assert fig.canvas.manager.toolmanager.get_tool(tool_name) is not None\n"], "sample_685": ["def test_log_file_level(testdir, caplog):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        import os\n\n            logging.basicConfig(filename='test.log', level=logging.INFO)\n            logging.info(\"This should be in the log file\")\n            assert \"This should be in the log file\" in caplog.text\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file = test.log\n        log_file_level = DEBUG\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*This should be in the log file*\"])\n    assert os.path.exists('test.log')\n    with open('test.log', 'r') as f:\n        assert f.read().strip() == \"This should be in the log file\"\n\n\n\n"], "sample_242": ["    def test_year_lookup_bounds(self):\n        class TestYearLookup(YearLookup):\n                return (start, finish)\n\n        lookup = TestYearLookup(Value(1), Value(2023))\n        connection = mock.Mock()\n        connection.features = mock.Mock(has_native_uuid_field=False)\n        lookup.connection = connection\n\n        self.assertEqual(lookup.year_lookup_bounds(connection, 2023), (20230101, 20231231))\n        self.assertEqual(lookup.year_lookup_bounds(connection, 2024), (20240101, 20241231))\n"], "sample_797": ["def test_power_transformer_sparse_matrix():\n    X = sparse.csc_matrix([[1, 2], [3, 4], [5, 6]])\n    for method in ['box-cox', 'yeo-johnson']:\n        pt = PowerTransformer(method=method)\n        X_trans = pt.fit_transform(X)\n        assert isinstance(X_trans, sparse.csc_matrix)\n        X_inv_trans = pt.inverse_transform(X_trans)\n        assert isinstance(X_inv_trans, sparse.csc_matrix)\n        assert_array_almost_equal(X.toarray(), X_inv_trans.toarray())\n\n\n\n"], "sample_76": ["    def test_language_settings_consistent(self):\n        with self.settings(\n            LANGUAGE_CODE='en',\n            LANGUAGES=[('en', 'English'), ('fr', 'French')],\n            LANGUAGES_BIDI=[\n                'en',\n                'fr',\n            ],\n        ):\n            self.assertEqual(check_language_settings_consistent(None), [])\n\n        with self.settings(\n            LANGUAGE_CODE='fr',\n            LANGUAGES=[('en', 'English'), ('fr', 'French')],\n            LANGUAGES_BIDI=[\n                'en',\n                'fr',\n            ],\n        ):\n            self.assertEqual(check_language_settings_consistent(None), [])\n\n        with self.settings(\n            LANGUAGE_CODE='es',\n            LANGUAGES=[('en', 'English'), ('fr', 'French')],\n            LANGUAGES_BIDI=[\n                'en',\n                'fr',\n            ],\n        ):\n            self.assertEqual(check_language_settings_consistent(None), [Error(\n                'You have provided a value for the LANGUAGE_CODE setting that is not in '\n                'the LANGUAGES setting.',\n                id='translation.E004',\n            )])\n"], "sample_552": ["compilation error"], "sample_758": ["        def __len__(self):\n            return 10\n"], "sample_519": ["def test_subplot_index_errors():\n    fig = plt.figure()\n\n    with pytest.raises(IndexError):\n        fig.add_subplot(1, 1, 2)\n\n    with pytest.raises(IndexError):\n        fig.add_subplot(2, 1, 3)\n\n    with pytest.raises(IndexError):\n        fig.add_subplot(2, 2, 5)\n\n    with pytest.raises(IndexError):\n        fig.add_subplot(0, 1, 1)\n\n    with pytest.raises(IndexError):\n        fig.add_subplot(1, 0, 1)\n"], "sample_598": ["    def test_summarize_attr_with_unicode(self):\n        attrs_a = {\"key\": \"This is a string with \u00fcnic\u00f6de characters.\"}\n        attrs_b = {\"key\": \"This is a different string.\"}\n        expected = dedent(\n            \"\"\"\\\n            key: This is a string with \u00fcnic\u00f6de characters.\"\"\"\n        ).strip()\n        actual = formatting.summarize_attr(\"key\", attrs_a)\n        assert actual == expected\n\n        expected = dedent(\n            \"\"\"\\\n            key: This is a different string.\"\"\"\n        ).strip()\n        actual = formatting.summarize_attr(\"key\", attrs_b)\n        assert actual == expected\n"], "sample_103": ["    def test_subquery_annotation_with_distinct(self):\n        distinct_authors_qs = Author.objects.filter(\n            book__publisher=OuterRef('pk')\n        ).values('name').annotate(count=Count('id')).values('name', 'count')\n        publisher_qs = Publisher.objects.annotate(\n            distinct_authors=Subquery(distinct_authors_qs, IntegerField()),\n        ).annotate(total=Count('book'))\n        self.assertEqual(dict(publisher_qs), {\n            1: {'distinct_authors': 2, 'total': 3},\n            3: {'distinct_authors': 1, 'total': 1},\n            7: {'distinct_authors': 1, 'total': 1},\n            9: {'distinct_authors': 1, 'total': 1},\n        })\n"], "sample_361": ["    def test_urlize_trim_url_limit(self):\n        self.assertEqual(urlize('This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit-of-20-characters', trim_url_limit=20),\n                         'This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit-of-20-characters...')\n        self.assertEqual(urlize('This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit-of-20-characters', trim_url_limit=30),\n                         'This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit-of-20-characters')\n\n\n\n"], "sample_490": ["    def test_expressions_with_include(self):\n        msg = \"UniqueConstraint.include cannot be used with expressions.\"\n        with self.assertRaisesMessage(ValueError, msg):\n            models.UniqueConstraint(\n                Lower(\"field\"),\n                name=\"test_func_include\",\n                include=[\"other_field\"],\n            )\n"], "sample_568": ["def test_surface3d_zsort_neg_inf():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n\n    x, y = np.mgrid[-2:2:0.1, -2:2:0.1]\n    z = np.sin(x)**2 + np.cos(y)**2\n    z[x.shape[0] // 2:, x.shape[1] // 2:] = -np.inf\n\n    ax.plot_surface(x, y, z, cmap='jet')\n    ax.view_init(elev=45, azim=145)\n"], "sample_930": ["def test_create_index_with_subentries(app):\n    text = (\".. index:: pair: docutils; reStructuredText\\n\"\n            \".. index:: pair: Python; interpreter\\n\"\n            \".. index:: pair: Sphinx; documentation tool\\n\"\n            \".. index:: pair: Sphinx; :+1:\\n\"\n            \".. index:: pair: Sphinx; subentry 1\\n\"\n            \".. index:: pair: Sphinx; subentry 2\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 7\n    assert index[0] == ('Symbols', [(':+1:', [[], [('Sphinx', [('', '#index-3')])], None])])\n    assert index[1] == ('D',\n                        [('documentation tool', [[], [('Sphinx', [('', '#index-2')])], None]),\n                         ('docutils', [[], [('reStructuredText', [('', '#index-0')])], None])])\n    assert index[2] == ('I', [('interpreter', [[], [('Python', [('', '#index-1')])], None])])\n    assert index[3] == ('P', [('Python', [[], [('interpreter', [('', '#index-1')])], None])])\n    assert index[4] == ('R', [('reStructuredText', [[], [('docutils', [('', '#index-0')])], None])])\n    assert index[5] == ('S',\n                        [('Sphinx', [[],\n                                     [(':+1:', [('', '#index-3')]),\n                                      ('documentation tool', [('', '#index-2')]),\n                                      ('subentry 1', [('', '#index-4')]),\n                                      ('subentry 2', [('', '#index-5')])],\n                                     None])])\n    assert index[6] == ('S', [('Sphinx', [[], [('subentry 1', [('', '#index-4')]),\n                                          ('subentry 2', [('', '#index-5')])], None])])\n\n\n\n"], "sample_309": ["    def test_parsing_invalid_date(self):\n        with self.assertRaises(ValueError):\n            parse_http_date('invalid date')\n"], "sample_1201": ["compilation error"], "sample_1085": ["def test_issue_11079():\n    assert Float('1.2345678901234567890123456789012345678901234567890').n(10) == '1.234567890'\n    assert Float('1.2345678901234567890123456789012345678901234567890').n(11) == '1.2345678901'\n    assert Float('1.2345678901234567890123456789012345678901234567890').n(12) == '1.23456789012'\n    assert Float('1.2345678901234567890123456789012345678901234567890').n(13) == '1.234567890123'\n    assert Float('1.2345678901234567890123456789012345678901234567890').n(14) == '1.2345678901234'\n    assert Float('1.2345678901234567890123456789012345678901234567890').n(15) == '1.23456789012345'\n    assert Float('1.23456789012345678901"], "sample_802": ["def test_pipeline_memory_with_fit_transform():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        if LooseVersion(joblib_version) < LooseVersion('0.12'):\n            # Deal with change of API in joblib\n            memory = Memory(cachedir=cachedir, verbose=10)\n        else:\n            memory = Memory(location=cachedir, verbose=10)\n        # Test with Transformer + SVC\n        clf = SVC(gamma='scale', probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', clone(transf)), ('svc', clf)])\n        cached_pipe = Pipeline([('transf', transf), ('svc', clf)],\n                               memory=memory)\n\n        # Memoize the transformer at the first fit_transform\n        cached_pipe.fit_transform(X, y)\n        pipe.fit_transform(X, y)\n        # Get the time stamp of the transformer in the cached pipeline\n        ts = cached_pipe.named_steps['transf'].timestamp_\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert not hasattr(transf, 'means_')\n        # Check that we are reading the cache while fitting\n        # a second time\n        cached_pipe.fit_transform(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal("], "sample_1202": ["def test_issue_10917():\n    assert Float(1).is_integer is True\n    assert Float(1.5).is_integer is False\n    assert Float(1.0).is_integer is True\n    assert Float(0).is_integer is True\n    assert Float(-1).is_integer is True\n"], "sample_866": ["def test_affinity_propagation_sparse_data():\n    # Test AffinityPropagation with sparse input data\n    X_sparse = csr_matrix(np.random.rand(100, 5))\n    af = AffinityPropagation(affinity='euclidean')\n    af.fit(X_sparse)\n    assert_array_equal(af.cluster_centers_.shape[0],\n                       af.cluster_centers_indices_.size)\n    assert_array_equal(af.labels_.shape[0], X_sparse.shape[0])\n"], "sample_253": ["    def test_snapshot_files_handles_new_files(self):\n        new_file = self.ensure_file(self.tempdir / 'new_file.py')\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file, new_file]):\n            snapshot1 = dict(self.reloader.snapshot_files())\n            self.assertIn(self.existing_file, snapshot1)\n            self.assertIn(new_file, snapshot1)\n"], "sample_63": ["    def test_template_loaders_with_app_dirs(self):\n        engine = Engine(dirs=[TEMPLATE_DIR], app_dirs=True)\n        template = engine.get_template('app_templates/foo.html')\n        self.assertEqual(template.render(Context()), 'app_templates\\n')\n"], "sample_886": ["def test_set_output_index():\n    \"\"\"Check that set_output with index works.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    est = EstimatorWithSetOutputIndex().fit(X)\n\n    est.set_output(transform=\"pandas\")\n\n    X_trans_pd = est.transform(X)\n    assert isinstance(X_trans_pd, pd.DataFrame)\n    assert_array_equal(X_trans_pd.index, [f\"s{i}\" for i in range(X.shape[0])])\n"], "sample_127": ["    def test_ignore_conflicts(self):\n        # Test that ignore_conflicts=True works as expected.\n        with self.assertNumQueries(1):\n            TwoFields.objects.bulk_create(self.data, ignore_conflicts=True)\n        self.assertEqual(TwoFields.objects.count(), len(self.data))\n        # Test that duplicate entries are not inserted.\n        with self.assertNumQueries(1):\n            TwoFields.objects.bulk_create(self.data, ignore_conflicts=True)\n        self.assertEqual(TwoFields.objects.count(), len(self.data))\n"], "sample_292": ["    def test_csrf_cookie_domain_with_subdomain(self):\n        \"\"\"\n        CSRF cookie domain with subdomain works correctly.\n        \"\"\"\n        req = self._get_GET_no_csrf_cookie_request()\n        with self.settings(CSRF_COOKIE_DOMAIN='.example.com'):\n            mw = CsrfViewMiddleware(token_view)\n            mw.process_view(req, token_view, (), {})\n            resp = mw(req)\n            csrf_cookie = resp.cookies.get(settings.CSRF_COOKIE_NAME, False)\n            self.assertEqual(csrf_cookie.domain, '.example.com')\n\n"], "sample_310": ["    def test_field_descriptions_with_placeholders(self):\n        class PlaceholderField(models.Field):\n            description = \"A field with placeholders: %(value)s\"\n\n        field = PlaceholderField()\n        self.assertEqual(views.get_readable_field_data_type(field), 'A field with placeholders: %(value)s')\n\n\n\n"], "sample_627": ["compilation error"], "sample_670": ["def test_parentheses_nesting(expr: str, expected: bool) -> None:\n    matcher = {\"true\": True, \"false\": False}.__getitem__\n    assert evaluate(expr, matcher) is expected\n"], "sample_389": ["    def test_prefixed(self):\n        # Add SCRIPT_NAME prefix to relative paths.\n        tests = (\n            \"path/\",\n            \"path\",\n        )\n        for setting in (\"MEDIA_URL\", \"STATIC_URL\"):\n            for path in tests:\n                new_settings = {setting: path}\n                with self.settings(**new_settings):\n                    for script_name in [\"/somesubpath\", \"/somesubpath/\", \"/\", \"\", None]:\n                        with self.subTest(script_name=script_name, **new_settings):\n                            try:\n                                self.set_script_name(script_name)\n                                expected_url = script_name + path\n                                self.assertEqual(getattr(settings, setting), expected_url)\n                            finally:\n                                clear_script_prefix()\n"], "sample_1165": ["def test_quaternion_integration():\n    q = Quaternion(1, 2, 3, 4)\n    assert integrate(q, x) == Quaternion(x, 2*x, 3*x, 4*x)\n    assert integrate(q, (x, 0, 1)) == Quaternion(1, 2, 3, 4)\n"], "sample_571": ["    def test_lmplot_ci_kwargs(self):\n\n        g = lm.lmplot(x=\"x\", y=\"y\", data=self.df, ci=95)\n        ax = g.axes[0, 0]\n        npt.assert_array_equal(ax.lines[1].get_ydata(),\n                               ax.lines[0].get_ydata() + ax.lines[1].get_yerr())\n        npt.assert_array_equal(ax.lines[0].get_ydata(),\n                               ax.lines[1].get_ydata() - ax.lines[1].get_yerr())\n\n        g = lm.lmplot(x=\"x\", y=\"y\", data=self.df, ci=99)\n        ax = g.axes[0, 0]\n        npt.assert_array_equal(ax.lines[1].get_ydata(),\n                               ax.lines[0].get_ydata() + ax.lines[1].get_yerr())\n        npt.assert_array_equal(ax.lines[0].get_ydata(),\n                               ax.lines[1].get_ydata() - ax.lines[1].get_yerr())\n\n        g = lm.lmplot(x=\"x\", y=\"y\", data=self.df, ci=None)\n        ax = g.axes[0, 0]\n        assert len(ax.lines) == 1\n"], "sample_651": ["    def test_re_emit_match_multiple_with_context_manager(self) -> None:\n        with pytest.warns(UserWarning, match=\"user warning\"):\n            with pytest.warns(UserWarning, match=\"user warning\"):\n                warnings.warn(\"first user warning\", UserWarning)\n                warnings.warn(\"second user warning\", UserWarning)\n"], "sample_1062": ["compilation error"], "sample_405": ["    def test_references_field_by_through_reverse(self):\n        operation = FieldOperation(\n            \"Model\", \"field\", models.ManyToManyField(\"Other\", through=\"Through\")\n        )\n        self.assertIs(\n            operation.references_field(\"Through\", \"reverse_field\", \"migrations\"), True\n        )\n        self.assertIs(\n            operation.references_field(\"Missing\", \"reverse_field\", \"migrations\"), False\n        )\n"], "sample_333": ["    def test_renderer_override_in_form_instance(self):\n        custom = CustomRenderer()\n        form = Form(renderer=DjangoTemplates())\n        form.renderer = custom\n        self.assertEqual(form.renderer, custom)\n"], "sample_944": ["def test_stringify_type_hints_GenericMeta():\n    from typing import GenericMeta  # type: ignore\n\n    class MyGenericMeta(GenericMeta):\n        pass\n\n    class MyGeneric(metaclass=MyGenericMeta, ):\n        T = TypeVar('T')\n\n            self.value = value\n\n    assert stringify(MyGeneric) == \"tests.test_util_typing.MyGeneric\"\n    assert stringify(MyGeneric[int]) == \"tests.test_util_typing.MyGeneric[int]\"\n"], "sample_123": ["    def test_parsing_invalid_date(self):\n        with self.assertRaises(ValueError):\n            parse_http_date('invalid date')\n"], "sample_440": ["    def test_update_conflicts_unique_fields_multiple(self):\n        self._test_update_conflicts(unique_fields=[\"number\", \"rank\"])\n"], "sample_557": ["def test_savefig_metadata_empty_string():\n    with pytest.raises(ValueError, match=\"metadata must be a dictionary\"):\n        Figure().savefig(io.BytesIO(), format='png', metadata='')\n"], "sample_218": ["    def test_trunc_func_with_timezone_and_output_field(self):\n        start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n        end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n        start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n        end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n        self.create_model(start_datetime, end_datetime)\n        melb = pytz.timezone('Australia/Melbourne')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated_date=TruncDate('start_datetime', output_field=DateField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, start_datetime.date()),\n                (end_datetime, end_datetime.date()),\n            ],\n            lambda m: (m.start_datetime, m.truncated_date)\n        )\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated_time=TruncTime('start_datetime', output_field=TimeField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, start_datetime.time()),\n                (end_datetime, end_datetime.time()),\n            ],\n            lambda m: (m.start_datetime, m.truncated_time)\n        )\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated_year=TruncYear('start_datetime', output_field=IntegerField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, start_datetime.year),\n                (end_datetime, end_datetime.year),\n            ],\n            lambda m: (m.start_datetime, m.truncated_year)\n        )\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n"], "sample_1015": ["compilation error"], "sample_192": ["    def test_invalid(self):\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '0',\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': 'invalid',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '1',\n        }\n        ChoiceFormSet = formset_factory(Choice)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [{'votes': ['Enter a valid number.']}, {}]\n        self.assertEqual(formset1._errors, expected_errors)\n        self.assertEqual(formset2._errors, expected_errors)\n"], "sample_410": ["    def test_group_permissions(self):\n        group = Group.objects.create(name=\"test_group\")\n        permission = Permission.objects.create(\n            name=\"test_permission\",\n            content_type=ContentType.objects.get_for_model(Group),\n            codename=\"test_codename\",\n        )\n        group.permissions.add(permission)\n        self.assertIn(permission, group.permissions.all())\n        self.assertEqual(group.permissions.count(), 1)\n"], "sample_517": ["def test_text_bbox_with_transform():\n    fig, ax = plt.subplots()\n    text = ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    bbox = text.get_window_extent(renderer=fig.canvas.get_renderer())\n    assert bbox.width > 0 and bbox.height > 0\n"], "sample_368": ["    def test_minimize_rollbacks_circular(self):\n        \"\"\"\n        Minimize rollbacks when there are circular dependencies.\n        \"\"\"\n        a1_impl = FakeMigration('a1')\n        a1 = ('a', '1')\n        a2_impl = FakeMigration('a2')\n        a2 = ('a', '2')\n        b1_impl = FakeMigration('b1')\n        b1 = ('b', '1')\n        graph = MigrationGraph()\n        graph.add_node(a1, a1_impl)\n        graph.add_node(a2, a2_impl)\n        graph.add_node(b1, b1_impl)\n        graph.add_dependency(None, b1, a1)\n        graph.add_dependency(None, a2, b1)\n        executor = MigrationExecutor(None)\n        executor.loader = FakeLoader(graph, {})\n\n        plan = executor.migration_plan({a1})\n\n        self.assertEqual(plan, [(a2_impl, True)])\n"], "sample_387": ["    def test_clear_button(self):\n        from selenium.webdriver.common.by import By\n\n        self.admin_login(username=\"super\", password=\"secret\", login_url=\"/\")\n        self.selenium.get(\n            self.live_server_url + reverse(\"admin:admin_widgets_event_add\")\n        )\n        main_window = self.selenium.current_window_handle\n\n        # Select a band\n        self.selenium.find_element(By.ID, \"lookup_id_main_band\").click()\n        self.wait_for_and_switch_to_popup()\n        link = self.selenium.find_element(By.LINK_TEXT, \"Bogey Blues\")\n        self.assertIn(\"/band/42/\", link.get_attribute(\"href\"))\n        link.click()\n\n        # The field now contains the selected band's id\n        self.selenium.switch_to.window(main_window)\n        self.wait_for_value(\"#id_main_band\", \"42\")\n\n        # Click the clear button\n        self.selenium.find_element(By.ID, \"clear_id_main_band\").click()\n\n        # The field is now empty\n        self.assertEqual(\n            self.selenium.find_element(By.ID, \"id_main_band\").get_attribute(\"value\"), \"\"\n        )\n\n"], "sample_960": ["def test_python_python_use_unqualified_type_names_enabled(app, status, warning):\n    app.build()\n    content = (app.outdir / 'index.html').read_text()\n    assert ('<span class=\"n\"><a class=\"reference internal\" href=\"#foo.Name\" title=\"foo.Name\">'\n            '<span class=\"pre\">Name</span></a></span>' in content)\n    assert '<span class=\"n\"><span class=\"pre\">foo.Age</span></span>' in content\n    assert ('<p><strong>name</strong> (<a class=\"reference internal\" href=\"#foo.Name\" '\n            'title=\"foo.Name\"><em>Name</em></a>) \u2013 blah blah</p>' in content)\n    assert '<p><strong>age</strong> (<em>foo.Age</em>) \u2013 blah blah</p>' in content\n"], "sample_237": ["    def test_permission_codename_uniqueness(self):\n        class Checked(models.Model):\n            class Meta:\n                permissions = [\n                    ('my_permission', 'Can do something'),\n                    ('my_permission', 'Can do something else'),\n                ]\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The permission codenamed 'my_permission' is duplicated for \"\n                \"model 'auth_tests.Checked'.\",\n                obj=Checked,\n                id='auth.E006',\n            ),\n        ])\n"], "sample_491": ["    def test_form_field_help_text(self):\n        class UserRegistration(Form):\n            username = CharField(max_length=10, help_text=\"Good luck picking a username that doesn't already exist.\")\n            password1 = CharField(widget=PasswordInput)\n            password2 = CharField(widget=PasswordInput)\n\n        f = UserRegistration(auto_id=False)\n        self.assertHTMLEqual(\n            f[\"username\"].render(),\n            '<label for=\"id_username\">Username:</label><p>Good luck picking a username that doesn&#x27;t already exist.</p>'\n            '<input type=\"text\" name=\"username\" maxlength=\"10\" required id=\"id_username\">',\n        )\n"], "sample_433": ["    def test_operation_with_custom_name(self):\n        class Migration(migrations.Migration):\n            operations = [\n                migrations.CreateModel(\n                    \"Person\", fields=[], name=\"my_person_model\"\n                ),\n            ]\n\n        migration = Migration(\"some_migration\", \"test_app\")\n        self.assertEqual(migration.suggest_name(), \"my_person_model\")\n"], "sample_130": ["    def test_complex_join_promotion(self):\n        query = Query(Item)\n        query.add_filter(Q(creator__num__gt=2) | Q(creator__name__icontains='John'))\n        query.add_filter(Q(modified__gt=F('created')))\n        query.add_select_related(['creator'])\n        query.promote_joins(set())\n        query.demote_joins(set())\n        self.assertEqual(query.alias_map, {'item': BaseTable('django_item', 'item')})\n        self.assertEqual(query.alias_refcount, {'item': 1})\n        self.assertEqual(query.join_info, [])\n"], "sample_117": ["    def test_password_too_short(self):\n        user = User.objects.get(username='testclient')\n        data = {'password1': 'too short', 'password2': 'too short'}\n        form = AdminPasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertIn('This password is too short. It must contain at least 8 characters.', form.errors['password1'])\n        self.assertIn('This password is too short. It must contain at least 8 characters.', form.errors['password2'])\n"], "sample_222": ["    def test_spooled_temp_file_seek(self):\n        with tempfile.SpooledTemporaryFile(max_size=1024) as temp:\n            temp.write(b\"foo bar baz quux\\n\")\n            temp.seek(0)\n            self.assertEqual(temp.read(), b\"foo bar baz quux\\n\")\n            temp.seek(6)\n            self.assertEqual(temp.read(), b\" bar baz quux\\n\")\n            temp.seek(-6, 2)\n            self.assertEqual(temp.read(), b\"quux\\n\")\n"], "sample_20": ["def test_masked_table_serialize_mask_with_no_data_mask(tmp_path):\n    filename = tmp_path / \"test.fits\"\n\n    t = simple_table(masked=True)  # int, float, and str cols with one masked element\n\n    t.write(filename, serialize_method=\"data_mask\")\n\n    t2 = Table.read(filename)\n    assert t2.masked is False\n    assert t2.colnames == t.colnames\n    for name in t2.colnames:\n        assert np.all(t2[name].mask == t[name].mask)\n        assert np.all(t2[name] == t[name])\n\n        # Data under the mask round-trips also (unmask data to show this).\n        t[name].mask = False\n        t2[name].mask = False\n        assert np.all(t2[name] == t[name])\n"], "sample_577": ["    def test_legend_handles_empty_series(self, xy):\n\n        s = pd.Series(dtype=\"object\")\n        p = Plot(**xy, color=s).add(MockMark()).plot()\n        legend, = p._figure.legends\n        assert legend.get_texts() == []\n"], "sample_849": ["def test_time_series_cv_with_nan():\n    X = np.array([[1, 2, np.nan], [4, 5, 6], [7, 8, 9], [10, 11, 12],\n                  [13, 14, np.nan]])\n    tscv = TimeSeriesSplit(2)\n    splits = tscv.split(X)\n    for train, test in splits:\n        assert np.isnan(np.sum(X[test])) == False\n"], "sample_1193": ["def test_are_coplanar():\n    p1 = Point2D(0, 0)\n    p2 = Point2D(1, 0)\n    p3 = Point2D(0, 1)\n    p4 = Point2D(1, 1)\n    p5 = Point2D(2, 0)\n    p6 = Point2D(0, 2)\n    p7 = Point2D(1, 2)\n\n    assert are_coplanar(p1, p2, p3)\n    assert are_coplanar(p2, p3, p4)\n    assert are_coplanar(p1, p2, p4)\n    assert not are_coplanar(p1, p2, p5)\n    assert not are_coplanar(p1, p2, p6)\n    assert not are_coplanar(p1, p2, p7)\n    assert are_coplanar(p1, p3, p4)\n    assert are_coplanar(p2, p3, p6)\n    assert are_coplanar(p2, p4, p7)\n    assert not are_coplanar(p1, p5, p6)\n    assert not are_coplanar(p1, p5, p7)\n    assert not are_coplanar(p1, p6, p7)\n    assert are_coplanar(p2, p3, p5)\n    assert are_coplanar(p2, p4, p6)\n    assert are_coplanar(p3, p4, p7)\n\n\n\n"], "sample_17": ["    def test_all_wrapped_are_in_helpers(self):\n        assert all_wrapped.issubset(\n            SUBCLASS_SAFE_FUNCTIONS\n            | UNSUPPORTED_FUNCTIONS\n            | set(FUNCTION_HELPERS.keys())\n            | set(DISPATCHED_FUNCTIONS.keys())\n        )\n"], "sample_562": ["def test_line_styles_with_markers():\n    fig, ax = plt.subplots()\n    markers = ['o', 's', '^', 'D', 'v', 'p', '*', '+', 'x', 'h', 'H', '8', 'd', 'p']\n    for i, marker in enumerate(markers):\n        ax.plot(np.linspace(0, 1, 10), marker=marker, linestyle='-', color=f'C{i}')\n"], "sample_991": ["def test_issue_14124():\n    x = Symbol('x')\n    p = Product(x**k, (k, 0, oo))\n    assert p.doit() == oo\n    assert p.is_convergent() is S.false\n"], "sample_1006": ["def test_binomial_special_cases():\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True)\n    \n    assert binomial(n, 0) == 1\n    assert binomial(n, n) == 1\n    assert binomial(n, k) == binomial(n, n - k)\n    assert binomial(n, k).is_positive is True\n    assert binomial(n, k).is_integer is True\n    assert binomial(n, k).is_real is True\n    assert binomial(n, k).is_nonnegative is True\n    assert binomial(n, -k) == 0\n    assert binomial(n, k).rewrite(gamma) == gamma(n + 1)/(gamma(k + 1)*gamma(n - k + 1))\n    assert binomial(n, k).rewrite(factorial) == factorial(n)/(factorial(k)*factorial(n - k))\n    assert binomial(n, k).rewrite(Product) == 'Product(_i, (_i, 0, k))'\n    assert binomial(n, k).rewrite(rf) == rf(n - k, k) / factorial(k)\n    assert binomial(n, k).rewrite(ff) == ff(n, k) / factorial(k)\n    assert binomial(n, k).is_commutative is True\n    assert binomial(n, k).is_associative is True\n    assert binomial(n, k).is_distributive is True\n    assert binomial(n, k).is_identity is False\n    assert binomial(n, k).is_inverse is False\n    assert binomial(n, k).is_nonzero is True\n    assert binomial(n, k).is_odd is False\n    assert binomial(n, k).is_even is False\n    assert binomial(n, k).is_positive is True\n    assert binomial(n, k).is_negative is False\n    assert binomial(n, k).is_real is True\n    assert binomial(n, k).is_complex is False\n    assert binomial(n, k).is_rational is True\n    assert binomial(n, k).is_integer is True\n    assert binomial(n, k).is_algebraic is True\n    "], "sample_884": ["def test_deprecated_property():\n    with pytest.warns(FutureWarning, match=\"n_features_ is deprecated\"):\n        mock_instance = MockClass2()\n        val = mock_instance.n_features_\n    assert val == 10\n"], "sample_652": ["compilation error"], "sample_711": ["def test_node_repr_failure_with_fixture_lookup_error(pytester: Pytester) -> None:\n    pytester.write(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            raise pytest.PytestLookupError(\"fixture not found\")\n\n            pass\n    \"\"\",\n        \"test_fixture_lookup.py\",\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*= test_fixture_lookup.py::test_my_test*\",\n            \"*fixture not found*\",\n        ]\n    )\n"], "sample_755": ["def test_davies_bouldin_score():\n    assert_raises_on_only_one_label(davies_bouldin_score)\n\n    assert_raises_on_all_points_same_cluster(davies_bouldin_score)\n\n    # Assert the value is 0. when all samples are equals\n    assert 0. == davies_bouldin_score(np.ones((10, 2)),\n                                     [0] * 10)\n\n    # General case\n    X = ([[0, 0], [1, 1]] * 5 + [[3, 3], [4, 4]] * 5 +\n         [[0, 4], [1, 3]] * 5 + [[3, 1], [4, 0]] * 5)\n    labels = [0] * 10 + [1] * 10 + [2] * 10 + [3] * 10\n    pytest.approx(davies_bouldin_score(X, labels), 0.8)\n"], "sample_118": ["    def test_nested_outerref_rhs(self):\n        tag = Tag.objects.create(name=self.au1.alias)\n        tag.articles.add(self.a1)\n        qs = Article.objects.annotate(\n            has_matching_tag=Exists(\n                Tag.objects.filter(name=OuterRef('author__alias'))\n            ),\n        )\n        self.assertEqual(qs.get(has_matching_tag=True), self.a1)\n"], "sample_1192": ["def test_disambiguate():\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z')\n    a = Symbol('a')\n    b = Symbol('b')\n    c = Symbol('c')\n    d = Symbol('d')\n\n    assert disambiguate(x, y, z) == (x, y, z)\n    assert disambiguate(x, x) == (x, x)\n    assert disambiguate(x, y, x) == (x_2, y, x_1)\n    assert disambiguate(x, y, z, a, b, c, d) == (x_2, y, z_1, a_1, b_1, c_1, d_1)\n    assert disambiguate(x, y, z, x, y, z) == (x_2, y, z_1, x_3, y_1, z_2)\n    assert disambiguate(x, y, z, x, y, z, x, y, z) == (x_2, y, z_1, x_3, y_1, z_2, x_4, y_2, z_3)\n    assert disambiguate(x, y, z, x, y, z, x, y, z, x, y, z) == (x_2, y, z_1, x_3, y_1, z_2, x_4, y_2, z_3, x_5, y_3, z_4)\n    assert disambiguate(x, y, z, x, y, z, x, y, z, x, y, z, x, y, z) == (x_2, y, z_1, x_3, y_1, z_2, x_4, y_2, z_3, x_5, y_3, z_4, x_6, y_4, z_5)\n    assert disambiguate(x, y, z, x, y, z, x, y, z, x, y, z, x, y, z, x, y, z) == (x_2, y, z_1, x_3, y_1,"], "sample_453": ["    def test_override_change_list_template_tags_with_custom_context(self):\n        request = self.request_factory.get(\n            reverse(\"admin:admin_views_article_changelist\")\n        )\n        request.user = self.superuser\n        admin = ArticleAdmin(Article, site)\n        admin.date_hierarchy = \"date\"\n        extra_context = {\"custom_context\": \"override\"}\n        response = admin.changelist_view(request, extra_context=extra_context)\n        response.render()\n        self.assertContains(response, \"override-change_list_object_tools\")\n        self.assertContains(response, \"override-change_list_results\")\n        self.assertContains(response, \"custom_context\")\n"], "sample_843": ["def test_kernel_is_stationary(kernel):\n    # Test stationarity of kernels.\n    if kernel.is_stationary():\n        K = kernel(X, X + 1)\n        assert_array_almost_equal(K, K[np.newaxis, :])\n    else:\n        K = kernel(X, X + 1)\n        assert_array_almost_equal(K, K[np.newaxis, :])\n"], "sample_207": ["    def test_key_transform_with_nested_lookup(self):\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(\n                value__d__1__f=KeyTransform('g', KeyTransform('0', 'value')),\n            ),\n            [self.objs[4]],\n        )\n"], "sample_224": ["    def test_aggregation_subquery_annotation_with_distinct(self):\n        \"\"\"\n        Subquery annotations with DISTINCT are included in the GROUP BY.\n        \"\"\"\n        distinct_authors_qs = Author.objects.filter(\n            pk=OuterRef('pk'),\n            book__name=OuterRef('book__name'),\n        ).values('pk').distinct()\n        author_qs = Author.objects.annotate(\n            distinct_author_id=Subquery(distinct_authors_qs),\n        ).annotate(count=Count('book'))\n        self.assertEqual(author_qs.count(), Author.objects.count())\n"], "sample_527": ["def test_toolmanager_add_tool():\n    with pytest.warns(UserWarning, match=_EXPECTED_WARNING_TOOLMANAGER):\n        plt.rcParams['toolbar'] = 'toolmanager'\n    fig = plt.gcf()\n    initial_len = len(fig.canvas.manager.toolmanager.tools)\n    tool_name = 'my_tool'\n    class MyTool:\n            pass\n            pass\n            pass\n    tool = MyTool(fig.canvas)\n    fig.canvas.manager.toolmanager.add_tool(tool_name, tool)\n    assert len(fig.canvas.manager.toolmanager.tools) == initial_len + 1\n    assert fig.canvas.manager.toolmanager.get_tool(tool_name) is tool\n    with pytest.warns(UserWarning,\n                      match=\"ToolManager already controls tool 'my_tool'\"):\n        fig.canvas.manager.toolmanager.add_tool(tool_name, tool)\n"], "sample_1036": ["def test_matmul_commutative_symbols():\n    a, b = symbols('a b', commutative=True)\n    assert MatMul(a, b, A, A.T).doit() == MatMul(b, a, A, A.T).doit()\n    assert MatMul(a, A, b, A.T).doit() == MatMul(b, A, a, A.T).doit()\n"], "sample_822": ["def test_check_sparse_matrices_with_different_shapes():\n    # Ensure an error is raised if the sparse matrices have different shapes.\n    XA = csr_matrix((np.ones(10), (2, 3)), shape=(5, 2))\n    XB = csr_matrix((np.ones(12), (3, 4)), shape=(4, 3))\n    assert_raises(ValueError, check_pairwise_arrays, XA, XB)\n"], "sample_80": ["    def test_related_isnull(self):\n        query = Query(Author)\n        where = query.build_where(Q(related_author__isnull=True))\n        lookup = where.children[0]\n        self.assertIsInstance(lookup, RelatedIsNull)\n        self.assertEqual(lookup.lhs.target, Author._meta.get_field('related_author'))\n\n\n\n"], "sample_1124": ["def test_FracElement_compose():\n    F, x,y,z = field(\"x,y,z\", ZZ)\n    f = (x**2 + 3*y)/z\n    g = lambda x: x**2\n\n    raises(NotImplementedError, lambda: f.compose(g))\n"], "sample_676": ["    def test_line_with_reprcrash_longrepr(monkeypatch):\n        import _pytest.terminal\n        from wcwidth import wcswidth\n\n        mocked_verbose_word = \"FAILED\"\n\n        mocked_pos = \"some::nodeid\"\n\n            return mocked_pos\n\n        monkeypatch.setattr(_pytest.terminal, \"_get_pos\", mock_get_pos)\n\n        class config(object):\n            pass\n\n        class rep(object):\n                return mocked_verbose_word\n                return \"<html><h1>crash</h1></html>\"\n\n        result = _line_with_reprcrash(config(), rep(), \"some::nodeid\", \"crash\", 10)\n        assert result == \"<html><h1>crash</h1></html>\"\n"], "sample_1118": ["def test_matpow_properties():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    \n    assert MatPow(A, 2).base == A\n    assert MatPow(A, 2).exp == 2\n    assert MatPow(A, 2).shape == (2, 2)\n    \n    assert MatPow(A, 0).doit() == Identity(2)\n    assert MatPow(A, -1).doit() == Inverse(A)\n    assert MatPow(A, 1).doit() == A\n    \n    assert MatPow(A*B, 2).doit() == MatPow(A, 2)*MatPow(B, 2)\n    assert MatPow(A*B, 3).doit() == MatPow(A, 3)*MatPow(B, 3)\n    \n    assert MatPow(A, 2).transpose() == MatPow(A.T, 2)\n"], "sample_1009": ["compilation error"], "sample_910": ["def test_prefixed_warnings(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    with prefixed_warnings(\"prefix:\"):\n        logger.warning('message1')\n        logger.warning('message2')\n\n    assert 'prefix: WARNING: message1' in warning.getvalue()\n    assert 'prefix: WARNING: message2' in warning.getvalue()\n"], "sample_551": ["def test_poly3d_legend():\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    verts = [[(0, 0, 0), (1, 0, 0), (1, 1, 0), (0, 1, 0)],\n             [(0, 0, 1), (1, 0, 1), (1, 1, 1), (0, 1, 1)]]\n    colors = ['red', 'green']\n    poly3d = Poly3DCollection(verts, facecolors=colors)\n    ax.add_collection3d(poly3d)\n    ax.legend()\n"], "sample_1142": ["def test_matrix_element_subs():\n    A = MatrixSymbol('A', 3, 3)\n    B = MatrixSymbol('B', 3, 3)\n    C = MatrixSymbol('C', 3, 3)\n    D = MatrixSymbol('D', 3, 3)\n\n    assert A[0, 0].subs({A: B}) == B[0, 0]\n    assert A[0, 0].subs({A: C}) == C[0, 0]\n    assert A[0, 0].subs({A: B, B: D}) == D[0, 0]\n    assert A[0, 0].subs({A: B, C: D}) == A[0, 0]  # C is not substituted\n\n    # Test with more complex expressions\n    expr = A[0, 0] + A[1, 1]\n    assert expr.subs({A: B}) == B[0, 0] + B[1, 1]\n    assert expr.subs({A: C}) == C[0, 0] + C[1, 1]\n    assert expr.subs({A: B, B: D}) == D[0, 0] + D[1, 1]\n\n    # Test with non-substitutable expressions\n    raises(TypeError, lambda: A[0, 0].subs({A: 1}))\n    raises(TypeError, lambda: A[0, 0].subs({A: [1, 2, 3]}))\n"], "sample_163": ["    def test_user_change_password_with_custom_password_validation(self):\n        from django.contrib.auth.models import User\n        from django.contrib.auth.password_validation import validate_password\n        from django.core.exceptions import ValidationError\n\n        class CustomPasswordValidator(validate_password):\n                if \"password\" in password:\n                    raise ValidationError(\"Password cannot contain the word 'password'\")\n                return super().validate(password, user)\n\n        with patch(\n            \"django.contrib.auth.password_validation.validate_password\",\n            new=CustomPasswordValidator,\n        ):\n            response = self.client.post(\n                reverse(\"auth_test_admin:auth_user_password_change\", args=(self.admin.pk,)),\n                {\n                    \"password1\": \"password1\",\n                    \"password2\": \"password1\",\n                },\n            )\n            self.assertEqual(response.status_code, 400)\n            self.assertContains(response, \"Password cannot contain the word 'password'\")\n"], "sample_254": ["    def test_inline_formset_error_message(self):\n        self.admin_login(username='super', password='secret')\n        self.selenium.get(self.live_server_url + reverse('admin:admin_inlines_holder5_add'))\n        self.wait_until_visible('#id_dummy')\n        self.selenium.find_element_by_id('id_dummy').send_keys(1)\n        fields = ['id_inner5stacked_set-0-dummy', 'id_inner5tabular_set-0-dummy']\n        show_links = self.selenium.find_elements_by_link_text('SHOW')\n        for show_index, field_name in enumerate(fields):\n            show_links[show_index].click()\n            self.wait_until_visible('#' + field_name)\n            self.selenium.find_element_by_id(field_name).send_keys(1)\n\n        # Before save all inputs have default border\n        for inline in ('stacked', 'tabular'):\n            for field_name in ('name', 'select', 'text'):\n                element_id = 'id_inner5%s_set-0-%s' % (inline, field_name)\n                self.assertBorder(\n                    self.selenium.find_element_by_id(element_id),\n                    '1px solid #cccccc',\n                )\n        self.selenium.find_element_by_xpath('//input[@value=\"Save\"]').click()\n        # Test the red border around inputs by css selectors\n        stacked_selectors = ['.errors input', '.errors select', '.errors textarea']\n        for selector in stacked_selectors:\n            self.assertBorder(\n                self.selenium.find_element_by_css_selector(selector),\n                '1px solid #ba2121',\n            )\n        tabular_selectors = [\n            'td ul.errorlist + input', 'td ul.errorlist + select', 'td ul.errorlist + textarea'\n        ]\n        for selector in tabular_selectors:\n            self.assertBorder(\n                self.selenium.find_element_by_css_selector(selector),\n                '1px solid #ba2121"], "sample_880": ["def test_ovr_decision_function():\n    # Test with binary classifiers\n    predictions = np.array([[0, 1], [1, 0], [0, 1], [1, 0]])\n    confidences = np.array([[0.8, 0.2], [0.3, 0.7], [0.9, 0.1], [0.2, 0.8]])\n    n_classes = 2\n    votes = _ovr_decision_function(predictions, confidences, n_classes)\n    expected_votes = np.array([[0, 1], [1, 0], [0, 1], [1, 0]])\n    expected_confidences = np.array([[0.6, 0.4], [0.4, 0.6], [0.8, 0.2], [0.2, 0.8]])\n    assert_array_almost_equal(votes, expected_votes)\n    assert_array_almost_equal(expected_confidences, votes + expected_confidences)\n\n    # Test with multi-class classifiers\n    predictions = np.array([[0, 1, 2], [1, 0, 2], [2, 1, 0], [0, 2, 1]])\n    confidences = np.array(\n        [[[0.8, 0.2, 0.0], [0.3, 0.7, 0.0], [0.1, 0.2, 0.7]],\n         [[0.1, 0.2, 0.7], [0.8, 0.2, 0.0], [0.3, 0.7, 0.0]],\n         [[0.2, 0.0, 0.8], [0.1, 0.7, 0.2], [0.3, 0.2, 0.5]],\n         [[0.7, 0.2, 0.1], [0.2, 0.8, 0.0], [0.1, 0.3, 0.6]]]\n    )\n    n_classes = 3\n    votes ="], "sample_1106": ["def test_matmul_with_zero_matrix():\n    A = MatrixSymbol('A', 2, 2)\n    B = ZeroMatrix(2, 2)\n    assert MatMul(A, B).doit() == ZeroMatrix(2, 2)\n    assert MatMul(B, A).doit() == ZeroMatrix(2, 2)\n"], "sample_1077": ["def test_issue_17326():\n    assert ImageSet(Lambda(x, x**2), S.Complexes) == \\\n        ImageSet(Lambda(x, x**2), S.Reals)\n"], "sample_478": ["    def test_actions_invalid_type(self):\n        class BandAdmin(ModelAdmin):\n            actions = 10\n\n        self.assertIsInvalid(\n            BandAdmin,\n            Band,\n            \"The value of 'actions' must be a list or tuple.\",\n            id=\"admin.E128\",\n        )\n"], "sample_505": ["def test_date2num_with_tzinfo():\n    dt = datetime.datetime(2023, 10, 26, 10, 30, tzinfo=dateutil.tz.tzutc())\n    num = mdates.date2num(dt)\n    assert isinstance(num, float)\n    assert mdates.num2date(num, tz=dateutil.tz.tzutc()) == dt\n"], "sample_643": ["def test_colorize_ansi_with_color_mapping(linter: PyLinter) -> None:\n    output = StringIO()\n    reporter = ColorizedTextReporter(output=output)\n    linter.reporter = reporter\n    linter.config.msg_template = \"{msg_id}:{line:03d}: {msg}\"\n    linter.open()\n    linter.set_current_module(\"my_mod\")\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n    linter.add_message(\"line-too-long\", line=2, args=(3, 4))\n    out_lines = output.getvalue().split(\"\\n\")\n    assert out_lines[1] == \"C0301:001: Line too long (1/2)\"\n    assert out_lines[2] == \"line-too-long:002: Line too long (3/4)\"\n\n\n\n"], "sample_236": ["    def test_fast_delete_with_signals(self):\n        \"\"\"\n        Fast delete should still work correctly when deletion signals are connected.\n        \"\"\"\n        class SignalReceiver:\n                self.called = False\n\n                self.called = True\n\n        receiver = SignalReceiver()\n        models.signals.post_delete.connect(receiver, sender=Referrer)\n        origin = Origin.objects.create()\n        referer = Referrer.objects.create(origin=origin, unique_field=42)\n        referer.delete()\n        self.assertTrue(receiver.called)\n        self.assertFalse(Referrer.objects.filter(pk=referer.pk).exists())\n        models.signals.post_delete.disconnect(receiver, sender=Referrer)\n"], "sample_954": ["def test_productionlist(app, status, warning):\n    app.builder.build_all()\n    content = (app.outdir / 'python.1').read_text()\n    assert r'\\fBproduction1\\fB ::= \\fItoken1\\fP' in content\n    assert r'\\fBproduction2\\fB ::= \\fItoken2\\fP' in content\n"], "sample_395": ["    def test_get_template_directories_custom_loader(self):\n        self.assertSetEqual(\n            autoreload.get_template_directories(),\n            {\n                ROOT / \"templates\",\n                ROOT / \"templates_extra\",\n            },\n        )\n"], "sample_701": ["def test_argument_percent_default_is_deprecated(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        \"\"\"\n        import argparse\n\n        parser = argparse.ArgumentParser()\n        parser.add_argument('--arg', type=str, default=\"%default\")\n        args = parser.parse_args()\n        print(args.arg)\n        \"\"\"\n    )\n    result = pytester.runpytest(p)\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: pytest now uses argparse.*\",\n            \"*%(default)s*\",\n        ]\n    )\n"], "sample_1019": ["compilation error"]}, "raw_scored_generations": {"sample_0": [false], "sample_1": [false], "sample_3": [false], "sample_2": [false], "sample_4": [false], "sample_5": [false], "sample_6": [false], "sample_7": [true], "sample_8": [false], "sample_9": [false], "sample_10": [true], "sample_11": [false], "sample_12": [true], "sample_13": [false], "sample_14": [true], "sample_15": [true], "sample_16": [true], "sample_17": [true], "sample_18": [true], "sample_19": [false], "sample_20": [true], "sample_21": [false], "sample_22": [false], "sample_23": [false], "sample_24": [false], "sample_25": [true], "sample_26": [false], "sample_27": [false], "sample_28": [true], "sample_29": [false], "sample_30": [false], "sample_31": [false], "sample_32": [false], "sample_33": [false], "sample_34": [false], "sample_35": [false], "sample_36": [false], "sample_37": [false], "sample_38": [false], "sample_39": [false], "sample_40": [false], "sample_41": [false], "sample_42": [true], "sample_43": [false], "sample_44": [false], "sample_45": [false], "sample_46": [false], "sample_47": [false], "sample_48": [false], "sample_49": [true], "sample_50": [false], "sample_51": [false], "sample_52": [true], "sample_54": [false], "sample_53": [true], "sample_55": [false], "sample_58": [true], "sample_56": [false], "sample_57": [false], "sample_59": [false], "sample_60": [false], "sample_61": [true], "sample_62": [true], "sample_63": [false], "sample_64": [false], "sample_65": [true], "sample_67": [false], "sample_66": [true], "sample_68": [false], "sample_69": [true], "sample_70": [false], "sample_71": [false], "sample_72": [false], "sample_73": [false], "sample_75": [false], "sample_74": [false], "sample_76": [true], "sample_77": [false], "sample_78": [false], "sample_79": [false], "sample_80": [false], "sample_82": [false], "sample_81": [false], "sample_83": [false], "sample_85": [false], "sample_84": [true], "sample_86": [false], "sample_88": [false], "sample_87": [true], "sample_89": [true], "sample_90": [false], "sample_91": [false], "sample_92": [false], "sample_93": [false], "sample_94": [false], "sample_95": [false], "sample_98": [false], "sample_96": [false], "sample_99": [false], "sample_97": [false], "sample_100": [true], "sample_102": [true], "sample_101": [false], "sample_103": [false], "sample_104": [false], "sample_107": [false], "sample_106": [false], "sample_105": [false], "sample_108": [false], "sample_109": [true], "sample_111": [true], "sample_110": [true], "sample_112": [false], "sample_113": [false], "sample_114": [false], "sample_115": [false], "sample_116": [false], "sample_117": [false], "sample_118": [false], "sample_119": [false], "sample_120": [false], "sample_121": [false], "sample_122": [false], "sample_123": [true], "sample_124": [false], "sample_125": [false], "sample_126": [false], "sample_127": [false], "sample_128": [true], "sample_129": [true], "sample_130": [false], "sample_131": [true], "sample_132": [false], "sample_133": [true], "sample_135": [false], "sample_134": [false], "sample_136": [true], "sample_139": [true], "sample_137": [false], "sample_138": [false], "sample_140": [false], "sample_141": [true], "sample_142": [false], "sample_143": [false], "sample_144": [true], "sample_145": [false], "sample_146": [true], "sample_147": [true], "sample_148": [false], "sample_151": [false], "sample_149": [false], "sample_152": [false], "sample_150": [false], "sample_153": [false], "sample_154": [false], "sample_155": [false], "sample_156": [true], "sample_157": [false], "sample_158": [false], "sample_159": [true], "sample_160": [false], "sample_161": [true], "sample_162": [true], "sample_163": [false], "sample_164": [false], "sample_165": [true], "sample_166": [false], "sample_167": [false], "sample_168": [false], "sample_169": [false], "sample_171": [true], "sample_170": [false], "sample_172": [true], "sample_173": [false], "sample_174": [false], "sample_175": [false], "sample_176": [true], "sample_177": [false], "sample_178": [false], "sample_180": [false], "sample_179": [true], "sample_182": [true], "sample_181": [true], "sample_183": [false], "sample_184": [false], "sample_185": [true], "sample_186": [false], "sample_187": [false], "sample_188": [false], "sample_189": [false], "sample_190": [true], "sample_191": [true], "sample_192": [false], "sample_193": [false], "sample_194": [true], "sample_195": [false], "sample_196": [false], "sample_198": [true], "sample_197": [false], "sample_199": [true], "sample_200": [false], "sample_201": [false], "sample_202": [false], "sample_203": [false], "sample_204": [false], "sample_205": [false], "sample_206": [false], "sample_207": [false], "sample_208": [false], "sample_209": [false], "sample_210": [false], "sample_211": [false], "sample_213": [false], "sample_212": [false], "sample_214": [false], "sample_215": [false], "sample_216": [false], "sample_217": [true], "sample_218": [false], "sample_219": [false], "sample_220": [false], "sample_221": [true], "sample_222": [false], "sample_223": [false], "sample_224": [true], "sample_225": [false], "sample_226": [false], "sample_227": [false], "sample_228": [false], "sample_229": [false], "sample_230": [true], "sample_231": [false], "sample_232": [false], "sample_233": [true], "sample_234": [false], "sample_235": [false], "sample_236": [false], "sample_237": [true], "sample_238": [false], "sample_239": [true], "sample_240": [true], "sample_241": [false], "sample_242": [false], "sample_243": [false], "sample_244": [true], "sample_245": [true], "sample_246": [true], "sample_247": [false], "sample_248": [false], "sample_249": [false], "sample_250": [false], "sample_251": [false], "sample_252": [false], "sample_253": [true], "sample_254": [false], "sample_256": [false], "sample_255": [false], "sample_257": [false], "sample_258": [false], "sample_259": [false], "sample_260": [true], "sample_261": [false], "sample_262": [false], "sample_263": [false], "sample_264": [false], "sample_265": [false], "sample_266": [false], "sample_267": [false], "sample_268": [true], "sample_269": [true], "sample_270": [false], "sample_271": [true], "sample_272": [false], "sample_273": [true], "sample_274": [false], "sample_275": [false], "sample_276": [false], "sample_277": [false], "sample_278": [true], "sample_279": [true], "sample_280": [false], "sample_281": [true], "sample_282": [false], "sample_283": [true], "sample_284": [false], "sample_285": [true], "sample_286": [true], "sample_287": [false], "sample_288": [false], "sample_289": [false], "sample_290": [true], "sample_291": [false], "sample_292": [false], "sample_293": [false], "sample_294": [false], "sample_295": [false], "sample_296": [false], "sample_297": [true], "sample_298": [true], "sample_299": [true], "sample_300": [false], "sample_301": [true], "sample_302": [false], "sample_303": [false], "sample_304": [false], "sample_305": [false], "sample_306": [false], "sample_307": [false], "sample_308": [false], "sample_309": [true], "sample_310": [false], "sample_312": [false], "sample_311": [false], "sample_313": [false], "sample_314": [false], "sample_315": [true], "sample_316": [false], "sample_317": [false], "sample_318": [false], "sample_319": [false], "sample_320": [true], "sample_321": [false], "sample_322": [false], "sample_323": [false], "sample_324": [false], "sample_325": [true], "sample_326": [false], "sample_327": [false], "sample_328": [false], "sample_329": [false], "sample_330": [false], "sample_331": [false], "sample_332": [true], "sample_333": [true], "sample_334": [false], "sample_335": [false], "sample_336": [false], "sample_337": [false], "sample_338": [true], "sample_339": [false], "sample_340": [false], "sample_341": [true], "sample_342": [true], "sample_343": [false], "sample_344": [false], "sample_345": [true], "sample_346": [false], "sample_347": [true], "sample_348": [false], "sample_349": [true], "sample_350": [false], "sample_351": [false], "sample_352": [false], "sample_353": [false], "sample_354": [false], "sample_355": [false], "sample_356": [true], "sample_357": [true], "sample_358": [false], "sample_359": [true], "sample_360": [false], "sample_361": [false], "sample_362": [false], "sample_363": [true], "sample_364": [false], "sample_365": [false], "sample_366": [false], "sample_367": [false], "sample_368": [false], "sample_369": [false], "sample_370": [false], "sample_371": [false], "sample_372": [false], "sample_373": [false], "sample_374": [false], "sample_375": [false], "sample_376": [false], "sample_377": [false], "sample_378": [true], "sample_379": [true], "sample_380": [false], "sample_381": [false], "sample_382": [false], "sample_383": [true], "sample_384": [false], "sample_385": [false], "sample_386": [true], "sample_387": [true], "sample_388": [false], "sample_389": [false], "sample_390": [true], "sample_391": [true], "sample_392": [false], "sample_393": [true], "sample_394": [true], "sample_395": [false], "sample_396": [true], "sample_397": [false], "sample_398": [false], "sample_399": [false], "sample_400": [false], "sample_401": [false], "sample_402": [false], "sample_403": [true], "sample_404": [true], "sample_405": [true], "sample_406": [false], "sample_407": [false], "sample_408": [false], "sample_409": [false], "sample_410": [false], "sample_411": [false], "sample_412": [false], "sample_413": [true], "sample_414": [true], "sample_415": [false], "sample_416": [true], "sample_417": [false], "sample_418": [false], "sample_419": [false], "sample_420": [true], "sample_421": [false], "sample_422": [false], "sample_423": [false], "sample_424": [false], "sample_425": [false], "sample_426": [false], "sample_427": [false], "sample_428": [false], "sample_429": [false], "sample_430": [false], "sample_431": [false], "sample_432": [true], "sample_433": [false], "sample_434": [false], "sample_435": [false], "sample_436": [false], "sample_437": [false], "sample_438": [false], "sample_439": [false], "sample_440": [false], "sample_441": [false], "sample_442": [false], "sample_443": [false], "sample_444": [false], "sample_445": [false], "sample_446": [false], "sample_447": [false], "sample_448": [false], "sample_449": [false], "sample_450": [false], "sample_451": [false], "sample_453": [false], "sample_452": [true], "sample_454": [false], "sample_455": [false], "sample_456": [false], "sample_457": [false], "sample_458": [false], "sample_459": [true], "sample_460": [true], "sample_461": [true], "sample_462": [false], "sample_463": [false], "sample_464": [true], "sample_465": [false], "sample_466": [false], "sample_467": [false], "sample_469": [false], "sample_468": [false], "sample_470": [false], "sample_471": [false], "sample_472": [false], "sample_473": [true], "sample_474": [false], "sample_475": [false], "sample_476": [false], "sample_477": [false], "sample_478": [false], "sample_479": [false], "sample_480": [true], "sample_481": [false], "sample_482": [false], "sample_483": [false], "sample_484": [true], "sample_485": [false], "sample_486": [false], "sample_487": [false], "sample_488": [false], "sample_489": [false], "sample_490": [false], "sample_491": [false], "sample_492": [false], "sample_493": [false], "sample_494": [false], "sample_495": [false], "sample_496": [true], "sample_497": [true], "sample_498": [false], "sample_499": [true], "sample_500": [false], "sample_501": [true], "sample_502": [false], "sample_503": [false], "sample_504": [false], "sample_505": [true], "sample_506": [false], "sample_507": [false], "sample_508": [false], "sample_509": [true], "sample_510": [true], "sample_511": [false], "sample_512": [false], "sample_513": [true], "sample_514": [false], "sample_515": [false], "sample_516": [false], "sample_517": [true], "sample_518": [true], "sample_519": [false], "sample_520": [false], "sample_521": [false], "sample_522": [false], "sample_523": [true], "sample_524": [false], "sample_525": [false], "sample_526": [false], "sample_527": [false], "sample_528": [true], "sample_529": [false], "sample_530": [false], "sample_531": [false], "sample_532": [true], "sample_533": [false], "sample_534": [false], "sample_535": [false], "sample_536": [false], "sample_537": [true], "sample_538": [false], "sample_539": [false], "sample_540": [false], "sample_541": [false], "sample_542": [false], "sample_543": [false], "sample_544": [false], "sample_545": [false], "sample_546": [false], "sample_547": [false], "sample_548": [false], "sample_549": [false], "sample_550": [false], "sample_551": [false], "sample_552": [false], "sample_553": [false], "sample_554": [true], "sample_555": [true], "sample_556": [false], "sample_557": [false], "sample_558": [false], "sample_559": [false], "sample_560": [false], "sample_561": [false], "sample_562": [false], "sample_563": [false], "sample_564": [false], "sample_565": [false], "sample_566": [false], "sample_567": [true], "sample_568": [false], "sample_569": [true], "sample_570": [false], "sample_571": [false], "sample_572": [true], "sample_573": [false], "sample_574": [false], "sample_575": [false], "sample_576": [true], "sample_577": [false], "sample_578": [false], "sample_579": [false], "sample_580": [false], "sample_581": [false], "sample_582": [false], "sample_583": [false], "sample_584": [false], "sample_585": [false], "sample_586": [false], "sample_587": [false], "sample_588": [false], "sample_589": [false], "sample_590": [false], "sample_591": [false], "sample_592": [true], "sample_593": [false], "sample_594": [true], "sample_595": [false], "sample_596": [true], "sample_597": [false], "sample_598": [true], "sample_599": [false], "sample_600": [false], "sample_601": [false], "sample_602": [false], "sample_603": [false], "sample_604": [false], "sample_605": [false], "sample_606": [false], "sample_607": [false], "sample_608": [true], "sample_609": [false], "sample_610": [false], "sample_611": [false], "sample_612": [true], "sample_613": [false], "sample_614": [true], "sample_615": [false], "sample_616": [false], "sample_617": [false], "sample_618": [false], "sample_619": [false], "sample_620": [false], "sample_621": [false], "sample_622": [false], "sample_623": [false], "sample_624": [false], "sample_625": [false], "sample_626": [false], "sample_627": [false], "sample_628": [false], "sample_629": [false], "sample_630": [false], "sample_631": [false], "sample_632": [false], "sample_633": [false], "sample_634": [false], "sample_635": [false], "sample_636": [false], "sample_637": [true], "sample_638": [false], "sample_639": [false], "sample_640": [false], "sample_641": [false], "sample_642": [false], "sample_643": [false], "sample_644": [false], "sample_645": [false], "sample_646": [true], "sample_647": [true], "sample_648": [true], "sample_649": [false], "sample_650": [false], "sample_651": [false], "sample_652": [false], "sample_653": [true], "sample_654": [false], "sample_655": [false], "sample_656": [false], "sample_657": [true], "sample_658": [true], "sample_659": [true], "sample_660": [false], "sample_661": [false], "sample_662": [false], "sample_663": [false], "sample_664": [false], "sample_665": [false], "sample_666": [false], "sample_667": [true], "sample_668": [false], "sample_669": [false], "sample_670": [false], "sample_671": [false], "sample_672": [false], "sample_673": [true], "sample_674": [false], "sample_675": [false], "sample_676": [false], "sample_677": [false], "sample_678": [false], "sample_679": [true], "sample_680": [false], "sample_681": [false], "sample_682": [false], "sample_683": [false], "sample_684": [false], "sample_685": [false], "sample_686": [false], "sample_687": [false], "sample_688": [false], "sample_689": [false], "sample_690": [false], "sample_691": [false], "sample_692": [false], "sample_693": [true], "sample_694": [false], "sample_695": [false], "sample_696": [false], "sample_697": [false], "sample_698": [false], "sample_699": [true], "sample_700": [false], "sample_701": [false], "sample_702": [true], "sample_703": [false], "sample_704": [false], "sample_705": [false], "sample_706": [false], "sample_707": [false], "sample_708": [false], "sample_709": [false], "sample_710": [true], "sample_711": [false], "sample_712": [false], "sample_713": [false], "sample_714": [false], "sample_715": [false], "sample_716": [false], "sample_717": [false], "sample_718": [false], "sample_719": [false], "sample_720": [false], "sample_721": [false], "sample_722": [false], "sample_723": [false], "sample_724": [false], "sample_725": [true], "sample_726": [false], "sample_727": [false], "sample_728": [false], "sample_729": [false], "sample_730": [false], "sample_731": [false], "sample_732": [false], "sample_733": [false], "sample_734": [true], "sample_735": [false], "sample_736": [false], "sample_737": [false], "sample_738": [false], "sample_739": [false], "sample_740": [false], "sample_741": [false], "sample_742": [true], "sample_743": [false], "sample_744": [false], "sample_745": [false], "sample_746": [false], "sample_747": [false], "sample_748": [false], "sample_749": [false], "sample_750": [false], "sample_751": [true], "sample_752": [false], "sample_753": [false], "sample_754": [false], "sample_755": [false], "sample_756": [false], "sample_757": [false], "sample_758": [false], "sample_759": [false], "sample_760": [false], "sample_761": [false], "sample_762": [true], "sample_763": [false], "sample_764": [false], "sample_765": [false], "sample_766": [false], "sample_767": [false], "sample_768": [false], "sample_769": [false], "sample_770": [false], "sample_771": [false], "sample_772": [true], "sample_773": [false], "sample_774": [false], "sample_775": [false], "sample_776": [false], "sample_777": [false], "sample_778": [false], "sample_779": [false], "sample_780": [false], "sample_781": [false], "sample_782": [false], "sample_783": [false], "sample_784": [false], "sample_785": [false], "sample_786": [false], "sample_787": [false], "sample_788": [false], "sample_789": [false], "sample_790": [false], "sample_791": [false], "sample_792": [false], "sample_793": [false], "sample_794": [false], "sample_795": [false], "sample_796": [true], "sample_797": [false], "sample_798": [false], "sample_799": [false], "sample_800": [false], "sample_801": [false], "sample_802": [false], "sample_803": [false], "sample_804": [false], "sample_805": [true], "sample_806": [false], "sample_807": [false], "sample_808": [false], "sample_809": [false], "sample_810": [false], "sample_811": [false], "sample_812": [false], "sample_813": [false], "sample_814": [true], "sample_815": [false], "sample_816": [false], "sample_817": [false], "sample_818": [false], "sample_819": [false], "sample_820": [false], "sample_821": [false], "sample_822": [false], "sample_823": [true], "sample_824": [false], "sample_825": [false], "sample_826": [false], "sample_827": [false], "sample_828": [false], "sample_829": [false], "sample_830": [true], "sample_831": [false], "sample_832": [false], "sample_833": [false], "sample_834": [false], "sample_835": [false], "sample_836": [false], "sample_837": [false], "sample_838": [false], "sample_839": [false], "sample_840": [false], "sample_841": [false], "sample_842": [false], "sample_843": [false], "sample_844": [false], "sample_845": [false], "sample_846": [false], "sample_847": [true], "sample_848": [false], "sample_849": [false], "sample_850": [true], "sample_851": [false], "sample_852": [false], "sample_853": [false], "sample_854": [false], "sample_855": [true], "sample_856": [false], "sample_857": [false], "sample_858": [false], "sample_859": [true], "sample_860": [false], "sample_861": [false], "sample_862": [false], "sample_863": [true], "sample_864": [true], "sample_865": [false], "sample_866": [true], "sample_867": [false], "sample_868": [false], "sample_869": [false], "sample_870": [false], "sample_871": [false], "sample_872": [false], "sample_873": [true], "sample_874": [false], "sample_875": [false], "sample_876": [false], "sample_877": [false], "sample_878": [false], "sample_879": [true], "sample_880": [false], "sample_881": [false], "sample_882": [false], "sample_883": [false], "sample_884": [true], "sample_885": [false], "sample_886": [false], "sample_887": [false], "sample_888": [false], "sample_889": [false], "sample_890": [false], "sample_891": [false], "sample_892": [false], "sample_893": [false], "sample_894": [false], "sample_895": [false], "sample_896": [false], "sample_897": [false], "sample_898": [false], "sample_899": [false], "sample_900": [false], "sample_901": [true], "sample_902": [false], "sample_903": [false], "sample_904": [false], "sample_905": [false], "sample_906": [false], "sample_907": [false], "sample_908": [true], "sample_909": [false], "sample_910": [false], "sample_911": [true], "sample_912": [false], "sample_913": [false], "sample_914": [true], "sample_915": [false], "sample_916": [true], "sample_917": [true], "sample_918": [false], "sample_919": [true], "sample_920": [false], "sample_921": [false], "sample_922": [false], "sample_923": [true], "sample_924": [true], "sample_925": [false], "sample_926": [true], "sample_927": [true], "sample_928": [false], "sample_929": [false], "sample_930": [false], "sample_931": [false], "sample_932": [false], "sample_933": [false], "sample_934": [true], "sample_935": [true], "sample_936": [true], "sample_937": [true], "sample_938": [false], "sample_939": [true], "sample_940": [false], "sample_941": [true], "sample_942": [false], "sample_943": [false], "sample_944": [false], "sample_945": [false], "sample_946": [false], "sample_947": [true], "sample_948": [false], "sample_949": [false], "sample_950": [false], "sample_951": [false], "sample_952": [false], "sample_953": [false], "sample_954": [false], "sample_955": [true], "sample_956": [false], "sample_957": [false], "sample_958": [false], "sample_959": [false], "sample_960": [false], "sample_961": [false], "sample_962": [false], "sample_963": [false], "sample_964": [false], "sample_965": [false], "sample_966": [false], "sample_967": [false], "sample_968": [false], "sample_969": [false], "sample_970": [false], "sample_971": [false], "sample_972": [false], "sample_973": [false], "sample_974": [false], "sample_975": [false], "sample_976": [false], "sample_977": [false], "sample_978": [false], "sample_979": [false], "sample_980": [false], "sample_981": [false], "sample_982": [false], "sample_983": [false], "sample_984": [true], "sample_985": [false], "sample_986": [false], "sample_987": [false], "sample_988": [false], "sample_989": [false], "sample_990": [false], "sample_991": [false], "sample_992": [false], "sample_993": [false], "sample_994": [false], "sample_995": [false], "sample_996": [false], "sample_997": [false], "sample_998": [false], "sample_999": [false], "sample_1000": [false], "sample_1001": [false], "sample_1002": [true], "sample_1003": [false], "sample_1004": [false], "sample_1005": [false], "sample_1006": [false], "sample_1007": [false], "sample_1008": [false], "sample_1009": [false], "sample_1010": [false], "sample_1011": [false], "sample_1012": [false], "sample_1013": [true], "sample_1014": [false], "sample_1015": [false], "sample_1016": [false], "sample_1017": [false], "sample_1018": [true], "sample_1019": [false], "sample_1020": [false], "sample_1021": [false], "sample_1022": [false], "sample_1023": [false], "sample_1024": [false], "sample_1025": [false], "sample_1026": [false], "sample_1027": [false], "sample_1028": [false], "sample_1029": [false], "sample_1030": [false], "sample_1031": [false], "sample_1032": [false], "sample_1033": [false], "sample_1034": [true], "sample_1035": [false], "sample_1036": [true], "sample_1037": [false], "sample_1038": [false], "sample_1039": [true], "sample_1040": [false], "sample_1041": [false], "sample_1042": [false], "sample_1043": [false], "sample_1044": [false], "sample_1045": [true], "sample_1046": [false], "sample_1047": [true], "sample_1048": [false], "sample_1049": [false], "sample_1050": [true], "sample_1051": [false], "sample_1052": [false], "sample_1053": [true], "sample_1054": [false], "sample_1055": [false], "sample_1056": [false], "sample_1057": [false], "sample_1058": [true], "sample_1059": [false], "sample_1060": [true], "sample_1061": [true], "sample_1062": [false], "sample_1063": [true], "sample_1064": [true], "sample_1065": [false], "sample_1066": [false], "sample_1067": [true], "sample_1068": [false], "sample_1069": [false], "sample_1070": [true], "sample_1071": [false], "sample_1072": [true], "sample_1073": [false], "sample_1074": [false], "sample_1075": [false], "sample_1076": [false], "sample_1077": [false], "sample_1078": [false], "sample_1079": [false], "sample_1080": [false], "sample_1081": [false], "sample_1082": [false], "sample_1083": [false], "sample_1084": [true], "sample_1085": [false], "sample_1086": [true], "sample_1087": [true], "sample_1088": [false], "sample_1089": [false], "sample_1090": [false], "sample_1091": [false], "sample_1092": [true], "sample_1093": [false], "sample_1094": [true], "sample_1095": [false], "sample_1096": [false], "sample_1097": [false], "sample_1098": [false], "sample_1099": [false], "sample_1100": [false], "sample_1101": [false], "sample_1102": [true], "sample_1103": [false], "sample_1104": [false], "sample_1105": [true], "sample_1106": [true], "sample_1107": [false], "sample_1108": [false], "sample_1109": [true], "sample_1110": [false], "sample_1111": [false], "sample_1112": [true], "sample_1113": [false], "sample_1114": [false], "sample_1115": [false], "sample_1116": [false], "sample_1117": [true], "sample_1118": [false], "sample_1119": [false], "sample_1120": [false], "sample_1121": [true], "sample_1122": [false], "sample_1123": [false], "sample_1124": [true], "sample_1125": [false], "sample_1126": [true], "sample_1127": [false], "sample_1128": [false], "sample_1129": [false], "sample_1130": [false], "sample_1131": [false], "sample_1132": [false], "sample_1133": [true], "sample_1134": [false], "sample_1135": [false], "sample_1136": [false], "sample_1137": [false], "sample_1138": [false], "sample_1139": [false], "sample_1140": [false], "sample_1141": [false], "sample_1142": [false], "sample_1143": [true], "sample_1144": [false], "sample_1145": [false], "sample_1146": [false], "sample_1147": [false], "sample_1148": [false], "sample_1149": [true], "sample_1150": [false], "sample_1151": [true], "sample_1152": [true], "sample_1153": [false], "sample_1154": [false], "sample_1155": [false], "sample_1156": [false], "sample_1157": [false], "sample_1158": [false], "sample_1159": [true], "sample_1160": [false], "sample_1161": [false], "sample_1162": [false], "sample_1163": [true], "sample_1164": [false], "sample_1165": [true], "sample_1166": [false], "sample_1167": [false], "sample_1168": [false], "sample_1169": [false], "sample_1170": [false], "sample_1171": [false], "sample_1172": [false], "sample_1173": [false], "sample_1174": [false], "sample_1175": [false], "sample_1176": [false], "sample_1177": [true], "sample_1178": [false], "sample_1179": [false], "sample_1180": [false], "sample_1181": [true], "sample_1182": [false], "sample_1183": [true], "sample_1184": [false], "sample_1185": [false], "sample_1186": [true], "sample_1187": [false], "sample_1188": [false], "sample_1189": [true], "sample_1190": [false], "sample_1191": [false], "sample_1192": [false], "sample_1193": [false], "sample_1194": [false], "sample_1195": [false], "sample_1196": [false], "sample_1197": [false], "sample_1198": [false], "sample_1199": [false], "sample_1200": [false], "sample_1201": [false], "sample_1202": [false], "sample_1203": [false], "sample_1204": [false], "sample_1205": [false], "sample_1206": [true], "sample_1207": [false], "sample_1208": [true], "sample_1209": [true]}}