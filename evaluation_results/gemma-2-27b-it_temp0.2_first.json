{"raw_generations": {"sample_852": ["    def test_make_checkerboard_shuffle(random_state=42):\n        X, rows, cols = make_checkerboard((10, 12), 2, shuffle=True,\n                                         random_state=random_state)\n        assert X.shape == (10, 12)\n        assert rows.shape == (2, 10)\n        assert cols.shape == (2, 12)\n        assert_array_equal(np.sum(rows, axis=0), np.array([5, 5]))\n        assert_array_equal(np.sum(cols, axis=0), np.array([6, 6]))\n"], "sample_1111": ["    def test_textplot_str_log():\n        x = Symbol('x')\n        expr = log(x)\n        lines = list(textplot_str(expr, 1, 5))\n        assert len(lines) == 22\n        assert lines[10] == \" 2.0 |----.......--------------------------------------------\"\n"], "sample_566": ["    def test_figure_dpi_set_get(self):\n        fig = Figure()\n        assert fig.dpi == mpl.rcParams['figure.dpi']\n        fig.dpi = 100\n        assert fig.dpi == 100\n"], "sample_773": ["    def test_logistic_regression_cv_multiclass_ovr_sparse_input():\n        # Test LogisticRegressionCV with sparse input and multiclass\n        # classification using 'ovr' strategy.\n\n        X = sp.csr_matrix(make_classification(n_samples=100, n_features=20,\n                                              n_informative=10,\n                                              n_classes=3, random_state=0))\n        y = make_classification(n_samples=100, n_features=20,\n                                n_informative=10,\n                                n_classes=3, random_state=0)[1]\n\n        clf = LogisticRegressionCV(Cs=10, cv=StratifiedKFold(5),\n                                   multi_class='ovr', solver='lbfgs',\n                                   random_state=0).fit(X, y)\n        check_predictions(clf, X, y)\n"], "sample_1207": ["    def test_parse_expr_rationalize():\n        assert parse_expr('1.2', transformations=(standard_transformations + (rationalize,))) == Rational(6, 5)\n        assert parse_expr('1.2345', transformations=(standard_transformations + (rationalize,))) == Rational(12345, 10000)\n        assert parse_expr('1.2e-3', transformations=(standard_transformations + (rationalize,))) == Rational(12, 10000)\n        assert parse_expr('1.2e3', transformations=(standard_transformations + (rationalize,))) == Rational(1200, 1)\n"], "sample_25": ["    def test_card_fix_value(self):\n        card = fits.Card.fromstring(\"FOO = 'This is a test string'\")\n        card._fix_value()\n        assert card.value == \"'This is a test string'\"\n\n        card = fits.Card.fromstring(\"BAR = 123.456\")\n        card._fix_value()\n        assert card.value == 123.456\n\n        card = fits.Card.fromstring(\"BAZ = 1.23456E+02\")\n        card._fix_value()\n        assert card.value == 123.456\n\n        card = fits.Card.fromstring(\"QUX = (1.23, 4.56)\")\n        card._fix_value()\n        assert card.value == (1.23, 4.56)\n\n"], "sample_377": ["    def test_callable_setting_wrapper_repr(self):\n        wrapped_callable = CallableSettingWrapper(lambda: None)\n        self.assertEqual(repr(wrapped_callable), '<CallableSettingWrapper object>')\n"], "sample_904": ["    def test_resolve_option_xref_with_subcommands(self, app, env):\n        app.builder.env = env\n        docname = 'index'\n        env.temp_data['progoptions'] = {\n            ('program-name', 'subcommand1'): ('index', 'option1'),\n            ('program-name', 'subcommand2 subcommand3'): ('index', 'option2'),\n        }\n\n        node = pending_xref('', '', refdomain='std', reftarget='subcommand2 subcommand3',\n                            reftype='option', std:program='program-name')\n        result = StandardDomain.resolve_xref(env, docname, app.builder, 'option',\n                                            'subcommand2 subcommand3', node, node)\n        assert isinstance(result, nodes.reference)\n        assert result['refuri'] == 'index#option2'\n        assert result.astext() == 'subcommand2 subcommand3'\n\n"], "sample_361": ["    def test_urlize_nofollow(self):\n        self.check_output(\n            lambda: urlize('http://example.com', nofollow=True),\n            '<a href=\"http://example.com\" rel=\"nofollow\">http://example.com</a>'\n        )\n"], "sample_979": ["def test_MatrixElement_subs():\n    i, j = symbols('i j')\n    M = MatrixSymbol('M', 3, 3)\n    me = MatrixElement(M, i, j)\n    assert me.subs(i, 1) == MatrixElement(M, 1, j)\n    assert me.subs(j, 2) == MatrixElement(M, i, 2)\n    assert me.subs({i:1, j:2}) == MatrixElement(M, 1, 2)\n"], "sample_1163": ["def test_polarify_subs():\n    x, y = symbols('x y')\n    expr = x*y\n    eq, subs = polarify(expr, subs=True)\n    assert eq == _x*_y\n    assert subs == {_x: x, _y: y}\n"], "sample_703": ["    def test_not_expr_parentheses(self):\n        assert evaluate(\"(not foo)\", lambda x: x == \"bar\") is True\n        assert evaluate(\"(not (foo))\", lambda x: x == \"bar\") is True\n"], "sample_1164": ["def test_cg_simp():\n    a, b, c = symbols('a b c')\n    alpha, beta, gamma = symbols('alpha beta gamma')\n    expr = CG(a, alpha, b, beta, c, gamma) + CG(a, alpha, b, beta, c, gamma)\n    assert cg_simp(expr) == 2*CG(a, alpha, b, beta, c, gamma)\n"], "sample_491": ["    def test_boundfield_label_tag_with_custom_label_suffix(self):\n        form = FrameworkForm({'name': 'John', 'language': 'P'})\n        bound_field = form['language']\n        label_tag = bound_field.label_tag(label_suffix=\":\")\n        self.assertIn(\"Python:\", label_tag)\n"], "sample_245": ["    def test_makemessages_no_location(self):\n        \"\"\"\n        Test that --no-location option works as expected.\n        \"\"\"\n        with captured_stdout() as stdout:\n            output, po_contents = self._run_makemessages(no_location=True)\n        self.assertNotIn('#: ', po_contents)\n        self.assertNotIn('msgid \"Hello world\"', po_contents)\n        self.assertMsgId('Hello world', po_contents)\n"], "sample_19": ["    def test_maps_read_and_write(self):\n        for filename in self._file_list:\n            with open(filename, \"rb\") as f:\n                header = fits.Header.fromtextfile(f)\n            wcs = wcs.WCS(header)\n            hdu = fits.PrimaryHDU(header=header)\n            with io.BytesIO() as out:\n                hdu.writeto(out)\n                out.seek(0)\n                new_header = fits.Header.fromtextfile(out)\n            assert new_header == header\n"], "sample_268": ["    def test_iter_modules_and_files_zipfile(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_filename = Path(tempdir) / 'test.zip'\n            with zipfile.ZipFile(zip_filename, 'w') as zf:\n                zf.writestr('module.py', 'print(\"Hello from module\")')\n            sys.path.append(tempdir)\n            self.addCleanup(sys.path.remove, tempdir)\n            self.import_and_cleanup('module')\n            self.assertFileFound(zip_filename)\n"], "sample_177": ["    def test_get_related_models_recursive_with_proxy_model(self):\n        class ProxyFood(Food):\n            class Meta:\n                proxy = True\n\n        with isolate_apps():\n            apps = Apps()\n            apps.register_model('test_app', Food)\n            apps.register_model('test_app', ProxyFood)\n            related_models = get_related_models_recursive(Food)\n            self.assertIn(('test_app', 'proxyfood'), related_models)\n"], "sample_342": ["    def test_autocomplete_permission_denied_invalid_field(self):\n        with model_admin(Answer, AnswerAdmin):\n            # Modify the AnswerAdmin to have an invalid field for autocomplete\n            AnswerAdmin.autocomplete_fields = ['nonexistent_field']\n            request = self.factory.get(self.url, {\n                'app_label': self.opts['app_label'],\n                'model_name': self.opts['model_name'],\n                'field_name': self.opts['field_name'],\n                'term': 'test',\n            })\n            request.user = self.user\n            response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n            self.assertEqual(response.status_code, 403)\n            self.assertEqual(response.content.decode(), 'Permission denied.')\n"], "sample_843": ["def test_kernel_operator():\n    kernel = RBF(length_scale=1.0)\n    op = KernelOperator(kernel, X)\n    K = op(Y)\n    assert_array_almost_equal(K, pairwise_kernels(X, Y, metric='rbf', gamma=1.0))\n"], "sample_106": ["    def test_get_cache_key_with_vary_header(self):\n        request = HttpRequest()\n        request.META['HTTP_ACCEPT_LANGUAGE'] = 'en-us'\n        request.META['HTTP_ACCEPT_ENCODING'] = 'gzip'\n        request.path = '/some/path/'\n        request.method = 'GET'\n        with self.settings(CACHE_MIDDLEWARE_KEY_PREFIX='test'):\n            key = get_cache_key(request)\n            self.assertIsNotNone(key)\n            self.assertIn('test.GET', key)\n            self.assertIn(hashlib.md5(b'/some/path/').hexdigest(), key)\n            self.assertIn('en-us', key)\n            self.assertIn('gzip', key)\n"], "sample_400": ["    def test_rename_field_with_default(self):\n        before_state = self.make_project_state(\n            [\n                self.author_with_biography_non_blank,\n            ]\n        )\n        after_state = self.make_project_state(\n            [\n                self.author_with_biography_blank,\n            ]\n        )\n        changes = self.get_changes(before_state, after_state)\n        self.assertNumberMigrations(changes, \"testapp\", 1)\n        self.assertOperationTypes(changes, \"testapp\", 0, [\"RenameField\"])\n        self.assertOperationAttributes(\n            changes, \"testapp\", 0, 0, name=\"biography\", field_name=\"biography\"\n        )\n"], "sample_601": ["    def test_strftime(self):\n        expected = self.times.strftime('%Y-%m-%d')\n        actual = self.times_data.dt.strftime('%Y-%m-%d')\n        assert_array_equal(actual, expected)\n"], "sample_794": ["    def test_ridge_classifier_sparse_multiclass(self):\n        X, y = make_multilabel_classification(n_samples=50,\n                                             n_features=10,\n                                             n_classes=3,\n                                             n_labels=2,\n                                             random_state=0)\n        X = sp.csr_matrix(X)\n        clf = RidgeClassifierCV(alphas=[0.1, 1.0, 10.0]).fit(X, y)\n        assert clf.coef_.shape == (3, 10)\n        assert clf.intercept_.shape == (3,)\n"], "sample_937": ["compilation error"], "sample_813": ["    def test_ard_regression_alpha(self):\n        rng = check_random_state(42)\n        n_samples, n_features = 50, 10\n        X = rng.randn(n_samples, n_features)\n        y = rng.randn(n_samples)\n        ard = ARDRegression(alpha_1=1e-5, alpha_2=1e-5,\n                            lambda_1=1e-5, lambda_2=1e-5,\n                            compute_score=True)\n        ard.fit(X, y)\n        assert_almost_equal(ard.alpha_, np.var(y), 2)\n"], "sample_219": ["    def test_f_expressions(self):\n        with CaptureQueriesContext(connection) as captured_queries:\n            qs = Company.objects.annotate(\n                double_employees=F('num_employees') * 2,\n                chairs_per_employee=F('num_chairs') / F('num_employees'),\n            ).order_by('name')\n            self.assertQuerysetEqual(\n                qs, [\n                    {'name': 'Example Inc.', 'num_employees': 2300, 'num_chairs': 5, 'double_employees': 4600, 'chairs_per_employee': Decimal('0.0021739130434782609')},\n                    {'name': 'Foobar Ltd.', 'num_employees': 3, 'num_chairs': 4, 'double_employees': 6, 'chairs_per_employee': Decimal('1.3333333333333333')},\n                    {'name': 'Test GmbH', 'num_employees': 32, 'num_chairs': 1, 'double_employees': 64, 'chairs_per_employee': Decimal('0.03125')},\n                ],\n                transform=lambda x: {k: x[k] for k in ['name', 'num_employees', 'num_chairs', 'double_employees', 'chairs_per_employee']},\n            )\n            self.assertEqual(len(captured_queries), 1)\n\n"], "sample_78": ["    def test_no_translations(self):\n        with translation.override('fr'):\n            out = StringIO()\n            err = StringIO()\n            with captured_stderr(err):\n                management.call_command('dance', stdout=out, stderr=err)\n            self.assertEqual(err.getvalue(), '')\n            self.assertEqual(out.getvalue(), 'Dancing!\\n')\n"], "sample_324": ["    def test_csrf_token_in_response_after_post_with_invalid_referer(self):\n        with self.settings(CSRF_TRUSTED_ORIGINS=['https://example.com']):\n            req = self._get_POST_csrf_cookie_request(\n                cookie=self._csrf_id_cookie,\n                meta_token=self._csrf_id,\n            )\n            req.META['HTTP_REFERER'] = 'http://example.com/'\n            response = self.middleware.process_view(req, post_form_view, (), {})\n            self.assertEqual(response.status_code, 403)\n            self.assertIn(REASON_BAD_ORIGIN % 'http://example.com/', response.content.decode())\n"], "sample_693": ["    def test_unittest_skip_reason(self, testdir: Pytester) -> None:\n        testdir.makepyfile(\n            \"\"\"\n            import unittest\n\n            class TestClass(unittest.TestCase):\n                @unittest.skip(\"skip reason\")\n                    pass\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.assert_outcomes(skipped=1)\n        assert \"skip reason\" in result.stdout.str()\n"], "sample_717": ["    def test_fetch_lfw_people_min_faces_per_person(self):\n        lfw_people = fetch_lfw_people(data_home=SCIKIT_LEARN_DATA,\n                                     min_faces_per_person=2)\n        assert_equal(len(lfw_people.target_names), 3)\n        assert_equal(len(lfw_people.data), 10)\n"], "sample_1065": ["    def test_binomial_mod_prime_large_n():\n        n = 10**6\n        k = 100\n        q = 101\n        assert binomial(n, k).Mod(q) == binomial(n, k) % q\n"], "sample_92": ["    def test_get_all_permissions(self):\n        self.assertEqual(\n            SimpleBackend().get_all_permissions(self.user),\n            {'user_perm', 'group_perm'},\n        )\n"], "sample_949": ["    def test_man_pages(app, status, warning):\n        app.config.man_pages = default_man_pages(app.config)\n        app.build()\n        assert len(app.env.all_docs) == 1\n        assert status.success is True\n        assert len(warning) == 0\n"], "sample_590": ["    def test_concat_dataarray_with_different_coords():\n        # Test concatenating DataArrays with different coordinates\n        da1 = DataArray(np.arange(4).reshape((2, 2)), dims=[\"x\", \"y\"], coords={\"x\": [0, 1], \"y\": [0, 1]})\n        da2 = DataArray(np.arange(4).reshape((2, 2)), dims=[\"x\", \"y\"], coords={\"x\": [2, 3], \"y\": [0, 1]})\n        expected = DataArray(\n            np.arange(8).reshape((4, 2)), dims=[\"x\", \"y\"], coords={\"x\": [0, 1, 2, 3], \"y\": [0, 1]}\n        )\n        actual = concat([da1, da2], dim=\"x\")\n        assert_identical(actual, expected)\n\n"], "sample_71": ["    def test_format_grouping_with_sequence(self):\n        self.assertEqual(nformat(1234567890, decimal_sep='.', decimal_pos=2, grouping=(3, 2, 0)), '1.234.567.890,00')\n"], "sample_993": ["def test_cyclic_conjugates():\n    assert len(x*y*x*y*x.cyclic_conjugates()) == 5\n    assert (x*y*x*y*x).cyclic_conjugates() == {x*y*x**2*y, x**2*y*x*y, y*x*y*x**2, y*x**2*y*x, x*y*x*y*x}\n    assert len(x*y*x**2*y*x.cyclic_conjugates()) == 3\n    assert (x*y*x**2*y*x).cyclic_conjugates() == {x**2*y*x**2*y, y*x**2*y*x**2, x*y*x**2*y*x}\n\n"], "sample_1134": ["def test_latex_SetExpr():\n    S = FiniteSet(1, 2, 3)\n    assert latex(S) == '\\\\left\\{1, 2, 3\\\\right\\}'\n\n    U = Union(S, {4, 5})\n    assert latex(U) == '\\\\left\\{1, 2, 3, 4, 5\\\\right\\}'\n\n    I = Intersection(S, {2, 3, 4})\n    assert latex(I) == '\\\\left\\{2, 3\\\\right\\}'\n\n    C = Complement(S, {2})\n    assert latex(C) == '\\\\left\\{1, 3\\\\right\\}'\n\n    SD = SymmetricDifference(S, {2, 4})\n    assert latex(SD) == '\\\\left\\{1, 3, 4\\\\right\\}'\n\n    PS = ProductSet(S, {a, b})\n    assert latex(PS) == '\\\\left\\\\{\\\\left(1, a\\\\right), \\\\left(1, b\\\\right), \\\\left(2, a\\\\right), \\\\left(2, b\\\\right), \\\\left(3, a\\\\right), \\\\left(3, b\\\\right)\\\\right\\\\}'\n"], "sample_240": ["    def test_make_token_with_timestamp_legacy(self):\n        user = User.objects.create_user(username='testuser', email='test@example.com', password='password')\n        generator = MockedPasswordResetTokenGenerator(datetime(2023, 1, 1, 12, 0, 0))\n        token = generator._make_token_with_timestamp(user, 1672531200, legacy=True)\n        self.assertEqual(token, '0-e744077012c12022948001072b80819c')\n"], "sample_1110": ["    def test_print_MatrixSolve(self):\n        A = MatrixSymbol('A', 2, 2)\n        b = MatrixSymbol('b', 2, 1)\n        x = MatrixSymbol('x', 2, 1)\n        eq = Eq(A*x, b)\n        sol = MatrixSolve(eq, x)\n        assert pycode(sol, language='python') == 'sympy.solve(Eq(A*x, b), x)'\n"], "sample_985": ["def test_Min_Max_evalf():\n    x = Symbol('x')\n    assert Min(x, 2).evalf(subs={x: 3}) == 2\n    assert Max(x, 2).evalf(subs={x: 3}) == 3\n    assert Min(x, 2).evalf(subs={x: 1}) == 1\n    assert Max(x, 2).evalf(subs={x: 1}) == 2\n"], "sample_1058": ["    def test_print_MatrixSymbol(self):\n        A = MatrixSymbol('A', 2, 2)\n        assert PythonCodePrinter().doprint(A) == 'A'\n        assert NumPyPrinter().doprint(A) == 'A'\n        assert SciPyPrinter().doprint(A) == 'A'\n        assert SymPyPrinter().doprint(A) == 'A'\n"], "sample_131": ["    def test_test_db_signature(self):\n        connection = self.get_connection_copy()\n        creation = BaseDatabaseCreation(connection)\n        original_signature = creation.test_db_signature()\n\n        # Modify some settings and check if the signature changes\n        connection.settings_dict['NAME'] = 'new_test_db'\n        new_signature = creation.test_db_signature()\n        self.assertNotEqual(original_signature, new_signature)\n\n        # Restore original settings\n        connection.settings_dict['NAME'] = connection.settings_dict['NAME']\n        self.assertEqual(creation.test_db_signature(), original_signature)\n"], "sample_524": ["    def test_colorbar_extension_length_uniform(self):\n        fig = _colorbar_extension_length('uniform')\n        self.compare(fig)\n"], "sample_976": ["def test_symbols_exclude():\n    x = Symbol('x')\n    a = Wild('a', exclude=[x])\n    b = Wild('b', exclude=[x])\n    assert (2*x**3*y*z).match(a*b) == {a: z, b: 2*x**3*y}\n"], "sample_1129": ["    def test_print_MatrixSolve(self):\n        A = MatrixSymbol('A', 2, 2)\n        b = MatrixSymbol('b', 2, 1)\n        x = MatrixSymbol('x', 2, 1)\n        eq = Eq(A*x, b)\n        sol = MatrixSolve(eq, x)\n        assert pycode(sol, language='python') == 'sympy.solve(Eq(A*x, b), x)'\n\n"], "sample_680": ["    def test_evaluate_skip_marks_skipif_true(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skipif(sys.platform == 'win32', reason=\"skip on windows\")\n                assert True\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\"*1 skipped*\"])\n        assert result.ret == 0\n"], "sample_820": ["    def test_voting_regressor_weights(self):\n        # Test that weights are correctly applied in VotingRegressor\n        clf1 = LinearRegression()\n        clf2 = RandomForestRegressor(n_estimators=10, random_state=1)\n        X_train, X_test, y_train, y_test = train_test_split(\n            X_r, y_r, test_size=0.2, random_state=42)\n        er = VotingRegressor([('lr', clf1), ('rf', clf2)], weights=[1, 2])\n        er.fit(X_train, y_train)\n        y_pred = er.predict(X_test)\n        # Check if predictions are closer to the predictions of the\n        # regressor with higher weight\n        assert_array_almost_equal(y_pred,\n                                  2 * clf2.predict(X_test) + clf1.predict(X_test),\n                                  decimal=2)\n"], "sample_327": ["    def test_jsonfield_with_encoder(self):\n        class MyForm(Form):\n            data = JSONField(encoder=DjangoJSONEncoder)\n\n        form = MyForm({'data': '{\"key\": \"value\", \"nested\": {\"key2\": 1}}'})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['data'], {'key': 'value', 'nested': {'key2': 1}})\n"], "sample_162": ["    def test_no_location_option(self):\n        \"\"\"\n        Test that the --no-location option removes location comments from the .po file.\n        \"\"\"\n        output, po_contents = self._run_makemessages(no_location=True)\n        self.assertNotIn('#: ', po_contents)\n"], "sample_662": ["    def test_report_to_json_and_back_with_exception_chain(self):\n        excinfo = ExceptionInfo(\n            Exception(\"hello\"),\n            stack=[\n                (\"file1.py\", 1, \"func1\"),\n                (\"file2.py\", 2, \"func2\"),\n            ],\n        )\n        reprtraceback = ReprTraceback(\n            reprentries=[\n                ReprEntry([\"line1\"], style=\"short\"),\n                ReprEntry([\"line2\"], style=\"long\"),\n            ]\n        )\n        reprcrash = ReprFileLocation(\"file1.py\", 1, \"func1\")\n        exception_info = ExceptionChainRepr(\n            [\n                (reprtraceback, reprcrash, \"First exception\"),\n                (reprtraceback, reprcrash, \"Second exception\"),\n            ]\n        )\n        report = TestReport(\n            nodeid=\"test_func\",\n            location=(\"file.py\", 1, \"test_func\"),\n            keywords={\"keyword1\"},\n            outcome=\"failed\",\n            longrepr=exception_info,\n            when=\"call\",\n            sections=[],\n            duration=0.1,\n            user_properties=[],\n        )\n        report_dict = pytest_report_to_serializable(report)\n        report_from_dict = pytest_report_from_serializable(report_dict)\n        assert isinstance(report_from_dict.longrepr, ExceptionChainRepr)\n        assert report_from_dict.longrepr.chain == report.longrepr.chain\n"], "sample_448": ["    def test_unique_constraint_with_expressions_and_condition(self):\n        with atomic():\n            UniqueConstraintProduct.objects.create(name=\"Product 1\", price=10)\n            with self.assertRaises(IntegrityError):\n                UniqueConstraintProduct.objects.create(name=\"Product 1\", price=20)\n            with self.assertRaises(IntegrityError):\n                UniqueConstraintProduct.objects.create(name=\"Product 2\", price=10)\n            UniqueConstraintConditionProduct.objects.create(name=\"Product 3\", price=10)\n            with self.assertRaises(IntegrityError):\n                UniqueConstraintConditionProduct.objects.create(name=\"Product 3\", price=20)\n"], "sample_483": ["    def test_check_middleware(self):\n        admin_site = AdminSite()\n        admin_site.register(Album, ValidFields)\n        admin_site.register(Song, ValidFormFieldsets)\n\n        middleware = [\n            AuthenticationMiddlewareSubclass,\n            MessageMiddlewareSubclass,\n            SessionMiddlewareSubclass,\n        ]\n\n        errors = admin_site.check(\n            middleware=middleware\n        )\n        self.assertEqual(len(errors), 0)\n\n"], "sample_745": ["    def test_inverse_transform_check():\n        func = lambda x: x ** 2\n        inv_func = lambda x: np.sqrt(x)\n        transformer = FunctionTransformer(func, inv_func=inv_func)\n        X = np.array([[1, 2], [3, 4]])\n        transformer.fit(X)\n        X_transformed = transformer.transform(X)\n        X_inverse_transformed = transformer.inverse_transform(X_transformed)\n        assert_allclose_dense_sparse(X, X_inverse_transformed)\n"], "sample_824": ["    def test_pairwise_distances_chunked_reduce_func_sparse(self):\n        X = csr_matrix([[0, 1], [1, 0]])\n        reduce_func = lambda D_chunk, start: (D_chunk.sum(axis=1),)\n        gen = pairwise_distances_chunked(X, reduce_func=reduce_func)\n        result = next(gen)\n        assert_array_equal(result[0], np.array([1, 1]))\n"], "sample_941": ["    def test_restify_forwardref():\n        assert restify(ForwardRef('MyClass1')) == ':class:`MyClass1`'\n"], "sample_198": ["    def test_concat_expression(self):\n        concat_expr = Concat(\n            F('name'), Value(': '), F('num_employees'), Value(' employees')\n        )\n        result = list(self.company_query.annotate(info=concat_expr))\n        self.assertEqual(result[0]['info'], 'Example Inc.: 2300 employees')\n        self.assertEqual(result[1]['info'], 'Foobar Ltd.: 3 employees')\n        self.assertEqual(result[2]['info'], 'Test GmbH: 32 employees')\n"], "sample_857": ["def test_sparse_input_classification():\n    for tree_class in CLF_TREES.values():\n        clf = tree_class(random_state=0)\n        for name, data in DATASETS.items():\n            if name in [\"sparse-pos\", \"sparse-neg\", \"sparse-mix\"]:\n                X = data[\"X_sparse\"]\n                y = data[\"y\"]\n                clf.fit(X, y)\n                assert clf.tree_.n_features == X.shape[1]\n                y_pred = clf.predict(X)\n                assert accuracy_score(y, y_pred) > 0.8\n\n"], "sample_345": ["    def test_iter_modules_and_files_zipfile(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_path = Path(tempdir) / 'test.zip'\n            with zipfile.ZipFile(zip_path, 'w') as zf:\n                zf.writestr('test_module.py', 'print(\"Hello\")')\n            sys.path.append(str(tempdir))\n            self.import_and_cleanup('test_module')\n            self.assertFileFound(zip_path)\n"], "sample_653": ["    def test_log_capture_handler_records_log_messages(self, caplog):\n        caplog.set_level(logging.INFO)\n        logging.info(\"This is a test message\")\n        assert len(caplog.records) == 1\n        assert caplog.records[0].levelno == logging.INFO\n        assert caplog.records[0].getMessage() == \"This is a test message\"\n"], "sample_583": ["    def test_vectorized_indexer_with_mask(self):\n        x = np.arange(10)\n        indexer = indexing.VectorizedIndexer((np.array([0, 1, 2]),\n                                             np.array([3, 4, 5])))\n        expected = x[indexer.tuple]\n        result = indexing.explicit_indexing_adapter(\n            indexer, x.shape, indexing.IndexingSupport.VECTORIZED,\n            lambda key: x[key])\n        assert_array_equal(result, expected)\n"], "sample_196": ["    def test_integer_field_range(self):\n        self.assertEqual(self.ops.integer_field_range('SmallIntegerField'), (-32768, 32767))\n        self.assertEqual(self.ops.integer_field_range('IntegerField'), (-2147483648, 2147483647))\n        self.assertEqual(self.ops.integer_field_range('BigIntegerField'), (-9223372036854775808, 9223372036854775807))\n        self.assertEqual(self.ops.integer_field_range('PositiveBigIntegerField'), (0, 9223372036854775807))\n        self.assertEqual(self.ops.integer_field_range('PositiveSmallIntegerField'), (0, 32767))\n        self.assertEqual(self.ops.integer_field_range('PositiveIntegerField'), (0, 2147483647))\n        self.assertEqual(self.ops.integer_field_range('SmallAutoField'), (-32768, 32767))\n        self.assertEqual(self.ops.integer_field_range('AutoField'), (-2147483648, 2147483647))\n        self.assertEqual(self.ops.integer_field_range('BigAutoField'), (-9223372036854775808, 9223372036854775807))\n"], "sample_642": ["def test_preprocess_options(\n    run: Run, capsys: CaptureFixture[str]"], "sample_138": ["    def test_manifest_strict_missing_entry(self):\n        \"\"\"\n        Test that a strict manifest raises an error when a file is missing.\n        \"\"\"\n        test_root = Path(TEST_ROOT)\n        test_file = test_root / 'test.css'\n        test_file.write_text('body { color: red; }')\n\n        with override_settings(STATICFILES_STORAGE='django.contrib.staticfiles.storage.ManifestStaticFilesStorage'):\n            # Create a manifest file\n            storage.staticfiles_storage.save_manifest()\n\n            # Delete the file from the manifest\n            manifest_path = Path(settings.STATIC_ROOT) / storage.staticfiles_storage.manifest_name\n            with open(manifest_path, 'r+') as f:\n                manifest = json.load(f)\n                manifest['paths'].pop(str(test_file.relative_to(test_root)), None)\n                f.seek(0)\n                json.dump(manifest, f)\n                f.truncate()\n\n            with self.assertRaises(ValueError) as e:\n                call_command('collectstatic', interactive=False, verbosity=0)\n            self.assertIn(\"Missing staticfiles manifest entry for 'test.css'\", str(e.exception))\n\n"], "sample_202": ["    def test_cookie_storage_max_size(self):\n        storage = self.storage_class(self.request)\n        messages = [Message(level=constants.DEBUG, message='Message 1', extra_tags=['tag1']),\n                    Message(level=constants.INFO, message='Message 2', extra_tags=['tag2']),\n                    Message(level=constants.WARNING, message='Message 3', extra_tags=['tag3']),\n                    Message(level=constants.ERROR, message='Message 4', extra_tags=['tag4']),\n                    Message(level=constants.SUCCESS, message='Message 5', extra_tags=['tag5'])]\n        set_cookie_data(storage, messages)\n\n        response = self.get_response(storage)\n        self.assertEqual(stored_cookie_messages_count(storage, response), 5)\n\n        # Add more messages to exceed the max cookie size\n        messages.extend([Message(level=constants.DEBUG, message='Message 6'),\n                         Message(level=constants.INFO, message='Message 7')])\n        set_cookie_data(storage, messages)\n\n        response = self.get_response(storage)\n        self.assertEqual(stored_cookie_messages_count(storage, response), 5)\n"], "sample_530": ["    def test_draggable_annotation(self):\n        fig, ax = plt.subplots()\n        x, y = 0.5, 0.5\n        ann = ax.annotate(\"test\", (x, y), xycoords=\"data\",\n                          annotation_clip=True)\n        draggable = DraggableAnnotation(ann)\n        event = MouseEvent('button_press_event', fig.canvas, x, y, button=MouseButton.LEFT)\n        draggable.on_pick(namedtuple('PickEvent', ['mouseevent'])(event))\n        event = MouseEvent('motion_notify_event', fig.canvas, x + 10, y + 10)\n        draggable.on_motion(event)\n        assert_allclose(ann.xyann, (x + 10, y + 10))\n"], "sample_604": ["    def test_format_timedelta_with_date_format(self):\n        t = pd.Timedelta(days=1, hours=2, minutes=30)\n        assert formatting.format_timedelta(t, timedelta_format=\"date\") == \"1 days\"\n        assert formatting.format_timedelta(t, timedelta_format=\"time\") == \"02:30:00\"\n"], "sample_283": ["    def test_runshell_sigint(self):\n        with mock.patch('django.db.backends.postgresql.client.subprocess.Popen') as mock_popen:\n            mock_popen.return_value.communicate.return_value = (b'', b'')\n            with mock.patch('django.db.backends.postgresql.client.signal.signal') as mock_signal:\n                client = DatabaseClient(None)\n                client.runshell([])\n                mock_signal.assert_any_call(signal.SIGINT, signal.SIG_IGN)\n                mock_signal.assert_any_call(signal.SIGINT, mock.ANY)\n"], "sample_48": ["    def test_aggregate_with_filter(self):\n        with CaptureQueriesContext(connection) as queries:\n            result = Book.objects.annotate(\n                avg_price=Avg('price', filter=Q(rating__gt=4))\n            ).filter(avg_price__isnull=False).values('avg_price').first()\n        self.assertEqual(len(queries), 2)\n        self.assertEqual(result['avg_price'], Approximate(Decimal('56.40')))\n"], "sample_313": ["    def test_template_changed_resets_loaders(self):\n        reset_loaders = mock.MagicMock()\n        with mock.patch('django.template.autoreload.reset_loaders', reset_loaders):\n            file_path = EXTRA_TEMPLATES_DIR / 'test.html'\n            autoreload.file_changed(file_path)\n        reset_loaders.assert_called_once()\n"], "sample_835": ["    def test_ada_boost_regressor_sparse_input(self):\n        # Test AdaBoostRegressor with sparse input\n        X_sparse = csc_matrix(boston.data)\n        y = boston.target\n\n        regressor = AdaBoostRegressor(random_state=0)\n        regressor.fit(X_sparse, y)\n        y_pred = regressor.predict(X_sparse)\n        assert_array_almost_equal(y_pred, regressor.predict(X_sparse.toarray()),\n                                 decimal=2)\n"], "sample_588": ["    def test_combine_nested_with_empty_datasets(self):\n        ds1 = Dataset()\n        ds2 = Dataset()\n        ds3 = Dataset({'a': ('x', [1, 2, 3])})\n        combined = combine_nested([ds1, ds2, ds3], concat_dim=['x'])\n        assert_identical(combined, ds3)\n"], "sample_1075": ["    def test_beta_eval_rewrite_as_gamma(self):\n        x = Symbol('x')\n        y = Symbol('y')\n        assert beta(x, y)._eval_rewrite_as_gamma(x, y) == gamma(x)*gamma(y) / gamma(x + y)\n"], "sample_1044": ["def test_Pow_as_content_primitive():\n    x = Symbol('x')\n    assert (2**(x + 1)).as_content_primitive() == (2, 2**x)\n    assert (2**(2*x + 1)).as_content_primitive() == (2, 2**(2*x))\n    assert ((2*x)**2).as_content_primitive() == (4, x**2)\n    assert ((2*x + 2)**2).as_content_primitive() == (4, (x + 1)**2)\n    assert (4**((1 + x)/2)).as_content_primitive() == (2, 4**(x/2))\n    assert (3**((1 + x)/2)).as_content_primitive() == (1, 3**((x + 1)/2))\n    assert (3**((5 + x)/2)).as_content_primitive() == (9, 3**((x + 1)/2))\n"], "sample_574": ["    def test_label_concise(self, x):\n        a, locs = self.setup_labels(x, concise=True)\n        formatter = a.major.formatter\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n        # TODO: check that the output is actually concise\n"], "sample_646": ["    def test_runtest_with_twisted_trial(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import unittest\n            from twisted.trial.unittest import TestCase\n\n            class MyTests(TestCase):\n                    pass\n\n                    self.fail(\"intentional failure\")\n\n            if __name__ == '__main__':\n                unittest.main()\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        assert result.ret == ExitCode.OK\n        result.stdout.fnmatch_lines(\n            [\n                \"*test_pass PASSED*\",\n                \"*test_fail FAILED*\",\n                \"*intentional failure*\",\n            ]\n        )\n"], "sample_528": ["def test_context_after_reset():\n    with temp_style('test_style'):\n        with style.context('test_style', after_reset=True):\n            assert mpl.rcParams[PARAM] == VALUE\n        assert mpl.rcParams[PARAM] != VALUE\n"], "sample_977": ["    def test_print_Derivative():\n        assert mcode(Derivative(f(x), x)) == 'Hold[D[f[x], x]]'\n        assert mcode(Derivative(f(x, y), x, 2)) == 'Hold[D[f[x, y], {x, 2}]]'\n"], "sample_523": ["    def test_legend_loc(self, loc):\n        fig, ax = plt.subplots()\n        ax.plot([1, 2, 3], label=\"Line 1\")\n        ax.plot([4, 5, 6], label=\"Line 2\")\n        legend = ax.legend(loc=loc)\n        fig.canvas.draw()\n        bbox = legend.get_window_extent()\n        assert bbox.x0 >= 0\n        assert bbox.y0 >= 0\n        assert bbox.x1 <= fig.bbox.width\n        assert bbox.y1 <= fig.bbox.height\n\n"], "sample_760": ["    def test_check_scoring_with_custom_scorer():\n        # Test check_scoring with a custom scorer\n        scorer = DummyScorer()\n        estimator = EstimatorWithFit()\n        scoring = scorer\n        result = check_scoring(estimator, scoring=scoring)\n        assert_equal(result, scorer)\n"], "sample_927": ["def test_function_template_args():\n    check('function',\n          'void foo(typename T, int x = 5)',\n          {1: 'foo_T_int'},\n          'void foo(typename T, int x = 5)',\n          key='foo',\n          asTextOutput='void foo(typename T, int x = 5)')\n"], "sample_983": ["def test_row_swap():\n    M = SparseMatrix([[1, 2], [3, 4]])\n    M.row_swap(0, 1)\n    assert M == SparseMatrix([[3, 4], [1, 2]])\n"], "sample_273": ["    def test_duplicate_db_table_names(self):\n        with override_settings(DATABASE_ROUTERS=[('check_framework.routers.EmptyRouter',)],\n                               DATABASES={'default': {'ENGINE': 'django.db.backends.sqlite3'}}), \\\n                modify_settings(INSTALLED_APPS=['check_framework.tests.duplicate_tables']):\n            from check_framework.tests.duplicate_tables import DuplicateTableApp\n            errors = DuplicateTableApp.check(databases=['default'])\n            self.assertEqual(len(errors), 1)\n            self.assertIsInstance(errors[0], Error)\n            self.assertIn(\"Duplicate table name 'duplicate_table'\", errors[0].msg)\n"], "sample_1152": ["    def test_powdenest_polar():\n        p = Symbol('p', polar=True)\n        assert powdenest(p**2) == p**2\n        assert powdenest((p**2)**3) == p**6\n        assert powdenest((p**2)**(S.Half)) == p\n        assert powdenest((p**2)**(-S.Half)) == 1/p\n        assert powdenest(p**(2*I)) == p**(2*I)\n        assert powdenest((p**(2*I))**3) == p**(6*I)\n"], "sample_1049": ["def test_plane_projection_line():\n    p1 = Point3D(1, 1, 1)\n    p2 = Point3D(2, 2, 2)\n    p3 = Point3D(3, 3, 3)\n    l = Line3D(p1, p2)\n    pl = Plane(p1, p2, p3)\n    assert pl.projection_line(l) == Point3D(1, 1, 1)\n"], "sample_706": ["    def test_not_expr_parentheses(self) -> None:\n        assert evaluate(\"not (foo)\", lambda x: x == \"bar\") is True\n        assert evaluate(\"not(foo)\", lambda x: x == \"foo\") is True\n"], "sample_789": ["    def test_ada_boost_regressor_sparse_input(self):\n        # Check if AdaBoostRegressor works with sparse input\n        X_sparse = csc_matrix(boston.data)\n        y = boston.target\n\n        regressor = AdaBoostRegressor(random_state=rng)\n        regressor.fit(X_sparse, y)\n        y_pred = regressor.predict(X_sparse)\n\n        assert_equal(len(y_pred), len(y))\n"], "sample_383": ["    def test_related_in_with_multi_column_pk(self):\n        # Regression test for #23605\n        a = Ticket23605A.objects.create(name=\"a\")\n        b = Ticket23605B.objects.create(name=\"b\", a=a)\n        c1 = Ticket23605C.objects.create(name=\"c1\", b=b)\n        c2 = Ticket23605C.objects.create(name=\"c2\", b=b)\n\n        qs = Ticket23605C.objects.filter(b__a__in=[a.pk])\n        self.assertQuerysetEqual(qs, [c1, c2], transform=lambda o: o.pk)\n\n        qs = Ticket23605C.objects.filter(b__a__in=[a])\n        self.assertQuerysetEqual(qs, [c1, c2], transform=lambda o: o.pk)\n"], "sample_105": ["    def test_view_setup(self):\n        view = SimpleView()\n        request = self.rf.get('/')\n        view.setup(request)\n        self.assertEqual(view.request, request)\n        self.assertEqual(view.args, ())\n        self.assertEqual(view.kwargs, {})\n"], "sample_592": ["    def test_format_timedelta(self):\n        t = pd.Timedelta(days=1, hours=2, minutes=30)\n        assert formatting.format_timedelta(t) == \"1 days 02:30:00\"\n        assert formatting.format_timedelta(t, timedelta_format=\"date\") == \"1 days\"\n        assert formatting.format_timedelta(t, timedelta_format=\"time\") == \"02:30:00\"\n        assert formatting.format_timedelta(pd.NaT) == \"NaT\"\n"], "sample_845": ["    def test_tfidfvectorizer_vocabulary_deprecation(self):\n        # Check that setting vocabulary after fit raises a warning\n        vectorizer = TfidfVectorizer()\n        vectorizer.fit(ALL_FOOD_DOCS)\n        with warnings.catch_warnings(record=True) as w:\n            vectorizer.vocabulary_ = {'test': 0}\n            assert len(w) == 1\n            assert issubclass(w[0].category, DeprecationWarning)\n"], "sample_420": ["    def test_modelform_with_custom_error_messages(self):\n        form = CustomErrorMessageForm(data={'name1': 'invalid'})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors['name1'], ['Form custom error message.'])\n"], "sample_515": ["def test_colorbar_tick_locator_formatter():\n    fig, ax = plt.subplots()\n    norm = Normalize(vmin=0, vmax=10)\n    cmap = plt.get_cmap('viridis')\n    cb = fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap), ax=ax)\n\n    # Test default tick locator and formatter\n    assert isinstance(cb.ax.yaxis.get_major_locator(), mticker.MaxNLocator)\n    assert isinstance(cb.ax.yaxis.get_major_formatter(),\n                      mticker.ScalarFormatter)\n\n    # Test setting custom tick locator and formatter\n    cb.set_ticks([0, 5, 10])\n    cb.set_ticklabels(['Low', 'Medium', 'High'])\n\n    assert np.allclose(cb.ax.yaxis.get_majorticklocs(), [0, 5, 10])\n    assert [t.get_text() for t in cb.ax.yaxis.get_majorticklabels()] == \\\n        ['Low', 'Medium', 'High']\n\n"], "sample_851": ["    def test_mean_tweedie_deviance_power_zero():\n        y_true = np.array([2, 0, 1, 4])\n        y_pred = np.array([0.5, 0.5, 2., 2.])\n        assert_almost_equal(mean_tweedie_deviance(y_true, y_pred, power=0),\n                            mean_squared_error(y_true, y_pred))\n"], "sample_1138": ["    def test_TR111():\n        assert TR111(sin(x)**2 + cos(x)**2) == 1\n        assert TR111(sin(x)**2 + cos(x)**2 + sin(y)**2) == 1 + sin(y)**2\n        assert TR111(sin(x)**2 + cos(x)**2 + sin(y)**2 + cos(y)**2) == 2\n"], "sample_878": ["    def test_sparse_output_threshold(self):\n        X = np.array([[1, 2], [3, 4], [5, 6]])\n        sparse_X = sparse.csr_matrix(X)\n\n        # Test with sparse_threshold=0.5\n        ct = ColumnTransformer(\n            transformers=[\n                ('trans1', Trans(), [0]),\n                ('trans2', Trans(), [1]),\n            ],\n            sparse_threshold=0.5,\n        )\n        ct.fit(sparse_X)\n        result = ct.transform(sparse_X)\n        assert isinstance(result, sparse.csr_matrix)\n\n        # Test with sparse_threshold=0\n        ct = ColumnTransformer(\n            transformers=[\n                ('trans1', Trans(), [0]),\n                ('trans2', Trans(), [1]),\n            ],\n            sparse_threshold=0,\n        )\n        ct.fit(sparse_X)\n        result = ct.transform(sparse_X)\n        assert isinstance(result, np.ndarray)\n\n"], "sample_422": ["    def test_prefetch_related_with_reverse_fk_and_filter(self):\n        with ignore_warnings(category=RemovedInDjango50Warning):\n            with CaptureQueriesContext(connection) as queries:\n                authors = Author.objects.prefetch_related('book_set').filter(\n                    book_set__title='Jane Eyre'\n                )\n                self.assertEqual(len(queries.captured_queries), 2)\n                self.assertWhereContains(queries.captured_queries[1]['sql'], 'book_set.title')\n                self.assertEqual(len(authors), 1)\n                self.assertEqual(authors[0].name, 'Charlotte')\n"], "sample_943": ["def test_apidoc_exclude_package(apidoc):\n    assert not (apidoc.outdir / 'package_a.rst').exists()\n"], "sample_1064": ["def test_tensorflow_piecewise():\n    x = Symbol('x')\n    expr = Piecewise((x, x < 0), (x**2, x >= 0))\n    _compare_tensorflow_scalar([x], expr)\n"], "sample_35": ["    def test_find_mod_objs_onlylocals_list():\n        class MyMod:\n                self.a = 1\n                self.b = 2\n\n                pass\n\n        MyMod.myfunc = introspection.resolve_name('astropy.utils.introspection.find_mod_objs')\n        mod = MyMod()\n        localnames, fqnames, objs = introspection.find_mod_objs('MyMod', onlylocals=['MyMod'])\n        assert localnames == ['a', 'b', 'myfunc']\n        assert fqnames == ['MyMod.a', 'MyMod.b', 'astropy.utils.introspection.find_mod_objs']\n        assert objs == [mod.a, mod.b, mod.myfunc]\n"], "sample_115": ["    def test_callable_setting_wrapper_repr(self):\n        class MySetting:\n                return 'MySetting()'\n\n        wrapped_setting = CallableSettingWrapper(MySetting())\n        self.assertEqual(repr(wrapped_setting), 'MySetting()')\n"], "sample_767": ["    def test_column_transformer_sparse_output(self):\n        X = np.array([[1, 2], [3, 4], [5, 6]])\n        ct = ColumnTransformer([\n            ('scaler', StandardScaler(), [0]),\n            ('passthrough', 'passthrough', [1])\n        ], sparse_threshold=0.5)\n        X_t = ct.fit_transform(X)\n        assert isinstance(X_t, sparse.csr_matrix)\n        assert_allclose_dense_sparse(X_t.toarray(),\n                                     ct.fit_transform(X).toarray())\n\n        ct = ColumnTransformer([\n            ('scaler', StandardScaler(), [0]),\n            ('passthrough', 'passthrough', [1])\n        ], sparse_threshold=0)\n        X_t = ct.fit_transform(X)\n        assert isinstance(X_t, np.ndarray)\n        assert_allclose_dense_sparse(X_t,\n                                     ct.fit_transform(X))\n"], "sample_872": ["    def test_top_k_accuracy_score_multiclass_labels_provided(self):\n        y_true = np.array([0, 1, 2, 2])\n        y_score = np.array([[0.5, 0.2, 0.2],\n                           [0.3, 0.4, 0.2],\n                           [0.2, 0.4, 0.3],\n                           [0.7, 0.2, 0.1]])\n        labels = [0, 1, 2]\n        score = top_k_accuracy_score(y_true, y_score, k=2, labels=labels)\n        assert_almost_equal(score, 0.75)\n"], "sample_622": ["    def test_encode_decode_bool_array_with_fill_value(self):\n        data = np.array([True, False, True, False], dtype=bool)\n        var = Variable([\"x\"], data, attrs={\"fill_value\": False})\n        ds = Dataset({\"foo\": var})\n        encoded = conventions.encode_cf_variable(var)\n        assert encoded.dtype == np.dtype(\"i1\")\n        assert encoded.attrs[\"dtype\"] == \"bool\"\n        assert encoded.attrs[\"_FillValue\"] == 0\n        decoded = conventions.decode_cf_variable(encoded)\n        assert_identical(decoded, var)\n"], "sample_442": ["    def test_timestamp_signer_max_age(self):\n        signer = signing.TimestampSigner()\n        with freeze_time(\"2023-01-01 00:00:00\"):\n            signed_value = signer.sign(\"test\")\n        with freeze_time(\"2023-01-01 00:00:10\"):\n            # Should raise SignatureExpired\n            with self.assertRaises(signing.SignatureExpired):\n                signer.unsign(signed_value, max_age=5)\n            # Should succeed\n            signer.unsign(signed_value, max_age=15)\n\n"], "sample_596": ["    def test_concat_dataarray_coords_override():\n        # Test concatenating DataArrays with different coordinates, using\n        # compat='override'\n        data = np.arange(12).reshape(3, 4)\n        coords1 = {'x': np.arange(3), 'y': np.arange(4)}\n        coords2 = {'x': np.arange(3) + 1, 'y': np.arange(4) + 1}\n        da1 = DataArray(data, coords=coords1)\n        da2 = DataArray(data, coords=coords2)\n\n        expected_coords = {'x': np.arange(3), 'y': np.arange(4)}\n        expected_data = np.concatenate([data, data], axis=0)\n        expected = DataArray(expected_data, coords=expected_coords)\n\n        actual = concat([da1, da2], dim='z', compat='override')\n        assert_identical(actual, expected)\n"], "sample_179": ["    def test_index_together_with_invalid_field(self):\n        class MyModel(models.Model):\n            name = models.CharField(max_length=100)\n            invalid_field = 'invalid'\n\n            class Meta:\n                index_together = [('name', 'invalid_field')]\n\n        errors = MyModel.check()\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertIn(\"'index_together' refers to the nonexistent field 'invalid_field'\", str(errors[0]))\n"], "sample_784": ["    def test_calibration_curve_multiclass():\n        X, y = make_classification(n_samples=100, n_features=20,\n                                   n_informative=10, n_classes=3,\n                                   random_state=42)\n        clf = RandomForestClassifier(random_state=42)\n        clf.fit(X, y)\n        y_prob = clf.predict_proba(X)\n\n        prob_true, prob_pred = calibration_curve(y, y_prob[:, 1],\n                                                 n_bins=5, strategy='uniform')\n        assert_equal(len(prob_true), len(prob_pred))\n        assert_greater(len(prob_true), 0)\n"], "sample_753": ["    def test_logistic_regression_cv_multiclass_ovr_sparse_input():\n        # Test LogisticRegressionCV with sparse input and multiclass\n        # classification using 'ovr' strategy.\n        X, y = make_classification(n_samples=100, n_features=20,\n                                   n_informative=10, n_classes=3,\n                                   random_state=42)\n        X_sp = sp.csr_matrix(X)\n        clf = LogisticRegressionCV(solver='lbfgs', multi_class='ovr',\n                                   cv=StratifiedKFold(n_splits=5),\n                                   random_state=42).fit(X_sp, y)\n        check_predictions(clf, X_sp, y)\n"], "sample_1085": ["def test_sympify_mpq():\n    assert sympify(mpq(1, 2)) == Rational(1, 2)\n    assert sympify(mpq(3, 4)) == Rational(3, 4)\n    assert sympify(mpq(-5, 6)) == Rational(-5, 6)\n"], "sample_207": ["    def test_key_transform_isnull_with_null_value(self):\n        model = JSONModel.objects.create(data={'key': None})\n        self.assertTrue(JSONModel.objects.filter(data__key__isnull=True).exists())\n        self.assertFalse(JSONModel.objects.filter(data__key__isnull=False).exists())\n"], "sample_470": ["    def test_lazy_str(self):\n        called = [False]\n\n            called[0] = True\n            return \"Hello, world!\"\n\n        lazy_str = lazystr(get_text)\n        self.assertFalse(called[0])\n        self.assertEqual(str(lazy_str), \"Hello, world!\")\n        self.assertTrue(called[0])\n"], "sample_1141": ["def test_MatrixElement_add():\n    M = MatrixSymbol('M', 2, 2)\n    i, j = symbols('i j', integer=True)\n    e = MatrixElement(M, i, j)\n    assert e + e == 2*e\n    assert e + 1 == 1 + e\n    assert e + MatrixElement(M, i, j) == 2*e\n    raises(TypeError, lambda: e + 2*M)\n"], "sample_720": ["    def test_quantile_transform_sparse_matrix_with_zeros(self):\n        X = sparse.csr_matrix([[1, 0, 2], [0, 3, 0], [4, 0, 6]])\n        qt = QuantileTransformer(n_quantiles=3, output_distribution='uniform')\n        X_trans = qt.fit_transform(X)\n        assert_true(sparse.issparse(X_trans))\n        assert_array_equal(X_trans.data,\n                           np.array([0.5, 1., 0.5, 1., 0.5, 1.]))\n"], "sample_1181": ["    def test_array_diagonal(self):\n        A = Array([[1, 2], [3, 4]])\n        expr = ArrayDiagonal(A, (0, 1))\n        printer = NumPyPrinter()\n        code = printer.doprint(expr)\n        assert code == 'numpy.diagonal(A, 0, axis1=0, axis2=1)'\n"], "sample_296": ["    def test_cookie_storage_max_size(self):\n        storage = self.storage_class(self.request)\n        messages = [Message(level=constants.DEBUG, message='message 1', extra_tags=['tag1']),\n                    Message(level=constants.INFO, message='message 2', extra_tags=['tag2']),\n                    Message(level=constants.WARNING, message='message 3', extra_tags=['tag3']),\n                    Message(level=constants.ERROR, message='message 4', extra_tags=['tag4']),\n                    Message(level=constants.SUCCESS, message='message 5', extra_tags=['tag5'])]\n        set_cookie_data(storage, messages)\n\n        response = self.client.get('/')\n        self.assertEqual(stored_cookie_messages_count(storage, response), 5)\n\n        # Add enough messages to exceed the max cookie size\n        for i in range(100):\n            messages.append(Message(level=constants.DEBUG, message=f'message {i+6}', extra_tags=[f'tag{i+6}']))\n        set_cookie_data(storage, messages)\n\n        response = self.client.get('/')\n        self.assertLess(stored_cookie_messages_count(storage, response), len(messages))\n"], "sample_159": ["    def test_user_model_username_field_not_in_required_fields(self):\n        with override_settings(AUTH_USER_MODEL='auth_tests.CustomUserUsernameFieldNotInRequiredFields'):\n            errors = check_user_model(app_configs=self.apps)\n            self.assertEqual(len(errors), 0)\n"], "sample_1159": ["def test_failing_assumptions_with_symbols():\n    x = Symbol('x', real=True)\n    y = Symbol('y', positive=True)\n    assert failing_assumptions(x*y, positive=True) == {'positive': None}\n    assert failing_assumptions(x + y, positive=True) == {'positive': None}\n    assert failing_assumptions(x**2, positive=True) == {}\n"], "sample_1057": ["    def test_render_as_module_fully_qualified():\n        code = Print(1)\n        expected = \"\"\"import sympy\n"], "sample_430": ["    def test_rabbit_circular_fk(self):\n        knight = Knight.objects.create()\n        rabbit1 = Rabbit.objects.create(knight=knight)\n        with self.assertRaises(IntegrityError):\n            Rabbit.objects.create(knight=knight, parent=rabbit1)\n"], "sample_1088": ["    def test_symmetrize_formal(self):\n        F = x**2 + y**2\n        sym, polys = symmetrize(F, formal=True)\n        assert sym == (s1**2 - 2*s2, 0)\n        assert polys == [(s1, x + y), (s2, x*y)]\n"], "sample_964": ["def test_parse_annotation():\n    assert _parse_annotation('int') == ('int', None)\n    assert _parse_annotation('str') == ('str', None)\n    assert _parse_annotation('list[int]') == ('list', ('int',))\n    assert _parse_annotation('dict[str, int]') == ('dict', ('str', 'int'))\n    assert _parse_annotation('Tuple[int, str]') == ('Tuple', ('int', 'str'))\n    assert _parse_annotation('Callable[[int], str]') == ('Callable', (('int',), 'str'))\n    assert _parse_annotation('Optional[int]') == ('Optional', ('int',))\n    assert _parse_annotation('Union[int, str]') == ('Union', ('int', 'str'))\n    assert _parse_annotation('Any') == ('Any', None)\n"], "sample_294": ["    def test_csrf_exempt_view_does_not_require_token(self):\n        request = self._get_POST_no_csrf_cookie_request()\n        response = csrf_exempt(token_view)(request)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.content, b'OK')\n"], "sample_739": ["    def test_label_binarize_multioutput_error(self):\n        y = np.array([[1, 2], [3, 4]])\n        assert_raises(ValueError, label_binarize, y, classes=[1, 2, 3, 4],\n                      multi_output='raw_values')\n"], "sample_1090": ["    def test_sympify_complex():\n        assert sympify(complex(1, 2)) == 1 + 2*S.ImaginaryUnit\n        assert sympify(complex(0, 2)) == 2*S.ImaginaryUnit\n        assert sympify(complex(-1, 2)) == -1 + 2*S.ImaginaryUnit\n        assert sympify(complex(1, -2)) == 1 - 2*S.ImaginaryUnit\n        assert sympify(complex(-1, -2)) == -1 - 2*S.ImaginaryUnit\n"], "sample_432": ["    def test_get_ordering_field_from_request(self):\n        request = self.factory.get(reverse(\"admin:admin_changelist\", args=(\"auth\", \"user\",)))\n        request.GET = {ORDER_VAR: \"username\"}\n        with self.settings(USE_TZ=True):\n            admin_site = admin.AdminSite()\n            admin_site.register(User)\n            cl = admin_site._build_change_list(request, User)\n            self.assertEqual(cl.ordering, (\"username\",))\n\n"], "sample_932": ["def test_cpp_enum_scoped():\n    check(\n        'enum',\n        'enum { A, B, C };',\n        {1: 'enum'},\n        output='enum { A, B, C }',\n        key='enum',\n        asTextOutput='enum { A, B, C }'\n    )\n"], "sample_687": ["    def test_log_records_for_sublogger(self, testdir: Testdir) -> None:\n        testdir.makepyfile(\n            \"\"\"\n            import logging\n\n            logger = logging.getLogger(__name__)\n            sublogger = logging.getLogger(__name__ + \".baz\")\n\n                sublogger.info(\"hello from sublogger\")\n                logger.info(\"hello from logger\")\n\n            test_something()\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.assert_outcomes(passed=1)\n        log_records = result.getfixturevalue(caplog_records_key)[\"call\"]\n        assert len(log_records) == 2\n        assert log_records[0].name == __name__ + \".baz\"\n        assert log_records[1].name == __name__\n"], "sample_967": ["def test_mathjax_config(app, status, warning):\n    app.builder.build_all()\n    out = (app.outdir / 'index.html').read_text()\n    assert '<script src=\"' + MATHJAX_URL + '\" defer></script>' in out\n    assert '<script type=\"text/x-mathjax-config\">' in out\n    assert 'MathJax.Hub.Config' in out\n"], "sample_686": ["    def test_deprecated_node_use_from_parent(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            class MyNode(pytest.Node):\n                pass\n\n                node = MyNode()\n                assert isinstance(node, pytest.Node)\n            \"\"\"\n        )\n        with warnings.catch_warnings(record=True) as record:\n            testdir.runpytest()\n        assert len(record) == 1\n        assert (\n            record[0].message.args[0]\n            == \"Direct construction of MyNode has been deprecated, please use MyNode.from_parent.\\n\"\n            \"See \"\n            \"https://docs.pytest.org/en/stable/deprecations.html#node-construction-changed-to-node-from-parent\"\n            \" for more details.\"\n        )\n"], "sample_869": ["    def test_brier_score_loss_multiclass():\n        y_true = np.array([0, 1, 2, 0])\n        y_prob = np.array([[0.1, 0.2, 0.7],\n                           [0.8, 0.1, 0.1],\n                           [0.2, 0.6, 0.2],\n                           [0.9, 0.05, 0.05]])\n        score = brier_score_loss(y_true, y_prob)\n        assert_almost_equal(score, 0.475)\n\n"], "sample_938": ["    def test_default_man_pages(app: Sphinx, status, warning) -> None:\n        app.config.master_doc = 'index'\n        app.config.project = 'Test Project'\n        app.config.release = '1.0'\n        app.config.author = 'Test Author'\n        default_man_pages(app.config)\n        assert app.config.man_pages == [('index', 'Test Project', 'Test Project 1.0', ['Test Author'], 1)]\n"], "sample_326": ["    def test_urlize_nofollow(self):\n        self.check_output(\n            urlize,\n            'Go to <a href=\"http://www.djangoproject.com\">Django</a>!',\n            'Go to <a href=\"http://www.djangoproject.com\">Django</a>!',\n        )\n        self.check_output(\n            urlize,\n            'Go to <a href=\"http://www.djangoproject.com\">Django</a>!',\n            'Go to <a href=\"http://www.djangoproject.com\" rel=\"nofollow\">Django</a>!',\n            nofollow=True,\n        )\n"], "sample_663": ["    def test_in_venv(self, tmpdir):\n        venv = tmpdir.mkdir(\"venv\")\n        venv.join(\"bin\").ensure(dir=True)\n        venv.join(\"Scripts\").ensure(dir=True)\n        assert _in_venv(venv)\n        assert not _in_venv(tmpdir)\n"], "sample_474": ["    def test_chr(self):\n        with register_lookup(Chr.lookup_name, Chr):\n            self.assertEqual(\n                Author.objects.filter(name__chr__exact=Chr(65)).count(), 1\n            )\n"], "sample_31": ["    def test_write_latex_cls(self, cosmo, tmp_path):\n        \"\"\"Test writing with different table classes.\"\"\"\n        for cls in [QTable, Table]:\n            with tmp_path.joinpath(\"test.tex\").open(\"w\") as f:\n                write_latex(cosmo, f, cls=cls)\n"], "sample_212": ["    def test_session_middleware_empty_session(self):\n        request = HttpRequest()\n        response = HttpResponse()\n        request.COOKIES = {settings.SESSION_COOKIE_NAME: 'some-session-key'}\n        request.session = self.SessionStore('some-session-key')\n        request.session.clear()\n        middleware = SessionMiddleware()\n        middleware.process_response(request, response)\n        self.assertFalse(settings.SESSION_COOKIE_NAME in response.cookies)\n"], "sample_54": ["    def test_file_response_with_filename(self):\n        with tempfile.NamedTemporaryFile(mode='w+t') as f:\n            f.write('Hello, world!')\n            f.seek(0)\n            response = FileResponse(f, filename='test.txt')\n            self.assertEqual(response['Content-Disposition'], 'attachment; filename=\"test.txt\"')\n            self.assertEqual(response['Content-Type'], 'text/plain')\n"], "sample_341": ["    def test_formset_factory_absolute_max(self):\n        formset_class = formset_factory(FavoriteDrinkForm, max_num=5, absolute_max=3)\n        formset = formset_class(data={'form-0-name': 'Coke', 'form-1-name': 'Pepsi', 'form-2-name': 'Sprite'})\n        self.assertTrue(formset.is_valid())\n        self.assertEqual(len(formset.cleaned_data), 3)\n\n        formset = formset_class(data={'form-0-name': 'Coke', 'form-1-name': 'Pepsi', 'form-2-name': 'Sprite', 'form-3-name': 'Dr Pepper'})\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(len(formset.cleaned_data), 3)\n\n        formset = formset_class(data={'form-0-name': 'Coke', 'form-1-name': 'Pepsi', 'form-2-name': 'Sprite', 'form-3-name': 'Dr Pepper', 'form-4-name': 'Fanta'})\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(len(formset.cleaned_data), 3)\n"], "sample_652": ["    def test_getfixtureinfo_raises_FixtureLookupError_for_nonexistent_fixture(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n                pass\n        \"\"\"\n        )\n        with pytest.raises(FixtureLookupError):\n            testdir.getfixtureinfo(testdir.getpytestpath(\"test_func\"))\n"], "sample_570": ["    def test_kde_cumulative(self, x, rng):\n        kde = KDE(cumulative=True)\n        density, support = kde(x)\n        assert density.min() >= 0\n        assert density.max() <= 1\n        assert_array_almost_equal(density[-1], 1)\n        assert_array_almost_equal(\n            self.integrate(density, support), 1, decimal=2\n        )\n"], "sample_51": ["    def test_parse_datetime_with_timezone(self):\n        dt_str = '2023-10-27T12:34:56+02:00'\n        dt = parse_datetime(dt_str)\n        self.assertEqual(dt.year, 2023)\n        self.assertEqual(dt.month, 10)\n        self.assertEqual(dt.day, 27)\n        self.assertEqual(dt.hour, 12)\n        self.assertEqual(dt.minute, 34)\n        self.assertEqual(dt.second, 56)\n        self.assertEqual(dt.tzinfo.utcoffset(dt).total_seconds(), 7200)\n"], "sample_384": ["    def test_bulk_update_with_related_objects(self):\n        for note in self.notes:\n            note.tags.add(self.tags[0])\n\n        # Update all notes with a new tag\n        Note.objects.filter(id__in=[n.id for n in self.notes]).update(\n            tags=self.tags[1]\n        )\n\n        # Check that all notes have the new tag\n        for note in self.notes:\n            self.assertEqual(note.tags.all()[0], self.tags[1])\n"], "sample_974": ["    def test_ccode_IndexedBase_contract_False(self):\n        len_y = 5\n        y = IndexedBase('y', shape=(len_y,))\n        t = IndexedBase('t', shape=(len_y,))\n        Dy = IndexedBase('Dy', shape=(len_y-1,))\n        i = Idx('i', len_y-1)\n        e=Eq(Dy[i], (y[i+1]-y[i])/(t[i+1]-t[i]))\n        code = ccode(e.rhs, assign_to=e.lhs, contract=False)\n        assert code == 'Dy[i] = (y[i + 1] - y[i])/(t[i + 1] - t[i]);'\n"], "sample_1099": ["    def test_partial_derivative_expand_product_rule():\n        expr = A(i) * B(j)\n        pd = PartialDerivative(expr, i)\n        pd_expanded = pd._expand_partial_derivative()\n        assert pd_expanded == PartialDerivative(A(i), i) * B(j) + A(i) * PartialDerivative(B(j), i)\n"], "sample_1197": ["    def test_get_dimensional_expr(self):\n        x = Symbol('x')\n        v = Symbol('v')\n        t = Symbol('t')\n        a = Symbol('a')\n        m = Symbol('m')\n\n        expr = m*v**2/2\n        dim = SI.get_dimensional_expr(expr)\n        assert dim == SI.get_quantity_dimension(joule).name\n\n        expr = v*t\n        dim = SI.get_dimensional_expr(expr)\n        assert dim == SI.get_quantity_dimension(meter).name\n\n        expr = a*t**2/2\n        dim = SI.get_dimensional_expr(expr)\n        assert dim == SI.get_quantity_dimension(meter).name\n\n        expr = x**2 + v**2\n        with warns_deprecated_sympy():\n            dim = SI.get_dimensional_expr(expr)\n        assert dim == S.One\n\n"], "sample_480": ["    def test_key_transform_isnull_with_null_value(self):\n        model = JSONModel.objects.create(data={'key': None})\n        self.assertTrue(JSONModel.objects.filter(data__key__isnull=True).exists())\n        self.assertFalse(JSONModel.objects.filter(data__key__isnull=False).exists())\n"], "sample_841": ["    def test_ridge_classifier_cv_sparse(self):\n        X = sp.csr_matrix(np.array([[1, 2], [3, 4], [5, 6]]))\n        y = np.array([0, 1, 0])\n        clf = RidgeClassifierCV(alphas=[0.1, 1.0, 10.0]).fit(X, y)\n        assert clf.coef_.shape == (1, 2)\n"], "sample_1206": ["def test_is_integer():\n    assert S.Pi.is_integer is False\n    assert S.EulerGamma.is_integer is False\n    assert S.GoldenRatio.is_integer is False\n    assert S.ImaginaryUnit.is_integer is False\n    assert S.Infinity.is_integer is False\n    assert S.NegativeInfinity.is_integer is False\n    assert S.NaN.is_integer is False\n    assert (1 + I).is_integer is False\n    assert (1 + S.ImaginaryUnit).is_integer is False\n    assert S.Zero.is_integer is True\n    assert S.One.is_integer is True\n    assert Integer(2).is_integer is True\n    assert Rational(1, 2).is_integer is False\n    assert Float(1.0).is_integer is True\n    assert Float(1.5).is_integer is False\n"], "sample_382": ["    def test_template_changed_resets_loaders(self):\n        reset_loaders = mock.patch('django.template.autoreload.reset_loaders')\n        with reset_loaders as mock_reset_loaders:\n            autoreload.file_changed(\n                Path(EXTRA_TEMPLATES_DIR / 'test.html'),\n                'test.html',\n            )\n        mock_reset_loaders.assert_called_once()\n"], "sample_1008": ["    def test_orientnew_axis(self):\n        N = ReferenceFrame('N')\n        A = N.orientnew('A', 'Axis', [pi/4, N.x + N.y])\n        assert A.dcm(N) == Matrix([[cos(pi/4), -sin(pi/4), 0],\n                                  [sin(pi/4), cos(pi/4), 0],\n                                  [0, 0, 1]])\n"], "sample_472": ["    def test_get_elided_page_range(self):\n        paginator = Paginator(range(100), 10)\n        self.assertEqual(\n            list(paginator.get_elided_page_range(1)),\n            list(range(1, 6)) + [paginator.ELLIPSIS] + list(range(96, 101)),\n        )\n        self.assertEqual(\n            list(paginator.get_elided_page_range(5)),\n            list(range(1, 6)) + [paginator.ELLIPSIS] + list(range(96, 101)),\n        )\n        self.assertEqual(\n            list(paginator.get_elided_page_range(10)),\n            list(range(1, 11)),\n        )\n        self.assertEqual(\n            list(paginator.get_elided_page_range(50)),\n            list(range(1, 4)) + [paginator.ELLIPSIS] + list(range(48, 51)),\n        )\n        self.assertEqual(\n            list(paginator.get_elided_page_range(95)),\n            list(range(1, 4)) + [paginator.ELLIPSIS] + list(range(93, 101)),\n        )\n        self.assertEqual(\n            list(paginator.get_elided_page_range(100)),\n            list(range(1, 11)),\n        )\n"], "sample_24": ["    def test_shape(self):\n        self.check(np.shape)\n"], "sample_1078": ["def test_indexed_free_symbols():\n    i, j = symbols('i j', integer=True)\n    A = IndexedBase('A')\n    B = IndexedBase('B', shape=(3, 3))\n    assert A[i, j].free_symbols == {A, i, j}\n    assert B[i, j].free_symbols == {B, i, j}\n    assert IndexedBase('C', shape=(i, j)).free_symbols == {i, j}\n"], "sample_1052": ["def test_codegen_indexed_base():\n    x, y = symbols('x y')\n    A = IndexedBase('A')\n    expr = Eq(A[x], x*y)\n    routine = make_routine('test', expr)\n    code = get_string(CCodeGen().dump_c, [routine])\n    assert 'A[x]' in code\n\n"], "sample_1000": ["def test_octave_code_piecewise_inline():\n    pw = Piecewise((x + 1, x > 0), (x, True))\n    assert octave_code(pw, assign_to=x, inline=False) == \\\n        'if (x > 0)\\n' \\\n        '    x = x + 1;\\n' \\\n        'else\\n' \\\n        '    x = x;\\n' \\\n        'end'\n"], "sample_455": ["    def test_unique_constraint_with_expressions_and_condition(self):\n        with atomic():\n            UniqueConstraintProduct.objects.create(name=\"Product 1\", price=10)\n            with self.assertRaises(IntegrityError):\n                UniqueConstraintProduct.objects.create(\n                    name=\"Product 2\", price=10, condition=True\n                )\n"], "sample_537": ["    def test_stride_windows_1d(self):\n        x = np.arange(100)\n        NFFT = 32\n        noverlap = 16\n        result = mlab._stride_windows(x, NFFT, noverlap)\n        target = self.calc_window_target(x, NFFT, noverlap)\n        assert_array_almost_equal(result, target)\n"], "sample_1161": ["def test_print_NDimArray():\n    a = NDimArray([1, 2, 3])\n    assert sstr(a) == 'NDimArray([1, 2, 3])'\n"], "sample_924": ["def test_cpp_function_template():\n    check('function',\n          'void foo(int a, typename T::type b);',\n          {1: 'foo'},\n          'void foo(int a, typename T::type b)',\n          key='foo')\n"], "sample_834": ["    def test_nca_warm_start(self):\n        nca = NeighborhoodComponentsAnalysis(n_components=2, init='pca',\n                                            warm_start=True, random_state=rng)\n        nca.fit(iris_data[:50], iris_target[:50])\n        nca.fit(iris_data, iris_target)\n        assert_equal(nca.components_.shape, (2, 4))\n"], "sample_818": ["    def test_spectral_clustering_precomputed(self):\n        # Test spectral clustering with a precomputed affinity matrix\n        random_state = check_random_state(0)\n        n_samples = 20\n        n_clusters = 3\n        X, _ = make_blobs(n_samples=n_samples, centers=n_clusters,\n                          random_state=random_state)\n        affinity_matrix = pairwise_distances(X)\n        affinity_matrix = np.exp(-affinity_matrix ** 2 / (2. * 1.0 ** 2))\n        sc = SpectralClustering(n_clusters=n_clusters, affinity='precomputed',\n                               random_state=random_state,\n                               assign_labels='kmeans')\n        labels = sc.fit_predict(affinity_matrix)\n        assert_equal(len(np.unique(labels)), n_clusters)\n"], "sample_876": ["    def test_partial_fit(self, X, y):\n        # Test partial_fit for both classification and regression\n        mlp = MLPClassifier(\n            hidden_layer_sizes=(10,),\n            max_iter=10,\n            random_state=1,\n            solver=\"sgd\",\n            learning_rate=\"constant\",\n            learning_rate_init=0.01,\n        )\n\n        # Fit on a subset of the data\n        mlp.partial_fit(X[:50], y[:50])\n\n        # Fit on the remaining data\n        mlp.partial_fit(X[50:], y[50:])\n\n        # Check if the model has converged\n        assert mlp.n_iter_ < mlp.max_iter\n\n"], "sample_618": ["    def test_apply_ufunc_scalar(self, func, expected_result):\n        da = xr.DataArray([1, 2], dims=[\"x\"])\n        result = apply_ufunc(func, da, 2)\n        assert_identical(result, expected_result)\n"], "sample_664": ["    def test_deprecated_external_plugins(self):\n        with pytest.raises(PytestDeprecationWarning) as excinfo:\n            deprecated.DEPRECATED_EXTERNAL_PLUGINS.add(\"pytest_foo\")\n        assert \"pytest_foo\" in str(excinfo.value)\n"], "sample_573": ["    def test_polyfit(self, df):\n        df[\"x\"] = np.linspace(0, 10, len(df))\n        df[\"y\"] = df[\"x\"]**2 + np.random.normal(0, 1, len(df))\n        groupby = GroupBy(df, [\"color\"])\n        result = PolyFit(order=2)(groupby, \"color\", \"x\", {})\n        assert isinstance(result, pd.DataFrame)\n        assert \"x\" in result.columns\n        assert \"y\" in result.columns\n"], "sample_689": ["    def test_deprecated_collect_module(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n                pass\n\n            pytest.collect.test_foo()\n        \"\"\"\n        )\n        with warnings.catch_warnings(record=True) as record:\n            pytester.runpytest()\n        assert any(\n            deprecated.PYTEST_COLLECT_MODULE.match(str(w.message))\n            for w in record\n        )\n"], "sample_503": ["    def test_linestyle_conversion(self, linestyle, expected):\n        line = mlines.Line2D([], [], linestyle=linestyle)\n        assert line._linestyle == expected\n"], "sample_544": ["    def test_pcolorimage_extent(self):\n        # Test that PcolorImage respects the extent argument.\n        fig, ax = plt.subplots()\n        x = np.arange(5)\n        y = np.arange(4)\n        X, Y = np.meshgrid(x, y)\n        data = np.random.rand(4, 5)\n        img = ax.pcolor(X, Y, data, extent=[0, 10, 0, 8])\n        assert img.get_extent() == (0, 10, 0, 8)\n"], "sample_481": ["    def test_join_with_empty_list(self):\n        self.assertEqual(self.engine.render('join01', {'a': []}), '')\n"], "sample_154": ["    def test_check_database_backends_with_databases(self):\n        mock_check = mock.MagicMock()\n        mock_check.return_value = ['issue1', 'issue2']\n        with mock.patch('django.db.connections') as mock_connections:\n            mock_connections.return_value.__getitem__.side_effect = lambda alias: mock.MagicMock(validation=mock.MagicMock(check=mock_check))\n            issues = check_database_backends(databases=self.databases)\n        self.assertEqual(issues, ['issue1', 'issue2', 'issue1', 'issue2'])\n"], "sample_370": ["    def test_prefetch_related_with_reverse_fk_and_filter(self):\n        with CaptureQueriesContext(connection) as queries:\n            # Prefetch authors and filter on a related field\n            authors = Author.objects.prefetch_related('books').filter(books__title='Poems')\n            self.assertQuerySetEqual(authors, [self.author1, self.author2, self.author3])\n            self.assertEqual(len(queries.captured_queries), 2)\n\n"], "sample_1205": ["    def test_gcd_ZZ_non_monic(self):\n        R, x = ring(\"x\", ZZ)\n        f = 2*x**2 + 4*x\n        g = 2*x + 2\n        h = f.gcd(g)\n        assert h == 2*x\n"], "sample_351": ["    def test_modelchoicefield_empty_label(self):\n        class CategoryForm(forms.Form):\n            category = forms.ModelChoiceField(Category.objects.all(), empty_label='Select a category')\n\n        form = CategoryForm()\n        self.assertEqual(form.fields['category'].choices[0][0], '')\n        self.assertEqual(form.fields['category'].choices[0][1], 'Select a category')\n"], "sample_445": ["    def test_timesince_aware_datetime(self):\n        with translation.override('en'):\n            now = timezone.now()\n            past = now - self.oneday\n            self.assertEqual(timesince(past), \"1 day\")\n            self.assertEqual(timesince(past, now=now), \"1 day\")\n            self.assertEqual(timesince(now, now=past), \"1 day\")\n"], "sample_220": ["    def test_set_cookie_expires_naive_datetime(self):\n        response = HttpResponse()\n        expires = datetime(2024, 1, 1, 12, 0, 0)\n        response.set_cookie('test', 'value', expires=expires)\n        self.assertEqual(response.cookies['test']['expires'], http_date(expires.replace(tzinfo=utc)))\n"], "sample_907": ["def test_cpp_enum_scoped():\n    check(\n        \"enum\",\n        \"enum class {a, b};\",\n        {1: \"enum-class-TestDoc-42-1\"},\n        \"enum class {a, b}\",\n        key=\"enum-class\",\n        asTextOutput=\"enum class {a, b}\",\n    )\n"], "sample_325": ["    def test_boundfield_label_tag_with_custom_label_suffix(self):\n        form = PersonNew({'first_name': 'John', 'last_name': 'Doe'})\n        bound_field = form['first_name']\n        label_tag = bound_field.label_tag(label_suffix='*')\n        self.assertIn('John*', label_tag)\n"], "sample_707": ["    def test_iterparentnodeids_empty(self, pytester: Pytester) -> None:\n        item = pytester.makepyfile(\n            \"\"\"\n                pass\n            \"\"\"\n        ).collect()\n        ids = list(nodes.iterparentnodeids(item.nodeid))\n        assert ids == [\"\", \"test_func\"]\n"], "sample_1061": ["def test_Pow_as_content_primitive():\n    x = Symbol('x')\n    assert Pow(2*x + 2, 2).as_content_primitive() == (4, (x + 1)**2)\n    assert Pow(4**( (1 + x)/2), 1).as_content_primitive() == (2, 4**(x/2))\n    assert Pow(3**( (1 + x)/2), 1).as_content_primitive() == (1, 3**((x + 1)/2))\n    assert Pow(3**( (5 + x)/2), 1).as_content_primitive() == (9, 3**((x + 1)/2))\n"], "sample_292": ["    def test_csrf_cookie_domain(self):\n        request = TestingHttpRequest()\n        request.META['HTTP_HOST'] = 'subdomain.example.com'\n        request.META['HTTP_REFERER'] = 'https://subdomain.example.com/path'\n        middleware = CsrfViewMiddleware()\n        response = middleware.process_view(request, None, None, None)\n        self.assertIsNone(response)\n        self.assertEqual(request.META['CSRF_COOKIE'], self._csrf_id_cookie)\n        self.assertTrue(request.csrf_cookie_needs_reset)\n\n"], "sample_287": ["    def test_check_middleware(self):\n        admin_site = AdminSite()\n        admin_site.register(Album, ValidFields)\n\n        middleware = [\n            AuthenticationMiddlewareSubclass,\n            SessionMiddlewareSubclass,\n            MessageMiddlewareSubclass,\n        ]\n        errors = admin_site.check(\n            middleware=middleware,\n        )\n        self.assertEqual(len(errors), 0)\n\n"], "sample_676": ["def test_plugin_nameversions(option):\n    plugininfo = [\n        (\"pytest-xdist\", DistInfo(project_name=\"pytest-xdist\", version=\"1.0.0\")),\n        (\"pytest-cov\", DistInfo(project_name=\"pytest-cov\", version=\"2.0.0\")),\n        (\"pytest-xdist\", DistInfo(project_name=\"pytest-xdist\", version=\"1.0.0\")),\n    ]\n    expected = [\"xdist-1.0.0\", \"cov-2.0.0\"]\n    assert _plugin_nameversions(plugininfo) == expected\n"], "sample_519": ["    def test_figure_dpi_set_get(self):\n        fig = Figure()\n        assert fig.dpi == mpl.rcParams['figure.dpi']\n        fig.dpi = 100\n        assert fig.dpi == 100\n"], "sample_98": ["    def test_server_handles_broken_pipe_error(self):\n        with self.assertRaises(HTTPError) as cm:\n            conn = HTTPConnection(self.live_server_url_test[0])\n            conn.request('GET', '/broken_pipe/')\n            conn.getresponse()\n        self.assertEqual(cm.exception.code, 500)\n"], "sample_525": ["    def test_figure_dpi_set_get(self):\n        fig = Figure()\n        assert fig.dpi == mpl.rcParams['figure.dpi']\n        fig.dpi = 100\n        assert fig.dpi == 100\n"], "sample_416": ["    def test_settings_to_cmd_args_env_with_ssl_options(self):\n        settings_dict = {\n            \"HOST\": \"localhost\",\n            \"PORT\": 5432,\n            \"NAME\": \"mydatabase\",\n            \"USER\": \"myuser\",\n            \"PASSWORD\": \"mypassword\",\n            \"OPTIONS\": {\n                \"sslmode\": \"require\",\n                \"sslrootcert\": \"/path/to/rootcert.pem\",\n                \"sslcert\": \"/path/to/clientcert.pem\",\n                \"sslkey\": \"/path/to/clientkey.pem\",\n            },\n        }\n        args, env = self.settings_to_cmd_args_env(settings_dict)\n        self.assertEqual(\n            args,\n            [\n                \"psql\",\n                \"-U\",\n                \"myuser\",\n                \"-h\",\n                \"localhost\",\n                \"-p\",\n                \"5432\",\n                \"mydatabase\",\n            ],\n        )\n        self.assertEqual(\n            env,\n            {\n                \"PGPASSWORD\": \"mypassword\",\n                \"PGSSLMODE\": \"require\",\n                \"PGSSLROOTCERT\": \"/path/to/rootcert.pem\",\n                \"PGSSLCERT\": \"/path/to/clientcert.pem\",\n                \"PGSSLKEY\": \"/path/to/clientkey.pem\",\n            },\n        )\n"], "sample_546": ["def test_figure_tight_layout():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], [4, 5, 6])\n    fig.tight_layout()\n    assert fig.get_tight_layout() is True\n"], "sample_149": ["    def test_user_model_required_fields_is_tuple(self):\n        with override_settings(AUTH_USER_MODEL='auth_tests.CustomUserTupleRequiredFields'):\n            errors = check_user_model(app_configs=self.apps)\n            self.assertEqual(len(errors), 0)\n"], "sample_902": ["    def test_pipeline_memory_caching(self):\n        # Test that Pipeline caches transformers when memory is given\n        memory = Memory(location=mkdtemp(), verbose=0)\n        X = np.random.randn(10, 5)\n        y = np.random.randn(10)\n\n        # Create a pipeline with a transformer that stores a timestamp\n        # on fit\n        pipeline = Pipeline([('dummy', DummyTransf()),\n                             ('clf', SVC())], memory=memory)\n\n        # First fit should take some time\n        start_time = time.time()\n        pipeline.fit(X, y)\n        fit_time_1 = time.time() - start_time\n\n        # Second fit should be much faster due to caching\n        start_time = time.time()\n        pipeline.fit(X, y)\n        fit_time_2 = time.time() - start_time\n\n        assert fit_time_2 < fit_time_1\n\n        # Clean up the temporary directory\n        shutil.rmtree(memory.location)\n"], "sample_1132": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((1, 2, 3))) == [(1, 2, 3), (-1, 2, 3), (1, -2, 3), (1, 2, -3),\n                                             (-1, -2, 3), (-1, 2, -3), (1, -2, -3), (-1, -2, -3)]\n"], "sample_763": ["    def test_check_consistent_length_sparse_matrix():\n        X = sparse_random_matrix(10, 5, density=0.5)\n        y = np.arange(11)\n        with pytest.raises(ValueError):\n            check_consistent_length(X, y)\n"], "sample_850": ["    def test_nystroem_sparse_input(self):\n        # check if Nystroem works with sparse input\n        X_sparse = csr_matrix(X)\n        nystroem = Nystroem(kernel='rbf', gamma=1., n_components=10)\n        nystroem.fit(X_sparse)\n        X_transformed = nystroem.transform(X_sparse)\n        assert X_transformed.shape == (300, 10)\n"], "sample_56": ["    def test_check_actions_uniqueness(self):\n        class MyAdmin(admin.ModelAdmin):\n            actions = ['action1', 'action1']\n\n        admin_site = AdminSite()\n        admin_site.register(Album, MyAdmin)\n        errors = admin_site.check()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'admin.E130')\n"], "sample_132": ["    def test_callable_setting_wrapper(self):\n        wrapped_callable = CallableSettingWrapper(lambda: 'hello')\n        self.assertEqual(repr(wrapped_callable), '<function <lambda> at 0x...> wrapped')\n"], "sample_883": ["    def test_ard_regression_alpha_lambda_update(self):\n        rng = check_random_state(0)\n        n_samples, n_features = 50, 10\n        X = rng.randn(n_samples, n_features)\n        y = rng.randn(n_samples)\n\n        # Test that alpha and lambda are updated correctly\n        model = ARDRegression(compute_score=True, max_iter=1)\n        model.fit(X, y)\n        assert len(model.scores_) == 1\n        # Check that alpha and lambda are not None\n        assert model.alpha_ is not None\n        assert (model.lambda_ != 0).any()\n\n"], "sample_152": ["    def test_delete_with_fast_delete_and_signals(self):\n        # Create objects\n        a = create_a()\n        b1 = B1.objects.create(a=a)\n        b2 = B2.objects.create(a=a)\n        b3 = B3.objects.create(a=a)\n\n        # Connect signal to track deletions\n        deleted_objects = []\n\n            deleted_objects.append(instance)\n\n        signals.post_delete.connect(track_deletion, sender=B1)\n        signals.post_delete.connect(track_deletion, sender=B2)\n        signals.post_delete.connect(track_deletion, sender=B3)\n\n        # Delete the parent object\n        a.delete()\n\n        # Assert that all related objects were deleted\n        self.assertEqual(len(deleted_objects), 3)\n        self.assertIn(b1, deleted_objects)\n        self.assertIn(b2, deleted_objects)\n        self.assertIn(b3, deleted_objects)\n"], "sample_935": ["def test_cpp_enum_scoped():\n    check(\n        'enum',\n        'enum { A, B, C };',\n        {1: 'enum'},\n        output='enum { A, B, C }',\n        key='enum',\n        asTextOutput='enum { A, B, C }'\n    )\n"], "sample_157": ["    def test_test_db_signature(self):\n        connection = get_connection_copy()\n        creation = BaseDatabaseCreation(connection)\n        original_settings = connection.settings_dict.copy()\n        signature = creation.test_db_signature()\n        self.assertEqual(\n            signature,\n            (\n                original_settings['HOST'],\n                original_settings['PORT'],\n                original_settings['ENGINE'],\n                TEST_DATABASE_PREFIX + original_settings['NAME'],\n            ),\n        )\n"], "sample_611": ["    def test_offset_repr(self, offset, expected_n):\n        assert repr(offset) == f\"{type(offset).__name__}(n={expected_n})\"\n"], "sample_435": ["    def test_creation_form_with_custom_user_model(self):\n        with override_settings(AUTH_USER_MODEL=\"tests.models.custom_user.CustomUser\"):\n            form = UserCreationForm()\n            self.assertEqual(form.fields[\"username\"].widget.attrs[\"autofocus\"], True)\n            self.assertTrue(isinstance(form.fields[\"username\"], UsernameField))\n"], "sample_417": ["    def test_floatformat01(self):\n        with translation.override(\"en-us\"):\n            output = self.engine.render_to_string(\"floatformat01\", {\"a\": 12.345, \"b\": Decimal(\"12.345\")})\n            self.assertEqual(output, \"12.345 12.345\")\n"], "sample_176": ["    def test_rename_field_with_default(self):\n        before_state = self.make_project_state([\n            self.author_name,\n        ])\n        after_state = self.make_project_state([\n            self.author_name_renamed_field,\n        ])\n        changes = self.get_changes(before_state.models, after_state.models)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['RenameField'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name', old_name='old_name')\n\n"], "sample_510": ["    def test_imshow_data_argument():\n        fig, ax = plt.subplots()\n        data = np.random.rand(10, 10)\n        ax.imshow(data, data=data)\n        assert ax.images[0].get_array() is data\n"], "sample_77": ["    def test_urlize_nofollow(self):\n        self.check_output(\n            urlize,\n            'Go to http://www.djangoproject.com for more information.',\n            '<a href=\"http://www.djangoproject.com\" rel=\"nofollow\">http://www.djangoproject.com</a> for more information.'\n        )\n"], "sample_250": ["    def test_format_timezone_aware_datetime(self):\n        dt = make_aware(datetime(2023, 10, 26, 10, 30, 0), get_fixed_timezone(utc))\n        self.assertEqual(format(dt, 'e'), '+0000')\n        self.assertEqual(format(dt, 'O'), '+0000')\n        self.assertEqual(format(dt, 'P'), '10:30 a.m.')\n        self.assertEqual(format(dt, 'T'), 'UTC')\n"], "sample_509": ["    def test_concise_date_formatter_offset(self, tz):\n        fig, ax = plt.subplots()\n        dates = [\n            datetime.datetime(2023, 1, 1, tzinfo=tz),\n            datetime.datetime(2023, 1, 2, tzinfo=tz),\n            datetime.datetime(2023, 1, 3, tzinfo=tz),\n        ]\n        ax.plot(dates, [1, 2, 3])\n        ax.xaxis.set_major_formatter(\n            mdates.ConciseDateFormatter(\n                mdates.AutoDateLocator(), tz=tz,\n                show_offset=True\n            )\n        )\n        fig.canvas.draw()\n        # Check that the offset is displayed correctly\n        for label in ax.get_xticklabels():\n            text = label.get_text()\n            if tz is not None:\n                assert tz.tzname(datetime.datetime.now()) in text\n            else:\n                assert \"UTC\" not in text\n\n"], "sample_447": ["    def test_expression_wrapper_with_annotation(self):\n        # Test that ExpressionWrapper works with annotations\n        queryset = Book.objects.annotate(\n            price_with_tax=ExpressionWrapper(\n                F(\"price\") * Decimal(\"1.06\"), output_field=DecimalField()\n            )\n        )\n        self.assertQuerysetEqual(\n            queryset.order_by(\"price_with_tax\"),\n            [\n                (\"159059725\", Decimal(\"31.86\")),\n                (\"067232959\", Decimal(\"24.59\")),\n                (\"159059996\", Decimal(\"31.46\")),\n                (\"013235613\", Decimal(\"31.46\")),\n                (\"013790395\", Decimal(\"87.77\")),\n                (\"155860191\", Decimal(\"79.50\")),\n            ],\n            lambda b: (b.isbn, b.price_with_tax),\n        )\n\n"], "sample_547": ["    def test_draggable_annotation(self):\n        fig, ax = plt.subplots()\n        x, y = 0.5, 0.5\n        ann = ax.annotate(\"test\", xy=(x, y), xycoords=\"data\",\n                          bbox=dict(boxstyle=\"round\", fc=\"w\"))\n        draggable = DraggableAnnotation(ann)\n        # Simulate a drag event\n        event = MouseEvent('motion_notify_event', fig.canvas, xpress=True,\n                           xdata=x + 0.1, ydata=y + 0.1, button=MouseButton.LEFT)\n        draggable.on_motion(event)\n        assert_allclose(ann.xyann, (x + 0.1, y + 0.1))\n"], "sample_551": ["    def test_poly3dcollection_shade_with_lightsource(self):\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection='3d')\n        verts = [\n            [(0, 0, 0), (1, 0, 0), (1, 1, 0), (0, 1, 0)],\n            [(0, 0, 1), (1, 0, 1), (1, 1, 1), (0, 1, 1)],\n        ]\n        pc = art3d.Poly3DCollection(verts, shade=True,\n                                   lightsource=mcolors.LightSource(azdeg=45, altdeg=45))\n        ax.add_collection3d(pc)\n        ax.set_xlim([0, 1])\n        ax.set_ylim([0, 1])\n        ax.set_zlim([0, 1])\n        plt.draw()\n        # Check if the colors are different\n        assert not same_color(pc.get_facecolor()[0], pc.get_facecolor()[1])\n"], "sample_975": ["    def test_unrad_issue_19681():\n        x, y = symbols('x y')\n        eq = sqrt(x**2 + y**2) - 1\n        sol = unrad(eq)\n        assert sol is not None\n        assert len(sol) == 2\n        assert sol[0].is_Eq\n        assert sol[1] == []\n"], "sample_527": ["    def test_figure_tight_layout(self):\n        fig, ax = plt.subplots()\n        ax.plot([1, 2, 3], [4, 5, 6])\n        fig.tight_layout()\n        # Check if the layout is tight\n        assert fig.bbox_inches.width > 0\n        assert fig.bbox_inches.height > 0\n"], "sample_318": ["compilation error"], "sample_305": ["    def test_window_functions(self):\n        # Test basic window functions\n        self.assertQuerysetEqual(\n            Book.objects.annotate(\n                rank=Window(\n                    expression=Rank(),\n                    partition_by=F('publisher'),\n                    order_by=F('price').desc()\n                )\n            ).filter(rank=1),\n            [\n                '159059725',\n                '013235613',\n                '155860191',\n            ],\n            transform=lambda obj: obj.isbn,\n        )\n\n        # Test window functions with subqueries\n        self.assertQuerysetEqual(\n            Book.objects.annotate(\n                avg_price=Subquery(\n                    Book.objects.filter(publisher=OuterRef('publisher')).values('price').annotate(avg_price=Avg('price'))\n                )\n            ).filter(price__gt=F('avg_price')),\n            [\n                '159059725',\n                '013235613',\n            ],\n            transform=lambda obj: obj.isbn,\n        )\n\n"], "sample_224": ["    def test_coalesce(self):\n        with CaptureQueriesContext(connection) as queries:\n            result = Book.objects.annotate(\n                price_or_zero=Coalesce(F('price'), Value(0, output_field=DecimalField()))\n            ).get(isbn='159059725')\n            self.assertEqual(result.price_or_zero, Decimal('30.00'))\n        self.assertEqual(len(queries), 1)\n\n        with CaptureQueriesContext(connection) as queries:\n            result = Book.objects.annotate(\n                price_or_zero=Coalesce(F('nonexistent_field'), Value(0, output_field=DecimalField()))\n            ).get(isbn='159059725')\n            self.assertEqual(result.price_or_zero, Decimal('0'))\n        self.assertEqual(len(queries), 1)\n"], "sample_134": ["    def test_serialize_lazy_object(self):\n        lazy_object = SimpleLazyObject(lambda: 'lazy_value')\n        serializer = serializer_factory(lazy_object)\n        self.assertEqual(serializer.serialize(), (\"'lazy_value'\", set()))\n"], "sample_209": ["    def test_order_with_respect_to_ordering(self):\n        dept1 = Department.objects.create(name='Dept 1')\n        dept2 = Department.objects.create(name='Dept 2')\n\n        worker1 = Worker.objects.create(name='Worker 1', department=dept1)\n        worker2 = Worker.objects.create(name='Worker 2', department=dept1)\n        worker3 = Worker.objects.create(name='Worker 3', department=dept2)\n\n        # Check initial order\n        self.assertEqual(list(Worker.objects.all().values_list('name', flat=True)), [\n            'Worker 1', 'Worker 2', 'Worker 3',\n        ])\n\n        # Set order for dept1\n        dept1.set_worker_order([worker2.id, worker1.id])\n\n        # Check order for dept1\n        self.assertEqual(list(Worker.objects.filter(department=dept1).values_list('name', flat=True)), [\n            'Worker 2', 'Worker 1',\n        ])\n\n        # Check order for dept2 remains unchanged\n        self.assertEqual(list(Worker.objects.filter(department=dept2).values_list('name', flat=True)), [\n            'Worker 3',\n        ])\n"], "sample_300": ["    def test_join_promotion_with_negated_or(self):\n        # Test join promotion when dealing with negated OR conditions.\n        query = Query(model=Author)\n        query.add_filter(Q(books__title__icontains='Django') | Q(books__title__icontains='Python'))\n        query.add_filter(~Q(books__title__icontains='SQL'))\n        jp = JoinPromoter(OR, 2, True)\n        jp.add_votes(['books'])\n        jp.add_votes(['books'])\n        jp.update_join_types(query)\n        self.assertEqual(query.alias_map['books'].join_type, 'LOUTER')\n"], "sample_492": ["    def test_serialize_operation_with_settings_reference(self):\n        class MyOperation(migrations.Operation):\n                super().__init__()\n                self.setting_name = setting_name\n\n                return (\n                    \"%s.%s\" % (self.__class__.__module__, self.__class__.__name__),\n                    [self.setting_name],\n                    {},\n                )\n\n        operation = MyOperation(\"DATABASE_ROUTERS\")\n        writer = OperationWriter(operation)\n        serialized, _ = writer.serialize()\n        self.assertIn(\"settings.DATABASE_ROUTERS\", serialized)\n"], "sample_822": ["    def test_pairwise_distances_chunked_empty_array(self):\n        X = np.array([])\n        X = X.reshape(0, 10)\n        with pytest.raises(ValueError):\n            list(pairwise_distances_chunked(X))\n"], "sample_587": ["    def test_merge_coords_with_conflicting_dims(self):\n        ds1 = xr.Dataset({'a': (('x',), [1, 2, 3]), 'b': (('y',), [4, 5])})\n        ds2 = xr.Dataset({'a': (('x',), [6, 7, 8]), 'c': (('y',), [9, 10])})\n        with pytest.raises(xr.MergeError):\n            merge([ds1, ds2], compat='equals')\n"], "sample_619": ["    def test_decode_cf_datetime_with_cftime(self):\n        # Test decoding with cftime.Datetime objects\n        dates = cftime_range(\"2000-01-01\", periods=10, freq=\"D\", calendar=\"noleap\")\n        data = Variable([\"time\"], dates)\n        ds = Dataset({\"time\": data})\n        ds.attrs[\"units\"] = \"days since 2000-01-01\"\n        ds.attrs[\"calendar\"] = \"noleap\"\n\n        # Encode and decode\n        encoded = ds.to_netcdf()\n        decoded = Dataset.from_dict(decode_cf(encoded))\n\n        assert_identical(decoded[\"time\"], ds[\"time\"])\n"], "sample_579": ["    def test_clustermap_row_colors(self):\n        data = self.df_norm.copy()\n        row_colors = self.letters.to_frame(name=\"letters\")\n        row_colors[\"color\"] = [\"red\", \"blue\", \"green\", \"purple\"]\n        cm = mat.clustermap(data, row_colors=row_colors,\n                           col_cluster=False,\n                           tree_kws={\"linewidths\": 0})\n        assert_colors_equal(cm.ax_row_colors.collections[0].get_facecolors(),\n                            np.array(row_colors[\"color\"])[:, None])\n"], "sample_173": ["    def test_integer_field_range(self):\n        self.assertEqual(self.ops.integer_field_range('SmallIntegerField'), (-32768, 32767))\n        self.assertEqual(self.ops.integer_field_range('IntegerField'), (-2147483648, 2147483647))\n        self.assertEqual(self.ops.integer_field_range('BigIntegerField'), (-9223372036854775808, 9223372036854775807))\n        self.assertEqual(self.ops.integer_field_range('PositiveBigIntegerField'), (0, 9223372036854775807))\n        self.assertEqual(self.ops.integer_field_range('PositiveSmallIntegerField'), (0, 32767))\n        self.assertEqual(self.ops.integer_field_range('PositiveIntegerField'), (0, 2147483647))\n        self.assertEqual(self.ops.integer_field_range('SmallAutoField'), (-32768, 32767))\n        self.assertEqual(self.ops.integer_field_range('AutoField'), (-2147483648, 2147483647))\n        self.assertEqual(self.ops.integer_field_range('BigAutoField'), (-9223372036854775808, 9223372036854775807))\n"], "sample_94": ["    def test_createsuperuser_interactive_with_password(self):\n        out = StringIO()\n        err = StringIO()\n        with override_settings(AUTH_USER_MODEL='tests.CustomUser'):\n            call_command('createsuperuser', stdout=out, stderr=err, interactive=True)\n        self.assertEqual(out.getvalue().strip(), 'Superuser created successfully.')\n        self.assertEqual(err.getvalue(), '')\n        self.assertEqual(CustomUser.objects.count(), 1)\n        user = CustomUser.objects.get(username='alice')\n        self.assertEqual(user.password, 'password')\n"], "sample_22": ["    def test_is_rotation_improper():\n        # Test for improper rotations (determinant -1)\n        R = np.array([[1, 0, 0], [0, -1, 0], [0, 0, -1]])\n        assert is_rotation(R, allow_improper=True)\n        assert not is_rotation(R)\n"], "sample_302": ["    def test_settings_to_cmd_args_env(self):\n        settings = {\n            'NAME': 'test_db',\n            'USER': 'test_user',\n            'HOST': 'test_host',\n            'PORT': 5432,\n            'PASSWORD': 'test_password',\n            'OPTIONS': {\n                'passfile': '/path/to/passfile',\n                'service': 'test_service',\n                'sslmode': 'require',\n                'sslrootcert': '/path/to/rootcert',\n                'sslcert': '/path/to/cert',\n                'sslkey': '/path/to/key',\n            },\n        }\n        expected_args = [\n            'psql',\n            '-U', 'test_user',\n            '-h', 'test_host',\n            '-p', '5432',\n            'test_db',\n        ]\n        expected_env = {\n            'PGPASSWORD': 'test_password',\n            'PGSERVICE': 'test_service',\n            'PGSSLMODE': 'require',\n            'PGSSLROOTCERT': '/path/to/rootcert',\n            'PGSSLCERT': '/path/to/cert',\n            'PGSSLKEY': '/path/to/key',\n            'PGPASSFILE': '/path/to/passfile',\n        }\n        args, env = DatabaseClient.settings_to_cmd_args_env(settings, [])\n        self.assertEqual(args, expected_args)\n        self.assertEqual(env, expected_env)\n"], "sample_484": ["    def test_right(self):\n        author = Author.objects.get(name=\"John Smith\")\n        self.assertEqual(Right(author.name, 5).evaluate(), \"Smith\")\n        self.assertEqual(Right(author.alias, 2).evaluate(), \"j\")\n        with connection.cursor() as cursor:\n            cursor.execute(\n                \"SELECT RIGHT(name, 5) FROM myapp_author WHERE name = %s\",\n                [\"John Smith\"],\n            )\n            self.assertEqual(cursor.fetchone()[0], \"Smith\")\n"], "sample_297": ["    def test_ticket_23605(self):\n        # Test for ticket #23605: Regression in QuerySet.filter() when using\n        # subqueries with joins.\n\n        # Create some objects for the test.\n        a = Ticket23605A.objects.create(name='a')\n        b = Ticket23605B.objects.create(name='b', a=a)\n        c = Ticket23605C.objects.create(name='c', b=b)\n\n        # This query should return the Ticket23605C object 'c'.\n        qs = Ticket23605C.objects.filter(b__a__name='a')\n        self.assertEqual(qs.count(), 1)\n        self.assertEqual(qs.get().name, 'c')\n"], "sample_742": ["    def test_logistic_regression_cv_multi_class_ovr(self):\n        # Test LogisticRegressionCV with multi_class='ovr' and\n        # different solvers\n        X, y = make_classification(n_samples=100, n_features=20,\n                                   n_informative=10, n_classes=3,\n                                   random_state=42)\n        for solver in ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']:\n            clf = LogisticRegressionCV(multi_class='ovr', solver=solver,\n                                       cv=StratifiedKFold(n_splits=5),\n                                       random_state=42)\n            clf.fit(X, y)\n            check_predictions(clf, X, y)\n"], "sample_380": ["    def test_aggregate_with_filter_on_related_field(self):\n        # Test that filtering on a related field works correctly with aggregates.\n        with CaptureQueriesContext(connection) as queries:\n            result = Book.objects.annotate(\n                avg_rating=Avg('rating'),\n            ).filter(avg_rating__gt=3.5).values('avg_rating')\n            self.assertQuerySetEqual(result, [\n                {'avg_rating': Approximate(Decimal('4.00'), places=2)},\n                {'avg_rating': Approximate(Decimal('4.50'), places=2)},\n            ], transform=lambda x: {'avg_rating': x['avg_rating']})\n            self.assertEqual(len(queries), 2)\n"], "sample_810": ["    def test_pipeline_memory_cache(self):\n        # Test that the pipeline caches the fitted transformers when memory is\n        # provided.\n        cachedir = mkdtemp()\n        memory = Memory(cachedir=cachedir, verbose=0)\n        X = np.array([[1, 2], [3, 4]])\n        y = np.array([0, 1])\n\n        # Create a pipeline with a transformer that stores the timestamp of\n        # its last fit\n        pipeline = Pipeline([('dummy', DummyTransf()), ('clf', SVC())],\n                            memory=memory)\n\n        # First fit\n        pipeline.fit(X, y)\n        timestamp1 = pipeline.named_steps['dummy'].timestamp_\n\n        # Second fit should load the cached transformer\n        pipeline.fit(X, y)\n        timestamp2 = pipeline.named_steps['dummy'].timestamp_\n\n        assert timestamp1 == timestamp2\n\n        shutil.rmtree(cachedir)\n"], "sample_624": ["    def test_diff_array_repr(self, compat):\n        a = xr.DataArray(np.arange(10), dims=\"x\")\n        b = xr.DataArray(np.arange(10) + 1, dims=\"x\")\n        expected = dedent(\n            f\"\"\"\n            Left and right DataArray objects are not {compat.__name__}\n            Differing values:\n            L\n                <xarray.DataArray (x: 10)>\n                array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n            R\n                <xarray.DataArray (x: 10)>\n                array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n            \"\"\"\n        )\n        assert formatting.diff_array_repr(a, b, compat) == expected\n"], "sample_1016": ["def test_octave_code_piecewise_no_default():\n    pw = Piecewise((x + 1, x > 0), (x, x < 0))\n    raises(ValueError, lambda: octave_code(pw))\n\n"], "sample_638": ["def test_run_with_unsupported_format(mock_subprocess, mock_graphviz):\n    with fix_import_path([\"test_module\"]):\n        with mock.patch(\"pylint.pyreverse.writer.DiagramWriter\") as mock_writer:\n            main.Run([\"test_module\", \"-o\", \"XYZ\"]).run([])\n            mock_writer.assert_not_called()\n            mock_subprocess.run.assert_called_once_with(\n                [\"dot\", \"-T\", \"XYZ\", \"-o\", \"test_module.XYZ\", \"test_module.dot\"],\n                capture_output=True,\n                check=True,\n            )\n"], "sample_827": ["    def test_inplace_swap_column_csc(self):\n        X = sp.csc_matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n        inplace_swap_column(X, 0, 2)\n        assert_array_equal(X.toarray(), [[3, 2, 1], [6, 5, 4], [9, 8, 7]])\n\n"], "sample_1032": ["def test_Min_rewrite_as_Heaviside():\n    x, y, z = symbols('x y z')\n    assert Min(x, y, z)._eval_rewrite_as_Heaviside(x, y, z) == x*Heaviside(x - y)*Heaviside(x - z) + y*Heaviside(y - x)*Heaviside(y - z) + z*Heaviside(z - x)*Heaviside(z - y)\n"], "sample_423": ["    def test_rabbit_circular_fk_index(self):\n        knight = Knight.objects.create()\n        rabbit1 = Rabbit.objects.create(knight=knight)\n        rabbit2 = Rabbit.objects.create(knight=knight, parent=rabbit1)\n        self.assertEqual(Rabbit.objects.filter(parent=rabbit1, knight=knight).count(), 1)\n"], "sample_1106": ["    def test_merge_explicit():\n        A = MatrixSymbol('A', 2, 2)\n        B = eye(2)\n        C = Matrix([[1, 2], [3, 4]])\n        X = MatAdd(A, B, C)\n        assert isinstance(X, MatAdd)\n        assert X.args[0] == A\n        assert X.args[1] == C + B\n"], "sample_853": ["    def test_transformer_inverse_check_warning(self):\n        # Check that a warning is raised when check_inverse is True and the\n        # transformer is not strictly inverse\n        transformer = FunctionTransformer(\n            func=lambda x: x**2, inverse_func=lambda x: np.sqrt(x)\n        )\n        regressor = DummyRegressor()\n        with assert_warns_message(\n            \"The provided functions or transformer are not strictly inverse\",\n            UserWarning\n        ):\n            TransformedTargetRegressor(\n                regressor=regressor, transformer=transformer,\n                check_inverse=True\n            ).fit(friedman[0], friedman[1])\n"], "sample_1021": ["def test_quaternion_pow_cos_sin():\n    q = Quaternion(1, 2, 3, 4)\n    assert q.pow_cos_sin(4) == Quaternion(900*cos(4*acos(sqrt(30)/30)), 1800*sqrt(29)*sin(4*acos(sqrt(30)/30))/29, 2700*sqrt(29)*sin(4*acos(sqrt(30)/30))/29, 3600*sqrt(29)*sin(4*acos(sqrt(30)/30))/29)\n"], "sample_933": ["    def test_gettext_catalog(self, app, status, warning):\n        app.build()\n        po_file = os.path.join(app.outdir, 'messages.pot')\n        assert os.path.exists(po_file)\n        with open(po_file, 'r', encoding='utf-8') as f:\n            content = f.read()\n        assert 'msgid \"Hello, world!\"' in content\n        assert 'msgid \"This is a test document.\"' in content\n"], "sample_99": ["    def test_extract_iso_year(self):\n        dt = datetime(2023, 12, 31, tzinfo=datetime_timezone.utc)\n        obj = self.create_model(dt, dt + timedelta(days=1))\n        self.assertEqual(DTModel.objects.filter(start_datetime__iso_year=2023).count(), 1)\n        self.assertEqual(DTModel.objects.filter(start_datetime__iso_year=2024).count(), 0)\n"], "sample_586": ["    def test_concat_dataarray_with_different_coords():\n        a = DataArray(np.arange(4).reshape((2, 2)), dims=[\"x\", \"y\"], coords={\"x\": [0, 1]})\n        b = DataArray(\n            np.arange(4).reshape((2, 2)), dims=[\"x\", \"y\"], coords={\"x\": [2, 3]}\n        )\n        expected = DataArray(\n            np.arange(8).reshape((4, 2)), dims=[\"x\", \"y\"], coords={\"x\": [0, 1, 2, 3]}\n        )\n        actual = concat([a, b], dim=\"x\")\n        assert_identical(actual, expected)\n"], "sample_1168": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((1, 2, 3))) == [(1, 2, 3), (-1, 2, 3), (1, -2, 3), (1, 2, -3),\n                                            (-1, -2, 3), (-1, 2, -3), (1, -2, -3), (-1, -2, -3)]\n"], "sample_160": ["    def test_format_large_decimal_with_grouping(self):\n        self.assertEqual(\n            nformat(Decimal('12345678901234567890.123456789'), decimal_sep=',', decimal_pos=2, grouping=3, thousand_sep='.'),\n            '12.345.678.901.234.567.890,12',\n        )\n"], "sample_978": ["def test_bspline_basis_set_repeated_knots():\n    knots = [0, 0, 2, 3, 4]\n    d = 1\n    splines = bspline_basis_set(d, knots, x)\n    assert len(splines) == len(knots) - d - 1\n    assert splines[0] == Piecewise((-x/2 + 1, (x >= 0) & (x <= 2)), (0, True))\n"], "sample_685": ["def test_log_level_setting(testdir: Testdir) -> None:\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        import pytest\n\n        logger = logging.getLogger(__name__)\n\n            logger.info(\"This is an info message\")\n            logger.debug(\"This is a debug message\")\n\n        pytest.main([\"-q\", \"--log-level=DEBUG\"])\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.assert_outcomes(passed=1)\n    log_records = result.stdout.str().splitlines()\n    assert \"This is a debug message\" in log_records\n"], "sample_411": ["    def test_no_color_force_color(self):\n        with mock.patch('django.core.management.color.no_style') as mock_no_style:\n            with mock.patch('django.core.management.color.color_style') as mock_color_style:\n                command = dance.DanceCommand()\n                command.handle(no_color=True, force_color=True)\n                mock_no_style.assert_not_called()\n                mock_color_style.assert_called_once_with(force_color=True)\n"], "sample_289": ["    def test_orderedset_discard(self):\n        s = OrderedSet([1, 2, 3])\n        s.discard(2)\n        self.assertEqual(list(s), [1, 3])\n        s.discard(4)\n        self.assertEqual(list(s), [1, 3])\n"], "sample_711": ["    def test_iterparentnodeids(self, pytester: Pytester) -> None:\n        p = pytester.mkdir(\"a/b/c\")\n        p.join(\"test_hello.py\").write(\"def test_func(): pass\")\n        result = pytester.runpytest()\n        result.assert_outcomes(passed=1)\n        nodeids = list(nodes.iterparentnodeids(\"a/b/c/test_hello.py::test_func\"))\n        assert nodeids == [\n            \"\",\n            \"a\",\n            \"a/b\",\n            \"a/b/c\",\n            \"a/b/c/test_hello.py\",\n            \"a/b/c/test_hello.py::test_func\",\n        ]\n"], "sample_461": ["    def test_urlfield_assume_scheme_deprecation(self):\n        with self.assertWarns(RemovedInDjango60Warning):\n            URLField(assume_scheme='https')\n"], "sample_255": ["    def test_handle_one_request_with_broken_pipe(self):\n        request = self.request_factory.get('/')\n        request._read_limited = lambda: None\n        request._get_content_length = lambda: 0\n        handler = WSGIRequestHandler(Stub(), Stub(), Stub(), Stub())\n        handler.rfile = BytesIO(b'GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n')\n        handler.wfile = Stub()\n        handler.requestline = b'GET / HTTP/1.1'\n        handler.request_version = 'HTTP/1.1'\n        handler.command = 'GET'\n        handler.headers = {'Host': 'example.com'}\n        handler.close_connection = False\n\n        with captured_stderr() as stderr:\n            handler.handle_one_request()\n\n        self.assertEqual(stderr.getvalue(), '')\n        self.assertTrue(handler.close_connection)\n"], "sample_406": ["    def test_manager_deconstruct(self):\n        class MyManager(BaseManager):\n            pass\n\n        manager = MyManager()\n        deconstructed = manager.deconstruct()\n        self.assertEqual(deconstructed, (False, 'tests.models_tests.MyManager', None, (), {}))\n\n        manager = MyManager.from_queryset(QuerySet)\n        deconstructed = manager.deconstruct()\n        self.assertEqual(deconstructed, (False, 'tests.models_tests.MyManagerFromQuerySet', None, (), {}))\n"], "sample_246": ["    def test_no_location_option(self):\n        \"\"\"\n        Test that the --no-location option removes location comments from the .po file.\n        \"\"\"\n        output, po_contents = self._run_makemessages(no_location=True)\n        self.assertNotIn('#: ', po_contents)\n"], "sample_371": ["    def test_callable_setting_wrapper_repr(self):\n        wrapped_callable = CallableSettingWrapper(lambda: None)\n        self.assertEqual(repr(wrapped_callable), '<bound method lambda of <object object at 0x...>>')\n"], "sample_310": ["    def test_model_detail_view_with_cached_property(self):\n        response = self.client.get(reverse('admin:admindocs-model-detail', args=['company', 'Company']))\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, 'get_name')\n        self.assertContains(response, 'CachedProperty')\n"], "sample_620": ["    def test_concat_coords_with_different_sizes(self, dim):\n        # Regression test for #3224\n        data = create_test_data()\n        ds1 = data.isel(time=slice(0, 5))\n        ds2 = data.isel(time=slice(5, 10))\n        ds3 = data.isel(time=slice(10, 15))\n\n        # Concatenate along 'time' dimension\n        concatenated = concat([ds1, ds2, ds3], dim=dim)\n\n        # Check that the concatenated dataset has the correct size\n        assert concatenated.dims[dim] == 15\n\n        # Check that the coordinates are correctly aligned\n        assert_identical(concatenated.coords[dim], data.coords[dim])\n\n"], "sample_238": ["    def test_window_functions(self):\n        with CaptureQueriesContext(connection) as queries:\n            qs = (\n                Book.objects.annotate(\n                    rank=Window(\n                        expression=Rank(),\n                        partition_by=F('publisher'),\n                        order_by=F('rating').desc(),\n                    )\n                ).filter(rank=1)\n            )\n            self.assertQuerysetEqual(qs, [\n                'The Definitive Guide to Django: Web Development Done Right',\n                'Artificial Intelligence: A Modern Approach',\n                'Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp',\n            ], lambda b: b.name)\n            self.assertEqual(len(queries.captured_queries), 1)\n"], "sample_304": ["    def test_validate_ipv6_address_with_zone_index(self):\n        with self.assertRaises(ValidationError):\n            validate_ipv6_address('fe80::1%eth0')\n"], "sample_140": ["    def test_sensitive_variables_decorator_no_args(self):\n        @sensitive_variables()\n            pass\n        self.assertEqual(my_function.sensitive_variables, '__ALL__')\n"], "sample_900": ["    def test_mlp_regressor_partial_fit_sparse(self):\n        # Test partial_fit with sparse input for MLPRegressor\n        X, y = make_regression(n_samples=100, n_features=10, random_state=42)\n        X_sparse = csr_matrix(X)\n        regressor = MLPRegressor(hidden_layer_sizes=(5,), solver='sgd',\n                                 max_iter=10, random_state=42)\n\n        regressor.partial_fit(X_sparse, y)\n        regressor.partial_fit(X_sparse, y)\n\n        # Check if the model can predict\n        regressor.predict(X_sparse)\n"], "sample_989": ["def test_sympify_mpmath_context():\n    x = mpmath.mpf('1.23')\n    x.context.prec = 50\n    y = sympify(x)\n    assert isinstance(y, Float)\n    assert y._prec == 50\n"], "sample_752": ["    def test_average_path_length_sparse(self):\n        n_samples = 10\n        n_estimators = 5\n        n_samples_leaf = rng.randint(1, 10, size=(n_samples, n_estimators))\n        sparse_n_samples_leaf = csc_matrix(n_samples_leaf)\n\n        dense_apl = _average_path_length(n_samples_leaf)\n        sparse_apl = _average_path_length(sparse_n_samples_leaf)\n\n        assert_array_almost_equal(dense_apl, sparse_apl)\n"], "sample_931": ["def test_parse_annotation():\n    assert _parse_annotation('int') == ('int', None)\n    assert _parse_annotation('str') == ('str', None)\n    assert _parse_annotation('List[int]') == ('List', 'int')\n    assert _parse_annotation('Dict[str, int]') == ('Dict', 'str, int')\n    assert _parse_annotation('Optional[str]') == ('Optional', 'str')\n    assert _parse_annotation('Union[int, str]') == ('Union', 'int, str')\n    assert _parse_annotation('Callable[[int], str]') == ('Callable', '[[int], str]')\n    assert _parse_annotation('Any') == ('Any', None)\n"], "sample_369": ["    def test_rename_field_with_default(self):\n        before = [\n            self.author_name,\n        ]\n        after = [\n            self.author_name_renamed,\n        ]\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['RenameField'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name', old_name='name')\n\n"], "sample_666": ["    def test_tee_capture(self, tmpdir):\n        # test that tee capture works as expected\n        p = tmpdir.join(\"out\")\n        with TeeStdCapture() as cap:\n            print(\"hello\")\n            sys.stderr.write(\"world\\n\")\n            with open(str(p), \"w\") as f:\n                print(\"file\", file=f)\n        assert cap.out == \"hello\\n\"\n        assert cap.err == \"world\\n\"\n        assert p.read() == \"file\\n\"\n"], "sample_218": ["    def test_extract_iso_week_day(self):\n        dt = datetime(2023, 10, 26, 12, 0, 0)\n        dt_model = self.create_model(dt, dt)\n        self.assertEqual(DTModel.objects.filter(id=dt_model.id).annotate(weekday=ExtractIsoWeekDay('start_datetime')).values('weekday')[0]['weekday'], 4)\n"], "sample_522": ["    def test_colorbar_extension_shape_uniform(self):\n        fig = _colorbar_extension_shape('uniform')\n        self.compare(fig)\n"], "sample_762": ["    def test_clone_pipeline(self):\n        # Test cloning of pipelines\n        clf = Pipeline([('svc', SVC())])\n        cloned_clf = clone(clf)\n        assert_true(isinstance(cloned_clf, Pipeline))\n        assert_equal(cloned_clf.steps[0][0], 'svc')\n        assert_true(isinstance(cloned_clf.steps[0][1], SVC))\n        assert_false(cloned_clf.steps[0][1] is clf.steps[0][1])\n"], "sample_13": ["def test_longitude_wrap_angle():\n    lon = Longitude(180 * u.deg, wrap_angle=180 * u.deg)\n    assert lon.wrap_angle == 180 * u.deg\n    assert lon.degree == 180\n\n    lon = Longitude(270 * u.deg, wrap_angle=180 * u.deg)\n    assert lon.wrap_angle == 180 * u.deg\n    assert lon.degree == -90\n\n    lon = Longitude(360 * u.deg, wrap_angle=180 * u.deg)\n    assert lon.wrap_angle == 180 * u.deg\n    assert lon.degree == 0\n\n    lon = Longitude(180 * u.deg, wrap_angle=360 * u.deg)\n    assert lon.wrap_angle == 360 * u.deg\n    assert lon.degree == 180\n\n    lon = Longitude(270 * u.deg, wrap_angle=360 * u.deg)\n    assert lon.wrap_angle == 360 * u.deg\n    assert lon.degree == 270\n\n    lon = Longitude(540 * u.deg, wrap_angle=360 * u.deg)\n    assert lon.wrap_angle == 360 * u.deg\n    assert lon.degree == 180\n"], "sample_285": ["    def test_check_finders_invalid_finder(self):\n        with override_settings(STATICFILES_FINDERS=['invalid.path.Finder']):\n            errors = check_finders(None)\n            self.assertEqual(len(errors), 1)\n            self.assertIsInstance(errors[0], Error)\n            self.assertIn('Finder \"invalid.path.Finder\" is not a subclass', errors[0].msg)\n"], "sample_373": ["    def test_view_detail_view_with_view_name(self):\n        response = self.client.get(reverse('admin:admindocs-view-detail', args=[\n            'django.contrib.auth.views.login',\n        ]))\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, 'django.contrib.auth.views.login')\n"], "sample_563": ["    def test_draggable_annotation(self):\n        fig, ax = plt.subplots()\n        x, y = 0.5, 0.5\n        ann = ax.annotate(\"test\", xy=(x, y), xycoords=\"data\")\n        draggable = DraggableAnnotation(ann)\n\n        # Simulate a drag event\n        event = MouseEvent(\n            'motion_notify_event',\n            fig.canvas,\n            x=fig.canvas.width / 2 + 10,\n            y=fig.canvas.height / 2 + 10,\n            button=MouseButton.LEFT,\n        )\n        draggable.on_motion(event)\n\n        # Assert that the annotation has moved\n        assert ann.xyann != (x, y)\n"], "sample_293": ["    def test_resolve_urlconf(self):\n        resolver = get_resolver(None)\n        self.assertIsInstance(resolver, URLResolver)\n"], "sample_1053": ["def test_sympify_mpq():\n    assert sympify(mpq(1, 2)) == Rational(1, 2)\n"], "sample_1153": ["def test_polarify_subs():\n    x, y = symbols('x y')\n    expr = x**y\n    eq, subs = polarify(expr, subs=True)\n    assert eq == _x**_y\n    assert subs == {_x: x, _y: y}\n"], "sample_800": ["    def test_check_estimators_unfitted(self):\n        # Test check_estimators_unfitted\n        for Estimator in [\n            NoSampleWeightPandasSeriesType,\n            ChangesDict,\n            SetsWrongAttribute,\n            ChangesWrongAttribute,\n            ChangesUnderscoreAttribute,\n            RaisesErrorInSetParams,\n            ModifiesValueInsteadOfRaisingError,\n            ModifiesAnotherValue,\n            CorrectNotFittedErrorClassifier,\n            BadBalancedWeightsClassifier,\n            BadTransformerWithoutMixin,\n            NotInvariantPredict,\n            LargeSparseNotSupportedClassifier,\n            SparseTransformer,\n            UntaggedBinaryClassifier,\n            TaggedBinaryClassifier,\n            RequiresPositiveYRegressor\n        ]:\n            with self.assertRaises(AttributeError):\n                check_estimators_unfitted(Estimator)\n\n"], "sample_598": ["    def test_format_timedelta_timedelta_format(self):\n        t = np.timedelta64(10, \"D\")\n        assert formatting.format_timedelta(t, timedelta_format=\"date\") == \"10 days\"\n        assert formatting.format_timedelta(t, timedelta_format=\"time\") == \"00:00:00\"\n        assert formatting.format_timedelta(t, timedelta_format=\"datetime\") == \"10 days\"\n"], "sample_1137": ["    def test_convert_to_multiple_units():\n        assert convert_to(speed_of_light, [meter, second]) == 299792458*meter/second\n        assert convert_to(3*newton, [centimeter, gram, second]) == 300000*centimeter*gram/second**2\n"], "sample_558": ["    def test_colorbar_axes_size(self, orientation):\n        fig, ax = plt.subplots()\n        divider = make_axes_locatable(ax)\n        cax = divider.append_axes(orientation, size=\"5%\", pad=0.1)\n        fig.colorbar(mpl.cm.ScalarMappable(cmap=\"viridis\"), cax=cax)\n        plt.draw()\n        # Check that the colorbar axes has the correct size\n        if orientation == \"horizontal\":\n            assert cax.get_position().width == 0.05\n        else:\n            assert cax.get_position().height == 0.05\n\n"], "sample_123": ["    def test_urlencode_multivaluedict(self):\n        data = MultiValueDict({'a': ['1', '2'], 'b': ['3']})\n        self.assertEqual(urlencode(data), 'a=1&a=2&b=3')\n"], "sample_597": ["    def test_merge_explicit_coords(self):\n        ds1 = xr.Dataset(\n            {\"foo\": ((\"x\", \"y\"), np.arange(6).reshape(2, 3))},\n            coords={\"x\": [0, 1], \"y\": [0, 1, 2]},\n        )\n        ds2 = xr.Dataset(\n            {\"bar\": ((\"x\", \"y\"), np.arange(6).reshape(2, 3) * 2)},\n            coords={\"x\": [0, 1], \"y\": [0, 1, 2]},\n        )\n\n        merged = xr.merge([ds1, ds2], explicit_coords=[\"x\", \"y\"])\n        assert_identical(merged, xr.Dataset({\"foo\": ds1.foo, \"bar\": ds2.bar}))\n"], "sample_485": ["    def test_urlize_nofollow(self):\n        self.check_output(\n            urlize,\n            \"Visit <a href='http://example.com'>example.com</a>.\",\n            \"Visit <a href='http://example.com'>example.com</a>.\",\n        )\n        self.check_output(\n            urlize,\n            \"Visit <a href='http://example.com'>example.com</a>.\",\n            \"Visit <a href='http://example.com' rel='nofollow'>example.com</a>.\",\n            nofollow=True,\n        )\n"], "sample_1109": ["def test_frac_rewrite_as_floor():\n    assert frac(x).rewrite(floor) == x - floor(x)\n    assert frac(x + I*y).rewrite(floor) == x - floor(x) + I*frac(y)\n"], "sample_960": ["def test_parse_annotation():\n    assert _parse_annotation('int') == ('int', None)\n    assert _parse_annotation('str, int') == ('str', 'int')\n    assert _parse_annotation('list[str]') == ('list', 'str')\n    assert _parse_annotation('dict[str, int]') == ('dict', 'str, int')\n    assert _parse_annotation('Tuple[int, ...] ') == ('Tuple', 'int, ...')\n    assert _parse_annotation('Callable[[int, str], None]') == ('Callable', '[[int, str], None]')\n    assert _parse_annotation('Union[int, str]') == ('Union', 'int, str')\n    assert _parse_annotation('Optional[int]') == ('Optional', 'int')\n    assert _parse_annotation('Any') == ('Any', None)\n"], "sample_1038": ["    def test_matadd_scalar_add():\n        assert MatAdd(A, 2) == A + 2\n        assert MatAdd(2, A) == 2 + A\n        assert MatAdd(A, 2, 3) == A + 5\n        assert MatAdd(2, A, 3) == A + 5\n"], "sample_441": ["    def test_password_validation_with_custom_user_model(self):\n        class CustomUserCreationForm(UserCreationForm):\n            class Meta:\n                model = CustomUser\n                fields = (\"username\", \"email\")\n\n        form = CustomUserCreationForm(data={\"username\": \"testuser\", \"email\": \"test@example.com\", \"password1\": \"password\", \"password2\": \"password\"})\n        self.assertTrue(form.is_valid())\n        user = form.save()\n        self.assertEqual(user.username, \"testuser\")\n        self.assertEqual(user.email, \"test@example.com\")\n"], "sample_912": ["def test_parse_annotation():\n    assert _parse_annotation('int') == ('int', None)\n    assert _parse_annotation('str') == ('str', None)\n    assert _parse_annotation('list[int]') == ('list', 'int')\n    assert _parse_annotation('dict[str, int]') == ('dict', ('str', 'int'))\n    assert _parse_annotation('Tuple[int, str]') == ('Tuple', ('int', 'str'))\n    assert _parse_annotation('Optional[str]') == ('Optional', 'str')\n    assert _parse_annotation('Union[int, str]') == ('Union', ('int', 'str'))\n    assert _parse_annotation('Callable[[int], str]') == ('Callable', '[[int], str]')\n"], "sample_854": ["    def test_svc_predict_proba_ovr_multiclass(self):\n        # Test predict_proba for SVC with ovr strategy and multiclass\n        # classification.\n        X_train, X_test, y_train, y_test = train_test_split(\n            iris.data, iris.target, test_size=0.2, random_state=42)\n\n        clf = svm.SVC(kernel='linear', decision_function_shape='ovr',\n                      probability=True, random_state=42)\n        clf.fit(X_train, y_train)\n        y_pred_proba = clf.predict_proba(X_test)\n\n        # Check that probabilities sum to 1 for each sample\n        assert_allclose(y_pred_proba.sum(axis=1), np.ones(len(y_test)))\n\n"], "sample_18": ["    def test_copy_info(self):\n        q2 = copy.copy(self.q)\n        assert_info_equal(self.q, q2)\n        q3 = copy.deepcopy(self.q)\n        assert_info_equal(self.q, q3)\n"], "sample_715": ["    def test_cross_val_score_sparse_matrix(self):\n        # Test cross_val_score with sparse matrix input\n        clf = MockClassifier(allow_nd=True)\n        scores = cross_val_score(clf, X_sparse, y, cv=3)\n        assert_array_almost_equal(scores, [1. / (1 + np.abs(0))] * 3)\n\n"], "sample_774": ["    def test_onehot_inverse_transform_unknown_categories(self):\n        enc = OneHotEncoder(handle_unknown='ignore')\n        X = [['Male', 1], ['Female', 3], ['Female', 2]]\n        enc.fit(X)\n        X_trans = enc.transform(X)\n        X_inv = enc.inverse_transform(X_trans)\n        assert_equal(X_inv, X)\n\n        # Test with unknown category\n        X_new = [['Male', 4]]\n        X_trans_new = enc.transform(X_new)\n        X_inv_new = enc.inverse_transform(X_trans_new)\n        assert_equal(X_inv_new, [['Male', None]])\n"], "sample_765": ["    def test_brier_score_loss_multilabel():\n        # Test brier score loss for multilabel classification\n        y_true = np.array([[1, 0, 1], [0, 1, 0], [1, 1, 0]])\n        y_prob = np.array([[0.8, 0.2, 0.9], [0.1, 0.9, 0.1], [0.7, 0.8, 0.2]])\n        score = brier_score_loss(y_true, y_prob)\n        assert_almost_equal(score, 0.11666666666666667)\n\n"], "sample_1136": ["    def test_ExpressionDomain_gcd(self):\n        f = EX(x**2 + 2*x + 1)\n        g = EX(x + 1)\n        assert f.gcd(g) == EX(x + 1)\n"], "sample_863": ["    def test_pipeline_memory_cache(self):\n        # Test that pipeline caching works correctly\n        # with memory\n\n        cachedir = mkdtemp()\n        memory = joblib.Memory(cachedir=cachedir, verbose=0)\n\n        # Create a pipeline with a transformer that stores the timestamp\n        # of its fit call\n        pipe = Pipeline([('dummy', DummyTransf()), ('clf', SVC())],\n                        memory=memory)\n\n        # Fit the pipeline\n        X = iris.data\n        y = iris.target\n        pipe.fit(X, y)\n\n        # Check that the transformer's timestamp is stored in the cache\n        with open(os.path.join(cachedir, 'dummy.pkl'), 'rb') as f:\n            loaded_transformer = joblib.load(f)\n        assert loaded_transformer.timestamp_ == pipe.named_steps['dummy'].timestamp_\n\n        # Fit the pipeline again, it should be loaded from cache\n        pipe.fit(X, y)\n        assert pipe.named_steps['dummy'].timestamp_ != loaded_transformer.timestamp_\n\n        shutil.rmtree(cachedir)\n"], "sample_1014": ["    def test_reshape(self):\n        a = ImmutableDenseNDimArray([1, 2, 3, 4, 5, 6], (2, 3))\n        b = a.reshape(3, 2)\n        assert b.shape == (3, 2)\n        assert b[0, 0] == 1\n        assert b[2, 1] == 6\n        raises(ValueError, lambda: a.reshape(2, 2))\n"], "sample_945": ["def test_parse_annotation():\n    assert _parse_annotation('int') == ('int', None)\n    assert _parse_annotation('str, int') == ('str', 'int')\n    assert _parse_annotation('list[int]') == ('list', 'int')\n    assert _parse_annotation('dict[str, int]') == ('dict', 'str, int')\n    assert _parse_annotation('Tuple[int, str]') == ('Tuple', 'int, str')\n    assert _parse_annotation('Optional[int]') == ('Optional', 'int')\n    assert _parse_annotation('Union[int, str]') == ('Union', 'int, str')\n    assert _parse_annotation('Callable[[int], str]') == ('Callable', '[[int], str]')\n    assert _parse_annotation('Any') == ('Any', None)\n"], "sample_112": ["    def test_submit_row_tag(self):\n        request = self.request_factory.get(reverse('admin:blog_article_change', args=(1,)))\n        request.user = User.objects.create_user('testuser', 'test@example.com', 'password')\n        context = {\n            'add': False,\n            'change': True,\n            'is_popup': False,\n            'save_as': False,\n            'has_add_permission': True,\n            'has_change_permission': True,\n            'has_view_permission': True,\n            'has_delete_permission': True,\n            'has_editable_inline_admin_formsets': False,\n            'show_save': True,\n            'show_save_and_add_another': True,\n            'show_save_and_continue': True,\n            'show_delete': True,\n        }\n        template = 'submit_line.html'\n        rendered = submit_row(Context(context))\n        self.assertIn('can_change', rendered)\n        self.assertIn('show_delete_link', rendered)\n        self.assertIn('show_save_as_new', rendered)\n        self.assertIn('show_save_and_add_another', rendered)\n        self.assertIn('show_save_and_continue', rendered)\n        self.assertIn('show_save', rendered)\n        self.assertIn('show_close', rendered)\n"], "sample_787": ["    def test_brier_score_loss_multiclass():\n        # Test brier_score_loss for multiclass classification\n        y_true = np.array([0, 1, 2, 0, 1, 2])\n        y_prob = np.array([[0.1, 0.8, 0.1],\n                           [0.2, 0.3, 0.5],\n                           [0.4, 0.2, 0.4],\n                           [0.6, 0.2, 0.2],\n                           [0.1, 0.7, 0.2],\n                           [0.3, 0.1, 0.6]])\n        score = brier_score_loss(y_true, y_prob)\n        assert_almost_equal(score, 0.3666666666666667)\n\n"], "sample_807": ["    def test_calibration_curve_with_sparse_input():\n        # Check if calibration_curve works with sparse input\n        X, y = make_classification(n_samples=100, n_features=10, random_state=42)\n        X_sparse = sparse.csr_matrix(X)\n        clf = LinearSVC(random_state=42)\n        clf.fit(X, y)\n        y_prob = clf.decision_function(X_sparse)\n        prob_true, prob_pred = calibration_curve(y, y_prob, normalize=True)\n        assert_equal(len(prob_true), len(prob_pred))\n"], "sample_599": ["    def test_unsigned_integer_coder():\n        data = np.array([0, 1, 2, 3, 4], dtype=np.uint8)\n        var = xr.Variable(\"x\", data, attrs={\"_Unsigned\": \"true\"})\n        encoded = variables.UnsignedIntegerCoder().encode(var)\n        decoded = variables.UnsignedIntegerCoder().decode(encoded)\n        assert_identical(var, decoded)\n\n        data = np.array([-1, 0, 1, 2, 3], dtype=np.int8)\n        var = xr.Variable(\"x\", data, attrs={\"_Unsigned\": \"true\"})\n        encoded = variables.UnsignedIntegerCoder().encode(var)\n        decoded = variables.UnsignedIntegerCoder().decode(encoded)\n        assert_identical(var, decoded)\n\n        data = np.array([0, 1, 2, 3, 4], dtype=np.int8)\n        var = xr.Variable(\"x\", data)\n        encoded = variables.UnsignedIntegerCoder().encode(var)\n        decoded = variables.UnsignedIntegerCoder().decode(encoded)\n        assert_identical(var, decoded)\n"], "sample_403": ["    def test_rename_index_unnamed(self):\n        with atomic(using=self.db_alias), connection.cursor() as cursor:\n            cursor.execute(\n                \"CREATE TABLE test_rename_index_unnamed (id INTEGER PRIMARY KEY, name TEXT)\"\n            )\n            cursor.execute(\n                \"CREATE INDEX test_rename_index_unnamed_idx ON test_rename_index_unnamed (name)\"\n            )\n\n        with self.assertRaises(FieldDoesNotExist):\n            self.models.RenameIndexUnnamed.objects.get(name=\"test\")\n\n        # Create a migration that renames the unnamed index\n        migration = Migration(\n            \"test_rename_index_unnamed\",\n            [\n                RenameIndex(\n                    \"test_rename_index_unnamed\",\n                    new_name=\"new_name\",\n                    old_fields=[\"name\"],\n                ),\n            ],\n        )\n\n        # Apply the migration\n        self.apply_migration(migration)\n\n        # Check that the index has been renamed\n        with connection.cursor() as cursor:\n            cursor.execute(\n                \"SELECT name FROM sqlite_master WHERE type='index' AND tbl_name='test_rename_index_unnamed'\"\n            )\n            self.assertEqual(cursor.fetchone()[0], \"new_name\")\n\n        # Rollback the migration\n        self.rollback_migration(migration)\n\n        # Check that the index has been renamed back to its original name\n        with connection.cursor() as cursor:\n            cursor.execute(\n                \"SELECT name FROM sqlite_master WHERE type='index' AND tbl_name='test_rename_index_unnamed'\"\n            )\n            self.assertEqual(cursor.fetchone()[0], \"test_rename_index_unnamed_idx\")\n"], "sample_639": ["    def test_get_full_documentation(self):\n        checker = OtherBasicChecker()\n        doc = checker.get_full_documentation(\n            msgs=checker.msgs, options=checker.options_and_values(), reports=()\n        )\n        self.assertIn(\"Basic checker has an example.\", doc)\n        self.assertIn(\"Verbatim name of the checker is ``basic``.\", doc)\n        self.assertIn(\"This checker is provided by ``None``.\", doc)\n\n"], "sample_309": ["    def test_urlencode_multivaluedict(self):\n        data = MultiValueDict({'a': ['1', '2'], 'b': '3'})\n        self.assertEqual(urlencode(data), 'a=1&a=2&b=3')\n"], "sample_468": ["    def test_context_pop_exception(self):\n        context = Context()\n        context.push({})\n        with self.assertRaises(ContextPopException):\n            context.pop()\n            context.pop()\n"], "sample_614": ["    def test_short_numpy_repr_with_edgeitems(self):\n        arr = np.arange(27).reshape(3, 3, 3)\n        expected = dedent(\n            \"\"\"\n            array([[[ 0,  1,  2],\n                    [ 3,  4,  5],\n                    [ 6,  7,  8]],\n\n                   [[ 9, 10, 11],\n                    [12, 13, 14],\n                    [15, 16, 17]],\n\n                   [[18, 19, 20],\n                    [21, 22, 23],\n                    [24, 25, 26]]])\n            \"\"\"\n        )\n        assert formatting.short_numpy_repr(arr) == expected\n"], "sample_808": ["    def test_decision_function_behaviour_new(self):\n        # Test that decision_function is consistent with score_samples\n        # when behaviour='new' and contamination is not 'auto'.\n        X = iris.data\n        y = iris.target\n        contamination = 0.1\n        clf = IsolationForest(contamination=contamination, behaviour='new')\n        clf.fit(X)\n        scores = clf.score_samples(X)\n        decision_function = clf.decision_function(X)\n        assert_array_almost_equal(decision_function, scores - clf.offset_)\n"], "sample_323": ["    def test_migrate_unapplied_initial_migration(self):\n        # Test that we can apply an initial migration that was previously\n        # unapplied due to a database error.\n\n        with self.connection.cursor() as cursor:\n            cursor.execute(\"DROP TABLE IF EXISTS migrations2_thing\")\n\n        # Create a migration that creates a table\n        migration = migrations.Migration(\n            \"0001_initial\",\n            operations=[\n                migrations.CreateModel(\n                    name=\"Thing\",\n                    fields=[\n                        (\"id\", models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name=\"ID\")),\n                        (\"name\", models.CharField(max_length=100)),\n                    ],\n                    options={\"db_table\": \"migrations2_thing\"},\n                ),\n            ],\n        )\n\n        # Simulate a database error during the initial migration\n        with mock.patch(\"django.db.migrations.executor.MigrationExecutor.apply_migration\") as mock_apply_migration:\n            mock_apply_migration.side_effect = DatabaseError(\"Simulated database error\")\n            executor = MigrationExecutor(self.connection)\n            with self.assertRaises(DatabaseError):\n                executor.migrate([\"migrations2\"], plan=executor.migration_plan([\"migrations2\", None]))\n\n        # Now, try to apply the migration again\n        mock_apply_migration.reset_mock()\n        executor.migrate([\"migrations2\"], plan=executor.migration_plan([\"migrations2\", None]))\n        mock_apply_migration.assert_called_once()\n"], "sample_49": ["    def test_multiwidget_media(self):\n        class MyMultiWidget(MultiWidget):\n                widgets = (TextInput(attrs={'class': 'foo'}), TextInput(attrs={'class': 'bar'}))\n                super().__init__(widgets, attrs)\n\n        class MyForm(Form):\n            myfield = MyMultiWidget()\n\n        form = MyForm()\n        self.assertEqual(\n            form.media,\n            Media(\n                css={'all': ['http://media.example.com/static/admin/css/widgets.css']},\n                js=['http://media.example.com/static/admin/js/vendor/jquery/jquery.js',\n                    'http://media.example.com/static/admin/js/jquery.init.js',\n                    'http://media.example.com/static/admin/js/core.js'],\n            ),\n        )\n"], "sample_766": ["    def test_dict_learning_transform_algorithm_threshold(self):\n        # Test the threshold algorithm for sparse coding\n        n_components = 5\n        dict_learning = DictionaryLearning(n_components=n_components,\n                                           transform_algorithm='threshold',\n                                           transform_alpha=0.1)\n        dict_learning.fit(X)\n        code = dict_learning.transform(X)\n        assert_equal(code.shape, (n_samples, n_components))\n        assert_less(np.sum(np.abs(code) < 1e-10),\n                    n_samples * n_components)\n"], "sample_953": ["def test_quickstart_overwrite(tmpdir):\n    answers = {\n        'Path for documentation': str(tmpdir),\n        'Separate source and build dirs': 'y',\n        'Project name': 'Test Project',\n        'Author name(s)': 'Test Author',\n        'Project version': '1.0',\n        'Project release': '1.0',\n        'Name prefix for templates and static dir': '_',\n        'Source file suffix': '.rst',\n        'Name of your master document (without suffix)': 'index',\n        'sphinx-ext.imgmath': 'y',\n        'Create Makefile?': 'y',\n        'Create Windows command file?': 'y',\n    }\n    qs.term_input = mock_input(answers)\n    qs.generate(DEFAULTS.copy(), overwrite=False)\n    # Create a file to overwrite\n    with open(path.join(str(tmpdir), 'source', 'conf.py'), 'w') as f:\n        f.write('test')\n    qs.generate(DEFAULTS.copy(), overwrite=True)\n    assert path.exists(path.join(str(tmpdir), 'source', 'conf.py'))\n"], "sample_585": ["    def test_groupby_assign_coords(self):\n        ds = xr.Dataset({'foo': (('x', 'y'), np.arange(6).reshape(2, 3)),\n                         'bar': (('x', 'y'), np.arange(6).reshape(2, 3))},\n                        coords={'x': [0, 1], 'y': [0, 1, 2]})\n        expected = ds.assign_coords({'new_coord': (('x',), [1, 2])})\n        result = ds.groupby('x').assign_coords(new_coord=[1, 2])\n        assert_identical(result, expected)\n"], "sample_286": ["    def test_get_or_create_with_defaults(self):\n        with self.assertRaises(ValueError):\n            Article.objects.get_or_create(headline='Test article', defaults={'pub_date': datetime.now() - timedelta(days=1)})\n"], "sample_659": ["    def test_raises_with_message(self):\n        with pytest.raises(ValueError, message=\"hello\"):\n            raise ValueError(\"hello\")\n"], "sample_388": ["    def test_remote_user_creation(self):\n        with self.settings(REMOTE_USER=self.known_user):\n            response = self.client.get(\"/\")\n            self.assertEqual(response.status_code, 200)\n            self.assertTrue(response.context[\"user\"].is_authenticated)\n            self.assertEqual(response.context[\"user\"].username, self.known_user)\n"], "sample_118": ["    def test_isnullwithnoneasrhs(self):\n        with self.assertRaises(FieldError):\n            IsNullWithNoneAsRHS.objects.filter(field__isnull=None)\n"], "sample_705": ["    def test_getpathnode(self, testdir: Testdir) -> None:\n        testdir.makepyfile(\n            \"\"\"\n                pass\n        \"\"\"\n        )\n        node = testdir.getpathnode(testdir.tmpdir / \"test_file.py\")\n        assert isinstance(node, pytest.Module)\n        assert node.name == \"test_file\"\n        assert node.fspath == testdir.tmpdir / \"test_file.py\"\n"], "sample_1123": ["def test_conditionset_subs_dummy_symbol_unchanged():\n    c = ConditionSet(x, x < 1, {x, z})\n    assert c.subs(x, y) == ConditionSet(x, x < 1, FiniteSet(y, z))\n"], "sample_133": ["    def test_set_language_with_invalid_language_code(self):\n        \"\"\"Test that set_language view handles invalid language codes gracefully.\"\"\"\n        inactive_language_code = self._get_inactive_language_code()\n        response = self.client.post(\n            reverse('set_language'),\n            {'next': '/', LANGUAGE_QUERY_PARAMETER: inactive_language_code},\n        )\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response['Location'], '/')\n        self.assertEqual(get_language(), settings.LANGUAGE_CODE)\n"], "sample_459": ["    def test_integer_field_overflow(self):\n        # Test that overflow and underflow exceptions are raised correctly.\n        with self.assertRaises(IntegerFieldOverflow.underflow_exception):\n            self.model.objects.create(value=self.backend_range[0] - 1)\n        with self.assertRaises(IntegerFieldOverflow.overflow_exception):\n            self.model.objects.create(value=self.backend_range[1] + 1)\n"], "sample_1128": ["    def test_set_pos_and_pos_from(self):\n        N = ReferenceFrame('N')\n        p1 = Point('p1')\n        p2 = Point('p2')\n        p1.set_pos(p2, 10*N.x)\n        assert p1.pos_from(p2) == 10*N.x\n"], "sample_1095": ["def test_from_inversion_vector():\n    assert Permutation.from_inversion_vector([3, 2, 1, 0, 0]) == Permutation([3, 2, 1, 0, 4, 5])\n    assert Permutation.from_inversion_vector([0, 0, 1, 2, 3]) == Permutation([0, 1, 2, 3, 4])\n    with raises(ValueError):\n        Permutation.from_inversion_vector([3, 2, 1, 0, 0, 0])\n"], "sample_321": ["    def test_csrf_cookie_domain_matching(self):\n        req = self._get_POST_csrf_cookie_request(cookie=self._csrf_id_cookie)\n        req.META['HTTP_HOST'] = 'subdomain.example.com'\n        middleware = CsrfViewMiddleware()\n        response = middleware.process_view(req, lambda r: HttpResponse(), (), {})\n        self.assertIsNone(response)\n"], "sample_812": ["    def test_estimator_pretty_printer_n_max_elements_to_show(self):\n        set_config(print_changed_only=False)\n        lr = LogisticRegression(penalty='l2', dual=False, tol=1e-4, C=1.0,\n                               fit_intercept=True, intercept_scaling=1,\n                               class_weight=None, random_state=None,\n                               solver='warn', max_iter=100,\n                               multi_class='warn', verbose=0, warm_start=False,\n                               n_jobs=None, l1_ratio=None)\n        pipe = make_pipeline(StandardScaler(), lr)\n        pipe.fit(np.random.randn(10, 5), np.random.randint(0, 2, size=10))\n        pp = _EstimatorPrettyPrinter(n_max_elements_to_show=3)\n        expected = (\n            \"Pipeline(steps=[('standardscaler', StandardScaler()), ('logisticregression', \"\n            \"LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, \"\n            \"intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='warn', \"\n            \"n_jobs=None, penalty='l2', random_state=None, solver='warn', tol=0.0001, \"\n            \"verbose=0, warm_start=False))])\"\n        )\n        assert re.sub(r'\\s+', ' ', pp.pformat(pipe)) == expected\n"], "sample_1041": ["    def test_transpose_add():\n        assert transpose(A + B) == transpose(A) + transpose(B)\n"], "sample_656": ["    def test_capture_manager_global_and_fixture_disabled(self, tmpdir):\n        cm = capture.CaptureManager(None)\n        with cm.global_and_fixture_disabled():\n            cm.start_global_capturing()\n            assert cm.is_globally_capturing()\n            cm.suspend_global_capture()\n            assert not cm.is_globally_capturing()\n            cm.resume_global_capture()\n            assert cm.is_globally_capturing()\n            cm.stop_global_capturing()\n            assert not cm.is_globally_capturing()\n\n"], "sample_507": ["    def test_update_convertible(self):\n        data = ['1', '2', '3']\n        ud = cat.UnitData()\n        ud.update(data)\n        assert len(ud._mapping) == 3\n        assert all(isinstance(k, str) for k in ud._mapping)\n        assert all(isinstance(v, int) for v in ud._mapping.values())\n"], "sample_158": ["    def test_check_ignored_options(self):\n        class MyModel(models.Model):\n            name = models.CharField(max_length=100)\n            friends = models.ManyToManyField('self', symmetrical=False, null=True)\n\n        errors = MyModel._meta.fields['friends'].check(from_model=MyModel)\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], DjangoWarning)\n        self.assertEqual(errors[0].id, 'fields.W340')\n"], "sample_463": ["    def test_rabbit_circular_fk_index(self):\n        knight = Knight.objects.create()\n        rabbit1 = Rabbit.objects.create(knight=knight)\n        rabbit2 = Rabbit.objects.create(knight=knight, parent=rabbit1)\n        self.assertEqual(Rabbit.objects.filter(knight=knight, parent=rabbit1).count(), 1)\n"], "sample_521": ["def test_poly3dcollection_zsort():\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    verts = [\n        [(0, 0, 0), (1, 0, 0), (1, 1, 0), (0, 1, 0)],\n        [(0, 0, 1), (1, 0, 1), (1, 1, 1), (0, 1, 1)],\n    ]\n    pc = art3d.Poly3DCollection(verts, zsort='min')\n    ax.add_collection(pc)\n    ax.set_xlim([0, 1])\n    ax.set_ylim([0, 1])\n    ax.set_zlim([0, 1])\n    return fig\n"], "sample_925": ["    def test_mock_module_attributes(self) -> None:\n        with mock(['my_module']):\n            my_module = import_module('my_module')\n            assert isinstance(my_module, _MockModule)\n            assert hasattr(my_module, 'some_attribute')\n            assert isinstance(my_module.some_attribute, _MockObject)\n            assert my_module.some_attribute.__display_name__ == 'my_module.some_attribute'\n"], "sample_837": ["    def test_get_blas_info():\n        blas_info = _get_blas_info()\n        assert isinstance(blas_info, dict)\n        for key in ['macros', 'lib_dirs', 'cblas_libs']:\n            assert key in blas_info\n"], "sample_222": ["    def test_lock_unlock(self):\n        with NamedTemporaryFile(mode='wb') as f:\n            self.assertTrue(locks.lock(f, locks.LOCK_EX))\n            self.assertTrue(locks.unlock(f))\n"], "sample_1092": ["def test_cse_issue_16868():\n    a = Symbol('a')\n    b = Symbol('b')\n    expr = (a + b)**2\n    reps, new_expr = cse([expr], symbols=(x0,))\n    assert new_expr[0] == x0**2\n    assert reps == [(x0, a + b)]\n\n"], "sample_1199": ["    def test_tensor_product_simp_trace(self):\n        A, B = symbols('A B', commutative=False)\n        tp = TensorProduct(A, B)\n        self.assertEqual(tensor_product_simp(Tr(tp)), Tr(A)*Tr(B))\n"], "sample_11": ["def test_sliced_wcs_world_to_pixel_values_with_slice_and_offset():\n    wcs = WCS_SPECTRAL_CUBE.copy()\n    sliced_wcs = SlicedLowLevelWCS(wcs, (slice(None), 5, slice(None)))\n\n    # Test world to pixel conversion with a slice and offset\n    world_coords = SkyCoord(\n        lon=25 * u.deg, lat=10 * u.deg, frame=Galactic\n    )\n    freq = Quantity(20.5, u.Hz)\n    pixel_coords = sliced_wcs.world_to_pixel_values(world_coords, freq)\n    assert_allclose(pixel_coords, (0, 5, 0))\n"], "sample_208": ["    def test_rename_field_with_default(self):\n        before_state = self.make_project_state([\n            self.author_name,\n        ])\n        after_state = self.make_project_state([\n            self.author_name_renamed,\n        ])\n        changes = self.get_changes(before_state.models, after_state.models)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['RenameField'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name', old_name='name_old')\n\n"], "sample_144": ["    def test_m2m_through_model_inheritance(self):\n        \"\"\"\n        Test that M2M fields through intermediary models work correctly with\n        inheritance.\n        \"\"\"\n        p1 = Person.objects.create(name='Person 1')\n        p2 = Person.objects.create(name='Person 2')\n        p3 = Person.objects.create(name='Person 3')\n\n        g1 = Group.objects.create(name='Group 1')\n        g2 = Group.objects.create(name='Group 2')\n\n        p1.groups.add(g1)\n        p2.groups.add(g1)\n        p3.groups.add(g2)\n\n        self.assertEqual(list(p1.groups.all()), [g1])\n        self.assertEqual(list(p2.groups.all()), [g1])\n        self.assertEqual(list(p3.groups.all()), [g2])\n\n        # Test adding a new group to an existing person\n        g3 = Group.objects.create(name='Group 3')\n        p1.groups.add(g3)\n        self.assertEqual(list(p1.groups.all()), [g1, g3])\n\n        # Test removing a group from a person\n        p1.groups.remove(g1)\n        self.assertEqual(list(p1.groups.all()), [g3])\n"], "sample_1175": ["def test_pretty_Heaviside():\n    assert pretty(Heaviside(x)) == 'H(x)'\n    assert pretty(Heaviside(x - 1)) == 'H(x - 1)'\n"], "sample_187": ["    def test_smart_split(self):\n        self.assertEqual(list(text.smart_split(r'This is \"a person\\'s\" test.')),\n                         ['This', 'is', '\"a person\\\\\\'s\"', 'test.'])\n        self.assertEqual(list(text.smart_split(r\"Another 'person\\'s' test.\")),\n                         ['Another', \"'person\\\\'s'\", 'test.'])\n        self.assertEqual(list(text.smart_split(r'A \"\\\"funky\\\" style\" test.')),\n                         ['A', '\"\\\\\"funky\\\\\" style\"', 'test.'])\n"], "sample_47": ["    def test_callable_setting_wrapper(self):\n        class CallableSetting:\n                return 'callable_value'\n\n        wrapped_setting = CallableSettingWrapper(CallableSetting())\n        self.assertEqual(str(wrapped_setting), str(CallableSetting()))\n        self.assertEqual(repr(wrapped_setting), repr(CallableSetting()))\n"], "sample_775": ["    def test_estimator_with_pipeline_in_param():\n        # Test that a pipeline inside an estimator's parameter is printed correctly\n        pipe = make_pipeline(StandardScaler(), LogisticRegression())\n        estimator = RFE(estimator=pipe)\n        expected = (\n            \"RFE(estimator=Pipeline(steps=[('standardscaler', StandardScaler()), \"\n            \"('logisticregression', LogisticRegression())]))\"\n        )\n        assert str(estimator) == expected\n"], "sample_1013": ["def test_lambdify_tensorflow_piecewise():\n    if not tensorflow:\n        skip(\"Tensorflow not installed\")\n    f = Piecewise((x, x < 0), (x**2, x >= 0))\n    f_tf = lambdify(x, f, 'tensorflow')\n    assert f_tf(-1) == -1\n    assert f_tf(1) == 1\n"], "sample_954": ["    def test_nested_inline_transform(self, app, status, warning):\n        app.builder.build_all()\n        content = open(app.outdir / 'manpage.1').read()\n        assert '<strong>foo=</strong><emphasis>var</emphasis>' in content\n        assert '<strong>&bar=</strong><emphasis>2</emphasis>' in content\n"], "sample_259": ["    def test_prefetch_related_objects_to_attr(self):\n        prefetch_related_objects(\n            [self.reader1, self.reader2],\n            Prefetch('books_read', queryset=Book.objects.filter(title__startswith='S')),\n        )\n        self.assertEqual(self.reader1.books_read.all()[0].title, 'Sense and Sensibility')\n        self.assertEqual(self.reader2.books_read.all()[0].title, 'Sense and Sensibility')\n"], "sample_458": ["    def test_floatformat01(self):\n        with translation.override(\"en-us\"):\n            output = self.engine.render_to_string(\"floatformat01\", {\"a\": 1.23456789, \"b\": Decimal(\"1.23456789\")})\n            self.assertEqual(output, \"1.23456789 1.23456789\")\n\n"], "sample_171": ["    def test_migrate_fake_initial(self):\n        \"\"\"\n        Test the --fake-initial flag.\n        \"\"\"\n        # Create a table for our model\n        with connection.cursor() as cursor:\n            cursor.execute(\"CREATE TABLE migrations_unicodemodel (id SERIAL PRIMARY KEY, name VARCHAR(255))\")\n\n        # Create a migration that adds a field to the model\n        self.migrate('test_migrations', '0002_unicodemodel_extra_field')\n\n        # Fake-apply the initial migration\n        call_command('migrate', '--fake-initial', app='migrations')\n\n        # Check that the migration is marked as applied\n        recorder = MigrationRecorder(connections['default'])\n        self.assertIn('0001_initial', recorder.applied_migrations)\n\n        # Check that the table still exists\n        with connection.cursor() as cursor:\n            cursor.execute(\"SELECT * FROM migrations_unicodemodel\")\n            self.assertEqual(cursor.fetchall(), [])\n\n        # Check that the new field is not added to the table\n        with connection.cursor() as cursor:\n            cursor.execute(\"DESCRIBE migrations_unicodemodel\")\n            columns = [column[0] for column in cursor.fetchall()]\n            self.assertNotIn('extra_field', columns)\n"], "sample_856": ["def test_shuffle_split_with_sparse_data():\n    # Test ShuffleSplit with sparse data\n    X = coo_matrix(np.eye(10))\n    y = np.arange(10)\n\n    ss = ShuffleSplit(n_splits=3, test_size=0.25, random_state=42)\n    for train_index, test_index in ss.split(X, y):\n        assert isinstance(X[train_index], coo_matrix)\n        assert isinstance(X[test_index], coo_matrix)\n"], "sample_401": ["    def test_formset_factory_absolute_max(self):\n        formset_class = formset_factory(\n            Choice,\n            max_num=5,\n            absolute_max=3,\n        )\n        formset = formset_class(data={\n            \"choices-TOTAL_FORMS\": \"4\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-0-choice\": \"Choice 1\",\n            \"choices-0-votes\": \"1\",\n            \"choices-1-choice\": \"Choice 2\",\n            \"choices-1-votes\": \"2\",\n            \"choices-2-choice\": \"Choice 3\",\n            \"choices-2-votes\": \"3\",\n            \"choices-3-choice\": \"Choice 4\",\n            \"choices-3-votes\": \"4\",\n        })\n        self.assertEqual(formset.total_form_count(), 3)\n        self.assertEqual(formset.errors, [ErrorList()])\n"], "sample_520": ["def test_poly3dcollection_zsort():\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n\n    verts = [\n        [(0, 0, 0), (1, 0, 0), (1, 1, 0), (0, 1, 0)],\n        [(0, 0, 1), (1, 0, 1), (1, 1, 1), (0, 1, 1)],\n    ]\n    pc = art3d.Poly3DCollection(verts, zsort='min')\n    ax.add_collection3d(pc)\n\n    ax.view_init(elev=30, azim=45)\n    return fig\n"], "sample_508": ["    def test_setp_alias(self):\n        fig, ax = plt.subplots()\n        line, = ax.plot([1, 2, 3], [4, 5, 6])\n        setp(line, 'lw', 3)\n        assert line.get_linewidth() == 3\n\n        setp(line, 'linewidth', 4)\n        assert line.get_linewidth() == 4\n"], "sample_204": ["    def test_custom_migration_module(self):\n        # Test loading migrations from a custom module path\n        with self.assertRaises(NodeNotFoundError):\n            MigrationLoader(connection=connections['default']).get_migration('app', '0001_initial')\n        # Create a migration file in the custom module path\n        os.makedirs(os.path.join(self.migration_dir, 'migrations_custom'), exist_ok=True)\n        with open(os.path.join(self.migration_dir, 'migrations_custom', '0001_initial.py'), 'w') as f:\n            f.write(\"\"\""], "sample_174": ["    def test_integer_field_range(self):\n        self.assertEqual(self.ops.integer_field_range('SmallIntegerField'), (-32768, 32767))\n        self.assertEqual(self.ops.integer_field_range('IntegerField'), (-2147483648, 2147483647))\n        self.assertEqual(self.ops.integer_field_range('BigIntegerField'), (-9223372036854775808, 9223372036854775807))\n"], "sample_58": ["    def test_form_media(self):\n        form = PersonNew()\n        self.assertEqual(form.media.render_js(), '')\n        self.assertEqual(form.media.render_css(), '')\n\n        form.fields['first_name'].widget.attrs['class'] = 'my-class'\n        self.assertEqual(form.media.render_js(), '')\n        self.assertEqual(form.media.render_css(), '')\n\n"], "sample_1193": ["def test_farthest_points_empty():\n    p = []\n    assert farthest_points(*p) == set()\n"], "sample_580": ["    def test_variable_type_strict_boolean():\n        assert variable_type(pd.Series([0, 1, 0, 1]), strict_boolean=True) == VarType(\"numeric\")\n        assert variable_type(pd.Series([True, False, True, False]), strict_boolean=True) == VarType(\"boolean\")\n        assert variable_type(pd.Series([0, 1, np.nan]), strict_boolean=True) == VarType(\"numeric\")\n        assert variable_type(pd.Series([True, False, np.nan]), strict_boolean=True) == VarType(\"boolean\")\n"], "sample_997": ["    def test_convert_equals_signs_nested(self):\n        expr = parse_expr(\"(1*2=x)=False\", transformations=(standard_transformations + (convert_equals_signs,)))\n        assert expr == Eq(Eq(2, x), False)\n"], "sample_74": ["    def test_runshell_db_ssl_options(self):\n        dbinfo = {\n            'host': 'localhost',\n            'port': 5432,\n            'database': 'mydb',\n            'user': 'myuser',\n            'password': 'mypassword',\n            'sslmode': 'require',\n            'sslrootcert': '/path/to/rootcert.pem',\n            'sslcert': '/path/to/cert.pem',\n            'sslkey': '/path/to/key.pem',\n        }\n        args, env = self._run_it(dbinfo)\n        self.assertEqual(args, ['psql', '-U', 'myuser', '-h', 'localhost', '-p', '5432', 'mydb'])\n        self.assertEqual(env, {\n            'PGPASSWORD': 'mypassword',\n            'PGSSLMODE': 'require',\n            'PGSSLROOTCERT': '/path/to/rootcert.pem',\n            'PGSSLCERT': '/path/to/cert.pem',\n            'PGSSLKEY': '/path/to/key.pem',\n        })\n"], "sample_372": ["    def test_reverse_lazy(self):\n        # Test that reverse_lazy works correctly with URL patterns.\n        with self.settings(ROOT_URLCONF='urlpatterns_reverse.urls'):\n            self.assertEqual(reverse_lazy('places', args=[3]), '/places/3/')\n            self.assertEqual(reverse_lazy('people', kwargs={'name': 'adrian'}), '/people/adrian/')\n"], "sample_887": ["    def test_calibration_curve_with_sparse_input(self, data):\n        X, y = data\n        X_sparse = sparse.csr_matrix(X)\n        clf = LogisticRegression(random_state=42)\n        clf.fit(X, y)\n        y_prob = clf.predict_proba(X_sparse)[:, 1]\n        prob_true, prob_pred = calibration_curve(y, y_prob, n_bins=10)\n        assert len(prob_true) == 10\n        assert len(prob_pred) == 10\n\n"], "sample_20": ["    def test_write_read_fits_with_masked_column(self):\n        # Create a table with a masked column\n        t = Table(self.data, masked=True)\n        t[\"c\"][1] = np.ma.masked\n        t.write(\"test.fits\", overwrite=True)\n\n        # Read the table back in\n        t2 = Table.read(\"test.fits\")\n\n        # Check that the masked value is preserved\n        assert np.all(t[\"c\"].mask == t2[\"c\"].mask)\n        assert_allclose(t[\"c\"][~t[\"c\"].mask], t2[\"c\"][~t2[\"c\"].mask])\n        os.remove(\"test.fits\")\n"], "sample_714": ["    def test_brier_score_loss_multilabel(self):\n        # Test brier score loss for multilabel classification\n        X, y = make_multilabel_classification(n_samples=10,\n                                             n_features=5,\n                                             n_classes=3,\n                                             random_state=0)\n        y_pred = np.random.rand(10, 3)\n        score = brier_score_loss(y, y_pred)\n        assert_almost_equal(score, 0.25, decimal=2)\n\n"], "sample_328": ["    def test_bulk_update_with_related_objects(self):\n        self.create_tags()\n        for i, note in enumerate(self.notes):\n            note.tags.add(self.tags[i])\n\n        Note.objects.filter(id__in=[n.id for n in self.notes[:5]]).update(\n            note=F('note') + ' updated', misc=F('misc') + ' updated'\n        )\n\n        for i, note in enumerate(self.notes):\n            if i < 5:\n                self.assertEqual(note.note, f'{i} updated')\n                self.assertEqual(note.misc, f'{i} updated')\n            else:\n                self.assertEqual(note.note, str(i))\n                self.assertEqual(note.misc, str(i))\n"], "sample_526": ["    def test_locator_empty_data(self, locator_class):\n        locator = locator_class()\n        with pytest.raises(ValueError):\n            locator.tick_values(None, None)\n"], "sample_1126": ["    def test_dagger_mul():\n        A = Operator('A')\n        B = Operator('B')\n        assert Dagger(A*B) == Dagger(B)*Dagger(A)\n"], "sample_34": ["    def test_unit_format_parse_with_fraction():\n        with catch_warnings():\n            # Ignore the warning about the deprecated format\n            warnings.simplefilter(\"ignore\", u.UnitsWarning)\n            result = u.Unit('1/2 * m/s').to_string('latex')\n        assert result == r'$\\frac{1}{2} \\, \\frac{\\text{m}}{\\text{s}}$'\n"], "sample_815": ["    def test_brier_score_loss_multiclass():\n        # Test brier score loss for multiclass classification\n        y_true = np.array([0, 1, 2, 0])\n        y_prob = np.array([[0.1, 0.8, 0.1],\n                           [0.2, 0.3, 0.5],\n                           [0.4, 0.1, 0.5],\n                           [0.7, 0.2, 0.1]])\n        score = brier_score_loss(y_true, y_prob)\n        assert_almost_equal(score, 0.425)\n\n"], "sample_1105": ["def test_matmul_inverse():\n    X = MatrixSymbol('X', 2, 2)\n    Y = MatrixSymbol('Y', 2, 2)\n    expr = MatMul(X, Y, Inverse(X*Y))\n    assert expr.doit() == Identity(2)\n"], "sample_385": ["    def test_autocomplete_select_multiple_required(self):\n        form = RequiredBandForm()\n        self.assertHTMLEqual(\n            str(form[\"band\"]),\n            '<select name=\"band\" id=\"id_band\" class=\"my-class admin-autocomplete\" data-ajax--cache=\"true\" data-ajax--delay=\"250\" data-ajax--type=\"GET\" data-ajax--url=\"/admin/autocomplete/\" data-app-label=\"music\" data-model-name=\"band\" data-field-name=\"band\" data-theme=\"admin-autocomplete\" data-allow-clear=\"false\" data-placeholder=\"\" lang=\"en\"><option value=\"\"></option></select>',\n        )\n"], "sample_122": ["    def test_get_cache_key_with_vary_header(self):\n        request = HttpRequest()\n        request.META['HTTP_ACCEPT_LANGUAGE'] = 'en-US'\n        request.META['HTTP_USER_AGENT'] = 'Mozilla/5.0'\n        request.path = '/some/path/'\n        response = HttpResponse()\n        response['Vary'] = 'Accept-Language, User-Agent'\n        learn_cache_key(request, response)\n        cache_key = get_cache_key(request)\n        self.assertIn('en-US', cache_key)\n        self.assertIn('Mozilla/5.0', cache_key)\n"], "sample_1030": ["    def test_closest_points_empty():\n        raises(ValueError, lambda: closest_points())\n"], "sample_821": ["    def test_affinity_propagation_precomputed_sparse(self):\n        # Test affinity propagation with precomputed sparse affinity matrix\n        X = csr_matrix(np.random.rand(10, 10))\n        ap = AffinityPropagation(affinity='precomputed')\n        ap.fit(X)\n        assert_raises(ValueError, ap.predict, np.random.rand(5, 10))\n"], "sample_97": ["    def test_watchman_unavailable(self):\n        with mock.patch('django.utils.autoreload.pywatchman') as mock_watchman:\n            mock_watchman.client.side_effect = WatchmanUnavailable('Watchman unavailable')\n            reloader = autoreload.get_reloader()\n            self.assertIsInstance(reloader, autoreload.StatReloader)\n"], "sample_227": ["    def test_list_filter_with_empty_field_list_filter(self):\n        request = self.request_factory.get('/admin/books/book/')\n        admin = BookAdminWithEmptyFieldListFilter(Book, site)\n        queryset = admin.get_queryset(request)\n        self.assertEqual(queryset.count(), 4)\n\n        request = self.request_factory.get('/admin/books/book/?author__exact=')\n        admin = BookAdminWithEmptyFieldListFilter(Book, site)\n        queryset = admin.get_queryset(request)\n        self.assertEqual(queryset.count(), 4)\n\n        request = self.request_factory.get('/admin/books/book/?title__exact=')\n        admin = BookAdminWithEmptyFieldListFilter(Book, site)\n        queryset = admin.get_queryset(request)\n        self.assertEqual(queryset.count(), 4)\n\n        request = self.request_factory.get('/admin/books/book/?improvedbook__exact=')\n        admin = BookAdminWithEmptyFieldListFilter(Book, site)\n        queryset = admin.get_queryset(request)\n        self.assertEqual(queryset.count(), 4)\n"], "sample_514": ["    def test_colorbar_extension_shape_vertical(self):\n        fig = _colorbar_extension_shape('proportional')\n        for i in range(4):\n            ax = fig.axes[i]\n            bbox = ax.get_position()\n            # Check that the height of the colorbar is greater than the width\n            assert bbox.height > bbox.width\n"], "sample_449": ["    def test_handle_one_request_closes_connection(self):\n        request = self.request_factory.get('/')\n        request.environ['CONTENT_LENGTH'] = '0'\n        handler = WSGIRequestHandler(Stub(makefile=UnclosableBytesIO()),\n                                     Stub(), Stub())\n        handler.requestline = request.get_full_path().encode()\n        handler.command = 'GET'\n        handler.request_version = 'HTTP/1.1'\n        handler.headers = {'Host': 'example.com'}\n        handler.close_connection = False\n        handler.handle_one_request()\n        self.assertTrue(handler.close_connection)\n"], "sample_776": ["    def test_lars_path_residues_positive(self):\n        # Test that _lars_path_residues handles positive constraint correctly.\n        X = np.array([[1, 2], [3, 4], [5, 6]])\n        y = np.array([1, 2, 3])\n        Gram = np.dot(X.T, X)\n        alphas = np.array([1, 0.5, 0.1])\n        coef_path, residues = _lars_path_residues(\n            X, y, Gram=Gram, alphas=alphas, positive=True\n        )\n        assert_greater(coef_path[0, :], 0)\n        assert_greater(coef_path[1, :], 0)\n\n"], "sample_1066": ["    def test_print_EmptySet(self):\n        self.assertEqual(mp.doprint(EmptySet()), '<set/>')\n        self.assertEqual(mpp.doprint(EmptySet()), '<mrow><mo>\u2205</mo></mrow>')\n"], "sample_269": ["    def test_set_language_with_invalid_language_code(self):\n        inactive_language_code = self._get_inactive_language_code()\n        response = self.client.post(reverse('set_language'), {\n            'next': '/',\n            LANGUAGE_QUERY_PARAMETER: inactive_language_code,\n        })\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(get_language(), settings.LANGUAGE_CODE)\n"], "sample_795": ["    def test_sparse_transformer_with_large_sparse_data(self):\n        # Test SparseTransformer with large sparse data\n        rng = np.random.RandomState(0)\n        X = sp.csr_matrix(rng.rand(1000, 1000))\n        transformer = SparseTransformer()\n        transformer.fit(X)\n        transformed_X = transformer.transform(X)\n        assert isinstance(transformed_X, sp.csr_matrix)\n        assert transformed_X.shape == X.shape\n"], "sample_922": ["def test_parse_annotation():\n    assert _parse_annotation('int') == ('int', None)\n    assert _parse_annotation('List[str]') == ('List', 'str')\n    assert _parse_annotation('Dict[str, int]') == ('Dict', ('str', 'int'))\n    assert _parse_annotation('Tuple[int, ...]') == ('Tuple', ('int', '...'))\n    assert _parse_annotation('Callable[[int, str], bool]') == ('Callable', '[[int, str], bool]')\n    assert _parse_annotation('Union[int, str]') == ('Union', ('int', 'str'))\n    assert _parse_annotation('Optional[str]') == ('Optional', 'str')\n    assert _parse_annotation('Any') == ('Any', None)\n"], "sample_959": ["def test_cpp_enum_scoped():\n    check(\n        'enum',\n        'enum { a, b, c };',\n        {1: 'enum'},\n        output='enum { a, b, c }',\n        asTextOutput='enum { a, b, c }'\n    )\n"], "sample_217": ["    def test_multiwidget_media(self):\n        class MyMultiWidget(MultiWidget):\n                widgets = (TextInput(attrs={'class': 'foo'}), TextInput(attrs={'class': 'bar'}))\n                super().__init__(widgets, attrs)\n\n        class MyForm(Form):\n            myfield = MyMultiWidget()\n\n        form = MyForm()\n        expected_media = Media(\n            {'css': {'all': ['http://media.example.com/static/admin/css/widgets.css']}},\n            {'js': ['http://media.example.com/static/admin/js/vendor/jquery/jquery.js',\n                    'http://media.example.com/static/admin/js/jquery.init.js',\n                    'http://media.example.com/static/admin/js/forms.js']},\n        )\n        self.assertEqual(form.media, expected_media)\n"], "sample_779": ["    def test_check_estimator_sparse_input(self):\n        # Test if estimators handle sparse input correctly\n        estimators = [\n            AdaBoostClassifier(),\n            RandomForestClassifier(),\n            LinearRegression(),\n            SGDClassifier(),\n            GaussianMixture(),\n            MiniBatchKMeans(),\n            NMF(),\n            MultiTaskElasticNet(),\n            SVC(),\n            KNeighborsRegressor(),\n        ]\n\n        for estimator in estimators:\n            # Create a sparse matrix\n            X = sp.csr_matrix([[1, 2], [3, 4]])\n            y = np.array([0, 1])\n\n            # Check if the estimator can handle sparse input\n            check_estimator(estimator, X, y)\n\n"], "sample_660": ["    def test_junitxml_with_xunit2_family(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n                pass\n        \"\"\"\n        )\n        result, dom = runandparse(testdir, \"--junitxml\", \"--junit-family=xunit2\")\n        assert result.ret == 0\n        testsuite = dom.find_first_by_tag(\"testsuite\")\n        assert testsuite[\"name\"] == \"pytest\"\n        testcase = testsuite.find_first_by_tag(\"testcase\")\n        assert testcase[\"classname\"] == \"test_func\"\n        assert testcase[\"name\"] == \"test_func\"\n"], "sample_496": ["    def test_management_command_with_custom_settings(self):\n        self.write_settings('custom_settings.py', sdict={'DEBUG': True})\n        os.environ['DJANGO_SETTINGS_MODULE'] = 'custom_settings'\n        try:\n            call_command('help', stdout=StringIO())\n        finally:\n            del os.environ['DJANGO_SETTINGS_MODULE']\n            self.remove_settings('custom_settings.py')\n"], "sample_1177": ["def test_polar_lift_evalf():\n    x = Symbol('x', real=True)\n    assert polar_lift(x).evalf(2) == x.evalf(2)\n    assert polar_lift(2*I).evalf(2) == 2*I\n    assert polar_lift(2 + 2*I).evalf(2) == (2 + 2*I).evalf(2)\n    assert polar_lift(exp(I*pi/4)).evalf(2) == exp(I*pi/4).evalf(2)\n"], "sample_438": ["    def test_generic_foreign_key_with_related_name(self):\n        question = Question.objects.create(text=\"What is the meaning of life?\")\n        answer = Answer.objects.create(question=question, text=\"42\")\n\n        self.assertEqual(answer.content_type.model, \"question\")\n        self.assertEqual(answer.object_id, question.id)\n        self.assertEqual(answer.question, question)\n"], "sample_678": ["    def test_fnmatch_ex(self, match):\n        assert match(\"tests/**/doc/test*.py\", \"tests/foo/bar/doc/test_foo.py\")\n"], "sample_405": ["    def test_rename_model_with_foreign_key(self):\n        with self.connection.cursor() as cursor:\n            cursor.execute(\"CREATE TABLE 'test_related' ('id' INTEGER PRIMARY KEY, 'name' VARCHAR(100))\")\n            cursor.execute(\"CREATE TABLE 'test_model' ('id' INTEGER PRIMARY KEY, 'related_id' INTEGER, FOREIGN KEY ('related_id') REFERENCES 'test_related' ('id'))\")\n\n        class Related(models.Model):\n            name = models.CharField(max_length=100)\n\n        class TestModel(models.Model):\n            related = models.ForeignKey(Related, on_delete=models.CASCADE)\n\n        before_state = ProjectState.from_apps(self.apps)\n        state = before_state.clone()\n        state.models['test_app', 'test_related'] = ModelState.from_model(Related)\n        state.models['test_app', 'test_model'] = ModelState.from_model(TestModel)\n        migration = Migration(\n            \"test_rename_model\",\n            [\n                RenameModel(\"TestModel\", \"RenamedModel\"),\n            ],\n            state=state,\n        )\n\n        with atomic(using=self.connection.alias):\n            with self.assertRaises(IntegrityError):\n                migration.apply(self.connection.alias, self.project_state)\n\n        # Rename the related model first\n        migration = Migration(\n            \"test_rename_related_model\",\n            [\n                RenameModel(\"Related\", \"RenamedRelated\"),\n            ],\n            state=before_state,\n        )\n        migration.apply(self.connection.alias, self.project_state)\n\n        migration = Migration(\n            \"test_rename_model\",\n            [\n                RenameModel(\"TestModel\", \"RenamedModel\"),\n            ],\n            state=self.project_state,\n        )\n        migration.apply(self.connection.alias, self.project_state)\n\n        self.assertTableExists(\"test_app_renamedrelated\")\n        self.assertTableExists(\"test_app_renamedmodel\")\n        self.assertColumnExists(\"test"], "sample_376": ["    def test_cookie_size_limit(self):\n        storage = self.get_storage()\n        messages = [Message(constants.DEBUG, get_random_string(100)) for _ in range(20)]\n        set_cookie_data(storage, messages)\n        response = self.get_response()\n        self.assertEqual(stored_cookie_messages_count(storage, response), 19)\n        self.assertEqual(storage._decode(response.cookies[storage.cookie_name].value)[-1], CookieStorage.not_finished)\n"], "sample_2": ["    def test_ccddata_from_fits_with_wcs(self):\n        # Create a CCDData object with WCS information\n        ccd = create_ccd_data()\n        wcs = WCS(naxis=2)\n        wcs.wcs.crpix = [50.5, 50.5]\n        wcs.wcs.cdelt = [-0.001, 0.001]\n        ccd.wcs = wcs\n\n        # Write the CCDData object to a FITS file\n        with fits.open(get_pkg_data_filename('data/test_ccddata.fits'), 'w') as hdul:\n            hdul[0].data = ccd.data\n            hdul[0].header.update(ccd.header)\n            hdul[0].header.update(ccd.wcs.to_header())\n\n        # Read the FITS file back into a CCDData object\n        ccd_read = CCDData.read(get_pkg_data_filename('data/test_ccddata.fits'))\n\n        # Assert that the WCS information is preserved\n        assert ccd_read.wcs is not None\n        assert ccd_read.wcs.wcs.crpix[0] == 50.5\n        assert ccd_read.wcs.wcs.cdelt[0] == -0.001\n"], "sample_980": ["def test_from_inversion_vector():\n    p = Permutation.from_inversion_vector([3, 2, 1, 0, 0])\n    assert p.array_form == [3, 2, 1, 0, 4, 5]\n    raises(ValueError, lambda: Permutation.from_inversion_vector([4, 2, 1, 0]))\n"], "sample_804": ["    def test_onehot_inverse_transform_unknown_categories(self):\n        enc = OneHotEncoder(handle_unknown='ignore')\n        X = [['Male', 1], ['Female', 3], ['Female', 2]]\n        enc.fit(X)\n        X_trans = enc.transform(X)\n        X_inv = enc.inverse_transform(X_trans)\n        assert_equal(X_inv, np.array([['Male', 1], ['Female', 3], ['Female', 2]]))\n"], "sample_701": ["    def test_deprecated_collect_module(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n                pass\n            pytest.collect.test_hello()\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.assert_outcomes(failed=1)\n        result.stdout.fnmatch_lines(\n            [\n                \"*DeprecationWarning*\",\n                \"*pytest.collect.test_hello was moved to pytest.test_hello*\",\n            ]\n        )\n"], "sample_1019": ["def test_factor_nc_issue_19826():\n    A = Symbol('A', commutative=False)\n    B = Symbol('B', commutative=False)\n    C = Symbol('C', commutative=False)\n    expr = (A*B + A*C + B*C)**2\n    assert factor_nc(expr) == (A + B + C)**2 * A**2 * B**2 * C**2\n"], "sample_262": ["    def test_lazy_str(self):\n        lazy_str = lazystr('Hello, world!')\n        self.assertEqual(str(lazy_str), 'Hello, world!')\n"], "sample_392": ["    def test_key_transform_isnull_with_subquery(self):\n        with self.assertRaises(NotSupportedError):\n            JSONModel.objects.annotate(\n                count=Count(\"data__key1\", filter=Q(data__key1__isnull=True))\n            ).get()\n"], "sample_971": ["    def test_is_suppressed_warning(self):\n        assert not is_suppressed_warning(None, None, [])\n        assert not is_suppressed_warning('foo', None, [])\n        assert is_suppressed_warning('foo', None, ['foo'])\n        assert is_suppressed_warning('foo', 'bar', ['foo.bar'])\n        assert is_suppressed_warning('foo', 'bar', ['foo.*'])\n        assert not is_suppressed_warning('foo', 'bar', ['baz'])\n        assert not is_suppressed_warning('foo', 'bar', ['foo.baz'])\n"], "sample_263": ["    def test_dumpdata_proxy_model_warning(self):\n        with warnings.catch_warnings(record=True) as w:\n            management.call_command('dumpdata', 'testapp', format='json')\n            self.assertEqual(len(w), 1)\n            self.assertIsInstance(w[0].message, ProxyModelWarning)\n            self.assertEqual(str(w[0].message),\n                             \"ProxySpy is a proxy model and won't be serialized.\")\n"], "sample_790": ["    def test_kernelpca_sparse_input(self):\n        X, _ = make_circles(n_samples=100, factor=.3, noise=.05, random_state=0)\n        X_sparse = sp.csr_matrix(X)\n\n        # Test with a dense kernel\n        kpca = KernelPCA(kernel=\"linear\", n_components=2)\n        X_transformed_dense = kpca.fit_transform(X)\n        kpca_sparse = KernelPCA(kernel=\"linear\", n_components=2)\n        X_transformed_sparse = kpca_sparse.fit_transform(X_sparse)\n        assert_array_almost_equal(X_transformed_dense, X_transformed_sparse)\n\n        # Test with a sparse kernel\n        kpca = KernelPCA(kernel=\"rbf\", gamma=10, n_components=2)\n        X_transformed_dense = kpca.fit_transform(X)\n        kpca_sparse = KernelPCA(kernel=\"rbf\", gamma=10, n_components=2)\n        X_transformed_sparse = kpca_sparse.fit_transform(X_sparse)\n        assert_array_almost_equal(X_transformed_dense, X_transformed_sparse)\n"], "sample_194": ["    def test_unique_constraint_with_include(self):\n        with atomic():\n            UniqueConstraintInclude.objects.create(name='foo', value='bar', extra='baz')\n            with self.assertRaises(IntegrityError):\n                UniqueConstraintInclude.objects.create(name='foo', value='bar', extra='qux')\n            UniqueConstraintInclude.objects.create(name='foo', value='qux', extra='baz')\n"], "sample_859": ["    def test_multi_task_lasso_cv_warm_start(self):\n        X, y = load_boston(return_X_y=True)\n        y = np.vstack((y, y)).T\n        n_samples, n_features = X.shape\n        n_tasks = y.shape[1]\n\n        # Create a MultiTaskLassoCV instance with warm_start=True\n        clf = MultiTaskLassoCV(cv=5, warm_start=True, random_state=42)\n\n        # Fit the model on the data\n        clf.fit(X, y)\n\n        # Check that the number of iterations is less than the maximum\n        assert clf.n_iter_ < clf.max_iter\n\n        # Create a copy of the fitted model\n        clf_copy = deepcopy(clf)\n\n        # Fit the copy on the same data\n        clf_copy.fit(X, y)\n\n        # Check that the number of iterations is less than the maximum\n        assert clf_copy.n_iter_ < clf.max_iter\n\n        # Check that the coefficients are the same\n        assert_array_almost_equal(clf.coef_, clf_copy.coef_)\n"], "sample_913": ["def test_parse_annotation():\n    assert _parse_annotation('int') == ('int', None)\n    assert _parse_annotation('str') == ('str', None)\n    assert _parse_annotation('list[int]') == ('list', 'int')\n    assert _parse_annotation('dict[str, int]') == ('dict', 'str, int')\n    assert _parse_annotation('Optional[str]') == ('Optional', 'str')\n    assert _parse_annotation('Union[int, str]') == ('Union', 'int, str')\n    assert _parse_annotation('Callable[[int], str]') == ('Callable', '[[int], str]')\n"], "sample_986": ["def test_evalf_piecewise():\n    p = Piecewise((x, x < 0), (x**2, x >= 0))\n    assert NS(p.subs(x, -1)) == '-1'\n    assert NS(p.subs(x, 1)) == '1'\n    assert NS(p.subs(x, 0)) == '0'\n"], "sample_201": ["    def test_cookie_storage_max_size(self):\n        storage = self.storage_class(self.request)\n        messages = [\n            Message(constants.ERROR, 'Message 1', extra_tags='error'),\n            Message(constants.INFO, 'Message 2'),\n            Message(constants.WARNING, 'Message 3'),\n            Message(constants.SUCCESS, 'Message 4'),\n        ]\n        set_cookie_data(storage, messages)\n        response = self.get_response(storage)\n        self.assertEqual(stored_cookie_messages_count(storage, response), 4)\n        messages.append(Message(constants.DEBUG, 'Message 5'))\n        set_cookie_data(storage, messages)\n        response = self.get_response(storage)\n        self.assertEqual(stored_cookie_messages_count(storage, response), 4)\n        self.assertEqual(storage._loaded_data[-1], CookieStorage.not_finished)\n"], "sample_1063": ["def test_lambdify_tensorflow_with_constant():\n    if not tensorflow:\n        skip(\"TensorFlow is not installed.\")\n    x = sympy.Symbol('x')\n    f = sympy.sin(x)\n    f_tf = lambdify(x, f, 'tensorflow')\n    result = f_tf(tensorflow.constant(1.0))\n    assert isinstance(result, tensorflow.Tensor)\n    assert result.numpy() == math.sin(1.0)\n"], "sample_581": ["    def test_blueprint_register_twice_same_name(self):\n        app = flask.Flask(__name__)\n        bp1 = flask.Blueprint('my_bp', __name__)\n        bp2 = flask.Blueprint('my_bp', __name__)\n\n        with pytest.raises(ValueError) as e:\n            app.register_blueprint(bp1)\n            app.register_blueprint(bp2)\n\n        assert \"The name 'my_bp' is already registered\" in str(e.value)\n"], "sample_433": ["    def test_rabbit_circular_fk(self):\n        knight = Knight.objects.create()\n        rabbit1 = Rabbit.objects.create(knight=knight)\n        rabbit2 = Rabbit.objects.create(knight=knight, parent=rabbit1)\n        with self.assertRaises(IntegrityError):\n            Rabbit.objects.create(knight=knight, parent=rabbit2)\n"], "sample_846": ["    def test_column_transformer_sparse_output_threshold(self):\n        X = np.array([[1, 2], [3, 4], [5, 6]])\n        sparse_X = sparse.csr_matrix(X)\n\n        ct = ColumnTransformer(\n            transformers=[\n                ('num', StandardScaler(), [0]),\n                ('cat', OneHotEncoder(), [1])\n            ],\n            sparse_threshold=0.5,\n        )\n        ct.fit(sparse_X)\n        result = ct.transform(sparse_X)\n        assert isinstance(result, sparse.csr_matrix)\n\n        ct = ColumnTransformer(\n            transformers=[\n                ('num', StandardScaler(), [0]),\n                ('cat', OneHotEncoder(), [1])\n            ],\n            sparse_threshold=0.1,\n        )\n        ct.fit(sparse_X)\n        result = ct.transform(sparse_X)\n        assert isinstance(result, np.ndarray)\n\n"], "sample_756": ["    def test_optics_cluster_extraction_varying_eps(self):\n        X, y = make_blobs(n_samples=100, centers=3, random_state=0)\n        optics = OPTICS(min_samples=5, max_eps=2, metric='euclidean')\n        optics.fit(X)\n        labels_05 = optics.extract_dbscan(eps=0.5)\n        labels_1 = optics.extract_dbscan(eps=1)\n        labels_15 = optics.extract_dbscan(eps=1.5)\n\n        assert_equal(len(set(labels_05[1])), 3)\n        assert_equal(len(set(labels_1[1])), 3)\n        assert_equal(len(set(labels_15[1])), 1)\n\n"], "sample_1190": ["    def test_get_dimensional_expr(self):\n        x = Symbol('x')\n        t = Symbol('t')\n        v = Symbol('v')\n        a = Symbol('a')\n        m = Symbol('m')\n\n        expr = v*t + 0.5*a*t**2\n        dim = SI.get_dimensional_expr(expr)\n        assert dim == length/time\n\n        expr = m*v**2/2\n        dim = SI.get_dimensional_expr(expr)\n        assert dim == energy\n\n        expr = exp(x*t)\n        dim = SI.get_dimensional_expr(expr)\n        assert dim == S.One\n\n        expr = sin(x*t)\n        dim = SI.get_dimensional_expr(expr)\n        assert dim == S.One\n\n        expr = log(x*t)\n        dim = SI.get_dimensional_expr(expr)\n        assert dim == S.One\n\n        expr = diff(x*t**2, t)\n        dim = SI.get_dimensional_expr(expr)\n        assert dim == length\n\n        expr = integrate(v, t)\n        dim = SI.get_dimensional_expr(expr)\n        assert dim == length\n\n"], "sample_444": ["    def test_manifest_strict_missing_file(self):\n        \"\"\"\n        Test that a strict manifest raises an error if a file is missing.\n        \"\"\"\n        # Create a manifest with a single file.\n        manifest_data = {\n            \"paths\": {\"/css/style.css\": \"css/style-1234567890ab.css\"},\n            \"version\": \"1.1\",\n            \"hash\": \"somehash\",\n        }\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as f:\n            json.dump(manifest_data, f)\n            manifest_path = f.name\n        settings.STATICFILES_STORAGE = (\n            \"django.contrib.staticfiles.storage.ManifestStaticFilesStorage\"\n        )\n        settings.STATICFILES_MANIFEST_STORAGE = (\n            \"django.contrib.staticfiles.storage.ManifestStaticFilesStorage\"\n        )\n        settings.STATIC_ROOT = os.path.join(TEST_ROOT, \"staticfiles\")\n        storage.staticfiles_storage.manifest_name = \"manifest.json\"\n        storage.staticfiles_storage.manifest_storage = storage.staticfiles_storage\n        shutil.copy(manifest_path, os.path.join(settings.STATIC_ROOT, \"manifest.json\"))\n\n        # Try to access a file that's not in the manifest.\n        with self.assertRaises(ValueError) as e:\n            storage.staticfiles_storage.url(\"css/missing.css\")\n        self.assertEqual(\n            str(e.exception), \"Missing staticfiles manifest entry for 'css/missing.css'\"\n        )\n"], "sample_451": ["    def test_parse_docstring(self):\n        title, body, metadata = parse_docstring(self.docstring)\n        self.assertEqual(title, \"Display an individual :model:`myapp.MyModel`.\")\n        self.assertEqual(\n            body,\n            \"Display an individual :model:`myapp.MyModel`.\\n\\n\"\n            \"**Context**\\n\\n\"\n            \"``RequestContext``\\n\\n\"\n            \"``mymodel``\\n\"\n            \"        An instance of :model:`myapp.MyModel`.\\n\\n\"\n            \"**Template:**\\n\\n\"\n            \":template:`myapp/my_template.html` (DESCRIPTION)\",\n        )\n        self.assertEqual(metadata, {\"some_metadata\": \"some data\"})\n"], "sample_1072": ["def test_frac_rewrite_as_floor():\n    assert frac(x).rewrite(floor) == x - floor(x)\n    assert frac(x + I*y).rewrite(floor) == x + I*y - floor(x + I*y)\n    assert frac(2*E).rewrite(floor) == 2*E - floor(2*E)\n    assert frac(Rational(23, 10)).rewrite(floor) == Rational(23, 10) - floor(Rational(23, 10))\n"], "sample_782": ["    def test_column_transformer_sparse_output(self):\n        X = np.array([[1, 2], [3, 4], [5, 6]])\n        sparse_X = sparse.csr_matrix(X)\n\n        ct = ColumnTransformer(\n            transformers=[\n                ('num', StandardScaler(), [0]),\n                ('cat', OneHotEncoder(), [1])\n            ],\n            remainder='passthrough',\n            sparse_threshold=0.5\n        )\n        ct.fit(sparse_X)\n        result = ct.transform(sparse_X)\n        assert isinstance(result, sparse.csr_matrix)\n\n        ct = ColumnTransformer(\n            transformers=[\n                ('num', StandardScaler(), [0]),\n                ('cat', OneHotEncoder(), [1])\n            ],\n            remainder='passthrough',\n            sparse_threshold=0.0\n        )\n        ct.fit(sparse_X)\n        result = ct.transform(sparse_X)\n        assert isinstance(result, np.ndarray)\n\n"], "sample_1140": ["def test_pretty_MatrixSlice():\n    A = MatrixSymbol('A', 3, 3)\n    assert pretty(A[1, :]) == 'A_{1, :}'\n    assert pretty(A[:, 2]) == 'A_{:, 2}'\n    assert pretty(A[1:3, 1:3]) == 'A_{1:3, 1:3}'\n"], "sample_785": ["    def test_shuffle_split_with_groups_sparse(self):\n        X = coo_matrix(np.eye(10))\n        y = np.arange(10)\n        groups = np.array([0, 0, 1, 1, 1, 2, 2, 2, 3, 3])\n        splitter = GroupShuffleSplit(n_splits=3, test_size=.25, random_state=0)\n        for train, test in splitter.split(X, y, groups):\n            assert_array_equal(np.unique(groups[train]),\n                               np.unique(groups[test]))\n"], "sample_399": ["    def test_aggregate_with_subquery(self):\n        # Test aggregation with a subquery that filters the results.\n        subquery = Book.objects.filter(rating__gt=4.0).values(\"publisher\")\n        result = (\n            Author.objects.filter(book__in=subquery)\n            .annotate(num_books=Count(\"book\"))\n            .order_by(\"num_books\")\n        )\n        self.assertQuerysetEqual(\n            result,\n            [\n                (\"James Bennett\", 1),\n                (\"Jeffrey Forcier\", 1),\n                (\"Adrian Holovaty\", 1),\n            ],\n            lambda a: (a.name, a.num_books),\n        )\n"], "sample_654": ["    def test_fixture_lookup_error_with_available_fixtures(self, tmpdir):\n        tmpdir.join(\"conftest.py\").write(\n            textwrap.dedent(\n                \"\"\"\n                import pytest\n\n                @pytest.fixture\n                    return 1\n\n                @pytest.fixture\n                    return 2\n                \"\"\"\n            )\n        )\n        with pytest.raises(FixtureLookupError) as excinfo:\n            pytest.main([\"-q\", str(tmpdir)])\n        assert excinfo.value.argname == \"fixture_c\"\n        assert \"available fixtures\" in str(excinfo.value)\n"], "sample_72": ["    def test_serialize_lazy_object(self):\n        lazy_value = SimpleLazyObject(lambda: 'test')\n        serializer = serializer_factory(lazy_value)\n        self.assertEqual(serializer.serialize(), (\"'test'\", set()))\n"], "sample_1070": ["def test_LambertW_eval_k():\n    assert LambertW(1.2, 0).n() == 0.635564016364870\n    assert LambertW(1.2, -1).n() == -1.34747534407696 - 4.41624341514535*I\n    assert LambertW(-1, 0).is_real is False\n    assert LambertW(-1, -1).is_real is True\n"], "sample_836": ["    def test_type_of_target_multilabel_sequences(self):\n        for y in MULTILABEL_SEQUENCES:\n            assert_raises_regex(ValueError,\n                                \"Sequence of sequences are no longer supported\",\n                                type_of_target, y)\n"], "sample_192": ["    def test_formset_factory_with_custom_kwargs(self):\n        formset_class = formset_factory(CustomKwargForm, extra=1)\n        formset = formset_class(\n            {'form-0-custom_kwarg': 'test'},\n            custom_kwarg='test_value',\n        )\n        self.assertEqual(formset.forms[0].custom_kwarg, 'test_value')\n"], "sample_589": ["def test_interp_na_multidim_nonuniform_time(da):\n    da, df = make_interpolate_example_data(shape=(10, 5), frac_nan=0.5, non_uniform=True)\n    interpolated = da.interp(time=da.time.values[1:9])\n    assert_array_equal(interpolated.values, df.interpolate(method='linear').values)\n\n"], "sample_320": ["    def test_add_foreign_key(self):\n        # Add a foreign key to an existing model\n        with atomic(using=self.connection.alias):\n            with self.assertRaises(FieldDoesNotExist):\n                Food.objects.get(restaurant__name='Pizza Place')\n\n            # Create a migration\n            migration = Migration(\n                'test_add_foreign_key',\n                [\n                    migrations.AddField(\n                        model_name='food',\n                        name='restaurant',\n                        field=models.ForeignKey(\n                            on_delete=models.CASCADE, to='test_app.Restaurant'\n                        ),\n                    ),\n                ],\n            )\n\n            # Apply the migration\n            self.apply_migration(migration)\n\n            # Check the database\n            food = Food.objects.create(name='Pizza', restaurant=Restaurant.objects.create(name='Pizza Place'))\n            self.assertEqual(food.restaurant.name, 'Pizza Place')\n\n            # Rollback the migration\n            self.rollback_migration(migration)\n\n            # Check that the field is gone\n            with self.assertRaises(FieldDoesNotExist):\n                Food.objects.get(restaurant__name='Pizza Place')\n"], "sample_52": ["    def test_modelchoicefield_empty_label(self):\n        class CategoryForm(forms.ModelForm):\n            class Meta:\n                model = Category\n                fields = ['name']\n\n        form = CategoryForm()\n        self.assertIn('', form.fields['name'].choices[0])\n        self.assertEqual(form.fields['name'].choices[0][1], '---------')\n\n"], "sample_1073": ["def test_sqrtdenest_biquadratic_denest():\n    x = Symbol('x', positive=True)\n    w = sqrt(2 + r2 + 5*r3 + (1 + r3)*sqrt(2 + r2 + 5*r3))\n    expr = sqrt((w**2).expand())\n    a, b, r = _sqrt_match(expr**2)\n    d2 = a**2 - b**2*r\n    res = sqrt_biquadratic_denest(expr, a, b, r, d2)\n    assert res == sqrt(2) + sqrt(sqrt(2) + 2) + 2\n"], "sample_83": ["    def test_filter_function_with_flags(self):\n        @self.library.filter(is_safe=True, expects_localtime=True)\n            return value\n\n        self.assertTrue(my_filter.is_safe)\n        self.assertTrue(my_filter.expects_localtime)\n        self.assertEqual(my_filter._filter_name, 'my_filter')\n"], "sample_677": ["    def test_not_expr_parentheses():\n        assert evaluate(\"not (a)\", lambda x: x == \"a\") is False\n        assert evaluate(\"not (not a)\", lambda x: x == \"a\") is True\n"], "sample_1184": ["    def test_conjugate_gauss_beams_f():\n        l, w_i, w_o = symbols('l w_i w_o')\n        assert streq(str(conjugate_gauss_beams(1064e-9, 1e-3, 5e-3, f=1)[0]),\n                     '1*(1 - sqrt(w_i**2/w_o**2 - pi**2*w_i**4/(f**2*l**2)))')\n        assert streq(str(conjugate_gauss_beams(1064e-9, 1e-3, 5e-3, f=1)[1]),\n                     'f*w_o**2*(w_i**2/w_o**2 - sqrt(w_i**2/w_o**2 - pi**2*w_i**4/(f**2*l**2)))/w_i**2')\n        assert streq(str(conjugate_gauss_beams(1064e-9, 1e-3, 5e-3, f=1)[2]),\n                     '1')\n"], "sample_1195": ["compilation error"], "sample_460": ["    def test_changelist_ordering(self):\n        response = self.client.get(reverse(\"admin:books_book_changelist\"))\n        self.assertContains(response, 'Book 1')\n        self.assertContains(response, 'Book 2')\n        response = self.client.get(reverse(\"admin:books_book_changelist\") + \"?o=-name\")\n        self.assertContains(response, 'Book 2')\n        self.assertContains(response, 'Book 1')\n"], "sample_1173": ["    def test_convert_equals_signs_nested():\n        assert parse_expr(\"(1*2=x)=False\", transformations=(standard_transformations + (convert_equals_signs,))) == Eq(Eq(2, x), False)\n"], "sample_234": ["    def test_union_with_different_select_related(self):\n        qs1 = Number.objects.select_related('other_number').filter(num__lt=5)\n        qs2 = Number.objects.filter(num__gte=5).select_related('other_number')\n        self.assertNumbersEqual(qs1.union(qs2), list(range(10)))\n"], "sample_746": ["    def test_brier_score_loss_multilabel(self):\n        # Test brier score loss for multilabel classification\n        X, y = make_multilabel_classification(n_samples=10,\n                                             n_features=5,\n                                             n_classes=3,\n                                             random_state=0)\n        y_pred = np.random.rand(10, 3)\n        score = brier_score_loss(y, y_pred)\n        assert_almost_equal(score, 0.333333333333, 8)\n"], "sample_805": ["    def test_mean_tweedie_deviance_p_values():\n        y_true = np.array([1, 2, 3, 4])\n        y_pred = np.array([1.1, 1.9, 3.1, 3.9])\n\n        for p in [-1, 0, 1, 2, 3]:\n            mean_tweedie_deviance(y_true, y_pred, p=p)\n\n        with pytest.raises(ValueError):\n            mean_tweedie_deviance(y_true, y_pred, p=-2)\n\n        with pytest.raises(ValueError):\n            mean_tweedie_deviance(y_true, y_pred, p=1.5)\n"], "sample_395": ["    def test_template_changed_resets_loaders(self):\n        mock_reset_loaders = self.patcher(\"django.template.autoreload.reset_loaders\")\n        file_path = EXTRA_TEMPLATES_DIR / \"test.html\"\n        autoreload.file_changed(file_path)\n        mock_reset_loaders.assert_called_once()\n"], "sample_1112": ["    def test_digits_negative_base():\n        raises(ValueError, lambda: digits(10, b=-2))\n"], "sample_33": ["    def test_did_you_mean_fix():\n        candidates = ['foo', 'bar', 'baz']\n        assert misc.did_you_mean('fo', candidates) == 'Did you mean foo?'\n        assert misc.did_you_mean('ba', candidates) == 'Did you mean bar?'\n        assert misc.did_you_mean('qux', candidates) == ''\n\n            return [s.upper()]\n        assert misc.did_you_mean('fo', candidates, fix=fix) == 'Did you mean FO?'\n"], "sample_582": ["def test_run_command_with_cert_adhoc(runner, tmpdir):\n    \"\"\"Test running with adhoc certificates.\"\"\"\n    app = Flask(__name__)\n    with tmpdir.as_cwd():\n        with open(\"app.py\", \"w\") as f:\n            f.write(\"from flask import Flask; app = Flask(__name__)\")\n        result = runner.invoke(\n            run_command, [\"--cert\", \"adhoc\", \"--host\", \"127.0.0.1\", \"--port\", \"5001\"]\n        )\n        assert result.exit_code == 0\n        assert \"Serving Flask app 'app'\" in result.output\n        assert \" * Debug mode: on\" in result.output\n"], "sample_3": ["def test_ecsv_masked_column():\n    \"\"\"Test writing and reading a table with a masked column.\"\"\"\n    # Create a table with a masked column\n    t = Table()\n    t['a'] = np.array([1, 2, 3], dtype=int)\n    t['b'] = MaskedColumn([1.0, np.nan, 3.0], mask=[False, True, False], unit='m/s')\n\n    # Write the table to a string\n    with StringIO() as f:\n        ascii.write(t, f, format='ecsv')\n        ecsv_str = f.getvalue()\n\n    # Read the table back from the string\n    t2 = ascii.read(ecsv_str, format='ecsv')\n\n    # Check that the masked column is read correctly\n    assert t2['b'].mask[1] is True\n    assert quantity_allclose(t2['b'].filled(0), [1.0, 0, 3.0])\n"], "sample_929": ["def test_parse_annotation():\n    assert _parse_annotation('int') == ('int', None)\n    assert _parse_annotation('str, int') == ('str', 'int')\n    assert _parse_annotation('List[int]') == ('List', 'int')\n    assert _parse_annotation('Dict[str, int]') == ('Dict', 'str, int')\n    assert _parse_annotation('Optional[int]') == ('Optional', 'int')\n    assert _parse_annotation('Union[str, int]') == ('Union', 'str, int')\n    assert _parse_annotation('Callable[[int], str]') == ('Callable', '[[int], str]')\n    assert _parse_annotation('Any') == ('Any', None)\n"], "sample_121": ["    def test_index_together_invalid_field(self):\n        with self.assertRaisesMessage(ImproperlyConfigured,\n                                     \"The field 'does_not_exist' does not exist in model 'InvalidModel'\"):\n            class InvalidModel(models.Model):\n                name = models.CharField(max_length=100)\n                index_together = [('name', 'does_not_exist')]\n"], "sample_319": ["    def test_rabbit_circular_fk_index(self):\n        knight = Knight.objects.create()\n        rabbit1 = Rabbit.objects.create(knight=knight)\n        rabbit2 = Rabbit.objects.create(knight=knight, parent=rabbit1)\n        self.assertEqual(Rabbit.objects.filter(knight=knight, parent=rabbit1).count(), 1)\n"], "sample_39": ["    def test_maps_001(self):\n        with warnings.catch_warnings():\n            warnings.simplefilter('ignore', AstropyUserWarning)\n            with fits.open(get_pkg_data_filename('maps/maps_001.hdr')) as hdul:\n                wcs = wcs.WCS(hdul[0].header)\n                assert wcs.wcs.naxis == 2\n                assert wcs.wcs.ctype[0] == 'RA---TAN'\n                assert wcs.wcs.ctype[1] == 'DEC--TAN'\n"], "sample_718": ["    def test_no_sample_weight_pandas_series_type(self):\n        # Test if estimator raises ValueError when sample_weight is pandas Series\n        estimator = NoSampleWeightPandasSeriesType()\n        X = np.array([[1, 2], [3, 4]])\n        y = np.array([0, 1])\n        import pandas as pd\n        sample_weight = pd.Series([1.0, 2.0])\n        assert_raises_regex(ValueError,\n                            \"Estimator does not accept 'sample_weight'\"\n                            \" of type pandas.Series\",\n                            estimator.fit, X, y, sample_weight=sample_weight)\n\n"], "sample_744": ["    def test_quantile_transform_ignore_zeros(self):\n        X = np.array([[0, 1], [0, 2], [1, 0], [1, 1]])\n        qt = QuantileTransformer(output_distribution='normal',\n                                ignore_zeros=True)\n        X_trans = qt.fit_transform(X)\n        assert_array_almost_equal(X_trans[0], qt.transform([[0, 0]]))\n        assert_array_almost_equal(X_trans[2], qt.transform([[1, 0]]))\n"], "sample_1069": ["def test_glsl_piecewise_no_default():\n    expr = Piecewise((x + 1, x > 0), (x, x < 0))\n    with raises(ValueError):\n        glsl_code(expr)\n"], "sample_81": ["    def test_regex_pattern_with_language_prefix(self):\n        pattern = RegexPattern(r'^/(?P<language>[a-z]{2})/path/(?P<pk>\\d+)/$', name='path')\n        resolver = get_resolver()\n        match = pattern.match('/fr/path/1/')\n        self.assertEqual(match[0], '')\n        self.assertEqual(match[1], ('1',))\n        self.assertEqual(match[2], {'language': 'fr', 'pk': '1'})\n"], "sample_362": ["    def test_rename_field_with_default(self):\n        before = self.make_project_state([\n            self.author_name,\n        ])\n        after = self.make_project_state([\n            self.author_name_renamed_field,\n        ])\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['RenameField'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name', old_name='name')\n\n"], "sample_1172": ["def test_solve_biquadratic_complex():\n    x, y = symbols('x y')\n    a = Poly(x**2 + y**2 - 1, x, y)\n    b = Poly(x*y - I, x, y)\n    sol = solve_biquadratic(a, b, Options((x, y), {'domain': 'C'}))\n    assert len(sol) == 4\n    assert all(isinstance(s, tuple) for s in sol)\n"], "sample_89": ["    def test_iter_modules_and_files_zipfile(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_path = Path(tempdir) / 'my_module.zip'\n            with zipfile.ZipFile(zip_path, 'w') as zf:\n                zf.writestr('my_module/__init__.py', '')\n            sys.path.append(str(tempdir))\n            self.import_and_cleanup('my_module')\n            self.assertFileFound(zip_path)\n"], "sample_829": ["    def test_sparse_input_partial_fit(self):\n        # Test that IncrementalPCA.partial_fit raises an error when\n        # given sparse input.\n        ipca = IncrementalPCA(n_components=2)\n        X_sparse = sparse.csr_matrix(iris.data)\n        assert_raises(TypeError, ipca.partial_fit, X_sparse)\n"], "sample_193": ["    def test_many_to_many_field_with_through_model(self):\n        apps = Apps()\n        apps.register(models.Model)\n        apps.register(UnicodeModel)\n        apps.register(FoodManager)\n        apps.register(FoodQuerySet)\n        apps.register(NoMigrationFoodManager)\n        apps.register(ModelWithCustomBase)\n\n        state = ProjectState.from_apps(apps)\n\n        # Create a model with a ManyToManyField with a through model\n        class Author(models.Model):\n            name = models.CharField(max_length=100)\n            books = models.ManyToManyField(UnicodeModel, through='BookAuthor')\n\n        class BookAuthor(models.Model):\n            author = models.ForeignKey(Author, on_delete=models.CASCADE)\n            book = models.ForeignKey(UnicodeModel, on_delete=models.CASCADE)\n            date_joined = models.DateField()\n\n        state.add_model(Author)\n        state.add_model(BookAuthor)\n        state.add_model(UnicodeModel)\n\n        # Check that the state reflects the ManyToManyField and its through model\n        self.assertIn('books', state.models['app_label', 'Author'].fields)\n        self.assertEqual(\n            state.models['app_label', 'Author'].fields['books'].remote_field.through,\n            state.models['app_label', 'BookAuthor'],\n        )\n\n        # Check that the through model has the correct foreign keys\n        self.assertIn('author', state.models['app_label', 'BookAuthor'].fields)\n        self.assertIn('book', state.models['app_label', 'BookAuthor'].fields)\n"], "sample_86": ["    def test_lazy_str(self):\n        lazy_str = lazy(str, str)('hello')\n        self.assertEqual(str(lazy_str), 'hello')\n        self.assertEqual(repr(lazy_str), \"'hello'\")\n"], "sample_657": ["    def test_mark_parametrize_empty_set(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"arg\", [])\n                pass\n            \"\"\"\n        )\n        result = testdir.runpytest()\n        assert result.ret == EXIT_INTERRUPTED\n        assert result.stdout.str().find(\n            \"Empty parameter set in 'test_empty' at line 4\"\n        ) != -1\n"], "sample_1149": ["    def test_singleton_registration():\n        class MySingleton(Basic, metaclass=Singleton):\n            pass\n        assert MySingleton() is MySingleton()\n        assert S.MySingleton is MySingleton()\n"], "sample_356": ["    def test_rename_field_with_default(self):\n        before_state = self.make_project_state([\n            self.author_name,\n        ])\n        after_state = self.make_project_state([\n            self.author_name_renamed_field,\n        ])\n        changes = self.get_changes(before_state, after_state)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['RenameField'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name', old_name='name')\n\n"], "sample_487": ["    def test_raw_id_fields_with_related_lookup(self):\n        class MyModelAdmin(ModelAdmin):\n            raw_id_fields = ('related_field',)\n\n        class MyModel(models.Model):\n            related_field = ForeignKey(User, on_delete=CASCADE)\n\n        self.assertIsInvalid(\n            MyModelAdmin,\n            MyModel,\n            msg=r\"The value of 'raw_id_fields' refers to 'related_field', which is a ForeignKey. \"\n            r\"You should use 'related_lookup_fields' instead.\",\n            id=\"admin.E131\",\n        )\n"], "sample_1042": ["def test_indexed_subs():\n    i, j = symbols('i j', integer=True)\n    A = IndexedBase('A')\n    x = Symbol('x')\n    expr = A[i, j]\n    assert Subs(expr, (i, j), (x, x + 1)).doit() == A[x, x + 1]\n"], "sample_241": ["    def test_expression_wrapper(self):\n        query = self.company_query.annotate(\n            double_employees=ExpressionWrapper(F('num_employees') * 2, output_field=IntegerField())\n        )\n        self.assertQuerysetEqual(\n            query, [\n                {'name': 'Example Inc.', 'num_employees': 2300, 'num_chairs': 5, 'double_employees': 4600},\n                {'name': 'Foobar Ltd.', 'num_employees': 3, 'num_chairs': 4, 'double_employees': 6},\n                {'name': 'Test GmbH', 'num_employees': 32, 'num_chairs': 1, 'double_employees': 64},\n            ],\n            transform=lambda x: {k: v for k, v in x.items() if k != 'id'}\n        )\n"], "sample_602": ["    def test_to_netcdf_multifile(self):\n        ds = xr.Dataset({\"foo\": ((\"x\", \"y\"), np.arange(12).reshape(3, 4))})\n        with tempfile.TemporaryDirectory() as tmpdir:\n            paths = [os.path.join(tmpdir, f\"file_{i}.nc\") for i in range(3)]\n            xr.save_mfdataset([ds] * 3, paths, engine=\"scipy\")\n            for path in paths:\n                with xr.open_dataset(path) as ds_loaded:\n                    assert_identical(ds, ds_loaded)\n"], "sample_254": ["    def test_inline_formset_initial_forms_are_valid(self):\n        request = self.factory.get('/admin/admin_inlines/holder/')\n        request.user = self.superuser\n        formset = InlineAdminForm.get_formset(request, self.holder, InnerInline, None)\n        self.assertTrue(all(form.is_valid() for form in formset.initial_forms))\n"], "sample_42": ["    def test_brightness_temperature_beam_area():\n        freq = 5 * u.GHz\n        beam_sigma = 50 * u.arcsec\n        beam_area = 2 * np.pi * (beam_sigma)**2\n        equiv = u.brightness_temperature(freq, beam_area)\n        assert_quantity_allclose((1 * u.Jy / beam_area).to(u.K, equivalencies=equiv),\n                                 3.526295144567176 * u.K)\n"], "sample_1107": ["def test_generate_oriented_forest():\n    assert list(generate_oriented_forest(4)) == [\n        [0, 1, 2, 3], [0, 1, 2, 2], [0, 1, 2, 1], [0, 1, 2, 0],\n        [0, 1, 1, 1], [0, 1, 1, 0], [0, 1, 0, 1], [0, 1, 0, 0],\n        [0, 0, 0, 0]]\n"], "sample_213": ["    def test_filedescriptor_get_with_none(self):\n        class MyModel(models.Model):\n            file = FileField()\n\n        instance = MyModel()\n        descriptor = MyModel._meta.get_field('file').descriptor_class(MyModel._meta.get_field('file'))\n        self.assertIsNone(descriptor.__get__(instance, MyModel))\n"], "sample_404": ["    def test_variable_attribute_lookup(self):\n        template = '{% load templatetag %}{{ foo.bar }}'\n        context = Context({'foo': {'bar': 'baz'}})\n        output = self.engine.render_to_string(template, context)\n        self.assertEqual(output, 'baz')\n"], "sample_577": ["    def test_subplot_spec_sharing(self):\n\n        p = Plot()\n        p.add(MockMark(), x=\"col\", y=\"row\")\n        p.add(MockMark(), x=\"col\", y=\"row\")\n\n        data = pd.DataFrame({\"col\": [1, 1, 2, 2], \"row\": [1, 2, 1, 2], \"x\": [1, 2, 3, 4], \"y\": [5, 6, 7, 8]})\n        p._data = data\n\n        p._subplots = [\n            {\"ax\": plt.subplot(2, 2, 1), \"col\": 1, \"row\": 1},\n            {\"ax\": plt.subplot(2, 2, 2), \"col\": 1, \"row\": 2},\n            {\"ax\": plt.subplot(2, 2, 3), \"col\": 2, \"row\": 1},\n            {\"ax\": plt.subplot(2, 2, 4), \"col\": 2, \"row\": 2},\n        ]\n\n        p._scales = {\"x\": Continuous(), \"y\": Continuous()}\n        p._shares = {\"x\": \"col\", \"y\": \"row\"}\n\n        p._setup_scales(data)\n        p._plot_layers()\n\n        assert p._subplots[0][\"ax\"].get_xlim() == p._subplots[1][\"ax\"].get_xlim()\n        assert p._subplots[2][\"ax\"].get_xlim() == p._subplots[3][\"ax\"].get_xlim()\n        assert p._subplots[0][\"ax\"].get_ylim() == p._subplots[2][\"ax\"].get_ylim()\n        assert p._subplots[1][\"ax\"].get_ylim() == p._subplots[3][\"ax\"].get_ylim()\n\n"], "sample_456": ["    def test_formset_factory_absolute_max(self):\n        formset_class = formset_factory(\n            Choice,\n            max_num=5,\n            absolute_max=3,\n        )\n        formset = formset_class(data={\n            \"form-TOTAL_FORMS\": \"4\",\n            \"form-INITIAL_FORMS\": \"0\",\n            \"form-MAX_NUM_FORMS\": \"5\",\n            \"form-MIN_NUM_FORMS\": \"0\",\n            \"form-0-choice\": \"Choice 1\",\n            \"form-0-votes\": \"1\",\n            \"form-1-choice\": \"Choice 2\",\n            \"form-1-votes\": \"2\",\n            \"form-2-choice\": \"Choice 3\",\n            \"form-2-votes\": \"3\",\n            \"form-3-choice\": \"Choice 4\",\n            \"form-3-votes\": \"4\",\n        })\n        self.assertEqual(formset.total_form_count(), 3)\n        self.assertEqual(formset.errors, [])\n"], "sample_605": ["def test_groupby_apply_with_new_dims(dataset):\n    result = dataset.groupby(\"x\").apply(lambda ds: ds.assign(bar=ds.foo.sum(\"y\")))\n    assert \"bar\" in result.data_vars\n    assert result.bar.dims == (\"x\", \"z\")\n"], "sample_116": ["    def test_make_template_fragment_key(self):\n        key = make_template_fragment_key('test_fragment')\n        self.assertEqual(key, 'template.cache.test_fragment.d41d8cd98f00b204e9800998ecf8427e')\n        key = make_template_fragment_key('test_fragment', vary_on=['arg1', 'arg2'])\n        self.assertEqual(key, 'template.cache.test_fragment.b858a15723102461928809789188280f')\n"], "sample_699": ["    def test_doctest_module_with_mocked_object(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n                return 42\n\n            class MyClass:\n                    self.value = 10\n\n                assert myfunc() == 42\n                obj = MyClass()\n                assert obj.value == 10\n            \"\"\"\n        )\n        pytester.runpytest(p)\n        assert pytester.stdout.str().find(\"1 passed\") != -1\n"], "sample_740": ["    def test_check_consistent_length_sparse_matrix():\n        X = sparse_random_matrix(10, 5, density=0.5)\n        y = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n        assert_raises(ValueError, check_consistent_length, X, y)\n\n        y = np.array([1, 2, 3, 4, 5])\n        assert_no_warnings(check_consistent_length, X, y)\n"], "sample_167": ["    def test_intword_large_number(self):\n        with translation.override('en'):\n            self.assertEqual(humanize.intword(1000000000000), '1.0 trillion')\n            self.assertEqual(humanize.intword(1200000000000), '1.2 trillion')\n            self.assertEqual(humanize.intword(1234567890123456789), '12.3 quadrillion')\n"], "sample_920": ["    def test_namedtuple_subclass(self):\n        docstring = cleandoc(NamedtupleSubclass.__doc__)\n        doc = GoogleDocstring(docstring, config=Config())\n        expected = dedent('''\n            Sample namedtuple subclass\n\n            Attributes\n            ----------\n            attr1 : Arbitrary type\n                Quick description of attr1\n            attr2 : Another arbitrary type\n                Quick description of attr2\n            attr3 : Type\n\n                Adds a newline after the type\n\n        ''')\n        self.assertEqual(str(doc), expected)\n"], "sample_559": ["    def test_zoomed_inset_axes(self):\n        fig, ax = plt.subplots()\n        axins = zoomed_inset_axes(ax, 6, loc=1)\n        axins.set_xlim(5, 7)\n        axins.set_ylim(0, 1)\n        plt.xticks(visible=False)\n        plt.yticks(visible=False)\n        mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n        ax.plot(np.arange(10), np.arange(10))\n        axins.plot(np.arange(10), np.arange(10))\n"], "sample_626": ["    def test_pandas_multiindex_adapter(self, level):\n        index = pd.MultiIndex.from_tuples(\n            [(\"a\", 1), (\"a\", 2), (\"b\", 1), (\"b\", 2)], names=[\"level1\", \"level2\"]\n        )\n        array = xr.DataArray(np.arange(4), coords={\"x\": index})\n        adapter = PandasMultiIndexingAdapter(index, level=level)\n        if level is None:\n            assert adapter.shape == (4,)\n        else:\n            assert adapter.shape == (4,)\n        assert adapter[0] == (\"a\", 1)\n        assert adapter[1] == (\"a\", 2)\n        assert adapter[2] == (\"b\", 1)\n        assert adapter[3] == (\"b\", 2)\n        assert adapter[OuterIndexer((slice(None),))] == index\n        assert adapter[OuterIndexer((slice(None), 0))] == index.get_level_values(0)\n        assert adapter[OuterIndexer((slice(None), 1))] == index.get_level_values(1)\n\n"], "sample_919": ["def test_function_template():\n    check('function',\n          'void foo(int a, typename T) {}',\n          {1: 'foo'},\n          'void foo(int a, typename T) {}',\n          key='foo')\n"], "sample_531": ["    def test_figure_dpi_set_get(self):\n        fig = Figure()\n        assert fig.dpi == mpl.rcParams['figure.dpi']\n        fig.dpi = 100\n        assert fig.dpi == 100\n"], "sample_630": ["def test_dot_writer_with_empty_project(setup):\n    \"\"\"test dot writer with empty project\"\"\"\n    CONFIG = Config()\n    CONFIG.output_format = \"dot\"\n    writer = DotWriter(CONFIG)\n    project = get_project(os.path.join(os.path.dirname(__file__), \"data_empty\"))\n    linker = Linker(project)\n    handler = DiadefsHandler(CONFIG)\n    dd = DefaultDiadefGenerator(linker, handler).visit(project)\n    for diagram in dd:\n        diagram.extract_relationships()\n    writer.write(dd)\n    assert os.path.exists(\"packages_No_Name.dot\")\n    assert os.path.exists(\"classes_No_Name.dot\")\n    os.remove(\"packages_No_Name.dot\")\n    os.remove(\"classes_No_Name.dot\")\n"], "sample_1028": ["def test_mod_gcd():\n    assert Mod(6*x, 3).simplify() == Mod(0, 3)\n    assert Mod(6*x, 2*x).simplify() == Mod(0, 2*x)\n    assert Mod(6*x + 1, 3).simplify() == Mod(1, 3)\n    assert Mod(6*x + 1, 2*x).simplify() == Mod(1, 2*x)\n"], "sample_100": ["    def test_iter_modules_and_files_zipfile(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            zip_path = Path(tmpdir) / 'my_module.zip'\n            with zipfile.ZipFile(zip_path, 'w') as zf:\n                zf.writestr('my_module/__init__.py', '')\n            sys.path.append(str(tmpdir))\n            self.import_and_cleanup('my_module')\n            self.assertFileFound(zip_path)\n"], "sample_1170": ["def test_print_NDimArray():\n    A = NDimArray([1, 2, 3], (3,))\n    assert sstr(A) == 'NDimArray([1, 2, 3], (3,))'\n"], "sample_236": ["    def test_cascade_delete_with_transaction(self):\n        # Create a chain of objects with CASCADE on delete\n        a = create_a()\n        b1 = B1.objects.create(a=a)\n        b2 = B2.objects.create(b1=b1)\n        b3 = B3.objects.create(b2=b2)\n\n        # Delete the top-level object\n        with transaction.atomic():\n            a.delete()\n\n        # Verify that all related objects are deleted\n        self.assertFalse(A.objects.exists())\n        self.assertFalse(B1.objects.exists())\n        self.assertFalse(B2.objects.exists())\n        self.assertFalse(B3.objects.exists())\n"], "sample_153": ["    def test_check_database_backends(self):\n        with mock.patch('django.db.backends.base.validation.BaseDatabaseValidation.check') as mock_check:\n            mock_check.return_value = []\n            errors = check_database_backends(connection.settings_dict)\n            self.assertEqual(errors, [])\n"], "sample_814": ["    def test_classification_sparse_input(self):\n        # Check classification on a sparse matrix.\n        X_sparse = csr_matrix(iris.data)\n        y = iris.target\n\n        clf = GradientBoostingClassifier(random_state=0)\n        clf.fit(X_sparse, y)\n        score = clf.score(X_sparse, y)\n        assert score > 0.9\n\n        # Test prediction with different sparse formats\n        X_sparse_csc = csc_matrix(iris.data)\n        X_sparse_coo = coo_matrix(iris.data)\n        assert_array_equal(clf.predict(X_sparse_csc), clf.predict(X_sparse))\n        assert_array_equal(clf.predict(X_sparse_coo), clf.predict(X_sparse))\n"], "sample_673": ["    def test_is_mocked(self):\n        class Mock:\n            pass\n\n        mock = Mock()\n        assert _is_mocked(mock)\n        assert not _is_mocked(object())\n"], "sample_1051": ["    def test_dotprint_repeat_false():\n        x = Symbol('x')\n        expr = x + x*x\n        dot = dotprint(expr, repeat=False)\n        assert 'x' in dot\n        assert dot.count('\"x\"') == 1\n"], "sample_108": ["    def test_reverse_with_converter(self):\n        for url, (url_name, app_name, kwargs) in converter_test_data:\n            with self.subTest(url=url):\n                resolved_url = reverse(url_name, kwargs=kwargs, app_name=app_name)\n                self.assertEqual(resolved_url, url)\n"], "sample_314": ["    def test_creation_form_with_custom_user_model(self):\n        with override_settings(AUTH_USER_MODEL='tests.models.custom_user.CustomUser'):\n            form = UserCreationForm()\n            self.assertEqual(form.fields['username'].widget.attrs['autofocus'], True)\n            self.assertFalse(form.fields.get('email'))\n            self.assertFalse(form.fields.get('first_name'))\n            self.assertFalse(form.fields.get('last_name'))\n"], "sample_647": ["    def test_warn_explicit_for(self, warning_class: type[warning_types.PytestWarning], pytester: Pytester) -> None:\n            pass\n\n        with pytester.raises(warning_class) as excinfo:\n            warning_types.warn_explicit_for(myfunc, warning_class(\"hello\"))\n        assert str(excinfo.value) == \"hello\"\n"], "sample_627": ["    def test_concat_with_different_coords_and_data_vars(self) -> None:\n        datasets = create_concat_datasets(num_datasets=2, include_day=False)\n        datasets[0] = datasets[0].assign_coords({\"new_coord\": [1, 2, 3, 4]})\n        datasets[1] = datasets[1].assign_coords({\"new_coord\": [5, 6, 7, 8]})\n        datasets[1] = datasets[1].drop_vars(\"precipitation\")\n        with pytest.raises(ValueError):\n            concat(datasets, dim=\"day\")\n\n"], "sample_576": ["    def test_subplot_spec_defaults(self):\n\n        p = Plot()\n        assert p._subplots == []\n        assert p._shares == {}\n        assert p._limits == {}\n        assert p._layout_spec == {}\n\n        p = Plot(col=\"a\")\n        assert p._subplots == []\n        assert p._shares == {\"col\": \"all\"}\n        assert p._limits == {}\n        assert p._layout_spec == {}\n\n        p = Plot(row=\"b\")\n        assert p._subplots == []\n        assert p._shares == {\"row\": \"all\"}\n        assert p._limits == {}\n        assert p._layout_spec == {}\n\n        p = Plot(col=\"a\", row=\"b\")\n        assert p._subplots == []\n        assert p._shares == {\"col\": \"all\", \"row\": \"all\"}\n        assert p._limits == {}\n        assert p._layout_spec == {}\n\n"], "sample_788": ["    def test_transform_constant_feature(self):\n        X = [[1, 1, 1, 1],\n             [1, 1, 1, 1],\n             [1, 1, 1, 1],\n             [1, 1, 1, 1]]\n        est = KBinsDiscretizer(n_bins=3, encode='onehot', strategy='uniform')\n        Xt = est.fit_transform(X)\n        assert_array_equal(Xt.toarray(), [[1, 0, 0],\n                                         [1, 0, 0],\n                                         [1, 0, 0],\n                                         [1, 0, 0]])\n"], "sample_145": ["    def test_list_editable_with_list_display_links(self):\n        class MyModelAdmin(ModelAdmin):\n            list_display = ('name', 'email')\n            list_display_links = ('name',)\n            list_editable = ('email',)\n\n        self.assertIsInvalid(\n            MyModelAdmin,\n            User,\n            r\"The value of 'list_editable\\[0\\]' cannot be in both 'list_editable' and 'list_display_links'.\",\n            id='admin.E123',\n        )\n"], "sample_215": ["    def test_callable_setting_wrapper(self):\n        wrapped_callable = CallableSettingWrapper(lambda: 'test')\n        self.assertEqual(repr(wrapped_callable), '<function <lambda> at ...>')\n"], "sample_982": ["    def test_primeomega(self):\n        assert primeomega(1) == 0\n        assert primeomega(2) == 1\n        assert primeomega(4) == 2\n        assert primeomega(6) == 2\n        assert primeomega(12) == 3\n        assert primeomega(20) == 3\n        assert primeomega(25) == 2\n        assert primeomega(100) == 3\n        assert primeomega(1000) == 5\n"], "sample_465": ["    def test_get_formset_exclude(self):\n        class MyModelAdmin(ModelAdmin):\n            model = Band\n            exclude = ('sign_date',)\n\n        admin = MyModelAdmin(Band, self.site)\n        formset = admin.get_formset(request)\n        self.assertNotIn('sign_date', formset.form.base_fields)\n"], "sample_1036": ["    def test_matmul_expand():\n        a = MatrixSymbol('a', 2, 2)\n        b = MatrixSymbol('b', 2, 2)\n        c = MatrixSymbol('c', 2, 2)\n        assert expand(a*(b + c)) == a*b + a*c\n        assert expand((a + b)*c) == a*c + b*c\n"], "sample_757": ["    def test_onehotencoder_inverse_transform_unknown_categories(self):\n        enc = OneHotEncoder(handle_unknown='ignore')\n        X = [['Male', 1], ['Female', 3], ['Female', 2]]\n        enc.fit(X)\n        X_trans = enc.transform([['Female', 4], ['Male', 1]])\n        X_inv = enc.inverse_transform(X_trans)\n        assert_equal(X_inv, [['Female', None], ['Male', 1]])\n"], "sample_1009": ["def test_vector_dot_product_with_zero_vector():\n    v1 = Vector([1, 2, 3])\n    v2 = Vector(0)\n    assert v1.dot(v2) == 0\n"], "sample_129": ["    def test_floatformat01(self):\n        with self.settings(USE_L10N=True):\n            output = self.engine.render_to_string('floatformat01', {'a': Decimal('1234.5678'), 'b': 1234.5678})\n            self.assertEqual(output, '1,234.568 1,234.568')\n"], "sample_387": ["    def test_formfield_for_dbfield_uuidfield(self):\n        ff = self.assertFormfield(\n            Company, \"uuid\", forms.CharField,\n        )\n        self.assertEqual(ff.widget.attrs.get(\"type\"), \"text\")\n"], "sample_873": ["    def test_inverse_transform_sparse(self):\n        selector = StepSelector(step=2)\n        selector.fit(X)\n        Xt = selector.transform(X)\n        X_inv = selector.inverse_transform(Xt)\n        assert_array_equal(X_inv.toarray(), Xinv)\n"], "sample_1204": ["def test_coset_equality():\n    a = Permutation([0, 1, 2])\n    b = Permutation([1, 2, 0])\n    G = PermutationGroup([a, b])\n    c1 = Coset(a, G, dir=\"+\")\n    c2 = Coset(a*b, G, dir=\"+\")\n    assert c1 == c2\n"], "sample_671": ["    def test_evalxfail_key_is_set_when_xfail_marker_is_present(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail\n                pass\n            \"\"\"\n        )\n        item = testdir.getitems()[0]\n        pytest_runtest_setup(item)\n        assert evalxfail_key in item._store\n"], "sample_29": ["    def test_write_latex_units(self, cosmo, tmp_path):\n        \"\"\"Test that units are correctly included in the LaTeX output.\"\"\"\n        filename = tmp_path / \"cosmo.tex\"\n        write_latex(cosmo, filename, latex_names=False)\n\n        with open(filename, \"r\") as f:\n            latex_str = f.read()\n\n        for param_name in cosmo.__parameters__:\n            param = getattr(cosmo, param_name)\n            if isinstance(param, Parameter) and param.unit is not None and param.unit != u.one:\n                assert f\" {param.unit} \" in latex_str\n"], "sample_640": ["    def test_is_builtin(self, name: str, expected: bool):\n        node = astroid.parse(f\"import {name}\")\n        assert utils.is_builtin(node.body[0].names[0].name) == expected\n"], "sample_1043": ["    def test_print_ImmutableSparseMatrix(self):\n        m = sympy.Matrix([[1, 0, 0], [0, 0, 1], [0, 1, 0]])\n        self.assertEqual(mcode(m),\n                         'SparseArray[{{1, 1} -> 1, {3, 3} -> 1, {2, 3} -> 1}, {3, 3}]')\n"], "sample_915": ["    def test_stringify_signature_with_return_annotation(self):\n            pass\n        sig = inspect.signature(func)\n        assert stringify_signature(sig) == '(a: int, b: str) -> datetime.datetime'\n"], "sample_896": ["    def test_partial_fit_init(Estimator, solver):\n        # Test that partial_fit works with different initializations\n        rng = np.random.RandomState(42)\n        X = rng.rand(100, 5)\n        nmf = Estimator(n_components=3, random_state=42, **solver)\n\n        # Test with random initialization\n        nmf.partial_fit(X)\n        W1 = nmf.transform(X)\n        H1 = nmf.components_\n\n        # Test with custom initialization\n        nmf = Estimator(n_components=3, random_state=42, **solver)\n        W_init = rng.rand(100, 3)\n        H_init = rng.rand(3, 5)\n        nmf.partial_fit(X, W=W_init, H=H_init)\n        W2 = nmf.transform(X)\n        H2 = nmf.components_\n\n        assert not np.allclose(W1, W2)\n        assert not np.allclose(H1, H2)\n"], "sample_783": ["    def test_missing_indicator_error_on_new_features(self):\n        X1 = np.array([[np.nan, 1, 3],\n                       [4, 0, np.nan],\n                       [8, 1, 0]])\n        X2 = np.array([[5, 1, np.nan],\n                       [np.nan, 2, 3],\n                       [2, 4, 0]])\n\n        indicator = MissingIndicator(features='missing-only',\n                                     error_on_new=True)\n        indicator.fit(X1)\n        with pytest.raises(ValueError):\n            indicator.transform(X2)\n"], "sample_1150": ["def test_complexregion_intersection():\n    a = Interval(0, 1)\n    b = Interval(0, 2*S.Pi)\n    c = Interval(1, 2)\n    d = Interval(S.Pi/2, 3*S.Pi/2)\n    unit_disk = ComplexRegion(a*b, polar=True)\n    upper_half_unit_disk = ComplexRegion(a*d, polar=True)\n    intersection = unit_disk.intersect(upper_half_unit_disk)\n    assert intersection == ComplexRegion(ProductSet(a, Interval(S.Pi/2, S.Pi)), polar=True)\n"], "sample_1125": ["def test_identity_operator_apply():\n    A = Operator('A')\n    I = IdentityOperator()\n    ket = symbols('ket', cls=Function)\n    assert I * ket == ket\n    assert ket * I == ket\n    assert I * A * ket == A * ket\n"], "sample_725": ["    def test_check_array_dtype_object_warn(self):\n        X = np.array([['a', 1], ['b', 2]], dtype=object)\n        with warnings.catch_warnings(record=True) as w:\n            check_array(X, dtype='numeric', warn_on_dtype=True)\n        assert_true(len(w) == 1)\n        assert_true(issubclass(w[0].category, DataConversionWarning))\n        assert_equal(str(w[0].message),\n                     \"Data with input dtype object was converted to float64\"\n                     \" by check_array.\")\n"], "sample_278": ["    def test_filtered_relation_as_sql(self):\n        with CaptureQueriesContext(connection) as captured_queries:\n            Company.objects.filter(\n                ceo__filtered_relation__name='Joe'\n            ).get()\n        self.assertEqual(len(captured_queries), 1)\n        sql = captured_queries[0]['sql']\n        self.assertIn('WHERE \"employee\".\"firstname\" = %s', sql)\n"], "sample_981": ["def test_unrank_lex():\n    perm = Permutation.unrank_lex(5, 10)\n    assert perm.rank() == 10\n    assert perm == Permutation([0, 2, 4, 1, 3])\n"], "sample_1084": ["def test_intersection_complexregion_interval():\n    a = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)\n    b = Interval(0, 1)\n    assert intersection_sets(a, b) == a\n\n"], "sample_1018": ["def test_fcode_piecewise_no_default():\n    x = symbols('x')\n    expr = Piecewise((x + 1, x > 0))\n    raises(ValueError, lambda: fcode(expr))\n"], "sample_844": ["def test_extend_region(r_plot, end):\n    steep_upward = np.array([False, False, False, False, True, True, True])\n    upward = np.array([False, False, False, False, True, True, True])\n    min_samples = 2\n    assert _extend_region(steep_upward, upward, 0, min_samples) == end\n"], "sample_644": ["    def test_import_from_future(self, checker: imports.ImportsChecker) -> None:\n        tree = astroid.parse(\n            \"\"\"\n            from __future__ import print_function\n            print(\"Hello\")\n        \"\"\"\n        )\n        checker.visit_module(tree)\n        self.assertEqual(checker.linter.stats.dependencies, {})\n"], "sample_1017": ["def test_bool_map_empty():\n    f1 = And(A, B)\n    f2 = Or()\n    assert bool_map(f1, f2) is False\n"], "sample_734": ["    def test_fowlkes_mallows_score_sparse(self):\n        labels_true = np.array([0, 0, 1, 1])\n        labels_pred = np.array([0, 0, 1, 1])\n        score = fowlkes_mallows_score(labels_true, labels_pred, sparse=True)\n        assert_almost_equal(score, 1.0)\n"], "sample_38": ["    def test_maps_read(self):\n        for filename in self._file_list:\n            with fits.open(filename) as hdul:\n                wcs = wcs.WCS(hdul[0].header)\n                assert isinstance(wcs, wcs.WCS)\n"], "sample_538": ["    def test_blended_transform_factory():\n        # Test that blended_transform_factory returns the correct type\n        x_transform = mtransforms.Affine2D()\n        y_transform = mtransforms.Affine2D()\n        transform = mtransforms.blended_transform_factory(x_transform,\n                                                        y_transform)\n        assert isinstance(transform, mtransforms.BlendedAffine2D)\n\n        x_transform = mtransforms.Affine2D()\n        y_transform = mtransforms.IdentityTransform()\n        transform = mtransforms.blended_transform_factory(x_transform,\n                                                        y_transform)\n        assert isinstance(transform, mtransforms.BlendedAffine2D)\n\n        x_transform = mtransforms.IdentityTransform()\n        y_transform = mtransforms.Affine2D()\n        transform = mtransforms.blended_transform_factory(x_transform,\n                                                        y_transform)\n        assert isinstance(transform, mtransforms.BlendedAffine2D)\n\n        x_transform = mtransforms.IdentityTransform()\n        y_transform = mtransforms.IdentityTransform()\n        transform = mtransforms.blended_transform_factory(x_transform,\n                                                        y_transform)\n        assert isinstance(transform, mtransforms.IdentityTransform)\n\n        x_transform = mtransforms.Affine2D()\n        y_transform = mtransforms.FuncTransform()\n        transform = mtransforms.blended_transform_factory(x_transform,\n                                                        y_transform)\n        assert isinstance(transform, mtransforms.BlendedGenericTransform)\n"], "sample_1130": ["    def test_point_pos_from_cyclic(self):\n        N = ReferenceFrame('N')\n        p1 = Point('p1')\n        p2 = Point('p2')\n        p3 = Point('p3')\n        p1.set_pos(p2, N.x)\n        p2.set_pos(p3, N.y)\n        p3.set_pos(p1, N.z)\n        with ignore_warnings():\n            pos = p1.pos_from(p2)\n        assert pos == N.x\n"], "sample_906": ["def test_cpp_enum_scoped():\n    check(\n        \"enum\",\n        \"enum { A, B, C }\",\n        {1: \"enum_A_B_C\"},\n        output=\"enum { A, B, C }\",\n        key=\"enum \",\n        asTextOutput=\"enum A, B, C\",\n    )\n"], "sample_625": ["    def test_unify_chunks_different_sizes(self, dim):\n        # Create two DataArrays with different chunk sizes along the same dimension\n        da1 = xr.DataArray(np.arange(10), dims=[dim], chunks=(5,))\n        da2 = xr.DataArray(np.arange(10), dims=[dim], chunks=(2,))\n\n        # Unify the chunk sizes\n        da1_unified, da2_unified = unify_chunks(da1, da2)\n\n        # Check that the chunk sizes are now the same\n        assert da1_unified.chunks == da2_unified.chunks\n        assert da1_unified.chunks == ((2, 2, 2, 2, 2),)\n"], "sample_539": ["def test_spanselector_draw_outside_axes(ax):\n    # Test that SpanSelector doesn't draw outside the axes limits\n    fig, ax = plt.subplots()\n    ax.set_xlim(0, 10)\n    ax.set_ylim(0, 10)\n\n    selector = widgets.SpanSelector(ax,\n                                    onselect=noop,\n                                    direction='horizontal',\n                                    minspan=1,\n                                    rectprops=dict(facecolor='red'))\n    event = mock_event(\n        type='button_press_event',\n        x=11, y=5, button=1, inaxes=ax)\n    selector.on_press(event)\n    event = mock_event(\n        type='button_release_event',\n        x=12, y=5, button=1, inaxes=ax)\n    selector.on_release(event)\n    assert selector.rect.get_x() == 10\n    assert selector.rect.get_width() == 0\n"], "sample_258": ["    def test_disconnect_weakref(self):\n            pass\n\n        weak_receiver = weakref.ref(receiver_func)\n        a_signal.connect(weak_receiver, weak=True)\n        self.assertTrue(a_signal.has_listeners())\n        del receiver_func\n        garbage_collect()\n        self.assertFalse(a_signal.has_listeners())\n"], "sample_606": ["    def test_polyval(self, dim):\n        x = xr.DataArray(np.arange(5), dims=[dim])\n        coeffs = xr.DataArray(np.array([1, 2, 3]), dims=[\"degree\"])\n        expected = np.polyval(x, coeffs.values)\n        actual = xr.polyval(x, coeffs, degree_dim=\"degree\")\n        assert_identical(actual, expected)\n"], "sample_40": ["    def test_brightness_temperature_beam_area():\n        freq = 5 * u.GHz\n        beam_sigma = 50 * u.arcsec\n        beam_area = 2 * np.pi * (beam_sigma)**2\n        equiv = u.brightness_temperature(freq, beam_area)\n        assert_quantity_allclose((1 * u.Jy / beam_area).to(u.K, equivalencies=equiv),\n                                 3.526295144567176 * u.K)\n\n"], "sample_182": ["    def test_union_with_different_select_related(self):\n        qs1 = Number.objects.select_related('other_number').filter(num__gt=5)\n        qs2 = Number.objects.select_related('other_number').filter(num__lt=5)\n        union_qs = qs1.union(qs2)\n        self.assertNumbersEqual(union_qs, list(range(10)))\n"], "sample_303": ["    def test_runshell_calls_subprocess_run(self, mock_subprocess_run):\n        self.client.settings_to_cmd_args_env = mock.MagicMock(return_value=([], {}))\n        self.client.runshell([])\n        mock_subprocess_run.assert_called_once_with([], env={}, check=True)\n"], "sample_691": ["    def test_faulthandler_timeout_enabled(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import time\n\n                time.sleep(1)\n        \"\"\"\n        )\n        pytester.addini(\"faulthandler_timeout=0.5\")\n        result = pytester.runpytest()\n        result.assert_outcomes(failed=1)\n        assert \"Traceback (most recent call last):\" in result.stdout.str()\n"], "sample_695": ["    def test_iterparentnodeids_empty(self, pytester: Pytester) -> None:\n        item = pytester.makepyfile(\n            \"\"\"\n                pass\n            \"\"\"\n        )\n        node = pytester.getnode(item)\n        assert list(nodes.iterparentnodeids(node.nodeid)) == [\"\"]\n"], "sample_69": ["    def test_iter_modules_and_files_zipfile(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_path = Path(tempdir) / 'my_module.zip'\n            with zipfile.ZipFile(zip_path, 'w') as zf:\n                zf.writestr('my_module/__init__.py', '')\n            sys.path.append(tempdir)\n            self.import_and_cleanup('my_module')\n            self.assertFileFound(zip_path)\n"], "sample_360": ["    def test_cache_middleware_cache_timeout_from_response(self):\n        with self.settings(CACHE_MIDDLEWARE_SECONDS=10):\n            response = HttpResponse('Hello, world!')\n            response['Cache-Control'] = 'max-age=30'\n            request = HttpRequest()\n            middleware = CacheMiddleware(lambda r: response)\n            response = middleware.process_response(request, response)\n            self.assertEqual(response['Cache-Control'], 'max-age=30')\n            self.assertEqual(caches[DEFAULT_CACHE_ALIAS].get(learn_cache_key(request, response, 30, middleware.key_prefix, cache=caches[DEFAULT_CACHE_ALIAS])), response)\n"], "sample_280": ["    def test_aggregate_with_window_function(self):\n        with CaptureQueriesContext(connection) as queries:\n            result = list(\n                Book.objects.annotate(\n                    rank=Window(\n                        expression=Rank(),\n                        partition_by=F('publisher__name'),\n                        order_by=F('rating').desc(),\n                    ),\n                ).filter(rank=1).values('name', 'publisher__name', 'rank')\n            )\n        self.assertEqual(len(result), 5)\n        self.assertQuerySetEqual(\n            result, [\n                {'name': 'The Definitive Guide to Django: Web Development Done Right', 'publisher__name': 'Apress', 'rank': 1},\n                {'name': 'Practical Django Projects', 'publisher__name': 'Apress', 'rank': 1},\n                {'name': 'Sams Teach Yourself Django in 24 Hours', 'publisher__name': 'Sams', 'rank': 1},\n                {'name': 'Python Web Development with Django', 'publisher__name': 'Prentice Hall', 'rank': 1},\n                {'name': 'Artificial Intelligence: A Modern Approach', 'publisher__name': 'Prentice Hall', 'rank': 1},\n            ],\n            transform=lambda x: {k: v for k, v in x.items() if k in ('name', 'publisher__name', 'rank')},\n        )\n        self.assertEqual(len(queries), 1)\n"], "sample_1186": ["def test_array_diff():\n    a = ImmutableDenseNDimArray([[x, y], [1, x*y]])\n    assert a.diff(x) == ImmutableDenseNDimArray([[1, y], [0, y]])\n    assert a.diff(y) == ImmutableDenseNDimArray([[0, 1], [0, x]])\n"], "sample_877": ["    def test_isotonic_regression_out_of_bounds_clip():\n        # Test that out_of_bounds='clip' works correctly.\n        X = np.array([1, 2, 3, 4, 5])\n        y = np.array([1, 2, 3, 4, 5])\n        iso = IsotonicRegression(out_of_bounds='clip')\n        iso.fit(X, y)\n        assert_array_equal(iso.predict([0, 6]), [1, 5])\n"], "sample_425": ["    def test_serialize_enum_flag(self):\n        with self.settings(USE_TZ=True):\n            self.assertEqual(\n                OperationWriter(\n                    migrations.CreateModel(\n                        name=\"TestModel\",\n                        fields=[\n                            models.IntegerField(\n                                choices=[(IntFlagEnum.A, \"A\"), (IntFlagEnum.B, \"B\")],\n                                default=IntFlagEnum.A,\n                            )\n                        ],\n                    ),\n                    indentation=0,\n                ).serialize()[0],\n                'migrations.CreateModel(\\n    name=\"TestModel\",\\n    fields=[(\\n        \"field\",\\n        models.IntegerField(\\n            choices=[(IntFlagEnum.A, \"A\"), (IntFlagEnum.B, \"B\")],\\n            default=IntFlagEnum.A,\\n        ),\\n    )],\\n)',\n            )\n\n"], "sample_190": ["    def test_isnull_with_none_as_rhs(self):\n        with self.assertRaises(ValueError):\n            IsNullWithNoneAsRHS.objects.filter(field__isnull=None)\n"], "sample_926": ["def test_cpp_enum_scoped():\n    check(\n        'enum',\n        'enum { A, B, C };',\n        {1: 'enum'},\n        output='enum { A, B, C }',\n        key='enum ',\n        asTextOutput='enum {A, B, C}'\n    )\n"], "sample_643": ["def test_text_reporter_with_msg_template(reporter: TextReporter, disable: list[str]) -> None:\n    \"\"\"Test that the text reporter uses the provided msg_template.\"\"\"\n    linter = PyLinter()\n    linter.reporter = reporter\n    linter.set_option(\"msg-template\", \"{path}:{line}:{column}: {msg_id}: {msg} ({symbol})\")\n    linter.disable(disable)\n    with redirect_stdout(StringIO()) as output:\n        linter.check(\n            [\n                FileItem(\n                    \"test.py\",\n                    \"test_file\",\n                    \"test_file\",\n                    \"test_file\",\n                    \"test_file\",\n                    None,\n                    None,\n                    None,\n                )\n            ]\n        )\n    output_string = output.getvalue()\n    assert \"test.py:1:0: C: Unused variable 'x' (unused-variable)\" in output_string\n"], "sample_410": ["    def test_get_email_field_name(self):\n        self.assertEqual(AbstractBaseUser.get_email_field_name(), 'email')\n        class CustomUser(AbstractBaseUser):\n            EMAIL_FIELD = 'custom_email'\n        self.assertEqual(CustomUser.get_email_field_name(), 'custom_email')\n"], "sample_368": ["    def test_migrate_unapplied_initial_migration(self):\n        # Test that an unapplied initial migration is detected and applied\n        # correctly.\n\n        with self.connection.cursor() as cursor:\n            self.connection.introspection.table_names(cursor)\n\n        # Create a new app with an initial migration\n        self.create_test_app(\"test_app\", \"test_app_migrations\")\n        self.migrate_apps([\"test_app\"])\n\n        # Now, delete the tables created by the initial migration\n        with self.connection.cursor() as cursor:\n            cursor.execute(\"DROP TABLE IF EXISTS test_app_testmodel\")\n\n        # Run migrations again, it should detect the unapplied initial migration\n        # and apply it.\n        executor = MigrationExecutor(self.connection)\n        executor.migrate(\n            targets=[(\"test_app\", None)],\n            fake_initial=True,\n        )\n\n        # Check that the table exists now\n        with self.connection.cursor() as cursor:\n            self.assertIn(\"test_app_testmodel\", self.connection.introspection.table_names(cursor))\n"], "sample_453": ["    def test_submit_row_tag(self):\n        request = self.request_factory.get(reverse('admin:articles_article_change', args=(1,)))\n        request.user = self.user\n        context = {\n            'add': False,\n            'change': True,\n            'is_popup': False,\n            'save_as': False,\n            'has_add_permission': True,\n            'has_change_permission': True,\n            'has_view_permission': True,\n            'has_delete_permission': True,\n            'has_editable_inline_admin_formsets': False,\n            'show_save': True,\n            'show_save_and_add_another': True,\n            'show_save_and_continue': True,\n            'show_delete': True,\n        }\n        template = submit_row(Context(context))\n        self.assertIn('can_change', template.dicts[0])\n        self.assertIn('show_delete_link', template.dicts[0])\n        self.assertIn('show_save_as_new', template.dicts[0])\n        self.assertIn('show_save_and_add_another', template.dicts[0])\n        self.assertIn('show_save_and_continue', template.dicts[0])\n        self.assertIn('show_save', template.dicts[0])\n        self.assertIn('show_close', template.dicts[0])\n"], "sample_811": ["    def test_pairwise_distances_chunked_sparse_input(self):\n        X = dok_matrix((5, 3), dtype=np.float64)\n        X[0, 0] = 1\n        X[1, 1] = 2\n        X[2, 2] = 3\n        X[3, 0] = 4\n        X[4, 1] = 5\n\n        # Test with a callable metric\n            return np.sum(np.abs(x - y))\n\n        for chunk_size in [1, 2, 3, 4, 5]:\n            distances = list(pairwise_distances_chunked(X, metric=callable_metric,\n                                                        chunk_size=chunk_size))\n            expected = pairwise_distances(X.toarray(), metric=callable_metric)\n            assert_allclose(np.concatenate(distances), expected)\n\n"], "sample_825": ["    def test_plssvd_fit_transform(self):\n        X, y = load_linnerud(return_X_y=True)\n        pls = PLSSVD(n_components=2)\n        X_c, y_c = pls.fit_transform(X, y)\n        assert X_c.shape == (n_samples, 2)\n        assert y_c.shape == (n_samples, 2)\n"], "sample_828": ["    def test_pairwise_distances_chunked_reduce_func_sparse(self):\n        X = csr_matrix([[0, 1], [1, 0]])\n        Y = csr_matrix([[1, 0], [0, 1]])\n\n            return D_chunk.mean(axis=1)\n\n        gen = pairwise_distances_chunked(X, Y, reduce_func=reduce_func)\n        result = next(gen)\n        assert_array_almost_equal(result, [0.5, 0.5])\n"], "sample_636": ["    def test_similar_with_ignore_imports(self) -> None:\n        with _patch_streams(StringIO()) as out:\n            Run([\"--ignore-imports\", join(DATA, \"similar_imports.py\")])\n            output = out.getvalue()\n            assert \"==similar_imports.py:[2:3]\" in output\n            assert \"==similar_imports.py:[5:6]\" in output\n"], "sample_1098": ["    def test_appellf1_derivatives():\n        a, b1, b2, c = symbols('a b1 b2 c')\n        assert appellf1(a, b1, b2, c, x, y).fdiff(5) == (a*b1/c)*appellf1(a + 1, b1 + 1, b2, c + 1, x, y)\n        assert appellf1(a, b1, b2, c, x, y).fdiff(6) == (a*b2/c)*appellf1(a + 1, b1, b2 + 1, c + 1, x, y)\n"], "sample_970": ["    def test_stringify_signature_unqualified_typehints(self):\n        sig = inspect.signature(lambda x: x,\n                                unqualified_typehints=True)\n        assert stringify_signature(sig, unqualified_typehints=True) == '(x)'\n"], "sample_911": ["def test_enum_scoped():\n    check(\"enum\", \"enum E { A, B };\", {1: \"E\"})\n    check(\"enum\", \"enum class E { A, B };\", {1: \"E\"})\n    check(\"enum\", \"enum struct E { A, B };\", {1: \"E\"})\n    check(\"enum\", \"namespace ns { enum E { A, B }; }\", {1: \"ns::E\"})\n    check(\"enum\", \"namespace ns { enum class E { A, B }; }\", {1: \"ns::E\"})\n    check(\"enum\", \"namespace ns { enum struct E { A, B }; }\", {1: \"ns::E\"})\n"], "sample_226": ["    def test_test_db_signature(self):\n        connection = get_connection_copy()\n        creation = BaseDatabaseCreation(connection)\n        original_signature = creation.test_db_signature()\n        # Change a setting that should affect the signature\n        connection.settings_dict['NAME'] = 'new_test_db'\n        new_signature = creation.test_db_signature()\n        self.assertNotEqual(original_signature, new_signature)\n"], "sample_381": ["    def test_rename_field_with_default(self):\n        before = self.make_project_state([\n            self.author_name,\n        ])\n        after = self.make_project_state([\n            self.author_name_renamed_field,\n        ])\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['RenameField'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name', old_name='name')\n\n"], "sample_682": ["    def test_evaluate_skip_marks_skipif_condition_evaluates_to_true(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skipif(sys.platform == 'win32', reason=\"skip on windows\")\n                assert True\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\"*skipped: skip on windows*\"])\n        assert result.ret == 0\n"], "sample_424": ["    def test_rename_field_with_related_objects(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\"CREATE TABLE IF NOT EXISTS test_related_object (id INTEGER PRIMARY KEY, name TEXT)\")\n            cursor.execute(\"INSERT INTO test_related_object (name) VALUES ('Object 1')\")\n            cursor.execute(\"INSERT INTO test_related_object (name) VALUES ('Object 2')\")\n\n        class RelatedObject(models.Model):\n            name = models.CharField(max_length=100)\n\n        class MyModel(models.Model):\n            related = models.ForeignKey(RelatedObject, on_delete=models.CASCADE)\n            other_field = models.CharField(max_length=100)\n\n        # Create some data\n        MyModel.objects.create(related=RelatedObject.objects.get(name='Object 1'), other_field='Value 1')\n        MyModel.objects.create(related=RelatedObject.objects.get(name='Object 2'), other_field='Value 2')\n\n        # Rename the field\n        operations = [\n            migrations.RenameField(\n                model_name='mymodel',\n                old_name='related',\n                new_name='related_object',\n            ),\n        ]\n        migration = Migration(\n            'test_rename_field',\n            operations,\n        )\n        with atomic():\n            self.apply_migration(migration)\n\n        # Check that the data is still there\n        self.assertEqual(MyModel.objects.count(), 2)\n        self.assertEqual(MyModel.objects.get(related_object__name='Object 1').other_field, 'Value 1')\n        self.assertEqual(MyModel.objects.get(related_object__name='Object 2').other_field, 'Value 2')\n\n        # Check that the field has been renamed in the database\n        with connection.cursor() as cursor:\n            cursor.execute(\"PRAGMA table_info(test_mymodel)\")\n            columns = [column[0] for column in cursor.fetchall()]\n            self.assertIn('related_object_id', columns)\n            self.assertNotIn('related"], "sample_674": ["compilation error"], "sample_350": ["    def test_union_with_subquery(self):\n        # Test union with a subquery that uses a different model\n        subquery = Celebrity.objects.filter(name__startswith='A').values('name')\n        queryset = Number.objects.filter(num__gt=5).union(subquery)\n        self.assertQuerysetEqual(queryset.order_by('num'), [\n            Number(num=6, other_num=4),\n            Number(num=7, other_num=3),\n            Number(num=8, other_num=2),\n            Number(num=9, other_num=1),\n            'Alice',\n        ], ordered=False)\n"], "sample_1131": ["    def test_scipy_special_functions(self):\n        assert SciPyPrinter().doprint(acos(x)) == 'scipy.special.arccos(x)'\n        assert SciPyPrinter().doprint(loggamma(x)) == 'scipy.special.gammaln(x)'\n        assert SciPyPrinter().doprint(sign(x)) == 'numpy.sign(x)'\n        assert SciPyPrinter().doprint(cosm1(x)) == 'scipy.special.cosm1(x)'\n"], "sample_645": ["def test_log_records_with_different_levels(pytester: Pytester) -> None:\n    pytester.mkdir(\"test_dir\")\n    pytester.makepyfile(\n        \"\"\"\n        import logging\n\n        logger = logging.getLogger(__name__)\n\n            logger.debug(\"This is a debug message\")\n            logger.info(\"This is an info message\")\n            logger.warning(\"This is a warning message\")\n            logger.error(\"This is an error message\")\n            logger.critical(\"This is a critical message\")\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--log-level=DEBUG\", \"-v\")\n    result.assert_outcomes(passed=1)\n    log_records = result.node.stash[caplog_records_key][\"call\"]\n    assert len(log_records) == 5\n    assert log_records[0].levelno == logging.DEBUG\n    assert log_records[1].levelno == logging.INFO\n    assert log_records[2].levelno == logging.WARNING\n    assert log_records[3].levelno == logging.ERROR\n    assert log_records[4].levelno == logging.CRITICAL\n\n"], "sample_1102": ["def test_groebner_basis_fglm():\n    from sympy.abc import x, y\n    F = [x**2 - 3*y - x + 1, y**2 - 2*x + y - 1]\n    G = groebner(F, x, y, order='grlex')\n\n    G_lex = G.fglm('lex')\n    assert _strict_eq(G_lex, groebner(F, x, y, order='lex'))\n"], "sample_543": ["def test_polygon_selector_draw_box(ax):\n    fig, ax = plt.subplots()\n    selector = widgets.PolygonSelector(ax, lambda verts: None)\n    selector._xys = [(0, 0), (1, 0), (1, 1), (0, 1), (0, 0)]\n    selector._selection_completed = True\n    selector._draw_box = True\n    selector._add_box()\n    assert isinstance(selector._box, widgets.RectangleSelector)\n    selector._remove_box()\n    assert selector._box is None\n"], "sample_497": ["    def test_integer_ticks(self, vmin, vmax, steps, expected):\n        locator = mticker.MaxNLocator(steps=steps)\n        ticks = locator.tick_values(vmin, vmax)\n        if expected is None:\n            expected = np.arange(int(vmin), int(vmax) + 1)\n        assert_array_equal(ticks, expected)\n"], "sample_1005": ["def test_latex_SingularityFunction():\n    assert latex(SingularityFunction(x, 0, 1)) == '\\\\operatorname{SingularityFunction}\\\\left(x, 0, 1\\\\right)'\n"], "sample_412": ["    def test_urlize_nofollow(self):\n        self.check_output(\n            urlize,\n            \"Visit <a href='http://www.example.com'>example.com</a>.\",\n            \"Visit <a href='http://www.example.com'>example.com</a>.\",\n        )\n        self.check_output(\n            urlize,\n            \"Visit <a href='http://www.example.com'>example.com</a>.\",\n            \"Visit <a href='http://www.example.com' rel='nofollow'>example.com</a>.\",\n            nofollow=True,\n        )\n"], "sample_889": ["    def test_calibrated_classifier_cv_ensemble(self, method, ensemble):\n        X, y = self.data\n        n_classes = len(np.unique(y))\n\n        if ensemble:\n            clf = VotingClassifier(\n                estimators=[\n                    (\"lr\", LogisticRegression()),\n                    (\"dt\", DecisionTreeClassifier()),\n                ]\n            )\n        else:\n            clf = LogisticRegression()\n\n        calibrated_clf = CalibratedClassifierCV(\n            clf, method=method, cv=LeaveOneOut()\n        )\n        calibrated_clf.fit(X, y)\n\n        # Check if predict_proba outputs probabilities\n        y_prob = calibrated_clf.predict_proba(X)\n        assert_allclose(y_prob.sum(axis=1), np.ones(N_SAMPLES))\n\n        # Check if predict outputs class labels\n        y_pred = calibrated_clf.predict(X)\n        assert_array_equal(y_pred.shape, (N_SAMPLES,))\n\n        # Check if the calibrated classifier has the same number of classes\n        assert calibrated_clf.n_classes_ == n_classes\n"], "sample_826": ["    def test_onehot_inverse_transform_unknown_categories(self):\n        enc = OneHotEncoder(handle_unknown='ignore')\n        X = [['Male', 1], ['Female', 3], ['Female', 2]]\n        enc.fit(X)\n        X_trans = enc.transform(X)\n        X_inv = enc.inverse_transform(X_trans)\n        assert_equal(X_inv, np.array([['Male', 1], ['Female', 3], ['Female', 2]]))\n\n        X_new = [['Male', 4]]\n        X_trans_new = enc.transform(X_new)\n        X_inv_new = enc.inverse_transform(X_trans_new)\n        assert_equal(X_inv_new, np.array([['Male', None]]))\n"], "sample_661": ["    def test_junitxml_duration_report_total(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import time\n            import pytest\n\n                time.sleep(0.1)\n                assert True\n        \"\"\"\n        )\n        result, dom = runandparse(testdir, \"--junitxml\")\n        testcase = dom.find_first_by_tag(\"testcase\")\n        assert testcase[\"time\"] == pytest.approx(\"0.100\", 0.01)\n"], "sample_1076": ["    def test_print_MatrixSolve(self):\n        A = MatrixSymbol('A', 2, 2)\n        b = MatrixSymbol('b', 2, 1)\n        x = MatrixSymbol('x', 2, 1)\n        eq = Eq(A*x, b)\n        sol = MatrixSolve(eq, x)\n        self.assertEqual(str(NumPyPrinter().doprint(sol)), 'numpy.linalg.solve(A, b)')\n"], "sample_886": ["    def test_wrap_in_pandas_container_sparse_input():\n        with pytest.raises(ValueError, match=\"Pandas output does not support sparse data.\"):\n            _wrap_in_pandas_container(csr_matrix((2, 2)), columns=[1, 2])\n"], "sample_607": ["    def test_remove_duplicates(dummy_duplicated_entrypoints):\n        unique_entrypoints = plugins.remove_duplicates(dummy_duplicated_entrypoints)\n        assert len(unique_entrypoints) == 2\n        assert unique_entrypoints[0].name == \"engine1\"\n        assert unique_entrypoints[1].name == \"engine2\"\n"], "sample_495": ["    def test_empty_page(self):\n        \"\"\"\n        Test that EmptyPage is raised when requesting a page number\n        greater than the number of pages.\n        \"\"\"\n        with self.assertRaises(EmptyPage):\n            Paginator([1, 2, 3], 2).page(2)\n"], "sample_386": ["    def test_safe_string_addition(self):\n        self.assertIsInstance(mark_safe(\"Hello\") + mark_safe(\" world\"), SafeString)\n        self.assertIsInstance(mark_safe(\"Hello\") + \" world\", str)\n        self.assertIsInstance(\"Hello\" + mark_safe(\" world\"), str)\n"], "sample_57": ["    def test_password_validation_with_custom_user_model(self):\n        class CustomUserCreationForm(UserCreationForm):\n            class Meta:\n                model = CustomUser\n\n        form = CustomUserCreationForm()\n        self.assertTrue(isinstance(form.fields['password1'].widget, forms.PasswordInput))\n        self.assertEqual(form.fields['password1'].help_text, password_validation.password_validators_help_text_html())\n"], "sample_1060": ["    def test_print_SparseMatrix(self):\n        M = SparseMatrix([[1, 0, 0], [0, 2, 0], [0, 0, 3]])\n        self.assertEqual(NumPyPrinter().doprint(M),\n                         'scipy.sparse.coo_matrix(([1, 2, 3], ([0, 1, 2], [0, 1, 2])), shape=(3, 3))')\n"], "sample_1171": ["def test_complexregion_intersection():\n    a = Interval(0, 1)\n    b = Interval(0, 2*S.Pi)\n    c = Interval(1, 2)\n    d = Interval(S.Pi/2, 3*S.Pi/2)\n    c1 = ComplexRegion(a*b, polar=True)\n    c2 = ComplexRegion(c*d, polar=True)\n    c3 = c1.intersect(c2)\n    assert isinstance(c3, PolarComplexRegion)\n    assert c3.sets == ProductSet(Interval(1, 1), Interval(S.Pi/2, 3*S.Pi/2))\n"], "sample_375": ["    def test_state_render_with_custom_manager(self):\n        state = ModelState.from_model(UnicodeModel)\n        model = state.render(Apps())\n        self.assertEqual(model._default_manager.__class__, FoodManager)\n        self.assertEqual(model.objects.__class__, FoodQuerySet)\n"], "sample_1045": ["def test_sympify_complex():\n    assert sympify(complex(1, 2)) == 1 + 2*I\n    assert sympify(complex(0, 1)) == I\n    assert sympify(complex(-1, 0)) == -1\n    assert sympify(complex(0, -1)) == -I\n    assert sympify(complex(-1, -2)) == -1 - 2*I\n"], "sample_164": ["    def test_require_debug_false_filter(self):\n        filter_ = RequireDebugFalse()\n        self.assertFalse(filter_.filter(logging.LogRecord(level=logging.ERROR, msg='test')))\n        with override_settings(DEBUG=True):\n            self.assertTrue(filter_.filter(logging.LogRecord(level=logging.ERROR, msg='test')))\n"], "sample_702": ["    def test_get_lines_after(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n                print(\"hello\")\n                print(\"world\")\n                print(\"this is a test\")\n            \"\"\"\n        )\n        result = testdir.runpytest()\n        matcher = LineMatcher(result.stdout.splitlines())\n        lines = matcher.get_lines_after(\"hello\")\n        assert lines == [\"world\", \"this is a test\"]\n"], "sample_467": ["    def test_empty_values(self):\n        self.check_html(\n            self.widget,\n            \"date\",\n            html=(\n                '<select name=\"date_year\" id=\"id_date_year\">'\n                '<option value=\"\">---</option>'\n                '<option value=\"2007\">2007</option>'\n                '<option value=\"2008\">2008</option>'\n                '<option value=\"2009\">2009</option>'\n                '<option value=\"2010\">2010</option>'\n                '<option value=\"2011\">2011</option>'\n                '<option value=\"2012\">2012</option>'\n                '<option value=\"2013\">2013</option>'\n                '<option value=\"2014\">2014</option>'\n                '<option value=\"2015\">2015</option>'\n                '<option value=\"2016\">2016</option>'\n                '</select>'\n                '<select name=\"date_month\" id=\"id_date_month\">'\n                '<option value=\"\">---</option>'\n                '<option value=\"1\">January</option>'\n                '<option value=\"2\">February</option>'\n                '<option value=\"3\">March</option>'\n                '<option value=\"4\">April</option>'\n                '<option value=\"5\">May</option>'\n                '<option value=\"6\">June</option>'\n                '<option value=\"7\">July</option>'\n                '<option value=\"8\">August</option>'\n                '<option value=\"9\">September</option>'\n                '<option value=\"10\">October</option>'\n                '<option value=\"11\">November</option>'\n                '<option value=\"12\">December</option>'\n                '</select>'\n                '<select name=\"date_day\" id=\"id_date_day\">'\n                '<option value=\"\">---</option>'\n                '<option value=\"1\">1</option>'\n                '<option value=\"2\">2</option>'\n                '<option value=\"3\">3</option>'\n                '<option value=\"4\">4</option>'\n                '<option value=\"5"], "sample_751": ["    def test_sparse_input_classification():\n        # Test AdaBoostClassifier with sparse input\n        X_sparse = csc_matrix(X)\n        clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n                                 algorithm=\"SAMME\")\n        clf.fit(X_sparse, y_class)\n        assert_array_equal(clf.predict(T), y_t_class)\n\n"], "sample_242": ["    def test_year_lookup_bounds(self):\n        lookup = YearLookup(None, None)\n        with mock.patch('django.db.models.lookups.DateTimeField') as mock_datetime_field:\n            mock_datetime_field.return_value.output_field = mock.MagicMock()\n            lookup.year_lookup_bounds(None, 2023)\n            mock_datetime_field.assert_called_once_with()\n"], "sample_232": ["    def test_key_transform_isnull_with_null_value(self):\n        obj = JSONModel.objects.create(data={'key': None})\n        self.assertTrue(JSONModel.objects.filter(data__key__isnull=True).exists())\n        self.assertFalse(JSONModel.objects.filter(data__key__isnull=False).exists())\n"], "sample_778": ["    def test_n_components_error(self):\n        X = np.random.rand(10, 5)\n        model = NMF(n_components=6)\n        with pytest.raises(ValueError):\n            model.fit(X)\n"], "sample_548": ["    def test_colorbar_extension_length_vertical(self):\n        fig, ax = plt.subplots()\n        data = np.arange(100).reshape((10, 10))\n        im = ax.imshow(data, cmap='viridis')\n        cbar = fig.colorbar(im, ax=ax, extend='both', extendfrac=0.1,\n                            orientation='vertical')\n        # Check that the colorbar extension length is correct\n        assert cbar.ax.get_ylim()[1] - cbar.ax.get_ylim()[0] > 0.2\n\n"], "sample_738": ["    def test_tfidf_vectorizer_vocabulary_update(self):\n        # Test if vocabulary is updated when fit is called again with new data\n        vectorizer = TfidfVectorizer()\n        vectorizer.fit(ALL_FOOD_DOCS[:3])\n        vocab1 = vectorizer.vocabulary_\n\n        vectorizer.fit(ALL_FOOD_DOCS[3:])\n        vocab2 = vectorizer.vocabulary_\n\n        assert_not_equal(vocab1, vocab2)\n        assert_true(set(vocab1.keys()).issubset(set(vocab2.keys())))\n\n"], "sample_698": ["    def test_log_capture_handler_reset(self, caplog: LogCaptureFixture) -> None:\n        caplog.handler.setLevel(logging.DEBUG)\n        caplog.handler.emit(logging.makeLogRecord({\"msg\": \"test\"}))\n        assert caplog.records\n        caplog.handler.reset()\n        assert not caplog.records\n"], "sample_679": ["    def test_mark_evaluator_istrue_with_condition_and_reason(self, request):\n        mark = Mark(\n            \"mymark\",\n            {\"condition\": \"1 == 1\", \"reason\": \"This is the reason\"},\n        )\n        item = Node(request.node.config, parent=None, name=\"test_func\")\n        item.add_marker(mark)\n        evaluator = MarkEvaluator(item, \"mymark\")\n        assert evaluator.istrue()\n        assert evaluator.reason == \"This is the reason\"\n"], "sample_237": ["    def test_user_model_required_fields_is_tuple(self):\n        with override_settings(AUTH_USER_MODEL='auth_tests.CustomUserTupleRequiredFields'):\n            errors = check_user_model(app_configs=self.apps)\n            self.assertEqual(len(errors), 0)\n"], "sample_692": ["    def test_tmpdir_factory_getbasetemp_with_given_basetemp(self, tmpdir: Path) -> None:\n        config = Config.fromdict({\"basetemp\": str(tmpdir)})\n        factory = TempPathFactory.from_config(config, _ispytest=True)\n        assert factory.getbasetemp() == tmpdir\n"], "sample_334": ["    def test_form_hidden_fields(self):\n        form = Person(data={'first_name': 'John', 'last_name': 'Doe'})\n        hidden_fields = form.hidden_fields()\n        self.assertEqual(len(hidden_fields), 0)\n\n        form = Person(data={'first_name': 'John', 'last_name': 'Doe'},\n                      initial={'birthday': datetime.date(2000, 1, 1)})\n        hidden_fields = form.hidden_fields()\n        self.assertEqual(len(hidden_fields), 1)\n        self.assertEqual(hidden_fields[0].name, 'birthday')\n"], "sample_8": ["    def test_masked_array_from_masked_array(self):\n        ma = MaskedArray(self.a, mask=self.mask_a)\n        assert_masked_equal(ma, MaskedArray(ma))\n        assert_masked_equal(ma, MaskedArray(ma.unmasked, mask=ma.mask))\n"], "sample_781": ["def check_classification_large(name):\n    \"\"\"Check classification on a larger dataset.\"\"\"\n    ForestClassifier = FOREST_CLASSIFIERS[name]\n\n    clf = ForestClassifier(n_estimators=10, random_state=1)\n    clf.fit(X_large, y_large)\n    score = clf.score(X_large, y_large)\n    assert score > 0.9, \"Failed with score = %f\" % score\n\n    # also test feature importances\n    importances = clf.feature_importances_\n    assert importances.shape[0] == X_large.shape[1]\n    assert np.all(importances >= 0)\n    assert np.all(importances <= 1)\n\n"], "sample_221": ["    def test_prefetch_related_pickleability(self):\n        container = Container.objects.create()\n        event1 = Event.objects.create(container=container)\n        event2 = Event.objects.create(container=container)\n        group = Group.objects.create()\n        group.events.add(event1, event2)\n\n        qs = Event.objects.prefetch_related('container', 'groups').all()\n        self.assert_pickles(qs)\n"], "sample_736": ["    def test_logistic_regression_cv_multiclass_ovr(self):\n        # Test LogisticRegressionCV with multi_class='ovr'\n        X, y = make_classification(n_samples=100, n_features=20,\n                                   n_informative=10, n_classes=3,\n                                   random_state=0)\n        clf = LogisticRegressionCV(multi_class='ovr', solver='lbfgs',\n                                   cv=StratifiedKFold(5), random_state=0)\n        clf.fit(X, y)\n        assert_equal(clf.coef_.shape, (3, 20))\n        assert_equal(clf.intercept_.shape, (3,))\n"], "sample_148": ["    def test_nested_objects_with_parent_child_relation(self):\n        self._connect(1, 0)\n        self._connect(2, 0)\n        self._connect(3, 2)\n        self._collect(0, 1, 2, 3)\n        target = [\n            [self.objs[0].num, [self.objs[1].num, [self.objs[3].num]]],\n            self.objs[2].num,\n        ]\n        self._check(target)\n"], "sample_670": ["    def test_not_parentheses(self):\n        assert evaluate(\"(not a)\", lambda x: x == \"b\") is True\n        assert evaluate(\"(not (a))\", lambda x: x == \"b\") is True\n"], "sample_830": ["    def test_get_blas_info():\n        blas_info = _get_blas_info()\n        assert isinstance(blas_info, dict)\n        for key in ['macros', 'lib_dirs', 'cblas_libs']:\n            assert key in blas_info\n"], "sample_111": ["    def test_get_ordering_field_columns(self):\n        request = self.factory.get(reverse('admin:musician_musician_changelist'))\n        request.user = self.superuser\n        musician_admin = MusicianAdmin(Musician, custom_site)\n        changelist = musician_admin.get_changelist_instance(request)\n        ordering_fields = changelist.get_ordering_field_columns()\n        self.assertEqual(ordering_fields, {0: 'asc'})\n"], "sample_833": ["    def test_logistic_regression_cv_multiclass_ovr_sparse_input(self):\n        X, y = make_classification(n_samples=100, n_features=20,\n                                   n_informative=10, random_state=0,\n                                   n_classes=3)\n        X_sp = sp.csr_matrix(X)\n        clf = LogisticRegressionCV(cv=5, solver='lbfgs', multi_class='ovr',\n                                   random_state=0).fit(X_sp, y)\n        check_predictions(clf, X_sp, y)\n"], "sample_748": ["    def test_gridsearchcv_error_invalid_param_grid(self):\n        clf = LinearSVC()\n        param_grid = {'foo': 0}\n        with pytest.raises(TypeError) as excinfo:\n            GridSearchCV(clf, param_grid).fit(X, y)\n        assert str(excinfo.value) == \"Parameter grid value is not iterable (key='foo', value=0)\"\n"], "sample_271": ["    def test_iter_modules_and_files_zipfile(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_path = Path(tempdir) / 'test.zip'\n            with zipfile.ZipFile(zip_path, 'w') as zf:\n                zf.writestr('test_module/__init__.py', '')\n                zf.writestr('test_module/test.py', '')\n            sys.path.append(tempdir)\n            self.addCleanup(sys.path.remove, tempdir)\n            self.import_and_cleanup('test_module')\n            self.assertFileFound(zip_path)\n"], "sample_223": ["    def test_select_related_with_isnull(self):\n        with self.assertNumQueries(2):\n            # We need to fetch the Author object to check for the related\n            # ExtraInfo object.\n            authors = Author.objects.filter(extra__isnull=False).select_related('extra')\n        self.assertEqual(authors.count(), 2)\n        self.assertEqual(authors[0].extra.info, 'e1')\n        self.assertEqual(authors[1].extra.info, 'e2')\n\n"], "sample_842": ["def test_kernel_operator(kernel):\n    # Test KernelOperator\n    k1 = RBF(length_scale=1.0)\n    k2 = ConstantKernel(constant_value=2.0)\n    op = KernelOperator(k1, k2)\n    K = op(X)\n    assert K.shape == (X.shape[0], X.shape[0])\n    assert_array_almost_equal(K, k1(X) * k2(X))\n"], "sample_733": ["    def test_tfidfvectorizer_vocabulary_consistency(self):\n        # Test that vocabulary is consistent between fit and fit_transform\n        corpus = [\"This is the first document.\",\n                  \"This document is the second document.\",\n                  \"And this is the third one.\",\n                  \"Is this the first document?\"]\n\n        vectorizer = TfidfVectorizer()\n        vectorizer.fit(corpus)\n        vocab1 = vectorizer.vocabulary_\n\n        vectorizer = TfidfVectorizer()\n        vectorizer.fit_transform(corpus)\n        vocab2 = vectorizer.vocabulary_\n\n        assert_equal(vocab1, vocab2)\n"], "sample_137": ["    def test_parse_docstring(self):\n        title, body, metadata = parse_docstring(self.docstring)\n        self.assertEqual(title, 'Display an individual :model:`myapp.MyModel`.')\n        self.assertEqual(body, 'some_metadata: some data')\n        self.assertEqual(metadata, {'some_metadata': 'some data'})\n"], "sample_992": ["    def test_scipy_sparse_matrix(self):\n        A = SparseMatrix([[1, 0], [0, 2]])\n        code = SciPyPrinter().doprint(A)\n        assert code == 'scipy.sparse.coo_matrix([1, 2], ([0, 1], [0, 1]), shape=(2, 2))'\n"], "sample_88": ["    def test_emailmessage_bad_header(self):\n        msg = EmailMessage(\n            subject='Subject', body='Body', from_email='from@example.com',\n            to=['to@example.com'],\n        )\n        with self.assertRaises(BadHeaderError):\n            msg['Subject'] = 'This is a\\nmulti-line subject'\n"], "sample_631": ["    def test_unused_variable_in_nested_function(self):\n        code = \"\"\"\n            x = 1\n                y = x\n            inner()\n        outer()\n        \"\"\"\n        tree = astroid.parse(code)\n        with self.assertAddsMessages(\n            Message(\n                msg_id=\"unused-variable\",\n                node=tree.body[0].body[1].body[0].targets[0],\n                args=(\"y\",),\n            )\n        ):\n            self.checker.visit_module(tree)\n\n"], "sample_450": ["    def test_get_admin_log_tag(self):\n        response = self.client.get(reverse(\"admin:index\"))\n        self.assertContains(response, '{% get_admin_log 10 as admin_log %}')\n        self.assertContains(response, '<ul class=\"log-entries\">')\n"], "sample_754": ["    def test_sparse_pca_fit_transform(self):\n        # Test fit and transform methods\n        n_components = 3\n        n_samples = 10\n        image_size = (10, 10)\n        random_state = 0\n        Y, _, _ = generate_toy_data(n_components, n_samples, image_size,\n                                     random_state)\n        spca = SparsePCA(n_components=n_components, random_state=random_state,\n                        normalize_components=self.norm_comp)\n        spca.fit(Y)\n        X_transformed = spca.transform(Y)\n        assert_equal(X_transformed.shape, (n_samples, n_components))\n"], "sample_632": ["    def test_similar_ignore_imports(self):\n        linter = PyLinter()\n        reporter = Reporter()\n        linter.set_reporter(reporter)\n        linter.load_plugin_modules(\n            [similar]\n        )  # pylint: disable=protected-access\n        with redirect_stdout(StringIO()):\n            linter.check([HIDE_CODE_WITH_IMPORTS])\n        assert (\n            reporter.messages\n            == [\n                (\n                    \"R0801\",\n                    \"Similar lines in 1 files\\n==hide_code_with_imports.py:1\\n   import os\\n   import sys\\n\",\n                    \"hide_code_with_imports.py\",\n                    1,\n                )\n            ]\n        )\n"], "sample_494": ["    def test_serialize_int_flag_enum(self):\n        class MyIntFlagEnum(enum.IntFlag):\n            A = 1\n            B = 2\n            C = 4\n\n        value = MyIntFlagEnum.A | MyIntFlagEnum.B\n        serialized, imports = serializer_factory(value).serialize()\n        self.assertEqual(serialized, \"MyIntFlagEnum.A | MyIntFlagEnum.B\")\n        self.assertEqual(imports, {\"import enum\"})\n"], "sample_1089": ["def test_factor_nc_issue_17145():\n    A = Symbol('A', commutative=False)\n    B = Symbol('B', commutative=False)\n    C = Symbol('C', commutative=False)\n    assert factor_nc(A*B + A*C) == A*(B + C)\n"], "sample_225": ["    def test_each_context_available_apps(self):\n        self.assertIn('available_apps', self.ctx)\n        self.assertIsInstance(self.ctx['available_apps'], list)\n        for app in self.ctx['available_apps']:\n            self.assertIn('name', app)\n            self.assertIn('app_label', app)\n            self.assertIn('app_url', app)\n            self.assertIn('has_module_perms', app)\n            self.assertIn('models', app)\n            for model in app['models']:\n                self.assertIn('model', model)\n                self.assertIn('name', model)\n                self.assertIn('object_name', model)\n                self.assertIn('perms', model)\n                self.assertIn('admin_url', model)\n                self.assertIn('add_url', model)\n"], "sample_823": ["    def test_pairwise_distances_chunked_reduce_func_sparse(self):\n        X = csr_matrix([[0, 1], [1, 0]])\n        Y = csr_matrix([[1, 0], [0, 1]])\n\n            return D_chunk.toarray()\n\n        gen = pairwise_distances_chunked(X, Y, reduce_func=reduce_func)\n        result = next(gen)\n        assert_array_equal(result, pairwise_distances(X, Y))\n"], "sample_331": ["    def test_parse_datetime_with_timezone(self):\n        dt = parse_datetime('2023-10-27T12:34:56+02:00')\n        self.assertEqual(dt.year, 2023)\n        self.assertEqual(dt.month, 10)\n        self.assertEqual(dt.day, 27)\n        self.assertEqual(dt.hour, 12)\n        self.assertEqual(dt.minute, 34)\n        self.assertEqual(dt.second, 56)\n        self.assertEqual(dt.tzinfo.utcoffset(dt).total_seconds(), 7200)\n"], "sample_1166": ["def test_Monomial_as_expr():\n    m = Monomial((1, 2, 3), gens=[x, y, z])\n    assert m.as_expr() == x*y**2*z**3\n    assert m.as_expr(x, z, y) == x*z**3*y**2\n    assert Monomial((1,)).as_expr() == x\n    assert Monomial((0,)).as_expr() == S.One\n"], "sample_120": ["    def test_serialize_lazy_object(self):\n        lazy_obj = SimpleLazyObject(lambda: 'test')\n        serializer = serializer_factory(lazy_obj)\n        self.assertEqual(serializer.serialize(), (\"'test'\", set()))\n"], "sample_346": ["    def test_method_decorator_with_class(self):\n        class MyClass:\n            @method_decorator(login_required, name='my_method')\n                return HttpResponse('OK')\n\n        instance = MyClass()\n        response = instance.my_method(HttpRequest())\n        self.assertEqual(response.status_code, 302)\n"], "sample_205": ["    def test_validationerror_from_dict(self):\n        error_dict = {\n            'field1': ['Error 1', 'Error 2'],\n            'field2': ValidationError('Error 3'),\n        }\n        ve = ValidationError(error_dict)\n        self.assertEqual(ve.error_dict, {\n            'field1': ['Error 1', 'Error 2'],\n            'field2': ['Error 3'],\n        })\n"], "sample_498": ["    def test_legend_bbox_to_anchor(self, loc, expected_bbox):\n        fig, ax = plt.subplots()\n        ax.plot([1, 2, 3], [4, 5, 6])\n        legend = ax.legend(loc=loc)\n        assert_allclose(legend.get_bbox_to_anchor().bounds, expected_bbox)\n"], "sample_511": ["    def test_imshow_data_argument():\n        fig, ax = plt.subplots()\n        data = np.random.rand(10, 10)\n        ax.imshow(data, data=data)\n        assert ax.images[0].get_array() is data\n"], "sample_777": ["    def test_classification_sparse_input(self):\n        # Check classification on a sparse matrix.\n        clf = GradientBoostingClassifier(random_state=1)\n        X_sparse = csr_matrix(iris.data)\n        clf.fit(X_sparse, iris.target)\n        score = clf.score(X_sparse, iris.target)\n        assert score > 0.9\n\n"], "sample_890": ["    def test_sequential_feature_selector_backward_selection_with_tol(\n        self, random_state"], "sample_1178": ["    def test_FunctionDefinition_from_FunctionPrototype(self):\n        fp = FunctionPrototype(real, 'foo', [x, y])\n        body = [Return(x*y)]\n        fd = FunctionDefinition.from_FunctionPrototype(fp, body)\n        assert isinstance(fd, FunctionDefinition)\n        assert fd.return_type == real\n        assert fd.name == 'foo'\n        assert fd.parameters == (x, y)\n        assert fd.body == CodeBlock(*body)\n"], "sample_419": ["    def test_formset_factory_absolute_max(self):\n        formset_class = formset_factory(\n            Choice,\n            max_num=5,\n            absolute_max=3,\n        )\n        formset = formset_class(data={\n            \"choices-TOTAL_FORMS\": \"4\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-0-choice\": \"Choice 1\",\n            \"choices-0-votes\": \"1\",\n            \"choices-1-choice\": \"Choice 2\",\n            \"choices-1-votes\": \"2\",\n            \"choices-2-choice\": \"Choice 3\",\n            \"choices-2-votes\": \"3\",\n            \"choices-3-choice\": \"Choice 4\",\n            \"choices-3-votes\": \"4\",\n        })\n        self.assertEqual(formset.errors, [])\n        self.assertEqual(formset.total_form_count(), 3)\n        self.assertEqual(formset.cleaned_data, [\n            {'choice': 'Choice 1', 'votes': 1},\n            {'choice': 'Choice 2', 'votes': 2},\n            {'choice': 'Choice 3', 'votes': 3},\n        ])\n\n"], "sample_462": ["    def test_empty_choices(self):\n        field = ChoiceField(choices=[])\n        self.assertFieldOutput(field, '', '')\n        with self.assertRaises(ValidationError):\n            field.clean('something')\n"], "sample_479": ["    def test_rename_index_with_old_fields(self):\n        operations = [\n            operations.RenameIndex(\n                \"UnicodeModel\",\n                new_name=\"new_index\",\n                old_fields=[\"name\"],\n            ),\n        ]\n        self.assertOptimizesTo(\n            operations,\n            [\n                operations.RenameIndex(\n                    \"UnicodeModel\",\n                    new_name=\"new_index\",\n                    old_fields=[\"name\"],\n                ),\n            ],\n        )\n"], "sample_716": ["    def test_ridge_classifier_cv_sparse_multiclass(self):\n        X, y = make_multilabel_classification(\n            n_samples=50, n_features=10, n_classes=3, random_state=0)\n        X = sp.csr_matrix(X)\n        clf = RidgeClassifierCV(alphas=[0.1, 1.0, 10.0], cv=5)\n        clf.fit(X, y)\n        assert_equal(clf.coef_.shape, (3, 10))\n        assert_equal(clf.intercept_.shape, (3,))\n"], "sample_893": ["    def test_export_text_multioutput():\n        # Test export_text with multi-output regression\n        rng = RandomState(0)\n        X = rng.rand(10, 2)\n        y = rng.rand(10, 2)\n        dt = DecisionTreeRegressor()\n        dt.fit(X, y)\n        report = export_text(dt)\n        assert \"value: [...\" in report\n        assert \"value: [...\" in report\n\n"], "sample_1002": ["def test_fibonacci():\n    assert fibonacci(0) == 0\n    assert fibonacci(1) == 1\n    assert fibonacci(2) == 1\n    assert fibonacci(3) == 2\n    assert fibonacci(4) == 3\n    assert fibonacci(5) == 5\n    assert fibonacci(10) == 55\n    assert fibonacci(20) == 6765\n\n"], "sample_363": ["    def test_formfield_for_dbfield_manytomany_rawid(self):\n        ff = self.assertFormfield(Band, 'members', widgets.ManyToManyRawIdWidget,\n                                  raw_id_fields={'members': {'verbose_name': 'Members'}})\n        self.assertEqual(ff.widget.rel.model, Member)\n        self.assertEqual(ff.widget.template_name, 'admin/widgets/many_to_many_raw_id.html')\n"], "sample_719": ["    def test_tfidfvectorizer_vocabulary_consistency(self):\n        # Test that vocabulary is consistent between fit and fit_transform\n        vectorizer = TfidfVectorizer(max_df=0.5)\n        vectorizer.fit(ALL_FOOD_DOCS)\n        vocab1 = vectorizer.vocabulary_\n\n        vectorizer = TfidfVectorizer(max_df=0.5)\n        vectorizer.fit_transform(ALL_FOOD_DOCS)\n        vocab2 = vectorizer.vocabulary_\n\n        assert_equal(vocab1, vocab2)\n"], "sample_155": ["    def test_file_response_with_filename(self):\n        with tempfile.NamedTemporaryFile(mode='w+b') as f:\n            f.write(b'This is a test file.')\n            f.seek(0)\n            response = FileResponse(f, filename='test.txt')\n            self.assertEqual(response['Content-Disposition'], 'attachment; filename=\"test.txt\"')\n            self.assertEqual(response['Content-Length'], str(f.tell()))\n"], "sample_125": ["    def test_set_cookie_expires_datetime(self):\n        response = HttpResponse()\n        now = datetime.now(utc)\n        response.set_cookie('test', 'value', expires=now + timedelta(days=1))\n        self.assertEqual(response.cookies['test']['expires'], http_date(now + timedelta(days=1)))\n"], "sample_1176": ["def test_is_integer():\n    assert S.Pi.is_integer is False\n    assert S.EulerGamma.is_integer is False\n    assert S.GoldenRatio.is_integer is False\n    assert S.ImaginaryUnit.is_integer is False\n    assert S.Infinity.is_integer is False\n    assert S.NegativeInfinity.is_integer is False\n    assert S.NaN.is_integer is False\n    assert (S.Half).is_integer is False\n    assert (S.NegativeOne).is_integer is True\n    assert (S.Zero).is_integer is True\n    assert (S.One).is_integer is True\n    assert (Integer(5)).is_integer is True\n    assert (Rational(5, 2)).is_integer is False\n    assert (Float(5.0)).is_integer is True\n    assert (Float(5.5)).is_integer is False\n\n"], "sample_860": ["    def test_check_scalar_error_messages():\n        # Test error messages for check_scalar\n        with pytest.raises(TypeError) as excinfo:\n            check_scalar(\"foo\", \"name\", int)\n        assert \"must be an instance of <class 'int'>, not <class 'str'>\" in str(\n            excinfo.value\n        )\n\n        with pytest.raises(ValueError) as excinfo:\n            check_scalar(10, \"name\", int, min_val=20)\n        assert \"'name'= 10, must be >= 20.\" in str(excinfo.value)\n\n        with pytest.raises(ValueError) as excinfo:\n            check_scalar(10, \"name\", int, max_val=5)\n        assert \"'name'= 10, must be <= 5.\" in str(excinfo.value)\n\n"], "sample_1031": ["def test_quantity_creation():\n    with warns_deprecated_sympy():\n        q = Quantity('my_quantity', abbrev='mq', dimension=length, scale_factor=10*m)\n    assert q.name == 'my_quantity'\n    assert q.abbrev == 'mq'\n    assert q.dimension == length\n    assert q.scale_factor == 10*m\n    assert q.unit_system == UnitSystem.get_default_unit_system()\n\n"], "sample_1167": ["    def test_latex_SetExpr(self):\n        S = FiniteSet(1, 2, 3)\n        self.assertEqual(latex(S), '\\\\left\\{1, 2, 3\\\\right\\}')\n\n        S = ImageSet(lambda x: 2*x, Interval(0, 1))\n        self.assertEqual(latex(S), '\\\\left\\{2 x \\\\mid x \\\\in \\\\left[0, 1\\\\right]\\\\right\\}')\n\n        S = ConditionSet(x, Eq(x**2, 1))\n        self.assertEqual(latex(S), '\\\\left\\{x \\\\mid x^{2} = 1\\\\right\\}')\n\n        S = Union(FiniteSet(1, 2), FiniteSet(3, 4))\n        self.assertEqual(latex(S), '\\\\left\\{1, 2, 3, 4\\\\right\\}')\n\n        S = Intersection(FiniteSet(1, 2, 3), FiniteSet(2, 3, 4))\n        self.assertEqual(latex(S), '\\\\left\\{2, 3\\\\right\\}')\n\n        S = Complement(UniversalSet, FiniteSet(1, 2))\n        self.assertEqual(latex(S), '\\\\mathbb{U} \\\\setminus \\\\left\\{1, 2\\\\right\\}')\n\n        S = SymmetricDifference(FiniteSet(1, 2), FiniteSet(2, 3))\n        self.assertEqual(latex(S), '\\\\left\\{1, 3\\\\right\\}')\n\n        S = ProductSet(Interval(0, 1), Interval(0, 1))\n        self.assertEqual(latex(S), '\\\\left[0, 1\\\\right] \\\\times \\\\left[0, 1\\\\right]')\n"], "sample_1022": ["    def test_split_symbols_custom_predicate():\n            if symbol not in ('list', 'of', 'unsplittable', 'names'):\n                    return _token_splittable(symbol)\n            return False\n        transformation = split_symbols_custom(can_split)\n        assert parse_expr('unsplittable', transformations=standard_transformations +\n        (transformation, implicit_multiplication)) == sympy.Symbol('unsplittable')\n        assert parse_expr('listofnames', transformations=standard_transformations +\n        (transformation, implicit_multiplication)) == sympy.Symbol('list')*sympy.Symbol('of')*sympy.Symbol('names')\n"], "sample_506": ["    def test_set_bounds(self, spine_type):\n        fig, ax = plt.subplots()\n        spine = ax.spines[spine_type]\n        spine.set_bounds(1, 2)\n        assert spine._bounds == (1, 2)\n"], "sample_231": ["    def test_callable_setting_wrapper_repr(self):\n            pass\n        wrapped_callable = CallableSettingWrapper(my_callable)\n        self.assertEqual(repr(wrapped_callable), repr(my_callable))\n"], "sample_684": ["    def test_repr_func_args_empty(self) -> None:\n        args = ReprFuncArgs([])\n        assert str(args) == \"\"\n"], "sample_962": ["    def test_mock_undecorate(self):\n        with mock(['test_util_typing']):\n            from sphinx.util.typing import undecorate\n            mock_obj = _MockObject('mock_func', ())\n            assert undecorate(mock_obj) is mock_obj\n            mock_obj.__sphinx_decorator_args__ = ('real_func', )\n            assert undecorate(mock_obj) is 'real_func'\n"], "sample_329": ["    def test_serialize_lazy_object(self):\n        lazy_value = SimpleLazyObject(lambda: 'lazy')\n        serializer = serializer_factory(lazy_value)\n        self.assertEqual(serializer.serialize(), (\"'lazy'\", set()))\n"], "sample_690": ["    def test_evaluate_skip_marks_skipif_condition_string(self, pytester: Pytester) -> None:\n        item = pytester.makepytest(\"def test_func(): pass\")\n        item._store[skipped_by_mark_key] = False\n        item._store[xfailed_key] = None\n        mark = pytest.mark.skipif(\n            \"sys.platform == 'win32'\", reason=\"skip on windows\"\n        )\n        item._nodeid = \"test_func\"\n        item.add_marker(mark)\n        evaluate_skip_marks(item)\n        assert item._store[skipped_by_mark_key] is True\n        assert item._store[xfailed_key] is None\n"], "sample_901": ["    def test_mini_batch_kmeans_sparse_input(representation, algo, dtype):\n        # Test MiniBatchKMeans with sparse input\n        if representation == 'dense':\n            X_ = X.astype(dtype)\n        else:\n            X_ = X_csr.astype(dtype)\n\n        kmeans = MiniBatchKMeans(n_clusters=n_clusters, init='k-means++',\n                                 n_init=1, random_state=42,\n                                 algorithm=algo, verbose=0)\n        kmeans.fit(X_)\n        labels = kmeans.labels_\n\n        # Check if the labels are consistent with the true labels\n        assert v_measure_score(true_labels, labels) > 0.9\n"], "sample_251": ["    def test_case_when_then(self):\n        qs = Book.objects.annotate(\n            price_category=Case(\n                When(price__gt=Decimal('30'), then=Value('expensive')),\n                When(price__gt=Decimal('20'), then=Value('moderate')),\n                default=Value('cheap'),\n                output_field=CharField(),\n            )\n        )\n        self.assertQuerysetEqual(\n            qs.filter(price_category='expensive'),\n            ['The Definitive Guide to Django: Web Development Done Right'],\n            lambda b: b.name\n        )\n        self.assertQuerysetEqual(\n            qs.filter(price_category='moderate'),\n            [\n                'Sams Teach Yourself Django in 24 Hours',\n                'Practical Django Projects',\n                'Python Web Development with Django',\n            ],\n            lambda b: b.name\n        )\n        self.assertQuerysetEqual(\n            qs.filter(price_category='cheap'),\n            ['Artificial Intelligence: A Modern Approach', 'Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp'],\n            lambda b: b.name\n        )\n"], "sample_578": ["    def test_bar_baseline(self):\n\n        data = pd.DataFrame({'x': [1, 2, 3], 'y': [2, 4, 6]})\n        bars = self.plot_bars(\n            variables={'x': 'x', 'y': 'y'},\n            mark_kws={'baseline': 1},\n            layer_kws={'orient': 'x'}\n        )\n\n        self.check_bar(bars[0], 0.5, 1, 1, 1)\n        self.check_bar(bars[1], 1.5, 1, 1, 3)\n        self.check_bar(bars[2], 2.5, 1, 1, 5)\n"], "sample_600": ["    def test_unsigned_integer_coder_roundtrip():\n        data = np.array([0, 1, 2, 3, 4, 255], dtype=np.uint8)\n        var = xr.Variable([\"x\"], data, attrs={\"_Unsigned\": \"true\"})\n        encoded = variables.UnsignedIntegerCoder().encode(var)\n        decoded = variables.UnsignedIntegerCoder().decode(encoded)\n        assert_identical(var, decoded)\n\n        data = np.array([-1, 0, 1, 2, 3, 4], dtype=np.int8)\n        var = xr.Variable([\"x\"], data, attrs={\"_Unsigned\": \"true\"})\n        encoded = variables.UnsignedIntegerCoder().encode(var)\n        decoded = variables.UnsignedIntegerCoder().decode(encoded)\n        assert_identical(var, decoded)\n"], "sample_397": ["    def test_get_template_builtins(self):\n        engine = Engine(builtins=[\"django.template.defaulttags\"])\n        self.assertEqual(len(engine.template_builtins), 1)\n        self.assertIsNotNone(engine.template_builtins[0])\n"], "sample_82": ["    def test_empty_values(self):\n        self.check_html(\n            self.widget,\n            'date',\n            '<select name=\"date_year\"><option value=\"\">---</option><option value=\"2007\">2007</option><option value=\"2008\">2008</option>...</select><select name=\"date_month\"><option value=\"\">---</option><option value=\"1\">January</option><option value=\"2\">February</option>...</select><select name=\"date_day\"><option value=\"\">---</option><option value=\"1\">1</option><option value=\"2\">2</option>...</select>',\n        )\n"], "sample_1056": ["    def test_numexpr_printer_piecewise():\n        expr = Piecewise((x, x < 1), (x**2, x >= 1))\n        printer = NumExprPrinter()\n        raises(TypeError, lambda: printer.doprint(expr))\n"], "sample_858": ["    def test_voting_regressor_weights_none(self):\n        # Test VotingRegressor with weights=None\n        reg1 = LinearRegression()\n        reg2 = RandomForestRegressor(n_estimators=10, random_state=1)\n        vr = VotingRegressor([('lr', reg1), ('rf', reg2)])\n        vr.fit(X_r, y_r)\n        y_pred = vr.predict(X_r)\n        assert_array_equal(y_pred.shape, y_r.shape)\n"], "sample_270": ["    def test_index_together_with_expressions(self):\n        class MyModel(models.Model):\n            name = models.CharField(max_length=100)\n            value = models.IntegerField()\n\n            class Meta:\n                index_together = [\n                    ('name', Abs(models.F('value'))),\n                ]\n\n        with self.assertRaises(checks.Error):\n            MyModel.check()\n"], "sample_398": ["    def test_password_reset_confirm_invalid_token(self):\n        # Test that an invalid token results in an error message.\n        self.client.logout()\n        uidb64 = urlsafe_base64_encode(str(self.u1.pk).encode()).decode()\n        token = \"invalid-token\"\n        response = self.client.get(\n            reverse(\"password_reset_confirm\", kwargs={\"uidb64\": uidb64, \"token\": token})\n        )\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, \"Password reset unsuccessful\")\n"], "sample_1124": ["    def test_sfield_from_expr_with_exp(self):\n        x = symbols('x')\n        K, f = sfield(exp(x) + x**2)\n        assert K.domain == QQ\n        assert f == FracElement(K.ring.new(exp(x) + x**2, 1))\n"], "sample_545": ["    def test_figure_dpi_set_get(self):\n        fig = Figure()\n        assert fig.dpi == mpl.rcParams['figure.dpi']\n        fig.dpi = 100\n        assert fig.dpi == 100\n"], "sample_772": ["def check_classification_iris(name):\n    \"\"\"Check classification on the iris dataset.\"\"\"\n    ForestClassifier = FOREST_CLASSIFIERS[name]\n\n    clf = ForestClassifier(n_estimators=10, random_state=1)\n    clf.fit(iris.data, iris.target)\n    score = clf.score(iris.data, iris.target)\n    assert score > 0.9\n\n    clf = ForestClassifier(n_estimators=10, max_features=1, random_state=1)\n    clf.fit(iris.data, iris.target)\n    score = clf.score(iris.data, iris.target)\n    assert score > 0.9\n"], "sample_724": ["compilation error"], "sample_839": ["    def test_tfidfvectorizer_vocabulary_consistency(self):\n        # Check that vocabulary is consistent between fit and fit_transform\n        corpus = ['This is the first document.',\n                  'This document is the second document.',\n                  'And this is the third one.',\n                  'Is this the first document?']\n\n        vectorizer = TfidfVectorizer()\n        vectorizer.fit(corpus)\n        vocab1 = vectorizer.vocabulary_\n\n        vectorizer = TfidfVectorizer()\n        vectorizer.fit_transform(corpus)\n        vocab2 = vectorizer.vocabulary_\n\n        assert vocab1 == vocab2\n"], "sample_649": ["    def test_log_level_setting(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import logging\n            import pytest\n\n            @pytest.mark.parametrize(\"log_level\", [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"])\n                logging.getLogger().setLevel(log_level)\n                logging.info(\"This is an info message\")\n                assert len(caplog.records) == 1\n                assert caplog.records[0].levelno == getattr(logging, log_level)\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 0\n"], "sample_861": ["    def test_parameter_sampler_invalid_input(self, klass):\n        with pytest.raises(error_type) as exc_info:\n            klass(input)\n        assert str(exc_info.value) == error_message\n"], "sample_119": ["    def test_join_promotion_with_related_isnull(self):\n        author = Author.objects.create(name='Author A')\n        item = Item.objects.create(author=author, name='Item A')\n        query = Item.objects.filter(author__isnull=True)\n        self.assertEqual(query.count(), 0)\n        query = Item.objects.filter(author__isnull=False)\n        self.assertEqual(query.count(), 1)\n"], "sample_421": ["    def test_case_when_with_subquery(self):\n        qs = CaseTestModel.objects.annotate(\n            case_when=Case(\n                When(integer=1, then=Sum(\"fkcasetestmodel__integer\")),\n                default=0,\n            )\n        )\n        self.assertEqual(\n            qs.filter(integer=1).values_list(\"case_when\", flat=True).first(), 1\n        )\n        self.assertEqual(\n            qs.filter(integer=2).values_list(\"case_when\", flat=True).first(), 0\n        )\n\n\n\n"], "sample_257": ["    def test_key_transform_isnull_with_null_key(self):\n        model = JSONModel.objects.create(data={'key': None})\n        self.assertTrue(JSONModel.objects.filter(data__key__isnull=True).exists())\n        self.assertFalse(JSONModel.objects.filter(data__key__isnull=False).exists())\n"], "sample_186": ["    def test_check_middleware_classes(self):\n        admin_site = AdminSite()\n        admin_site.register(Song, ValidFields)\n        middleware = [\n            AuthenticationMiddlewareSubclass,\n            MessageMiddlewareSubclass,\n            SessionMiddlewareSubclass,\n        ]\n        admin_site.middleware = middleware\n        errors = admin_site.check()\n        self.assertEqual(len(errors), 0)\n"], "sample_203": ["    def test_validate_email_with_unicode_domain(self):\n        validate_email = validators.EmailValidator()\n        with self.assertRaises(ValidationError):\n            validate_email('test@\u4f60\u597d.com')\n"], "sample_637": ["    def test_fixme_with_pragma(self):\n        stmts = _tokenize_str(\n            \"\"\"\n            # pylint: disable=fixme\n            # FIXME: This is a fixme\n                pass\n            \"\"\"\n        )\n        with set_config(notes=[\"FIXME\"]):\n            self.checker.process_tokens(stmts)\n            self.assertNoMessages()\n\n"], "sample_1034": ["    def test_grover_iteration_twice():\n        nqubits = 2\n        f = return_one_on_two\n        v = OracleGate(nqubits, f)\n        initial_state = superposition_basis(nqubits)\n        after_one_iteration = grover_iteration(initial_state, v)\n        after_two_iterations = grover_iteration(after_one_iteration, v)\n        assert qapply(after_two_iterations) == IntQubit(2, nqubits=nqubits)\n"], "sample_407": ["    def test_related_object_deletion(self):\n        # Delete the Reporter.\n        self.r.delete()\n        # Check that the Article's reporter is now None.\n        self.assertIsNone(Article.objects.get(headline=\"This is a test\").reporter)\n"], "sample_568": ["def test_poly3dcollection_shade():\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n\n    verts = [\n        [(0, 0, 0), (1, 0, 0), (1, 1, 0), (0, 1, 0)],\n        [(0, 0, 1), (1, 0, 1), (1, 1, 1), (0, 1, 1)],\n    ]\n    pc = art3d.Poly3DCollection(verts, facecolors=['r', 'b'],\n                                edgecolors='k', shade=True)\n    ax.add_collection3d(pc)\n    ax.set_xlim([0, 1])\n    ax.set_ylim([0, 1])\n    ax.set_zlim([0, 1])\n    return fig\n"], "sample_1027": ["def test_groebner_basis_zero_dimensional():\n    from sympy.abc import x, y\n\n    F = [x**2 - 3*y - x + 1, y**2 - 2*x + y - 1]\n    G = groebner(F, x, y, order='grlex')\n\n    assert G.is_zero_dimensional\n"], "sample_396": ["    def test_ticket_23605(self):\n        # Regression test for #23605: Ensure that joins are correctly handled\n        # when using subqueries with EXISTS.\n\n        # Create some objects for the test\n        Ticket23605A.objects.create(name=\"A1\")\n        Ticket23605B.objects.create(name=\"B1\", a=Ticket23605A.objects.get(name=\"A1\"))\n        Ticket23605C.objects.create(name=\"C1\", b=Ticket23605B.objects.get(name=\"B1\"))\n\n        # This query should return True because there is a Ticket23605C object\n        # associated with a Ticket23605B object, which is associated with a\n        # Ticket23605A object.\n        self.assertTrue(\n            Ticket23605A.objects.filter(\n                Exists(\n                    Ticket23605B.objects.filter(\n                        a=OuterRef(\"pk\"),\n                        Ticket23605C__b=OuterRef(\"pk\"),\n                    )\n                )\n            ).exists()\n        )\n\n        # This query should return False because there is no Ticket23605C object\n        # associated with a Ticket23605B object, which is associated with a\n        # Ticket23605A object.\n        self.assertFalse(\n            Ticket23605A.objects.filter(\n                Exists(\n                    Ticket23605B.objects.filter(\n                        a=OuterRef(\"pk\"),\n                        Ticket23605C__b=OuterRef(\"pk\"),\n                    )\n                )\n            ).exclude(pk=1).exists()\n        )\n"], "sample_633": ["    def test_similar_ignore_imports(self):\n        linter = PyLinter()\n        reporter = Reporter()\n        linter.set_reporter(reporter)\n        linter.add_checker(similar.SimilarChecker(linter))\n        linter.options.ignore_imports = True\n        with redirect_stdout(StringIO()):\n            linter.check([HIDE_CODE_WITH_IMPORTS])\n        stats = linter.stats\n        assert stats[\"nb_duplicated_lines\"] == 0\n        assert stats[\"percent_duplicated_lines\"] == 0\n"], "sample_571": ["    def test_residplot(self):\n        with mpl.rc_context({'figure.figsize': (6, 4)}):\n            ax = lm.residplot(x=\"x\", y=\"y\", data=self.df, ax=plt.gca())\n        assert len(ax.lines) == 2\n        assert ax.collections[0].get_offsets().shape[0] == 60\n\n        ax = lm.residplot(x=\"x\", y=\"y\", data=self.df, lowess=True)\n        assert len(ax.lines) == 3\n\n        ax = lm.residplot(x=\"x\", y=\"y\", data=self.df, robust=True)\n        assert len(ax.lines) == 2\n\n        with pytest.raises(ValueError):\n            lm.residplot(x=\"x\", y=\"y\", data=self.df, order=3, robust=True)\n\n"], "sample_1156": ["def test_asech_rewrite():\n    x = Symbol('x')\n    assert asech(x).rewrite(log) == log(1/x + sqrt(1/x**2 - 1))\n"], "sample_322": ["    def test_migrate_forwards_with_replacements(self):\n        # Test that migrations with replacements are applied correctly.\n        with self.connection.cursor() as cursor:\n            cursor.execute(\"DROP TABLE IF EXISTS migrations2_replacedmodel\")\n        self.migrate_apps([\"migrations2\"])\n        # Check that the replaced migration has been applied\n        recorder = MigrationRecorder(self.connection)\n        self.assertIn(('migrations2', '0002_replacedmodel'), recorder.applied_migrations())\n"], "sample_32": ["    def test_wz_setter(self):\n        \"\"\"Test setting the wz parameter.\"\"\"\n        cosmo = self._cls(**self._cls_args, **self._cls_kwargs)\n        new_wz = 0.2\n        cosmo.wz = new_wz\n        assert cosmo.wz == new_wz\n"], "sample_957": ["    def test_restify_invalid_builtin_classes():\n        assert restify(Struct) == ':class:`struct.Struct`'\n        assert restify(TracebackType) == ':class:`types.TracebackType`'\n"], "sample_142": ["    def test_modelformset_factory_with_fk_name(self):\n        formset = modelformset_factory(\n            parent_model=Author,\n            model=Book,\n            fk_name='author',\n            fields=['title'],\n        )\n        self.assertEqual(formset.fk.name, 'author')\n"], "sample_658": ["    def test_doctest_module_collects_doctests_in_conftest(self, tmpdir):\n        conftest_path = tmpdir.join(\"conftest.py\")\n        conftest_path.write(\n            textwrap.dedent(\n                \"\"\"\n                pass\n            \"\"\"\n            )\n        )\n        modcol = DoctestModule(conftest_path, None)\n        items = list(modcol.collect())\n        assert len(items) == 1\n        assert isinstance(items[0], DoctestItem)\n"], "sample_786": ["    def test_transform_constant_feature(self):\n        X = [[1, 1, 1],\n             [1, 1, 1],\n             [1, 1, 1]]\n        est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n        with warnings.catch_warnings(record=True) as w:\n            est.fit(X)\n            assert_warns_message(w, \"Feature 0 is constant and will be replaced with 0.\")\n            assert_warns_message(w, \"Feature 1 is constant and will be replaced with 0.\")\n            assert_warns_message(w, \"Feature 2 is constant and will be replaced with 0.\")\n        Xt = est.transform(X)\n        assert_array_equal(Xt, [[0, 0, 0],\n                               [0, 0, 0],\n                               [0, 0, 0]])\n"], "sample_1201": ["    def test_cgs_gauss_conversions():\n        assert convert_to(statcoulomb, coulomb, cgs_gauss) == 10*speed_of_light*statcoulomb\n        assert convert_to(coulomb, statcoulomb, cgs_gauss) == 1/(10*speed_of_light)*coulomb\n        assert convert_to(statvolt, volt, cgs_gauss) == 10**(-6)*speed_of_light*statvolt\n        assert convert_to(volt, statvolt, cgs_gauss) == 1/(10**(-6)*speed_of_light)*volt\n        assert convert_to(gauss, tesla, cgs_gauss) == 10**(-4)*gauss\n        assert convert_to(tesla, gauss, cgs_gauss) == 10**(4)*tesla\n"], "sample_793": ["    def test_iforest_sparse_input(self):\n        # Test IsolationForest with sparse input\n        X_sparse = csc_matrix(boston.data)\n        clf = IsolationForest(random_state=rng)\n        clf.fit(X_sparse)\n        assert_raises(ValueError, clf.predict, boston.data)\n        clf.predict(X_sparse)\n"], "sample_103": ["    def test_aggregate_with_filter_on_related_field(self):\n        # Test using a filter on a related field within an aggregate.\n        with CaptureQueriesContext(connection) as queries:\n            result = Book.objects.annotate(\n                avg_rating=Avg('rating'),\n            ).filter(avg_rating__gt=3.5).values('avg_rating').distinct()\n            self.assertQuerySetEqual(result, [\n                {'avg_rating': Approximate(Decimal('4.00'))},\n                {'avg_rating': Approximate(Decimal('4.50'))},\n            ], transform=lambda x: {'avg_rating': x['avg_rating']})\n            self.assertEqual(len(queries), 2)\n\n"], "sample_948": ["def test_cpp_enum_nested():\n    check('enum',\n          'enum class {key}Enum {{ A, B, C }};',\n          {1: 'enum-class-TestDoc-42-keyEnum'},\n          output='enum class {key}Enum {{ A, B, C }};',\n          key='My',\n          asTextOutput='enum class MyEnum { A, B, C };')\n"], "sample_615": ["    def test_where_with_different_coords(self, dim):\n        x = xr.DataArray(\n            np.arange(4), dims=[dim], coords={dim: np.arange(4)}\n        )\n        y = xr.DataArray(\n            np.arange(5), dims=[dim], coords={dim: np.arange(5)}\n        )\n        cond = xr.DataArray(\n            [True, False, True, True], dims=[dim], coords={dim: np.arange(4)}\n        )\n        expected = xr.DataArray(\n            [0, 5, 2, 3], dims=[dim], coords={dim: np.arange(4)}\n        )\n        actual = xr.where(cond, x, y)\n        assert_identical(actual, expected)\n"], "sample_191": ["    def test_iter_modules_and_files_zipfile(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_path = Path(tempdir) / 'my_module.zip'\n            with zipfile.ZipFile(zip_path, 'w') as zipf:\n                zipf.writestr('my_module/__init__.py', '')\n            sys.path.append(str(tempdir))\n            self.import_and_cleanup('my_module')\n            self.assertFileFound(zip_path)\n"], "sample_109": ["    def test_required_field_no_placeholder(self):\n        form = RequiredBandForm()\n        self.assertNotIn(self.empty_option, form.as_p())\n"], "sample_942": ["def test_parse_annotation():\n    assert _parse_annotation('int', {}) == [('literal', 'int')]\n    assert _parse_annotation('List[str]', {}) == [('name', 'List'),\n                                                  ('punctuation', '['),\n                                                  ('name', 'str'),\n                                                  ('punctuation', ']')]\n    assert _parse_annotation('Dict[str, int]', {}) == [('name', 'Dict'),\n                                                       ('punctuation', '['),\n                                                       ('name', 'str'),\n                                                       ('punctuation', ','),\n                                                       ('sp', ' '),\n                                                       ('name', 'int'),\n                                                       ('punctuation', ']')]\n    assert _parse_annotation('Optional[Union[str, int]]', {}) == [('name', 'Optional'),\n                                                                 ('punctuation', '['),\n                                                                 ('name', 'Union'),\n                                                                 ('punctuation', '['),\n                                                                 ('name', 'str'),\n                                                                 ('punctuation', ','),\n                                                                 ('sp', ' '),\n                                                                 ('name', 'int'),\n                                                                 ('punctuation', ']'),\n                                                                 ('punctuation', ']')]\n"], "sample_249": ["    def test_test_db_signature(self):\n        connection = get_connection_copy()\n        creation = BaseDatabaseCreation(connection)\n        original_settings = connection.settings_dict.copy()\n        signature = creation.test_db_signature()\n        self.assertEqual(signature[3], TEST_DATABASE_PREFIX + original_settings['NAME'])\n        connection.settings_dict['NAME'] = 'new_name'\n        signature = creation.test_db_signature()\n        self.assertEqual(signature[3], TEST_DATABASE_PREFIX + 'new_name')\n"], "sample_616": ["    def test_polyval_dataset(self, dim):\n        coords = xr.Dataset(\n            {\n                dim: np.arange(5),\n                \"other_dim\": np.arange(3),\n            }\n        )\n        coeffs = xr.Dataset(\n            {\n                \"degree\": np.arange(3),\n                \"other_dim\": np.arange(3),\n            }\n        )\n        coeffs[\"coeffs\"] = np.arange(9).reshape(3, 3)\n        result = xr.polyval(coords[dim], coeffs, degree_dim=\"degree\")\n        assert isinstance(result, xr.Dataset)\n        assert result.dims == (dim, \"other_dim\")\n        assert result.shape == (5, 3)\n\n"], "sample_1001": ["def test_latex_lowergamma():\n    assert latex(lowergamma(x, y)) == '\\\\operatorname{lowergamma}\\\\left(x, y \\\\right)'\n"], "sample_936": ["    def test_stringify_generic_alias_with_broken_args():\n        assert stringify(BrokenType()) == 'BrokenType'\n"], "sample_613": ["def test_groupby_apply_with_empty_groups(dataset):\n    ds = dataset.groupby(\"x\").apply(lambda x: x.where(x[\"foo\"] > 0))\n    assert \"a\" in ds.groups\n    assert \"b\" in ds.groups\n    assert \"c\" in ds.groups\n    assert ds.sel(x=\"a\").isnull().all()\n"], "sample_26": ["    def test_image_hdu_section(self):\n        hdu = fits.ImageHDU(np.arange(100).reshape((10, 10)))\n        section = hdu.section[(1:9, 2:8)]\n        assert_equal(section.shape, (8, 6))\n        assert_equal(section.data, hdu.data[1:9, 2:8])\n"], "sample_440": ["    def test_bulk_create_with_custom_pk(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\"SELECT MAX(id) FROM django_test_country\")\n            max_id = cursor.fetchone()[0]\n\n        BigAutoFieldModel.objects.bulk_create(\n            [BigAutoFieldModel(name=f'Test {i}') for i in range(10)]\n        )\n\n        with connection.cursor() as cursor:\n            cursor.execute(\"SELECT MAX(id) FROM django_test_bigautofieldmodel\")\n            new_max_id = cursor.fetchone()[0]\n\n        self.assertEqual(new_max_id, max_id + 10)\n"], "sample_832": ["    def test_ard_regression_alpha(self):\n        rng = check_random_state(42)\n        n_samples, n_features = 50, 10\n        X = rng.randn(n_samples, n_features)\n        y = rng.randn(n_samples)\n        clf = ARDRegression(alpha_1=1., alpha_2=1.,\n                            lambda_1=1., lambda_2=1.,\n                            compute_score=True)\n        clf.fit(X, y)\n        assert_almost_equal(clf.alpha_, np.mean(clf.scores_),\n                            decimal=2)\n"], "sample_635": ["    def test_param_doc_with_type(self):\n        \"\"\"Test that a parameter with a type in the docstring is correctly identified.\"\"\"\n        node = astroid.parse(\n            \"\"\"\n                '''\n                This function takes a parameter.\n\n                :param param: An integer parameter.\n                :type param: int\n                '''\n                pass\n            \"\"\"\n        ).body[0]\n        with self.assertNoMessages():\n            self.checker.visit_functiondef(node)\n"], "sample_46": ["    def test_uuid_lookup_with_hyphen(self):\n        obj = UUIDModel.objects.create(uuid_field=uuid.UUID('a1b2c3d4-e5f6-7890-1234-567890abcdef'))\n        self.assertEqual(UUIDModel.objects.filter(uuid_field=uuid.UUID('a1b2c3d4-e5f6-7890-1234-567890abcdef')).count(), 1)\n        self.assertEqual(UUIDModel.objects.filter(uuid_field='a1b2c3d4-e5f6-7890-1234-567890abcdef').count(), 1)\n"], "sample_816": ["    def test_tfidf_vectorizer_vocabulary_deprecation(self):\n        tfidf = TfidfVectorizer(vocabulary=['a', 'b', 'c'])\n        with pytest.warns(FutureWarning, match=\"The 'vocabulary' attribute\"):\n            tfidf.fit(ALL_FOOD_DOCS)\n"], "sample_1139": ["def test_complexregion_intersection():\n    a = Interval(0, 1)\n    b = Interval(0, 2*S.Pi)\n    c = Interval(S.Pi/2, 3*S.Pi/2)\n    unit_disk = ComplexRegion(a*b, polar=True)\n    upper_half_unit_disk = ComplexRegion(a*c, polar=True)\n    intersection = unit_disk.intersect(upper_half_unit_disk)\n    assert intersection == ComplexRegion(ProductSet(a, Interval(S.Pi/2, S.Pi)), polar=True)\n"], "sample_770": ["    def test_silhouette_samples_sparse(self):\n        X, y = datasets.make_blobs(n_samples=100, random_state=42)\n        X = csr_matrix(X)\n        silhouette_samples(X, y)\n"], "sample_612": ["    def test_groupby_apply_with_empty_groups(self):\n        ds = self.dataset.isel(x=[0, 1])\n        grouped = ds.groupby(\"x\")\n        result = grouped.apply(lambda x: x.mean(dim=\"y\"))\n        expected = ds.groupby(\"x\").mean(dim=\"y\")\n        assert_identical(result, expected)\n"], "sample_210": ["    def test_view_as_view_initkwargs_invalid_method(self):\n        with self.assertRaises(TypeError):\n            SimpleView.as_view(get='invalid')\n"], "sample_741": ["    def test_randomized_search_cv_refit_multi_metric(self):\n        # Test refit with multiple metrics\n        clf = SVC(gamma=\"scale\")\n        param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n        scoring = {'accuracy': 'accuracy', 'f1': 'f1_macro'}\n        rs = RandomizedSearchCV(clf, param_grid, scoring=scoring, refit='f1',\n                                cv=2, n_iter=2, random_state=0)\n        rs.fit(X, y)\n\n        # Check if refitted estimator is the best one according to 'f1'\n        best_f1 = max(rs.cv_results_['mean_test_f1'])\n        assert_almost_equal(rs.best_score_, best_f1)\n        assert_equal(rs.best_params_['kernel'], 'linear')\n        assert_equal(rs.best_params_['C'], 1)\n\n        # Check if the best estimator is the one with highest 'f1'\n        best_estimator = rs.best_estimator_\n        y_pred = best_estimator.predict(X)\n        assert_almost_equal(f1_score(y, y_pred, average='macro'), best_f1)\n\n"], "sample_594": ["    def test_format_timedelta_timedelta64(self):\n        # GH: 3777\n        t = np.timedelta64(1, \"D\")\n        assert formatting.format_timedelta(t) == \"1 days\"\n        assert formatting.format_timedelta(t, timedelta_format=\"date\") == \"1 days\"\n        assert formatting.format_timedelta(t, timedelta_format=\"time\") == \"00:00:00\"\n"], "sample_1104": ["def test_print_Tr():\n    assert sstr(Tr(Matrix([[1, 2], [3, 4]]))) == 'Tr(Matrix([[1, 2], [3, 4]]))'\n"], "sample_819": ["    def test_voting_regressor_weights_none(self):\n        clf1 = LinearRegression()\n        clf2 = RandomForestRegressor(n_estimators=10, random_state=1)\n        eclf = VotingRegressor([('lr', clf1), ('rf', clf2)])\n        eclf.fit(X_r, y_r)\n        y_pred = eclf.predict(X_r)\n        assert_array_equal(y_pred.shape, y_r.shape)\n"], "sample_505": ["    def test_concise_date_formatter_offset(self, tz):\n        fig, ax = plt.subplots()\n        locator = mdates.AutoDateLocator(tz=tz)\n        formatter = mdates.ConciseDateFormatter(locator, tz=tz,\n                                                show_offset=True)\n        ax.plot([mdates.date2num(datetime.datetime(2023, 1, 1, 12, tzinfo=tz)),\n                 mdates.date2num(datetime.datetime(2023, 1, 2, 12, tzinfo=tz))],\n                [1, 2])\n        ax.xaxis.set_major_locator(locator)\n        ax.xaxis.set_major_formatter(formatter)\n        fig.canvas.draw()\n        labels = [t.get_text() for t in ax.xaxis.get_ticklabels()]\n        if tz is None:\n            assert labels == ['Jan 1', 'Jan 2']\n        else:\n            assert labels == ['Jan 1\\nUTC', 'Jan 2\\nUTC']\n"], "sample_454": ["    def test_exclusion_constraint_include_spgist(self):\n        with atomic():\n            model = UniqueConstraintInclude.objects.create(\n                name='test',\n                value=1,\n            )\n            constraints = get_constraints(UniqueConstraintInclude._meta.db_table)\n            self.assertEqual(len(constraints), 1)\n            constraint = constraints[0]\n            self.assertEqual(constraint['name'], 'unique_constraint_include_name')\n            self.assertEqual(constraint['type'], 'EXCLUDE')\n            self.assertIn('USING spgist', constraint['sql'])\n            self.assertIn('INCLUDE (value)', constraint['sql'])\n"], "sample_727": ["    def test_imputer_sparse_zero_missing_values(self):\n        X = sparse.csr_matrix([[1, 0, 2],\n                               [0, 3, 0],\n                               [4, 0, 6]])\n        X_true = X.copy()\n        missing_values = 0\n        strategy = 'mean'\n        statistics = np.array([2., 3., 4.])\n        _check_statistics(X, X_true, strategy, statistics, missing_values)\n"], "sample_102": ["    def test_union_with_different_select_related(self):\n        qs1 = Number.objects.select_related('other_number').filter(num__gt=5)\n        qs2 = Number.objects.filter(num__lt=5).select_related('other_number')\n        union_qs = qs1.union(qs2)\n        self.assertNumbersEqual(union_qs, [\n            Number(num=6, other_num=4),\n            Number(num=7, other_num=3),\n            Number(num=8, other_num=2),\n            Number(num=9, other_num=1),\n            Number(num=0, other_num=10),\n            Number(num=1, other_num=9),\n            Number(num=2, other_num=8),\n            Number(num=3, other_num=7),\n            Number(num=4, other_num=6),\n        ])\n"], "sample_655": ["    def test_capture_manager_global_and_fixture_disabled(self, tmpdir):\n        cm = CaptureManager()\n        with cm.global_and_fixture_disabled():\n            cm.start_global_capturing()\n            assert cm.is_globally_capturing()\n            cm.suspend_global_capture()\n            assert not cm.is_globally_capturing()\n            cm.resume_global_capture()\n            assert cm.is_globally_capturing()\n            cm.stop_global_capturing()\n            assert not cm.is_globally_capturing()\n"], "sample_344": ["    def test_state_clone(self):\n        state = ProjectState()\n        state.add_model(ModelState.from_model(models.Model))\n        clone = state.clone()\n        self.assertEqual(state.models, clone.models)\n        self.assertIsNot(state.models, clone.models)\n"], "sample_439": ["    def test_form_hidden_fields(self):\n        form = PersonNew({'first_name': 'John', 'last_name': 'Doe'})\n        self.assertEqual(form.as_p(), '<p><label for=\"id_first_name\">First name:</label> <input type=\"text\" name=\"first_name\" value=\"John\" id=\"first_name_id\" required></p>\\n<p><label for=\"id_last_name\">Last name:</label> <input type=\"text\" name=\"last_name\" value=\"Doe\" id=\"id_last_name\" required></p>\\n<p><label for=\"id_birthday\">Birthday:</label> <input type=\"text\" name=\"birthday\" id=\"id_birthday\" required></p>')\n"], "sample_1158": ["def test_sympify_numpy_array():\n    if numpy is None:\n        skip(\"NumPy not installed\")\n    a = numpy.array([1, 2, 3])\n    assert sympify(a) == ImmutableDenseNDimArray([1, 2, 3])\n    a = numpy.array([[1, 2], [3, 4]])\n    assert sympify(a) == ImmutableDenseNDimArray([[1, 2], [3, 4]])\n    a = numpy.array([1.0, 2.0, 3.0])\n    assert sympify(a) == ImmutableDenseNDimArray([1.0, 2.0, 3.0])\n"], "sample_9": ["    def test_multicol_output(self):\n        \"\"\"Test that multicolumn output works correctly.\"\"\"\n        table = Table([[1, 2, 3], [4, 5, 6]], names=['a', 'b', 'c'])\n        table['a'] = Column(table['a'], colspan=2)\n        html_output = html.write(table)\n        soup = BeautifulSoup('\\n'.join(html_output), 'html.parser')\n        rows = soup.find_all('tr')\n        assert len(rows) == 2\n        cells = rows[0].find_all('th')\n        assert len(cells) == 1\n        assert cells[0].text.strip() == 'a'\n        assert cells[0]['colspan'] == '2'\n        cells = rows[1].find_all('td')\n        assert len(cells) == 1\n        assert cells[0].text.strip() == '1 2'\n"], "sample_1": ["    def test_separability_matrix_compound_model_cm11():\n        transform = compound_models['cm11'][0]\n        expected_separable = compound_models['cm11'][1][0]\n        expected_matrix = compound_models['cm11'][1][1]\n        assert_allclose(is_separable(transform), expected_separable)\n        assert_allclose(separability_matrix(transform), expected_matrix)\n"], "sample_584": ["    def test_combine_nested_with_empty_list(self):\n        datasets = []\n        with pytest.raises(ValueError):\n            combine_nested(datasets, concat_dim=['x', 'y'])\n"], "sample_10": ["    def test_set_column_with_mask(self):\n        t = self.t\n        mask = np.array([True, False, True])\n        t['a'] = MaskedColumn(self.a.data, mask=mask)\n        assert np.all(t['a'].mask == mask)\n"], "sample_956": ["    def test_resolve_reference_any_inventory_disabled_reftypes(self, mock_read_from_url, mock_inventory_file):\n        app = self.app\n        set_config(app, {'test': ('https://example.com/inv', 'inv')})\n        mock_read_from_url.return_value = io.BytesIO(inventory_v2.encode())\n        mock_inventory_file.load.return_value = inventory_v2\n\n        app.config.intersphinx_disabled_reftypes = ['std:func']\n        node, contnode = fake_node('std', 'func', 'some_function', 'some_function')\n        result = missing_reference(app, app.env, node, contnode)\n        assert result is None\n\n        node, contnode = fake_node('std', 'class', 'SomeClass', 'SomeClass')\n        result = missing_reference(app, app.env, node, contnode)\n        assert isinstance(result, nodes.reference)\n"], "sample_65": ["    def test_set_language_with_invalid_language_code(self):\n        \"\"\"Test that set_language returns a 404 when given an invalid language code.\"\"\"\n        inactive_language_code = self._get_inactive_language_code()\n        response = self.client.post(\n            reverse('set_language'),\n            {'next': '/', LANGUAGE_QUERY_PARAMETER: inactive_language_code},\n        )\n        self.assertEqual(response.status_code, 404)\n"], "sample_282": ["    def test_partially_required_multivaluefield(self):\n        form = PartiallyRequiredForm({'f_0': 'hello', 'f_1': 'world'})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['f'], 'hello,world')\n\n        form = PartiallyRequiredForm({'f_0': 'hello'})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['f'], 'hello,')\n\n        form = PartiallyRequiredForm({'f_0': 'hello', 'f_1': ''})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['f'], 'hello,')\n\n        form = PartiallyRequiredForm({'f_0': ''})\n        self.assertFalse(form.is_valid())\n        self.assertIn('f', form.errors)\n"], "sample_91": ["    def test_page_not_found_custom_template(self):\n        response = page_not_found(self.request_factory.get('/nonexistent_url/'), Http404('Custom message'))\n        self.assertEqual(response.status_code, 404)\n        self.assertContains(response, 'Custom message')\n        self.assertTemplateUsed(response, 'custom_404.html')\n"], "sample_1035": ["    def test_measure_partial_oneshot_with_condition():\n        q = superposition_basis(3)\n        q = qapply(OracleGate(return_one_on_two, 3)*q)\n        result = measure_partial_oneshot(q, (0, 1))\n        assert result in [IntQubit(2, 3), IntQubit(3, 3)]\n"], "sample_429": ["compilation error"], "sample_0": ["def test_uncertainty_pickle(UncertClass):\n    data = np.array([1, 2, 3])\n    uncert = UncertClass(data)\n    uncert_pickled = pickle.loads(pickle.dumps(uncert))\n    assert_array_equal(uncert.array, uncert_pickled.array)\n"], "sample_1203": ["    def test_homomorphism_kernel():\n        G = DihedralGroup(8)\n        H = CyclicGroup(4)\n        phi = homomorphism(G, H, [G.generators[0]])\n        assert phi.kernel().order() == 4\n"], "sample_288": ["    def test_key_transform_isnull_with_null_key(self):\n        model = JSONModel.objects.create(data={'key': None})\n        self.assertTrue(JSONModel.objects.filter(data__key__isnull=True).exists())\n        self.assertFalse(JSONModel.objects.filter(data__key__isnull=False).exists())\n"], "sample_864": ["    def test_bandwidth_estimation_sparse(self):\n        X_sparse = sparse.csr_matrix(X)\n        bandwidth = estimate_bandwidth(X_sparse, quantile=0.2,\n                                       random_state=0)\n        bandwidth_dense = estimate_bandwidth(X, quantile=0.2,\n                                            random_state=0)\n        assert_almost_equal(bandwidth, bandwidth_dense)\n\n"], "sample_113": ["    def test_replace_named_groups(self):\n        self.assertEqual(utils.replace_named_groups('^(?P<a>\\w+)/b/(\\w+)$'), '^<a>/b/(\\w+)$')\n        self.assertEqual(utils.replace_named_groups('^(?P<a>\\w+)/b/(?P<c>\\w+)/$'), '^<a>/b/<c>/$')\n        self.assertEqual(utils.replace_named_groups('^(?P<a>\\w+)/b/(\\w+)'), '^<a>/b/(\\w+)')\n        self.assertEqual(utils.replace_named_groups('^(?P<a>\\w+)/b/(?P<c>\\w+)'), '^<a>/b/<c>')\n        self.assertEqual(utils.replace_named_groups('^(?P<a>(x|y))/b'), '^<a>/b')\n"], "sample_248": ["    def test_no_startup(self):\n        with captured_stdout() as stdout, captured_stdin() as stdin, mock.patch('os.environ', {'PYTHONSTARTUP': 'print(\"Should not be executed\")'}):\n            call_command('shell', no_startup=True)\n        self.assertNotIn('Should not be executed', stdout.getvalue())\n"], "sample_1050": ["    def test_print_MatrixSymbol(self):\n        A = MatrixSymbol('A', 2, 3)\n        assert pycode(A) == 'A'\n"], "sample_1154": ["    def test_linsolve_complex():\n        eqs = [Eq(x + I*y, 1 + 2*I), Eq(x - I*y, 1 - 2*I)]\n        sol = _linsolve(eqs, [x, y])\n        assert sol == {x: 1, y: 0}\n"], "sample_316": ["    def test_image_file_dimensions(self):\n        if Image is None:\n            return\n\n        with NamedTemporaryFile(suffix='.jpg') as f:\n            f.write(b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x06\\x04\\x05\\x06\\x05\\x04\\x06\\x06\\x05\\x06\\x07\\x07\\x06\\x08\\x0a\\x10\\x0a\\x08\\x0a\\x14\\x12\\x10\\x0a\\x0c\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\xff\\xdb\\x00C\\x01\\x06\\x04\\x05\\x06\\x05\\x04\\x06\\x06\\x05\\x06\\x07\\x07\\x06\\x08\\x0a\\x10\\x0a\\x08\\x0a\\x14\\x12\\x10\\x0a\\x0c\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0a\\x0"], "sample_275": ["    def test_delete_locking(self):\n        with transaction.atomic():\n            p1 = Person.objects.create(name='Person 1')\n            p2 = Person.objects.create(name='Person 2')\n            p1.related_people.add(p2)\n\n        with self.conn2.cursor() as cursor:\n            cursor.execute(\"SELECT id FROM delete_regress_person WHERE name = 'Person 1'\")\n            p1_id = cursor.fetchone()[0]\n\n        with transaction.atomic():\n            Person.objects.filter(id=p1_id).delete()\n\n        with self.conn2.cursor() as cursor:\n            cursor.execute(\"SELECT COUNT(*) FROM delete_regress_person\")\n            self.assertEqual(cursor.fetchone()[0], 1)\n"], "sample_683": ["    def test_capture_manager_suspend_resume(self, tmpdir):\n        capman = CaptureManager(\"sys\")\n        capman.start_global_capturing()\n        print(\"hello\")\n        capman.suspend_global_capture()\n        print(\"world\")\n        capman.resume_global_capture()\n        print(\"!\")\n        out, err = capman.read_global_capture()\n        assert out == \"hello\\n!\\n\"\n        assert err == \"\"\n"], "sample_1094": ["def test_basic_eq():\n    assert b1 != b2\n    assert b2 == b2\n    assert b2 == b21\n    assert b1 != b3\n    assert b2 != b3\n"], "sample_623": ["    def test_to_netcdf_invalid_netcdf(self) -> None:\n        ds = xr.Dataset({\"foo\": (\"x\", [1, 2, 3])})\n        with pytest.raises(ValueError, match=\"unrecognized option 'invalid_netcdf'\"):\n            ds.to_netcdf(\n                \"test.nc\",\n                engine=\"scipy\",\n                invalid_netcdf=True,\n            )\n"], "sample_66": ["    def test_get_full_path_info_with_trailing_slash(self):\n        request = HttpRequest()\n        request.path_info = '/path/'\n        self.assertEqual(request.get_full_path_info(), '/path/')\n        self.assertEqual(request.get_full_path_info(force_append_slash=True), '/path/')\n"], "sample_336": ["compilation error"], "sample_199": ["    def test_when_with_subquery(self):\n        qs = Book.objects.annotate(\n            is_popular=Case(\n                When(\n                    Exists(Book.objects.filter(authors=OuterRef('authors'), rating__gte=4.5)),\n                    then=True,\n                ),\n                default=False,\n                output_field=BooleanField(),\n            )\n        )\n        self.assertQuerysetEqual(\n            qs.filter(is_popular=True),\n            [\n                'The Definitive Guide to Django: Web Development Done Right',\n                'Practical Django Projects',\n                'Artificial Intelligence: A Modern Approach',\n            ],\n            transform=lambda b: b.name,\n        )\n"], "sample_141": ["    def test_serialize_decimal_field(self):\n        score = Score.objects.create(value=decimal.Decimal('12.34'))\n        serialized = serializers.serialize('json', [score])\n        deserialized = json.loads(serialized)\n        self.assertEqual(deserialized[0]['fields']['value'], '12.34')\n"], "sample_1117": ["    def test_AskDiagonalHandler_DiagonalMatrix(self):\n        x = Symbol('x')\n        diag = DiagonalMatrix(x, x)\n        assert ask(Q.diagonal(diag)) is True\n"], "sample_553": ["def test_grab_frame_kwargs(anim):\n    writer = NullMovieWriter()\n    anim.save('test.mp4', writer=writer)\n    assert writer._count == anim.frames\n    assert writer.savefig_kwargs == {}\n"], "sample_994": ["def test_catalan():\n    assert Catalan.is_positive is True\n    assert Catalan.is_irrational is None\n    assert Catalan > 0\n    assert Catalan < 1\n    assert Catalan.approximation_interval(Rational) == (Rational(9, 10), S.One)\n"], "sample_897": ["    def test_partial_dependence_categorical_features(\n        clf_diabetes, diabetes"], "sample_610": ["compilation error"], "sample_963": ["    def test_restify_invalid_builtin_classes():\n        assert restify(Struct) == ':py:class:`struct.Struct`'\n        assert restify(TracebackType) == ':py:class:`types.TracebackType`'\n"], "sample_761": ["    def test_missing_indicator_sparse_csr(self):\n        X = sparse.csr_matrix([[1, 2, np.nan],\n                              [4, np.nan, 6],\n                              [np.nan, 8, 10]])\n        indicator = MissingIndicator(sparse='auto')\n        Xt = indicator.fit_transform(X)\n        assert_allclose_dense_sparse(Xt,\n                                     np.array([[False, False, True],\n                                               [False, True, False],\n                                               [True, False, False]]))\n\n        indicator = MissingIndicator(sparse=True)\n        Xt = indicator.fit_transform(X)\n        assert isinstance(Xt, sparse.csc_matrix)\n        assert_allclose_dense_sparse(Xt,\n                                     np.array([[False, False, True],\n                                               [False, True, False],\n                                               [True, False, False]]))\n\n"], "sample_1087": ["    def test_interpolating_poly():\n        x = symbols('x')\n        Y = symbols('Y0:5')\n        X = symbols('X0:5')\n        p = interpolating_poly(5, x, X, Y)\n        assert isinstance(p, Poly)\n        assert p.subs({x: X[0]}) == Y[0]\n        assert p.subs({x: X[1]}) == Y[1]\n        assert p.subs({x: X[2]}) == Y[2]\n        assert p.subs({x: X[3]}) == Y[3]\n        assert p.subs({x: X[4]}) == Y[4]\n"], "sample_650": ["    def test_log_level_setting_from_ini(self, pytester: Pytester) -> None:\n        pytester.makeini(\n            \"\"\"\n            [pytest]\n            log_level = WARNING\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        assert result.ret == 0\n        assert result.stdout.lines == [\n            \"*log_level* set to WARNING\",\n        ]\n\n"], "sample_1135": ["def test_as_ordered_factors():\n    assert (2*x*y*sin(x)*cos(x)).as_ordered_factors() == [2, x, y, sin(x), cos(x)]\n    assert (x*y*sin(x)*cos(x)).as_ordered_factors() == [x, y, sin(x), cos(x)]\n    assert (sin(x)*cos(x)*x*y).as_ordered_factors() == [sin(x), cos(x), x, y]\n    assert (sin(x)*cos(x)*x*y).as_ordered_factors(order='lex') == [cos(x), sin(x), x, y]\n"], "sample_895": ["    def test_column_transformer_sparse_output(self):\n        X = np.array([[1, 2], [3, 4], [5, 6]])\n        sparse_X = sparse.csr_matrix(X)\n\n        ct = ColumnTransformer(\n            transformers=[\n                (\"num\", StandardScaler(), [0]),\n                (\"cat\", OneHotEncoder(), [1]),\n            ],\n            sparse_threshold=0.8,\n        )\n\n        # Check that sparse output is produced\n        Xt = ct.fit_transform(sparse_X)\n        assert isinstance(Xt, sparse.csr_matrix)\n\n        # Check that dense output is produced when sparse_threshold is 0\n        ct.sparse_threshold = 0\n        Xt = ct.fit_transform(sparse_X)\n        assert isinstance(Xt, np.ndarray)\n"], "sample_731": ["    def test_fetch_california_housing(self):\n        # Test that the data is loaded correctly\n        data = fetch_california_housing()\n        assert data.data.shape == (20640, 8)\n        assert data.target.shape == (20640,)\n        assert len(data.feature_names) == 8\n        assert isinstance(data.DESCR, str)\n\n        # Test that the data is loaded correctly with return_X_y=True\n        X, y = fetch_california_housing(return_X_y=True)\n        assert X.shape == (20640, 8)\n        assert y.shape == (20640,)\n\n        # Test that the data is loaded correctly with a specific data_home\n        data_home = 'test_data_home'\n        data = fetch_california_housing(data_home=data_home)\n        assert data.data.shape == (20640, 8)\n        assert data.target.shape == (20640,)\n        assert len(data.feature_names) == 8\n        assert isinstance(data.DESCR, str)\n\n"], "sample_928": ["    def test_textwidth(self):\n        assert textwidth('hello') == 5\n        assert textwidth('hello world') == 11\n        assert textwidth('hello\\nworld') == 11\n        assert textwidth('\u4f60\u597d') == 4\n        assert textwidth('\u4f60\u597d\u4e16\u754c') == 6\n        assert textwidth('!@#$%^&*()') == 10\n"], "sample_261": ["    def test_parse_datetime_with_timezone(self):\n        dt_str = '2023-10-27T12:34:56+02:00'\n        dt = parse_datetime(dt_str)\n        self.assertEqual(dt.year, 2023)\n        self.assertEqual(dt.month, 10)\n        self.assertEqual(dt.day, 27)\n        self.assertEqual(dt.hour, 12)\n        self.assertEqual(dt.minute, 34)\n        self.assertEqual(dt.second, 56)\n        self.assertEqual(dt.tzinfo.utcoffset(dt).total_seconds(), 7200)\n"], "sample_914": ["compilation error"], "sample_882": ["    def test_mlp_classifier_partial_fit(dataset, request):\n        X, y = dataset\n        mlp = MLPClassifier(\n            hidden_layer_sizes=(10,),\n            max_iter=10,\n            solver=\"sgd\",\n            random_state=42,\n            learning_rate=\"constant\",\n            learning_rate_init=0.001,\n            warm_start=True,\n        )\n\n        # First fit\n        mlp.fit(X[:100], y[:100])\n        score1 = mlp.score(X[100:], y[100:])\n\n        # Second fit\n        mlp.partial_fit(X[100:], y[100:])\n        score2 = mlp.score(X[100:], y[100:])\n\n        assert score2 >= score1\n\n"], "sample_75": ["    def test_prefetch_related_with_select_related(self):\n        with CaptureQueriesContext(connection) as queries:\n            prefetch_related_objects(\n                Reader.objects.all().select_related('favorite_authors'),\n                Prefetch('favorite_authors__books', to_attr='favorite_books'),\n            )\n        self.assertEqual(len(queries.captured_queries), 3)\n        self.assertWhereContains(queries.captured_queries[1], 'reader_id')\n        self.assertWhereContains(queries.captured_queries[2], 'author_id')\n"], "sample_486": ["    def test_inlineformset_factory_with_uuid_pk_parent(self):\n        ChildFormSet = inlineformset_factory(\n            UUIDPKParent, UUIDPKChild, fields=[\"name\", \"description\"]\n        )\n        parent = UUIDPKParent.objects.create(name=\"Parent 1\")\n        formset = ChildFormSet(instance=parent)\n        self.assertEqual(formset.forms[0].instance.parent, parent)\n"], "sample_838": ["    def test_remainder_sparse_output(self):\n        X = np.array([[0, 1], [2, 3]])\n        ct = ColumnTransformer(\n            transformers=[('num', StandardScaler(), [0]),\n                          ('cat', OneHotEncoder(), [1])],\n            remainder='passthrough', sparse_threshold=0.5)\n        Xt = ct.fit_transform(X)\n        assert sparse.issparse(Xt)\n        assert_allclose_dense_sparse(Xt.toarray(),\n                                     np.array([[ -1.22474487,  0.,  0.,  2.],\n                                               [ 1.22474487,  1.,  0.,  3.]]))\n\n"], "sample_21": ["def test_read_qdp_with_comments():\n    data = \"\"\""], "sample_307": ["    def test_format_timezone_aware_datetime(self):\n        dt = make_aware(datetime(2023, 10, 26, 10, 30, 0), get_fixed_timezone(utc))\n        self.assertEqual(format(dt, 'e'), '+0000')\n        self.assertEqual(format(dt, 'O'), '+0000')\n        self.assertEqual(format(dt, 'P'), '10:30 a.m.')\n        self.assertEqual(format(dt, 'T'), 'UTC')\n"], "sample_732": ["    def test_subset_SF(self):\n        data = fetch_kddcup99(subset='SF', percent10=True)\n        assert_equal(data.data.shape, (69969, 4))\n        assert_equal(data.target.shape, (69969,))\n"], "sample_562": ["    def test_marker_paths(self, marker, expected_path):\n        style = MarkerStyle(marker)\n        assert style.path.vertices.shape == expected_path.vertices.shape\n        assert_array_equal(style.path.vertices, expected_path.vertices)\n"], "sample_243": ["    def test_join_promotion_complex_or(self):\n        # Test join promotion for complex OR conditions.\n        query = Query(model=Author, using='default')\n        query.add_filter(Q(books__title__icontains='Django') | Q(books__title__icontains='Python'))\n        query.add_filter(Q(name__startswith='A'))\n        join_promoter = JoinPromoter(OR, 2, False)\n        join_promoter.add_votes(['books'])\n        join_promoter.add_votes(['books'])\n        to_demote = join_promoter.update_join_types(query)\n        self.assertEqual(to_demote, {'books'})\n\n"], "sample_1015": ["    def test_ccode_complex(self):\n        from sympy import I\n        expr = (1 + 2*I) * (3 - I)\n        expected = '((1 + 2*I) * (3 - I))'\n        self.assertEqual(ccode(expr), expected)\n\n"], "sample_1067": ["def test_expand_2arg():\n    x, y = symbols('x y')\n    assert expand_2arg(2*(x + y)) == 2*x + 2*y\n    assert expand_2arg(2*(x + y + 1)) == 2*x + 2*y + 2\n    assert expand_2arg(x*(y + 1)) == x*y + x\n    assert expand_2arg(2*x*(y + 1)) == 2*x*y + 2*x\n    assert expand_2arg((x + 1)*y) == x*y + y\n    assert expand_2arg(2*(x + 1)*y) == 2*x*y + 2*y\n"], "sample_999": ["def test_latex_SingularityFunction():\n    assert latex(SingularityFunction(x, 0, 1)) == '\\\\text{SingularityFunction}(x, 0, 1)'\n"], "sample_557": ["    def test_figure_savefig_bbox_inches_tight(self):\n        fig, ax = plt.subplots()\n        ax.plot([0, 1], [0, 1])\n        ax.set_xlabel('X Label')\n        ax.set_ylabel('Y Label')\n\n        # Save the figure with bbox_inches='tight'\n        with io.BytesIO() as buf:\n            fig.savefig(buf, format='png', bbox_inches='tight')\n            buf.seek(0)\n            img = Image.open(buf)\n\n        # Check if the image size is smaller than the default figure size\n        assert img.size[0] < mpl.rcParams['figure.figsize'][0] * fig.dpi\n        assert img.size[1] < mpl.rcParams['figure.figsize'][1] * fig.dpi\n"], "sample_343": ["    def test_generic_relation_ordering(self):\n        post1 = Post.objects.create(title='Post 1')\n        post2 = Post.objects.create(title='Post 2')\n        question1 = Question.objects.create(content='Question 1', post=post1)\n        question2 = Question.objects.create(content='Question 2', post=post2)\n        answer1 = Answer.objects.create(question=question1, text='Answer 1')\n        answer2 = Answer.objects.create(question=question2, text='Answer 2')\n\n        # Test ordering by related field\n        self.assertEqual(\n            list(post1.answers.order_by('question__content')),\n            [answer1],\n        )\n        self.assertEqual(\n            list(post2.answers.order_by('question__content')),\n            [answer2],\n        )\n\n        # Test ordering by related field with reverse relation\n        self.assertEqual(\n            list(question1.answers.order_by('post__title')),\n            [answer1],\n        )\n        self.assertEqual(\n            list(question2.answers.order_by('post__title')),\n            [answer2],\n        )\n"], "sample_14": ["    def test_longitude_wrap_angle_setter():\n        lon = Longitude('180d')\n        assert lon.wrap_angle == Angle('360d')\n        lon.wrap_angle = Angle('180d')\n        assert lon.wrap_angle == Angle('180d')\n        assert_allclose(lon.degree, 180)\n"], "sample_183": ["    def test_case_when_with_subquery(self):\n        qs = CaseTestModel.objects.annotate(\n            case_when=Case(\n                When(integer2__gt=F('integer'), then=Value('greater')),\n                When(integer2__lt=F('integer'), then=Value('less')),\n                default=Value('equal'),\n                output_field=CharField(),\n            ),\n        )\n        self.assertQuerysetEqual(\n            qs.filter(case_when='greater'),\n            [\n                CaseTestModel.objects.get(integer=1, integer2=3, string='1'),\n                CaseTestModel.objects.get(integer=2, integer2=3, string='2'),\n                CaseTestModel.objects.get(integer=3, integer2=4, string='3'),\n                CaseTestModel.objects.get(integer=3, integer2=4, string='3'),\n                CaseTestModel.objects.get(integer=3, integer2=3, string='3'),\n            ],\n        )\n"], "sample_1100": ["def test_Pow_as_content_primitive():\n    assert (2**(x + 1)).as_content_primitive() == (2, 2**x)\n    assert (2**(x + 1/2)).as_content_primitive() == (1, 2**(x + 1/2))\n    assert (2**(1/2 + x)).as_content_primitive() == (1, 2**(1/2 + x))\n    assert (2**(1/2 + 1/2)).as_content_primitive() == (2**(1/2), 2**(1/2))\n    assert (2**(1/2 + 1/2*x)).as_content_primitive() == (1, 2**(1/2 + 1/2*x))\n    assert (2**(1/2*x + 1/2)).as_content_primitive() == (1, 2**(1/2*x + 1/2))\n    assert (2**(1/2*x + 1/2*y)).as_content_primitive() == (1, 2**(1/2*x + 1/2*y))\n"], "sample_260": ["    def test_alter_unique_together_empty_to_non_empty(self):\n        before = [\n            migrations.CreateModel(\n                name='UnicodeModel',\n                fields=[\n                    ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                    ('name', models.CharField(max_length=100)),\n                ],\n                options={'unique_together': set()},\n            ),\n        ]\n        after = [\n            migrations.CreateModel(\n                name='UnicodeModel',\n                fields=[\n                    ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                    ('name', models.CharField(max_length=100)),\n                ],\n                options={'unique_together': {('name',)},},\n            ),\n        ]\n        self.assertOptimizesTo(\n            operations.Operations(before, after),\n            [\n                operations.AlterModelOptions(\n                    name='UnicodeModel',\n                    options={'unique_together': {('name',)}},\n                ),\n            ],\n        )\n"], "sample_1033": ["def test_as_content_primitive_radical():\n    from sympy import sqrt\n    assert (2*sqrt(2) + 4*sqrt(10)).as_content_primitive(radical=True) == (2, sqrt(2)*(1 + 2*sqrt(5)))\n"], "sample_28": ["    def test_card_fix_value(self):\n        card = fits.Card.fromstring(\"KEY   = 'This is a test string' / This is a comment\")\n        card._fix_value()\n        assert card.value == \"'This is a test string'\"\n        assert card.comment == \" / This is a comment\"\n\n        card = fits.Card.fromstring(\"KEY   = 12345678901234567890 / This is a comment\")\n        card._fix_value()\n        assert card.value == \"12345678901234567890\"\n        assert card.comment == \" / This is a comment\"\n\n        card = fits.Card.fromstring(\"KEY   = 123.45678901234567890 / This is a comment\")\n        card._fix_value()\n        assert card.value == \"123.45678901234567890\"\n        assert card.comment == \" / This is a comment\"\n\n        card = fits.Card.fromstring(\"KEY   = (1.23, 4.56) / This is a comment\")\n        card._fix_value()\n        assert card.value == \"(1.23, 4.56)\"\n        assert card.comment == \" / This is a comment\"\n\n"], "sample_374": ["    def test_prefetch_related_with_select_related_and_m2m(self):\n        with CaptureQueriesContext(connection) as queries:\n            prefetch_related_objects(\n                [self.reader1],\n                'books_read__authors',\n            )\n        self.assertEqual(len(queries), 3)\n        self.assertWhereContains(queries[0]['sql'], 'reader.name')\n        self.assertWhereContains(queries[1]['sql'], 'book.title')\n        self.assertWhereContains(queries[2]['sql'], 'author.name')\n"], "sample_501": ["    def test_legend_bbox_to_anchor(self, loc, expected_bbox):\n        fig, ax = plt.subplots()\n        ax.plot([1, 2, 3], [4, 5, 6])\n        legend = ax.legend(loc=loc)\n        if expected_bbox is None:\n            assert legend.get_bbox_to_anchor() is None\n        else:\n            assert legend.get_bbox_to_anchor().bounds == expected_bbox\n\n"], "sample_45": ["    def test_extract_iso_year(self):\n        dt = datetime(2023, 12, 31, tzinfo=timezone.utc)\n        self.create_model(dt, dt + timedelta(days=1))\n        self.assertEqual(\n            DTModel.objects.filter(start_datetime__iso_year=2023).count(),\n            1,\n        )\n        self.assertEqual(\n            DTModel.objects.filter(start_datetime__iso_year=2024).count(),\n            0,\n        )\n"], "sample_1118": ["    def test_MatPow_derivative_matrix_lines():\n        x = symbols('x')\n        A = MatrixSymbol('A', 2, 2)\n        p = MatPow(A, 2)\n        res = p._eval_derivative_matrix_lines(x)\n        assert res[0]._lines[0].args[0].args[0] == Identity(1)\n        assert res[0]._lines[0].args[0].args[1] == 2*A\n        assert res[0]._lines[0].args[0].args[2] == A**(2-1)\n"], "sample_1047": ["def test_issue_10183():\n    x = Symbol('x', real=True)\n    assert (x**2).is_real is True\n    assert (x**2).is_positive is None\n    assert (x**2).is_negative is None\n"], "sample_608": ["    def test_diff_array_repr(self, compat):\n        a = xr.DataArray(np.arange(4), dims=[\"x\"])\n        b = xr.DataArray(np.arange(4) + 1, dims=[\"x\"])\n        expected = dedent(\n            f\"\"\"\n            Left and right DataArray objects are not {compat.__name__}\n            Differing values:\n            L\n                <xarray.DataArray (x: 4)>\n                array([0, 1, 2, 3])\n            R\n                <xarray.DataArray (x: 4)>\n                array([1, 2, 3, 4])\n            \"\"\"\n        )\n        assert formatting.diff_array_repr(a, b, compat) == expected\n\n"], "sample_990": ["def test_acsch_rewrite():\n    x = Symbol('x')\n    assert acsch(x)._eval_rewrite_as_log() == log(1/x + sqrt(1/x**2 + 1))\n"], "sample_504": ["    def test_colorbar_extendfrac_auto(self):\n        # Test that 'auto' extendfrac behaves as expected for different\n        # spacing types.\n        cmap, norms = _get_cmap_norms()\n        fig, axes = plt.subplots(2, 2)\n        for i, extend in enumerate(('neither', 'min', 'max', 'both')):\n            norm = norms[extend]\n            boundaries = values = norm.boundaries\n            values = values[:-1]\n            ax = axes.flat[i]\n            Colorbar(ax, cmap=cmap, norm=norm,\n                     boundaries=boundaries, values=values,\n                     extend=extend, extendfrac='auto',\n                     orientation='vertical')\n            ax.tick_params(left=False, labelleft=False,\n                           bottom=False, labelbottom=False)\n        fig.tight_layout()\n        # We don't have a good way to directly compare the extendfrac\n        # lengths, so we'll just visually inspect the output.\n"], "sample_549": ["    def test_delete_masked_points_empty(self):\n        x = np.array([])\n        y = np.array([])\n        mask = np.array([], dtype=bool)\n        x_new, y_new = delete_masked_points(x, y, mask)\n        assert_array_equal(x_new, x)\n        assert_array_equal(y_new, y)\n"], "sample_44": ["    def test_function_unit_creation_with_physical_unit(self):\n        for lu_unit, pu in itertools.product(lu_units, pu_sample):\n            with pytest.raises(ValueError):\n                lu_unit(physical_unit=pu)\n"], "sample_490": ["    def test_unique_constraint_with_expressions_and_condition(self):\n        with atomic():\n            UniqueConstraintConditionProduct.objects.create(name=\"Product A\", price=10)\n            with self.assertRaises(IntegrityError):\n                UniqueConstraintConditionProduct.objects.create(\n                    name=\"Product B\", price=10, condition=True\n                )\n            with self.assertRaises(IntegrityError):\n                UniqueConstraintConditionProduct.objects.create(\n                    name=\"Product A\", price=10, condition=True\n                )\n            UniqueConstraintConditionProduct.objects.create(\n                name=\"Product C\", price=20, condition=True\n            )\n"], "sample_457": ["    def test_unique_constraint_with_expressions_and_condition(self):\n        with atomic():\n            UniqueConstraintProduct.objects.create(name=\"Product A\", price=10.0)\n            with self.assertRaises(ValidationError):\n                UniqueConstraintProduct.objects.create(\n                    name=\"Product A\", price=20.0, condition=True\n                )\n            with self.assertRaises(ValidationError):\n                UniqueConstraintProduct.objects.create(\n                    name=\"Product B\", price=10.0, condition=True\n                )\n"], "sample_735": ["    def test_gaussian_mixture_precisions_cholesky(self):\n        # Test that the precisions_cholesky_ attribute is correctly computed\n        # for different covariance types.\n        for covariance_type in COVARIANCE_TYPE:\n            gm = GaussianMixture(n_components=self.n_components,\n                                covariance_type=covariance_type,\n                                random_state=0).fit(self.X[covariance_type])\n            if covariance_type == 'full':\n                for k in range(self.n_components):\n                    assert_allclose(\n                        np.dot(gm.precisions_cholesky_[k],\n                               gm.precisions_cholesky_[k].T),\n                        gm.covariances_[k] ** -1)\n            elif covariance_type == 'tied':\n                assert_allclose(\n                    np.dot(gm.precisions_cholesky_, gm.precisions_cholesky_.T),\n                    gm.covariances_['tied'] ** -1)\n            else:\n                assert_allclose(\n                    gm.precisions_cholesky_ ** 2, gm.covariances_[covariance_type])\n"], "sample_966": ["def test_parse_annotation():\n    assert _parse_annotation('int') == ('int', None)\n    assert _parse_annotation('List[str]') == ('List', 'str')\n    assert _parse_annotation('Dict[str, int]') == ('Dict', ('str', 'int'))\n    assert _parse_annotation('Tuple[int, ...]') == ('Tuple', ('int', Ellipsis))\n    assert _parse_annotation('Callable[[int, str], float]') == ('Callable',\n                                                                ([('int', 'str')], 'float'))\n    assert _parse_annotation('Union[int, str]') == ('Union', ('int', 'str'))\n    assert _parse_annotation('Optional[str]') == ('Optional', ('str',))\n"], "sample_603": ["def test_summarize_variable_multiindex(multiindex):\n    expected_preview = \"(level_1, level_2)\"\n    actual = fh.summarize_variable(\"x\", multiindex[\"x\"], is_index=True)\n    assert expected_preview in actual\n"], "sample_1054": ["def test_complexregion_intersection():\n    a = Interval(2, 3)\n    b = Interval(4, 6)\n    c = Interval(1, 8)\n    c1 = ComplexRegion(a*b)\n    c2 = ComplexRegion(Union(a*b, b*c))\n    c3 = ComplexRegion(Interval(2, 4)*Interval(4, 6))\n    assert c1.intersect(c3) == c3\n    assert c2.intersect(c3) == c3\n    assert c1.intersect(c2) == c1\n"], "sample_550": ["    def test_get_tightbbox_for_layout_only(self):\n        fig, ax = plt.subplots()\n        ax.set_xlabel('X Label')\n        ax.set_ylabel('Y Label')\n        ax.set_title('Title')\n\n        # Test with for_layout_only=True\n        bbox = ax.get_tightbbox(for_layout_only=True)\n        assert bbox.width < ax.get_tightbbox().width\n        assert bbox.height < ax.get_tightbbox().height\n\n        # Test with for_layout_only=False (default)\n        bbox = ax.get_tightbbox(for_layout_only=False)\n        assert bbox.width == ax.get_tightbbox().width\n        assert bbox.height == ax.get_tightbbox().height\n"], "sample_940": ["    def test_is_builtin_class_method(self):\n        assert inspect.is_builtin_class_method(int, '__init__')\n        assert not inspect.is_builtin_class_method(str, '__init__')\n        assert not inspect.is_builtin_class_method(datetime.datetime, 'now')\n"], "sample_16": ["    def test_shape(self):\n        self.check(np.shape, self.q)\n"], "sample_1209": ["    def test_prefix_unit():\n        from sympy.physics.units import meter\n        prefixed_units = prefix_unit(meter, PREFIXES)\n        assert len(prefixed_units) == len(PREFIXES)\n        assert prefixed_units[0].name == 'yottameter'\n        assert prefixed_units[-1].name == 'yoctometer'\n"], "sample_1082": ["def test_acsch_rewrite():\n    x = Symbol('x')\n    assert acsch(x)._eval_rewrite_as_log(x) == log(1/x + sqrt(1/x**2 + 1))\n"], "sample_337": ["    def test_csrf_token_length_validation(self):\n        with override_settings(CSRF_TOKEN_LENGTH=32):\n            token = get_token(HttpRequest())\n            self.assertEqual(len(token), 32)\n"], "sample_63": ["    def test_render_to_string_with_context(self):\n        template = self.engine.from_string('Hello {{ name }}!')\n        context = Context({'name': 'world'})\n        self.assertEqual(template.render(context), 'Hello world!')\n"], "sample_436": ["    def test_runserver_ipv6(self):\n        self.write_settings(\"settings.py\")\n        os.environ[\"DJANGO_SETTINGS_MODULE\"] = \"test_project.settings\"\n        with captured_stdout() as stdout, captured_stderr() as stderr:\n            try:\n                call_command(\"runserver\", \"--ipv6\", \"--nothreading\", addrport=\"::1:8001\")\n            except SystemExit:\n                pass\n        self.assertIn(\"Starting development server at http://[::1]:8001/\", stdout.getvalue())\n        self.assertNotIn(\"Error:\", stderr.getvalue())\n"], "sample_469": ["    def test_annotate_with_subquery(self):\n        # Test annotating with a subquery that references the outer query.\n        subquery = Book.objects.filter(\n            authors__in=OuterRef(\"authors\")\n        ).values(\"isbn\").annotate(Count(\"isbn\"))\n        result = (\n            Author.objects.annotate(\n                num_books=Subquery(subquery.values(\"isbn__count\")[:1])\n            )\n            .filter(num_books__gt=1)\n            .values(\"name\", \"num_books\")\n        )\n        self.assertQuerysetEqual(\n            result,\n            [\n                {\"name\": \"Adrian Holovaty\", \"num_books\": 2},\n                {\"name\": \"Jacob Kaplan-Moss\", \"num_books\": 2},\n                {\"name\": \"Brad Dayley\", \"num_books\": 1},\n                {\"name\": \"James Bennett\", \"num_books\": 2},\n                {\"name\": \"Jeffrey Forcier\", \"num_books\": 3},\n                {\"name\": \"Paul Bissex\", \"num_books\": 2},\n                {\"name\": \"Wesley J. Chun\", \"num_books\": 3},\n            ],\n        )\n"], "sample_1062": ["    def test_TR12i():\n        assert TR12i(sin(x)**2 + cos(x)**2) == S(1)\n        assert TR12i(sin(x)**2 + cos(x)**2 + sin(y)**2) == sin(y)**2 + S(1)\n        assert TR12i(sin(x)**2 + cos(x)**2 + sin(y)**2 + cos(y)**2) == S(2)\n"], "sample_572": ["    def test_kde_univariate_cumulative(self, x, rng):\n        kde = KDE(cumulative=True)\n        density, support = kde(x)\n        assert_array_almost_equal(density, [self.integrate(density, support[:i+1]) for i in range(len(support))])\n"], "sample_809": ["    def test_mutual_info_classif_sparse_input():\n        rng = check_random_state(0)\n        X = csr_matrix(rng.rand(10, 5))\n        y = rng.randint(0, 2, size=10)\n        mi = mutual_info_classif(X, y)\n        assert_equal(mi.shape, (5,))\n        assert_greater(np.sum(mi), 0)\n"], "sample_394": ["    def test_add_view_with_readonly_field(self):\n        response = self.client.get(reverse('admin:admin_views_article_add'))\n        self.assertEqual(response.status_code, 200)\n        readonly_field = self.get_admin_readonly_field(response, 'section')\n        self.assertIsNotNone(readonly_field)\n        self.assertEqual(readonly_field.field['value'], self.s1.pk)\n"], "sample_124": ["    def test_form_initial_data(self):\n        data = {'first_name': 'John', 'last_name': 'Doe', 'birthday': '2000-01-01'}\n        form = Person(data)\n        self.assertEqual(form.initial['first_name'], 'John')\n        self.assertEqual(form.initial['last_name'], 'Doe')\n        self.assertEqual(form.initial['birthday'], datetime.date(2000, 1, 1))\n\n"], "sample_541": ["def test_polygon_selector_draw_box(ax):\n        pass\n\n    selector = widgets.PolygonSelector(ax, onselect, draw_bounding_box=True)\n    selector._xys = [(0, 0), (1, 0), (1, 1), (0, 1), (0, 0)]\n    selector._selection_completed = True\n    selector._draw_polygon()\n    assert isinstance(selector._box, widgets.RectangleSelector)\n"], "sample_1020": ["    def test_mcode_Derivative():\n        assert mcode(Derivative(sin(x), x)) == 'Hold[D[Sin[x], x]]'\n        assert mcode(Derivative(sin(x), x, 2)) == 'Hold[D[Sin[x], {x, 2}]]'\n        assert mcode(Derivative(f(x), x)) == 'Hold[D[f[x], x]]'\n"], "sample_1191": ["    def test_hermite_normal_form_modulo_D_raises_DMShapeError():\n        A = DomainMatrix([[ZZ(1), ZZ(2)], [ZZ(3), ZZ(4)]], (2, 2), ZZ)\n        D = ZZ(10)\n        raises(DMShapeError, lambda: _hermite_normal_form_modulo_D(A, D))\n"], "sample_1029": ["compilation error"], "sample_151": ["    def test_rename_field_with_default(self):\n        before_state = self.make_project_state([\n            self.author_name_default,\n        ])\n        after_state = self.make_project_state([\n            self.author_name_default_renamed,\n        ])\n        changes = self.get_changes(before_state.models, after_state.models)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['RenameField'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name', old_name='name_old')\n\n"], "sample_493": ["    def test_annotate_count_distinct(self):\n        qs = Book.objects.annotate(\n            author_count=Count(\"authors\", distinct=True)\n        ).filter(author_count__gt=1)\n        self.assertQuerysetEqual(qs, [\n            \"Artificial Intelligence: A Modern Approach\",\n            \"Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp\",\n            \"Python Web Development with Django\",\n            \"The Definitive Guide to Django: Web Development Done Right\",\n        ], lambda b: b.name)\n"], "sample_1145": ["    def test_refine_sign_complex():\n        x = Symbol('x', complex=True)\n        assert refine(sign(x), Q.positive(re(x)) & Q.zero(im(x))) == 1\n        assert refine(sign(x), Q.negative(re(x)) & Q.zero(im(x))) == -1\n        assert refine(sign(x), Q.zero(re(x)) & Q.positive(im(x))) == I\n        assert refine(sign(x), Q.zero(re(x)) & Q.negative(im(x))) == -I\n"], "sample_917": ["def test_function_template_id():\n    check(\"function\", \"void foo(int a, T b)\", {\n        1: \"foo\",\n        2: \"foo_a_T\",\n        3: \"foo_int_T\",\n    })\n"], "sample_185": ["    def test_get_format_modules_reverse(self):\n        with patch_formats('de', DATE_FORMAT='Y-m-d'):\n            modules = get_format_modules('de', reverse=True)\n            self.assertEqual(modules[0].DATE_FORMAT, 'Y-m-d')\n"], "sample_290": ["    def test_rename_field_with_default(self):\n        before_state = self.make_project_state([\n            self.author_name_default,\n        ])\n        after_state = self.make_project_state([\n            self.author_name_default_renamed,\n        ])\n        changes = self.get_changes(before_state.models, after_state.models)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['RenameField'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name', old_name='name_old')\n\n"], "sample_414": ["    def test_formfield_for_dbfield_uuidfield(self):\n        ff = self.assertFormfield(\n            Company, \"uuid\", forms.CharField,\n        )\n        self.assertEqual(ff.widget.attrs.get(\"type\"), \"text\")\n"], "sample_973": ["    def test_stringify_signature_unqualified_typehints(self):\n                 *args: 'module.AnotherClass',\n                 **kwargs: 'module.YetAnotherClass'):\n            pass\n\n        sig = inspect.signature(func)\n        result = inspect.stringify_signature(sig, unqualified_typehints=True)\n        assert result == '(a: Class, b: OtherClass, c: int = 10, *args: AnotherClass, **kwargs: YetAnotherClass)'\n"], "sample_427": ["    def test_formset_factory_absolute_max(self):\n        formset_class = formset_factory(\n            Choice,\n            max_num=5,\n            absolute_max=3,\n        )\n        formset = formset_class(data={\n            \"choices-TOTAL_FORMS\": \"4\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-0-choice\": \"Choice 1\",\n            \"choices-0-votes\": \"1\",\n            \"choices-1-choice\": \"Choice 2\",\n            \"choices-1-votes\": \"2\",\n            \"choices-2-choice\": \"Choice 3\",\n            \"choices-2-votes\": \"3\",\n            \"choices-3-choice\": \"Choice 4\",\n            \"choices-3-votes\": \"4\",\n        })\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(formset.errors, [\n            [{'choice': ['This field is required.']}],\n            [{'votes': ['This field is required.']}],\n            [{'choice': ['This field is required.']}],\n            [{'votes': ['This field is required.']}],\n        ])\n        self.assertEqual(formset.total_form_count(), 3)\n"], "sample_916": ["def test_function_template():\n    check('function', 'void foo(int a, T b)', {1: 'foo'}, 'void foo(int a, T b)')\n"], "sample_898": ["    def test_label_ranking_average_precision_score_empty_labels(self):\n        y_true = np.zeros((5, 3))\n        y_score = np.zeros((5, 3))\n        score = label_ranking_average_precision_score(y_true, y_score)\n        assert_equal(score, 0.0)\n"], "sample_247": ["    def test_annotate_with_subquery(self):\n        # Test annotating with a subquery that uses the outer query's alias.\n        subquery = Book.objects.filter(authors__in=OuterRef('authors')).values('id')\n        qs = Author.objects.annotate(\n            books_by_friends=Subquery(subquery)\n        ).filter(books_by_friends__isnull=False)\n        self.assertQuerysetEqual(\n            qs,\n            [\n                'Adrian Holovaty',\n                'Jacob Kaplan-Moss',\n                'Brad Dayley',\n                'James Bennett',\n                'Jeffrey Forcier',\n                'Paul Bissex',\n                'Wesley J. Chun',\n            ],\n            transform=lambda a: a.name,\n        )\n"], "sample_1122": ["def test_polar_lift_evalf():\n    x = Symbol('x')\n    assert polar_lift(x).evalf() == x.evalf()\n    assert polar_lift(2).evalf() == 2\n    assert polar_lift(2*I).evalf() == 2*I\n    assert polar_lift(2 + 2*I).evalf() == (2 + 2*I).evalf()\n"], "sample_1192": ["def test_disambiguate_with_mapping():\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z')\n    exprs = [x + y, x + z]\n    mapping = {str(x): Symbol('a'), str(y): Symbol('b'), str(z): Symbol('c')}\n    result = disambiguate(*exprs)\n    assert result == (a + b, a + c)\n"], "sample_540": ["    def test_null_writer(self):\n        fig, ax = plt.subplots()\n        line, = ax.plot([], [])\n        ax.set_xlim(0, 10)\n        ax.set_ylim(-1, 1)\n\n            line.set_data([], [])\n            return line,\n\n            x = np.linspace(0, 10, 100)\n            y = np.sin(x + i)\n            line.set_data(x, y)\n            return line,\n\n        writer = NullMovieWriter()\n        ani = animation.FuncAnimation(fig, animate, init_func=init,\n                                      frames=5, blit=False,\n                                      writer=writer)\n        ani.save('test.mp4')\n        assert writer.outfile == 'test.mp4'\n        assert writer._count == 5\n"], "sample_1081": ["    def test_is_deficient(self):\n        assert is_deficient(15)\n        assert not is_deficient(20)\n        assert is_deficient(12)\n"], "sample_1004": ["def test_conditionset_subs_dummy_symbol():\n    c = ConditionSet(x, x < 1, {x, z})\n    assert c.subs(x, y) == ConditionSet(x, x < 1, {y, z})\n    assert c.subs(x, y).subs(x, y) == ConditionSet(y, y < 1, {y, z})\n    assert ConditionSet(y, y < 1, {y, z}).subs(y, 1) == ConditionSet(y, y < 1, {z})\n    assert ConditionSet(y, y < 1, {y, z}).subs(y, 1).subs(y, 1) == ConditionSet(y, y < 1, {z})\n"], "sample_991": ["def test_product_empty_product():\n    assert product(1, (k, n, n - 1)) == 1\n"], "sample_529": ["    def test_legend_bbox_to_anchor(self, loc, expected_bbox):\n        fig, ax = plt.subplots()\n        ax.plot([1, 2, 3], [4, 5, 6])\n        legend = ax.legend(loc=loc)\n        assert_allclose(legend.get_bbox_to_anchor().bounds, expected_bbox)\n"], "sample_333": ["    def test_form_as_p(self):\n        person = PersonNew({'first_name': 'John', 'last_name': 'Doe', 'birthday': '2000-01-01'})\n        rendered_form = person.as_p()\n        self.assertIn('<p', rendered_form)\n        self.assertIn('</p>', rendered_form)\n        self.assertIn('John', rendered_form)\n        self.assertIn('Doe', rendered_form)\n        self.assertIn('2000-01-01', rendered_form)\n"], "sample_181": ["    def test_filtered_aggregate_with_subquery(self):\n        # Test an aggregate with a subquery filter.\n        subquery = Book.objects.filter(contact__name='test').values('publisher').annotate(\n            avg_price=Avg('price')\n        )\n        result = Publisher.objects.annotate(\n            avg_price_for_test_books=Subquery(subquery.values('avg_price')[:1])\n        ).get(pk=self.p1.pk)\n        self.assertEqual(result.avg_price_for_test_books, Approximate(Decimal('30.00')))\n"], "sample_1198": ["def test_parse_mathematica_function_with_arguments():\n    parser = MathematicaParser()\n    expr = parser.parse(\"Sin[x]\")\n    assert expr == sin(x)\n\n    expr = parser.parse(\"Sin[x + y]\")\n    assert expr == sin(x + y)\n\n    expr = parser.parse(\"f[x, y]\")\n    assert expr == Function('f')(x, y)\n\n    expr = parser.parse(\"f[x, y + z]\")\n    assert expr == Function('f')(x, y + z)\n"], "sample_281": ["    def test_permission_denied_for_missing_search_fields(self):\n        with model_admin(Answer, AnswerAdmin, admin_site=site):\n            AnswerAdmin.get_search_fields = lambda *args: []\n            request = self.factory.get(self.url, {\n                'app_label': self.opts['app_label'],\n                'model_name': self.opts['model_name'],\n                'field_name': self.opts['field_name'],\n                'term': 'foo',\n            })\n            request.user = self.user\n            with self.assertRaises(Http404):\n                AutocompleteJsonView.as_view(**self.as_view_args)(request)\n"], "sample_206": ["    def test_filefield_save_form_data_with_empty_string(self):\n        doc = Document.objects.create(file='')\n        self.assertEqual(doc.file, '')\n"], "sample_340": ["    def test_migrations_module_custom(self):\n        \"\"\"\n        Tests loading migrations from a custom MIGRATION_MODULES setting.\n        \"\"\"\n        loader = MigrationLoader(connection)\n        loader.build_graph()\n        self.assertEqual(\n            loader.disk_migrations.keys(),\n            {('testapp', '0001_initial'), ('testapp', '0002_custom_migration')},\n        )\n"], "sample_308": ["    def test_format_timezone_aware_datetime(self):\n        dt = make_aware(datetime(2023, 10, 26, 10, 30, 0), get_fixed_timezone(utc))\n        self.assertEqual(format(dt, 'e'), '+0000')\n        self.assertEqual(format(dt, 'O'), '+0000')\n        self.assertEqual(format(dt, 'P'), '10:30 a.m.')\n        self.assertEqual(format(dt, 'T'), 'UTC')\n"], "sample_143": ["    def test_camel_case_to_spaces(self):\n        self.assertEqual(text.camel_case_to_spaces('someCamelCaseString'), 'some camel case string')\n        self.assertEqual(text.camel_case_to_spaces('SomeCamelCaseString'), 'some camel case string')\n        self.assertEqual(text.camel_case_to_spaces('SomeCamelCaseStringWithNumbers123'), 'some camel case string with numbers 123')\n"], "sample_128": ["    def test_index_creation_with_condition(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\"DROP INDEX IF EXISTS test_article_published_index\")\n        model = Article\n        index = Index(fields=['published'], condition=Q(title__startswith='Django'))\n        index.create_sql(model, connection.schema_editor())\n        with connection.cursor() as cursor:\n            cursor.execute(\"SELECT sql FROM sqlite_master WHERE type='index' AND name='test_article_published_index'\")\n            row = cursor.fetchone()\n            self.assertIsNotNone(row)\n            self.assertIn(\"WHERE title LIKE 'Django%'\", row[0])\n\n"], "sample_477": ["    def test_random(self):\n        self.assertHTMLEqual(\n            self.render({\"a\": [1, 2, 3], \"b\": [\"a\", \"b\", \"c\"]}),\n            \"random01\",\n            \"1 a\",\n        )\n"], "sample_93": ["    def test_aggregate_with_filter(self):\n        with CaptureQueriesContext(connection) as queries:\n            # Test Avg() with a filter\n            avg_age = Author.objects.filter(name__startswith='J').aggregate(Avg('age'))\n            self.assertEqual(avg_age['age__avg'], 36.0)\n            self.assertEqual(len(queries), 1)\n\n            # Test Sum() with a filter\n            total_pages = Book.objects.filter(rating__gt=4).aggregate(Sum('pages'))\n            self.assertEqual(total_pages['pages__sum'], 1482)\n            self.assertEqual(len(queries), 2)\n\n            # Test Count() with a filter\n            num_books = Book.objects.filter(publisher__name='Apress').aggregate(Count('isbn'))\n            self.assertEqual(num_books['isbn__count'], 2)\n            self.assertEqual(len(queries), 3)\n"], "sample_1023": ["    def test_cycle_length_values():\n        func = lambda i: (i**2 + 1) % 51\n        n = cycle_length(func, 4, values=True)\n        assert list(n) == [17, 35, 2, 5, 26, 14, 44, 50, 2, 5, 26, 14]\n"], "sample_355": ["    def test_get_user_permissions_with_backend(self):\n        with self.settings(AUTH_USER_MODEL='auth_tests.test_auth_backends.CustomUser'):\n            user = CustomUser.objects.create_user('test', 'test@example.com', 'test')\n            self.assertEqual(\n                list(self.user.get_user_permissions()),\n                ['user_perm']\n            )\n"], "sample_434": ["    def test_view_is_async(self):\n        class AsyncView(View):\n            async def get(self, request):\n                return HttpResponse()\n\n        class SyncView(View):\n                return HttpResponse()\n\n        self.assertTrue(AsyncView.view_is_async)\n        self.assertFalse(SyncView.view_is_async)\n\n        with self.assertRaises(ImproperlyConfigured):\n            class MixedView(View):\n                async def get(self, request):\n                    return HttpResponse()\n\n                    return HttpResponse()\n"], "sample_791": ["    def test_onehot_inverse_transform_unknown_categories(self):\n        enc = OneHotEncoder(handle_unknown='ignore')\n        X = [['Male', 1], ['Female', 3], ['Female', 2]]\n        enc.fit(X)\n        X_trans = enc.transform(X)\n        X_inv = enc.inverse_transform(X_trans)\n        assert_equal(X_inv, np.array([['Male', 1], ['Female', 3], ['Female', 2]],\n                                     dtype=object))\n"], "sample_575": ["    def test_label_concise(self, x):\n        a, locs = self.setup_labels(x, concise=True)\n        formatter = a.major.formatter\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n        # TODO: more specific test about the output format?\n"], "sample_961": ["def test_parse_annotation():\n    assert _parse_annotation('int') == ('int', None)\n    assert _parse_annotation('str, int') == ('Tuple[str, int]', None)\n    assert _parse_annotation('List[str]') == ('List[str]', None)\n    assert _parse_annotation('Dict[str, int]') == ('Dict[str, int]', None)\n    assert _parse_annotation('Optional[int]') == ('Optional[int]', None)\n    assert _parse_annotation('Union[str, int]') == ('Union[str, int]', None)\n    assert _parse_annotation('Callable[[int], str]') == ('Callable[[int], str]', None)\n    assert _parse_annotation('Any') == ('Any', None)\n    assert _parse_annotation('None') == ('None', None)\n    assert _parse_annotation('...') == ('...', None)\n"], "sample_317": ["    def test_rss201rev2_feed(self):\n        feed = Rss201rev2Feed(\n            title=\"My Blog\",\n            link=\"http://example.com/blog/\",\n            description=\"A blog about nothing.\",\n        )\n        feed.add_item(\n            title=\"My first post\",\n            link=\"http://example.com/blog/post1/\",\n            description=\"This is my first post.\",\n            pubdate=self.e1.published,\n        )\n        feed.add_item(\n            title=\"My second post\",\n            link=\"http://example.com/blog/post2/\",\n            description=\"This is my second post.\",\n            pubdate=self.e2.published,\n        )\n\n        xml = feed.writeString('utf-8')\n        dom = minidom.parseString(xml)\n\n        self.assertEqual(dom.documentElement.tagName, 'rss')\n        self.assertEqual(dom.documentElement.getAttribute('version'), '2.0')\n\n        channel = dom.getElementsByTagName('channel')[0]\n        self.assertChildNodeContent(channel, {\n            'title': 'My Blog',\n            'link': 'http://example.com/blog/',\n            'description': 'A blog about nothing.',\n        })\n        self.assertChildNodes(channel, ['title', 'link', 'description', 'item', 'item'])\n\n        items = channel.getElementsByTagName('item')\n        self.assertEqual(len(items), 2)\n\n        self.assertChildNodeContent(items[0], {\n            'title': 'My first post',\n            'link': 'http://example.com/blog/post1/',\n            'description': 'This is my first post.',\n        })\n        self.assertEqual(items[0].getElementsByTagName('pubDate')[0].firstChild.wholeText,\n                         rfc2822_date(self.e1.published))\n\n        self.assertChildNodeContent(items[1], {\n            'title': 'My second post',\n            'link': 'http://example.com/blog/post2/',\n            'description': 'This is my second post.',\n        })\n        self.assertEqual(items[1].getElementsByTagName('pubDate')[0"], "sample_466": ["    def test_operation_writer_handles_settings_reference(self):\n        class MyOperation(migrations.Operation):\n                super().__init__()\n                self.setting_name = setting_name\n\n                return (\n                    \"%s.%s\" % (self.__class__.__module__, self.__class__.__name__),\n                    [self.setting_name],\n                    {},\n                )\n\n        operation = MyOperation(\"MY_SETTING\")\n        writer = OperationWriter(operation)\n        serialized, _ = writer.serialize()\n        self.assertIn(\"settings.MY_SETTING\", serialized)\n"], "sample_1012": ["    def test_print_SparseMatrix(self):\n        m = SparseMatrix([[1, 0, 0], [0, 2, 0], [0, 0, 3]])\n        code = NumPyPrinter().doprint(m)\n        assert code == 'scipy.sparse.coo_matrix([1, 2, 3], ([0, 1, 2], [0, 1, 2]), shape=(3, 3))'\n\n"], "sample_952": ["    def test_stringify_signature_with_forwardref(self):\n        class MyClass:\n                pass\n\n            class InnerClass:\n                pass\n\n        sig = inspect.signature(MyClass.my_method)\n        sig = inspect.evaluate_signature(sig, globalns={'MyClass': MyClass})\n        result = inspect.stringify_signature(sig)\n        assert result == '(arg1: MyClass.InnerClass, arg2: MyClass.InnerClass = None)'\n"], "sample_555": ["    def test_fancyarrowpatch_mutation_scale(self):\n        fig, ax = plt.subplots()\n        arrow = FancyArrowPatch((0, 0), (1, 1), arrowstyle='->',\n                               mutation_scale=20)\n        ax.add_patch(arrow)\n        fig.canvas.draw()\n        # Check that the arrowhead size is scaled correctly\n        arrow_head_size = arrow.get_path().vertices[-4:]\n        assert_almost_equal(np.max(np.abs(arrow_head_size)), 20)\n"], "sample_7": ["    def test_masked_column_insert(self):\n        col = table.MaskedColumn([1, 2, 3], name='a', dtype=int)\n        col.mask = [False, True, False]\n\n        # Insert at beginning\n        new_col = col.insert(0, [0], mask=[False])\n        assert_array_equal(new_col.data, [0, 1, 2, 3])\n        assert_array_equal(new_col.mask, [False, True, False, False])\n\n        # Insert in middle\n        new_col = col.insert(1, [4, 5], mask=[False, True])\n        assert_array_equal(new_col.data, [1, 4, 5, 2, 3])\n        assert_array_equal(new_col.mask, [False, False, True, True, False])\n\n        # Insert at end\n        new_col = col.insert(3, [6], mask=[False])\n        assert_array_equal(new_col.data, [1, 2, 3, 6])\n        assert_array_equal(new_col.mask, [False, True, False, False])\n\n        # Test with string column\n        col = table.MaskedColumn(['a', 'b', 'c'], name='a', dtype='S1')\n        col.mask = [False, True, False]\n        new_col = col.insert(1, ['d', 'e'], mask=[False, True])\n        assert_array_equal(new_col.data, ['a', 'd', 'e', 'b', 'c'])\n        assert_array_equal(new_col.mask, [False, False, True, True, False])\n"], "sample_1097": ["def test_blockcut():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (1, 3))\n    assert isinstance(B, BlockMatrix)\n    assert ImmutableMatrix(B.blocks[0, 1]) == ImmutableMatrix([[1, 2, 3]])\n"], "sample_170": ["    def test_callable_setting_wrapper(self):\n        wrapped_callable = CallableSettingWrapper(lambda: 'test')\n        self.assertEqual(repr(wrapped_callable), '<function <lambda> at 0x...> wrapped')\n"], "sample_266": ["    def test_migrations_module_custom(self):\n        \"\"\"\n        Test loading migrations from a custom migrations module.\n        \"\"\"\n        # Create a custom migrations module\n        with open(os.path.join(self.migration_dir, 'testapp', 'migrations_custom.py'), 'w') as f:\n            f.write('from django.db import migrations\\n')\n            f.write('MIGRATION_1 = migrations.Migration(\\n')\n            f.write(\"    'initial',\\n\")\n            f.write(\"    dependencies=[],\\n\")\n            f.write(\"    operations=[],\\n\")\n            f.write(\")\\n\")\n        compileall.compiledir(self.migration_dir)\n\n        # Load the migrations\n        loader = MigrationLoader(connection)\n        loader.build_graph()\n\n        # Check if the migration is loaded\n        self.assertIn(('testapp', '0001_initial'), loader.disk_migrations)\n\n        # Clean up the custom migrations module\n        os.remove(os.path.join(self.migration_dir, 'testapp', 'migrations_custom.py'))\n"], "sample_1151": ["    def test_mod_noncommutative():\n        raises(TypeError, lambda: Mod(x, y*z))\n"], "sample_126": ["    def test_rename_field_with_default(self):\n        before_state = self.make_project_state([\n            self.author_name,\n        ])\n        after_state = self.make_project_state([\n            self.author_name_renamed,\n        ])\n        changes = self.get_changes(before_state.models, after_state.models)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['RenameField'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name', old_name='name', field_type='CharField')\n\n"], "sample_1157": ["def test_convert_xor():\n    assert parse_expr('x^2', transformations=(convert_xor,)) == x**2\n    assert parse_expr('2^3', transformations=(convert_xor,)) == 2**3\n    assert parse_expr('x^y', transformations=(convert_xor,)) == x**y\n    assert parse_expr('2^y', transformations=(convert_xor,)) == 2**y\n"], "sample_1074": ["    def test_is_polycyclic(self):\n        G = SymmetricGroup(4)\n        assert G.is_polycyclic\n        G = DihedralGroup(8)\n        assert G.is_polycyclic\n        G = AbelianGroup(5)\n        assert G.is_polycyclic\n        G = PermutationGroup([Permutation([0, 1, 2]), Permutation([0, 2, 1])])\n        assert G.is_polycyclic\n        G = PermutationGroup([Permutation([0, 1, 2, 3]), Permutation([1, 3, 0, 2])])\n        assert not G.is_polycyclic\n"], "sample_561": ["    def test_marker_paths(self, marker, expected_path):\n        style = markers.MarkerStyle(marker)\n        assert style._path.vertices.shape == expected_path.vertices.shape\n        assert np.allclose(style._path.vertices, expected_path.vertices)\n"], "sample_311": ["    def test_changelist_filter_by_related_field(self):\n        response = self.client.get(reverse('admin:books_book_changelist'))\n        self.assertContains(response, 'Promo 1')\n        self.assertContains(response, 'Promo 2')\n\n        response = self.client.get(reverse('admin:books_book_changelist') + '?promo__name=Promo%201')\n        self.assertContains(response, 'Book 1')\n        self.assertNotContains(response, 'Book 2')\n"], "sample_1039": ["def test_print_MatrixSymbol():\n    m = MatrixSymbol('A', 2, 3)\n    assert mathml(m) == '<ci>A</ci>'\n    assert mathml(m, printer='presentation') == '<mi>A</mi>'\n\n"], "sample_364": ["    def test_include_with_namespace_and_app_name(self):\n        with self.assertRaises(ImproperlyConfigured):\n            resolve('/namespaced-base64/world/')\n"], "sample_669": ["    def test_capture_manager_tee_sys(self, tmpdir):\n        config = pytest.Config(tmpdir)\n        capman = capture.CaptureManager(\"tee-sys\")\n        config.pluginmanager.register(capman, \"capturemanager\")\n\n        with capman.global_and_fixture_disabled():\n            out, err = capman.read_global_capture()\n            assert out == \"\"\n            assert err == \"\"\n\n        with capture.TeeStdCapture() as cap:\n            print(\"hello\", file=sys.stdout)\n            print(\"world\", file=sys.stderr)\n            assert cap.out == \"hello\\n\"\n            assert cap.err == \"world\\n\"\n\n        out, err = capman.read_global_capture()\n        assert out == \"hello\\n\"\n        assert err == \"world\\n\"\n"], "sample_471": ["    def test_integer_field_with_min_value(self):\n        field = IntegerField(min_value=10)\n        self.assertFieldValidationPasses(field, 10)\n        self.assertFieldValidationPasses(field, 11)\n        with self.assertRaises(ValidationError):\n            field.clean(9)\n"], "sample_233": ["    def test_token_expiration(self):\n        user = User.objects.create_user(username='testuser', password='password')\n        generator = MockedPasswordResetTokenGenerator(now=datetime.now())\n        token = generator.make_token(user)\n        # Advance time past the expiration limit\n        generator._now_val = generator._now_val + timedelta(seconds=settings.PASSWORD_RESET_TIMEOUT + 1)\n        self.assertFalse(generator.check_token(user, token))\n"], "sample_532": ["    def test_corner_mask(self):\n        x = np.arange(-5, 5, 0.25)\n        y = np.arange(-5, 5, 0.25)\n        X, Y = np.meshgrid(x, y)\n        Z = np.sin(np.sqrt(X**2 + Y**2))\n        # Create a masked array with a masked corner\n        Z = np.ma.masked_where(np.logical_and(X > 2, Y > 2), Z)\n        fig, ax = plt.subplots()\n        cs = ax.contourf(X, Y, Z, corner_mask=True)\n        plt.colorbar(cs)\n\n"], "sample_533": ["def test_contour_corner_mask():\n    x = np.arange(-5, 5, 0.25)\n    y = np.arange(-5, 5, 0.25)\n    X, Y = np.meshgrid(x, y)\n    Z = np.sin(np.sqrt(X**2 + Y**2))\n    # Create a masked array with a masked corner\n    Z = np.ma.masked_where(X * Y < -10, Z)\n    fig, ax = plt.subplots()\n    cs = ax.contourf(X, Y, Z, corner_mask=True)\n    plt.colorbar(cs)\n\n"], "sample_1037": ["def test_issue_18626():\n    X = MatrixSymbol('X', 2, 2)\n    Y = MatrixSymbol('Y', 2, 2)\n    Z = MatrixSymbol('Z', 2, 2)\n    expr = MatMul(X, Y, Z)\n    assert expr.doit() == MatMul(X, Y, Z)\n"], "sample_885": ["    def test_interval_constraint(self, interval_type, closed):\n        interval = Interval(interval_type, 0, 10, closed=closed)\n        assert interval.is_satisfied_by(5)\n        assert not interval.is_satisfied_by(-1)\n        assert not interval.is_satisfied_by(11)\n        if interval_type is Integral:\n            assert not interval.is_satisfied_by(5.5)\n        if closed in (\"left\", \"both\"):\n            assert interval.is_satisfied_by(0)\n        if closed in (\"right\", \"both\"):\n            assert interval.is_satisfied_by(10)\n        if closed == \"neither\":\n            assert not interval.is_satisfied_by(0)\n            assert not interval.is_satisfied_by(10)\n"], "sample_502": ["    def test_plot_date_format():\n        fig, ax = plt.subplots()\n        dates = np.arange('2023-01-01', '2023-01-10', dtype='datetime64[D]')\n        values = np.arange(10)\n        ax.plot_date(dates, values, fmt='o-')\n        ax.xaxis.set_major_formatter(mpl.dates.DateFormatter('%Y-%m-%d'))\n        fig.savefig('test_plot_date_format.png')\n        # Check if the plot looks correct\n        subprocess.run(['compare', '-metric', 'AE', 'test_plot_date_format.png', 'expected_plot_date_format.png'], stdout=subprocess.PIPE)\n        assert subprocess.run(['compare', '-metric', 'AE', 'test_plot_date_format.png', 'expected_plot_date_format.png'], stdout=subprocess.PIPE).returncode == 0\n\n"], "sample_965": ["    def test_signature_from_ast_with_posonlyargs(self):\n        code = 'def func(a, b, /, c, d=42): pass'\n        module = ast.parse(code)\n        function = cast(ast.FunctionDef, module.body[0])  # type: ignore\n        sig = inspect.signature_from_ast(function, code)\n        assert str(sig) == '(a, b, /, c, d=42)'\n"], "sample_1174": ["def test_polarify_subs():\n    x, y = symbols('x y')\n    expr = x*y\n    p_expr, subs = polarify(expr, subs=True)\n    assert p_expr == _x*_y\n    assert subs == {_x: x, _y: y}\n"], "sample_175": ["    def test_cascade_delete_with_m2m_through_model(self):\n        a = create_a()\n        m2m_from = M2MFrom.objects.create(a=a)\n        m2m_to1 = M2MTo.objects.create()\n        m2m_to2 = M2MTo.objects.create()\n        m2m_from.m2m_tos.add(m2m_to1, m2m_to2)\n        with transaction.atomic():\n            a.delete()\n        self.assertFalse(M2MFrom.objects.exists())\n        self.assertFalse(M2MTo.objects.filter(pk=m2m_to1.pk).exists())\n        self.assertFalse(M2MTo.objects.filter(pk=m2m_to2.pk).exists())\n"], "sample_708": ["    def test_getstatementrange_ast_empty_lines():\n        source = Source(\n            \"\"\""], "sample_488": ["    def test_get_swappable_settings_name(self):\n        with override_settings(INSTALLED_APPS=SOME_INSTALLED_APPS):\n            apps.populate(SOME_INSTALLED_APPS)\n            self.assertEqual(apps.get_swappable_settings_name(\"auth.user\"), \"AUTH_USER_MODEL\")\n            self.assertEqual(apps.get_swappable_settings_name(\"django.contrib.auth.models.user\"), \"AUTH_USER_MODEL\")\n            self.assertIsNone(apps.get_swappable_settings_name(\"nonexistent.model\"))\n            self.assertIsNone(apps.get_swappable_settings_name(\"apps.apps.totallynormal\"))\n"], "sample_84": ["    def test_urlencode_multivaluedict(self):\n        data = MultiValueDict({'key1': ['value1', 'value2'], 'key2': 'value3'})\n        self.assertEqual(urlencode(data), 'key1=value1&key1=value2&key2=value3')\n"], "sample_651": ["    def test_deprecated_call_with_match(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import warnings\n\n                warnings.warn('use v3 of this api', DeprecationWarning)\n                return 200\n\n                assert api_call_v2() == 200\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.assert_outcomes(passed=1)\n        assert result.stdout.lines == [\n            \"============================= test session starts ==============================\",\n            \"platform ...\",\n            \"rootdir: ...\",\n            \"collected 1 item\",\n            \"test_api_call.py .                                                      [100%]\",\n            \"============================== 1 passed in ... ===============================\",\n        ]\n\n"], "sample_62": ["    def test_register_model_twice(self):\n        with self.assertRaises(AlreadyRegistered):\n            self.site.register(Location)\n            self.site.register(Location)\n"], "sample_946": ["def test_parse_annotation():\n    assert _parse_annotation('int') == ('int', None)\n    assert _parse_annotation('list[str]') == ('list', 'str')\n    assert _parse_annotation('dict[str, int]') == ('dict', ('str', 'int'))\n    assert _parse_annotation('Tuple[int, ...]') == ('Tuple', ('int', Ellipsis))\n    assert _parse_annotation('Callable[[int], str]') == ('Callable', '[[int], str]')\n    assert _parse_annotation('Optional[str]') == ('Optional', 'str')\n    assert _parse_annotation('Union[int, str]') == ('Union', ('int', 'str'))\n\n"], "sample_750": ["    def test_omp_gram_precomputed_norms(self):\n        # Test orthogonal_mp_gram with precomputed norms\n        rng = check_random_state(0)\n        X = rng.randn(n_samples, n_features)\n        y = rng.randn(n_samples, n_targets)\n        G, Xy = np.dot(X.T, X), np.dot(X.T, y)\n        norms_squared = np.sum(y ** 2, axis=0)\n        coef = orthogonal_mp_gram(G, Xy, n_nonzero_coefs=n_nonzero_coefs,\n                                  tol=None, norms_squared=norms_squared,\n                                  copy_Gram=False, copy_Xy=False)\n        coef_ = orthogonal_mp(X, y, n_nonzero_coefs=n_nonzero_coefs,\n                              tol=None, precompute=False, copy_X=False)\n        assert_array_almost_equal(coef, coef_)\n"], "sample_1091": ["    def test_relational_evalf():\n        assert (x > 2).evalf(subs={x: 3}) == True\n        assert (x > 2).evalf(subs={x: 1}) == False\n        assert (x > 2).evalf(subs={x: 2}) == False\n        assert (Eq(x, 2)).evalf(subs={x: 2.0}) == True\n        assert (Eq(x, 2)).evalf(subs={x: 2.1}) == False\n"], "sample_239": ["    def test_formset_factory_absolute_max(self):\n        formset_class = formset_factory(FavoriteDrinkForm, max_num=5, absolute_max=3)\n        formset = formset_class(data={'form-0-name': 'Coke', 'form-1-name': 'Pepsi', 'form-2-name': 'Sprite'})\n        self.assertTrue(formset.is_valid())\n        self.assertEqual(len(formset.cleaned_data), 3)\n\n        formset = formset_class(data={'form-0-name': 'Coke', 'form-1-name': 'Pepsi', 'form-2-name': 'Sprite', 'form-3-name': 'Dr Pepper'})\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(formset.errors, [{'name': ['Please submit at most 3 forms.']}])\n"], "sample_1071": ["    def test_convert_to_mixed_units():\n        x = 10*kilometer + 500*meter\n        assert convert_to(x, [meter]) == 10500*meter\n        assert convert_to(x, [mile]) == 6.21371192237334*mile\n"], "sample_408": ["    def test_rename_field_with_default(self):\n        before = self.make_project_state(\n            [\n                self.author_with_name,\n            ]\n        )\n        after = self.make_project_state(\n            [\n                self.author_with_name_renamed_field,\n            ]\n        )\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, \"testapp\", 1)\n        self.assertOperationTypes(changes, \"testapp\", 0, [\"RenameField\"])\n        self.assertOperationAttributes(\n            changes, \"testapp\", 0, 0, name=\"name\", old_name=\"name\"\n        )\n\n"], "sample_359": ["    def test_add_index_with_expressions(self):\n        with atomic(using=self.database):\n            with CaptureQueriesContext(connection) as queries:\n                with self.assertRaises(IntegrityError):\n                    self.create_model(\n                        'UnicodeModel',\n                        [\n                            ('name', models.CharField(max_length=100)),\n                            ('value', models.IntegerField()),\n                        ],\n                        options={'indexes': [models.Index(fields=['name'], name='test_index_name')]},\n                    )\n                self.assertEqual(len(queries.captured_queries), 1)\n\n"], "sample_244": ["    def test_formset_factory_absolute_max(self):\n        formset_class = formset_factory(Choice, max_num=2, absolute_max=3)\n        formset = formset_class(data={'choices-0-choice': 'a', 'choices-0-votes': '1',\n                                     'choices-1-choice': 'b', 'choices-1-votes': '2',\n                                     'choices-TOTAL_FORMS': '3',\n                                     'choices-INITIAL_FORMS': '0',\n                                     'choices-MAX_NUM_FORMS': '2',\n                                     'choices-MIN_NUM_FORMS': '0'})\n        self.assertTrue(formset.is_valid())\n        self.assertEqual(formset.total_form_count(), 3)\n\n        formset = formset_class(data={'choices-0-choice': 'a', 'choices-0-votes': '1',\n                                     'choices-1-choice': 'b', 'choices-1-votes': '2',\n                                     'choices-2-choice': 'c', 'choices-2-votes': '3',\n                                     'choices-TOTAL_FORMS': '4',\n                                     'choices-INITIAL_FORMS': '0',\n                                     'choices-MAX_NUM_FORMS': '2',\n                                     'choices-MIN_NUM_FORMS': '0'})\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(formset.errors, [{'TOTAL_FORMS': [ValidationError('Please submit at most 3 forms.', code='too_many_forms')]}])\n"], "sample_1143": ["def test_sympify_Tuple():\n    assert sympify(Tuple((1, 2, 3))) == Tuple((1, 2, 3))\n    assert sympify((1, 2, 3)) == Tuple((1, 2, 3))\n"], "sample_6": ["    def test_longitude_wrap_angle_setter():\n        lon = Longitude(10 * u.deg)\n        assert lon.wrap_angle == Angle(360 * u.deg)\n        lon.wrap_angle = 180 * u.deg\n        assert lon.wrap_angle == Angle(180 * u.deg)\n        assert lon.value == 10\n        lon = Longitude(370 * u.deg)\n        assert lon.value == 10\n        lon.wrap_angle = 180 * u.deg\n        assert lon.value == -10\n"], "sample_1025": ["    def test_numpy_piecewise(self):\n        p = Piecewise((x, x < 0), (y, x >= 0))\n        code = NumPyPrinter().doprint(p)\n        assert code == 'numpy.select([x < 0], [x, y], default=numpy.nan)'\n"], "sample_68": ["    def test_callable_setting_wrapper_repr(self):\n        class MySetting:\n                return 'MySetting()'\n\n        wrapper = CallableSettingWrapper(MySetting())\n        self.assertEqual(repr(wrapper), 'MySetting()')\n"], "sample_1006": ["    def test_binomial_expand_func_negative_k():\n        n = Symbol('n', integer=True)\n        assert binomial(n, -1).expand(func=True) == 0\n"], "sample_279": ["    def test_check_constraint_sql(self):\n        model = Product\n        constraint = CheckConstraint(check=Q(price__gt=0), name='positive_price')\n        with mock.patch.object(connection, 'introspection') as mock_introspection:\n            mock_introspection.get_constraints.return_value = []\n            constraint.constraint_sql(model, connection.schema_editor())\n            mock_introspection.get_constraints.assert_called_once_with(\n                connection.cursor(), model._meta.db_table\n            )\n"], "sample_55": ["    def test_change_list_filter_by_related_field(self):\n        response = self.client.get(reverse('admin:books_book_changelist'))\n        self.assertContains(response, 'Promo 1')\n        self.assertContains(response, 'Promo 2')\n\n        response = self.client.get(reverse('admin:books_book_changelist') + '?promo__name=Promo%201')\n        self.assertContains(response, 'Promo 1')\n        self.assertNotContains(response, 'Promo 2')\n"], "sample_681": ["    def test_log_cli_level_overrides_log_level(self, testdir: Testdir) -> None:\n        testdir.makepyfile(\n            \"\"\"\n            import logging\n            import pytest\n\n            @pytest.mark.parametrize(\"log_level, expected_level\", [\n                (\"DEBUG\", logging.DEBUG),\n                (\"INFO\", logging.INFO),\n                (\"WARNING\", logging.WARNING),\n                (\"ERROR\", logging.ERROR),\n                (\"CRITICAL\", logging.CRITICAL),\n            ])\n                logging.getLogger().setLevel(log_level)\n                logging.info(\"This is a test message\")\n                assert logging.getLogger().getEffectiveLevel() == expected_level\n        \"\"\"\n        )\n        result = testdir.runpytest(\"--log-cli-level=WARNING\")\n        result.assert_outcomes(passed=5)\n"], "sample_348": ["    def test_inline_formset_factory_fk_name(self):\n        class MyInline(TabularInline):\n            model = Song\n            fk_name = 'band'\n\n        class MyAdmin(ModelAdmin):\n            inlines = [MyInline]\n\n        self.assertIsInvalid(MyAdmin, Band,\n                             r\"Inline 'MyInline' for model 'Band' has 'fk_name' set to 'band', but the model has more than one ForeignKey to 'Band'. You must specify a 'fk_name' attribute.\",\n                             hint='Inline foreign keys must be unambiguous.')\n"], "sample_737": ["    def test_tfidfvectorizer_vocabulary_consistency(self):\n        # Test that vocabulary is consistent between fit and fit_transform\n        vectorizer = TfidfVectorizer()\n        vectorizer.fit(ALL_FOOD_DOCS)\n        vocab1 = vectorizer.vocabulary_\n\n        vectorizer = TfidfVectorizer()\n        vectorizer.fit_transform(ALL_FOOD_DOCS)\n        vocab2 = vectorizer.vocabulary_\n\n        assert_equal(vocab1, vocab2)\n"], "sample_366": ["    def test_parse_datetime_with_timezone(self):\n        dt_str = '2023-10-27T10:30:00-05:00'\n        dt = parse_datetime(dt_str)\n        self.assertEqual(dt.year, 2023)\n        self.assertEqual(dt.month, 10)\n        self.assertEqual(dt.day, 27)\n        self.assertEqual(dt.hour, 10)\n        self.assertEqual(dt.minute, 30)\n        self.assertEqual(dt.second, 0)\n        self.assertEqual(dt.tzinfo.utcoffset(dt).total_seconds(), -18000)\n"], "sample_87": ["    def test_iter_modules_and_files_zipfile(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_path = Path(tempdir) / 'my_module.zip'\n            with zipfile.ZipFile(zip_path, 'w') as zf:\n                zf.writestr('my_module/__init__.py', '')\n            sys.path.append(str(tempdir))\n            self.import_and_cleanup('my_module')\n            self.assertFileFound(zip_path)\n"], "sample_402": ["    def test_should_redirect_with_slash_valid_path(self):\n        request = self.rf.get('/test/')\n        middleware = CommonMiddleware()\n        self.assertFalse(middleware.should_redirect_with_slash(request))\n"], "sample_921": ["    def test_is_builtin_class_method_with_descriptor(self):\n        class MyClass:\n                pass\n\n        MyClass.__init__ = property(MyClass.__init__)\n\n        assert inspect.is_builtin_class_method(MyClass, '__init__')\n"], "sample_567": ["    def test_annotation_arrowprops_mutation_scale(self):\n        fig, ax = plt.subplots()\n        text = \"Test\"\n        xy = (0.5, 0.5)\n        xytext = (0.7, 0.7)\n\n        # Test default mutation scale\n        ann = ax.annotate(text, xy=xy, xytext=xytext,\n                          arrowprops=dict(arrowstyle=\"->\"))\n        assert ann.arrow_patch.get_mutation_scale() == 10\n\n        # Test setting mutation scale\n        ann = ax.annotate(text, xy=xy, xytext=xytext,\n                          arrowprops=dict(arrowstyle=\"->\",\n                                          mutation_scale=20))\n        assert ann.arrow_patch.get_mutation_scale() == 20\n\n"], "sample_987": ["def test_evalf_piecewise():\n    p = Piecewise((x, x < 1), (x**2, x >= 1))\n    assert NS(p.subs(x, 0.5)) == '0.5'\n    assert NS(p.subs(x, 2)) == '4.0'\n    assert NS(p.subs(x, 1)) == '1.0'\n"], "sample_593": ["def test_summarize_coord_multiindex(multiindex):\n    expected = (\n        \"<div class='xr-var-name'><span class='xr-has-index'>x</span></div>\"\n        \"<div class='xr-var-dims'>()</div>\"\n        \"<div class='xr-var-dtype'>MultiIndex</div>\"\n        \"<div class='xr-var-preview'>('a', 1), ('a', 2), ('b', 1), ('b', 2)</div>\"\n        \"<input id='attrs-a5a4c66d-9655-491c-9285-669c29709648' class='xr-var-attrs-in' type='checkbox' disabled>\"\n        \"<label for='attrs-a5a4c66d-9655-491c-9285-669c29709648' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label>\"\n        \"<input id='data-99238556-518c-498c-871a-272527207478' class='xr-var-data-in' type='checkbox'>\"\n        \"<label for='data-99238556-518c-498c-871a-272527207478' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label>\"\n        \"<div class='xr-var-attrs'></div>\"\n        \"<div class='xr-var-data'><pre>&#x27;a&#x27; <br>&#x27;b&#x27;</pre></div>\"\n    )\n    actual = fh.summarize_coord(\"x\", multiindex[\"x\"])\n    assert actual == expected\n"], "sample_354": ["    def test_createsuperuser_with_password(self):\n        out = StringIO()\n        err = StringIO()\n        with override_settings(PASSWORD_HASHERS=['django.contrib.auth.hashers.MD5PasswordHasher']):\n            call_command('createsuperuser', stdout=out, stderr=err, interactive=False, username='alice', password='password')\n        self.assertEqual(out.getvalue(), \"Superuser created successfully.\\n\")\n        self.assertEqual(err.getvalue(), '')\n        user = User.objects.get(username='alice')\n        self.assertTrue(user.check_password('password'))\n"], "sample_43": ["    def test_regular_events_empty_block():\n        t = np.array([0, 1, 2, 3, 4, 5])\n        x = np.array([0, 0, 0, 0, 0, 0])\n        dt = 1\n        edges = bayesian_blocks(t, x, fitness='regular_events', dt=dt)\n        assert_allclose(edges, [0, 6])\n"], "sample_998": ["def test_latex_SingularityFunction():\n    assert latex(SingularityFunction(x, 0)) == '\\\\delta(x)'\n    assert latex(SingularityFunction(x, 1)) == '\\\\theta(x)'\n    assert latex(SingularityFunction(x, -1)) == '\\\\text{sgn}(x)'\n"], "sample_1096": ["def test_indexed_free_symbols():\n    i = Idx('i')\n    j = Idx('j')\n    A = IndexedBase('A')\n    B = IndexedBase('B')\n\n    assert A[i].free_symbols == {A, i}\n    assert A[i, j].free_symbols == {A, i, j}\n    assert (A[i] + B[j]).free_symbols == {A, B, i, j}\n    assert IndexedBase('C', shape=(i, j)).free_symbols == {i, j}\n"], "sample_1103": ["def test_Pow_as_content_primitive():\n    assert (2**(x + 1)).as_content_primitive() == (2, 2**x)\n    assert (2**(x + 1/2)).as_content_primitive() == (1, 2**(x + 1/2))\n    assert (2**(1 + x/2)).as_content_primitive() == (2, 2**(x/2))\n    assert (2**(1/2 + x/2)).as_content_primitive() == (1, 2**(x/2 + 1/2))\n    assert (2**(x/2 + 1/2)).as_content_primitive() == (1, 2**(x/2 + 1/2))\n    assert (2**(x/2 + 1)).as_content_primitive() == (2, 2**(x/2))\n"], "sample_96": ["    def test_list_display_links_not_in_list_display(self):\n        class MyModelAdmin(ModelAdmin):\n            list_display = ('name',)\n            list_display_links = ('email',)\n\n        self.assertIsInvalid(\n            MyModelAdmin,\n            User,\n            r\"The value of 'list_display_links\\[0\\]' refers to 'email', which is not defined in 'list_display'.\",\n            id='admin.E111',\n        )\n"], "sample_1114": ["def test_complexregion_intersection():\n    a = Interval(0, 1)\n    b = Interval(0, 2*S.Pi)\n    c = Interval(S.Pi/2, 3*S.Pi/2)\n    cr1 = ComplexRegion(a*b, polar=True)\n    cr2 = ComplexRegion(a*c, polar=True)\n    intersection = cr1.intersect(cr2)\n    assert intersection == ComplexRegion(a*Intersection(b, c), polar=True)\n"], "sample_1133": ["def test_deviation_ray3d():\n    n1, n2 = symbols('n1, n2')\n    n = Matrix([0, 0, 1])\n    P = Plane(Point3D(0, 0, 0), normal_vector=[0, 0, 1])\n    r1 = Ray3D(Point3D(-1, -1, 1), Point3D(0, 0, 0))\n    assert ae(deviation(r1, n1, n2, plane=P), -acos(-sqrt(-2*n1**2/(3*n2**2) + 1)) + acos(-sqrt(3)/3), 5)\n"], "sample_871": ["    def test_silhouette_samples_sparse_csr(self):\n        X, y = datasets.make_blobs(n_samples=100, random_state=42)\n        X_sparse = csr_matrix(X)\n        silhouette_avg = silhouette_score(X_sparse, y)\n        silhouette_avg_dense = silhouette_score(X, y)\n        assert_allclose(silhouette_avg, silhouette_avg_dense)\n"], "sample_61": ["    def test_ascii_username_validator(self):\n        validator = validators.ASCIIUsernameValidator()\n        valid_usernames = ['john.doe', 'john_doe', 'john123', 'john.doe@example.com']\n        invalid_usernames = ['john doe', 'j\u00f5hn', 'john!', 'john@example.com ']\n        for username in valid_usernames:\n            self.assertIsNone(validator(username))\n        for username in invalid_usernames:\n            with self.assertRaises(ValidationError):\n                validator(username)\n"], "sample_743": ["    def test_kneighbors_graph_sparse_input(self):\n        # Test kneighbors_graph with sparse input\n        X = csr_matrix(iris.data)\n        for algorithm in ALGORITHMS:\n            for mode in ['connectivity', 'distance']:\n                neigh = neighbors.KNeighborsClassifier(n_neighbors=5,\n                                                      algorithm=algorithm)\n                neigh.fit(X)\n                A = neigh.kneighbors_graph(X, mode=mode)\n                assert_true(issparse(A))\n                assert_equal(A.shape, (150, 150))\n"], "sample_330": ["    def test_truncate_name(self):\n        self.assertEqual(truncate_name('table_name'), 'table_name')\n        self.assertEqual(truncate_name('very_long_table_name'), 'very_long_table_name')\n        self.assertEqual(truncate_name('very_long_table_name', length=10), 'very_long_t')\n        self.assertEqual(truncate_name('\"schema\".\"table_name\"', length=15), '\"schema\".\"table_n')\n        self.assertEqual(truncate_name('\"schema\".\"very_long_table_name\"', length=20), '\"schema\".\"very_lo')\n"], "sample_156": ["    def test_get_initial_for_field(self):\n        class MyForm(Form):\n            name = CharField(initial='John')\n            age = IntegerField(initial=30)\n\n        form = MyForm()\n        self.assertEqual(form.get_initial_for_field(form.fields['name'], 'name'), 'John')\n        self.assertEqual(form.get_initial_for_field(form.fields['age'], 'age'), 30)\n\n        form = MyForm(initial={'name': 'Jane', 'age': 25})\n        self.assertEqual(form.get_initial_for_field(form.fields['name'], 'name'), 'Jane')\n        self.assertEqual(form.get_initial_for_field(form.fields['age'], 'age'), 25)\n\n        class MyFormWithCallableInitial(Form):\n            name = CharField(initial=lambda: 'John')\n\n        form = MyFormWithCallableInitial()\n        self.assertEqual(form.get_initial_for_field(form.fields['name'], 'name'), 'John')\n"], "sample_1119": ["def test_inverse_ADJ():\n    A = Matrix([[1, 2], [3, 4]])\n    assert A.inverse_ADJ() == A.inv()\n\n"], "sample_390": ["    def test_serve_if_modified_since(self):\n        response = self.client.get(f\"/{self.prefix}/test.txt\", HTTP_IF_MODIFIED_SINCE=http_date(1))\n        self.assertEqual(response.status_code, 304)\n        response = self.client.get(f\"/{self.prefix}/test.txt\", HTTP_IF_MODIFIED_SINCE=http_date(2))\n        self.assertEqual(response.status_code, 200)\n"], "sample_59": ["    def test_get_order_with_respect_to_empty(self):\n        department = Department.objects.create(name='Sales')\n        worker1 = Worker.objects.create(name='Alice', department=department)\n        worker2 = Worker.objects.create(name='Bob', department=department)\n\n        self.assertEqual(list(worker1.get_department_order()), [])\n        self.assertEqual(list(worker2.get_department_order()), [])\n"], "sample_73": ["    def test_manifest_strict_mode(self):\n        \"\"\"\n        Test that strict mode in ManifestStaticFilesStorage raises ValueError\n        when a file is referenced but not present in the manifest.\n        \"\"\"\n        with self.settings(STATICFILES_STORAGE='django.contrib.staticfiles.storage.ManifestStaticFilesStorage'):\n            # Create a file that will be referenced but not included in the manifest\n            test_file = os.path.join(TEST_ROOT, 'test.css')\n            with open(test_file, 'w') as f:\n                f.write('body { background-color: red; }')\n\n            # Create a template that references the test file\n            self.create_template('test.html', '{% load static %}<link rel=\"stylesheet\" href=\"{% static \"test.css\" %}\">')\n\n            # Run collectstatic to generate the manifest\n            call_command('collectstatic', interactive=False, verbosity=0)\n\n            # Try to render the template, which should raise a ValueError\n            with self.assertRaises(ValueError) as e:\n                self.render_template('test.html')\n\n            self.assertIn(\"Missing staticfiles manifest entry for 'test.css'\", str(e.exception))\n"], "sample_1162": ["def test_expand_mul_noncommutative():\n    x = noncomm_x\n    y = noncomm_x\n    assert expand_mul(x*y) == x*y\n    assert expand_mul(x*y*x) == x*y*x\n    assert expand_mul((x+y)*(x+y)) == x*x + x*y + y*x + y*y\n"], "sample_1068": ["def test_octave_code_indexed():\n    i = Idx('i', 3)\n    A = IndexedBase('A', shape=(3,))\n    code = octave_code(A[i], assign_to='x')\n    assert code == 'x = A(i);'\n\n"], "sample_796": ["    def test_huber_sparse_input(self):\n        X, y = make_regression_with_outliers(n_samples=50, n_features=20)\n        X_sparse = sparse.csr_matrix(X)\n        huber = HuberRegressor()\n        huber.fit(X_sparse, y)\n        assert_array_almost_equal(huber.coef_,\n                                  LinearRegression().fit(X, y).coef_)\n"], "sample_277": ["    def test_q_resolve_expression_empty(self):\n        q = Q()\n        with self.assertRaises(ValueError):\n            q.resolve_expression()\n"], "sample_955": ["compilation error"], "sample_874": ["    def test_feature_names_out_with_sparse_input(self):\n        selector = StepSelector(step=2)\n        Xt = sp.csr_matrix(X)\n        selector.fit(Xt)\n        assert_array_equal(selector.get_feature_names_out(feature_names), feature_names_t)\n"], "sample_700": ["    def test_skip_function_with_skip_mark(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skip(reason=\"skip this test\")\n                assert False\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.assert_outcomes(skipped=1)\n        assert \"skip this test\" in result.stdout.str()\n"], "sample_536": ["def test_polygon_selector_move_all(ax):\n    fig, ax = plt.subplots()\n    selector = widgets.PolygonSelector(ax, lambda verts: None)\n    selector._xys = [(0, 0), (1, 0), (1, 1), (0, 1), (0, 0)]\n    selector._selection_completed = True\n    selector._add_box()\n\n    # Simulate a mouse press and drag event to move all vertices\n    event = mock_event(type='button_press_event', x=0.5, y=0.5, button=1)\n    selector.onpress(event)\n    event = mock_event(type='motion_notify_event', x=1.5, y=1.5)\n    selector.onmove(event)\n    event = mock_event(type='button_release_event', x=1.5, y=1.5, button=1)\n    selector.onrelease(event)\n\n    # Assert that all vertices have been moved by the same amount\n    expected_verts = [(1, 1), (2, 1), (2, 2), (1, 2), (1, 1)]\n    assert selector._xys == expected_verts\n"], "sample_347": ["    def test_make_aware_zoneinfo(self):\n        naive_dt = datetime.datetime(2023, 10, 26, 10, 0, 0)\n        aware_dt = timezone.make_aware(naive_dt, PARIS_ZI)\n        self.assertEqual(aware_dt.tzinfo, PARIS_ZI)\n        self.assertEqual(aware_dt.astimezone(UTC), datetime.datetime(2023, 10, 26, 12, 0, 0, tzinfo=UTC))\n"], "sample_367": ["    def test_cache_page_timeout(self):\n        response = fully_decorated(HttpRequest())\n        self.assertEqual(response.status_code, 200)\n        self.assertIn('Cache-Control', response['Cache-Control'])\n"], "sample_534": ["    def test_contour_label_rotation(self):\n        x = np.arange(-5, 5, 0.25)\n        y = np.arange(-5, 5, 0.25)\n        X, Y = np.meshgrid(x, y)\n        Z = np.sin(np.sqrt(X**2 + Y**2))\n\n        fig, ax = plt.subplots()\n        cs = ax.contour(X, Y, Z, levels=10)\n        ax.clabel(cs, inline=True, fontsize=8, rotation=45)\n\n"], "sample_136": ["    def test_get_full_path_info_with_trailing_slash(self):\n        request = HttpRequest()\n        request.path_info = '/path/'\n        self.assertEqual(request.get_full_path_info(), '/path/')\n        self.assertEqual(request.get_full_path_info(force_append_slash=True), '/path/')\n"], "sample_621": ["    def test_indexes_all_equal_multiindex_different_levels():\n        # Test case with multi-indexes having different levels\n        idx1 = PandasMultiIndex(pd.MultiIndex.from_tuples([(1, 'a'), (2, 'b')]), 'dim1')\n        idx2 = PandasMultiIndex(pd.MultiIndex.from_tuples([(1, 'a'), (2, 'c')]), 'dim1')\n        idx3 = PandasMultiIndex(pd.MultiIndex.from_tuples([(1, 'a'), (2, 'b')]), 'dim2')\n\n        vars1 = {'dim1': Variable(['dim1'], [1, 2]), 'dim2': Variable(['dim2'], [1, 2])}\n        vars2 = {'dim1': Variable(['dim1'], [1, 2]), 'dim2': Variable(['dim2'], [1, 2])}\n        vars3 = {'dim1': Variable(['dim1'], [1, 2]), 'dim2': Variable(['dim2'], [1, 2])}\n\n        assert not indexes_all_equal([(idx1, vars1), (idx2, vars2)])\n        assert not indexes_all_equal([(idx1, vars1), (idx3, vars3)])\n"], "sample_894": ["def check_classification_iris(name):\n    \"\"\"Check classification on the iris dataset.\"\"\"\n    ForestClassifier = FOREST_CLASSIFIERS[name]\n\n    clf = ForestClassifier(n_estimators=10, random_state=1)\n    clf.fit(iris.data, iris.target)\n    score = clf.score(iris.data, iris.target)\n    assert score > 0.9\n\n    # also test predict_proba\n    y_proba = clf.predict_proba(iris.data)\n    assert y_proba.shape == (iris.data.shape[0], 3)\n    assert_almost_equal(y_proba.sum(axis=1), np.ones(iris.data.shape[0]))\n"], "sample_1188": ["def test_pretty_del():\n    assert pretty(Del) == '\u2207'\n    assert upretty(Del) == '\u2207'\n"], "sample_1187": ["def test_integration_reduction_dynamic():\n    p1 = Polygon(Point(0, 0), Point(1, 0), Point(1, 1), Point(0, 1))\n    p2 = Polygon(Point(0.5, 0.5), Point(1.5, 0.5), Point(1.5, 1.5), Point(0.5, 1.5))\n    expr = x**2 + y**2\n    result = integration_reduction_dynamic(p1, p2, expr)\n    assert result == S(11)/12\n"], "sample_1101": ["    def test_schur_partition_large_n():\n        n = 100\n        partition = schur_partition(n)\n        assert len(partition) == _schur_subsets_number(n)\n        for subset in partition:\n            assert all(a + b not in subset for a in subset for b in subset if a != b)\n"], "sample_352": ["    def test_where_node_split_having_with_aggregate(self):\n        node = WhereNode([\n            F('id') + 1,\n            Q(id__gt=1),\n        ], AND)\n        where_node, having_node = node.split_having()\n        self.assertIsNone(having_node)\n        self.assertEqual(where_node.children, [F('id') + 1, Q(id__gt=1)])\n\n        node = WhereNode([\n            F('id') + 1,\n            Q(id__gt=1),\n            Count('related'),\n        ], AND)\n        where_node, having_node = node.split_having()\n        self.assertIsNone(where_node)\n        self.assertEqual(having_node.children, [Count('related')])\n"], "sample_339": ["    def test_inlineformset_factory_with_to_field(self):\n        class AuthorForm(forms.ModelForm):\n            class Meta:\n                model = Author\n                fields = ['name', 'age']\n\n        class BookForm(forms.ModelForm):\n            class Meta:\n                model = Book\n                fields = ['title', 'author']\n\n        BookInlineFormSet = inlineformset_factory(\n            Author, Book, form=BookForm, fk_name='author', extra=1\n        )\n        author = Author.objects.create(name='Test Author', age=30)\n        formset = BookInlineFormSet(instance=author)\n        self.assertEqual(len(formset.forms), 1)\n        self.assertEqual(formset.forms[0].fields['author'].initial, author)\n"], "sample_358": ["    def test_table_references_table(self):\n        self.assertTrue(self.reference.references_table('TABLE'))\n        self.assertFalse(self.reference.references_table('other_table'))\n"], "sample_1185": ["    def test_decompogen_abs():\n        assert decompogen(Abs(x), x) == [Abs(x)]\n"], "sample_569": ["    def test_residplot(self):\n        with mpl.rc_context({'figure.figsize': (6, 4)}):\n            ax = lm.residplot(\"x\", \"y\", data=self.df, ax=plt.gca())\n            assert isinstance(ax, mpl.axes.Axes)\n            plt.close('all')\n\n            ax = lm.residplot(\"x\", \"y\", data=self.df, lowess=True)\n            assert isinstance(ax, mpl.axes.Axes)\n            plt.close('all')\n\n            ax = lm.residplot(\"x\", \"y\", data=self.df, robust=True)\n            assert isinstance(ax, mpl.axes.Axes)\n            plt.close('all')\n\n            ax = lm.residplot(\"x\", \"y\", data=self.df, order=2)\n            assert isinstance(ax, mpl.axes.Axes)\n            plt.close('all')\n\n            ax = lm.residplot(\"x\", \"y\", data=self.df, x_partial=\"d\")\n            assert isinstance(ax, mpl.axes.Axes)\n            plt.close('all')\n\n"], "sample_272": ["    def test_migrate_forwards_with_fake_initial(self):\n        \"\"\"\n        Test that migrations marked as initial can be applied as fake migrations.\n        \"\"\"\n        with self.connection.cursor() as cursor:\n            self.connection.introspection.get_table_description(cursor, 'migrations2_initialmodel')\n        # Create a migration that adds a model\n        migration = self.create_migration(\n            \"migrations2\", \"0002_initialmodel\",\n            operations=[\n                migrations.CreateModel(\n                    name='InitialModel',\n                    fields=[\n                        ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                        ('name', models.CharField(max_length=100)),\n                    ],\n                ),\n            ],\n        )\n        # Add the migration to the graph\n        self.loader.graph.add_migration(migration)\n\n        # Create a MigrationExecutor\n        executor = MigrationExecutor(self.connection)\n        # Apply the migration as a fake migration\n        state = executor.migrate(\n            targets=[('migrations2', '0002_initialmodel')],\n            fake=True,\n            fake_initial=True,\n        )\n        # Assert that the migration was applied\n        self.assertEqual(state.apps.get_model('migrations2', 'InitialModel').objects.count(), 0)\n"], "sample_27": ["    def test_diff_nonstandard_hdu(self):\n        # Regression test for #3161\n        hdu1 = DummyNonstandardExtHDU(data=[1, 2, 3])\n        hdu2 = DummyNonstandardExtHDU(data=[1, 2, 4])\n        diff = FITSDiff(hdu1, hdu2)\n        assert diff.diff_hdu_count == 1\n        assert diff.diff_data == [(0, (np.array([1, 2, 3]), np.array([1, 2, 4])))]\n"], "sample_923": ["def test_cpp_nested_template_function():\n    check('function',\n          'template <typename T> void foo(T t);',\n          {1: 'foo'},\n          'template <typename T> void foo(T t);',\n          key='foo',\n          asTextOutput='foo<T>(T t)')\n"], "sample_4": ["    def test_write_read_latex_names(self, cosmo, tmp_path):\n        \"\"\"Test writing and reading with latex names.\"\"\"\n        filename = tmp_path / \"cosmo.html\"\n        write_html_table(cosmo, filename, latex_names=True)\n        read_cosmo = read_html_table(filename, latex_names=True)\n        assert read_cosmo == cosmo\n"], "sample_428": ["    def test_format_large_decimal_scientific_notation(self):\n        self.assertEqual(\n            nformat(Decimal(\"1.23456789012345678901234567890\"), decimal_pos=3),\n            \"1.235\",\n        )\n"], "sample_168": ["    def test_remove_stale_content_types_interactive_no(self):\n        with captured_stdout() as stdout, mock.patch('builtins.input', return_value='no'):\n            call_command('remove_stale_contenttypes', database='default', interactive=True, verbosity=2)\n        self.assertIn(\"Stale content types remain.\", stdout.getvalue())\n        self.assertEqual(ContentType.objects.count(), self.before_count + 1)\n"], "sample_565": ["    def test_mark_inset(self):\n        fig, ax = plt.subplots()\n        axin = inset_axes(ax, \"30%\", \"40%\")\n        mark_inset(ax, axin, loc1=1, loc2=3)\n        fig.canvas.draw()\n        # Check if the patches are created\n        assert len(ax.patches) == 1\n        assert len(axin.patches) == 2\n"], "sample_443": ["    def test_file_based_cache_cull(self):\n        cache_dir = tempfile.mkdtemp()\n        try:\n            with self.settings(CACHES={\"default\": {\"BACKEND\": \"django.core.cache.backends.filebased.FileBasedCache\", \"LOCATION\": cache_dir, \"MAX_ENTRIES\": 3, \"CULL_FREQUENCY\": 2}}):\n                cache.set(\"key1\", 1)\n                cache.set(\"key2\", 2)\n                cache.set(\"key3\", 3)\n                cache.set(\"key4\", 4)\n                self.assertEqual(len(os.listdir(cache_dir)), 4)\n                cache.get(\"key1\")  # Access a key to prevent it from being culled\n                cache.clear()\n                self.assertEqual(len(os.listdir(cache_dir)), 0)\n        finally:\n            shutil.rmtree(cache_dir)\n"], "sample_357": ["    def test_remove_field_with_default(self):\n        before = self.make_project_state([\n            self.author_with_biography_non_blank,\n        ])\n        after = self.make_project_state([\n            self.author_with_biography_blank,\n        ])\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['RemoveField'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='biography')\n"], "sample_200": ["    def test_emailmessage_attach_file_with_utf8_content(self):\n        with tempfile.NamedTemporaryFile(mode='w+', delete=False) as f:\n            f.write('This is a test file with UTF-8 content.\\n'\n                    'It has some special characters like \u00e9\u00e0\u00e7\u00fc\u00f6\u00df.')\n            f.flush()\n            filename = f.name\n        try:\n            msg = EmailMessage(\n                'Subject', 'Body', 'from@example.com', ['to@example.com'],\n            )\n            msg.attach_file(filename)\n            attachments = self.get_decoded_attachments(msg)\n            self.assertEqual(len(attachments), 1)\n            self.assertEqual(attachments[0][0], os.path.basename(filename))\n            self.assertEqual(attachments[0][2], 'text/plain; charset=\"utf-8\"')\n            self.assertEqual(attachments[0][1].decode('utf-8'),\n                             'This is a test file with UTF-8 content.\\n'\n                             'It has some special characters like \u00e9\u00e0\u00e7\u00fc\u00f6\u00df.')\n        finally:\n            os.unlink(filename)\n"], "sample_988": ["def test_sympify_complex():\n    assert sympify(complex(1, 2)) == 1 + 2*I\n    assert sympify(complex(-1, -2)) == -1 - 2*I\n    assert sympify(complex(0, 2)) == 2*I\n    assert sympify(complex(1, 0)) == 1\n"], "sample_709": ["    def test_runpytest_inprocess_timeout(self, monkeypatch):\n        \"\"\"Test that runpytest_inprocess times out correctly.\"\"\"\n        monkeypatch.setattr(timing, \"time\", lambda: 0)\n        p = self.makepyfile(\n            \"\"\"\n            import time\n            time.sleep(10)\n            print(\"hello\")\n        \"\"\"\n        )\n        with pytest.raises(self.TimeoutExpired) as excinfo:\n            self.runpytest_inprocess(p, timeout=1)\n        assert \"1 second timeout expired\" in str(excinfo.value)\n\n"], "sample_866": ["    def test_affinity_propagation_equal_similarities_and_preferences():\n        # Test case for when all similarities and preferences are equal\n        S = np.ones((5, 5))\n        preference = 1\n        assert _equal_similarities_and_preferences(S, preference)\n\n        preference = np.array([1, 1, 1, 1, 1])\n        assert _equal_similarities_and_preferences(S, preference)\n\n        S = np.zeros((5, 5))\n        assert not _equal_similarities_and_preferences(S, preference)\n\n        preference = np.array([2, 2, 2, 2, 2])\n        assert not _equal_similarities_and_preferences(S, preference)\n\n"], "sample_721": ["    def test_check_array_dtype_object_warn(self):\n        # Test that a warning is raised when dtype is object and warn_on_dtype\n        # is True\n        with warnings.catch_warnings(record=True) as w:\n            warnings.simplefilter(\"always\")\n            X = np.array([['a', 1], ['b', 2]], dtype=object)\n            check_array(X, dtype='numeric', warn_on_dtype=True)\n            assert_true(len(w) == 1)\n            assert_equal(w[0].category, DataConversionWarning)\n"], "sample_211": ["    def test_view_as_view(self):\n        view = SimpleView.as_view()\n        request = self.rf.get('/')\n        response = view(request)\n        self._assert_simple(response)\n"], "sample_934": ["def test_cpp_enum_scoped():\n    check(\n        'enum',\n        'enum { A, B, C };',\n        {1: 'enum'},\n        output='enum { A, B, C }',\n        key='enum',\n    )\n"], "sample_764": ["    def test_column_transformer_sparse_output_with_sparse_input(self):\n        X = sparse.csr_matrix([[1, 2], [3, 4]])\n        transformer = ColumnTransformer(\n            transformers=[('scaler', StandardScaler(), [0]),\n                          ('onehot', OneHotEncoder(), [1])],\n            remainder='passthrough', sparse_threshold=0.5)\n        Xt = transformer.fit_transform(X)\n        assert_equal(Xt.shape, (2, 4))\n        assert isinstance(Xt, sparse.csr_matrix)\n"], "sample_848": ["    def test_multioutput_regressor_sparse_input(self):\n        # Test MultiOutputRegressor with sparse input\n        X, y = make_classification(n_samples=100, n_features=10,\n                                   n_informative=5, n_classes=3,\n                                   random_state=0)\n        y = np.array(y).reshape(-1, 1)\n        y = np.hstack((y, y))\n        X_sparse = sp.csr_matrix(X)\n        regressor = MultiOutputRegressor(Ridge())\n        regressor.fit(X_sparse, y)\n        y_pred = regressor.predict(X_sparse)\n        assert_array_almost_equal(y_pred, regressor.predict(X))\n"], "sample_1040": ["def test_print_MatrixSymbol():\n    assert mathml(MatrixSymbol('A', 2, 2), printer='content') == '<apply><csymbol definitionURL=\"http://www.sympy.org/symenglish/MatrixSymbol\">MatrixSymbol</csymbol><ci>A</ci><cn type=\"integer\">2</cn><cn type=\"integer\">2</cn></apply>'\n    assert mathml(MatrixSymbol('A', 2, 2), printer='presentation') == '<mi>A</mi>'\n\n"], "sample_1055": ["def test_encipher_bg():\n    p = 11\n    q = 19\n    key = bg_private_key(p, q)\n    N = bg_public_key(p, q)\n    msg = 10\n    c, x_L = encipher_bg(msg, N)\n    assert decipher_bg((c, x_L), key) == msg\n\n"], "sample_256": ["    def test_password_validation_with_custom_user_model(self):\n        with override_settings(AUTH_USER_MODEL='tests.models.custom_user.CustomUser'):\n            form = UserCreationForm()\n            self.assertTrue(isinstance(form.fields['username'].widget, CharField))\n            self.assertFalse(form.fields.get('email'))\n"], "sample_478": ["    def test_raw_id_fields_with_empty_string(self):\n        class MyModelAdmin(ModelAdmin):\n            raw_id_fields = ['nonexistent_field', '']\n\n        self.assertIsInvalid(\n            MyModelAdmin,\n            ValidationTestModel,\n            msg=r\"The value of 'raw_id_fields' contains an empty string.\",\n            id=\"admin.E019\",\n        )\n"], "sample_1113": ["def test_block_collapse_inverse_2x2():\n    B = BlockMatrix([[X1, X2], [X3, X4]])\n    C = block_collapse(B.inverse())\n    assert isinstance(C, BlockMatrix)\n    assert C.blockshape == (2, 2)\n"], "sample_668": ["    def test_node_use_from_parent(self):\n        with pytest.raises(deprecated.PytestDeprecationWarning) as excinfo:\n            nodes.Item.from_parent(None, None)\n        assert str(excinfo.value).startswith(\n            \"Direct construction of Item has been deprecated, please use Item.from_parent.\"\n        )\n"], "sample_951": ["    def test_signature_from_ast_posonlyargs(self):\n        code = 'def func(a, b, /, c, d=1): pass'\n        module = ast.parse(code)\n        function = cast(ast.FunctionDef, module.body[0])  # type: ignore\n        sig = inspect.signature_from_ast(function, code)\n        assert sig.parameters[0].kind == Parameter.POSITIONAL_ONLY\n        assert sig.parameters[1].kind == Parameter.POSITIONAL_ONLY\n        assert sig.parameters[2].kind == Parameter.POSITIONAL_OR_KEYWORD\n        assert sig.parameters[3].kind == Parameter.POSITIONAL_OR_KEYWORD\n"], "sample_1179": ["def test_print_NDimArray():\n    a = NDimArray([1, 2, 3], (3,))\n    assert sstr(a) == 'NDimArray([1, 2, 3], (3,))'\n"], "sample_792": ["    def test_gaussian_nb_partial_fit_multiclass():\n        # Test partial_fit for multiclass GaussianNB\n        clf = GaussianNB()\n        X_train, X_test, y_train, y_test = train_test_split(X2, y2,\n                                                            test_size=0.33,\n                                                            random_state=42)\n        clf.partial_fit(X_train[:2], y_train[:2], classes=[1, 2, 3])\n        clf.partial_fit(X_train[2:], y_train[2:])\n        assert_equal(clf.classes_, [1, 2, 3])\n        assert_equal(clf.predict(X_test), clf.fit(X_train, y_train).predict(X_test))\n"], "sample_909": ["    def test_namedtuple_subclass(self):\n        docstring = NamedtupleSubclass.__doc__\n        expected = dedent('''\n            Sample namedtuple subclass\n\n            Attributes\n            ----------\n            attr1 : Arbitrary type\n                Quick description of attr1\n            attr2 : Another arbitrary type\n                Quick description of attr2\n            attr3 : Type\n\n                Adds a newline after the type\n\n        ''')\n        self.assertEqual(GoogleDocstring(docstring).lines(), expected.splitlines())\n"], "sample_235": ["    def test_on_commit_rollback(self):\n        with transaction.atomic():\n            self.do(1)\n            self.do(2)\n            raise transaction.TransactionManagementError()\n        self.assertNotified([])\n        self.assertEqual(Thing.objects.count(), 0)\n"], "sample_1093": ["    def test_print_Identity(self):\n        A = Identity(2)\n        assert pycode(A, language='numpy') == 'numpy.eye(2)'\n        assert pycode(A, language='scipy') == 'numpy.eye(2)'\n        assert pycode(A, language='sympy') == 'sympy.Identity(2)'\n"], "sample_274": ["    def test_modelmultiplechoicefield_invalid_pk_value(self):\n        class MyForm(Form):\n            choices = ModelMultipleChoiceField(ChoiceModel.objects.all())\n\n        form = MyForm({'choices': ['1', '2', 'not_a_pk']})\n        self.assertFormErrors(\n            [\n                '\u201cnot_a_pk\u201d is not a valid value.',\n            ],\n            form.full_clean,\n        )\n"], "sample_184": ["    def test_index_together_invalid_types(self):\n        class MyModel(models.Model):\n            name = models.CharField(max_length=100)\n            age = models.IntegerField()\n\n            class Meta:\n                index_together = (('name', 123),)\n\n        errors = MyModel.check()\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertIn(\"All 'index_together' elements must be lists or tuples.\", errors[0].msg)\n"], "sample_1079": ["def test_point3d_intersection():\n    p1 = Point3D(1, 2, 3)\n    p2 = Point3D(4, 5, 6)\n    l = Line3D(p1, p2)\n    assert p1.intersection(l) == [p1]\n    assert p2.intersection(l) == [p2]\n    assert Point3D(2, 3, 4).intersection(l) == [Point3D(2, 3, 4)]\n    assert Point3D(0, 0, 0).intersection(l) == []\n"], "sample_379": ["    def test_safe_string_addition(self):\n        self.assertIsInstance(mark_safe('a') + mark_safe('b'), SafeString)\n        self.assertIsInstance(mark_safe('a') + 'b', str)\n        self.assertIsInstance('a' + mark_safe('b'), str)\n"], "sample_1121": ["def test_expand_2arg():\n    assert expand_2arg(x*(y + z)) == x*y + x*z\n    assert expand_2arg(2*(x + y)) == 2*x + 2*y\n    assert expand_2arg(2*(x + y + z)) == 2*x + 2*y + 2*z\n    assert expand_2arg(x*(y + z + 1)) == x*y + x*z + x\n    assert expand_2arg(x*(y + z + 1) + 2*(x + y)) == x*y + x*z + x + 2*x + 2*y\n    assert expand_2arg(2*(x + y) + 3*(x + z)) == 2*x + 2*y + 3*x + 3*z\n"], "sample_180": ["    def test_check_long_column_names_with_truncation(self):\n        allowed_len, db_alias = get_max_column_name_length()\n        if allowed_len is None:\n            self.skipTest(\"No database supports non-truncating column names\")\n\n        with override_settings(DATABASES={'default': {'ENGINE': 'django.db.backends.sqlite3'}}):\n            class MyModel(models.Model):\n                field1 = models.CharField(max_length=255)\n                field2 = models.CharField(max_length=255)\n\n            errors = MyModel.check()\n            self.assertEqual(len(errors), 0)\n\n"], "sample_230": ["    def test_jsonfield_with_encoder(self):\n        class MyForm(Form):\n            data = JSONField(encoder=DjangoJSONEncoder)\n\n        data = {'key': 'value', 'another_key': 123}\n        form = MyForm({'data': json.dumps(data)})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['data'], data)\n"], "sample_391": ["    def test_alter_unique_together_empty_to_empty(self):\n        \"\"\"\n        #24871 - Ensure that altering unique_together from an empty list to\n        another empty list doesn't create a migration.\n        \"\"\"\n        before = [\n            migrations.CreateModel(\n                name=\"UnicodeModel\",\n                fields=[\n                    models.CharField(max_length=255, primary_key=True, serialize=False),\n                ],\n                options={\"unique_together\": set()},\n            ),\n        ]\n        after = [\n            migrations.CreateModel(\n                name=\"UnicodeModel\",\n                fields=[\n                    models.CharField(max_length=255, primary_key=True, serialize=False),\n                ],\n                options={\"unique_together\": set()},\n            ),\n        ]\n        self.assertDoesNotOptimize(before, after)\n\n"], "sample_252": ["    def test_key_transform_null_lookup(self):\n        model = JSONModel.objects.create(data={'key': None})\n        with self.assertNumQueries(1):\n            self.assertTrue(JSONModel.objects.filter(data__key__isnull=True).exists())\n        with self.assertNumQueries(1):\n            self.assertFalse(JSONModel.objects.filter(data__key__isnull=False).exists())\n"], "sample_910": ["    def test_is_suppressed_warning(self):\n        assert is_suppressed_warning('sphinx.ext.autodoc', 'some_subtype', ['sphinx.ext.autodoc.some_subtype']) is True\n        assert is_suppressed_warning('sphinx.ext.autodoc', 'some_subtype', ['sphinx.ext.autodoc.*']) is True\n        assert is_suppressed_warning('sphinx.ext.autodoc', 'some_subtype', ['sphinx.ext.autodoc']) is True\n        assert is_suppressed_warning('sphinx.ext.autodoc', 'some_subtype', ['some_other_warning']) is False\n        assert is_suppressed_warning('sphinx.ext.autodoc', None, ['sphinx.ext.autodoc.some_subtype']) is True\n        assert is_suppressed_warning('sphinx.ext.autodoc', None, ['sphinx.ext.autodoc.*']) is True\n        assert is_suppressed_warning('sphinx.ext.autodoc', None, ['sphinx.ext.autodoc']) is True\n        assert is_suppressed_warning(None, None, ['sphinx.ext.autodoc.some_subtype']) is False\n"], "sample_378": ["    def test_bulk_update_with_related_objects(self):\n        self.create_tags()\n        for i, note in enumerate(self.notes):\n            note.tags.add(self.tags[i])\n\n        Note.objects.filter(id__in=[n.id for n in self.notes[:5]]).update(\n            note=F('note') + ' updated', tags=self.tags[5:]\n        )\n\n        for i, note in enumerate(self.notes):\n            if i < 5:\n                self.assertEqual(note.note, f'{i} updated')\n                self.assertEqual(note.tags.all(), self.tags[5:])\n            else:\n                self.assertEqual(note.note, str(i))\n                self.assertEqual(note.tags.all(), [self.tags[i]])\n"], "sample_12": ["    def test_longitude_wrap_angle():\n        lon = Longitude(100 * u.deg)\n        assert lon.wrap_angle == 360 * u.deg\n        lon.wrap_angle = 180 * u.deg\n        assert lon.wrap_angle == 180 * u.deg\n        assert_allclose(lon.degree, 100 - 360)\n"], "sample_253": ["    def test_iter_modules_and_files_zipfile(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_path = Path(tempdir) / 'my_module.zip'\n            with zipfile.ZipFile(zip_path, 'w') as zipf:\n                zipf.writestr('my_module/__init__.py', '')\n            sys.path.append(tempdir)\n            self.import_and_cleanup('my_module')\n            self.assertFileFound(zip_path)\n"], "sample_389": ["    def test_settings_modification(self):\n        self.assertEqual(settings.ITEMS, [\"b\", \"c\", \"d\"])\n        self.assertEqual(settings.ITEMS_OUTER, [1, 2, 3])\n        self.assertEqual(settings.TEST, \"override\")\n        self.assertEqual(settings.TEST_OUTER, \"outer\")\n"], "sample_560": ["    def test_legend_loc(self, loc):\n        fig, ax = plt.subplots()\n        ax.plot([1, 2, 3], label='label')\n        ax.legend(loc=loc)\n        fig.canvas.draw()\n        # Check that the legend is in the correct location\n        bbox = ax.get_legend().get_window_extent()\n        assert bbox.x0 < bbox.x1\n        assert bbox.y0 < bbox.y1\n\n"], "sample_150": ["    def test_check_migrations_no_migrations(self):\n        with mock.patch('django.db.migrations.executor.MigrationExecutor.migration_plan', return_value=[]):\n            with self.assertLogs() as captured:\n                BaseCommand().check_migrations()\n            self.assertEqual(captured.records, [])\n"], "sample_1115": ["def test_riemann_cyclic_replace():\n    Lorentz = TensorIndexType('Lorentz', dummy_name='L')\n    i, j, k, l = tensor_indices('i,j,k,l', Lorentz)\n    R = TensorHead('R', [Lorentz]*4, TensorSymmetry.riemann())\n    t = R(i,j,k,l)*(R(-i,-j,-k,-l) - 2*R(-i,-k,-j,-l))\n    t = riemann_cyclic_replace(t)\n    assert t.equals(R(i,j,k,l)*(R(-i,-j,-k,-l) - 2*R(-i,-k,-j,-l)))\n"], "sample_409": ["    def test_blocktranslate_simple(self):\n        template = Template(\n            \"{% load i18n %}{% blocktranslate %}This is {{ anton }}.{% endblocktranslate %}\"\n        )\n        with translation.override(\"de\"):\n            output = template.render(Context({\"anton\": \"Anton\"}))\n        self.assertEqual(output, \"This is Anton.\")\n"], "sample_452": ["    def test_rename_field_with_related_objects(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\"CREATE TABLE other_app_model (id INT PRIMARY KEY)\")\n\n        class OtherAppModel(models.Model):\n            pass\n\n        class MyModel(models.Model):\n            name = models.CharField(max_length=100)\n            other_model = models.ForeignKey(OtherAppModel, on_delete=models.CASCADE)\n\n        with atomic():\n            MyModel.objects.create(name='test', other_model=OtherAppModel.objects.create())\n\n        # Rename the field\n        operations = [\n            migrations.RenameField(\n                model_name='mymodel',\n                old_name='other_model',\n                new_name='related_model',\n            ),\n        ]\n        migration = Migration(\n            'test_rename_field_with_related_objects',\n            operations,\n        )\n\n        # Apply the migration\n        self.apply_migration(migration)\n\n        # Check the database schema\n        with connection.cursor() as cursor:\n            cursor.execute(\"SELECT column_name FROM information_schema.columns WHERE table_name = %s\", ('mymodel',))\n            columns = [row[0] for row in cursor.fetchall()]\n            self.assertIn('related_model_id', columns)\n\n        # Check that related objects are still accessible\n        self.assertEqual(MyModel.objects.get(name='test').related_model.pk, 1)\n\n        # Rollback the migration\n        self.rollback_migration(migration)\n\n        # Check the database schema\n        with connection.cursor() as cursor:\n            cursor.execute(\"SELECT column_name FROM information_schema.columns WHERE table_name = %s\", ('mymodel',))\n            columns = [row[0] for row in cursor.fetchall()]\n            self.assertIn('other_model_id', columns)\n\n        # Check that related objects are still accessible\n        self.assertEqual(MyModel.objects.get(name='test').other_model.pk, 1)\n"], "sample_995": ["def test_GoldenRatio_properties():\n    assert GoldenRatio.is_irrational is True\n    assert GoldenRatio.is_algebraic is True\n    assert GoldenRatio.is_transcendental is False\n    assert GoldenRatio > 1\n    assert GoldenRatio < 2\n    assert GoldenRatio.expand(func=True) == 1/2 + sqrt(5)/2\n"], "sample_730": ["    def test_multi_task_lasso_cv_sparse_input(self):\n        X, y = load_boston(return_X_y=True)\n        X = sparse.csr_matrix(X)\n        y = np.array(y).reshape(-1, 1)\n        # Repeat y to simulate multi-task output\n        y = np.repeat(y, 3, axis=1)\n        clf = MultiTaskLassoCV().fit(X, y)\n        assert_true(clf.coef_.shape == (3, X.shape[1]))\n"], "sample_315": ["    def test_language_redirect_with_trailing_slash(self):\n        request = RequestFactory().get('/nl/')\n        middleware = LocaleMiddleware()\n        response = middleware.process_request(request)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(translation.get_language(), 'nl')\n"], "sample_482": ["    def test_escapeseq_basic(self):\n        self.assertEqual(\n            self.engine.render_to_string(\"escapeseq_basic\", {\"a\": [\"<p>\"], \"b\": [mark_safe(\"<p>\")]}),\n            \"&lt;p&gt; -- &lt;p&gt;\",\n        )\n"], "sample_849": ["def test_shuffle_split_with_sparse_data():\n    # Test ShuffleSplit with sparse data\n    X = coo_matrix(np.eye(10))\n    y = np.arange(10)\n    ss = ShuffleSplit(n_splits=3, test_size=0.25, random_state=0)\n    for train_index, test_index in ss.split(X, y):\n        assert isinstance(X[train_index], coo_matrix)\n        assert isinstance(X[test_index], coo_matrix)\n"], "sample_1160": ["def test_intersection_complexregion_empty():\n    a = ComplexRegion(Interval(0, 1)*Interval(0, 1))\n    b = ComplexRegion(Interval(2, 3)*Interval(2, 3))\n    assert intersection_sets(a, b) == S.EmptySet\n"], "sample_817": ["    def test_sparse_variance_threshold(self):\n        X = csr_matrix(data)\n        selector = VarianceThreshold(threshold=0.5)\n        selector.fit(X)\n        assert_array_equal(selector.variances_, np.array([0., 0.66666667, 0., 0.66666667, 6.33333333]))\n        assert_array_equal(selector.get_support(), np.array([False, True, False, True, True]))\n"], "sample_984": ["def test_printmethod():\n    class Foo(Expr):\n            return 'foo'\n\n            return 'Foo()'\n\n    f = Foo()\n    assert sstr(f) == 'foo'\n    assert sstr(f, printmethod='_sympyrepr') == 'Foo()'\n"], "sample_512": ["    def test_plot_date_format():\n        fig, ax = plt.subplots()\n        dates = np.arange('2023-01-01', '2023-01-10', dtype='datetime64[D]')\n        values = np.arange(10)\n        ax.plot_date(dates, values, fmt='o-')\n        ax.xaxis.set_major_formatter(mpl.dates.DateFormatter('%Y-%m-%d'))\n        fig.autofmt_xdate()\n        fig.canvas.draw()\n        # Check if the x-axis labels are formatted correctly\n        labels = [t.get_text() for t in ax.get_xticklabels()]\n        expected_labels = ['2023-01-01', '2023-01-02', '2023-01-03',\n                           '2023-01-04', '2023-01-05', '2023-01-06',\n                           '2023-01-07', '2023-01-08', '2023-01-09',\n                           '2023-01-10']\n        assert labels == expected_labels\n"], "sample_892": ["    def test_ada_boost_regressor_sparse_input(self):\n        # Test AdaBoostRegressor with sparse input\n        X_sparse = csc_matrix(diabetes.data)\n        y = diabetes.target\n\n        regressor = AdaBoostRegressor(random_state=rng)\n        regressor.fit(X_sparse, y)\n        y_pred = regressor.predict(X_sparse)\n\n        assert_array_almost_equal(y_pred, regressor.predict(X_sparse.toarray()), 5)\n"], "sample_95": ["    def test_vary_on_headers(self):\n        @vary_on_headers('Accept-Language')\n            return HttpResponse('OK')\n        request = HttpRequest()\n        request.META['HTTP_ACCEPT_LANGUAGE'] = 'en-US'\n        response = view(request)\n        self.assertEqual(response['Vary'], 'Accept-Language')\n"], "sample_76": ["    def test_check_setting_languages_bidi(self):\n        settings.LANGUAGES_BIDI = ['en', 'ar', 'he']\n        self.assertEqual(check_setting_languages_bidi(None, **{}), [])\n\n        settings.LANGUAGES_BIDI = ['en', 123, 'he']\n        errors = check_setting_languages_bidi(None, **{})\\\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, 'translation.E003')\n\n        settings.LANGUAGES_BIDI = ['en', 'ar', 'he', 'invalid']\n        errors = check_setting_languages_bidi(None, **{})\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, 'translation.E003')\n"], "sample_713": ["    def test_ridge_classifier_cv_sparse_multiclass(self):\n        X, y = make_multilabel_classification(n_samples=50,\n                                             n_features=10,\n                                             n_classes=3,\n                                             n_labels=2,\n                                             random_state=0)\n        X = sp.csr_matrix(X)\n        clf = RidgeClassifierCV(alphas=[0.1, 1.0, 10.0], cv=5)\n        clf.fit(X, y)\n        assert_equal(clf.coef_.shape, (3, 10))\n        assert_equal(clf.intercept_.shape, (3,))\n"], "sample_393": ["    def test_makemessages_ignore_patterns(self):\n        copytree(\n            os.path.join(os.path.dirname(__file__), \"test_project\"), self.work_dir\n        )\n        with open(os.path.join(self.work_dir, \"test_project\", \"settings.py\"), \"a\") as f:\n            f.write(\n                '\\n'\n                'LOCALE_PATHS = [\\n'\n                '    os.path.join(BASE_DIR, \"locale\"),\\n'\n                ']'\n            )\n        output, po_contents = self._run_makemessages(\n            ignore_patterns=[\"*.pyc\", \"templates/ignore_me.html\"]\n        )\n        self.assertMsgId(\"This should be extracted\", po_contents)\n        self.assertNotMsgId(\"This should be ignored\", po_contents)\n"], "sample_195": ["    def test_no_transaction_support(self):\n        with self.assertRaises(NotSupportedError):\n            with transaction.atomic():\n                pass\n"], "sample_267": ["    def test_sqlite_regexp(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\"SELECT django_regexp('hello', 'h.llo')\")\n            self.assertTrue(cursor.fetchone()[0])\n            cursor.execute(\"SELECT django_regexp('hello', 'world')\")\n            self.assertFalse(cursor.fetchone()[0])\n"], "sample_85": ["    def test_m2m_delete_cascade(self):\n        # Test that deleting a parent object cascades to related objects\n        # when on_delete=models.CASCADE is used.\n        a = create_a()\n        r1 = R.objects.create(name='r1', a=a)\n        r2 = R.objects.create(name='r2', a=a)\n        r3 = R.objects.create(name='r3', a=a)\n\n        self.assertEqual(R.objects.count(), 3)\n        a.delete()\n        self.assertEqual(R.objects.count(), 0)\n"], "sample_299": ["    def test_check_cache_location_not_exposed_with_staticfiles_dir(self):\n        settings.MEDIA_ROOT = pathlib.Path(__file__).parent / 'media'\n        settings.STATIC_ROOT = pathlib.Path(__file__).parent / 'static'\n        settings.STATICFILES_DIRS = [\n            (None, pathlib.Path(__file__).parent / 'staticfiles'),\n        ]\n        settings.CACHES = {\n            'default': {\n                'BACKEND': 'django.core.cache.backends.filebased.FileBasedCache',\n                'LOCATION': str(pathlib.Path(__file__).parent / 'cache'),\n            },\n        }\n        errors = check_cache_location_not_exposed(None, **{})\n        self.assertEqual(len(errors), 3)\n        for error in errors:\n            self.assertIsInstance(error, Warning)\n            self.assertIn('cache', error.msg)\n            self.assertIn('LOCATION', error.msg)\n"], "sample_759": ["    def test_onehotencoder_inverse_transform_unknown_categories(self):\n        enc = OneHotEncoder(handle_unknown='ignore')\n        X = [['Male', 1], ['Female', 3], ['Female', 2]]\n        enc.fit(X)\n        X_trans = enc.transform([['Female', 4], ['Male', 1]])\n        X_inv = enc.inverse_transform(X_trans)\n        assert_equal(X_inv, [['Female', None], ['Male', 1]])\n"], "sample_90": ["    def test_modelform_with_custom_error_messages(self):\n        form = CustomErrorMessageForm(data={'name1': 'invalid'})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors['name1'], ['Form custom error message.'])\n"], "sample_1146": ["    def test_latex_SetExpr(self):\n        S = FiniteSet(1, 2, 3)\n        self.assertEqual(latex(S), '\\\\left\\{1, 2, 3\\\\right\\}')\n        self.assertEqual(latex(S.complement(UniversalSet())), '\\\\left\\{x \\\\mid x \\\\notin \\\\left\\{1, 2, 3\\\\right\\}\\\\right\\}')\n        self.assertEqual(latex(Union(S, {4, 5})), '\\\\left\\{1, 2, 3, 4, 5\\\\right\\}')\n        self.assertEqual(latex(Intersection(S, {2, 3, 4})), '\\\\left\\{2, 3\\\\right\\}')\n        self.assertEqual(latex(Complement(S, {2, 3, 4})), '\\\\left\\{1\\\\right\\}')\n        self.assertEqual(latex(SymmetricDifference(S, {2, 3, 4})), '\\\\left\\{1, 4\\\\right\\}')\n        self.assertEqual(latex(ProductSet(S, {4, 5})), '\\\\left\\\\{(1, 4), (1, 5), (2, 4), (2, 5), (3, 4), (3, 5)\\\\right\\\\}')\n\n"], "sample_803": ["    def test_roc_auc_score_multiclass(self):\n        # Test roc_auc_score with multiclass data\n        y_true = np.array([0, 1, 2, 0, 1, 2])\n        y_score = np.array([[0.1, 0.8, 0.1],\n                            [0.2, 0.3, 0.5],\n                            [0.7, 0.1, 0.2],\n                            [0.9, 0.05, 0.05],\n                            [0.3, 0.6, 0.1],\n                            [0.1, 0.1, 0.8]])\n        with pytest.raises(ValueError):\n            roc_auc_score(y_true, y_score)\n"], "sample_499": ["    def test_legend_handler_map(self):\n        fig, ax = plt.subplots()\n        x = np.arange(10)\n        y = np.arange(10)\n\n        # Create a custom handler for Line2D\n        class MyHandler(mlegend.HandlerLine2D):\n                               xdescent, ydescent, width, height, fontsize,\n                               trans):\n                # Create a new Line2D instance with different properties\n                return [mlines.Line2D([0], [0], color='red', linestyle='--')]\n\n        # Register the custom handler\n        mlegend.Legend.set_default_handler_map({Line2D: MyHandler()})\n\n        ax.plot(x, y)\n        ax.legend()\n\n        # Check if the custom handler is used\n        for handle in ax.get_legend().legendHandles:\n            assert isinstance(handle, mlines.Line2D)\n            assert handle.get_color() == 'red'\n            assert handle.get_linestyle() == '--'\n\n        # Reset the default handler map\n        mlegend.Legend.set_default_handler_map(\n            mlegend.Legend.get_default_handler_map())\n\n"], "sample_704": ["    def test_iterparentnodeids_empty(self, pytester: Pytester) -> None:\n        item = pytester.makepyfile(\n            \"\"\"\n                pass\n            \"\"\"\n        ).collect()\n        assert list(item.iterparentnodeids()) == [\"\"]\n"], "sample_516": ["    def test_pdf_metadata(self):\n        with NamedTemporaryFile(delete=False) as tmpfile:\n            filename = tmpfile.name\n        metadata = {'Creator': 'My software', 'Author': 'Me',\n                    'Title': 'Awesome'}\n        with PdfPages(filename, metadata=metadata) as pdf:\n            fig, ax = plt.subplots()\n            ax.plot([1, 2, 3], [4, 5, 6])\n            pdf.savefig(fig)\n        with open(filename, 'rb') as f:\n            pdf_content = f.read()\n        os.remove(filename)\n\n        # Check for metadata in the PDF\n        assert b'/Creator' in pdf_content\n        assert b'/Author' in pdf_content\n        assert b'/Title' in pdf_content\n        assert b'My software' in pdf_content\n        assert b'Me' in pdf_content\n        assert b'Awesome' in pdf_content\n"], "sample_332": ["    def test_formset_factory_absolute_max(self):\n        formset_class = formset_factory(Choice, max_num=5, absolute_max=10)\n        formset = formset_class(data={'choices-TOTAL_FORMS': '6', 'choices-0-choice': 'A'})\n        self.assertTrue(formset.is_valid())\n        self.assertEqual(formset.total_form_count(), 6)\n\n        formset_class = formset_factory(Choice, max_num=5, absolute_max=5)\n        formset = formset_class(data={'choices-TOTAL_FORMS': '6', 'choices-0-choice': 'A'})\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(formset.total_form_count(), 5)\n"], "sample_178": ["    def test_formset_factory_absolute_max(self):\n        formset_class = formset_factory(Choice, absolute_max=2)\n        formset = formset_class(data={'choices-TOTAL_FORMS': '3', 'choices-0-choice': 'A', 'choices-1-choice': 'B', 'choices-2-choice': 'C'})\n        self.assertEqual(formset.total_form_count(), 2)\n        self.assertEqual(len(formset.forms), 2)\n"], "sample_189": ["    def test_cache_key_warnings(self):\n        with warnings.catch_warnings(record=True) as w:\n            cache.set('a' * 251, 1)\n            self.assertEqual(len(w), 1)\n            self.assertEqual(str(w[0].message), KEY_ERRORS_WITH_MEMCACHED_MSG % ('a' * 251))\n\n            cache.set('a\\x00b', 1)\n            self.assertEqual(len(w), 2)\n            self.assertEqual(str(w[1].message), KEY_ERRORS_WITH_MEMCACHED_MSG % 'a\\x00b')\n"], "sample_798": ["    def test_ridge_classifier_cv_sparse(self):\n        # Test RidgeClassifierCV with sparse input\n        X = sp.csr_matrix(np.array([[1, 2], [3, 4], [5, 6]]))\n        y = np.array([0, 1, 0])\n        clf = RidgeClassifierCV(alphas=[0.1, 1.0, 10.0]).fit(X, y)\n        assert clf.coef_.shape == (1, 2)\n"], "sample_1059": ["def test_assoc_laguerre_diff():\n    n = Symbol('n', integer=True)\n    a = Symbol('a')\n    assert diff(assoc_laguerre(n, a, x), x) == -assoc_laguerre(n - 1, a + 1, x)\n"], "sample_1007": ["def test_binomial_expand_func():\n    n = Symbol('n', integer=True, positive=True)\n    assert expand_func(binomial(n, 3)) == n*(n - 2)*(n - 1)/6\n"], "sample_908": ["compilation error"], "sample_1026": ["def test_lambdify_tensorflow_matrix():\n    if not tensorflow:\n        skip(\"Tensorflow not installed\")\n    A = MatrixSymbol('A', 2, 2)\n    expr = A[0, 0] + A[1, 1]\n    f = lambdify(A, expr, 'tensorflow')\n    a = tensorflow.constant([[1, 2], [3, 4]])\n    assert f(a).numpy() == 5\n"], "sample_1024": ["def test_sympify_mpmath_complex():\n    x = mpmath.mpc(1, 2)\n    assert sympify(x) == 1 + 2*S.ImaginaryUnit\n"], "sample_712": ["    def test_onehot_sparse_ignore_unknown(self):\n        enc = OneHotEncoder(handle_unknown='ignore', sparse=True)\n        X = [['Male', 1], ['Female', 3], ['Female', 2]]\n        enc.fit(X)\n        X_test = [['Female', 4]]\n        X_trans = enc.transform(X_test)\n        assert_equal(X_trans.shape, (1, 4))\n        assert_array_equal(X_trans.toarray(), [[0., 0., 0., 1.]])\n"], "sample_60": ["    def test_add_media_to_episode(self):\n        response = self.client.get(reverse('admin:generic_inline_admin_episode_add'))\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, 'Add Episode')\n\n        # Submit the form with media\n        data = {\n            'name': 'New Episode',\n            'media-TOTAL_FORMS': '2',\n            'media-INITIAL_FORMS': '0',\n            'media-0-url': 'http://example.com/new_episode.mp3',\n            'media-0-content_type': str(ContentType.objects.get_for_model(Episode).pk),\n            'media-0-object_id': str(self.episode_pk),\n            'media-1-url': 'http://example.com/new_episode_image.png',\n            'media-1-content_type': str(ContentType.objects.get_for_model(Episode).pk),\n            'media-1-object_id': str(self.episode_pk),\n        }\n        response = self.client.post(reverse('admin:generic_inline_admin_episode_add'), data)\n        self.assertEqual(response.status_code, 302)\n\n        # Check if the episode and media were created\n        episode = Episode.objects.get(pk=self.episode_pk)\n        self.assertEqual(episode.name, 'New Episode')\n        self.assertEqual(episode.media.count(), 2)\n"], "sample_939": ["compilation error"], "sample_110": ["    def test_pickle_expression_list(self):\n        qs = Event.objects.filter(\n            models.Q(when__gt=datetime.datetime(2023, 1, 1)) | models.Q(when__isnull=True)\n        )\n        self.assert_pickles(qs)\n"], "sample_1196": ["    def test_Contains_eval_non_Set():\n        x = Symbol('x')\n        raises(TypeError, lambda: Contains(x, 1))\n"], "sample_130": ["    def test_join_promotion_with_or_and_related_field(self):\n        author = Author.objects.create(name='John Doe')\n        item1 = Item.objects.create(author=author, name='Item 1')\n        item2 = Item.objects.create(author=author, name='Item 2')\n        item3 = Item.objects.create(author=author, name='Item 3')\n\n        q = Q(item__name='Item 1') | Q(item__name='Item 2') & Q(item__name='Item 3')\n        qs = Item.objects.filter(q)\n        self.assertQuerysetEqual(qs, [item1, item2, item3], transform=lambda o: o)\n"], "sample_867": ["    def test_parameter_sampler_invalid_input(self):\n        param_distributions = {'foo': [0, 1]}\n        sampler = ParameterSampler(param_distributions, n_iter=2)\n        with pytest.raises(ValueError, match=r\"Parameter 'foo' should be a list\"):\n            sampler.get_params()\n"], "sample_634": ["    def test_expand_modules_ignore_paths_re(self) -> None:\n        ignore_list_paths_re = [re.compile(r\".*test_.*\\.py$\")]\n        files_or_modules = [\"test_module.py\", \"another_module.py\"]\n        result, errors = expand_modules(\n            files_or_modules, [], [], ignore_list_paths_re\n        )\n        assert len(result) == 1\n        assert result[0][\"name\"] == \"another_module\"\n"], "sample_415": ["    def test_unique_constraint_with_expressions(self):\n        with atomic():\n            Product.objects.create(name=\"Foo\", price=10.0)\n            with self.assertRaises(IntegrityError):\n                Product.objects.create(name=\"FOO\", price=10.0)\n\n            Product.objects.create(name=\"Bar\", price=20.0)\n            with self.assertRaises(IntegrityError):\n                Product.objects.create(name=\"bar\", price=20.0)\n\n            # Test case-insensitive uniqueness with Lower function\n            Product.objects.create(name=\"baz\", price=30.0)\n            with self.assertRaises(IntegrityError):\n                Product.objects.create(name=\"BAZ\", price=30.0)\n\n"], "sample_891": ["    def test_top_k_accuracy_score_multiclass_labels(self):\n        y_true = np.array([0, 1, 2, 2])\n        y_score = np.array([[0.5, 0.2, 0.2],\n                           [0.3, 0.4, 0.2],\n                           [0.2, 0.4, 0.3],\n                           [0.7, 0.2, 0.1]])\n        labels = [0, 1, 2]\n        score = top_k_accuracy_score(y_true, y_score, k=2, labels=labels)\n        assert_almost_equal(score, 0.75)\n"], "sample_295": ["    def test_window_function_with_partition_by(self):\n        with CaptureQueriesContext(connection) as queries:\n            list(\n                Company.objects.annotate(\n                    avg_employees=Window(\n                        Avg('num_employees'), partition_by=F('based_in_eu')\n                    )\n                )\n            )\n        self.assertEqual(len(queries), 1)\n"], "sample_17": ["    def test_shape(self):\n        self.check(np.shape, self.q)\n"], "sample_722": ["    def test_mini_batch_kmeans_sparse_input(self):\n        # Test MiniBatchKMeans with sparse input\n        kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=42)\n        kmeans.fit(X_csr)\n        labels = kmeans.labels_\n        assert_equal(labels.shape[0], n_samples)\n        assert_true(np.all(np.unique(labels) < n_clusters))\n        assert_almost_equal(v_measure_score(true_labels, labels), 1.0,\n                            decimal=2)\n\n"], "sample_172": ["    def test_formfield_for_dbfield_uuidfield(self):\n        ff = self.assertFormfield(Company, 'uuid', forms.UUIDField)\n        self.assertEqual(ff.widget.attrs.get('type'), 'text')\n"], "sample_1189": ["def test_lambdify_tensorflow_sparse_matrix():\n    if not tensorflow:\n        skip(\"TensorFlow is not installed.\")\n    A = SparseMatrix([[1, 0, 0], [0, 2, 0], [0, 0, 3]])\n    expr = A * Matrix([x, y, z])\n    f = lambdify(x, expr, 'tensorflow')\n    result = f(tensorflow.constant([1, 2, 3]))\n    assert (result.numpy() == numpy.array([1, 4, 9])).all()\n"], "sample_667": ["    def test_tmpdir_numbered(tmpdir_factory: pathlib.TempPathFactory) -> None:\n        p1 = tmpdir_factory.mktemp(\"foo\")\n        p2 = tmpdir_factory.mktemp(\"foo\")\n        assert p1 != p2\n        assert p1.name.startswith(\"foo-\")\n        assert p2.name.startswith(\"foo-\")\n        assert int(p1.name.split(\"-\")[1]) < int(p2.name.split(\"-\")[1])\n"], "sample_881": ["    def test_top_k_accuracy_score_multiclass_labels_provided(self):\n        y_true = np.array([0, 1, 2, 2])\n        y_score = np.array([[0.5, 0.2, 0.2],\n                           [0.3, 0.4, 0.2],\n                           [0.2, 0.4, 0.3],\n                           [0.7, 0.2, 0.1]])\n        labels = [0, 1, 2]\n        score = top_k_accuracy_score(y_true, y_score, k=2, labels=labels)\n        assert_almost_equal(score, 0.75)\n"], "sample_968": ["def test_parse_annotation():\n    assert _parse_annotation('int') == ('int', [])\n    assert _parse_annotation('List[str]') == ('List', [('str', [])])\n    assert _parse_annotation('Dict[str, int]') == ('Dict', [('str', []), ('int', [])])\n    assert _parse_annotation('Tuple[int, ...]') == ('Tuple', [('int', []), ('...', [])])\n    assert _parse_annotation('Callable[[int, str], float]') == ('Callable', [\n        ([], [('int', []), ('str', [])]),\n        ('float', [])\n    ])\n    assert _parse_annotation('Union[int, str]') == ('Union', [('int', []), ('str', [])])\n    assert _parse_annotation('Optional[int]') == ('Optional', [('int', [])])\n"], "sample_1208": ["def test_MatrixStudentT_sample():\n    from sympy.stats.crv import sample\n    n, p = 2, 2\n    nu = symbols('nu', positive=True)\n    M = MatrixSymbol('M', n, p)\n    Omega = MatrixSymbol('Omega', p, p)\n    Sigma = MatrixSymbol('Sigma', n, n)\n    X = MatrixSymbol('X', n, p)\n\n    T = MatrixStudentT('T', nu, M, Omega, Sigma)\n    pspace = MatrixPSpace('T', T, n, p)\n    # Test sampling\n    raises(NotImplementedError, lambda: sample(T, size=(2,)))\n"], "sample_104": ["    def test_manifest_strict_mode(self):\n        \"\"\"\n        Test that ManifestStaticFilesStorage raises an error if a file is referenced\n        in a template but not present in the manifest.\n        \"\"\"\n        # Create a file that will be referenced in a template but not included in\n        # the static files collection.\n        missing_file_path = os.path.join(TEST_ROOT, 'missing_file.css')\n        with open(missing_file_path, 'w') as f:\n            f.write('/* This file should not be included in the manifest */')\n\n        # Create a template that references the missing file.\n        self.create_template('test_template.html',\n                             '<link rel=\"stylesheet\" href=\"{% static \"missing_file.css\" %}\">')\n\n        # Collect static files.\n        call_command('collectstatic', verbosity=0)\n\n        # Render the template.\n        with self.assertRaises(ValueError) as e:\n            self.render_template('test_template.html')\n\n        self.assertIn(\"Missing staticfiles manifest entry for 'missing_file.css'\", str(e.exception))\n"], "sample_50": ["    def test_runshell_db_with_password(self):\n        dbinfo = {\n            'host': 'localhost',\n            'port': 5432,\n            'database': 'test_db',\n            'user': 'test_user',\n            'password': 'test_password',\n        }\n        args, pgpassword = self._run_it(dbinfo)\n        self.assertEqual(args, ['psql', '-U', 'test_user', '-h', 'localhost', '-p', '5432', 'test_db'])\n        self.assertEqual(pgpassword, 'test_password')\n"], "sample_950": ["def test_parse_annotation_with_complex_types():\n    assert _parse_annotation('List[Tuple[str, int]]') == 'List[Tuple[str, int]]'\n    assert _parse_annotation('Dict[str, Union[int, float]]') == 'Dict[str, Union[int, float]]'\n    assert _parse_annotation('Callable[[str], int]') == 'Callable[[str], int]'\n"], "sample_338": ["    def test_rename_field_with_default(self):\n        before = [\n            self.author_name,\n        ]\n        after = [\n            self.author_name_renamed,\n        ]\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['RenameField'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name', old_name='name')\n\n"], "sample_771": ["    def test_power_transform_yeo_johnson_sparse(self):\n        X = sparse.csr_matrix([[1, 2], [3, 2], [4, 5]])\n        pt = PowerTransformer(method='yeo-johnson')\n        X_trans = pt.fit_transform(X)\n        assert_allclose_dense_sparse(X_trans,\n                                     power_transform(X, method='yeo-johnson'))\n\n"], "sample_769": ["    def test_brier_score_loss_multilabel():\n        # Test brier score loss for multilabel classification\n        X, y = make_multilabel_classification(n_samples=10, n_features=5,\n                                              n_classes=3, random_state=0)\n        y_pred = np.random.rand(10, 3)\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", UndefinedMetricWarning)\n            score = brier_score_loss(y, y_pred)\n        assert score >= 0 and score <= 1\n"], "sample_500": ["    def test_colorbar_extension_ticks(self):\n        # Test that ticks are correctly placed for colorbars with extensions.\n        cmap, norms = _get_cmap_norms()\n        fig, axs = plt.subplots(2, 2)\n        for i, extension_type in enumerate(('neither', 'min', 'max', 'both')):\n            norm = norms[extension_type]\n            boundaries = norm.boundaries\n            values = boundaries[:-1]\n            cb = Colorbar(axs[i // 2, i % 2], cmap=cmap, norm=norm,\n                          boundaries=boundaries, values=values,\n                          extend=extension_type, extendfrac=0.1)\n            cb.set_ticks(values[::2])\n            # Check that the ticks are correctly placed.\n            assert_allclose(cb.ax.get_yticks(), values[::2])\n"], "sample_628": ["    def test_spelling_ignore_words(self):\n        self.checker.ignore_list = [\"pylint\", \"test\"]\n        self._check_spelling(\"wrong-spelling-in-comment\", \"# This is a test pylint comment\", 1)\n        self.assertNoMessages()\n"], "sample_972": ["    def test_restify_union_with_none():\n        assert restify(Union[int, None]) == 'Optional[int]'\n        assert restify(Union[None, str]) == 'Optional[str]'\n        assert restify(Union[int, None, str]) == 'Optional[Union[int, str]]'\n"], "sample_517": ["    def test_annotation_arrowprops_mutation_scale(self):\n        fig, ax = plt.subplots()\n        text = ax.annotate(\"test\", (0.5, 0.5), xycoords=\"axes fraction\",\n                           arrowprops=dict(arrowstyle=\"->\",\n                                           mutation_scale=20))\n        fig.canvas.draw()\n        bbox = text.arrow_patch.get_window_extent()\n        assert bbox.width > 100  # Check if arrow is scaled\n"], "sample_723": ["    def test_sparse_fit_transform_zero_missing_values(self):\n        # Test that fit_transform works correctly when missing_values=0\n        X = sparse.csr_matrix([[1, 0, 2], [0, 3, 0], [4, 0, 6]])\n        X_true = X.copy()\n        missing_values = 0\n        strategy = 'mean'\n        statistics = np.array([2., 3., 4.])\n\n        _check_statistics(X, X_true, strategy, statistics, missing_values)\n"], "sample_165": ["    def test_modelmultiplechoicefield_invalid_list(self):\n        class MyForm(Form):\n            choices = ModelMultipleChoiceField(ChoiceModel.objects.all())\n\n        form = MyForm({'choices': 'a,b,c'})\n        self.assertFormErrors(\n            [\n                'Enter a list of values.',\n            ],\n            form.full_clean,\n        )\n"], "sample_875": ["def test_brier_score_loss_pos_label_string():\n    y_true = np.array([\"spam\", \"ham\", \"ham\", \"spam\"])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    with pytest.raises(ValueError):\n        brier_score_loss(y_true, y_prob)\n"], "sample_1200": ["    def test_get_dimensional_expr(self):\n        x = Symbol('x')\n        v = Symbol('v')\n        t = Symbol('t')\n        a = Symbol('a')\n        m = Symbol('m')\n        F = Symbol('F')\n\n        # Test basic units\n        assert SI.get_dimensional_expr(meter) == length\n        assert SI.get_dimensional_expr(second) == time\n        assert SI.get_dimensional_expr(kilogram) == mass\n\n        # Test derived units\n        assert SI.get_dimensional_expr(velocity) == length / time\n        assert SI.get_dimensional_expr(acceleration) == length / (time**2)\n        assert SI.get_dimensional_expr(force) == mass * length / (time**2)\n\n        # Test expressions with symbols\n        assert SI.get_dimensional_expr(x * meter) == length\n        assert SI.get_dimensional_expr(v * meter / second) == length / time\n        assert SI.get_dimensional_expr(a * meter / (second**2)) == length / (time**2)\n        assert SI.get_dimensional_expr(F * kilogram * meter / (second**2)) == mass * length / (time**2)\n\n        # Test expressions with functions\n        assert SI.get_dimensional_expr(sin(x * meter)) == S.One\n        assert SI.get_dimensional_expr(exp(t * second)) == S.One\n        assert SI.get_dimensional_expr(log(m * kilogram)) == S.One\n\n        # Test expressions with derivatives\n        assert SI.get_dimensional_expr(diff(x * meter, t)) == length / time\n        assert SI.get_dimensional_expr(diff(v * meter / second, t)) == length / (time**2)\n\n        # Test expressions with integrals\n        assert SI.get_dimensional_expr(integrate(v * meter / second, t)) == length\n"], "sample_146": ["    def test_check_setting_language_code_invalid(self):\n        with override_settings(LANGUAGE_CODE=123):\n            errors = check_setting_language_code(None, **{})\n            self.assertEqual(len(errors), 1)\n            self.assertIsInstance(errors[0], Error)\n            self.assertEqual(errors[0].id, 'translation.E001')\n"], "sample_166": ["    def test_salted_hmac_invalid_algorithm(self):\n        with self.assertRaises(InvalidAlgorithm):\n            salted_hmac('test_salt', 'test_value', algorithm='invalid_algorithm')\n"], "sample_855": ["def test_dummy_regressor_constant_sparse():\n    X = np.array([[0], [0], [0], [0]])\n    y = sp.csr_matrix([[1, 0, 5, 4, 3],\n                       [2, 0, 1, 2, 5],\n                       [1, 0, 4, 5, 2],\n                       [1, 3, 3, 2, 0]])\n    clf = DummyRegressor(strategy=\"constant\", constant=y[0])\n    clf.fit(X, y)\n    y_pred = clf.predict(X)\n    assert_array_equal(y_pred, y[0])\n"], "sample_41": ["    def test_unit_format_latex_with_unicode():\n        \"\"\"Test that latex formatting works with unicode characters.\"\"\"\n        with catch_warnings() as w:\n            u.Unit('\u03bcm', format={'latex': r'\\mu m'})\n        assert len(w) == 0\n"], "sample_591": ["    def test_merge_empty_datasets(self):\n        ds1 = xr.Dataset()\n        ds2 = xr.Dataset(data_vars={'a': ('x', [1, 2])})\n        actual = merge([ds1, ds2])\n        expected = ds2.copy()\n        assert_identical(actual, expected)\n"], "sample_880": ["    def test_type_of_target_multilabel_sequences(self):\n        for y in MULTILABEL_SEQUENCES:\n            assert type_of_target(y) == \"multilabel-indicator\"\n"], "sample_301": ["    def test_iter_modules_and_files_zipfile(self):\n        with tempfile.NamedTemporaryFile(suffix='.zip') as zip_file:\n            zip_filename = zip_file.name\n            with zipfile.ZipFile(zip_filename, 'w') as zipf:\n                zipf.writestr('test_module.py', 'pass')\n            self.import_and_cleanup('test_module')\n            self.assertFileFound(Path(zip_filename) / 'test_module.py')\n"], "sample_710": ["    def test_pytest_pycollect_makeitem_skip_unittest_class(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import unittest\n\n            class TestClass(unittest.TestCase):\n                @unittest.skip(\"skip this class\")\n                    pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.assert_outcomes(skipped=1)\n        assert \"skip this class\" in result.stdout.str()\n"], "sample_67": ["    def test_modelform_with_custom_error_message(self):\n        form = CustomErrorMessageForm(data={'name1': 'invalid'})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors['name1'], ['Form custom error message.'])\n"], "sample_535": ["    def test_custom_cell(fig, ax):\n        cell = CustomCell((0, 0), width=0.5, height=0.5,\n                          facecolor='r', edgecolor='k',\n                          text='Hello', loc='center')\n        table = Table(ax, loc='upper left')\n        table.add_cell(0, 0, cell)\n        table.auto_set_column_width(0)\n        table.scale(1, 1)\n        return fig\n"], "sample_688": ["    def test_bestrelpath_absolute_paths_different_drives(self, testdir: Testdir) -> None:\n        testdir.makefile(\".txt\", content=\"hello\")\n        p1 = Path(\"C:/some/path\")\n        p2 = Path(\"D:/another/path\")\n        assert bestrelpath(p1, p2) == str(p2)\n"], "sample_228": ["    def test_formset_factory_absolute_max(self):\n        formset_class = formset_factory(Choice, absolute_max=3)\n        formset = formset_class(data={'choices-0-choice': 'a', 'choices-1-choice': 'b', 'choices-2-choice': 'c',\n                                     'choices-TOTAL_FORMS': '4'})\n        self.assertEqual(formset.errors, [])\n        self.assertEqual(formset.total_form_count(), 3)\n\n        formset = formset_class(data={'choices-0-choice': 'a', 'choices-1-choice': 'b', 'choices-2-choice': 'c',\n                                     'choices-3-choice': 'd', 'choices-TOTAL_FORMS': '4'})\n        self.assertEqual(len(formset.errors), 1)\n        self.assertEqual(formset.errors[0].code, 'too_many_forms')\n        self.assertEqual(formset.total_form_count(), 3)\n"], "sample_694": ["def test_nose_support(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n            assert 1 == 1\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n    result.stdout.fnmatch_lines(\n        [\n            \"*Support for nose tests is deprecated*\",\n            \"*is using nose method: `test_nose`*\",\n        ]\n    )\n"], "sample_617": ["    def test_polyval_dataset(self, dim):\n        coords = xr.Dataset(\n            {\n                dim: np.arange(5),\n                \"other\": np.arange(5),\n            }\n        )\n        coeffs = xr.Dataset(\n            {\n                \"degree\": np.arange(3),\n                \"other\": np.arange(3),\n            }\n        )\n        result = xr.polyval(coords[dim], coeffs, degree_dim=\"degree\")\n        assert_identical(result[dim], np.polyval(coeffs[\"degree\"].values, coords[dim].values))\n        assert_identical(result[\"other\"], coeffs[\"other\"])\n\n"], "sample_431": ["    def test_get_or_create_with_defaults(self):\n        with self.assertNumQueries(1):\n            obj, created = Article.objects.get_or_create(\n                headline=\"Test headline\",\n                defaults={\"pub_date\": datetime.now() - timedelta(days=1)},\n            )\n        self.assertTrue(created)\n        self.assertEqual(obj.headline, \"Test headline\")\n        self.assertIsNotNone(obj.pub_date)\n\n        with self.assertNumQueries(0):\n            obj, created = Article.objects.get_or_create(headline=\"Test headline\")\n        self.assertFalse(created)\n        self.assertEqual(obj.headline, \"Test headline\")\n"], "sample_1155": ["    def test_construct_domain_algebraic_extension_with_floats():\n        K, coeffs = construct_domain([sqrt(2), Float(1.23)], extension=True)\n        assert K == QQ.algebraic_field((sqrt(2), sqrt(2)))\n        assert coeffs[0] == K.from_sympy(sqrt(2))\n        assert coeffs[1] == K.from_sympy(Float(1.23))\n"], "sample_1147": ["def test_latex_SetExpr():\n    S = FiniteSet(1, 2, 3)\n    assert latex(S) == '\\\\left\\{1, 2, 3\\\\right\\}'\n    assert latex(S, mode='inline') == '$\\{1, 2, 3\\}$'\n    assert latex(S.union(FiniteSet(4, 5))) == '\\\\left\\{1, 2, 3, 4, 5\\\\right\\}'\n    assert latex(S.intersect(FiniteSet(2, 3, 4))) == '\\\\left\\{2, 3\\\\right\\}'\n    assert latex(S.complement(UniversalSet())) == '\\\\mathbb{U} \\\\setminus \\\\left\\{1, 2, 3\\\\right\\}'\n\n"], "sample_513": ["    def test_legend_bbox_to_anchor(self):\n        fig, ax = plt.subplots()\n        ax.plot([1, 2, 3], [4, 5, 6], label='Line 1')\n        ax.plot([1, 2, 3], [1, 2, 3], label='Line 2')\n        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\n"], "sample_5": ["    def test_model_bounding_box(self):\n        for model_data in MODELS:\n            model_class = model_data['class']\n            model = model_class(**model_data['parameters'])\n            if model_data.get('bounding_box') is not False:\n                bbox = model.bounding_box\n                assert isinstance(bbox, ModelBoundingBox)\n                assert bbox.is_finite\n                if isinstance(bbox.xmin, u.Quantity):\n                    assert bbox.xmin.unit == model.inputs[0].unit\n                if isinstance(bbox.xmax, u.Quantity):\n                    assert bbox.xmax.unit == model.inputs[0].unit\n                if len(model.inputs) > 1:\n                    if isinstance(bbox.ymin, u.Quantity):\n                        assert bbox.ymin.unit == model.inputs[1].unit\n                    if isinstance(bbox.ymax, u.Quantity):\n                        assert bbox.ymax.unit == model.inputs[1].unit\n            else:\n                assert model.bounding_box is None\n"], "sample_554": ["    def test_annotation_clip(self):\n        fig, ax = plt.subplots()\n        ax.plot([0, 1], [0, 1])\n        ann = ax.annotate(\"Test\", xy=(2, 2), xycoords='data',\n                          annotation_clip=True)\n        fig.canvas.draw()\n        assert ann.get_visible() is False\n\n        ann.set_annotation_clip(False)\n        fig.canvas.draw()\n        assert ann.get_visible() is True\n"], "sample_1144": ["    def test_requires_partial_no_free_symbols():\n        x, y = symbols('x y')\n        expr = exp(x*y)\n        assert requires_partial(expr) == True\n"], "sample_1080": ["    def test_refine_Pow_complex_base():\n        x = Symbol('x', real=True)\n        y = Symbol('y', real=True)\n        assert refine( (1 + I)**x, Q.real(x)) == (1 + I)**x\n        assert refine( (1 + I)**y, Q.positive(y)) == (1 + I)**y\n        assert refine( (1 + I)**y, Q.negative(y)) == (1 + I)**y\n"], "sample_107": ["    def test_callable_setting_wrapper_repr(self):\n        class MyCallable:\n                return 'MyCallable'\n        wrapper = CallableSettingWrapper(MyCallable())\n        self.assertEqual(repr(wrapper), 'MyCallable')\n"], "sample_552": ["    def test_figure_dpi_set_get(self):\n        fig = Figure()\n        assert fig.dpi == mpl.rcParams['figure.dpi']\n        fig.dpi = 100\n        assert fig.dpi == 100\n"], "sample_556": ["    def test_figure_dpi_set_get(self):\n        fig = Figure()\n        assert fig.dpi == mpl.rcParams['figure.dpi']\n        fig.dpi = 100\n        assert fig.dpi == 100\n"], "sample_840": ["    def test_plssvd_fit_transform(self):\n        X, y = load_linnerud(return_X_y=True)\n        pls = PLSSVD(n_components=2)\n        X_c, y_c = pls.fit_transform(X, y)\n        assert X_c.shape == (X.shape[0], 2)\n        assert y_c.shape == (y.shape[0], 2)\n"], "sample_291": ["    def test_view_as_view_initkwargs(self):\n        view = views.SimpleView.as_view(parameter='value')\n        instance = view(self.rf.get('/'))\n        self.assertEqual(instance.parameter, 'value')\n"], "sample_542": ["    def test_annotation_arrowprops_mutation_scale(self):\n        fig, ax = plt.subplots()\n        text = ax.annotate(\"Test\", (0.5, 0.5), xycoords='axes fraction',\n                           arrowprops=dict(arrowstyle='->',\n                                           mutation_scale=20))\n        fig.canvas.draw()\n        # Check if the arrow is scaled correctly\n        assert text.arrow_patch.get_mutation_scale() == 20\n"], "sample_780": ["    def test_partial_fit_online_learning(self):\n        n_components, X = _build_sparse_mtx()\n        lda = LatentDirichletAllocation(n_components=n_components,\n                                       learning_method='online',\n                                       batch_size=2,\n                                       max_iter=10,\n                                       random_state=0)\n        lda.partial_fit(X)\n        lda.partial_fit(X)\n        assert_greater_equal(lda.n_iter_, 2)\n"], "sample_15": ["    def test_trigonometric(test):\n        assert_allclose(test.f(*test.q_in), test.q_out)\n"], "sample_489": ["    def test_bulk_create_with_custom_pk(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\"SELECT MAX(id) FROM django_migrations\")\n            max_id = cursor.fetchone()[0]\n        Pizzeria.objects.bulk_create(\n            [\n                Pizzeria(name=\"Pizza Hut\", founded=1958),\n                Pizzeria(name=\"Domino's\", founded=1960),\n            ]\n        )\n        with connection.cursor() as cursor:\n            cursor.execute(\"SELECT MAX(id) FROM django_migrations\")\n            self.assertEqual(cursor.fetchone()[0], max_id)\n\n"], "sample_958": ["def test_cpp_function_template():\n    check('function',\n          'template <typename T> void func(T t);',\n          {1: 'func', 2: 'func__T'},\n          'void func(T t);',\n          key='func',\n          asTextOutput='void func(T t)')\n"], "sample_306": ["    def test_parse_datetime_with_timezone(self):\n        dt_str = '2023-10-27T12:34:56+02:00'\n        dt = parse_datetime(dt_str)\n        self.assertEqual(dt.year, 2023)\n        self.assertEqual(dt.month, 10)\n        self.assertEqual(dt.day, 27)\n        self.assertEqual(dt.hour, 12)\n        self.assertEqual(dt.minute, 34)\n        self.assertEqual(dt.second, 56)\n        self.assertEqual(dt.tzinfo.utcoffset(dt).total_seconds(), 7200)\n"], "sample_214": ["    def test_key_transform_isnull_with_null_value(self):\n        obj = JSONModel.objects.create(data={'key': None})\n        self.assertTrue(JSONModel.objects.filter(data__key__isnull=True).exists())\n        self.assertFalse(JSONModel.objects.filter(data__key__isnull=False).exists())\n"], "sample_629": ["    def test_expand_modules_ignore_list_re(self):\n        files_or_modules = [\"test_module.py\", \"test_package/test_module.py\"]\n        ignore_list = []\n        ignore_list_re = [re.compile(r\"^test_package\")]\n        ignore_list_paths_re = []\n        result, errors = expand_modules(\n            files_or_modules, ignore_list, ignore_list_re, ignore_list_paths_re\n        )\n        assert len(result) == 1\n        assert result[0][\"name\"] == \"test_module\"\n"], "sample_799": ["    def test_cross_val_score_with_sparse_data_and_extra_fit_params(self):\n        # Test cross_val_score with sparse data and extra fit parameters\n        clf = MockClassifier(allow_nd=True)\n        scores = cross_val_score(clf, X_sparse, y, cv=3,\n                                scoring='accuracy',\n                                fit_params={'dummy_int': 1,\n                                            'dummy_str': 'str',\n                                            'dummy_obj': object()})\n        assert_array_almost_equal(scores, [1. / 1.1, 1. / 1.1, 1. / 1.1],\n                                 decimal=2)\n\n"], "sample_831": ["    def test_export_text_max_depth(self):\n        clf = DecisionTreeClassifier(max_depth=3).fit(X, y)\n        # Test max_depth truncation\n        report = export_text(clf, max_depth=1)\n        assert_in(\"truncated branch\", report)\n        report = export_text(clf, max_depth=3)\n        assert_not_in(\"truncated branch\", report)\n"], "sample_265": ["    def test_get_templatetag_libraries(self):\n        # Test with custom libraries\n        custom_libraries = {'my_library': 'my_app.templatetags.my_library'}\n        engine = self.engine_class({'OPTIONS': {'libraries': custom_libraries}})\n        libraries = engine.get_templatetag_libraries(custom_libraries)\n        self.assertIn('my_library', libraries)\n\n        # Test with installed libraries\n        engine = self.engine_class({'OPTIONS': {}})\n        libraries = engine.get_templatetag_libraries({})\n        self.assertIn('i18n', libraries)\n"], "sample_641": ["compilation error"], "sample_365": ["    def test_cached_property_name_argument(self):\n        class MyClass:\n                self.value = value\n\n            @cached_property\n                return self.value * 2\n\n        obj = MyClass(5)\n        self.assertEqual(obj.my_property, 10)\n        obj.value = 10\n        self.assertEqual(obj.my_property, 10)  # Should return cached value\n"], "sample_1183": ["    def test_field_from_expr(self):\n        F, x = field('x', ZZ)\n        f = F.from_expr(x**2 + 1)\n        assert f.numer == Poly.from_expr(x**2 + 1, x)\n        assert f.denom == Poly.from_expr(1, x)\n        assert f == F.new(x**2 + 1, 1)\n\n"], "sample_188": ["    def test_window_frame_start_end(self):\n        with connection.cursor() as cursor:\n            # Test RowRange\n            row_range = RowRange(start=2, end=4)\n            start, end = row_range.window_frame_start_end(connection, 2, 4)\n            self.assertEqual(start, '2 FOLLOWING')\n            self.assertEqual(end, '4 FOLLOWING')\n\n            row_range = RowRange(start=-1, end=None)\n            start, end = row_range.window_frame_start_end(connection, -1, None)\n            self.assertEqual(start, '1 PRECEDING')\n            self.assertEqual(end, 'UNBOUNDED FOLLOWING')\n\n            # Test ValueRange\n            value_range = ValueRange(start=2, end=4)\n            start, end = value_range.window_frame_start_end(connection, 2, 4)\n            self.assertEqual(start, '2 FOLLOWING')\n            self.assertEqual(end, '4 FOLLOWING')\n\n            value_range = ValueRange(start=-1, end=None)\n            start, end = value_range.window_frame_start_end(connection, -1, None)\n            self.assertEqual(start, '1 PRECEDING')\n            self.assertEqual(end, 'UNBOUNDED FOLLOWING')\n"], "sample_801": ["    def test_pprint_pipeline(self):\n        pipe = make_pipeline(\n            StandardScaler(),\n            SelectKBest(chi2, k=10),\n            LogisticRegressionCV()\n        )\n        expected = (\n            \"Pipeline(steps=[('standardscaler', StandardScaler()),\\n\"\n            \"                ('selectkbest', SelectKBest(k=10, score_func=<function chi2 at 0x...>)),\\n\"\n            \"                ('logisticregressioncv', LogisticRegressionCV())])\"\n        )\n        assert re.sub(r'0x\\w+', '0x...', repr(pipe)) == expected\n"], "sample_729": ["    def test_multi_task_lasso_cv_sparse_input(self):\n        X, y = load_boston(return_X_y=True)\n        X = sparse.csr_matrix(X)\n        y = np.array(y).reshape(-1, 1)\n        clf = MultiTaskLassoCV()\n        clf.fit(X, y)\n        assert_equal(clf.coef_.shape, (1, X.shape[1]))\n"], "sample_1003": ["def test_Options_clone():\n    opt = Options((x, y, z), {'domain': 'ZZ'})\n    opt2 = opt.clone({'domain': 'QQ'})\n    assert opt2['domain'] == QQ\n    assert opt['domain'] == ZZ\n"], "sample_264": ["    def test_cookie_storage_legacy_hash_invalid(self):\n        storage = self.storage_class(self.request)\n        message = Message(\n            'This is a test message.', constants.INFO, extra_tags='test'\n        )\n        set_cookie_data(storage, [message])\n        # Modify the cookie data to make the hash invalid.\n        storage.request.COOKIES[CookieStorage.cookie_name] = storage.request.COOKIES[CookieStorage.cookie_name][:-1]\n        messages = storage.get_messages()\n        self.assertEqual(messages, [])\n"], "sample_64": ["    def test_getlist(self):\n        qd = QueryDict('a=1&a=2&b=3')\n        self.assertEqual(qd.getlist('a'), ['1', '2'])\n        self.assertEqual(qd.getlist('b'), ['3'])\n        self.assertEqual(qd.getlist('c'), [])\n"], "sample_905": ["    def test_stringify_signature_unqualified_typehints(self):\n        sig = inspect.signature(lambda x: x, unqualified_typehints=True)\n        assert stringify_signature(sig, unqualified_typehints=True) == '(x)'\n"], "sample_418": ["    def test_length_is_filter(self):\n        template = self.engine.from_string('{% load templatetags %}'\n                                          '{% if some_list|length_is:\"4\" %}Four{% endif %}')\n        self.assertEqual(template.render({'some_list': [1, 2, 3, 4]}), 'Four')\n"], "sample_163": ["    def test_password_reset_confirm_token_in_session(self):\n        # Test that the token is stored in the session and used for password reset.\n        self.client.force_login(self.u1)\n        response = self.client.post(reverse(\"password_reset\"), {\"email\": self.u1.email})\n        self.assertRedirects(response, reverse(\"password_reset_done\"))\n        uidb64 = response.url.split(\"/\")[-2]\n        token = response.url.split(\"/\")[-1]\n        self.client.logout()\n\n        # Access the password reset confirm view with the token in the URL.\n        response = self.client.get(\n            reverse(\"password_reset_confirm\", kwargs={\"uidb64\": uidb64, \"token\": token})\n        )\n        self.assertEqual(response.status_code, 200)\n        self.assertIn(INTERNAL_RESET_SESSION_TOKEN, self.client.session)\n        self.assertEqual(self.client.session[INTERNAL_RESET_SESSION_TOKEN], token)\n\n        # Access the password reset confirm view with the reset token.\n        response = self.client.get(\n            reverse(\n                \"password_reset_confirm\", kwargs={\"uidb64\": uidb64, \"token\": \"set-password\"}\n            )\n        )\n        self.assertEqual(response.status_code, 200)\n        self.assertIn(INTERNAL_RESET_SESSION_TOKEN, self.client.session)\n        self.assertEqual(self.client.session[INTERNAL_RESET_SESSION_TOKEN], token)\n\n"], "sample_768": ["def test_stratified_shuffle_split_with_sparse_data():\n    X = coo_matrix(np.eye(5))\n    y = np.array([0, 0, 1, 1, 2])\n    sss = StratifiedShuffleSplit(n_splits=3, test_size=0.25, random_state=0)\n    for train_index, test_index in sss.split(X, y):\n        assert_array_equal(X[train_index].toarray(),\n                           X.toarray()[train_index])\n        assert_array_equal(X[test_index].toarray(),\n                           X.toarray()[test_index])\n"], "sample_847": ["    def test_multitask_lasso_cv_sparse(self):\n        X, y = load_boston(return_X_y=True)\n        X = sparse.csr_matrix(X)\n        y = np.array(y).reshape(-1, 1)\n        n_samples, n_features = X.shape\n\n        clf = MultiTaskLassoCV(cv=3).fit(X, y)\n        assert clf.coef_.shape == (1, n_features)\n        assert clf.intercept_.shape == (1,)\n\n        # Test with multi-output\n        y = np.concatenate((y, y), axis=1)\n        clf = MultiTaskLassoCV(cv=3).fit(X, y)\n        assert clf.coef_.shape == (2, n_features)\n        assert clf.intercept_.shape == (2,)\n"], "sample_755": ["    def test_silhouette_samples_sparse_input(self):\n        X, y = datasets.make_blobs(n_samples=100, random_state=42)\n        X_sparse = csr_matrix(X)\n        silhouette_samples(X_sparse, y)\n"], "sample_1046": ["def test_riemann_cyclic_replace():\n    Lorentz = TensorIndexType('Lorentz', dummy_fmt='L')\n    i, j, k, l = tensor_indices('i,j,k,l', Lorentz)\n    R = tensorhead('R', [Lorentz]*4, [[2, 2]])\n    t = R(i,j,k,l)*(R(-i,-j,-k,-l) - 2*R(-i,-k,-j,-l))\n    t = riemann_cyclic_replace(t)\n    assert t.equals(0)\n"], "sample_672": ["    def test_saferepr_maxsize():\n        class Foo:\n                return \"a\" * 500\n\n        assert len(saferepr(Foo())) < 240\n"], "sample_802": ["    def test_pipeline_memory_cache(self):\n        # Test that the pipeline caches the fitted transformers when memory is\n        # provided.\n        memory = Memory(location=mkdtemp(), verbose=0)\n        X = np.random.randn(10, 5)\n        y = np.random.randint(0, 2, size=10)\n\n        # Create a pipeline with a transformer that stores the timestamp of\n        # its last fit\n        pipeline = Pipeline([('dummy', DummyTransf()), ('clf', SVC())],\n                            memory=memory)\n\n        # First fit\n        pipeline.fit(X, y)\n        first_timestamp = pipeline.named_steps['dummy'].timestamp_\n\n        # Second fit should load from cache\n        pipeline.fit(X, y)\n        second_timestamp = pipeline.named_steps['dummy'].timestamp_\n\n        assert first_timestamp == second_timestamp\n\n        # Clean up the temporary directory\n        shutil.rmtree(memory.location)\n"], "sample_197": ["    def test_timesince_aware_datetime(self):\n        with translation.override('en'):\n            now = timezone.now()\n            past = now - self.oneday\n            self.assertEqual(timesince(past), '1 day')\n            self.assertEqual(timesince(past, now=now), '1 day')\n"], "sample_1182": ["    def test_print_MatrixSolve(self):\n        A = MatrixSymbol('A', 3, 3)\n        b = MatrixSymbol('b', 3, 1)\n        x = MatrixSymbol('x', 3, 1)\n        eq = Eq(A*x, b)\n        sol = MatrixSolve(eq, x)\n        code = SymPyPrinter().doprint(sol)\n        assert code == 'sympy.solve(Eq(A*x, b), x)'\n"], "sample_37": ["    def test_maps_001(self):\n        with warnings.catch_warnings():\n            warnings.simplefilter('ignore', UserWarning)\n            with fits.open(self._file_list[0]) as hdul:\n                w = wcs.WCS(hdul[0].header)\n                assert w.naxis == 2\n                assert w.wcs.ctype[0] == 'RA---TAN'\n                assert w.wcs.ctype[1] == 'DEC--TAN'\n"], "sample_870": ["    def test_predict_with_fixed_kernel(self, kernel):\n        # Test prediction with a kernel where some hyperparameters are fixed.\n        gpr = GaussianProcessRegressor(kernel=kernel, alpha=0.1)\n        gpr.fit(X, y)\n        y_pred, sigma = gpr.predict(X2, return_std=True)\n        assert_array_almost_equal(y_pred, f(X2).ravel(), decimal=2)\n        assert sigma.shape == (X2.shape[0],)\n"], "sample_726": ["    def test_label_binarize_multioutput_error(self):\n        y = np.array([[1, 0], [0, 1]])\n        assert_raises(ValueError, label_binarize, y, classes=[0, 1],\n                      multioutput='raw_values')\n"], "sample_862": ["    def test_tfidf_vectorizer_vocabulary_consistency(self):\n        # Check that vocabulary is consistent across fit and fit_transform\n        corpus = [\"This is the first document.\",\n                  \"This document is the second document.\",\n                  \"And this is the third one.\",\n                  \"Is this the first document?\"]\n\n        vectorizer = TfidfVectorizer()\n        vectorizer.fit(corpus)\n        vocab1 = vectorizer.vocabulary_\n\n        vectorizer = TfidfVectorizer()\n        vectorizer.fit_transform(corpus)\n        vocab2 = vectorizer.vocabulary_\n\n        assert vocab1 == vocab2\n"], "sample_79": ["    def test_pluralize_with_comma(self):\n        self.check_values(\n            (0, 'classes'),\n            (1, 'class'),\n            (2, 'classes'),\n        )\n"], "sample_70": ["    def test_cascade_delete_with_m2m_relation(self):\n        \"\"\"\n        Test cascading deletion when a model has a ManyToManyField with\n        on_delete=CASCADE.\n        \"\"\"\n        m2m_to = M2MTo.objects.create()\n        m2m_from1 = M2MFrom.objects.create(name='m2m_from1', m2m_to=m2m_to)\n        m2m_from2 = M2MFrom.objects.create(name='m2m_from2', m2m_to=m2m_to)\n        m2m_to.delete()\n        self.assertFalse(M2MFrom.objects.filter(pk=m2m_from1.pk).exists())\n        self.assertFalse(M2MFrom.objects.filter(pk=m2m_from2.pk).exists())\n"], "sample_1011": ["def test_octave_code_piecewise_no_default():\n    pw = Piecewise((x + 1, x > 0), (x, x < 0))\n    raises(ValueError, lambda: octave_code(pw, assign_to=x))\n"], "sample_298": ["    def test_token_expires(self):\n        user = User.objects.create_user(username='testuser', password='password')\n        generator = MockedPasswordResetTokenGenerator(now=datetime.now())\n        token = generator.make_token(user)\n        self.assertTrue(generator.check_token(user, token))\n        # Advance time beyond the timeout\n        generator._now_val = generator._now_val + timedelta(seconds=11)\n        self.assertFalse(generator.check_token(user, token))\n"], "sample_80": ["    def test_join_promotion_negated_or(self):\n        query = Query(Item.objects.model)\n        query.add_filter(Q(author__name='John') | Q(author__name='Jane'))\n        query.add_filter(~Q(author__name='John'))\n        join_promoter = JoinPromoter(OR, 2, True)\n        join_promoter.add_votes(['author'])\n        join_promoter.update_join_types(query)\n        self.assertEqual(query.alias_map['author'].join_type, 'LOUTER')\n"], "sample_675": ["    def test_log_level_setting(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import logging\n            import pytest\n\n                logging.info(\"This is an info message\")\n                logging.debug(\"This is a debug message\")\n\n            @pytest.mark.parametrize(\"log_level\", [\"INFO\", \"DEBUG\"])\n                with pytest.raises(SystemExit):\n                    pytest.main([\"-v\", \"--log-level\", log_level, \"test_log_level.py\"])\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        assert result.ret == 0\n"], "sample_475": ["    def test_raw_id_fields_with_related_lookup(self):\n        class MyModelAdmin(ModelAdmin):\n            raw_id_fields = ('related_field',)\n\n        class MyModel(Model):\n            related_field = ForeignKey(User, on_delete=CASCADE)\n\n        self.assertIsInvalid(\n            MyModelAdmin,\n            MyModel,\n            msg=r\"The value of 'raw_id_fields' refers to 'related_field', which is a ForeignKey. \"\n            r\"You should use 'related_lookup_fields' instead.\",\n            id=\"admin.E131\",\n        )\n"], "sample_413": ["    def test_check_setting_app_dirs_loaders(self):\n        errors = check_setting_app_dirs_loaders(None, **{})\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, E001.id)\n"], "sample_161": ["    def test_check_ignored_options(self):\n        class MyModel(models.Model):\n            name = models.CharField(max_length=100)\n            friends = models.ManyToManyField('self', through='Friendship', null=True)\n\n        class Friendship(models.Model):\n            from_friend = models.ForeignKey(MyModel, on_delete=models.CASCADE, related_name='outgoing_friendships')\n            to_friend = models.ForeignKey(MyModel, on_delete=models.CASCADE, related_name='incoming_friendships')\n\n        errors = MyModel._meta.get_field('friends').check(from_model=MyModel)\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], DjangoWarning)\n        self.assertIn('null has no effect on ManyToManyField.', errors[0].msg)\n\n"], "sample_229": ["    def test_union_with_different_fields(self):\n        qs1 = Number.objects.values('num')\n        qs2 = Number.objects.values('other_num')\n        union_qs = qs1.union(qs2)\n        self.assertQuerysetEqual(union_qs, list(qs1) + list(qs2), lambda x: x['num'] if 'num' in x else x['other_num'])\n"], "sample_797": ["    def test_quantile_transform_sparse_input(self):\n        X = sparse_random(10, 5, density=0.5, format='csr', random_state=0)\n        for ignore_implicit_zeros in [True, False]:\n            for axis in [0, 1]:\n                Xt = quantile_transform(X, axis=axis,\n                                        ignore_implicit_zeros=ignore_implicit_zeros)\n                assert_sparse_equal(Xt,\n                                    quantile_transform(X.toarray(), axis=axis,\n                                                       ignore_implicit_zeros=ignore_implicit_zeros))\n"], "sample_758": ["    def test_check_consistent_length_pandas(self):\n        # Test check_consistent_length with pandas DataFrame\n        df = MockDataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]})\n        X = df[['col1']]\n        y = df[['col2']]\n        check_consistent_length(X, y)\n\n        y = np.array([1, 2])\n        with pytest.raises(ValueError) as excinfo:\n            check_consistent_length(X, y)\n        assert \"Found input variables with inconsistent numbers of samples\" in str(excinfo.value)\n"], "sample_473": ["    def test_get_script_prefix_with_force_script_name(self):\n        request = self.request_factory.get('/')\n        self.assertEqual(get_script_prefix(request), \"/prefix\")\n"], "sample_749": ["    def test_column_transformer_sparse_output(self):\n        X = sparse.csr_matrix([[1, 2], [3, 4]])\n        ct = ColumnTransformer([('scaler', StandardScaler(), [0]),\n                                ('passthrough', 'passthrough', 1)])\n        Xt = ct.fit_transform(X)\n        assert_true(sparse.issparse(Xt))\n        assert_allclose_dense_sparse(ct.transform(X), Xt)\n"], "sample_899": ["    def test_check_estimators_unfitted(self):\n        # Test that unfitted estimators raise an error when predict is called\n        estimators = [\n            CorrectNotFittedErrorClassifier(),\n            NoCheckinPredict(),\n            NoSampleWeightPandasSeriesType(),\n            LargeSparseNotSupportedClassifier(),\n            SparseTransformer(),\n        ]\n        for estimator in estimators:\n            with assert_raises(CorrectNotFittedError):\n                estimator.predict(np.array([[1, 2], [3, 4]]))\n"], "sample_1142": ["def test_matrix_element_derivative():\n    i, j = symbols('i j', integer=True)\n    M = MatrixSymbol('M', 3, 3)\n    assert diff(M[i, j], M[1, 1]) == KroneckerDelta(i, 1)*KroneckerDelta(j, 1)\n"], "sample_1194": ["def test_julia_code_piecewise_no_default():\n    pw = Piecewise((x + 1, x > 0), (x, x < 0))\n    raises(ValueError, lambda: julia_code(pw))\n"], "sample_353": ["    def test_createsuperuser_interactive_password_validation(self):\n        # Test that password validation works in interactive mode.\n        out = StringIO()\n        err = StringIO()\n        with override_settings(PASSWORD_HASHERS=['django.contrib.auth.hashers.MD5PasswordHasher']):\n            call_command('createsuperuser', stdout=out, stderr=err, interactive=True)\n        self.assertIn('Error: Your passwords didn\\'t match.', err.getvalue())\n"], "sample_888": ["    def test_sparse_input(self):\n        rng = check_random_state(0)\n        X = rng.randn(100, 10)\n        X_sparse = csc_matrix(X)\n        clf = IsolationForest(random_state=0).fit(X_sparse)\n        assert clf.predict(X_sparse).shape == (100,)\n        assert clf.decision_function(X_sparse).shape == (100,)\n        assert clf.score_samples(X_sparse).shape == (100,)\n"], "sample_1010": ["def test_latex_SingularityFunction():\n    assert latex(SingularityFunction(x, 1, 1)) == '\\\\delta^{(1)}(x)'\n    assert latex(SingularityFunction(x, 2, 1)) == '\\\\delta^{(2)}(x)'\n    assert latex(SingularityFunction(x, 1, 2)) == '\\\\delta^{(1,2)}(x)'\n"], "sample_30": ["    def test_write_table_binary(self):\n        \"\"\"\n        Test writing a table to a VOTable file in binary format.\n        \"\"\"\n        table = Table.from_arrays(\n            [np.arange(10), np.arange(10, 20)], names=[\"col1\", \"col2\"]\n        )\n        votable = VOTableFile()\n        votable.resources.append(Resource(tables=[table]))\n\n        with io.BytesIO() as buffer:\n            votable.to_xml(buffer, tabledata_format=\"binary\")\n            buffer.seek(0)\n            votable_read = parse(buffer)\n\n        assert_array_equal(votable_read.resources[0].tables[0][\"col1\"], table[\"col1\"])\n        assert_array_equal(votable_read.resources[0].tables[0][\"col2\"], table[\"col2\"])\n"], "sample_595": ["    def test_str_accessor_encode_decode(self, dtype):\n        data = np.array([\"a\", \"b\", \"c\"], dtype=dtype)\n        da = xr.DataArray(data)\n        encoded = da.str.encode(\"utf-8\")\n        decoded = encoded.str.decode(\"utf-8\")\n        assert_equal(decoded, da)\n"], "sample_1086": ["def test_print_AccumBounds():\n    assert sstr(AccumBounds(x, 0, 1)) == 'AccumBounds(x, 0, 1)'\n"], "sample_1120": ["def test_matrix_element_diff():\n    i, j = symbols('i j', integer=True)\n    M = MatrixSymbol('M', 3, 3)\n    me = MatrixElement(M, i, j)\n    assert diff(me, M[1, 1]) == KroneckerDelta(i, 1)*KroneckerDelta(j, 1)\n"], "sample_135": ["    def test_format_timezone_aware_datetime(self):\n        dt = make_aware(datetime(2023, 10, 26, 10, 30, 0), get_fixed_timezone(180))\n        self.assertEqual(format(dt, 'e'), '+0300')\n        self.assertEqual(format(dt, 'T'), 'CET')\n        self.assertEqual(format(dt, 'O'), '+0300')\n        self.assertEqual(format(dt, 'P'), '10:30 a.m.')\n"], "sample_1116": ["    def test_Inverse_doit_inv_expand():\n        assert Inverse(A).doit(inv_expand=False) == Inverse(A)\n        assert Inverse(A*B).doit(inv_expand=False) == (A*B)**(-1)\n"], "sample_865": ["    def test_sparse_input_extra_trees(self):\n        # Check that ExtraTreeClassifier and ExtraTreeRegressor work with sparse\n        # input.\n        for tree_type in SPARSE_TREES:\n            Tree = ALL_TREES[tree_type]\n            for sparse_format in [csc_matrix, csr_matrix, coo_matrix]:\n                X_sparse = sparse_format(DATASETS[\"iris\"][\"X\"])\n                y = DATASETS[\"iris\"][\"y\"]\n\n                clf = Tree(random_state=0)\n                clf.fit(X_sparse, y)\n\n                # Check that predict works\n                clf.predict(X_sparse)\n\n                # Check that predict_proba works for classifiers\n                if tree_type in CLF_TREES:\n                    clf.predict_proba(X_sparse)\n"], "sample_996": ["def test_product_empty():\n    assert product(1, (k, 5, 4)).doit() == 1\n    assert product(k, (k, 5, 4)).doit() == 1\n"], "sample_697": ["    def test_getbasetemp_with_given_basetemp(self, tmp_path_factory: TempPathFactory) -> None:\n        given_basetemp = tmp_path_factory._given_basetemp\n        assert given_basetemp is None\n        given_basetemp = Path(\"/tmp/pytest-given-basetemp\")\n        tmp_path_factory._given_basetemp = given_basetemp\n        basetemp = tmp_path_factory.getbasetemp()\n        assert basetemp == given_basetemp\n        assert basetemp.exists()\n        rm_rf(basetemp)\n"], "sample_23": ["    def test_angle_pickle():\n        a = Angle(1.2345, unit=u.deg)\n        b = pickle.loads(pickle.dumps(a))\n        assert a == b\n        assert a.unit == b.unit\n"], "sample_117": ["    def test_create_user_with_custom_email_field(self):\n        with override_settings(AUTH_USER_MODEL='tests.models.with_custom_email_field.CustomEmailFieldUser'):\n            data = {'username': 'testuser', 'password1': 'password', 'password2': 'password'}\n            form = UserCreationForm(data=data)\n            self.assertTrue(form.is_valid())\n            user = form.save()\n            self.assertEqual(user.username, 'testuser')\n            self.assertEqual(user.email, 'testuser@example.com')\n"], "sample_101": ["    def test_wsgi_request_limited_stream(self):\n        request = self.request_factory.get('/')\n        request.META['CONTENT_LENGTH'] = '1024'\n        request.META['wsgi.input'] = BytesIO(b'a' * 2048)\n        wsgi_app = get_wsgi_application()\n        response = wsgi_app(request.environ, lambda *args: None)\n        self.assertEqual(len(response[0].read()), 1024)\n"], "sample_1127": ["def test_coset_equality():\n    a = Permutation(1, 2)\n    b = Permutation(0, 1)\n    G = PermutationGroup([a, b])\n    cst1 = Coset(a, G, dir=\"+\")\n    cst2 = Coset(a*b, G, dir=\"+\")\n    assert cst1 == cst2\n\n"], "sample_665": ["    def test_collect_function_with_fixture(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n                return 42\n\n                assert my_fixture == 42\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.assert_outcomes(passed=1)\n"], "sample_930": ["def test_indexentries_see(app, status, warning):\n    app.env.get_domain('index').entries = {\n        'index.rst': [\n            ('see', 'entry1', 'id1', 'main', None),\n            ('seealso', 'entry2', 'id2', 'main', None),\n        ]\n    }\n    indexentries = IndexEntries(app.env)\n    index = indexentries.create_index(app.builder)\n    assert index[0][1][0][0][0] == ('main', 'see entry1')\n    assert index[0][1][1][0][0] == ('main', 'see also entry2')\n"], "sample_868": ["    def test_silhouette_score_empty_clusters():\n        # Test that silhouette_score handles empty clusters correctly\n        labels = np.array([0, 0, 1, 1, 2])\n        X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6]])\n        with pytest.raises(ValueError):\n            silhouette_score(X, labels)\n"], "sample_437": ["    def test_set_autocommit_with_force_begin_transaction_with_broken_autocommit(\n        self, mock_get_autocommit"], "sample_696": ["    def test_pytest_collect_module(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n                pass\n\n            pytest.collect.test_func()\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.assert_outcomes(failed=1)\n        result.stdout.fnmatch_lines(\n            [\n                \"*DeprecationWarning: pytest.collect.test_func was moved to pytest.test_func*\",\n            ]\n        )\n"], "sample_1108": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((1, 2, 3))) == [(1, 2, 3), (-1, 2, 3), (1, -2, 3), (1, 2, -3),\n                                             (-1, -2, 3), (-1, 2, -3), (1, -2, -3), (-1, -2, -3)]\n"], "sample_947": ["def test_function_pointer():\n    check('function',\n          'void (*func_ptr)(int a, int b)',\n          {1: 'func_ptr'},\n          'void (*func_ptr)(int a, int b)',\n          asTextOutput='void (*func_ptr)(int a, int b)')\n"], "sample_1083": ["def test_asech_rewrite_as_log():\n    x = Symbol('x')\n    assert asech(x)._eval_rewrite_as_log(x) == log(1/x + sqrt(1/x**2 - 1))\n"], "sample_349": ["    def test_autocomplete_select_multiple_required(self):\n        form = RequiredBandForm()\n        self.assertHTMLEqual(\n            str(form['band']),\n            '<select name=\"band\" id=\"id_band\" class=\"my-class admin-autocomplete\" data-ajax--cache=\"true\" data-ajax--delay=\"250\" data-ajax--type=\"GET\" data-ajax--url=\"/admin/autocomplete/\" data-app-label=\"music\" data-model-name=\"band\" data-field-name=\"band\" data-theme=\"admin-autocomplete\" data-allow-clear=\"false\" data-placeholder=\"\" lang=\"en\" required><option value=\"\"></option></select>'\n        )\n"], "sample_918": ["def test_parse_annotation():\n    assert _parse_annotation('int') == ('int', None)\n    assert _parse_annotation('str') == ('str', None)\n    assert _parse_annotation('list[int]') == ('list', 'int')\n    assert _parse_annotation('dict[str, int]') == ('dict', 'str, int')\n    assert _parse_annotation('Tuple[int, str]') == ('Tuple', 'int, str')\n    assert _parse_annotation('Callable[[int], str]') == ('Callable', '[[int], str]')\n    assert _parse_annotation('Optional[int]') == ('Optional', 'int')\n    assert _parse_annotation('Union[int, str]') == ('Union', 'int, str')\n\n"], "sample_879": ["    def test_ordinal_encoder_unknown_value_float_dtype(self):\n        enc = OrdinalEncoder(handle_unknown=\"use_encoded_value\",\n                             unknown_value=np.nan, dtype=np.float64)\n        X = [['Male', 1], ['Female', 3], ['Female', np.nan]]\n        enc.fit(X)\n        X_trans = enc.transform(X)\n        assert_allclose(X_trans, [[1., 0.], [0., 1.], [0., np.nan]])\n"], "sample_518": ["    def test_fancyarrowpatch_mutation_scale(self):\n        fig, ax = plt.subplots()\n        arrow = FancyArrowPatch((0, 0), (1, 1),\n                                arrowstyle='->',\n                                mutation_scale=20,\n                                transform=ax.transData)\n        ax.add_patch(arrow)\n        ax.set_xlim(-1, 2)\n        ax.set_ylim(-1, 2)\n        fig.canvas.draw()\n        # Check that the arrowhead size is scaled correctly\n        arrow_head_size = arrow.get_path().vertices[-3:]\n        assert_almost_equal(np.linalg.norm(arrow_head_size[0] -\n                                          arrow_head_size[1]), 20)\n\n"], "sample_53": ["    def test_required_field_with_empty_option(self):\n        form = RequiredBandForm()\n        self.assertIn(self.empty_option, form.as_p())\n"], "sample_1165": ["def test_pow_cos_sin():\n    q = Quaternion(1, 2, 3, 4)\n    assert q.pow_cos_sin(4) == Quaternion(900*cos(4*acos(sqrt(30)/30)),\n                                        1800*sqrt(29)*sin(4*acos(sqrt(30)/30))/29,\n                                        2700*sqrt(29)*sin(4*acos(sqrt(30)/30))/29,\n                                        3600*sqrt(29)*sin(4*acos(sqrt(30)/30))/29)\n"], "sample_446": ["    def test_floatformat01(self):\n        with translation.override(\"en-us\"):\n            output = self.engine.render_to_string(\"floatformat01\", {\"a\": 1.23456789, \"b\": Decimal(\"1.23456789\")})\n            self.assertEqual(output, \"1.23456789 1.23456789\")\n"], "sample_564": ["def test_stem3d():\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    x, y, z = get_test_data(delta=0.2)\n    ax.stem(x, y, z, linefmt='r-', markerfmt='bo', basefmt='k--')\n    ax.set_xlabel('X')\n    ax.set_ylabel('Y')\n    ax.set_zlabel('Z')\n    return fig\n"], "sample_884": ["    def test_deprecated_property_inheritance():\n        obj = MockClass2()\n        with pytest.warns(FutureWarning, match=\"n_features_ is deprecated\"):\n            _ = obj.n_features_\n"], "sample_169": ["    def test_deserialize_json_field_with_custom_decoder(self):\n        data = '{\"key\": \"value\", \"nested\": {\"key2\": \"value2\"}}'\n        obj = JSONModel.objects.create(data=data, decoder=CustomJSONDecoder)\n        serialized = serializers.serialize('xml', [obj])\n        deserialized = list(serializers.deserialize('xml', serialized))\n        self.assertEqual(deserialized[0].object.data['key'], 'value')\n        self.assertEqual(deserialized[0].object.data['nested']['key2'], 'value2')\n"], "sample_1202": ["def test_is_integer():\n    assert S.Pi.is_integer is False\n    assert S.EulerGamma.is_integer is False\n    assert S.GoldenRatio.is_integer is False\n    assert S.ImaginaryUnit.is_integer is False\n    assert S.Infinity.is_integer is False\n    assert S.NegativeInfinity.is_integer is False\n    assert S.NaN.is_integer is False\n    assert S.Zero.is_integer is True\n    assert S.One.is_integer is True\n    assert Integer(5).is_integer is True\n    assert Rational(5, 2).is_integer is False\n    assert Float(5.0).is_integer is True\n    assert Float(5.2).is_integer is False\n"], "sample_1048": ["def test_parabola_intersection_with_segment():\n    p1 = Point(0,0)\n    l1 = Line(Point(1, -2), Point(-1,-2))\n    parabola1 = Parabola(p1, l1)\n    seg1 = Segment2D(Point(-5, -6), Point(5, -6))\n    assert parabola1.intersection(seg1) == []\n"], "sample_147": ["    def test_select_related_with_prefetch_related(self):\n        # Test that select_related() works correctly with prefetch_related()\n        # when the prefetch_related() target is a ManyToManyField.\n        number1 = Number.objects.create(num=11, other_num=1)\n        number2 = Number.objects.create(num=12, other_num=2)\n        number1.related_numbers.add(number2)\n\n        numbers = Number.objects.select_related('related_numbers').prefetch_related('related_numbers').all()\n        self.assertEqual(len(numbers), 2)\n        self.assertEqual(numbers[0].related_numbers.all(), [number2])\n        self.assertEqual(numbers[1].related_numbers.all(), [])\n"], "sample_609": ["    def test_apply_ufunc_scalar(self, func, expected_result):\n        da = xr.DataArray([0, 1, 2])\n        result = apply_ufunc(func, da)\n        assert_identical(result, expected_result)\n"], "sample_276": ["    def test_model_detail_view_with_custom_model(self):\n        response = self.client.get(reverse('admin:admindocs-model-detail', args=[Company._meta.app_label, Company._meta.model_name]))\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, 'Company')\n        self.assertContains(response, 'name')\n        self.assertContains(response, 'description')\n"], "sample_127": ["    def test_bulk_create_with_related_objects(self):\n        pizzeria = Pizzeria(name=\"Pizza Palace\")\n        pizzeria.save()\n        state = State(name=\"California\", country=self.data[0])\n        state.save()\n        restaurant = Restaurant(name=\"Pizza Planet\", pizzeria=pizzeria, state=state)\n        restaurant.save()\n        bulk_data = [\n            Restaurant(name=\"Pizza Hut\", pizzeria=pizzeria, state=state),\n            Restaurant(name=\"Domino's\", pizzeria=pizzeria, state=state),\n        ]\n        Restaurant.objects.bulk_create(bulk_data)\n        self.assertEqual(Restaurant.objects.count(), 3)\n"], "sample_312": ["    def test_add_squash(self):\n        node3 = Node([('c', 3)])\n        self.node1.add(node3, 'AND')\n        self.assertEqual(self.node1.children, self.node1_children + [('c', 3)])\n"], "sample_1077": ["    def test_complexregion_polar_intersection(self):\n        r = Interval(0, 1)\n        theta = Interval(0, 2*S.Pi)\n        c1 = ComplexRegion(r*theta, polar=True)\n        c2 = ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n        intersection = c1.intersect(c2)\n        assert intersection == c2\n"], "sample_139": ["    def test_changelist_search_with_empty_string(self):\n        request = self._mocked_authenticated_request(reverse('admin:auth_user_changelist'), self.superuser)\n        request.GET = {SEARCH_VAR: ''}\n        response = UserAdmin.changelist_view(request)\n        self.assertEqual(response.status_code, 200)\n        self.assertIn('Search: ', response.content.decode())\n"], "sample_284": ["    def test_hashed_files_css_url_converter(self):\n        \"\"\"\n        Test that the URL converter correctly replaces URLs in CSS files.\n        \"\"\"\n        css_path = 'css/style.css'\n        css_content = \"\"\"\n            body {\n                background-image: url(\"images/background.jpg\");\n            }\n        \"\"\"\n        self.create_file(css_path, css_content)\n        self.create_file('images/background.jpg', b'image data')\n\n        call_command('collectstatic', interactive=False, verbosity=0)\n\n        hashed_css_path = self.hashed_file_path(css_path)\n        with open(os.path.join(settings.STATIC_ROOT, hashed_css_path), 'r') as f:\n            hashed_css_content = f.read()\n\n        expected_url = self.hashed_file_path('images/background.jpg')\n        self.assertIn(f'url(\"{expected_url}\")', hashed_css_content)\n"], "sample_806": ["    def test_classification_sparse_input(self):\n        # Check classification on a sparse matrix.\n        clf = GradientBoostingClassifier(n_estimators=10, random_state=1)\n        X_sparse = csr_matrix(iris.data)\n        clf.fit(X_sparse, iris.target)\n        assert_array_equal(clf.predict(X_sparse), clf.predict(iris.data))\n\n"], "sample_1148": ["def test_matrix_element_diff():\n    i, j = symbols('i j', integer=True)\n    M = MatrixSymbol('M', 3, 3)\n    assert diff(M[i, j], M[i, j]) == 1\n    assert diff(M[i, j], M[i+1, j]) == 0\n    assert diff(M[i, j], M[i, j+1]) == 0\n"], "sample_903": ["    def test_perplexity_search(self):\n        # Test if binary search for perplexity works correctly\n        n_samples = 100\n        X = make_blobs(n_samples=n_samples, centers=3, random_state=0)[0]\n        perplexities = [5, 30, 50]\n        for perplexity in perplexities:\n            distances = pairwise_distances(X, metric='euclidean', squared=True)\n            target_entropy = _binary_search_perplexity(distances, perplexity)\n            assert_almost_equal(target_entropy, perplexity, decimal=1)\n\n"], "sample_1180": ["def test_point3d_direction_cosine():\n    p1 = Point3D(1, 2, 3)\n    p2 = Point3D(2, 3, 5)\n    assert p1.direction_cosine(p2) == [sqrt(6)/6, sqrt(6)/6, sqrt(6)/3]\n"], "sample_648": ["    def test_mark_parametrize_ids_from_mark(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"x\", [1, 2], ids=[\"a\", \"b\"])\n                pass\n            \"\"\"\n        )\n        result = pytester.runpytest(p)\n        assert result.ret == 0\n        assert result.stdout.lines == [\n            \"*test_func[a]\",\n            \"*test_func[b]\",\n        ]\n"], "sample_476": ["    def test_save_and_retrieve_image(self):\n        p = self.PersonModel.objects.create(name=\"Alice\", mugshot=self.file1)\n        self.assertEqual(p.mugshot.name, \"4x8.png\")\n        self.assertEqual(p.mugshot.size, self.file1.size)\n        self.assertEqual(p.mugshot.width, 4)\n        self.assertEqual(p.mugshot.height, 8)\n        p.save()\n        p = self.PersonModel.objects.get(pk=p.pk)\n        self.assertEqual(p.mugshot.name, \"4x8.png\")\n        self.assertEqual(p.mugshot.size, self.file1.size)\n        self.assertEqual(p.mugshot.width, 4)\n        self.assertEqual(p.mugshot.height, 8)\n"], "sample_464": ["    def test_file_response_with_seekable_file(self):\n        with tempfile.NamedTemporaryFile(mode=\"w+b\") as f:\n            f.write(b\"Hello, world!\")\n            f.seek(0)\n            response = FileResponse(f)\n            self.assertEqual(response[\"Content-Length\"], 13)\n            self.assertEqual(response[\"Content-Type\"], \"application/octet-stream\")\n            self.assertEqual(response.getvalue(), b\"Hello, world!\")\n"], "sample_969": ["    def test_restify_forwardref():\n        assert restify(ForwardRef('MyClass')) == ':py:class:`MyClass'`\n        assert restify(ForwardRef('typing.List')) == ':py:class:`~typing.List'`\n"], "sample_335": ["    def test_decimal_field_max_digits_and_decimal_places(self):\n        field = DecimalField(max_digits=5, decimal_places=2)\n        self.assertFieldOutput(field, '123.45')\n        with self.assertRaises(ValidationError):\n            field.clean('12345.67')  # Too many digits\n        with self.assertRaises(ValidationError):\n            field.clean('123.456')  # Too many decimal places\n        with self.assertRaises(ValidationError):\n            field.clean('-12345.67')  # Too many digits\n        with self.assertRaises(ValidationError):\n            field.clean('-123.456')  # Too many decimal places\n"], "sample_1169": ["def test_simplify_index_permutations():\n    p, q, r, s = symbols('p,q,r,s')\n    f = Function('f')\n    g = Function('g')\n\n    expr = f(p,r)*g(q,s) - f(q,r)*g(p,s) + f(q,s)*g(p,r) - f(p,s)*g(q,r)\n    PermutList = [PermutationOperator(p,q),PermutationOperator(r,s)]\n    result = simplify_index_permutations(expr,PermutList)\n    assert result == f(p, r)*g(q, s)*PermutationOperator(p, q)*PermutationOperator(r, s)\n\n"], "sample_728": ["    def test_make_checkerboard_shape():\n        X, rows, cols = make_checkerboard((10, 10), 2)\n        assert_equal(X.shape, (10, 10))\n        assert_equal(rows.shape, (2, 10))\n        assert_equal(cols.shape, (2, 10))\n"], "sample_944": ["    def test_restify_union_with_none():\n        assert restify(Union[str, NoneType]) == 'Optional[str]'\n        assert restify(Union[NoneType, str]) == 'Optional[str]'\n        assert restify(Union[int, NoneType]) == 'Optional[int]'\n        assert restify(Union[NoneType, int]) == 'Optional[int]'\n"], "sample_747": ["    def test_quantile_transform_sparse_matrix(self):\n        X = sparse.csr_matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n        transformer = QuantileTransformer(n_quantiles=3, random_state=0)\n        X_trans = transformer.fit_transform(X)\n        assert_true(sparse.issparse(X_trans))\n        assert_array_equal(X_trans.shape, X.shape)\n"], "sample_36": ["    def test_biweight_midcorrelation_outlier():\n        with NumpyRNGContext(12345):\n            x = normal(0, 1, 100)\n            y = normal(0, 1, 100)\n            x[0] = 10\n            bicorr = biweight_midcorrelation(x, y)\n        assert_allclose(bicorr, np.corrcoef(x, y)[0, 1], rtol=1e-2)\n"], "sample_114": ["    def test_rename_field_with_default(self):\n        before_state = self.make_project_state([\n            self.author_with_name,\n        ])\n        after_state = self.make_project_state([\n            self.author_with_name_renamed,\n        ])\n        changes = self.get_changes(before_state.models, after_state.models)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['RenameField'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name', old_name='name', field_type='CharField')\n\n"], "sample_216": ["    def test_rename_field_with_default(self):\n        before = [\n            self.author_name,\n        ]\n        after = [\n            self.author_name_renamed,\n        ]\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['RenameField'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name', old_name='name_old')\n\n"], "sample_426": ["    def test_timesince_aware_datetime(self):\n        with translation.override('en'):\n            now = timezone.now()\n            past = now - self.oneday\n            self.assertEqual(timesince(past), \"1 day\")\n            self.assertEqual(timesince(past, now=now), \"1 day\")\n"]}, "raw_scored_generations": {"sample_0": [true], "sample_2": [false], "sample_3": [false], "sample_1": [false], "sample_4": [true], "sample_5": [false], "sample_6": [false], "sample_7": [false], "sample_8": [false], "sample_9": [false], "sample_10": [false], "sample_11": [false], "sample_12": [false], "sample_13": [false], "sample_14": [false], "sample_15": [false], "sample_16": [false], "sample_17": [false], "sample_18": [true], "sample_19": [false], "sample_20": [false], "sample_21": [false], "sample_22": [false], "sample_23": [false], "sample_24": [false], "sample_25": [false], "sample_26": [false], "sample_27": [false], "sample_28": [false], "sample_29": [false], "sample_30": [false], "sample_31": [false], "sample_32": [true], "sample_33": [false], "sample_34": [false], "sample_35": [false], "sample_36": [false], "sample_37": [false], "sample_38": [false], "sample_39": [false], "sample_40": [false], "sample_41": [false], "sample_42": [false], "sample_43": [false], "sample_44": [false], "sample_45": [false], "sample_46": [false], "sample_47": [false], "sample_48": [false], "sample_49": [false], "sample_50": [true], "sample_51": [true], "sample_52": [false], "sample_54": [false], "sample_53": [false], "sample_55": [false], "sample_58": [false], "sample_56": [false], "sample_57": [false], "sample_59": [false], "sample_60": [false], "sample_61": [true], "sample_62": [false], "sample_63": [true], "sample_64": [true], "sample_65": [false], "sample_67": [false], "sample_66": [true], "sample_68": [false], "sample_69": [false], "sample_70": [false], "sample_71": [false], "sample_72": [false], "sample_73": [true], "sample_75": [false], "sample_74": [true], "sample_76": [false], "sample_77": [false], "sample_78": [false], "sample_79": [false], "sample_80": [false], "sample_82": [false], "sample_81": [false], "sample_83": [false], "sample_85": [false], "sample_84": [false], "sample_86": [true], "sample_88": [false], "sample_87": [false], "sample_89": [false], "sample_90": [false], "sample_91": [false], "sample_92": [true], "sample_93": [false], "sample_94": [false], "sample_95": [false], "sample_98": [false], "sample_96": [false], "sample_99": [false], "sample_97": [true], "sample_100": [false], "sample_102": [false], "sample_101": [false], "sample_103": [false], "sample_104": [true], "sample_107": [false], "sample_106": [false], "sample_105": [true], "sample_108": [false], "sample_109": [true], "sample_111": [false], "sample_110": [false], "sample_112": [false], "sample_113": [true], "sample_114": [false], "sample_115": [false], "sample_116": [false], "sample_117": [false], "sample_118": [false], "sample_119": [false], "sample_120": [false], "sample_121": [false], "sample_122": [false], "sample_123": [false], "sample_124": [false], "sample_125": [false], "sample_126": [false], "sample_127": [false], "sample_128": [false], "sample_129": [false], "sample_130": [false], "sample_131": [false], "sample_132": [false], "sample_133": [false], "sample_135": [false], "sample_134": [false], "sample_136": [true], "sample_139": [false], "sample_137": [false], "sample_138": [true], "sample_140": [false], "sample_141": [false], "sample_142": [false], "sample_143": [false], "sample_144": [false], "sample_145": [false], "sample_146": [true], "sample_147": [false], "sample_148": [false], "sample_151": [false], "sample_149": [false], "sample_152": [false], "sample_150": [false], "sample_153": [false], "sample_154": [false], "sample_155": [false], "sample_156": [true], "sample_157": [true], "sample_158": [false], "sample_159": [false], "sample_160": [false], "sample_161": [true], "sample_162": [true], "sample_163": [false], "sample_164": [false], "sample_165": [false], "sample_166": [true], "sample_167": [false], "sample_168": [true], "sample_169": [false], "sample_171": [false], "sample_170": [false], "sample_172": [false], "sample_173": [true], "sample_174": [true], "sample_175": [false], "sample_176": [false], "sample_177": [false], "sample_178": [false], "sample_180": [true], "sample_179": [true], "sample_182": [false], "sample_181": [true], "sample_183": [false], "sample_184": [false], "sample_185": [false], "sample_186": [false], "sample_187": [true], "sample_188": [false], "sample_189": [false], "sample_190": [false], "sample_191": [false], "sample_192": [false], "sample_193": [false], "sample_194": [false], "sample_195": [false], "sample_196": [true], "sample_198": [false], "sample_197": [false], "sample_199": [false], "sample_200": [false], "sample_201": [false], "sample_202": [false], "sample_203": [false], "sample_204": [false], "sample_205": [false], "sample_206": [false], "sample_207": [false], "sample_208": [false], "sample_209": [false], "sample_210": [true], "sample_211": [true], "sample_213": [false], "sample_212": [false], "sample_214": [false], "sample_215": [false], "sample_216": [false], "sample_217": [false], "sample_218": [true], "sample_219": [false], "sample_220": [false], "sample_221": [false], "sample_222": [true], "sample_223": [false], "sample_224": [false], "sample_225": [true], "sample_226": [true], "sample_227": [true], "sample_228": [false], "sample_229": [false], "sample_230": [true], "sample_231": [false], "sample_232": [false], "sample_233": [true], "sample_234": [false], "sample_235": [false], "sample_236": [false], "sample_237": [false], "sample_238": [false], "sample_239": [false], "sample_240": [false], "sample_241": [true], "sample_242": [false], "sample_243": [false], "sample_244": [false], "sample_245": [true], "sample_246": [true], "sample_247": [false], "sample_248": [false], "sample_249": [true], "sample_250": [false], "sample_251": [false], "sample_252": [false], "sample_253": [false], "sample_254": [false], "sample_256": [false], "sample_255": [false], "sample_257": [false], "sample_258": [false], "sample_259": [true], "sample_260": [false], "sample_261": [true], "sample_262": [false], "sample_263": [false], "sample_264": [false], "sample_265": [false], "sample_266": [false], "sample_267": [false], "sample_268": [false], "sample_269": [false], "sample_270": [false], "sample_271": [false], "sample_272": [false], "sample_273": [false], "sample_274": [false], "sample_275": [true], "sample_276": [false], "sample_277": [false], "sample_278": [false], "sample_279": [false], "sample_280": [false], "sample_281": [false], "sample_282": [true], "sample_283": [false], "sample_284": [true], "sample_285": [false], "sample_286": [false], "sample_287": [false], "sample_288": [false], "sample_289": [true], "sample_290": [false], "sample_291": [false], "sample_292": [true], "sample_293": [true], "sample_294": [true], "sample_295": [false], "sample_296": [false], "sample_297": [false], "sample_298": [false], "sample_299": [false], "sample_300": [false], "sample_301": [false], "sample_302": [false], "sample_303": [false], "sample_304": [true], "sample_305": [false], "sample_306": [true], "sample_307": [false], "sample_308": [false], "sample_309": [false], "sample_310": [false], "sample_312": [false], "sample_311": [false], "sample_313": [false], "sample_314": [true], "sample_315": [false], "sample_316": [false], "sample_317": [false], "sample_318": [false], "sample_319": [false], "sample_320": [false], "sample_321": [true], "sample_322": [false], "sample_323": [false], "sample_324": [true], "sample_325": [false], "sample_326": [false], "sample_327": [true], "sample_328": [false], "sample_329": [false], "sample_330": [false], "sample_331": [true], "sample_332": [false], "sample_333": [true], "sample_334": [false], "sample_335": [false], "sample_336": [false], "sample_337": [false], "sample_338": [false], "sample_339": [false], "sample_340": [false], "sample_341": [false], "sample_342": [false], "sample_343": [false], "sample_344": [false], "sample_345": [false], "sample_346": [false], "sample_347": [false], "sample_348": [false], "sample_349": [false], "sample_350": [false], "sample_351": [false], "sample_352": [false], "sample_353": [false], "sample_354": [false], "sample_355": [false], "sample_356": [false], "sample_357": [false], "sample_358": [false], "sample_359": [false], "sample_360": [false], "sample_361": [false], "sample_362": [false], "sample_363": [true], "sample_364": [false], "sample_365": [false], "sample_366": [true], "sample_367": [false], "sample_368": [false], "sample_369": [false], "sample_370": [false], "sample_371": [false], "sample_372": [true], "sample_373": [false], "sample_374": [false], "sample_375": [false], "sample_376": [false], "sample_377": [false], "sample_378": [false], "sample_379": [true], "sample_380": [false], "sample_381": [false], "sample_382": [false], "sample_383": [false], "sample_384": [false], "sample_385": [false], "sample_386": [true], "sample_387": [false], "sample_388": [false], "sample_389": [true], "sample_390": [false], "sample_391": [false], "sample_392": [false], "sample_393": [true], "sample_394": [false], "sample_395": [false], "sample_396": [false], "sample_397": [false], "sample_398": [false], "sample_399": [false], "sample_400": [false], "sample_401": [false], "sample_402": [false], "sample_403": [false], "sample_404": [true], "sample_405": [false], "sample_406": [false], "sample_407": [false], "sample_408": [false], "sample_409": [false], "sample_410": [false], "sample_411": [false], "sample_412": [false], "sample_413": [true], "sample_414": [false], "sample_415": [false], "sample_416": [true], "sample_417": [false], "sample_418": [false], "sample_419": [false], "sample_420": [false], "sample_421": [false], "sample_422": [false], "sample_423": [false], "sample_424": [false], "sample_425": [false], "sample_426": [false], "sample_427": [false], "sample_428": [false], "sample_429": [false], "sample_430": [false], "sample_431": [false], "sample_432": [false], "sample_433": [false], "sample_434": [false], "sample_435": [false], "sample_436": [false], "sample_437": [false], "sample_438": [true], "sample_439": [false], "sample_440": [false], "sample_441": [false], "sample_442": [false], "sample_443": [true], "sample_444": [true], "sample_445": [false], "sample_446": [false], "sample_447": [false], "sample_448": [false], "sample_449": [false], "sample_450": [false], "sample_451": [false], "sample_453": [false], "sample_452": [false], "sample_454": [false], "sample_455": [false], "sample_456": [false], "sample_457": [false], "sample_458": [false], "sample_459": [false], "sample_460": [false], "sample_461": [false], "sample_462": [false], "sample_463": [false], "sample_464": [false], "sample_465": [false], "sample_466": [false], "sample_467": [false], "sample_469": [false], "sample_468": [false], "sample_470": [false], "sample_471": [false], "sample_472": [false], "sample_473": [false], "sample_474": [false], "sample_475": [false], "sample_476": [false], "sample_477": [false], "sample_478": [false], "sample_479": [false], "sample_480": [false], "sample_481": [false], "sample_482": [false], "sample_483": [false], "sample_484": [false], "sample_485": [false], "sample_486": [false], "sample_487": [false], "sample_488": [false], "sample_489": [false], "sample_490": [false], "sample_491": [false], "sample_492": [false], "sample_493": [false], "sample_494": [false], "sample_495": [false], "sample_496": [false], "sample_497": [false], "sample_498": [false], "sample_499": [false], "sample_500": [false], "sample_501": [false], "sample_502": [false], "sample_503": [false], "sample_504": [false], "sample_505": [false], "sample_506": [false], "sample_507": [false], "sample_508": [false], "sample_509": [false], "sample_510": [false], "sample_511": [false], "sample_512": [false], "sample_513": [false], "sample_514": [false], "sample_515": [false], "sample_516": [false], "sample_517": [false], "sample_518": [false], "sample_519": [false], "sample_520": [false], "sample_521": [false], "sample_522": [false], "sample_523": [false], "sample_524": [false], "sample_525": [false], "sample_526": [false], "sample_527": [false], "sample_528": [true], "sample_529": [false], "sample_530": [false], "sample_531": [false], "sample_532": [false], "sample_533": [false], "sample_534": [false], "sample_535": [false], "sample_536": [false], "sample_537": [false], "sample_538": [false], "sample_539": [false], "sample_540": [false], "sample_541": [false], "sample_542": [false], "sample_543": [true], "sample_544": [false], "sample_545": [false], "sample_546": [false], "sample_547": [false], "sample_548": [false], "sample_549": [false], "sample_550": [false], "sample_551": [false], "sample_552": [false], "sample_553": [false], "sample_554": [false], "sample_555": [false], "sample_556": [false], "sample_557": [false], "sample_558": [false], "sample_559": [false], "sample_560": [false], "sample_561": [false], "sample_562": [false], "sample_563": [false], "sample_564": [false], "sample_565": [false], "sample_566": [false], "sample_567": [false], "sample_568": [false], "sample_569": [false], "sample_570": [false], "sample_571": [false], "sample_572": [false], "sample_573": [false], "sample_574": [false], "sample_575": [false], "sample_576": [false], "sample_577": [false], "sample_578": [false], "sample_579": [false], "sample_580": [false], "sample_581": [false], "sample_582": [false], "sample_583": [false], "sample_584": [false], "sample_585": [false], "sample_586": [false], "sample_587": [false], "sample_588": [false], "sample_589": [false], "sample_590": [false], "sample_591": [false], "sample_592": [true], "sample_593": [false], "sample_594": [false], "sample_595": [false], "sample_596": [false], "sample_597": [false], "sample_598": [false], "sample_599": [false], "sample_600": [false], "sample_601": [false], "sample_602": [false], "sample_603": [false], "sample_604": [true], "sample_605": [true], "sample_606": [false], "sample_607": [false], "sample_608": [false], "sample_609": [false], "sample_610": [false], "sample_611": [false], "sample_612": [false], "sample_613": [false], "sample_614": [false], "sample_615": [false], "sample_616": [false], "sample_617": [false], "sample_618": [false], "sample_619": [false], "sample_620": [false], "sample_621": [false], "sample_622": [false], "sample_623": [false], "sample_624": [false], "sample_625": [false], "sample_626": [false], "sample_627": [false], "sample_628": [true], "sample_629": [false], "sample_630": [false], "sample_631": [false], "sample_632": [false], "sample_633": [false], "sample_634": [false], "sample_635": [false], "sample_636": [false], "sample_637": [false], "sample_638": [false], "sample_639": [false], "sample_640": [false], "sample_641": [false], "sample_642": [false], "sample_643": [false], "sample_644": [false], "sample_645": [false], "sample_646": [false], "sample_647": [false], "sample_648": [false], "sample_649": [false], "sample_650": [false], "sample_651": [false], "sample_652": [false], "sample_653": [false], "sample_654": [false], "sample_655": [false], "sample_656": [false], "sample_657": [false], "sample_658": [false], "sample_659": [false], "sample_660": [false], "sample_661": [false], "sample_662": [false], "sample_663": [false], "sample_664": [false], "sample_665": [false], "sample_666": [false], "sample_667": [false], "sample_668": [false], "sample_669": [false], "sample_670": [false], "sample_671": [false], "sample_672": [false], "sample_673": [false], "sample_674": [false], "sample_675": [false], "sample_676": [false], "sample_677": [false], "sample_678": [false], "sample_679": [false], "sample_680": [false], "sample_681": [false], "sample_682": [false], "sample_683": [false], "sample_684": [false], "sample_685": [false], "sample_686": [false], "sample_687": [false], "sample_688": [false], "sample_689": [false], "sample_690": [false], "sample_691": [false], "sample_692": [false], "sample_693": [false], "sample_694": [false], "sample_695": [false], "sample_696": [false], "sample_697": [false], "sample_698": [false], "sample_699": [false], "sample_700": [false], "sample_701": [false], "sample_702": [false], "sample_703": [false], "sample_704": [false], "sample_705": [false], "sample_706": [true], "sample_707": [false], "sample_708": [false], "sample_709": [false], "sample_710": [false], "sample_711": [false], "sample_712": [false], "sample_713": [false], "sample_714": [false], "sample_715": [false], "sample_716": [false], "sample_717": [true], "sample_718": [false], "sample_719": [false], "sample_720": [false], "sample_721": [false], "sample_722": [false], "sample_723": [false], "sample_724": [false], "sample_725": [false], "sample_726": [false], "sample_727": [false], "sample_728": [false], "sample_729": [false], "sample_730": [false], "sample_731": [true], "sample_732": [false], "sample_733": [false], "sample_734": [false], "sample_735": [false], "sample_736": [true], "sample_737": [false], "sample_738": [false], "sample_739": [false], "sample_740": [false], "sample_741": [false], "sample_742": [false], "sample_743": [false], "sample_744": [false], "sample_745": [false], "sample_746": [false], "sample_747": [false], "sample_748": [false], "sample_749": [false], "sample_750": [false], "sample_751": [false], "sample_752": [false], "sample_753": [false], "sample_754": [false], "sample_755": [false], "sample_756": [false], "sample_757": [false], "sample_758": [false], "sample_759": [false], "sample_760": [false], "sample_761": [false], "sample_762": [false], "sample_763": [false], "sample_764": [false], "sample_765": [false], "sample_766": [false], "sample_767": [false], "sample_768": [false], "sample_769": [false], "sample_770": [false], "sample_771": [false], "sample_772": [false], "sample_773": [false], "sample_774": [false], "sample_775": [false], "sample_776": [false], "sample_777": [false], "sample_778": [false], "sample_779": [false], "sample_780": [true], "sample_781": [true], "sample_782": [false], "sample_783": [false], "sample_784": [false], "sample_785": [false], "sample_786": [false], "sample_787": [false], "sample_788": [false], "sample_789": [false], "sample_790": [false], "sample_791": [false], "sample_792": [false], "sample_793": [false], "sample_794": [false], "sample_795": [false], "sample_796": [false], "sample_797": [false], "sample_798": [false], "sample_799": [false], "sample_800": [true], "sample_801": [false], "sample_802": [false], "sample_803": [false], "sample_804": [false], "sample_805": [false], "sample_806": [false], "sample_807": [false], "sample_808": [false], "sample_809": [false], "sample_810": [false], "sample_811": [false], "sample_812": [false], "sample_813": [false], "sample_814": [false], "sample_815": [false], "sample_816": [false], "sample_817": [false], "sample_818": [false], "sample_819": [false], "sample_820": [false], "sample_821": [false], "sample_822": [false], "sample_823": [false], "sample_824": [false], "sample_825": [false], "sample_826": [true], "sample_827": [false], "sample_828": [false], "sample_829": [false], "sample_830": [false], "sample_831": [false], "sample_832": [false], "sample_833": [false], "sample_834": [false], "sample_835": [false], "sample_836": [false], "sample_837": [false], "sample_838": [false], "sample_839": [false], "sample_840": [false], "sample_841": [false], "sample_842": [false], "sample_843": [false], "sample_844": [false], "sample_845": [false], "sample_846": [false], "sample_847": [false], "sample_848": [false], "sample_849": [false], "sample_850": [false], "sample_851": [false], "sample_852": [false], "sample_853": [false], "sample_854": [false], "sample_855": [false], "sample_856": [false], "sample_857": [true], "sample_858": [false], "sample_859": [false], "sample_860": [false], "sample_861": [false], "sample_862": [false], "sample_863": [false], "sample_864": [false], "sample_865": [false], "sample_866": [false], "sample_867": [false], "sample_868": [false], "sample_869": [false], "sample_870": [false], "sample_871": [false], "sample_872": [false], "sample_873": [false], "sample_874": [false], "sample_875": [true], "sample_876": [false], "sample_877": [false], "sample_878": [false], "sample_879": [false], "sample_880": [false], "sample_881": [false], "sample_882": [false], "sample_883": [false], "sample_884": [false], "sample_885": [false], "sample_886": [false], "sample_887": [false], "sample_888": [false], "sample_889": [false], "sample_890": [false], "sample_891": [false], "sample_892": [false], "sample_893": [false], "sample_894": [false], "sample_895": [false], "sample_896": [false], "sample_897": [false], "sample_898": [false], "sample_899": [false], "sample_900": [false], "sample_901": [false], "sample_902": [false], "sample_903": [false], "sample_904": [false], "sample_905": [false], "sample_906": [false], "sample_907": [false], "sample_908": [false], "sample_909": [false], "sample_910": [false], "sample_911": [false], "sample_912": [false], "sample_913": [false], "sample_914": [false], "sample_915": [false], "sample_916": [false], "sample_917": [false], "sample_918": [false], "sample_919": [false], "sample_920": [false], "sample_921": [false], "sample_922": [false], "sample_923": [false], "sample_924": [false], "sample_925": [false], "sample_926": [false], "sample_927": [false], "sample_928": [false], "sample_929": [false], "sample_930": [false], "sample_931": [false], "sample_932": [false], "sample_933": [false], "sample_934": [false], "sample_935": [false], "sample_936": [false], "sample_937": [false], "sample_938": [false], "sample_939": [false], "sample_940": [false], "sample_941": [false], "sample_942": [false], "sample_943": [true], "sample_944": [false], "sample_945": [false], "sample_946": [false], "sample_947": [false], "sample_948": [false], "sample_949": [false], "sample_950": [false], "sample_951": [false], "sample_952": [false], "sample_953": [false], "sample_954": [false], "sample_955": [false], "sample_956": [false], "sample_957": [false], "sample_958": [false], "sample_959": [false], "sample_960": [false], "sample_961": [false], "sample_962": [false], "sample_963": [false], "sample_964": [false], "sample_965": [false], "sample_966": [false], "sample_967": [true], "sample_968": [false], "sample_969": [false], "sample_970": [false], "sample_971": [false], "sample_972": [true], "sample_973": [false], "sample_974": [false], "sample_975": [false], "sample_976": [false], "sample_977": [false], "sample_978": [true], "sample_979": [true], "sample_980": [false], "sample_981": [true], "sample_982": [true], "sample_983": [true], "sample_984": [false], "sample_985": [false], "sample_986": [false], "sample_987": [false], "sample_988": [false], "sample_989": [true], "sample_990": [false], "sample_991": [true], "sample_992": [false], "sample_993": [false], "sample_994": [true], "sample_995": [true], "sample_996": [true], "sample_997": [false], "sample_998": [false], "sample_999": [false], "sample_1000": [false], "sample_1001": [false], "sample_1002": [true], "sample_1003": [false], "sample_1004": [true], "sample_1005": [false], "sample_1006": [false], "sample_1007": [true], "sample_1008": [false], "sample_1009": [false], "sample_1010": [false], "sample_1011": [true], "sample_1012": [false], "sample_1013": [true], "sample_1014": [false], "sample_1015": [false], "sample_1016": [true], "sample_1017": [false], "sample_1018": [true], "sample_1019": [false], "sample_1020": [false], "sample_1021": [true], "sample_1022": [false], "sample_1023": [false], "sample_1024": [true], "sample_1025": [false], "sample_1026": [true], "sample_1027": [true], "sample_1028": [false], "sample_1029": [false], "sample_1030": [false], "sample_1031": [false], "sample_1032": [false], "sample_1033": [true], "sample_1034": [true], "sample_1035": [true], "sample_1036": [false], "sample_1037": [true], "sample_1038": [false], "sample_1039": [true], "sample_1040": [false], "sample_1041": [false], "sample_1042": [true], "sample_1043": [false], "sample_1044": [false], "sample_1045": [false], "sample_1046": [false], "sample_1047": [false], "sample_1048": [true], "sample_1049": [false], "sample_1050": [false], "sample_1051": [false], "sample_1052": [false], "sample_1053": [true], "sample_1054": [false], "sample_1055": [true], "sample_1056": [false], "sample_1057": [false], "sample_1058": [false], "sample_1059": [true], "sample_1060": [false], "sample_1061": [false], "sample_1062": [false], "sample_1063": [true], "sample_1064": [false], "sample_1065": [false], "sample_1066": [false], "sample_1067": [false], "sample_1068": [false], "sample_1069": [false], "sample_1070": [false], "sample_1071": [false], "sample_1072": [false], "sample_1073": [false], "sample_1074": [false], "sample_1075": [false], "sample_1076": [false], "sample_1077": [false], "sample_1078": [false], "sample_1079": [true], "sample_1080": [false], "sample_1081": [true], "sample_1082": [true], "sample_1083": [false], "sample_1084": [false], "sample_1085": [true], "sample_1086": [false], "sample_1087": [false], "sample_1088": [false], "sample_1089": [true], "sample_1090": [false], "sample_1091": [true], "sample_1092": [false], "sample_1093": [false], "sample_1094": [false], "sample_1095": [false], "sample_1096": [false], "sample_1097": [true], "sample_1098": [false], "sample_1099": [false], "sample_1100": [false], "sample_1101": [false], "sample_1102": [false], "sample_1103": [false], "sample_1104": [false], "sample_1105": [true], "sample_1106": [false], "sample_1107": [true], "sample_1108": [false], "sample_1109": [false], "sample_1110": [false], "sample_1111": [false], "sample_1112": [false], "sample_1113": [false], "sample_1114": [true], "sample_1115": [false], "sample_1116": [false], "sample_1117": [false], "sample_1118": [false], "sample_1119": [false], "sample_1120": [false], "sample_1121": [false], "sample_1122": [false], "sample_1123": [true], "sample_1124": [false], "sample_1125": [false], "sample_1126": [false], "sample_1127": [false], "sample_1128": [false], "sample_1129": [false], "sample_1130": [false], "sample_1131": [false], "sample_1132": [false], "sample_1133": [false], "sample_1134": [false], "sample_1135": [false], "sample_1136": [true], "sample_1137": [false], "sample_1138": [false], "sample_1139": [false], "sample_1140": [false], "sample_1141": [true], "sample_1142": [false], "sample_1143": [false], "sample_1144": [false], "sample_1145": [false], "sample_1146": [false], "sample_1147": [false], "sample_1148": [true], "sample_1149": [false], "sample_1150": [false], "sample_1151": [true], "sample_1152": [false], "sample_1153": [false], "sample_1154": [false], "sample_1155": [false], "sample_1156": [false], "sample_1157": [false], "sample_1158": [true], "sample_1159": [false], "sample_1160": [false], "sample_1161": [false], "sample_1162": [false], "sample_1163": [false], "sample_1164": [false], "sample_1165": [true], "sample_1166": [false], "sample_1167": [false], "sample_1168": [false], "sample_1169": [true], "sample_1170": [false], "sample_1171": [false], "sample_1172": [false], "sample_1173": [false], "sample_1174": [false], "sample_1175": [false], "sample_1176": [false], "sample_1177": [false], "sample_1178": [false], "sample_1179": [false], "sample_1180": [true], "sample_1181": [false], "sample_1182": [false], "sample_1183": [true], "sample_1184": [true], "sample_1185": [false], "sample_1186": [false], "sample_1187": [false], "sample_1188": [false], "sample_1189": [true], "sample_1190": [false], "sample_1191": [false], "sample_1192": [false], "sample_1193": [true], "sample_1194": [true], "sample_1195": [false], "sample_1196": [false], "sample_1197": [false], "sample_1198": [true], "sample_1199": [false], "sample_1200": [false], "sample_1201": [false], "sample_1202": [false], "sample_1203": [false], "sample_1204": [false], "sample_1205": [false], "sample_1206": [false], "sample_1207": [false], "sample_1208": [false], "sample_1209": [false]}}