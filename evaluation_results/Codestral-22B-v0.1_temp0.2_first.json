{"raw_generations": {"sample_200": ["    def test_attach_file(self):\n        temp_dir = tempfile.mkdtemp()\n        try:\n            file_path = os.path.join(temp_dir, 'test.txt')\n            with open(file_path, 'w') as f:\n                f.write('Test content')\n\n            email = EmailMessage()\n            email.attach_file(file_path)\n\n            attachments = self.get_decoded_attachments(email)\n            self.assertEqual(len(attachments), 1)\n            filename, content, mimetype = attachments[0]\n            self.assertEqual(filename, 'test.txt')\n            self.assertEqual(content, b'Test content')\n            self.assertEqual(mimetype, 'text/plain')\n        finally:\n            shutil.rmtree(temp_dir)\n"], "sample_1007": ["def test_binomial_rewrite_as_gamma():\n    n, k = symbols('n k', integer=True)\n    assert binomial(n, k).rewrite(gamma) == gamma(n + 1) / (gamma(k + 1) * gamma(n - k + 1))\n"], "sample_55": ["    def test_admin_form_fields(self):\n        response = self.client.get(reverse('admin:admin_views_section_change', args=(self.s1.pk,)))\n        fields = self.get_admin_form_fields(response)\n        self.assertEqual(len(fields), 1)  # There's only one field in the Section model\n        self.assertEqual(fields[0].field['name'], 'name')\n"], "sample_744": ["def test_quantile_transformer_n_quantiles_greater_than_subsample():\n    X = np.array([[1], [2], [3], [4], [5]])\n    n_quantiles = 6\n    subsample = 5\n    with pytest.raises(ValueError, match=\"The number of quantiles cannot be greater than the number of samples used.\"):\n        QuantileTransformer(n_quantiles=n_quantiles, subsample=subsample).fit(X)\n"], "sample_908": ["compilation error"], "sample_1060": ["def test_print_Mod():\n    expr = Mod(x, y)\n    printer = PythonCodePrinter()\n    result = printer._print_Mod(expr)\n    assert result == \"x % y\"\n"], "sample_693": ["def test_pytest_pycollect_makeitem(pytester: Pytester, monkeypatch: MonkeyPatch):\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n\n        class TestMyClass(unittest.TestCase):\n                self.assertEqual(1, 1)\n        \"\"\"\n    )\n\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n\n    # Test that the function returns None when unittest is not imported\n    monkeypatch.delitem(sys.modules, \"unittest\")\n    from my_code_file import pytest_pycollect_makeitem\n    assert pytest_pycollect_makeitem(None, \"TestMyClass\", object) is None\n"], "sample_488": ["    def test_register_model(self):\n        # Test registering a new model\n        app_label = 'test_app'\n        model_name = 'TestModel'\n        class TestModel(models.Model):\n            class Meta:\n                app_label = app_label\n\n        apps.register_model(app_label, TestModel)\n        self.assertEqual(apps.get_registered_model(app_label, model_name), TestModel)\n\n        # Test registering a model with the same name and module raises RuntimeWarning\n        with self.assertWarns(RuntimeWarning):\n            apps.register_model(app_label, TestModel)\n\n        # Test registering a model with the same name but different module raises RuntimeError\n        class DifferentTestModel(models.Model):\n            class Meta:\n                app_label = app_label\n\n        with self.assertRaises(RuntimeError):\n            apps.register_model(app_label, DifferentTestModel)\n"], "sample_572": ["    def test_univariate_integration(self, x):\n        kde = KDE()\n        density, support = kde(x)\n        assert np.isclose(self.integrate(density, support), 1.0)\n"], "sample_416": ["    def test_runshell(self):\n        sigint_handler = signal.getsignal(signal.SIGINT)\n        with mock.patch('subprocess.run') as mock_run, mock.patch('signal.signal') as mock_signal:\n            DatabaseClient().runshell(['-c', 'SELECT 1'])\n            mock_signal.assert_any_call(signal.SIGINT, signal.SIG_IGN)\n            mock_signal.assert_any_call(signal.SIGINT, sigint_handler)\n            mock_run.assert_called_once_with(['psql', '-c', 'SELECT 1'], env=None, check=True)\n"], "sample_1114": ["def test_complex_region_from_real():\n    unit = Interval(0, 1)\n    region = ComplexRegion.from_real(unit)\n    assert region == CartesianComplexRegion(ProductSet(unit, FiniteSet(0)))\n"], "sample_5": ["def test_evaluate(model):\n    cls = model['class']\n    parameters = model['parameters']\n    evaluation = model['evaluation']\n\n    m = cls(**parameters)\n    for args, expected in evaluation:\n        result = m(*args)\n        assert_quantity_allclose(result, expected)\n"], "sample_1029": ["def test_srepr_AlgebraicNumber():\n    a = AlgebraicNumber(root(2, 3), [1, 2, 3])\n    sT(a, \"AlgebraicNumber(root(2, 3), [1, 2, 3])\")\n"], "sample_738": ["def test_tfidf_vectorizer_with_custom_analyzer():\n    vectorizer = TfidfVectorizer(analyzer=lazy_analyze)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n    assert_array_equal(X.toarray(), np.ones((len(ALL_FOOD_DOCS), 1)))\n"], "sample_272": ["    def test_migrate_all_backwards(self):\n        \"\"\"\n        Test the _migrate_all_backwards method of MigrationExecutor.\n        \"\"\"\n        executor = MigrationExecutor(connection)\n        plan = [\n            (executor.loader.graph.nodes[('migrations', '0001_initial')], True),\n            (executor.loader.graph.nodes[('migrations', '0002_add_field')], True),\n        ]\n        full_plan = executor.migration_plan(executor.loader.graph.leaf_nodes(), clean_start=True)\n        state = executor._migrate_all_backwards(plan, full_plan, fake=False)\n        self.assertNotIn(('migrations', '0001_initial'), executor.recorder.applied_migrations())\n        self.assertNotIn(('migrations', '0002_add_field'), executor.recorder.applied_migrations())\n"], "sample_234": ["def test_union_with_empty_queryset(self):\n    qs1 = Number.objects.filter(num__gt=5)\n    qs2 = Number.objects.none()\n    union_qs = qs1.union(qs2)\n    self.assertNumbersEqual(union_qs, [6, 7, 8, 9])\n"], "sample_312": ["def test_add_method(self):\n    self.node2.add(('c', 3), 'DEFAULT')\n    self.assertEqual(self.node2.children, [('c', 3)])\n    self.node2.add(('d', 4), 'DEFAULT')\n    self.assertEqual(self.node2.children, [('c', 3), ('d', 4)])\n    self.node2.add(Node([('e', 5)]), 'DEFAULT')\n    self.assertEqual(self.node2.children, [('c', 3), ('d', 4), Node([('e', 5)])])\n    self.node2.add(Node([('f', 6)], 'AND'), 'OR')\n    self.assertEqual(self.node2.children, [Node([('c', 3), ('d', 4), Node([('e', 5)])]), Node([('f', 6)], 'AND')])\n"], "sample_584": ["def test_infer_concat_order_from_coords(self):\n    ds1 = Dataset({'x': ('time', [1, 2, 3]), 'y': ('time', [4, 5, 6])},\n                  coords={'time': ('time', [10, 20, 30])})\n    ds2 = Dataset({'x': ('time', [4, 5, 6]), 'y': ('time', [7, 8, 9])},\n                  coords={'time': ('time', [40, 50, 60])})\n    combined_ids, concat_dims = _infer_concat_order_from_coords([ds1, ds2])\n    expected_ids = OrderedDict([((0,), ds1), ((1,), ds2)])\n    assert_combined_tile_ids_equal(combined_ids, expected_ids)\n    assert concat_dims == ['time']\n"], "sample_1138": ["def test_TR111():\n    assert TR111(1 - 1/tan(x)**2) == 1 - cot(x)**2\n"], "sample_329": ["    def test_settings_reference_serializer(self):\n        value = SettingsReference('TIME_ZONE')\n        serializer = serializer_factory(value)\n        self.assertEqual(serializer.serialize(), (\"settings.TIME_ZONE\", {\"from django.conf import settings\"}))\n"], "sample_1170": ["def test_print_Tr():\n    A = Matrix([[1, 2], [3, 4]])\n    expr = Tr(A)\n    assert sstr(expr) == \"Tr(Matrix([[1, 2], [3, 4]]))\"\n"], "sample_18": ["def test_quantity_info_copy(self):\n    q_copy = copy.copy(self.q)\n    assert_info_equal(self.q, q_copy)\n"], "sample_184": ["    def test_unique_together_with_invalid_field(self):\n        class InvalidUniqueTogetherModel(models.Model):\n            field1 = models.CharField(max_length=10)\n            field2 = models.CharField(max_length=10)\n\n            class Meta:\n                unique_together = (('field1', 'invalid_field'),)\n\n        errors = InvalidUniqueTogetherModel.check()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'models.E012')\n        self.assertEqual(str(errors[0]), \"'unique_together' refers to the nonexistent field 'invalid_field'.\")\n"], "sample_39": ["def test_maps_files(self):\n    for filename in self._file_list:\n        with fits.open(filename) as hdulist:\n            w = wcs.WCS(hdulist[0].header)\n            # Perform some basic checks to ensure the WCS object is valid\n            assert w.naxis == 2\n            assert w.wcs.naxis == 2\n            assert w.wcs.lng == 0\n            assert w.wcs.lat == 1\n            assert w.wcs.lngtyp == 'RA'\n            assert w.wcs.lattyp == 'DEC'\n"], "sample_45": ["    def test_trunc_date(self):\n        dt = datetime(2022, 3, 15, 12, 30, 45)\n        obj = self.create_model(dt, dt + timedelta(days=1))\n        result = DTModel.objects.annotate(trunc_date=TruncDate('start_datetime')).get(id=obj.id).trunc_date\n        self.assertEqual(result, truncate_to(dt, 'day'))\n"], "sample_686": ["def test_deprecated_warnings(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        from _pytest import deprecated\n\n            class TestClass:\n                funcargnames = ['arg1', 'arg2']\n            with pytest.warns(deprecated.FUNCARGNAMES):\n                _ = TestClass.funcargnames\n\n            with pytest.warns(deprecated.FILLFUNCARGS):\n                from _pytest.python import Function\n                func = Function(name='test_func', parent=None)\n                func._fillfuncargs()\n\n        # Add more tests for other deprecated warnings as needed\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.assert_outcomes(passed=2)\n"], "sample_391": ["def test_create_model_with_managers(self):\n    operations = [\n        migrations.CreateModel(\n            name='TestModel',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('name', models.CharField(max_length=100)),\n            ],\n            managers=[\n                ('custom_manager', EmptyManager()),\n            ],\n        ),\n    ]\n    expected = [\n        migrations.CreateModel(\n            name='TestModel',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('name', models.CharField(max_length=100)),\n            ],\n            managers=[\n                ('custom_manager', EmptyManager()),\n            ],\n        ),\n    ]\n    self.assertOptimizesTo(operations, expected, exact=1)\n"], "sample_688": ["def test_import_path_importlib_mode(self, pytester: Pytester):\n    pytester.makepyfile(\n        test_module=\"\"\"\n            assert True\n        \"\"\"\n    )\n    test_module_path = pytester.path / \"test_module.py\"\n    import_path(test_module_path, mode=ImportMode.importlib)\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n"], "sample_888": ["def test_isolation_forest_with_sparse_matrix():\n    # Test IsolationForest with a sparse matrix input\n    rng = check_random_state(0)\n    X = csc_matrix(rng.rand(100, 10))\n    clf = IsolationForest(random_state=0)\n    clf.fit(X)\n    y_pred = clf.predict(X)\n    assert y_pred.shape == (100,)\n"], "sample_1148": ["def test_matrix_element_derivative():\n    M = MatrixSymbol('M', n, n)\n    v = MatrixSymbol('v', n, 1)\n    i, j = symbols('i j', integer=True)\n    elem = MatrixElement(M, i, j)\n    deriv = elem.diff(v)\n    assert deriv == KroneckerDelta(i, v.args[1], (0, n-1)) * KroneckerDelta(j, v.args[2], (0, n-1))\n"], "sample_802": ["def test_pipeline_with_fit_params():\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([0, 1, 0])\n    pipeline = make_pipeline(TransfFitParams(), LogisticRegression())\n    pipeline.fit(X, y, logisticregression__C=1.0)\n    assert pipeline.named_steps['logisticregression'].fit_params == {'C': 1.0}\n"], "sample_1089": ["def test_decompose_power():\n    assert decompose_power(x) == (x, 1)\n    assert decompose_power(x**2) == (x, 2)\n    assert decompose_power(x**(2*y)) == (x**y, 2)\n    assert decompose_power(x**(2*y/3)) == (x**(y/3), 2)\n"], "sample_647": ["def test_warn_explicit_for(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        from _pytest import warning_types\n\n            pass\n\n            warning_types.warn_explicit_for(test_func, warning_types.PytestWarning(\"Test warning\"))\n\n        if __name__ == \"__main__\":\n            pytest.main()\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*Test warning*\"])\n"], "sample_359": ["    def test_create_model_with_duplicate_fields(self):\n        operation = CreateModel(\n            name='DuplicateModel',\n            fields=[\n                ('field1', models.CharField(max_length=100)),\n                ('field1', models.IntegerField()),  # duplicate field name\n            ],\n        )\n        with self.assertRaises(ValueError) as context:\n            operation.deconstruct()\n        self.assertEqual(\n            str(context.exception),\n            \"Found duplicate value field1 in CreateModel fields argument.\"\n        )\n"], "sample_14": ["def test_angle_to_string_format():\n    a = Angle(45, unit=u.deg)\n    assert a.to_string(format='unicode') == '45\u00b000\u203200\u2033'\n    assert a.to_string(format='latex') == '$45^\\circ00{}^\\prime00{}^{\\prime\\prime}$'\n    assert a.to_string(format='latex_inline') == '$45^\\circ00{}^\\prime00{}^{\\prime\\prime}$'\n    with pytest.raises(ValueError):\n        a.to_string(format='invalid_format')\n"], "sample_465": ["def test_get_form(self):\n    ma = ModelAdmin(Band, self.site)\n    form = ma.get_form(request)\n    self.assertIsInstance(form, forms.ModelForm)\n    self.assertIn('name', form.base_fields)\n    self.assertIn('bio', form.base_fields)\n    self.assertIn('sign_date', form.base_fields)\n"], "sample_273": ["    def test_check_default_pk(self):\n        class DefaultPKModel(models.Model):\n            pass\n\n        with self.settings(DEFAULT_AUTO_FIELD='django.db.models.AutoField'):\n            errors = DefaultPKModel.check()\n            self.assertEqual(len(errors), 1)\n            self.assertEqual(errors[0].id, 'models.W042')\n\n        class CustomPKModel(models.Model):\n            id = models.BigAutoField(primary_key=True)\n\n        with self.settings(DEFAULT_AUTO_FIELD='django.db.models.AutoField'):\n            errors = CustomPKModel.check()\n            self.assertEqual(len(errors), 0)\n"], "sample_1050": ["def test_print_Mod():\n    expr = Mod(x, y)\n    result = pycode(expr)\n    assert result == \"x % y\"\n"], "sample_793": ["def test_isolation_forest_sparse_input():\n    # Test that IsolationForest can handle sparse input\n    X = csc_matrix(iris.data)\n    clf = IsolationForest(random_state=rng)\n    clf.fit(X)\n    y_pred = clf.predict(X)\n    assert_array_equal(y_pred.shape, (X.shape[0],))\n"], "sample_52": ["def test_model_choice_field_to_python(self):\n    field = forms.ModelChoiceField(queryset=Category.objects.all())\n    value = self.c1.pk\n    result = field.to_python(value)\n    self.assertEqual(result, self.c1)\n"], "sample_726": ["def test_label_binarizer_sparse_output():\n    lb = LabelBinarizer(sparse_output=True)\n    y = [0, 1, 2, 1]\n    lb.fit(y)\n    y_bin = lb.transform(y)\n    assert_true(issparse(y_bin))\n    assert_array_equal(y_bin.toarray(), np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0]]))\n"], "sample_1028": ["def test_mod_with_zero_divisor():\n    with raises(ZeroDivisionError):\n        Mod(x, 0)\n"], "sample_441": ["    def test_password_help_text(self):\n        form = UserChangeForm(instance=self.u1)\n        self.assertIn(f\"../../{self.u1.pk}/password/\", form.fields['password'].help_text)\n"], "sample_521": ["def test_text_3d_get_position_3d():\n    text = art3d.Text3D(x=1, y=2, z=3, text='Test')\n    assert text.get_position_3d() == (1, 2, 3)\n"], "sample_490": ["    def test_check_constraint_validation(self):\n        product = Product(name='Test', price=10)\n        product.full_clean()  # Should not raise any error\n\n        product.price = -5\n        with self.assertRaises(ValidationError):\n            product.full_clean()  # Should raise ValidationError due to check constraint\n"], "sample_141": ["def test_deserialize_fk_value(self):\n    field = models.ForeignKey(Score, on_delete=models.CASCADE)\n    using = 'default'\n    handle_forward_references = False\n\n    # Test with None value\n    self.assertIsNone(serializers.deserialize_fk_value(field, None, using, handle_forward_references))\n\n    # Test with existing object's natural key\n    score = Score.objects.create(value=10)\n    field_value = score.natural_key()\n    self.assertEqual(serializers.deserialize_fk_value(field, field_value, using, handle_forward_references), score.pk)\n\n    # Test with non-existing object's natural key\n    field_value = ('Non-existing',)\n    with self.assertRaises(Score.DoesNotExist):\n        serializers.deserialize_fk_value(field, field_value, using, handle_forward_references)\n\n    # Test with existing object's primary key\n    field_value = score.pk\n    self.assertEqual(serializers.deserialize_fk_value(field, field_value, using, handle_forward_references), score.pk)\n\n    # Test with non-existing object's primary key\n    field_value = 999\n    with self.assertRaises(Score.DoesNotExist):\n        serializers.deserialize_fk_value(field, field_value, using, handle_forward_references)\n"], "sample_626": ["def test_pandas_multi_indexing_adapter_repr():\n    index = pd.MultiIndex.from_tuples([(\"a\", 1), (\"b\", 2)], names=[\"letter\", \"number\"])\n    adapter = PandasMultiIndexingAdapter(index, level=\"letter\")\n    assert repr(adapter) == \"PandasMultiIndexingAdapter(array=MultiIndex(['a', 'b'], names=['letter', 'number']), level='letter', dtype=object)\"\n"], "sample_204": ["    def test_check_consistent_history(self):\n        \"\"\"\n        Test that check_consistent_history raises InconsistentMigrationHistory\n        if any applied migrations have unapplied dependencies.\n        \"\"\"\n        # Set up a migration graph with an unapplied dependency\n        loader = MigrationLoader(connection)\n        loader.graph.add_node(('testapp', '0001_initial'), None)\n        loader.graph.add_node(('testapp', '0002_add_field'), None)\n        loader.graph.add_dependency(('testapp', '0002_add_field'), ('testapp', '0001_initial'))\n        recorder = MigrationRecorder(connection)\n        recorder.record_applied('testapp', '0002_add_field')\n        # Check that check_consistent_history raises InconsistentMigrationHistory\n        with self.assertRaises(InconsistentMigrationHistory):\n            loader.check_consistent_history(connection)\n"], "sample_984": ["def test_print_Tr():\n    A = Matrix([[1, 2], [3, 4]])\n    assert sstr(Tr(A)) == \"Tr(Matrix([[1, 2], [3, 4]]))\"\n"], "sample_422": ["def test_forward_many_to_one_descriptor_get_prefetch_queryset(self):\n    # Test the get_prefetch_queryset method of ForwardManyToOneDescriptor\n    queryset = Author.objects.all()\n    prefetcher = get_prefetcher(queryset, 'first_book')\n    prefetch_queryset, _, _, _, _, _ = prefetcher.get_prefetch_queryset(queryset, queryset)\n    self.assertIsInstance(prefetch_queryset, QuerySet)\n    self.assertEqual(prefetch_queryset.model, Book)\n    self.assertWhereContains(str(prefetch_queryset.query), '`books_book`.`id` IN')\n"], "sample_1100": ["def test_pow_is_finite():\n    assert (x**y).is_finite == None\n    assert (x**2).is_finite == None\n    assert (2**x).is_finite == True\n    assert (2**2).is_finite == True\n    assert (0**x).is_finite == (x > 0)\n    assert (0**2).is_finite == True\n    assert (oo**x).is_finite == (x < 0)\n    assert (oo**2).is_finite == True\n    assert (zoo**x).is_finite == False\n    assert (zoo**2).is_finite == False\n"], "sample_226": ["    def test_test_db_signature(self):\n        test_connection = get_connection_copy()\n        db_creation = BaseDatabaseCreation(test_connection)\n        settings_dict = test_connection.settings_dict\n        expected_signature = (\n            settings_dict['HOST'],\n            settings_dict['PORT'],\n            settings_dict['ENGINE'],\n            TEST_DATABASE_PREFIX + settings_dict['NAME'],\n        )\n        self.assertEqual(db_creation.test_db_signature(), expected_signature)\n"], "sample_727": ["def test_imputer_with_nan_values():\n    \"\"\"Test imputation with NaN values.\"\"\"\n    X = np.array([[1, 2, np.nan], [4, np.nan, 6], [7, 8, 9]])\n    X_true = np.array([[1, 2, 5.5], [4, 5.5, 6], [7, 8, 9]])\n    statistics = np.array([1, 5.5, 7])\n\n    _check_statistics(X, X_true, \"mean\", statistics, np.nan)\n"], "sample_855": ["def test_dummy_classifier_constant_strategy():\n    X = np.array([[0], [1], [2], [3]])\n    y = np.array([1, 2, 1, 1])\n    constant = 2\n    clf = DummyClassifier(strategy=\"constant\", constant=constant)\n    clf.fit(X, y)\n    y_pred = clf.predict(X)\n    assert_array_equal(y_pred, np.full_like(y, constant))\n"], "sample_953": ["def test_generate_function():\n    d = {\n        'path': 'test_project',\n        'sep': False,\n        'dot': '_',\n        'project': 'Test Project',\n        'author': 'Test Author',\n        'version': '1.0',\n        'release': '1.0.0',\n        'language': 'en',\n        'suffix': '.rst',\n        'master': 'index',\n        'extensions': [],\n        'makefile': True,\n        'batchfile': True,\n        'quiet': True,\n    }\n    qs.generate(d, overwrite=True, silent=True)\n    assert path.isdir(d['path'])\n    assert path.isfile(path.join(d['path'], 'conf.py'))\n    assert path.isfile(path.join(d['path'], 'index.rst'))\n    assert path.isfile(path.join(d['path'], 'Makefile'))\n    assert path.isfile(path.join(d['path'], 'make.bat'))\n"], "sample_1062": ["def test_TR111():\n    assert TR111(1 - 1/tan(x)**2) == 1 - cot(x)**2\n"], "sample_300": ["def test_add_filtered_relation(self):\n    query = Query(Author)\n    filtered_relation = Author.objects.filter(name__startswith='A').as_filtered_relation('authors_starting_with_a')\n    query.add_filtered_relation(filtered_relation, 'authors_starting_with_a')\n    self.assertIn('authors_starting_with_a', query._filtered_relations)\n    self.assertEqual(query._filtered_relations['authors_starting_with_a'], filtered_relation)\n"], "sample_1045": ["def test_integer_nthroot():\n    assert integer_nthroot(8, 3) == (2, True)\n    assert integer_nthroot(27, 3) == (3, True)\n    assert integer_nthroot(26, 3) == (3, False)\n"], "sample_1071": ["def test_convert_to_multiple_units():\n    expr = 3*newton\n    target_units = [centimeter, gram, second]\n    result = convert_to(expr, target_units)\n    assert result == 300000*centimeter*gram/second**2\n"], "sample_467": ["    def test_format_value_with_date(self):\n        value = date(2012, 3, 4)\n        result = self.widget.format_value(value)\n        self.assertEqual(result, {\"year\": 2012, \"month\": 3, \"day\": 4})\n"], "sample_593": ["def test_dataset_repr(dataset):\n    html_repr = fh.dataset_repr(dataset)\n    assert isinstance(html_repr, str)\n    assert \"xarray.Dataset\" in html_repr\n    assert \"Dimensions\" in html_repr\n    assert \"Coordinates\" in html_repr\n    assert \"Data variables\" in html_repr\n    assert \"Attributes\" in html_repr\n"], "sample_712": ["def test_ordinal_encoder_inverse_transform():\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    X_transformed = enc.transform(X)\n    X_inverse = enc.inverse_transform(X_transformed)\n    assert_array_equal(X, X_inverse)\n"], "sample_108": ["    def test_converter_to_url(self):\n        for url, (view_name, namespace, kwargs) in converter_test_data:\n            with self.subTest(url=url, view_name=view_name, namespace=namespace, kwargs=kwargs):\n                if namespace:\n                    reversed_url = reverse(f'{namespace}:{view_name}', kwargs=kwargs)\n                else:\n                    reversed_url = reverse(view_name, kwargs=kwargs)\n                self.assertEqual(url, reversed_url)\n"], "sample_531": ["def test_figure_align_labels():\n    fig, axs = plt.subplots(2, 2)\n    for ax in axs.flat:\n        ax.label_outer()\n    fig.align_labels()\n"], "sample_928": ["def test_default_role():\n    from sphinx.util import docutils\n    from sphinx.util.rst import default_role\n\n    with default_role('test', 'emphasis'):\n        assert docutils.is_registered_role('')\n\n    assert not docutils.is_registered_role('')\n"], "sample_590": ["def test_concat_dataarray_with_dim_coord():\n    da1 = DataArray(np.arange(10), dims='x', coords={'x': np.arange(10)})\n    da2 = DataArray(np.arange(10, 20), dims='x', coords={'x': np.arange(10, 20)})\n    result = concat([da1, da2], dim='x')\n    expected = DataArray(np.arange(20), dims='x', coords={'x': np.arange(20)})\n    assert_identical(result, expected)\n"], "sample_550": ["def test_get_tightbbox_for_layout_only():\n    fig, ax = plt.subplots()\n    ax.set_title(\"Test Title\")\n    ax.set_xlabel(\"Test X Label\")\n    ax.set_ylabel(\"Test Y Label\")\n    bbox = ax.get_tightbbox(fig.canvas.get_renderer(), for_layout_only=True)\n    assert bbox.width > 0\n    assert bbox.height > 0\n    plt.close(fig)\n"], "sample_1151": ["def test_mod_with_add():\n    p = x + y + 2\n    q = x\n    assert Mod(p, q) == Mod(y + 2, x)\n"], "sample_1099": ["def test_partial_derivative_evaluation():\n    expr = A(i) * B(j)\n    pd = PartialDerivative(expr, A(k))\n    result = pd._perform_derivative()\n    assert result == B(j) * A(k).diff(A(k))\n"], "sample_863": ["def test_pipeline_fit_transform_with_fit_params():\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([0, 1, 0])\n    pipeline = make_pipeline(TransfFitParams(), Mult(mult=2))\n    pipeline.fit(X, y, transffitparamst__should_succeed=True)\n    X_transformed = pipeline.transform(X)\n    assert_array_equal(X_transformed, np.array([[2, 4], [6, 8], [10, 12]]))\n    assert pipeline.named_steps['transffitparamst'].fit_params == {'should_succeed': True}\n"], "sample_206": ["    def test_save_form_data(self):\n        document = Document()\n        document.my_file.save_form_data(document, 'test.txt')\n        self.assertEqual(document.my_file, 'test.txt')\n\n        document.my_file.save_form_data(document, None)\n        self.assertEqual(document.my_file, '')\n"], "sample_532": ["def test_contour_labeler_event_handler():\n    fig, ax = plt.subplots()\n    X, Y = np.meshgrid(np.linspace(-3, 3, 256), np.linspace(-3, 3, 256))\n    Z = (1 - X/2 + X**5 + Y**3) * np.exp(-X**2 - Y**2)\n    cs = ax.contour(X, Y, Z)\n\n    event = type('Event', (), {'name': 'button_press_event', 'button': 1, 'x': 0, 'y': 0, 'inaxes': ax})\n    _contour_labeler_event_handler(cs, inline=True, inline_spacing=5, event=event)\n    assert len(cs.labelTexts) == 1\n\n    event = type('Event', (), {'name': 'button_press_event', 'button': 3})\n    cs.pop_label()\n    assert len(cs.labelTexts) == 0\n\n    event = type('Event', (), {'name': 'key_press_event', 'key': 'escape'})\n    _contour_labeler_event_handler(cs, inline=True, inline_spacing=5, event=event)\n    assert len(cs.labelTexts) == 0\n"], "sample_566": ["def test_figure_align_labels():\n    fig, axs = plt.subplots(2, 2)\n    for ax in axs.flat:\n        ax.label_outer()\n    fig.align_labels()\n"], "sample_990": ["def test_atanh_rewrite_as_log():\n    x = symbols('x')\n    assert atanh(x)._eval_rewrite_as_log(x) == (log(1 + x) - log(1 - x)) / 2\n"], "sample_831": ["def test_export_text_with_show_weights():\n    decision_tree = DecisionTreeClassifier(random_state=0, max_depth=2)\n    decision_tree = decision_tree.fit(X, y)\n    r = export_text(decision_tree, feature_names=['feature_1', 'feature_2'], show_weights=True)\n    assert_in('weights: [3.0, 0.0]', r)\n    assert_in('weights: [0.0, 3.0]', r)\n    assert_in('weights: [0.0, 0.0, 3.0]', r)\n"], "sample_8": ["    def test_masked_array_initialization_with_quantity(self):\n        ma = Masked(self.a, mask=self.mask_a)\n        assert isinstance(ma.unmasked, Quantity)\n        assert_array_equal(ma.unmasked.value, self.a.value)\n        assert_array_equal(ma.mask, self.mask_a)\n"], "sample_914": ["compilation error"], "sample_161": ["    def test_unique_many_to_many_field(self):\n        class MyModel(models.Model):\n            m2m_field = models.ManyToManyField('self', unique=True)\n\n        field = MyModel._meta.get_field('m2m_field')\n        errors = field._check_unique()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'fields.E330')\n"], "sample_504": ["def test_colorbar_extension_length():\n    fig_uniform = _colorbar_extension_length('uniform')\n    fig_proportional = _colorbar_extension_length('proportional')\n    return fig_uniform, fig_proportional\n"], "sample_1171": ["def test_complex_region_from_real():\n    unit = Interval(0, 1)\n    region = ComplexRegion.from_real(unit)\n    assert region == CartesianComplexRegion(ProductSet(unit, FiniteSet(0)))\n"], "sample_472": ["def test_page_methods(self):\n    \"\"\"\n    Test the methods of the Page class.\n    \"\"\"\n    object_list = list(range(1, 101))\n    paginator = Paginator(object_list, 10)\n    page = paginator.page(5)\n\n    self.assertEqual(len(page), 10)\n    self.assertEqual(page[0], 41)\n    self.assertEqual(page[9], 50)\n    self.assertTrue(page.has_next())\n    self.assertTrue(page.has_previous())\n    self.assertTrue(page.has_other_pages())\n    self.assertEqual(page.next_page_number(), 6)\n    self.assertEqual(page.previous_page_number(), 4)\n    self.assertEqual(page.start_index(), 41)\n    self.assertEqual(page.end_index(), 50)\n"], "sample_898": ["def test_roc_auc_score_multiclass():\n    y_true = np.array([0, 1, 2, 0, 1, 2])\n    y_score = np.array([[0.1, 0.2, 0.7],\n                        [0.3, 0.4, 0.3],\n                        [0.6, 0.1, 0.3],\n                        [0.2, 0.7, 0.1],\n                        [0.8, 0.1, 0.1],\n                        [0.1, 0.3, 0.6]])\n\n    # Test 'macro' average\n    macro_roc_auc = roc_auc_score(y_true, y_score, average='macro')\n    assert_almost_equal(macro_roc_auc, 0.7777777777777778)\n\n    # Test 'weighted' average\n    weighted_roc_auc = roc_auc_score(y_true, y_score, average='weighted')\n    assert_almost_equal(weighted_roc_auc, 0.7777777777777778)\n\n    # Test 'ovr' multi-class strategy\n    ovr_roc_auc = roc_auc_score(y_true, y_score, multi_class='ovr')\n    assert_array_almost_equal(ovr_roc_auc, [0.83333333, 0.5, 0.5])\n\n    # Test 'ovo' multi-class strategy\n    ovo_roc_auc = roc_auc_score(y_true, y_score, multi_class='ovo')\n    assert_array_almost_equal(ovo_roc_auc, [0.83333333, 0.5, 0.5, 0.5, 0.5, 0.5])\n"], "sample_985": ["def test_min_max_rewrite_as_piecewise():\n    x, y, z = symbols('x y z')\n    assert Min(x, y)._eval_rewrite_as_Piecewise(x, y) == Piecewise((x, x <= y), (y, True))\n    assert Max(x, y)._eval_rewrite_as_Piecewise(x, y) == Piecewise((y, x <= y), (x, True))\n    assert Min(x, y, z)._eval_rewrite_as_Piecewise(x, y, z) == Piecewise((x, x <= y, x <= z), (y, x > y, y <= z), (z, True))\n    assert Max(x, y, z)._eval_rewrite_as_Piecewise(x, y, z) == Piecewise((z, x <= y, x <= z), (y, x > y, y >= z), (x, True))\n"], "sample_942": ["def test_parse_annotation(app):\n    env = Mock()\n    env.ref_context = {}\n    result = _parse_annotation(\"List[int]\", env)\n    assert len(result) == 5\n    assert isinstance(result[0], nodes.Text) and result[0].astext() == \"List\"\n    assert isinstance(result[1], addnodes.desc_sig_punctuation) and result[1].astext() == \"[\"\n    assert isinstance(result[2], pending_xref) and result[2].astext() == \"int\"\n    assert isinstance(result[3], addnodes.desc_sig_punctuation) and result[3].astext() == \"]\"\n"], "sample_818": ["def test_spectral_clustering_with_precomputed_affinity(eigen_solver, assign_labels):\n    # Test spectral_clustering with precomputed affinity matrix\n    X = np.array([[1, 1], [2, 1], [1, 0], [4, 7], [3, 5], [3, 6]])\n    affinity = rbf_kernel(X)\n    labels = spectral_clustering(affinity, n_clusters=2, eigen_solver=eigen_solver, assign_labels=assign_labels)\n    assert_equal(len(np.unique(labels)), 2)\n"], "sample_435": ["    def test_password_help_text(self):\n        form = UserChangeForm(instance=self.u1)\n        self.assertIn(f\"../../{self.u1.pk}/password/\", form.fields[\"password\"].help_text)\n"], "sample_1136": ["def test_expression_domain():\n    K = EX\n\n    f = K(x + 2)\n    g = K(x**2 - 1)\n\n    assert f + g == K(x**2 + x - 1)\n    assert f - g == K(-x**2 + x + 3)\n    assert f * g == K(x**3 + 2*x**2 - x - 2)\n    assert f / g == K((x + 2) / (x**2 - 1))\n    assert f**2 == K(x**2 + 4*x + 4)\n    assert f.gcd(g) == K(1)\n    assert f.lcm(g) == f * g\n    assert K.is_positive(K(x)) is None\n    assert K.is_negative(K(-x)) is True\n    assert K.is_nonpositive(K(0)) is True\n    assert K.is_nonnegative(K(x**2)) is True\n    assert K.numer(K((x + 2) / (x**2 - 1))) == K(x + 2)\n    assert K.denom(K((x + 2) / (x**2 - 1))) == K(x**2 - 1)\n"], "sample_705": ["def test_syspathinsert(pytester: Pytester) -> None:\n    original_sys_path = sys.path.copy()\n    pytester.syspathinsert()\n    assert sys.path[0] == str(pytester.path)\n    sys.path = original_sys_path\n"], "sample_1047": ["def test_is_algebraic():\n    x = Symbol('x')\n    assert sqrt(2).is_algebraic\n    assert log(x).is_algebraic\n    assert exp(x).is_algebraic\n    assert sin(x).is_algebraic\n    assert asin(x).is_algebraic\n    assert factorial(x).is_algebraic == False\n    assert Mod(x, 2).is_algebraic == None\n    assert (x + I).is_algebraic\n    assert (x**2 - 2).is_algebraic\n    assert (x**2 + 1).is_algebraic\n    assert (x**2 - 2*sqrt(2)).is_algebraic == False\n    assert (x**2 + 2*sqrt(2)).is_algebraic == False\n"], "sample_1193": ["def test_are_coplanar():\n    a = Line3D(Point3D(5, 0, 0), Point3D(1, -1, 1))\n    b = Line3D(Point3D(0, -2, 0), Point3D(3, 1, 1))\n    c = Line3D(Point3D(0, -1, 0), Point3D(5, -1, 9))\n    assert not are_coplanar(a, b, c)\n\n    d = Line3D(Point3D(0, 0, 0), Point3D(1, 1, 1))\n    assert are_coplanar(a, b, d)\n"], "sample_666": ["def test_global_and_fixture_disabled(self, method):\n    capman = CaptureManager(method)\n    capman.global_and_fixture_disabled = lambda: contextlib.nullcontext()\n    with capman.global_and_fixture_disabled():\n        assert not capman.is_globally_captured()\n        assert not capman.is_fixture_captured()\n"], "sample_1115": ["def test_tensor_mul_with_scalar():\n    Lorentz = TensorIndexType('Lorentz', dummy_name='L')\n    i, j = tensor_indices('i,j', Lorentz)\n    A = tensor_heads('A', [Lorentz]*2, TensorSymmetry.fully_symmetric(2))\n    t = A(i, j) * 2\n    assert t == 2 * A(i, j)\n"], "sample_466": ["    def test_serialize_enum(self):\n        # Test serialization of Enum instances\n        text_enum = TextEnum.A\n        text_enum_string, text_enum_imports = MigrationWriter.serialize(text_enum)\n        self.assertEqual(text_enum_string, \"TestModel1.TextEnum.A\")\n        self.assertEqual(text_enum_imports, {\"import TestModel1\"})\n\n        text_translated_enum = TextTranslatedEnum.B\n        text_translated_enum_string, text_translated_enum_imports = MigrationWriter.serialize(text_translated_enum)\n        self.assertEqual(text_translated_enum_string, \"TestModel1.TextTranslatedEnum.B\")\n        self.assertEqual(text_translated_enum_imports, {\"import TestModel1\", \"from django.utils.translation import gettext_lazy as _\"})\n\n        binary_enum = BinaryEnum.A\n        binary_enum_string, binary_enum_imports = MigrationWriter.serialize(binary_enum)\n        self.assertEqual(binary_enum_string, \"TestModel1.BinaryEnum.A\")\n        self.assertEqual(binary_enum_imports, {\"import TestModel1\"})\n\n        int_enum = IntEnum.B\n        int_enum_string, int_enum_imports = MigrationWriter.serialize(int_enum)\n        self.assertEqual(int_enum_string, \"TestModel1.IntEnum.B\")\n        self.assertEqual(int_enum_imports, {\"import TestModel1\"})\n\n        int_flag_enum = IntFlagEnum.A | IntFlagEnum.B\n        int_flag_enum_string, int_flag_enum_imports = MigrationWriter.serialize(int_flag_enum)\n        self.assertEqual(int_flag_enum_string, \"TestModel1.IntFlagEnum.A | TestModel1.IntFlagEnum.B\")\n        self.assertEqual(int_flag_enum_imports, {\"import TestModel1\"})\n"], "sample_486": ["def test_inlineformset_factory_with_fk_name(self):\n    InlineFormSet = inlineformset_factory(\n        AutoPKParent,\n        AutoPKChildOfUUIDPKParent,\n        fk_name=\"auto_pk_parent\",\n    )\n    self.assertEqual(InlineFormSet.fk.name, \"auto_pk_parent\")\n"], "sample_403": ["    def test_create_model_with_duplicate_field_names(self):\n        operation = migrations.CreateModel(\n            name=\"DuplicateFieldModel\",\n            fields=[\n                (\"field1\", models.CharField(max_length=10)),\n                (\"field1\", models.IntegerField()),\n            ],\n        )\n        with self.assertRaisesMessage(\n            ValueError, \"Found duplicate value field1 in CreateModel fields argument.\"\n        ):\n            operation.deconstruct()\n"], "sample_1140": ["compilation error"], "sample_682": ["def test_evaluate_xfail_marks(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.xfail(reason=\"bug 123\")\n            assert False\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.assert_outcomes(xfailed=1)\n    assert \"bug 123\" in result.stdout.str()\n"], "sample_679": ["    def test_istrue(self, attr, modulename):\n        class DummyItem:\n                self.config = None\n                self.obj = None\n\n                if name == \"mark\":\n                    return [Mark(\"mark\", args=(\"True\",), kwargs={\"reason\": \"Test reason\"})]\n                return []\n\n        evaluator = MarkEvaluator(DummyItem(), attr)\n        assert evaluator.istrue() is True\n        assert evaluator.getexplanation() == \"Test reason\"\n"], "sample_343": ["    def test_generic_foreign_key_get_filter_kwargs_for_object(self):\n        question = Question.objects.create(question_text=\"Test question\")\n        answer = Answer.objects.create(question=question, answer_text=\"Test answer\")\n        gfk = GenericForeignKey('content_type', 'object_id')\n        filter_kwargs = gfk.get_filter_kwargs_for_object(answer)\n        self.assertEqual(filter_kwargs, {'object_id': answer.id, 'content_type': answer.content_type_id})\n"], "sample_1059": ["def test_jacobi_normalized_special_values():\n    n = Symbol('n', integer=True)\n    a = Symbol('a')\n    b = Symbol('b')\n\n    assert jacobi_normalized(n, a, b, 0) == jacobi(n, a, b, 0) / sqrt(2**(a + b + 1) * gamma(a + n + 1) * gamma(b + n + 1) / ((a + b + 2*n + 1) * factorial(n) * gamma(a + b + n + 1)))\n    assert jacobi_normalized(n, a, b, 1) == jacobi(n, a, b, 1) / sqrt(2**(a + b + 1) * gamma(a + n + 1) * gamma(b + n + 1) / ((a + b + 2*n + 1) * factorial(n) * gamma(a + b + n + 1)))\n    assert jacobi_normalized(n, a, b, -1) == jacobi(n, a, b, -1) / sqrt(2**(a + b + 1) * gamma(a + n + 1) * gamma(b + n + 1) / ((a + b + 2*n + 1) * factorial(n) * gamma(a + b + n + 1)))\n"], "sample_142": ["compilation error"], "sample_124": ["def test_field_widget_attrs(self):\n    field = CharField(max_length=10, min_length=5)\n    widget_attrs = field.widget_attrs(TextInput())\n    self.assertEqual(widget_attrs['maxlength'], '10')\n    self.assertEqual(widget_attrs['minlength'], '5')\n"], "sample_1011": ["def test_kronecker_delta():\n    i, j = symbols('i j', integer=True)\n    expr = KroneckerDelta(i, j)\n    assert mcode(expr) == \"double(i == j)\"\n"], "sample_186": ["    def test_check_autocomplete_fields(self):\n        class InvalidAutocompleteFields(admin.ModelAdmin):\n            autocomplete_fields = 'title'\n\n        class InvalidAutocompleteFieldsItem(admin.ModelAdmin):\n            autocomplete_fields = ['invalid_field']\n\n        class ValidAutocompleteFieldsItem(admin.ModelAdmin):\n            autocomplete_fields = ['author']\n\n        class NoRelatedAdmin(admin.ModelAdmin):\n            autocomplete_fields = ['city']\n\n        class NoSearchFields(admin.ModelAdmin):\n            autocomplete_fields = ['state']\n\n        site = AdminSite()\n        site.register(Song, ValidAutocompleteFieldsItem)\n\n        self.assertEqual(\n            ModelAdminChecks()._check_autocomplete_fields(InvalidAutocompleteFields()),\n            must_be('a list or tuple', option='autocomplete_fields', obj=InvalidAutocompleteFields(), id='admin.E036')\n        )\n        self.assertEqual(\n            ModelAdminChecks()._check_autocomplete_fields_item(InvalidAutocompleteFieldsItem(), 'invalid_field', 'autocomplete_fields[0]'),\n            refer_to_missing_field(field='invalid_field', option='autocomplete_fields[0]', obj=InvalidAutocompleteFieldsItem(), id='admin.E037')\n        )\n        self.assertEqual(\n            ModelAdminChecks()._check_autocomplete_fields_item(NoRelatedAdmin(), 'city', 'autocomplete_fields[0]'),\n            [checks.Error(\n                'An admin for model \"City\" has to be registered to be referenced by NoRelatedAdmin.autocomplete_fields.',\n                obj=NoRelatedAdmin.__class__,\n                id='admin.E039',\n            )]\n        )\n        self.assertEqual(\n            ModelAdminChecks()._check_autocomplete_fields_item(NoSearchFields(), 'state', 'autocomplete_fields[0]'),\n            [checks.Error(\n                'State"], "sample_409": ["def test_i18n03(self):\n    output = self.engine.render_to_string(\"i18n03\", {\"anton\": \"Anton\"})\n    self.assertEqual(output, \"Anton\")\n"], "sample_709": ["def test_syspathinsert(pytester: Pytester) -> None:\n    pytester.syspathinsert()\n    assert str(pytester.path) in sys.path\n"], "sample_362": ["def test_generate_altered_db_table(self):\n    changes = self.get_changes(\n        [self.author_with_db_table_options],\n        [self.author_with_new_db_table_options],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelTable\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, table=\"author_two\")\n"], "sample_659": ["def test_exception_info_from_current(self):\n    try:\n        raise ValueError(\"test exception\")\n    except ValueError:\n        excinfo = ExceptionInfo.from_current()\n        assert excinfo.typename == \"ValueError\"\n        assert str(excinfo.value) == \"test exception\"\n"], "sample_74": ["    def test_runshell_db_with_ssl(self):\n        dbinfo = {\n            'host': 'localhost',\n            'port': '5432',\n            'database': 'testdb',\n            'user': 'testuser',\n            'password': 'testpass',\n            'sslmode': 'verify-ca',\n            'sslrootcert': 'root.crt',\n            'sslcert': 'client.crt',\n            'sslkey': 'client.key',\n        }\n        args, pg_env = self._run_it(dbinfo)\n        self.assertIn('-U', args)\n        self.assertIn('testuser', args)\n        self.assertIn('-h', args)\n        self.assertIn('localhost', args)\n        self.assertIn('-p', args)\n        self.assertIn('5432', args)\n        self.assertIn('testdb', args)\n        self.assertEqual(pg_env['PGSSLMODE'], 'verify-ca')\n        self.assertEqual(pg_env['PGSSLROOTCERT'], 'root.crt')\n        self.assertEqual(pg_env['PGSSLCERT'], 'client.crt')\n        self.assertEqual(pg_env['PGSSLKEY'], 'client.key')\n"], "sample_1180": ["def test_point_canberra_distance():\n    p1 = Point(1, 1)\n    p2 = Point(3, 3)\n    assert p1.canberra_distance(p2) == 1\n\n    p1 = Point(0, 0)\n    p2 = Point(3, 3)\n    assert p1.canberra_distance(p2) == 2\n\n    p1 = Point(0, 0)\n    p2 = Point(0, 0)\n    with raises(ValueError):\n        p1.canberra_distance(p2)\n"], "sample_385": ["    def setUp(self):\n        self.band1 = Band.objects.create(name=\"Band1\")\n        self.band2 = Band.objects.create(name=\"Band2\")\n        self.album = Album.objects.create(band=self.band1)\n"], "sample_631": ["def test_check_self_cls_assign(self):\n    node = astroid.parse(\"class Test:\\n    def method(self):\\n        self = 10\").body[0].body[0].body[0]\n    with self.assertAddsMessages(Message('self-cls-assignment', node=node, args=('self',))):\n        self.checker._check_self_cls_assign(node)\n"], "sample_919": ["def test_function_pointer_to_member():\n    input = \"void (C::*f)(int)\"\n    idDict = {1: \"C::f\"}\n    output = \"void (C::*f)(int)\"\n    check(\"function\", input, idDict, output)\n"], "sample_967": ["def test_mathjax_install(app, status, warning):\n    app.builder.build_all()\n    assert 'http://example.com/mathjax.js' in app.builder.script_files\n    assert 'defer' in app.builder.script_files['http://example.com/mathjax.js']\n    assert 'mathjax_config' in warning.getvalue()\n"], "sample_318": ["    def test_resolve_error_handler(self):\n        resolver = get_resolver()\n        self.assertEqual(resolver.resolve_error_handler(400), views.custom_handler400)\n        self.assertEqual(resolver.resolve_error_handler(403), views.custom_handler403)\n        self.assertEqual(resolver.resolve_error_handler(404), views.custom_handler404)\n        self.assertEqual(resolver.resolve_error_handler(500), views.custom_handler500)\n"], "sample_555": ["def test_fancyarrowpatch_set_positions():\n    arrow = FancyArrowPatch((0, 0), (1, 1))\n    assert_array_equal(arrow._posA_posB, [[0, 0], [1, 1]])\n    arrow.set_positions((2, 2), (3, 3))\n    assert_array_equal(arrow._posA_posB, [[2, 2], [3, 3]])\n"], "sample_975": ["def test_nsolve_with_one_dimensional_function():\n    x = Symbol('x')\n    result = nsolve(sin(x), x, 2)\n    assert mnorm(result - mpf(3.14159265358979)) < 1e-14\n"], "sample_194": ["    def test_check_constraint(self):\n        check = models.Q(price__gt=0)\n        constraint = CheckConstraint(check=check, name='positive_price')\n        self.assertEqual(constraint.check, check)\n        self.assertEqual(constraint.name, 'positive_price')\n\n        # Test constraint_sql\n        model = Product\n        schema_editor = mock.Mock()\n        schema_editor._check_sql.return_value = 'CHECK (price > 0)'\n        self.assertEqual(constraint.constraint_sql(model, schema_editor), 'CHECK (price > 0)')\n\n        # Test create_sql\n        schema_editor._create_check_sql.return_value = 'ALTER TABLE product ADD CONSTRAINT positive_price CHECK (price > 0)'\n        self.assertEqual(constraint.create_sql(model, schema_editor), 'ALTER TABLE product ADD CONSTRAINT positive_price CHECK (price > 0)')\n\n        # Test remove_sql\n        schema_editor._delete_check_sql.return_value = 'ALTER TABLE product DROP CONSTRAINT positive_price'\n        self.assertEqual(constraint.remove_sql(model, schema_editor), 'ALTER TABLE product DROP CONSTRAINT positive_price')\n\n        # Test deconstruct\n        path, args, kwargs = constraint.deconstruct()\n        self.assertEqual(path, 'django.db.models.CheckConstraint')\n        self.assertEqual(args, ())\n        self.assertEqual(kwargs, {'name': 'positive_price', 'check': check})\n\n        # Test clone\n        cloned_constraint = constraint.clone()\n        self.assertEqual(cloned_constraint.check, check)\n        self.assertEqual(cloned_constraint.name, 'positive_price')\n"], "sample_236": ["def test_collect_with_restricted_objects(self):\n    # Create a restricted object\n    restricted_obj = RChild.objects.create(r=self.DEFAULT)\n\n    # Create an object that references the restricted object\n    obj = RChildChild.objects.create(rchild=restricted_obj)\n\n    # Collect objects for deletion\n    collector = Collector(using='default')\n    collector.collect([obj])\n\n    # Check that the restricted object is in the collector's restricted_objects\n    self.assertIn(RChild, collector.restricted_objects)\n    self.assertIn(RChild._meta.get_field('rchild'), collector.restricted_objects[RChild])\n    self.assertIn(restricted_obj, collector.restricted_objects[RChild][RChild._meta.get_field('rchild')])\n\n    # Try to delete the object, which should raise a RestrictedError\n    with self.assertRaises(RestrictedError) as cm:\n        collector.delete()\n\n    # Check that the RestrictedError contains the restricted object\n    self.assertIn(restricted_obj, cm.exception.restricted_objects)\n"], "sample_443": ["    def setUp(self):\n        self.cache = caches[\"default\"]\n        self.cache.clear()\n"], "sample_212": ["    def test_session_middleware(self):\n        middleware = SessionMiddleware(lambda request: HttpResponse())\n        request = HttpRequest()\n        response = middleware(request)\n        self.assertIsNotNone(request.session)\n        self.assertFalse(request.session.modified)\n        self.assertTrue(request.session.is_empty())\n        self.assertNotIn(settings.SESSION_COOKIE_NAME, response.cookies)\n\n        # Simulate a session modification\n        request.session['test'] = 'test'\n        response = middleware(request)\n        self.assertTrue(request.session.modified)\n        self.assertFalse(request.session.is_empty())\n        self.assertIn(settings.SESSION_COOKIE_NAME, response.cookies)\n\n        # Simulate a session deletion\n        del request.session['test']\n        response = middleware(request)\n        self.assertTrue(request.session.modified)\n        self.assertTrue(request.session.is_empty())\n        self.assertNotIn(settings.SESSION_COOKIE_NAME, response.cookies)\n"], "sample_297": ["def test_query_with_filtered_relation(self):\n    filtered_relation = Author.objects.filter(num__gt=2000)\n    items = Item.objects.filter(creator__in=filtered_relation)\n    self.assertEqual(list(items), [self.i3, self.i4])\n"], "sample_156": ["def test_form_initialization(self):\n    data = {'first_name': 'John', 'last_name': 'Doe', 'birthday': '1990-01-01'}\n    form = Person(data=data)\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data, data)\n"], "sample_452": ["    def test_add_index(self):\n        operation = migrations.AddIndex(\"TestModel\", models.Index(fields=[\"name\"], name=\"test_index\"))\n\n        # Test state_forwards\n        state = ProjectState()\n        state.add_model(ModelState(\"app_label\", \"TestModel\", [], {}, (models.Model,), []))\n        operation.state_forwards(\"app_label\", state)\n        self.assertEqual(len(state.models[\"app_label\", \"testmodel\"].options[\"indexes\"]), 1)\n\n        # Test database_forwards\n        with self.temporary_migration_table() as table_name:\n            with connection.schema_editor() as schema_editor:\n                schema_editor.create_model(UnicodeModel)\n                operation.database_forwards(\"app_label\", schema_editor, ProjectState(), state)\n                self.assertIn(\"test_index\", connection.introspection.get_constraints(connection.cursor(), \"app_label_testmodel\"))\n\n        # Test database_backwards\n        with self.temporary_migration_table() as table_name:\n            with connection.schema_editor() as schema_editor:\n                schema_editor.create_model(UnicodeModel)\n                operation.database_backwards(\"app_label\", schema_editor, state, ProjectState())\n                self.assertNotIn(\"test_index\", connection.introspection.get_constraints(connection.cursor(), \"app_label_testmodel\"))\n"], "sample_1120": ["def test_matrix_element_derivative():\n    M = MatrixSymbol('M', n, n)\n    N = MatrixSymbol('N', n, n)\n    i, j = symbols('i j', integer=True)\n    elem = MatrixElement(M, i, j)\n    dM = MatrixElement(N, i, j)\n    result = elem._eval_derivative(dM)\n    expected = KroneckerDelta(i, dM.i, (0, n-1)) * KroneckerDelta(j, dM.j, (0, n-1))\n    assert result == expected\n"], "sample_34": ["def test_unit_conversion_with_equivalencies():\n    # Test unit conversion with equivalencies\n    equivalencies = [(u.m, u.cm, lambda x: x * 100, lambda x: x / 100)]\n    assert_allclose(u.m.to(u.cm, equivalencies=equivalencies), 100)\n    assert_allclose(u.cm.to(u.m, equivalencies=equivalencies), 0.01)\n"], "sample_368": ["    def test_migration_plan_with_replaced_migration(self):\n        \"\"\"\n        Test that the migration plan is correctly reloaded when a replaced migration is missing.\n        \"\"\"\n        executor = MigrationExecutor(connection)\n        executor.loader.replace_migrations = True\n        executor.loader.build_graph()\n        target = ('migrations', '0002_replaced')\n        # Remove the replaced migration from the graph\n        del executor.loader.graph.node_map[target]\n        plan = executor.migration_plan([target])\n        # The migration plan should be reloaded without replacements\n        self.assertFalse(executor.loader.replace_migrations)\n        # The plan should include the replacement migration\n        self.assertIn((executor.loader.graph.nodes[('migrations', '0003_replacement')], False), plan)\n"], "sample_994": ["def test_integer_nthroot():\n    assert integer_nthroot(8, 3) == (2, True)\n    assert integer_nthroot(27, 3) == (3, True)\n    assert integer_nthroot(26, 3) == (3, False)\n"], "sample_339": ["    def test_save_m2m_called_after_save(self):\n        class BookForm(forms.ModelForm):\n            class Meta:\n                model = Book\n                fields = ['name', 'authors']\n\n        author1 = Author.objects.create(name='Author 1')\n        author2 = Author.objects.create(name='Author 2')\n        book_form = BookForm({'name': 'Test Book', 'authors': [author1.pk, author2.pk]})\n        self.assertTrue(book_form.is_valid())\n        book = book_form.save(commit=False)\n        self.assertFalse(book.authors.exists())\n        book.save()\n        self.assertTrue(book.authors.exists())\n        self.assertEqual(book.authors.count(), 2)\n"], "sample_598": ["def test_format_timedelta(self):\n    # Test formatting of timedelta objects\n    td = pd.Timedelta(days=2, hours=3, minutes=4, seconds=5)\n    assert formatting.format_timedelta(td) == \"2 days 03:04:05\"\n    assert formatting.format_timedelta(td, timedelta_format=\"date\") == \"2 days\"\n    assert formatting.format_timedelta(td, timedelta_format=\"time\") == \"03:04:05\"\n"], "sample_396": ["def test_query_ordering(self):\n    # Test ordering by a field with a custom database column name\n    items = Item.objects.order_by('created')\n    self.assertEqual(list(items), [self.i2, self.i1, self.i3, self.i4])\n\n    # Test ordering by a related field with a custom database column name\n    items = Item.objects.order_by('creator__num')\n    self.assertEqual(list(items), [self.i1, self.i3, self.i2, self.i4])\n"], "sample_998": ["def test_latex_Quaternion():\n    q = Quaternion(1, 2, 3, 4)\n    assert latex(q) == \"1 + 2\\\\mathbf{i} + 3\\\\mathbf{j} + 4\\\\mathbf{k}\"\n"], "sample_1195": ["def test_simplify_gamma_expression():\n    i0, i1, i2 = tensor_indices('i0:3', LorentzIndex)\n    p = TensorHead('p', [LorentzIndex])\n    expr = p(i0)*G(-i0)*G(i1)*p(-i1)*G(i2)*p(-i2)\n    simplified_expr = simplify_gamma_expression(expr)\n    expected_expr = -4*p(i0)*p(-i0)*p(i1)*p(-i1)*p(i2)*p(-i2)\n    assert _is_tensor_eq(simplified_expr, expected_expr)\n"], "sample_49": ["def test_media_property_with_extend(self):\n    class ParentWidget(Widget):\n        class Media:\n            css = {'all': ['parent.css']}\n            js = ['parent.js']\n\n    class ChildWidget(ParentWidget):\n        class Media:\n            css = {'all': ['child.css']}\n            js = ['child.js']\n\n    widget = ChildWidget()\n    expected_media = Media(css={'all': ['parent.css', 'child.css']}, js=['parent.js', 'child.js'])\n    self.assertEqual(widget.media, expected_media)\n"], "sample_987": ["def test_evalf_atan():\n    assert NS(atan(1), 15) == \"0.785398163397448\"\n    assert NS(atan(0), 15) == \"0.0\"\n    assert NS(atan(oo), 15) == \"1.57079632679490\"\n    assert NS(atan(ninf), 15) == \"-1.57079632679490\"\n"], "sample_542": ["def test_annotation_arrowprops():\n    fig, ax = plt.subplots()\n    ann = ax.annotate('Test', xy=(0.5, 0.5), xytext=(0.2, 0.2),\n                      arrowprops=dict(facecolor='black', shrink=0.05))\n    assert isinstance(ann.arrow_patch, mpatches.FancyArrowPatch)\n    assert ann.arrow_patch.get_facecolor() == 'black'\n    assert ann.arrow_patch.shrinkA == 0.05\n    assert ann.arrow_patch.shrinkB == 0.05\n"], "sample_334": ["def test_form_initialization(self):\n    data = {'first_name': 'John', 'last_name': 'Doe', 'birthday': '1990-01-01'}\n    form = Person(data=data)\n    self.assertTrue(form.is_bound)\n    self.assertEqual(form.data, data)\n    self.assertEqual(form.initial, {})\n    self.assertEqual(form.prefix, None)\n    self.assertEqual(form.error_class, ErrorList)\n    self.assertEqual(form.label_suffix, ':')\n    self.assertFalse(form.empty_permitted)\n    self.assertTrue(form.use_required_attribute)\n    self.assertIsInstance(form.renderer, DjangoTemplates)\n"], "sample_835": ["def test_adaboost_classifier_with_sample_weight():\n    X, y = iris.data, iris.target\n    sample_weight = np.ones(len(y))\n    sample_weight[y == 0] = 0.5\n    clf = AdaBoostClassifier(n_estimators=10, random_state=rng)\n    clf.fit(X, y, sample_weight=sample_weight)\n    assert len(clf.estimators_) == 10\n    assert_array_less(clf.estimator_errors_, 0.5)\n"], "sample_305": ["def test_aggregate_with_filter(self):\n    # Test aggregate function with filter\n    avg_rating = Book.objects.filter(publisher=self.p1).aggregate(Avg('rating'))\n    self.assertEqual(avg_rating['rating__avg'], 4.25)\n"], "sample_964": ["def test_parse_annotation(app):\n    env = app.builder.env\n    annotation = \"List[Union[int, str]]\"\n    result = _parse_annotation(annotation, env)\n    expected = [pending_xref('', 'List', refdomain='py', reftype='class', reftarget='typing.List'),\n                addnodes.desc_sig_punctuation('', '['),\n                pending_xref('', 'Union', refdomain='py', reftype='class', reftarget='typing.Union'),\n                addnodes.desc_sig_punctuation('', '['),\n                addnodes.desc_sig_literal_number('', 'int'),\n                addnodes.desc_sig_punctuation('', ','),\n                addnodes.desc_sig_space(),\n                addnodes.desc_sig_literal_string('', \"'str'\"),\n                addnodes.desc_sig_punctuation('', ']'),\n                addnodes.desc_sig_punctuation('', ']')]\n    assert_node(result, expected)\n"], "sample_774": ["def test_ordinal_encoder_inverse_transform():\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    X_transformed = enc.transform(X)\n    X_inverse = enc.inverse_transform(X_transformed)\n    assert_array_equal(X_inverse, X)\n"], "sample_946": ["def test_parse_annotation(app):\n    env = app.builder.env\n    result = _parse_annotation(\"List[int]\", env)\n    assert len(result) == 3\n    assert isinstance(result[0], pending_xref)\n    assert result[0].get('reftarget') == 'List'\n    assert result[1].astext() == '['\n    assert isinstance(result[2], pending_xref)\n    assert result[2].get('reftarget') == 'int'\n"], "sample_962": ["def test_mock_finder():\n    with mock(['target.module.name']):\n        import target.module.name\n        assert 'target.module.name' in sys.modules\n        assert sys.modules['target.module.name'].__sphinx_mock__\n\n    assert 'target.module.name' not in sys.modules\n"], "sample_1013": ["def test_lambdify_with_tensorflow_module():\n    f = Max(x, sin(x))\n    func = lambdify(x, f, 'tensorflow')\n    result = func(tensorflow.constant(1.0))\n    sess = tensorflow.Session()\n    assert sess.run(result) == 1.0\n"], "sample_459": ["def test_integer_field_exact(self):\n    obj = self.model.objects.create(value=123)\n    self.assertEqual(self.model.objects.get(value__exact=123), obj)\n    with self.assertRaises(self.model.DoesNotExist):\n        self.model.objects.get(value__exact=456)\n"], "sample_527": ["def test_figure_savefig_transparent():\n    fig = Figure()\n    ax = fig.add_subplot(111)\n    ax.plot([1, 2, 3], [1, 2, 3])\n    fig.savefig('test.png', transparent=True)\n    # Add assertions to verify the saved figure is transparent\n"], "sample_786": ["def test_invalid_n_bins(strategy):\n    with assert_raises(ValueError):\n        KBinsDiscretizer(n_bins=1, strategy=strategy).fit(X)\n"], "sample_387": ["def test_formfield_for_foreignkey_with_autocomplete(self):\n    \"\"\"\n    Test that formfield_for_dbfield returns an AutocompleteSelect widget for\n    ForeignKey fields in the autocomplete_fields list.\n    \"\"\"\n    self.assertFormfield(\n        Car,\n        \"owner\",\n        widgets.AutocompleteSelect,\n        autocomplete_fields=(\"owner\",),\n    )\n"], "sample_669": ["def test_start_global_capturing(method):\n    capman = CaptureManager(method)\n    capman.start_global_capturing()\n    assert capman.is_globally_capturing()\n    assert capman._global_capturing is not None\n    capman.stop_global_capturing()\n    assert not capman.is_globally_capturing()\n    assert capman._global_capturing is None\n"], "sample_27": ["def test_table_data_diff_ignore_fields(self):\n    col1 = Column(name='COL1', format='I', array=[1, 2, 3])\n    col2 = Column(name='COL2', format='I', array=[4, 5, 6])\n    col3 = Column(name='COL3', format='I', array=[7, 8, 9])\n\n    hdu1 = BinTableHDU.from_columns([col1, col2])\n    hdu2 = BinTableHDU.from_columns([col1, col3])\n\n    diff = TableDataDiff(hdu1.data, hdu2.data, ignore_fields=['COL2'])\n    assert diff.identical\n"], "sample_673": ["def test_get_checker(mocker):\n    checker = _get_checker()\n    assert checker is not None\n    assert isinstance(checker, mocker.ANY)\n"], "sample_710": ["def test_pytest_pycollect_makeitem(pytester: Pytester, monkeypatch: MonkeyPatch):\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n\n        class TestMyClass(unittest.TestCase):\n                self.assertEqual(1, 1)\n        \"\"\"\n    )\n    monkeypatch.setitem(sys.modules, \"unittest\", sys.modules[\"unittest\"])\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n"], "sample_834": ["def test_nca_transform():\n    nca = NeighborhoodComponentsAnalysis(n_components=2, random_state=0)\n    nca.fit(iris_data, iris_target)\n    transformed_data = nca.transform(iris_data)\n    assert transformed_data.shape == (iris_data.shape[0], 2)\n"], "sample_678": ["def test_fnmatch_ex_with_pathlib(self, match, pattern, path):\n    assert match(pattern, path)\n"], "sample_635": ["def test_numpy_docstring_match_param_docs(self):\n    \"\"\"Test match_param_docs method for NumpyDocstring\"\"\"\n    docstring = \"\"\"\n    Parameters\n    ----------\n    param1 : int\n        Description of param1.\n    param2 : str, optional\n        Description of param2.\n    \"\"\"\n    doc = Docstring(docstring)\n    params_with_doc, params_with_type = doc.match_param_docs()\n    assert params_with_doc == {\"param1\", \"param2\"}\n    assert params_with_type == {\"param1\", \"param2\"}\n"], "sample_1156": ["def test_asech_diff():\n    x = symbols('x')\n    assert asech(x).diff(x) == -1/(x*sqrt(1 - x**2))\n"], "sample_741": ["def test_grid_search_cv_with_pipeline():\n    # Test GridSearchCV with a pipeline\n    pipe = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),\n                           ('classifier', LinearSVC())])\n    param_grid = {'classifier__C': [0.1, 1.0, 10.0]}\n    grid_search = GridSearchCV(pipe, param_grid, cv=5)\n    grid_search.fit(X, y)\n    assert_true(hasattr(grid_search, 'best_estimator_'))\n    assert_true(hasattr(grid_search, 'best_params_'))\n    assert_true(hasattr(grid_search, 'best_score_'))\n"], "sample_434": ["    def setUp(self):\n        self.factory = RequestFactory()\n"], "sample_529": ["def test_legend_set_draggable():\n    fig, ax = plt.subplots()\n    line, = ax.plot([1, 2, 3], [1, 2, 3], label='Test line')\n    legend = ax.legend()\n\n    # Test enabling draggable\n    draggable = legend.set_draggable(state=True)\n    assert isinstance(draggable, mlegend.DraggableLegend)\n    assert legend.get_draggable() is True\n\n    # Test disabling draggable\n    legend.set_draggable(state=False)\n    assert legend.get_draggable() is False\n"], "sample_1145": ["def test_refine_matrixelement_antisymmetric():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.antisymmetric(X)) == -X[1, 0]\n    assert refine(X[1, 0], Q.antisymmetric(X)) == -X[0, 1]\n"], "sample_602": ["def test_to_netcdf_invalid_netcdf():\n    ds = xr.Dataset({'var': ('dim', np.arange(10))})\n    with xr.set_options(file_cache_maxsize=0):\n        with xr.testing.assert_warns(UserWarning):\n            ds.to_netcdf('test.nc', engine='h5netcdf', invalid_netcdf=True)\n"], "sample_1161": ["def test_print_Subs():\n    expr = x + y\n    old = x\n    new = 2*x\n    sub = Subs(expr, old, new)\n    assert sstr(sub) == \"Subs(x + y, x, 2*x)\"\n"], "sample_70": ["    def test_sort_method(self):\n        collector = Collector(using='default')\n        collector.dependencies = {\n            A: {B, C},\n            B: {D},\n            C: {D},\n            D: set(),\n        }\n        collector.data = {\n            A: [A()],\n            B: [B()],\n            C: [C()],\n            D: [D()],\n        }\n        collector.sort()\n        self.assertEqual(list(collector.data.keys()), [D, B, C, A])\n"], "sample_811": ["def test_pairwise_distances_chunked_reduce_func_output_size():\n    X = np.random.RandomState(0).rand(5, 3)\n    reduce_func = lambda D_chunk, start: D_chunk.mean(axis=1)\n    gen = pairwise_distances_chunked(X, reduce_func=reduce_func)\n    with assert_raises_regexp(ValueError, \"Expected same length as input\"):\n        next(gen)\n"], "sample_483": ["    def test_check_autocomplete_fields(self):\n        class InvalidAutocompleteFields(admin.ModelAdmin):\n            autocomplete_fields = \"title\"\n\n        class InvalidAutocompleteFieldsItem(admin.ModelAdmin):\n            autocomplete_fields = [\"invalid_field\"]\n\n        class ValidAutocompleteFieldsItem(admin.ModelAdmin):\n            autocomplete_fields = [\"author\"]\n\n        class NoRelatedAdmin(admin.ModelAdmin):\n            autocomplete_fields = [\"city\"]\n\n        class NoSearchFields(admin.ModelAdmin):\n            autocomplete_fields = [\"state\"]\n\n        site = AdminSite()\n        site.register(Song, ValidAutocompleteFieldsItem)\n\n        self.assertEqual(\n            ModelAdminChecks()._check_autocomplete_fields(InvalidAutocompleteFields()),\n            must_be(\"a list or tuple\", \"autocomplete_fields\", InvalidAutocompleteFields(), \"admin.E036\"),\n        )\n        self.assertEqual(\n            ModelAdminChecks()._check_autocomplete_fields_item(InvalidAutocompleteFieldsItem(), \"invalid_field\", \"autocomplete_fields[0]\"),\n            refer_to_missing_field(\"invalid_field\", \"autocomplete_fields[0]\", InvalidAutocompleteFieldsItem(), \"admin.E037\"),\n        )\n        self.assertEqual(\n            ModelAdminChecks()._check_autocomplete_fields_item(NoRelatedAdmin(), \"city\", \"autocomplete_fields[0]\"),\n            [checks.Error(\"An admin for model 'City' has to be registered to be referenced by NoRelatedAdmin.autocomplete_fields.\", obj=NoRelatedAdmin, id=\"admin.E039\")],\n        )\n        self.assertEqual(\n            ModelAdminChecks()._check_autocomplete_fields_item(NoSearchFields(), \"state\", \"autocomplete_fields[0]\"),\n            [checks.Error(\"StateAdmin must define 'search_fields', because it's referenced by NoSearchFields.autocomplete_fields.\", obj=NoSearchFields"], "sample_10": ["def test_set_column_with_masked_values(self):\n    t = self._table_type([self.a, self.b])\n    masked_col = self._column_type([1, 2, 3], name='masked', mask=[True, False, True])\n    t['masked'] = masked_col\n    assert isinstance(t['masked'], MaskedColumn)\n    assert_array_equal(t['masked'].mask, [True, False, True])\n"], "sample_717": ["def test_fetch_lfw_people():\n    # Test fetch_lfw_people function with color=True\n    dataset = fetch_lfw_people(data_home=SCIKIT_LEARN_DATA, color=True)\n    assert_equal(dataset.images.shape[1:], (250, 250, 3))\n    assert_equal(dataset.data.shape[1], 250 * 250 * 3)\n\n    # Test fetch_lfw_people function with resize=0.75\n    dataset = fetch_lfw_people(data_home=SCIKIT_LEARN_DATA, resize=0.75)\n    assert_equal(dataset.images.shape[1:], (187, 187))\n    assert_equal(dataset.data.shape[1], 187 * 187)\n\n    # Test fetch_lfw_people function with min_faces_per_person=3\n    dataset = fetch_lfw_people(data_home=SCIKIT_LEARN_DATA, min_faces_per_person=3)\n    assert_equal(len(np.unique(dataset.target)), len(FAKE_NAMES) - 1)  # One name has less than 3 faces\n"], "sample_140": ["    def test_sensitive_variables_with_specified_variables(self):\n        @sensitive_variables('user', 'password')\n            pass\n\n        self.assertEqual(my_function.sensitive_variables, ('user', 'password'))\n"], "sample_971": ["def test_is_suppressed_warning():\n    assert is_suppressed_warning('ref.python', None, ['ref.python'])\n    assert is_suppressed_warning('ref.python', 'module', ['ref.python.module'])\n    assert is_suppressed_warning('ref.python', 'module', ['ref.python.*'])\n    assert not is_suppressed_warning('ref.python', 'module', ['ref.python.class'])\n    assert not is_suppressed_warning('ref.cpp', None, ['ref.python'])\n    assert not is_suppressed_warning(None, None, ['ref.python'])\n"], "sample_382": ["    def test_template_changed(self):\n        file_path = EXTRA_TEMPLATES_DIR / 'test_template.html'\n        file_path.touch()\n        with mock.patch('django.utils.autoreload.file_changed.send') as mock_send:\n            autoreload.template_changed(None, file_path)\n            mock_send.assert_called_once()\n        file_path.unlink()\n"], "sample_642": ["def test_preprocess_options_enable_all_extensions(capsys: CaptureFixture[str]) -> None:\n    \"\"\"Test the _preprocess_options function with --enable-all-extensions option.\"\"\"\n    with tempfile.TemporaryDirectory() as tmpdir:\n        # Create a fake extension file\n        fake_extension_path = Path(tmpdir) / \"pylint\" / \"extensions\" / \"fake_extension.py\"\n        fake_extension_path.parent.mkdir(parents=True)\n        fake_extension_path.touch()\n\n        # Mock the extensions module to return the fake extension\n        with mock.patch.dict(\"sys.modules\", {\"pylint.extensions\": importlib.import_module(\"pylint.extensions\")}):\n            with mock.patch(\"pylint.extensions.__file__\", str(fake_extension_path)):\n                run = Run([\"--enable-all-extensions\"], exit=False)\n                assert \"pylint.extensions.fake_extension\" in run._plugins\n\n        # Check that the output is empty\n        captured = capsys.readouterr()\n        assert captured.out == \"\"\n        assert captured.err == \"\"\n"], "sample_420": ["def test_modelform_defines_fields(self):\n    class DefinesFieldsForm(forms.ModelForm):\n        class Meta:\n            model = Book\n            fields = \"__all__\"\n\n    class ExcludesFieldsForm(forms.ModelForm):\n        class Meta:\n            model = Book\n            exclude = [\"title\"]\n\n    class NoFieldsForm(forms.ModelForm):\n        class Meta:\n            model = Book\n\n    self.assertTrue(modelform_defines_fields(DefinesFieldsForm))\n    self.assertTrue(modelform_defines_fields(ExcludesFieldsForm))\n    self.assertFalse(modelform_defines_fields(NoFieldsForm))\n"], "sample_31": ["def test_write_latex_invalid_format(self, cosmo, tmp_path):\n    \"\"\"Test that an error is raised when an invalid format is provided.\"\"\"\n    with pytest.raises(ValueError, match=\"format must be 'latex' or 'ascii.latex', not invalid\"):\n        write_latex(cosmo, tmp_path / \"test.tex\", format=\"invalid\")\n"], "sample_64": ["    def test_http_response_redirect(self):\n        response = HttpResponseRedirect('/redirect-url/')\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response['Location'], '/redirect-url/')\n\n        with self.assertRaises(DisallowedRedirect):\n            HttpResponseRedirect('http://example.com')\n"], "sample_694": ["def test_check_ispytest_warning(pytester):\n    pytester.makepyfile(\n        \"\"\"\n        import warnings\n        from _pytest import deprecated\n\n            with warnings.catch_warnings(record=True) as w:\n                deprecated.check_ispytest(False)\n                assert len(w) == 1\n                assert issubclass(w[-1].category, PytestDeprecationWarning)\n                assert \"A private pytest class or function was used.\" in str(w[-1].message)\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n"], "sample_159": ["    def test_non_unique_username_field(self):\n        errors = check_user_model(self.apps.get_app_configs())\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'auth.W004')\n"], "sample_1082": ["def test_asech_diff():\n    x = symbols('x')\n    assert asech(x).diff(x) == -1/(x*sqrt(1 - x**2))\n    assert asech(1).diff(x) == 0\n"], "sample_848": ["def test_multioutput_regressor_partial_fit():\n    X, y = datasets.make_regression(n_samples=100, n_features=10, n_targets=3, random_state=42)\n    est = MultiOutputRegressor(estimator=SGDRegressor())\n    est.partial_fit(X[:50], y[:50])\n    y_pred = est.predict(X[50:])\n    assert y_pred.shape == (50, 3)\n"], "sample_473": ["    def setUp(self):\n        request_started.disconnect(close_old_connections)\n"], "sample_745": ["def test_function_transformer_with_custom_func():\n    args_store = []\n    kwargs_store = {}\n    custom_func = _make_func(args_store, kwargs_store, func=lambda X: X ** 2)\n    ft = FunctionTransformer(func=custom_func, kw_args={'a': 1, 'b': 2})\n    X = np.array([[1, 2], [3, 4]])\n    ft.fit_transform(X)\n    assert_array_equal(args_store[0], X)\n    assert_equal(kwargs_store, {'a': 1, 'b': 2})\n    assert_array_equal(ft.transform(X), X ** 2)\n"], "sample_1184": ["def test_beam_parameter_properties():\n    p = BeamParameter(530e-9, 1, w=1e-3)\n    assert p.q == 1 + 1.88679245283019*I*pi\n    assert N(p.q) == 1.0 + 5.92753330865999*I\n    assert p.w_0 == 0.00100000000000000\n    assert p.z_r == 5.92753330865999\n    fs = FreeSpace(10)\n    p1 = fs*p\n    assert N(p.w) == 0.00101413072159615\n    assert N(p1.w) == 0.00210803120913829\n"], "sample_360": ["    def setUp(self):\n        self.factory = RequestFactory()\n        self.middleware = CacheMiddleware(empty_response)\n"], "sample_1143": ["def test_integer_nthroot():\n    assert integer_nthroot(8, 3) == (2, True)\n    assert integer_nthroot(27, 3) == (3, True)\n    assert integer_nthroot(26, 3) == (3, False)\n"], "sample_1009": ["def test_vector_diff():\n    q1 = dynamicsymbols('q1')\n    N = ReferenceFrame('N')\n    A = N.orientnew('A', 'Axis', [q1, N.y])\n    assert A.x.diff(q1, N) == -sin(q1) * N.x - cos(q1) * N.z\n"], "sample_250": ["    def test_date_format_with_time_specifiers(self):\n        dt = datetime(2022, 1, 1, 12, 30, 45)\n        with self.assertRaises(TypeError):\n            format(dt, 'Y-m-d H:i:s')\n"], "sample_3": ["def test_ecsv_outputter_json_subtype():\n    # Test the EcsvOutputter with JSON-encoded values\n    t = Table()\n    t['a'] = [1, 2, 3]\n    t['b'] = ['[1, 2, 3]', '[4, 5, 6]', '[7, 8, 9]']\n    t['b'].info.dtype = 'str'\n    t['b'].info.subtype = 'json'\n\n    outputter = EcsvOutputter()\n    outputter._convert_vals(t.columns.values())\n\n    assert np.array_equal(t['b'].data, np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=object))\n"], "sample_570": ["    def test_kde_univariate(self, x):\n        kde = KDE()\n        density, support = kde(x)\n        assert np.all(density >= 0)\n        assert np.isclose(self.integrate(density, support), 1)\n"], "sample_797": ["def test_power_transform_yeo_johnson():\n    X = np.array([[1, 2], [3, 2], [4, 5]])\n    pt = PowerTransformer(method='yeo-johnson')\n    X_trans = pt.fit_transform(X)\n    X_inv = pt.inverse_transform(X_trans)\n    assert_array_almost_equal(X, X_inv)\n"], "sample_530": ["def test_offsetbox_draggable():\n    fig, ax = plt.subplots()\n    box = TextArea(\"Test\")\n    ab = AnnotationBbox(box, (0.5, 0.5))\n    ax.add_artist(ab)\n\n    # Simulate dragging the AnnotationBbox\n    draggable = DraggableAnnotation(ab)\n    draggable.save_offset()\n    draggable.update_offset(50, 50)\n    draggable.finalize_offset()\n\n    plt.close(fig)\n"], "sample_996": ["def test_product_convergence():\n    assert product(1/n**2, (n, 1, oo)).is_convergent() == S.false\n    assert product(exp(-n**2), (n, 1, oo)).is_convergent() == S.false\n    assert product(cos(pi/n), (n, 1, oo)).is_convergent() == S.true\n"], "sample_901": ["def test_kmeans_predict_sparse_elkan(representation, algo, dtype):\n    if representation == 'sparse' and algo == 'elkan':\n        X = X_csr.astype(dtype)\n        kmeans = KMeans(n_clusters=n_clusters, algorithm=algo, random_state=42)\n        kmeans.fit(X)\n        labels = kmeans.predict(X)\n        assert_array_equal(labels, true_labels)\n"], "sample_1137": ["def test_convert_to_planck_units():\n    from sympy.physics.units import hbar, speed_of_light\n    result = convert_to(hbar, [gravitational_constant, speed_of_light, hbar])\n    assert result == hbar / sqrt(gravitational_constant * speed_of_light**3)\n"], "sample_285": ["def test_default_storage_finder(self):\n    finder = get_finder('django.contrib.staticfiles.finders.DefaultStorageFinder')\n    self.assertIsInstance(finder, BaseFinder)\n    self.assertEqual(finder.storage, settings.DEFAULT_FILE_STORAGE)\n\n    # Test find method\n    with mock.patch('django.core.files.storage.default_storage.exists') as mock_exists, \\\n         mock.patch('django.core.files.storage.default_storage.path') as mock_path:\n        mock_exists.return_value = True\n        mock_path.return_value = '/path/to/file'\n        result = finder.find('test.txt')\n        self.assertEqual(result, '/path/to/file')\n        mock_exists.assert_called_once_with('test.txt')\n        mock_path.assert_called_once_with('test.txt')\n\n    # Test list method\n    with mock.patch('django.contrib.staticfiles.utils.get_files') as mock_get_files:\n        mock_get_files.return_value = ['test.txt']\n        result = list(finder.list([]))\n        self.assertEqual(result, [('test.txt', settings.DEFAULT_FILE_STORAGE)])\n        mock_get_files.assert_called_once_with(settings.DEFAULT_FILE_STORAGE, [])\n"], "sample_1150": ["def test_complex_region_from_real():\n    unit = Interval(0, 1)\n    complex_region = ComplexRegion.from_real(unit)\n    assert complex_region == CartesianComplexRegion(ProductSet(unit, FiniteSet(0)))\n"], "sample_492": ["    def test_serialize_enum(self):\n        for enum_class in [TextEnum, TextTranslatedEnum, BinaryEnum, IntEnum, IntFlagEnum]:\n            operation = custom_migration_operations.operations.AlterField(\n                model_name='TestModel',\n                name='enum_field',\n                field=models.CharField(max_length=10, choices=[(tag, tag.value) for tag in enum_class]),\n            )\n            operation_string, _ = OperationWriter(operation).serialize()\n            self.assertIn(f\"'choices=[({repr(tag)}, {repr(tag.value)}) for tag in {enum_class.__name__}\", operation_string)\n"], "sample_940": ["def test_signature_from_str():\n    sig = inspect.signature_from_str(\"(a: int, b: str = 'default') -> bool\")\n    assert str(sig) == \"(a: int, b: str = 'default') -> bool\"\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.parameters['b'].default == 'default'\n    assert sig.return_annotation == bool\n"], "sample_1176": ["def test_integer_nthroot():\n    assert integer_nthroot(8, 3) == (2, True)\n    assert integer_nthroot(27, 3) == (3, True)\n    assert integer_nthroot(26, 3) == (3, False)\n"], "sample_254": ["def test_inline_change_view(self):\n    url = reverse('admin:admin_inlines_inner_change', args=[self.holder.inner.pk])\n    response = self.client.get(url)\n    self.assertEqual(response.status_code, 200)\n    self.assertContains(response, INLINE_CHANGELINK_HTML)\n"], "sample_665": ["def test_function_definition_runtest(self):\n    with pytest.raises(RuntimeError, match=\"function definitions are not supposed to be used\"):\n        self.function.runtest()\n"], "sample_57": ["    def test_clean_password(self):\n        form = UserChangeForm(instance=self.u1)\n        self.assertEqual(form.clean_password(), self.u1.password)\n"], "sample_569": ["def test_regplot_with_numpy_arrays(self):\n    x = self.df['x'].values\n    y = self.df['y'].values\n    ax = lm.regplot(x=x, y=y)\n    assert isinstance(ax, mpl.axes.Axes)\n"], "sample_482": ["def test_escapeseq_safe(self):\n    self.assertEqual(self.output[\"escapeseq_safe\"], \"a, b\")\n    self.context[\"c\"] = [mark_safe(\"a\"), mark_safe(\"b\")]\n    self.assertEqual(self.output[\"escapeseq_safe\"], \"a, b\")\n"], "sample_852": ["def test_make_classification_n_samples_greater_than_n_classes():\n    n_samples = 100\n    n_classes = 5\n    X, y = make_classification(n_samples=n_samples, n_classes=n_classes)\n    assert len(np.unique(y)) == n_classes\n    assert len(y) == n_samples\n"], "sample_436": ["    def test_runserver_ipv6(self):\n        self.write_settings(\"settings.py\")\n        with self.settings(ROOT_URLCONF=__name__):\n            urlpatterns = [\n                path(\"\", serve, {\"path\": \".\", \"document_root\": self.test_dir}),\n            ]\n            with mock.patch(\"django.core.management.commands.runserver.run\") as run_mock:\n                call_command(\"runserver\", \"::1:8000\", use_ipv6=True)\n                run_mock.assert_called_once_with(\n                    \"::1\", 8000, mock.ANY, ipv6=True, threading=True, server_cls=RunserverCommand.server_cls\n                )\n"], "sample_15": ["compilation error"], "sample_534": ["def test_contour_with_extent():\n    x = np.linspace(-5, 5, 100)\n    y = np.linspace(-5, 5, 100)\n    X, Y = np.meshgrid(x, y)\n    Z = np.sin(X) + np.cos(Y)\n\n    fig, ax = plt.subplots()\n    cs = ax.contour(X, Y, Z, levels=10, extent=[-4, 4, -4, 4])\n\n    assert ax.get_xlim() == (-4, 4)\n    assert ax.get_ylim() == (-4, 4)\n    assert len(cs.levels) == 10\n"], "sample_271": ["    def test_zip_imported_module(self):\n        zip_filename = self.temporary_file('test.zip')\n        module_name = 'test_module'\n        module_filename = f'{module_name}.py'\n        module_code = b'print(\"Hello, world!\")'\n\n        with zipfile.ZipFile(zip_filename, 'w') as zipf:\n            zipf.writestr(module_filename, module_code)\n\n        sys.path.insert(0, str(zip_filename))\n        self.addCleanup(sys.path.remove, str(zip_filename))\n\n        self.import_and_cleanup(module_name)\n        self.assertFileFound(zip_filename)\n"], "sample_427": ["def test_formset_with_custom_kwargs(self):\n    CustomKwargFormSet = formset_factory(CustomKwargForm, extra=2, form_kwargs={'custom_kwarg': 'test'})\n    formset = CustomKwargFormSet()\n    for form in formset:\n        self.assertEqual(form.custom_kwarg, 'test')\n"], "sample_672": ["def test_saferepr_with_exception():\n    class BadRepr:\n            raise ValueError(\"Bad __repr__\")\n\n    obj = BadRepr()\n    result = saferepr(obj)\n    assert \"ValueError\" in result\n    assert \"BadRepr\" in result\n"], "sample_1066": ["def test_mathml_printing_of_derivative():\n    expr = Derivative(sin(x), x)\n    result = mathml(expr)\n    expected = \"<apply><diff/><bvar><ci>x</ci></bvar><sin><ci>x</ci></sin></apply>\"\n    assert result == expected\n"], "sample_1042": ["def test_indexed_base_strides():\n    A = IndexedBase('A', strides=(2, 3))\n    i, j = symbols('i j', integer=True)\n    assert A[i, j].strides == (2, 3)\n"], "sample_1073": ["def test_sqrtdenest_with_cos():\n    expr = sqrt(2)*(3/(sqrt(7) + sqrt(5)*cos(2)))\n    assert sqrtdenest(expr) == sqrt(2)*(3/(sqrt(7) + sqrt(5)*cos(2)))\n"], "sample_1027": ["def test_to_rational_coeffs():\n    p = Poly(((x**2-1)*(x-2)).subs({x:x*(1 + sqrt(2))}), x, domain='EX')\n    lc, r, _, g = to_rational_coeffs(p)\n    assert lc == 7 + 5*sqrt(2)\n    assert r == -2*sqrt(2) + 2\n    assert g == Poly(x**3 + x**2 - 1/4*x - 1/4, x, domain='QQ')\n"], "sample_394": ["def test_admin_view_index(self):\n    response = self.client.get(reverse(\"admin:index\"))\n    self.assertEqual(response.status_code, 200)\n    self.assertContains(response, \"Site administration\")\n"], "sample_84": ["    def test_urlencode_with_multivalue_dict(self):\n        query = MultiValueDict({'key1': ['value1', 'value2'], 'key2': ['value3']})\n        result = urlencode(query)\n        self.assertEqual(result, 'key1=value1&key1=value2&key2=value3')\n"], "sample_192": ["def test_formset_factory_with_custom_kwargs(self):\n    CustomKwargFormSet = formset_factory(CustomKwargForm, formset=BaseFormSet, extra=2, form_kwargs={'custom_kwarg': 'test'})\n    formset = CustomKwargFormSet()\n    for form in formset:\n        self.assertEqual(form.custom_kwarg, 'test')\n"], "sample_643": ["def test_colorize_ansi(reporter):\n    msg = \"Test message\"\n    msg_style = MessageStyle(\"red\", (\"bold\",))\n    result = reporter.colorize_ansi(msg, msg_style)\n    assert result == \"\\033[1;31mTest message\\033[0m\"\n"], "sample_1040": ["def test_print_MatrixSymbol():\n    A = MatrixSymbol('A', 2, 2)\n    assert mathml(A, printer='presentation') == '<mi mathvariant=\"bold\">A</mi>'\n"], "sample_581": ["def test_blueprint_add_url_rule_with_invalid_endpoint(app):\n    bp = flask.Blueprint(\"test\", __name__)\n\n    with pytest.raises(ValueError) as excinfo:\n        bp.add_url_rule(\"/\", endpoint=\"invalid.endpoint\", view_func=lambda: None)\n\n    assert str(excinfo.value) == \"'endpoint' may not contain a dot '.' character.\"\n"], "sample_993": ["def test_free_group_elements():\n    # Test the creation of free group elements\n    assert x * y != y * x\n    assert x**2 * y**-1 * x**-2 == F.identity\n    assert x**2 * y**-2 * z**-1 == F.dtype(((x, 2), (y, -2), (z, -1)))\n"], "sample_187": ["    def test_truncator_chars(self):\n        truncator = text.Truncator('This is a long text that needs to be truncated.')\n        result = truncator.chars(10)\n        self.assertEqual(result, 'This is a\u2026')\n"], "sample_103": ["    def test_aggregate_filter(self):\n        # Test filtering with aggregate functions\n        books_after_2000 = Book.objects.filter(pubdate__year__gt=2000)\n        avg_rating_after_2000 = books_after_2000.aggregate(Avg('rating', filter=F('pages') > 400))['rating__avg']\n        self.assertEqual(avg_rating_after_2000, 4.0)\n\n        count_books_with_high_rating = Book.objects.aggregate(Count('id', filter=F('rating') > 4.0))['id__count']\n        self.assertEqual(count_books_with_high_rating, 4)\n"], "sample_983": ["def test_sparse_matrix_solve():\n    A = SparseMatrix([[2, 1], [1, 2]])\n    b = Matrix([3, 4])\n    x = A.solve(b)\n    assert x == Matrix([2, 1])\n"], "sample_60": ["def test_generic_inline_admin_change_view(self):\n    url = reverse('admin:generic_inline_admin_episode_change', args=[self.episode_pk])\n    response = self.client.get(url)\n    self.assertEqual(response.status_code, 200)\n    self.assertContains(response, 'This Week in Django')\n    self.assertContains(response, 'http://example.com/podcast.mp3')\n    self.assertContains(response, 'http://example.com/logo.png')\n"], "sample_1204": ["def test_coset_init():\n    a = Permutation(1, 2)\n    b = Permutation(0, 1)\n    G = PermutationGroup([a, b])\n    cst = Coset(a, G, dir=\"+\")\n    assert cst.is_right_coset\n    assert not cst.is_left_coset\n"], "sample_432": ["def test_get_changelist_instance_with_invalid_lookup_parameters(self):\n    request = self._mocked_authenticated_request(\"/admin/admin_changelist/parent/?invalid_param=1\", self.superuser)\n    parent_admin = ParentAdmin(Parent, custom_site)\n    with self.assertRaises(IncorrectLookupParameters):\n        parent_admin.get_changelist_instance(request)\n"], "sample_762": ["def test_is_classifier():\n    clf = SVC()\n    assert_true(is_classifier(clf))\n\n    reg = DecisionTreeRegressor()\n    assert_false(is_classifier(reg))\n\n    no_est = NoEstimator()\n    assert_false(is_classifier(no_est))\n"], "sample_536": ["def test_button_callback(ax):\n        callback.called = True\n    callback.called = False\n    button = widgets.Button(ax, 'Test')\n    button.on_clicked(callback)\n    event = mock_event(button, 'button_press_event', x=0.5, y=0.5)\n    do_event(button, event)\n    event = mock_event(button, 'button_release_event', x=0.5, y=0.5)\n    do_event(button, event)\n    assert callback.called\n"], "sample_619": ["def test_decode_cf_datetime_with_invalid_units(num_dates, calendar):\n    invalid_units = \"invalid units\"\n    with pytest.raises(ValueError, match=f\"invalid time units: {invalid_units}\"):\n        decode_cf_datetime(num_dates, invalid_units, calendar)\n"], "sample_819": ["def test_voting_classifier_predict_proba():\n    clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=1)\n    clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n    clf3 = GaussianNB()\n    X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n    y = np.array([1, 1, 1, 2, 2, 2])\n    eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft')\n    eclf = eclf.fit(X, y)\n    proba = eclf.predict_proba(X)\n    assert proba.shape == (6, 2)\n    assert_array_almost_equal(proba.sum(axis=1), np.ones(6))\n"], "sample_446": ["def test_floatformat_with_arg(self):\n    self.engine.context[\"c\"] = Decimal(\"34.23234\")\n    self.engine.context[\"d\"] = Decimal(\"34.00000\")\n    self.engine.context[\"e\"] = Decimal(\"34.26000\")\n    self.assertEqual(self.engine.render(\"floatformat02\"), \"34.232 34.000 34.260\")\n"], "sample_350": ["def test_union(self):\n    qs1 = Number.objects.filter(num__lt=5)\n    qs2 = Number.objects.filter(num__gt=5)\n    union_qs = qs1.union(qs2)\n    self.assertNumbersEqual(union_qs, Number.objects.all(), ordered=False)\n"], "sample_845": ["def test_tfidf_vectorizer_with_custom_analyzer():\n    vectorizer = TfidfVectorizer(analyzer=lazy_analyze)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n    assert X.shape == (11, 1)\n    assert_array_almost_equal(X.toarray(), np.ones((11, 1)))\n"], "sample_484": ["    def test_right_function(self):\n        author = Author.objects.get(name=\"John Smith\")\n        self.assertEqual(Right(Lower(\"name\"), 4).resolve_expression(author), \"mith\")\n        self.assertEqual(Right(Lower(\"alias\"), 3).resolve_expression(author), \"ith\")\n        self.assertEqual(Right(Lower(\"name\"), 100).resolve_expression(author), \"john smith\")\n        self.assertEqual(Right(Lower(\"alias\"), 100).resolve_expression(author), \"smithj\")\n        self.assertEqual(Right(Lower(\"name\"), Value(4)).resolve_expression(author), \"mith\")\n        self.assertEqual(Right(Lower(\"alias\"), Value(3)).resolve_expression(author), \"ith\")\n        self.assertEqual(Right(Lower(\"name\"), Length(\"name\")).resolve_expression(author), \"john smith\")\n        self.assertEqual(Right(Lower(\"alias\"), Length(\"alias\")).resolve_expression(author), \"smithj\")\n        author = Author.objects.get(name=\"Rhonda\")\n        self.assertEqual(Right(Lower(\"name\"), 4).resolve_expression(author), \"onda\")\n        self.assertEqual(Right(Lower(\"name\"), 100).resolve_expression(author), \"rhonda\")\n        self.assertEqual(Right(Lower(\"name\"), Value(4)).resolve_expression(author), \"onda\")\n        self.assertEqual(Right(Lower(\"name\"), Length(\"name\")).resolve_expression(author), \"rhonda\")\n"], "sample_81": ["    def test_route_pattern_match(self):\n        pattern = RoutePattern(route='foo/<int:pk>')\n        match = pattern.match('foo/123')\n        self.assertEqual(match, ('', (), {'pk': 123}))\n"], "sample_418": ["compilation error"], "sample_748": ["def test_parameter_grid_with_empty_dict():\n    param_grid = {}\n    grid = ParameterGrid(param_grid)\n    assert_equal(list(grid), [{}])\n    assert_grid_iter_equals_getitem(grid)\n"], "sample_753": ["def test_logistic_regression_path_multinomial():\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=2,\n                               n_redundant=10, n_classes=3, random_state=42)\n    coefs, Cs, n_iter = logistic_regression_path(X, y, multi_class='multinomial')\n    assert_equal(coefs.shape, (len(Cs), 3, 20))\n    assert_equal(n_iter.shape, (len(Cs),))\n"], "sample_1207": ["def test_convert_xor():\n    tokens = [(OP, '^')]\n    result = convert_xor(tokens, {}, {})\n    assert result == [(OP, '**')]\n"], "sample_761": ["def test_iterative_imputer_with_custom_estimator():\n    \"\"\"Test IterativeImputer with a custom estimator.\"\"\"\n    X = np.array([[1, 2, np.nan],\n                  [3, np.nan, 5],\n                  [7, 8, 9]])\n\n    estimator = DummyRegressor(strategy=\"mean\")\n    imputer = IterativeImputer(estimator=estimator)\n    X_imputed = imputer.fit_transform(X)\n\n    # Check that the imputed values are correct\n    X_true = np.array([[1, 2, 6],\n                       [3, 5.5, 5],\n                       [7, 8, 9]])\n    assert_array_almost_equal(X_imputed, X_true)\n"], "sample_675": ["def test_log_capture_fixture_at_level(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        import pytest\n\n        @pytest.fixture\n            # Mock the LogCaptureFixture class\n            class MockLogCaptureFixture:\n                    self._item = item\n                    self._initial_log_levels = {}\n\n                    pass\n\n                @property\n                    return None\n\n                    logger = logging.getLogger(logger)\n                    self._initial_log_levels.setdefault(logger, logger.level)\n                    logger.setLevel(level)\n\n                @pytest.yield_fixture\n                    logger = logging.getLogger(logger)\n                    orig_level = logger.level\n                    logger.setLevel(level)\n                    yield\n                    logger.setLevel(orig_level)\n\n            return MockLogCaptureFixture(request.node)\n\n            logger = logging.getLogger('test_logger')\n            orig_level = logger.level\n\n            with caplog.at_level(logging.DEBUG, 'test_logger'):\n                assert logger.level == logging.DEBUG\n\n            assert logger.level == orig_level\n        \"\"\"\n    )\n\n    result = testdir.runpytest()\n    result.assert_outcomes(passed=1)\n"], "sample_701": ["def test_check_ispytest_warning():\n    with pytest.warns(PytestDeprecationWarning, match=\"A private pytest class or function was used.\"):\n        deprecated.check_ispytest(False)\n"], "sample_1061": ["def test_pow_integer_nthroot():\n    assert integer_nthroot(16, 2) == (4, True)\n    assert integer_nthroot(26, 2) == (5, False)\n    assert integer_nthroot(0, 2) == (0, True)\n    assert integer_nthroot(1, 2) == (1, True)\n    assert integer_nthroot(27, 3) == (3, True)\n    assert integer_nthroot(27, 4) == (2, False)\n    assert integer_nthroot(125, 3) == (5, True)\n    assert integer_nthroot(125, 4) == (3, False)\n"], "sample_1133": ["def test_transverse_magnification():\n    assert transverse_magnification(30, 15) == -2\n    assert transverse_magnification(20, 10) == -2\n    assert transverse_magnification(0, 1) == -0\n"], "sample_252": ["    def test_call(self):\n        key_name = 'test_key'\n        factory = KeyTransformFactory(key_name)\n        transform = factory()\n        self.assertIsInstance(transform, KeyTransform)\n        self.assertEqual(transform.key_name, key_name)\n"], "sample_357": ["def test_generate_altered_managers(self):\n    changes = self.get_changes([self.author_with_biography_non_blank], [self.author_with_biography_blank])\n    self.assertOperationTypes(changes, 'testapp', 0, ['AlterModelManagers'])\n"], "sample_266": ["    def test_check_consistent_history(self):\n        \"\"\"\n        Test the check_consistent_history method.\n        \"\"\"\n        # Create a migration graph with an inconsistent history\n        loader = MigrationLoader(connection)\n        loader.graph.add_node(('test', '0001_initial'), None)\n        loader.graph.add_node(('test', '0002_add_field'), None)\n        loader.graph.add_dependency(('test', '0002_add_field'), ('test', '0001_initial'))\n        recorder = MigrationRecorder(connection)\n        recorder.record_applied(('test', '0002_add_field'))\n        # Check that an InconsistentMigrationHistory error is raised\n        with self.assertRaises(InconsistentMigrationHistory):\n            loader.check_consistent_history(connection)\n"], "sample_687": ["def test_logging_levels(caplog):\n    caplog.set_level(logging.INFO)\n    logger.info(\"This is an info message\")\n    sublogger.debug(\"This is a debug message\")\n    assert len(caplog.records) == 1\n    assert caplog.records[0].levelname == \"INFO\"\n    assert caplog.records[0].message == \"This is an info message\"\n"], "sample_274": ["    def test_model_form_save(self):\n        data = {'name': 'Test Choice'}\n        form = ModelForm(data, model=ChoiceModel)\n        self.assertTrue(form.is_valid())\n        instance = form.save()\n        self.assertEqual(instance.name, 'Test Choice')\n"], "sample_616": ["def test_broadcast_compat_data():\n    var = xr.Variable((\"x\", \"y\"), np.arange(6).reshape(2, 3))\n    broadcast_dims = (\"z\",)\n    core_dims = (\"x\", \"y\")\n    expected_data = np.arange(6).reshape(1, 2, 3)\n    assert_array_equal(broadcast_compat_data(var, broadcast_dims, core_dims), expected_data)\n"], "sample_758": ["def test_check_non_negative():\n    X = np.array([[1, 2], [3, -4]])\n    with pytest.raises(ValueError, match=\"Negative values in data passed to whom\"):\n        check_non_negative(X, \"test\")\n\n    X = sp.csr_matrix([[1, 2], [3, -4]])\n    with pytest.raises(ValueError, match=\"Negative values in data passed to whom\"):\n        check_non_negative(X, \"test\")\n\n    X = np.array([[1, 2], [3, 4]])\n    check_non_negative(X, \"test\")  # should not raise an error\n\n    X = sp.csr_matrix([[1, 2], [3, 4]])\n    check_non_negative(X, \"test\")  # should not raise an error\n"], "sample_122": ["    def test_learn_cache_key(self):\n        request = HttpRequest()\n        request.META = {'HTTP_ACCEPT_LANGUAGE': 'en-US'}\n        response = HttpResponse()\n        response['Vary'] = 'Accept-Language'\n        cache_key = learn_cache_key(request, response)\n        self.assertIsNotNone(cache_key)\n        self.assertIn('en-US', cache_key)\n"], "sample_1012": ["def test_print_SparseMatrix():\n    expr = SparseMatrix(3, 3, {(0, 0): 1, (1, 1): 2, (2, 2): 3})\n    printer = SciPyPrinter()\n    result = printer._print_SparseMatrix(expr)\n    expected = \"scipy.sparse.coo_matrix([1, 2, 3], ([0, 1, 2], [0, 1, 2]), shape=(3, 3))\"\n    assert result == expected\n"], "sample_696": ["def test_check_ispytest_warning():\n    with pytest.warns(PytestDeprecationWarning, match=\"A private pytest class or function was used.\"):\n        deprecated.check_ispytest(False)\n"], "sample_689": ["def test_deprecated_warnings(pytester: Pytester):\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        from _pytest import deprecated\n\n            with pytest.warns(deprecated.FILLFUNCARGS) as record:\n                # Simulate the deprecated usage\n                pytest.Function._request._fillfixtures()\n            assert len(record) == 1\n            assert \"FILLFUNCARGS\" in str(record[0].message)\n\n            with pytest.warns(deprecated.PYTEST_COLLECT_MODULE) as record:\n                # Simulate the deprecated usage\n                pytest.collect.Module(\"test_module\")\n            assert len(record) == 1\n            assert \"PYTEST_COLLECT_MODULE\" in str(record[0].message)\n\n            with pytest.warns(deprecated.MINUS_K_DASH) as record:\n                # Simulate the deprecated usage\n                pytest.main([\"-k\", \"-expr\"])\n            assert len(record) == 1\n            assert \"MINUS_K_DASH\" in str(record[0].message)\n\n            with pytest.warns(deprecated.MINUS_K_COLON) as record:\n                # Simulate the deprecated usage\n                pytest.main([\"-k\", \"expr:\"])\n            assert len(record) == 1\n            assert \"MINUS_K_COLON\" in str(record[0].message)\n\n            with pytest.warns(deprecated.WARNING_CAPTURED_HOOK) as record:\n                # Simulate the deprecated usage\n                    pass\n            assert len(record) == 1\n            assert \"WARNING_CAPTURED_HOOK\" in str(record[0].message)"], "sample_311": ["    def test_admin_site_index(self):\n        response = self.client.get(reverse('admin:index'))\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, 'Site administration')\n        self.assertContains(response, 'Articles')\n        self.assertContains(response, 'Sections')\n"], "sample_730": ["def test_elastic_net_cv_with_multi_task_output():\n    X, y = load_boston(return_X_y=True)\n    y = np.column_stack((y, y))  # Create multi-task output\n    enet_cv = ElasticNetCV(cv=5, l1_ratio=[.1, .5, .7, .9, .95, .99, 1])\n    with assert_raises_regex(ValueError, \"For multi-task outputs, use MultiTaskElasticNetCV\"):\n        enet_cv.fit(X, y)\n"], "sample_568": ["def test_text_3d_get_position_3d(fig):\n    ax = fig.add_subplot(111, projection='3d')\n    text = art3d.Text3D(x=1, y=2, z=3, text='Test')\n    ax.add_artist(text)\n    assert text.get_position_3d() == (1, 2, 3)\n"], "sample_398": ["    def test_login_view_redirects_authenticated_user(self):\n        self.login()\n        response = self.client.get(reverse(\"login\"))\n        self.assertRedirects(response, settings.LOGIN_REDIRECT_URL)\n"], "sample_439": ["def test_form_with_file_field(self):\n    class FileForm(Form):\n        file = FileField()\n\n    data = {\"file\": SimpleUploadedFile(\"test.txt\", b\"file_content\")}\n    form = FileForm(data=data, files=data)\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data[\"file\"].read(), b\"file_content\")\n"], "sample_690": ["def test_evaluate_skip_marks(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.skip(reason=\"skip this test\")\n            assert False\n\n        @pytest.mark.skipif(sys.version_info < (3, 7), reason=\"requires python3.7 or higher\")\n            assert False\n\n            assert True\n        \"\"\"\n    )\n\n    result = pytester.runpytest()\n\n    result.assert_outcomes(skipped=2, passed=1)\n    result.stdout.fnmatch_lines([\"*::test_skip_mark SKIPPED*skip this test\"])\n    result.stdout.fnmatch_lines([\"*::test_skipif_mark SKIPPED*requires python3.7 or higher\"])\n    result.stdout.no_fnmatch_line(\"*::test_no_mark*\")\n"], "sample_96": ["    def test_filter_vertical_not_sequence(self):\n        class MyModelAdmin(ModelAdmin):\n            filter_vertical = 'not_a_sequence'\n\n        self.assertIsInvalid(MyModelAdmin, ValidationTestModel, \"The value of 'filter_vertical' must be a list or tuple.\", id='admin.E017')\n"], "sample_304": ["compilation error"], "sample_1052": ["def test_make_routine_matrix_output():\n    x, y = symbols('x y')\n    r = make_routine('fcn', [x*y, Eq(f, 1), Eq(g, x + g), Matrix([[x, 2]])])\n    assert [arg.result_var for arg in r.results] == [result_5397460570204848505]\n    assert [arg.expr for arg in r.results] == [x*y]\n    assert [arg.name for arg in r.arguments if isinstance(arg, InputArgument)] == [x, y]\n    assert [arg.name for arg in r.arguments if isinstance(arg, OutputArgument)] == [f, out_8598435338387848786]\n    assert [arg.expr for arg in r.arguments if isinstance(arg, OutputArgument)] == [1, Matrix([[x, 2]])]\n    assert [arg.name for arg in r.arguments if isinstance(arg, InOutArgument)] == [g]\n    assert [arg.expr for arg in r.arguments if isinstance(arg, InOutArgument)] == [g + x]\n"], "sample_197": ["    def test_timesince_future_date(self):\n        future_date = self.t + self.oneyear\n        result = timesince(future_date, now=self.t)\n        self.assertEqual(result, '0 minutes')\n"], "sample_365": ["def test_lazy_object(self):\n        return \"Test String\"\n\n    lazy_obj = SimpleLazyObject(setup_func)\n    self.assertEqual(lazy_obj._wrapped, empty)\n    self.assertEqual(str(lazy_obj), \"Test String\")\n    self.assertIsInstance(lazy_obj._wrapped, str)\n\n    # Test copying\n    lazy_obj_copy = copy.copy(lazy_obj)\n    self.assertEqual(lazy_obj_copy._wrapped, \"Test String\")\n\n    # Test deepcopy\n    lazy_obj_deepcopy = copy.deepcopy(lazy_obj)\n    self.assertEqual(lazy_obj_deepcopy._wrapped, \"Test String\")\n    self.assertIsNot(lazy_obj_deepcopy._wrapped, lazy_obj._wrapped)\n"], "sample_183": ["def test_case_expression_with_duration_field(self):\n    duration = timedelta(days=1)\n    CaseTestModel.objects.create(duration=duration)\n    result = CaseTestModel.objects.annotate(\n        duration_case=Case(\n            When(duration=duration, then=Value(1)),\n            default=Value(0),\n            output_field=IntegerField(),\n        )\n    ).values('duration_case')\n    self.assertEqual(result[0]['duration_case'], 1)\n"], "sample_857": ["def test_tree_classifier_with_sample_weight():\n    X, y = DATASETS[\"iris\"][\"X\"], DATASETS[\"iris\"][\"y\"]\n    sample_weight = np.ones(y.shape[0])\n    sample_weight[y == 0] = 2\n\n    clf = DecisionTreeClassifier(random_state=0)\n    clf.fit(X, y, sample_weight=sample_weight)\n\n    y_pred = clf.predict(X)\n    assert accuracy_score(y, y_pred, sample_weight=sample_weight) > 0.9\n"], "sample_1201": ["def test_unit_conversion():\n    # Test conversion from statcoulomb to coulomb\n    assert convert_to(1*statcoulomb, coulomb, cgs_gauss) == 10*speed_of_light*statcoulomb\n\n    # Test conversion from coulomb to statcoulomb\n    assert convert_to(1*coulomb, statcoulomb, cgs_gauss) == 1/(10*speed_of_light)*statcoulomb\n\n    # Test conversion from statvolt to volt\n    assert convert_to(1*statvolt, volt, cgs_gauss) == 10**6/speed_of_light*statvolt\n\n    # Test conversion from volt to statvolt\n    assert convert_to(1*volt, statvolt, cgs_gauss) == speed_of_light/(10**6)*volt\n\n    # Test conversion from ohm to henry\n    assert convert_to(1*ohm, henry, cgs_gauss) == 10**5/speed_of_light**2/centimeter*second**2\n\n    # Test conversion from henry to ohm\n    assert convert_to(1*henry, ohm, cgs_gauss) == speed_of_light**2*centimeter/(10**5*second**2)\n"], "sample_614": ["def test_format_timedelta_date(self):\n    timedelta_str = formatting.format_timedelta(np.timedelta64(3, 'D'), timedelta_format='date')\n    assert timedelta_str == '3 days'\n"], "sample_630": ["def test_dot_writer_get_values(generated_file):\n    \"\"\"Test the get_values method of DotWriter class.\"\"\"\n    config = Config()\n    writer = DotWriter(config)\n    project = get_project(os.path.join(os.path.dirname(__file__), \"data\"))\n    linker = Linker(project)\n    obj = linker.classes[\"data.module1.Class1\"]\n    values = writer.get_values(obj)\n    assert \"label\" in values\n    assert \"shape\" in values\n    assert values[\"shape\"] == \"record\"\n    assert \"Class1\" in values[\"label\"]\n    assert \"attr1\" in values[\"label\"]\n    assert \"method1\" in values[\"label\"]\n"], "sample_1113": ["def test_block_matrix_entry():\n    B = BlockMatrix([[X1, X2], [X3, X4]])\n    assert B[0, 0] == X1[0, 0]\n    assert B[0, 1] == X1[0, 1]\n    assert B[1, 0] == X3[0, 0]\n    assert B[1, 1] == X3[0, 1]\n    assert B[2, 0] == X4[1, 0]\n    assert B[2, 1] == X4[1, 1]\n"], "sample_175": ["def test_restricted_error_raised_for_restricted_objects(self):\n    # Create a restricted object\n    restricted_obj = R.objects.create()\n    # Create an object that references the restricted object\n    obj = MR.objects.create(r=restricted_obj)\n    # Create a collector and collect the object\n    collector = Collector(using='default')\n    collector.collect([obj])\n    # Check that a RestrictedError is raised when deleting the object\n    with self.assertRaises(RestrictedError):\n        collector.delete()\n"], "sample_864": ["def test_mean_shift_predict():\n    # Test the predict method of MeanShift\n    bandwidth = estimate_bandwidth(X, quantile=0.2, n_samples=500)\n    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n    ms.fit(X)\n\n    # Generate new data\n    X_new, _ = make_blobs(n_samples=100, n_features=2, centers=centers,\n                          cluster_std=0.4, shuffle=True, random_state=42)\n\n    labels = ms.predict(X_new)\n\n    # Check that the output has the correct shape\n    assert labels.shape == (100,)\n\n    # Check that the output labels are within the range of cluster labels\n    assert np.all(labels >= 0) and np.all(labels < n_clusters)\n"], "sample_82": ["def test_select_date_widget_with_empty_label(self):\n    widget = SelectDateWidget(\n        years=('2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016'),\n        empty_label=('Year', 'Month', 'Day'),\n    )\n    rendered = widget.render('date', None)\n    self.assertInHTML('<option value=\"\">Year</option>', rendered)\n    self.assertInHTML('<option value=\"\">Month</option>', rendered)\n    self.assertInHTML('<option value=\"\">Day</option>', rendered)\n"], "sample_270": ["    def test_unique_together_valid(self):\n        class ValidUniqueTogether(models.Model):\n            field1 = models.CharField(max_length=10)\n            field2 = models.IntegerField()\n\n            class Meta:\n                unique_together = (('field1', 'field2'),)\n\n        errors = ValidUniqueTogether.check()\n        self.assertEqual(errors, [])\n"], "sample_77": ["def test_urlize(self):\n    self.check_output(urlize, 'http://example.com', '<a href=\"http://example.com\">http://example.com</a>')\n    self.check_output(urlize, 'www.example.com', '<a href=\"http://www.example.com\">www.example.com</a>')\n    self.check_output(urlize, 'example@example.com', '<a href=\"mailto:example@example.com\">example@example.com</a>')\n    self.check_output(urlize, 'Visit http://example.com', 'Visit <a href=\"http://example.com\">http://example.com</a>')\n    self.check_output(urlize, 'Visit www.example.com', 'Visit <a href=\"http://www.example.com\">www.example.com</a>')\n    self.check_output(urlize, 'Email example@example.com', 'Email <a href=\"mailto:example@example.com\">example@example.com</a>')\n"], "sample_352": ["    def test_split_having_with_aggregate(self):\n        query = Item.objects.annotate(num_tags=Count('tags')).filter(num_tags__gt=1)\n        where_node, having_node = query.where.split_having()\n        self.assertIsNone(where_node)\n        self.assertIsNotNone(having_node)\n        self.assertTrue(having_node.contains_aggregate)\n"], "sample_840": ["def test_pls_regression_n_components_greater_than_p():\n    X = np.random.rand(10, 5)\n    Y = np.random.rand(10, 2)\n    pls = pls_.PLSRegression(n_components=6)\n    with pytest.raises(ValueError, match=\"Invalid number of components: 6\"):\n        pls.fit(X, Y)\n"], "sample_968": ["def test_parse_annotation():\n    env = Mock()\n    env.config.python_use_unqualified_type_names = False\n\n    # Test parsing a simple type annotation\n    annotation = \"int\"\n    result = _parse_annotation(annotation, env)\n    assert_node(result, [pending_xref, nodes.Text], text=\"int\")\n\n    # Test parsing a complex type annotation\n    annotation = \"List[Union[str, int]]\"\n    result = _parse_annotation(annotation, env)\n    assert_node(result, [pending_xref, desc_sig_punctuation, desc_sig_punctuation,\n                         desc_sig_punctuation, pending_xref, desc_sig_punctuation,\n                         desc_sig_punctuation, desc_sig_punctuation])\n"], "sample_791": ["def test_ordinal_encoder_inverse_transform():\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    X_transformed = enc.transform(X)\n    X_inverse = enc.inverse_transform(X_transformed)\n    assert_array_equal(X_inverse, X)\n"], "sample_597": ["def test_merge_core_fill_value(self):\n    x = xr.DataArray(\n        [[1.0, 2.0], [3.0, 5.0]],\n        dims=(\"lat\", \"lon\"),\n        coords={\"lat\": [35.0, 40.0], \"lon\": [100.0, 120.0]},\n        name=\"var1\",\n    )\n    y = xr.DataArray(\n        [[5.0, 6.0], [7.0, 8.0]],\n        dims=(\"lat\", \"lon\"),\n        coords={\"lat\": [35.0, 42.0], \"lon\": [100.0, 150.0]},\n        name=\"var2\",\n    )\n    z = xr.DataArray(\n        [[0.0, 3.0], [4.0, 9.0]],\n        dims=(\"time\", \"lon\"),\n        coords={\"time\": [30.0, 60.0], \"lon\": [100.0, 150.0]},\n        name=\"var3\",\n    )\n\n    merged = merge.merge_core([x, y, z], fill_value=-999.0)\n    expected_var1 = xr.DataArray(\n        [[1.0, 2.0, -999.0], [3.0, 5.0, -999.0], [-999.0, -999.0, -999.0]],\n        dims=(\"lat\", \"lon\"),\n        coords={\"lat\": [35.0, 40.0, 42.0], \"lon\": [100.0, 120.0, 150.0]},\n        name=\"var1\",\n    )\n    expected_var2 = xr.DataArray(\n        [[5.0, -999.0, 6.0], [-999.0, -999.0, -999.0], ["], "sample_1010": ["def test_latex_Quaternion():\n    q = Quaternion(1, 2, 3, 4)\n    assert latex(q) == \"1 + 2\\\\mathbf{i} + 3\\\\mathbf{j} + 4\\\\mathbf{k}\"\n"], "sample_812": ["def test_estimator_pretty_printer_changed_only():\n    # Test that _EstimatorPrettyPrinter correctly prints only changed parameters\n    lr = LogisticRegression(C=10, max_iter=200)\n    printer = _EstimatorPrettyPrinter(compact=True)\n    output = printer.pformat(lr)\n    assert output == \"LogisticRegression(C=10, max_iter=200)\"\n"], "sample_770": ["def test_silhouette_score_with_sample_size():\n    X, y = datasets.make_blobs(n_samples=100, n_features=2, centers=2, random_state=42)\n    sample_size = 50\n    score_full = silhouette_score(X, y)\n    score_sample = silhouette_score(X, y, sample_size=sample_size, random_state=42)\n    assert_greater(score_sample, 0)\n    assert_greater(score_full, score_sample)\n"], "sample_413": ["    def test_check_setting_app_dirs_loaders(self):\n        errors = check_setting_app_dirs_loaders(None)\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0], E001)\n"], "sample_1203": ["def test_group_isomorphism_free_groups():\n    F, a, b = free_group(\"a, b\")\n    G = FpGroup(F, [a**3, b**3, (a*b)**2])\n    H = AlternatingGroup(4)\n    check, T = group_isomorphism(G, H)\n    assert check\n    assert T(b*a*b**-1*a**-1*b**-1) == Permutation(0, 2, 3)\n"], "sample_407": ["def test_article_str_method(self):\n    expected_str = \"This is a test\"\n    self.assertEqual(str(self.a), expected_str)\n"], "sample_117": ["    def test_clean_password(self):\n        form = UserChangeForm(instance=self.u1)\n        self.assertEqual(form.clean_password(), self.u1.password)\n"], "sample_546": ["def test_figure_savefig_transparent():\n    fig = Figure()\n    ax = fig.add_subplot(111)\n    ax.plot([1, 2, 3], [1, 2, 3])\n    fig.savefig('test.png', transparent=True)\n    # Add assertions to verify the saved figure is transparent\n"], "sample_296": ["    def test_encode_decode_messages(self):\n        storage = CookieStorage(None)\n        messages = [Message(constants.INFO, 'Test message 1'), Message(constants.ERROR, 'Test message 2')]\n        encoded_data = storage._encode(messages)\n        decoded_data = storage._decode(encoded_data)\n        self.assertEqual(messages, decoded_data)\n"], "sample_512": ["def test_xlim():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], [4, 5, 6])\n    plt.xlim(2, 3)\n    assert ax.get_xlim() == (2, 3)\n"], "sample_1": ["def test_arithmetic_operators():\n    # Test arithmetic operators with models having the same n_inputs and n_outputs\n    model1 = sh1 & sh2\n    model2 = scl1 & scl2\n    model_add = model1 + model2\n    model_sub = model1 - model2\n    model_mul = model1 * model2\n    model_div = model1 / model2\n    model_pow = model1 ** model2\n\n    assert_allclose(_arith_oper(model1, model2), np.ones((2, 2)))\n    assert_allclose(_arith_oper(model_add, model_sub), np.ones((2, 2)))\n    assert_allclose(_arith_oper(model_mul, model_div), np.ones((2, 2)))\n    assert_allclose(_arith_oper(model_pow, model_pow), np.ones((2, 2)))\n\n    # Test arithmetic operators with models having different n_inputs or n_outputs\n    model3 = sh1 & sh2 & sh1\n    with pytest.raises(ModelDefinitionError):\n        _arith_oper(model1, model3)\n\n    model4 = sh1 & sh2 & scl1\n    with pytest.raises(ModelDefinitionError):\n        _arith_oper(model1, model4)\n"], "sample_513": ["def test_legend_set_draggable():\n    fig, ax = plt.subplots()\n    line, = ax.plot([1, 2, 3], [1, 2, 3], label='Test line')\n    legend = ax.legend()\n\n    # Test enabling draggable\n    draggable = legend.set_draggable(True)\n    assert isinstance(draggable, mlegend.DraggableLegend)\n    assert legend.get_draggable() is True\n\n    # Test disabling draggable\n    legend.set_draggable(False)\n    assert legend.get_draggable() is False\n"], "sample_725": ["def test_check_memory():\n    # Test with None\n    memory = check_memory(None)\n    assert isinstance(memory, sklearn.externals.joblib.Memory)\n\n    # Test with a string\n    memory = check_memory('cache_dir')\n    assert isinstance(memory, sklearn.externals.joblib.Memory)\n    assert memory.location == 'cache_dir'\n\n    # Test with a joblib.Memory object\n    memory_obj = sklearn.externals.joblib.Memory(location='cache_dir')\n    memory = check_memory(memory_obj)\n    assert memory is memory_obj\n\n    # Test with an invalid object\n    with pytest.raises(ValueError):\n        check_memory('invalid_object')\n"], "sample_181": ["def test_filtered_aggregate_with_annotation(self):\n    annotated_books = Book.objects.annotate(double_pages=F('pages') * 2)\n    filtered_aggregate = annotated_books.filter(pages__gt=400).aggregate(Avg('double_pages'))\n    self.assertEqual(filtered_aggregate['double_pages__avg'], 1200)\n"], "sample_936": ["def test_stringify_forward_ref():\n    class MyClass3(MyClass1):\n        __forward_arg__ = 'MyClass1'\n\n    assert stringify(MyClass3) == 'MyClass1'\n"], "sample_617": ["def test_broadcast_compat_data():\n    var = xr.Variable((\"x\", \"y\"), np.arange(6).reshape(2, 3))\n    broadcast_dims = (\"z\",)\n    core_dims = (\"x\", \"y\")\n    expected_data = np.arange(6).reshape(1, 2, 3)\n    assert_array_equal(broadcast_compat_data(var, broadcast_dims, core_dims), expected_data)\n"], "sample_425": ["    def test_serializer_factory_with_model_field(self):\n        field = models.CharField(max_length=255)\n        serializer = serializer_factory(field)\n        self.assertIsInstance(serializer, ModelFieldSerializer)\n        serialized, imports = serializer.serialize()\n        self.assertEqual(serialized, \"models.CharField(max_length=255)\")\n        self.assertEqual(imports, {\"from django.db import models\"})\n"], "sample_655": ["def test_suspend_resume_global_capture(capsys):\n    capman = CaptureManager(\"fd\")\n    capman.start_global_capturing()\n    print(\"This should be captured\")\n    capman.suspend_global_capture()\n    print(\"This should not be captured\")\n    capman.resume_global_capture()\n    print(\"This should be captured\")\n    out, err = capman.read_global_capture()\n    assert \"This should be captured\" in out\n    assert \"This should not be captured\" not in out\n    capman.stop_global_capturing()\n"], "sample_400": ["def test_generate_altered_managers_with_custom_queryset_and_manager(self):\n    questioner = MigrationQuestioner(specified_apps=[\"otherapp\"])\n    changes = self.get_changes(\n        [self.other_pony],\n        [self.other_pony_food],\n        questioner,\n    )\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterModelManagers\"])\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        0,\n        name=\"Pony\",\n        managers=[\n            (\"food_qs\", FoodQuerySet.as_manager()),\n            (\"food_mgr\", FoodManager(\"a\", \"b\")),\n            (\"food_mgr_kwargs\", FoodManager(\"x\", \"y\", 3, 4)),\n        ],\n    )\n"], "sample_816": ["def test_hashing_vectorizer_alternate_sign():\n    vectorizer = HashingVectorizer(alternate_sign=True)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n    assert np.all(np.abs(X.data) == 1)\n    assert np.all(np.diff(np.sort(X.data)) == 2)\n"], "sample_111": ["def test_get_queryset_with_invalid_lookup_parameters(self):\n    request = self._mocked_authenticated_request('/admin/admin_changelist/band/?invalid_field=invalid_value', self.superuser)\n    with self.assertRaises(IncorrectLookupParameters):\n        BandAdmin(Band, custom_site).get_changelist(request).get_queryset(request)\n"], "sample_952": ["def test_signature_from_str():\n    sig = inspect.signature_from_str(\"(a: int, b: str = 'default')\")\n    assert str(sig) == \"(a: int, b: str = 'default')\"\n"], "sample_788": ["def test_inverse_transform(strategy, expected):\n    est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy=strategy)\n    est.fit(X)\n    Xt = est.transform(X)\n    Xinv = est.inverse_transform(Xt)\n    assert_array_almost_equal(Xinv, X)\n"], "sample_1081": ["def test_is_amicable():\n    assert is_amicable(220, 284)\n    assert not is_amicable(220, 220)\n    assert not is_amicable(220, 285)\n"], "sample_773": ["def test_logistic_regression_cv_binary():\n    X, y = make_classification(n_samples=100, n_features=20, n_classes=2, random_state=42)\n    clf = LogisticRegressionCV(cv=5, random_state=0)\n    check_predictions(clf, X, y)\n    assert_greater(clf.score(X, y), 0.9)\n"], "sample_823": ["def test_pairwise_distances_chunked_reduce_func_output_size():\n    X = np.random.RandomState(0).rand(5, 3)\n    r = .2\n\n        neigh = [np.flatnonzero(d < r) for d in D_chunk]\n        avg_dist = (D_chunk * (D_chunk < r)).mean(axis=1)\n        return neigh, avg_dist, np.ones(D_chunk.shape[0])\n\n    gen = pairwise_distances_chunked(X, reduce_func=reduce_func)\n    neigh, avg_dist, extra = next(gen)\n    assert_equal(len(neigh), len(avg_dist))\n    assert_equal(len(neigh), len(extra))\n"], "sample_202": ["    def test_encode_decode_safedata(self):\n        storage = CookieStorage(None)\n        message = Message(constants.INFO, mark_safe(\"This is a safe message\"))\n        encoded_data = storage._encode([message])\n        decoded_data = storage._decode(encoded_data)\n        self.assertEqual(len(decoded_data), 1)\n        self.assertIsInstance(decoded_data[0].message, SafeData)\n        self.assertEqual(decoded_data[0].message, \"This is a safe message\")\n"], "sample_815": ["def test_brier_score_loss():\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    expected_score = 0.037\n    assert_almost_equal(brier_score_loss(y_true, y_prob), expected_score)\n"], "sample_65": ["    def test_get_catalog(self):\n        \"\"\"Test the get_catalog method.\"\"\"\n        view = JavaScriptCatalog()\n        view.translation = gettext.translation('djangojs', localedir=locale_dir, languages=[settings.LANGUAGE_CODE])\n        catalog = view.get_catalog()\n        self.assertIsInstance(catalog, dict)\n        self.assertIn('', catalog)\n"], "sample_806": ["def test_classification_toy_presort_loss(presort, loss):\n    check_classification_toy(presort, loss)\n"], "sample_547": ["def test_offsetbox_get_bbox():\n    ob = OffsetBox()\n    ob.set_width(100)\n    ob.set_height(200)\n    renderer = ob.figure._get_renderer()\n    bbox = ob.get_bbox(renderer)\n    assert bbox.width == 100\n    assert bbox.height == 200\n"], "sample_275": ["    def test_delete(self):\n        # Create some objects to delete\n        Book.objects.create(title='Book 1')\n        Book.objects.create(title='Book 2')\n        Book.objects.create(title='Book 3')\n\n        # Delete one object\n        deleted, _ = Book.objects.filter(title='Book 2').delete()\n        self.assertEqual(deleted, 1)\n\n        # Check that the object was deleted\n        self.assertEqual(Book.objects.count(), 2)\n        self.assertFalse(Book.objects.filter(title='Book 2').exists())\n\n        # Delete multiple objects\n        deleted, _ = Book.objects.filter(title__in=['Book 1', 'Book 3']).delete()\n        self.assertEqual(deleted, 2)\n\n        # Check that the objects were deleted\n        self.assertEqual(Book.objects.count(), 0)\n        self.assertFalse(Book.objects.filter(title__in=['Book 1', 'Book 3']).exists())\n"], "sample_1049": ["def test_plane_intersection_with_line():\n    p = Plane(Point3D(1, 1, 1), normal_vector=(1, 1, 1))\n    l = Line3D(Point3D(2, 2, 2), Point3D(3, 3, 3))\n    intersection = p.intersection(l)\n    assert len(intersection) == 1\n    assert intersection[0] == Point3D(2, 2, 2)\n"], "sample_165": ["    def test_modelform_with_file_field(self):\n        class FileUploadForm(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = ['file_field']\n\n        upload_file = SimpleUploadedFile(\"test_file.txt\", b\"file_content\")\n        form = FileUploadForm(files={'file_field': upload_file})\n        self.assertTrue(form.is_valid())\n        instance = form.save()\n        self.assertEqual(instance.file_field.read(), b\"file_content\")\n"], "sample_759": ["def test_ordinal_encoder_inverse_transform():\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    X_transformed = enc.transform(X)\n    X_inverse = enc.inverse_transform(X_transformed)\n    assert_array_equal(X, X_inverse)\n"], "sample_859": ["def test_elastic_net_cv_with_multi_output():\n    X, y = load_boston(return_X_y=True)\n    y = np.column_stack((y, y))  # create multi-output target\n    enet_cv = ElasticNetCV(cv=5, random_state=0)\n    with pytest.raises(ValueError, match=\"For multi-task outputs, use MultiTaskElasticNetCV\"):\n        enet_cv.fit(X, y)\n"], "sample_522": ["def test_colorbar_extension_length():\n    fig_uniform = _colorbar_extension_length('uniform')\n    fig_proportional = _colorbar_extension_length('proportional')\n    return fig_uniform, fig_proportional\n"], "sample_814": ["def test_classification_toy_presort_loss(presort, loss):\n    check_classification_toy(presort, loss)\n"], "sample_903": ["def test_tsne_with_precomputed_metric():\n    # Test TSNE with precomputed metric\n    dist_matrix = pairwise_distances(X_2d_grid, metric='euclidean')\n    tsne = TSNE(metric='precomputed')\n    X_transformed = tsne.fit_transform(dist_matrix)\n    assert_equal(X_transformed.shape, (100, 2))\n"], "sample_1084": ["def test_intersection_sets_complex_region_with_interval():\n    a = ComplexRegion(Interval(0, 1), Interval(0, pi))\n    b = Interval(0, 2)\n    result = intersection_sets(a, b)\n    expected = ComplexRegion(Interval(0, 1), Interval(0, pi))\n    assert result == expected\n"], "sample_1132": ["def test_is_palindromic():\n    assert is_palindromic([1, 0, 1])\n    assert not is_palindromic('abcbb')\n    assert not is_palindromic('abcbb', 1)\n    assert is_palindromic('abcbb', 1, -1)\n    assert is_palindromic('abcbb', -4, -1)\n"], "sample_554": ["def test_annotation_contains():\n    fig, ax = plt.subplots()\n    ann = Annotation(\"Test\", xy=(0.5, 0.5), xytext=(0.6, 0.6), xycoords='data')\n    ax.add_artist(ann)\n\n    # Test contains when mouseevent is outside the annotation\n    mouseevent = MouseEvent('button_press_event', fig.canvas, 0, 0, button=1)\n    contains, _ = ann.contains(mouseevent)\n    assert not contains\n\n    # Test contains when mouseevent is inside the annotation\n    mouseevent = MouseEvent('button_press_event', fig.canvas, 0.55, 0.55, button=1)\n    contains, _ = ann.contains(mouseevent)\n    assert contains\n\n    # Test contains when mouseevent is inside the arrow patch\n    mouseevent = MouseEvent('button_press_event', fig.canvas, 0.55, 0.55, button=1)\n    ann.arrow_patch = mpatches.FancyArrowPatch((0.5, 0.5), (0.6, 0.6))\n    contains, _ = ann.contains(mouseevent)\n    assert contains\n\n    plt.close(fig)\n"], "sample_188": ["def test_expression_wrapper(self):\n    expr = ExpressionWrapper(F('num_employees'), output_field=IntegerField())\n    self.assertEqual(str(expr), 'num_employees')\n    self.assertEqual(expr.resolve_expression(self.company_query).as_sql(self.company_query.query.compiler, connection)[0], '`company`.`num_employees`')\n"], "sample_478": ["    def test_filter_vertical_invalid_type(self):\n        class MyModelAdmin(admin.ModelAdmin):\n            filter_vertical = \"invalid_type\"\n\n        self.assertIsInvalid(\n            MyModelAdmin,\n            ValidationTestModel,\n            \"The value of 'filter_vertical' must be a list or tuple.\",\n            id=\"admin.E017\",\n        )\n"], "sample_1102": ["def test_to_rational_coeffs():\n    p = Poly(((x**2-1)*(x-2)).subs({x:x*(1 + sqrt(2))}), x, domain='EX')\n    lc, r, _, g = to_rational_coeffs(p)\n    assert lc == 7 + 5*sqrt(2)\n    assert r == 2 - 2*sqrt(2)\n    assert g == Poly(x**3 + x**2 - 1/4*x - 1/4, x, domain='QQ')\n"], "sample_462": ["def test_choice_field_valid_value(self):\n    choices = [(\"1\", \"One\"), (\"2\", \"Two\"), (\"3\", \"Three\")]\n    field = ChoiceField(choices=choices)\n    self.assertTrue(field.valid_value(\"1\"))\n    self.assertTrue(field.valid_value(\"2\"))\n    self.assertTrue(field.valid_value(\"3\"))\n    self.assertTrue(field.valid_value(1))\n    self.assertFalse(field.valid_value(\"4\"))\n    self.assertFalse(field.valid_value(4))\n"], "sample_633": ["def test_similar_ignore_signatures():\n    sim = similar.Similar(min_lines=4, ignore_signatures=True)\n    with open(SIMILAR1, encoding=\"utf-8\") as stream:\n        sim.append_stream(SIMILAR1, stream)\n    with open(SIMILAR2, encoding=\"utf-8\") as stream:\n        sim.append_stream(SIMILAR2, stream)\n    output = StringIO()\n    with redirect_stdout(output):\n        sim.run()\n    assert \"4 similar lines in 2 files\" in output.getvalue()\n"], "sample_930": ["def test_create_index(app, status, warning):\n    env = app.builder.env\n    index_entries = IndexEntries(env)\n\n    # Add some sample index entries\n    domain = env.get_domain('index')\n    domain.entries['testfile'] = [\n        ('single', 'entry1', 'id1', 'main1', None),\n        ('pair', 'entry2 pair2', 'id2', 'main2', None),\n        ('triple', 'entry3 triple3 triple3', 'id3', 'main3', None),\n        ('see', 'entry4 see4', 'id4', 'main4', None),\n        ('seealso', 'entry5 seealso5', 'id5', 'main5', None),\n        ('unknown', 'entry6', 'id6', 'main6', None),\n    ]\n\n    # Call the create_index method\n    index = index_entries.create_index(app.builder)\n\n    # Assert the expected results\n    assert len(index) > 0\n    assert index[0][0] == 'entry1'\n    assert index[1][0] == 'entry2'\n    assert index[2][0] == 'entry3'\n    assert index[3][0] == 'entry4'\n    assert index[4][0] == 'entry5'\n    assert warning.getvalue() == \"unknown index entry type 'unknown'\\n\"\n"], "sample_317": ["def test_rss201rev2_feed(self):\n    feed = Rss201rev2Feed(\n        title=\"Test Feed\",\n        link=\"http://example.com/\",\n        description=\"This is a test feed.\",\n        language=\"en\",\n        author_email=\"test@example.com\",\n        author_name=\"Test Author\",\n        author_link=\"http://example.com/author\",\n        subtitle=\"Test Subtitle\",\n        categories=[\"Test Category\"],\n        feed_url=\"http://example.com/feed\",\n        feed_copyright=\"Copyright 2022\",\n        feed_guid=\"http://example.com/feed-guid\",\n        ttl=\"60\",\n    )\n    feed.add_item(\n        title=\"Test Item\",\n        link=\"http://example.com/item\",\n        description=\"This is a test item.\",\n        author_email=\"item@example.com\",\n        author_name=\"Item Author\",\n        author_link=\"http://example.com/item-author\",\n        pubdate=datetime.datetime(2022, 1, 1, tzinfo=TZ),\n        comments=\"http://example.com/item-comments\",\n        unique_id=\"http://example.com/item-guid\",\n        unique_id_is_permalink=True,\n        categories=[\"Item Category\"],\n        item_copyright=\"Item Copyright 2022\",\n        ttl=\"30\",\n        updateddate=datetime.datetime(2022, 1, 2, tzinfo=TZ),\n        enclosures=[Enclosure(\"http://example.com/enclosure\", \"1024\", \"audio/mpeg\")],\n    )\n    xml = feed.writeString(\"utf-8\")\n    dom = minidom.parseString(xml)\n    rss = dom.documentElement\n    self.assertEqual(rss.nodeName, \"rss\")\n    self.assertEqual(rss.getAttribute(\"version\"), \"2.0\")\n    channel = rss.getElementsByTagName(\"channel\")[0]\n    self.assertChildNodes(channel, [\"title\", \"link\", \"description\", \"atom"], "sample_216": ["def test_field_is_referenced(self):\n    project_state = ProjectState()\n    project_state.add_model(self.author_with_book)\n    project_state.add_model(self.book)\n\n    # Test when field is referenced\n    self.assertTrue(field_is_referenced(project_state, (\"otherapp\", \"book\"), (\"author\",)))\n\n    # Test when field is not referenced\n    self.assertFalse(field_is_referenced(project_state, (\"otherapp\", \"book\"), (\"title\",)))\n"], "sample_1110": ["def test_print_MatrixSolve():\n    A = MatrixSymbol('A', 3, 3)\n    b = MatrixSymbol('b', 3, 1)\n    expr = MatrixSolve(A, b)\n    result = pycode(expr, printer=NumPyPrinter)\n    assert result == \"numpy.linalg.solve(A, b)\"\n"], "sample_1032": ["def test_minmax_rewrite_as_Heaviside():\n    x, y, z = symbols('x y z')\n    assert Min(x, y).rewrite(Heaviside) == x*(1 - Heaviside(x - y)) + y*Heaviside(x - y)\n    assert Max(x, y).rewrite(Heaviside) == x*Heaviside(x - y) + y*(1 - Heaviside(x - y))\n    assert Min(x, y, z).rewrite(Heaviside) == x*(1 - Heaviside(x - y))*(1 - Heaviside(x - z)) + y*Heaviside(x - y)*(1 - Heaviside(y - z)) + z*Heaviside(x - z)*Heaviside(y - z)\n    assert Max(x, y, z).rewrite(Heaviside) == x*Heaviside(x - y)*Heaviside(x - z) + y*Heaviside(y - x)*Heaviside(y - z) + z*Heaviside(z - x)*Heaviside(z - y)\n"], "sample_363": ["def test_formfield_for_uuid_field(self):\n    \"\"\"\n    Test that formfield_for_dbfield returns the correct widget for a UUIDField.\n    \"\"\"\n    self.assertFormfield(MyFileField, 'uuid_field', widgets.AdminUUIDInputWidget)\n"], "sample_979": ["def test_matrix_element_derivative():\n    A_elem = MatrixElement(A, n, m)\n    B_elem = MatrixElement(B, l, k)\n\n    # Test derivative with respect to a different matrix element\n    assert diff(A_elem, B_elem) == KroneckerDelta(n, l) * KroneckerDelta(m, k)\n\n    # Test derivative with respect to the same matrix element\n    assert diff(A_elem, A_elem) == 1\n\n    # Test derivative with respect to a scalar\n    assert diff(A_elem, x) == 0\n"], "sample_263": ["    def test_dumpdata_with_primary_keys(self):\n        category = Category.objects.create(name=\"Test Category\")\n        article = Article.objects.create(title=\"Test Article\", category=category)\n\n        out = StringIO()\n        management.call_command('dumpdata', 'app_name.Article', primary_keys=article.pk, stdout=out)\n        self.assertIn(str(article.pk), out.getvalue())\n"], "sample_19": ["def test_maps_sip(self):\n    for filename in self._file_list:\n        with fits.open(filename) as hdulist:\n            header = hdulist[0].header\n            w = wcs.WCS(header)\n            assert w.sip is not None\n            assert w.sip.a is not None\n            assert w.sip.b is not None\n            assert w.sip.ap is not None\n            assert w.sip.bp is not None\n            assert w.sip.crpix is not None\n"], "sample_30": ["def test_parse_single_table_with_columns():\n    filename = get_pkg_data_filename(\"data/regression/single_table_with_columns.xml\")\n    table = parse_single_table(filename, columns=[\"col1\", \"col3\"])\n    assert table.colnames == [\"col1\", \"col3\"]\n"], "sample_458": ["def test_floatformat_with_arg(self):\n    self.engine.render_to_string(\n        \"floatformat02\", {\"c\": 34.23234, \"d\": 34.00000, \"e\": 34.26000}\n    )\n"], "sample_925": ["def test_mock_module_attributes():\n    \"\"\"Test the attributes of the _MockModule class.\"\"\"\n    mock_module = _MockModule('test_module')\n    assert mock_module.__file__ == os.devnull\n    assert mock_module.__sphinx_mock__ is True\n    assert mock_module.__all__ == []\n    assert mock_module.__path__ == []\n"], "sample_506": ["def test_spines_set_color():\n    fig, ax = plt.subplots()\n    spines = Spines(left=ax.spines['left'], right=ax.spines['right'],\n                    bottom=ax.spines['bottom'], top=ax.spines['top'])\n    spines.set_color('red')\n    plt.close(fig)\n"], "sample_255": ["def test_handle_one_request(self):\n    request = self.request_factory.get('/')\n    environ = WSGIRequestHandler.make_environ(request)\n    handler = WSGIRequestHandler(Stub(getsockname=('127.0.0.1', 8000)), ('127.0.0.1', 8000), BytesIO(), environ)\n    handler.server = Stub(get_app=lambda: lambda env, start_response: start_response('200 OK', []))\n    handler.handle_one_request()\n    self.assertEqual(handler.wfile.getvalue(), b'')\n"], "sample_480": ["def test_key_transform_factory(self):\n    factory = KeyTransformFactory(\"test_key\")\n    transform = factory(Value(\"test_value\"))\n    self.assertIsInstance(transform, KeyTransform)\n    self.assertEqual(transform.key_name, \"test_key\")\n    self.assertEqual(transform.lhs.value, \"test_value\")\n"], "sample_661": ["def test_add_global_property(self, testdir):\n    logxml = LogXML(\"junit.xml\", \"prefix\", \"suite_name\")\n    logxml.add_global_property(\"key\", \"value\")\n    assert logxml.global_properties == [(\"key\", \"value\")]\n"], "sample_837": ["def test_get_blas_info():\n    blas_info = _get_blas_info()\n    assert isinstance(blas_info, dict)\n    assert 'macros' in blas_info\n    assert 'lib_dirs' in blas_info\n    assert 'cblas_libs' in blas_info\n"], "sample_469": ["    def test_annotation_filtering(self):\n        qs = Author.objects.annotate(\n            young=Case(\n                When(age__lt=30, then=Value('Y')),\n                default=Value('N'),\n                output_field=CharField(),\n            )\n        )\n        self.assertSequenceEqual(\n            qs.filter(young='Y').values_list('name', flat=True),\n            ['James Bennett', 'Paul Bissex', 'Wesley J. Chun']\n        )\n"], "sample_267": ["    def test_sqlite_datetime_parse(self):\n        from django.db.backends.sqlite3.base import _sqlite_datetime_parse\n        dt = '2022-01-01 12:00:00'\n        tzname = 'UTC'\n        conn_tzname = 'UTC'\n        result = _sqlite_datetime_parse(dt, tzname, conn_tzname)\n        self.assertEqual(str(result), '2022-01-01 12:00:00+00:00')\n"], "sample_364": ["    def test_path_with_invalid_kwargs(self):\n        with self.assertRaises(TypeError):\n            path('invalid/', empty_view, kwargs='invalid')\n"], "sample_1091": ["def test_relational_simplify():\n    e = Eq(x + 2, 5)\n    simplified = e._eval_simplify()\n    assert simplified == Eq(x, 3)\n"], "sample_102": ["def test_union_with_empty_queryset(self):\n    qs1 = Number.objects.filter(num__gt=5)\n    qs2 = Number.objects.none()\n    union_qs = qs1.union(qs2)\n    self.assertNumbersEqual(union_qs, [6, 7, 8, 9])\n"], "sample_487": ["    def test_filter_horizontal_invalid_type(self):\n        class MyModelAdmin(ModelAdmin):\n            filter_horizontal = \"invalid_type\"\n\n        self.assertIsInvalid(\n            MyModelAdmin,\n            ValidationTestModel,\n            \"The value of 'filter_horizontal' must be a list or tuple.\",\n            id=\"admin.E018\",\n        )\n"], "sample_1183": ["def test_field_operations():\n    _, x, y = field(\"x,y\", ZZ)\n    f = (x**2 + y)/(x - 1)\n    g = (x + y)/(x + 1)\n\n    assert f + g == (x**2 + 2*x*y + y + 1)/(x**2 - 1)\n    assert f - g == (x**2 - 2*x*y + y - 1)/(x**2 - 1)\n    assert f * g == (x**2 + x*y + y)/(x**2 - 1)\n    assert f / g == (x**2 + x*y + y)/(x**2 - x - y)\n    assert f.diff(x) == (2*x + y)/(x - 1)**2\n"], "sample_316": ["    def test_get_image_dimensions(self):\n        if Image is None:\n            self.skipTest(\"Pillow not installed\")\n\n        # Create a simple image using Pillow\n        image = Image.new('RGB', (100, 200))\n\n        # Save the image to a BytesIO object\n        image_io = BytesIO()\n        image.save(image_io, format='PNG')\n        image_io.seek(0)\n\n        # Test the function with the BytesIO object\n        width, height = get_image_dimensions(image_io)\n        self.assertEqual(width, 100)\n        self.assertEqual(height, 200)\n\n        # Test the function with a file path\n        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp:\n            image.save(temp, format='PNG')\n            width, height = get_image_dimensions(temp.name)\n            self.assertEqual(width, 100)\n            self.assertEqual(height, 200)\n            os.unlink(temp.name)\n\n        # Test the function with a non-existent file path\n        width, height = get_image_dimensions('non_existent_file.png')\n        self.assertEqual(width, None)\n        self.assertEqual(height, None)\n"], "sample_524": ["def test_colorbar_extension_length():\n    fig_uniform = _colorbar_extension_length('uniform')\n    fig_proportional = _colorbar_extension_length('proportional')\n    return fig_uniform, fig_proportional\n"], "sample_1074": ["def test_schreier_sims_random():\n    S = SymmetricGroup(5)\n    base, strong_gens = S.schreier_sims_random(consec_succ=5)\n    assert _verify_bsgs(S, base, strong_gens)\n"], "sample_854": ["def test_libsvm_sparse_predict():\n    X = sparse.csr_matrix([[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1]])\n    y = np.array([1, 1, 1, 2, 2, 2])\n    clf = svm.SVC(kernel='linear')\n    clf.fit(X, y)\n    X_test = sparse.csr_matrix([[-1, -1], [2, 2], [3, 2]])\n    y_pred = clf.predict(X_test)\n    assert_array_equal(y_pred, np.array([1, 2, 2]))\n"], "sample_1101": ["def test_schur_partition_with_symbols():\n    x = symbols('x')\n    raises(ValueError, lambda: schur_partition(x))\n"], "sample_53": ["    def test_decompress(self):\n        widget = SplitDateTimeWidget()\n        value = datetime.datetime(2022, 1, 1, 12, 30)\n        decompressed_value = widget.decompress(value)\n        self.assertEqual(decompressed_value, [datetime.date(2022, 1, 1), datetime.time(12, 30)])\n"], "sample_650": ["def test_log_capture_fixture_force_enable_logging(caplog: LogCaptureFixture):\n    # Test that _force_enable_logging enables logging at the desired level\n    # if it was disabled via logging.disable().\n    import logging\n\n    # Disable logging at the WARNING level.\n    logging.disable(logging.WARNING)\n\n    # Set the log level to INFO using the fixture.\n    caplog.set_level(logging.INFO)\n\n    # Verify that logging is enabled at the INFO level.\n    logger = logging.getLogger()\n    assert logger.isEnabledFor(logging.INFO)\n\n    # Disable logging again to restore the original state.\n    logging.disable(logging.NOTSET)\n"], "sample_553": ["def test_null_movie_writer(anim):\n    \"\"\"Test NullMovieWriter.\"\"\"\n    writer = NullMovieWriter()\n    with writer.saving(anim._fig, 'test.mp4', 100):\n        for frame in anim.new_saved_frame_seq():\n            anim._draw_next_frame(frame, blit=False)\n            writer.grab_frame()\n    assert writer.fig is anim._fig\n    assert writer.outfile == 'test.mp4'\n    assert writer.dpi == 100\n    assert writer.args == ()\n    assert writer._count == 5\n    assert 'dpi' not in writer.savefig_kwargs\n    assert 'bbox_inches' not in writer.savefig_kwargs\n    assert 'format' not in writer.savefig_kwargs\n"], "sample_670": ["def test_evaluate_with_ident():\n        return ident == \"test\"\n\n    assert evaluate(\"test\", matcher) is True\n    assert evaluate(\"not test\", matcher) is False\n    assert evaluate(\"test or test\", matcher) is True\n    assert evaluate(\"test and test\", matcher) is True\n    assert evaluate(\"test and not test\", matcher) is False\n    assert evaluate(\"(test)\", matcher) is True\n    assert evaluate(\"not (test)\", matcher) is False\n    assert evaluate(\"test or not test\", matcher) is True\n    assert evaluate(\"test and not (test)\", matcher) is False\n"], "sample_1096": ["def test_indexed_derivative():\n    A = IndexedBase('A')\n    i, j = symbols('i j', cls=Idx)\n    A_ij = A[i, j]\n    dA_ij = Derivative(A_ij, A[i, j])\n    assert dA_ij == KroneckerDelta(i, i)*KroneckerDelta(j, j)\n"], "sample_871": ["def test_silhouette_score_sparse_input():\n    # Test silhouette_score function with sparse input\n    X = csr_matrix([[1, 2], [3, 4], [5, 6]])\n    labels = np.array([0, 1, 0])\n    score = silhouette_score(X, labels, metric=\"euclidean\")\n    assert isinstance(score, float)\n"], "sample_493": ["def test_aggregate_with_filter(self):\n    # Test aggregate with filter\n    result = Book.objects.filter(publisher=self.p1).aggregate(Avg('pages'))\n    self.assertEqual(result['pages__avg'], 381.5)\n"], "sample_893": ["def test_export_text_with_class_names():\n    decision_tree = DecisionTreeClassifier(random_state=0, max_depth=2)\n    decision_tree = decision_tree.fit(X, y)\n    class_names = [\"Class 0\", \"Class 1\"]\n    r = export_text(decision_tree, feature_names=[\"Feature 1\", \"Feature 2\"], class_names=class_names)\n    assert \"class: Class 0\" in r\n    assert \"class: Class 1\" in r\n"], "sample_444": ["def test_hashed_name_with_fragment(self):\n    name = \"test.css?#iefix\"\n    content = StringIO(\"/*# sourceMappingURL=test.css.map */\")\n    hashed_name = storage.staticfiles_storage.hashed_name(name, content)\n    self.assertIn(\"?#\", hashed_name)\n    self.assertPostCondition()\n"], "sample_668": ["def test_node_use_from_parent():\n    with pytest.warns(deprecated.NODE_USE_FROM_PARENT) as record:\n        node = nodes.Item(\"test_node\")\n    assert len(record) == 1\n    assert \"Direct construction of Item has been deprecated\" in str(record[0].message)\n"], "sample_718": ["    def test_check_estimator_correct_not_fitted_error(self):\n        # Test that the correct NotFittedError is raised\n        estimator = CorrectNotFittedErrorClassifier()\n        X = np.array([[1, 2], [3, 4]])\n        y = np.array([0, 1])\n        with self.assertRaises(CorrectNotFittedError):\n            estimator.predict(X)\n        estimator.fit(X, y)\n        estimator.predict(X)  # Should not raise an error\n"], "sample_280": ["def test_aggregate_filter(self):\n    # Test filter argument in Aggregate\n    books = Book.objects.filter(publisher=self.p1)\n    avg_rating = books.aggregate(Avg('rating', filter=Q(pages__gt=400)))['rating__avg']\n    self.assertEqual(avg_rating, 4.5)\n"], "sample_949": ["def test_default_man_pages(app):\n    config = Config({\n        'project': 'Test Project',\n        'release': '1.0',\n        'author': 'Test Author',\n        'root_doc': 'index'\n    })\n    result = default_man_pages(config)\n    assert result == [('index', 'testproject', 'Test Project 1.0', ['Test Author'], 1)]\n"], "sample_367": ["    def test_fully_decorated_docstring_and_attributes(self):\n        \"\"\"\n        Test that the fully decorated function retains its docstring and attributes.\n        \"\"\"\n        self.assertEqual(fully_decorated.__doc__, \"Expected __doc__\")\n        self.assertEqual(fully_decorated.anything, \"Expected __dict__\")\n"], "sample_713": ["def test_ridge_classifier_cv_multilabel():\n    X, y = make_multilabel_classification(random_state=0)\n    ridge_cv = RidgeClassifierCV()\n    assert_raise_message(ValueError, \"RidgeClassifierCV doesn't support multi-label classification\", ridge_cv.fit, X, y)\n"], "sample_281": ["def test_permission_denied(self):\n    \"\"\"Test that a PermissionDenied is raised when the user doesn't have permission.\"\"\"\n    request = self.factory.get(self.url, self.opts)\n    request.user = self.user\n    with self.assertRaises(PermissionDenied):\n        self.get_view()(request)\n"], "sample_905": ["def test_signature_from_str():\n    sig = inspect.signature_from_str(\"(a: int, b: str = 'default')\")\n    assert str(sig) == \"(a: int, b: str = 'default')\"\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.parameters['b'].default == 'default'\n"], "sample_683": ["def test_start_global_capturing(self, method):\n    capman = CaptureManager(method)\n    capman.start_global_capturing()\n    assert capman._global_capturing is not None\n    assert capman._global_capturing._state == \"started\"\n"], "sample_1054": ["def test_complex_region_intersection():\n    a = Interval(2, 3)\n    b = Interval(4, 6)\n    c = Interval(1, 8)\n    c1 = ComplexRegion(a*b)\n    c2 = ComplexRegion(Union(a*b, b*c))\n    intersection = c1.intersect(c2)\n    assert intersection == c1\n"], "sample_1182": ["def test_print_loggamma():\n    expr = loggamma(x)\n    result = pycode(expr)\n    assert result == \"math.lgamma(x)\"\n"], "sample_1160": ["def test_intersection_sets_complex_region():\n    c1 = ComplexRegion(Interval(0, 1), Interval(0, pi))\n    c2 = ComplexRegion(Interval(0, 2), Interval(0, pi/2))\n    result = intersection_sets(c1, c2)\n    expected = ComplexRegion(Interval(0, 1), Interval(0, pi/2))\n    assert result == expected\n"], "sample_1006": ["def test_binomial_rewrite_as_gamma():\n    n, k = symbols('n k', integer=True)\n    assert binomial(n, k).rewrite(gamma) == gamma(n + 1) / (gamma(k + 1) * gamma(n - k + 1))\n"], "sample_208": ["def test_generate_altered_order_with_respect_to(self):\n    changes = self.get_changes(\n        [self.author_with_book],\n        [self.author_with_book_order_wrt],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterOrderWithRespectTo\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Author\", order_with_respect_to=\"book\")\n"], "sample_233": ["    def test_check_token_valid(self):\n        user = User.objects.create_user(username='testuser', password='12345')\n        now = datetime.now()\n        token_generator = MockedPasswordResetTokenGenerator(now)\n        token = token_generator.make_token(user)\n        self.assertTrue(token_generator.check_token(user, token))\n"], "sample_496": ["def test_command_error_handling(self):\n    class ErrorCommand(BaseCommand):\n            raise CommandError(\"Test error message\")\n\n    with self.assertRaises(CommandError) as cm:\n        call_command('error')\n    self.assertEqual(str(cm.exception), \"Test error message\")\n"], "sample_190": ["def test_year_exact_lookup(self):\n    articles = Article.objects.filter(pub_date__year__exact=2005)\n    self.assertCountEqual(articles, [self.a1, self.a2, self.a3, self.a4, self.a5, self.a6, self.a7])\n"], "sample_841": ["def test_ridge_regression_solver_options(solver):\n    ridge = Ridge(solver=solver)\n    ridge.fit(X_diabetes, y_diabetes)\n    assert hasattr(ridge, 'coef_')\n    assert hasattr(ridge, 'intercept_')\n"], "sample_876": ["def test_mlp_classifier_activation(activation):\n    clf = MLPClassifier(activation=activation, random_state=0, max_iter=100)\n    clf.fit(X_iris, y_iris)\n    assert clf.score(X_iris, y_iris) > 0.9\n"], "sample_145": ["    def test_filter_vertical_not_a_list_or_tuple(self):\n        class MyModelAdmin(ModelAdmin):\n            filter_vertical = 'not_a_list_or_tuple'\n\n        self.assertIsInvalid(MyModelAdmin, ValidationTestModel,\n                             \"The value of 'filter_vertical' must be a list or tuple.\",\n                             id='admin.E017')\n"], "sample_479": ["def test_rename_model_with_related_fields(self):\n    operations = [\n        migrations.CreateModel(\n            name='Author',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('name', models.CharField(max_length=100)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='Book',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('title', models.CharField(max_length=200)),\n                ('author', models.ForeignKey('Author', on_delete=models.CASCADE)),\n            ],\n        ),\n        migrations.RenameModel(\n            old_name='Author',\n            new_name='Writer',\n        ),\n    ]\n    expected = [\n        migrations.CreateModel(\n            name='Writer',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('name', models.CharField(max_length=100)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='Book',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('title', models.CharField(max_length=200)),\n                ('author', models.ForeignKey('Writer', on_delete=models.CASCADE)),\n            ],\n        ),\n    ]\n    self.assertOptimizesTo(operations, expected)\n"], "sample_313": ["    def test_watch_for_template_changes(self):\n        sender = mock.Mock()\n        autoreload.autoreload_started.send(sender=autoreload)\n        sender.watch_dir.assert_called_with(EXTRA_TEMPLATES_DIR, '**/*')\n"], "sample_258": ["    def test_receiver_disconnect(self):\n        \"\"\"Test disconnecting a receiver\"\"\"\n        a_signal.connect(receiver_1_arg)\n        self.assertTrue(a_signal.has_listeners())\n        a_signal.disconnect(receiver_1_arg)\n        self.assertFalse(a_signal.has_listeners())\n        self.assertTestIsClean(a_signal)\n"], "sample_645": ["def test_logging_levels(caplog):\n    caplog.set_level(logging.INFO)\n    logger.info(\"This is an info message\")\n    sublogger.debug(\"This is a debug message\")\n    assert \"This is an info message\" in caplog.text\n    assert \"This is a debug message\" not in caplog.text\n"], "sample_501": ["def test_legend_set_draggable():\n    fig, ax = plt.subplots()\n    line, = ax.plot([1, 2, 3], [1, 2, 3], label='Test line')\n    legend = ax.legend()\n\n    # Test enabling draggable\n    draggable = legend.set_draggable(True)\n    assert isinstance(draggable, mlegend.DraggableLegend)\n    assert legend.get_draggable() is True\n\n    # Test disabling draggable\n    legend.set_draggable(False)\n    assert legend.get_draggable() is False\n"], "sample_1144": ["def test_split_super_sub():\n    assert split_super_sub('a_x^1') == ('a', ['1'], ['x'])\n    assert split_super_sub('var_sub1__sup_sub2') == ('var', ['sup'], ['sub1', 'sub2'])\n    assert split_super_sub('name123') == ('name', [], ['123'])\n    assert split_super_sub('') == ('', [], [])\n"], "sample_991": ["def test_product_convergence():\n    assert product(1/n**2, (n, 1, oo)).is_convergent() == True\n    assert product(exp(-n**2), (n, 1, oo)).is_convergent() == False\n"], "sample_144": ["def test_model_save_base(self):\n    user = User(username='testuser')\n    user.save_base(raw=False, force_insert=True, force_update=False, using=None, update_fields=None)\n    self.assertIsNotNone(user.pk)\n    self.assertTrue(user._state.adding)\n    user.save_base(raw=False, force_insert=False, force_update=True, using=None, update_fields=None)\n    self.assertFalse(user._state.adding)\n"], "sample_749": ["def test_column_transformer_with_sparse_matrix_transformer():\n    X = np.array([[0., 1., 2., 2.],\n                  [1., 1., 0., 1.]])\n    ct = ColumnTransformer(\n        [(\"sparse\", SparseMatrixTrans(), slice(0, 2))])\n    ct.fit(X)\n    X_transformed = ct.transform(X)\n    assert_true(sparse.issparse(X_transformed))\n    assert_array_equal(X_transformed.toarray(), np.eye(2))\n"], "sample_1016": ["def test_hankel_functions():\n    expr1 = hankel1(0, x)\n    expr2 = hankel2(1, y)\n    assert mcode(expr1) == \"besselh(0, 1, x)\"\n    assert mcode(expr2) == \"besselh(1, 2, y)\"\n"], "sample_131": ["    def setUp(self):\n        self.test_connection = self.get_connection_copy()\n        self.db_creation = BaseDatabaseCreation(self.test_connection)\n"], "sample_256": ["    def test_form_renders_password_help_text(self):\n        form = UserChangeForm(instance=self.u1)\n        self.assertIn('../password/', form.fields['password'].help_text)\n"], "sample_331": ["    def test_parse_datetime_with_timezone(self):\n        value = \"2022-01-01T12:34:56+03:00\"\n        expected = datetime(2022, 1, 1, 12, 34, 56, tzinfo=get_fixed_timezone(180))\n        self.assertEqual(parse_datetime(value), expected)\n"], "sample_217": ["def test_media_property(self):\n    class TestWidget(Widget):\n        class Media:\n            css = {'all': ('test.css',)}\n            js = ('test.js',)\n\n    widget = TestWidget()\n    self.assertEqual(widget.media._css, {'all': ['test.css']})\n    self.assertEqual(widget.media._js, ['test.js'])\n"], "sample_981": ["def test_commutes_with():\n    p = Permutation([1, 4, 3, 0, 2, 5])\n    q = Permutation([0, 1, 2, 3, 4, 5])\n    assert p.commutes_with(q) == True\n    q = Permutation([2, 3, 5, 4, 1, 0])\n    assert p.commutes_with(q) == False\n"], "sample_1003": ["def test_series_flag():\n    options = Options((), {'series': True})\n    assert options.series == True\n    options = Options((), {'series': False})\n    assert options.series == False\n    raises(OptionError, lambda: Options((), {'series': 'invalid'}))\n"], "sample_997": ["def test_convert_equals_signs():\n    expr = parse_expr(\"(1*2=x)=False\", transformations=(standard_transformations + (convert_equals_signs,)))\n    assert expr == Eq(Eq(2, Symbol('x')), False)\n"], "sample_558": ["def test_image_grid_cbar_set_cax():\n    fig = plt.figure()\n    grid = ImageGrid(fig, 111, (1, 3), cbar_mode='each', cbar_set_cax=True)\n    for ax, cax in zip(grid, grid.cbar_axes):\n        assert ax.cax is cax\n"], "sample_1098": ["def test_appellf1_derivative():\n    a, b1, b2, c, x, y = symbols('a b1 b2 c x y')\n    f = appellf1(a, b1, b2, c, x, y)\n    assert f.fdiff(5) == (a*b1/c)*appellf1(a + 1, b1 + 1, b2, c + 1, x, y)\n    assert f.fdiff(6) == (a*b2/c)*appellf1(a + 1, b1, b2 + 1, c + 1, x, y)\n"], "sample_746": ["def test_brier_score_loss():\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    expected_score = 0.037\n    assert_almost_equal(brier_score_loss(y_true, y_prob), expected_score)\n"], "sample_244": ["def test_custom_kwarg_formset(self):\n    CustomKwargFormSet = formset_factory(CustomKwargForm, extra=2, form_kwargs={'custom_kwarg': 'test'})\n    formset = CustomKwargFormSet()\n    for form in formset:\n        self.assertEqual(form.custom_kwarg, 'test')\n"], "sample_884": ["def test_is_deprecated():\n    assert _is_deprecated(mock_function)\n    assert _is_deprecated(MockClass1)\n    assert _is_deprecated(MockClass2().method)\n    assert _is_deprecated(MockClass2().n_features_)\n    assert _is_deprecated(MockClass3.__init__)\n    assert _is_deprecated(MockClass6)\n    assert not _is_deprecated(MockClass4)\n    assert not _is_deprecated(MockClass5)\n"], "sample_264": ["    def test_max_cookie_size(self):\n        storage = self.storage_class(self.request)\n        messages = [Message(constants.INFO, get_random_string(1000)) for _ in range(10)]\n        response = self.response_class()\n        unstored_messages = storage._store(messages, response, remove_oldest=True)\n        self.assertEqual(self.stored_messages_count(storage, response), 5)\n        self.assertEqual(len(unstored_messages), 5)\n"], "sample_127": ["def test_bulk_create_with_ignore_conflicts(self):\n    Country.objects.bulk_create(self.data, ignore_conflicts=True)\n    # Try to create the same objects again, this time with ignore_conflicts=True\n    Country.objects.bulk_create(self.data, ignore_conflicts=True)\n    # Check that the number of countries in the database is still 4\n    self.assertEqual(Country.objects.count(), 4)\n"], "sample_951": ["def test_signature_from_str():\n    sig = inspect.signature_from_str(\"(a: int, b: str = 'default')\")\n    assert str(sig) == \"(a: int, b: str = 'default')\"\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.parameters['b'].default == 'default'\n"], "sample_838": ["def test_column_transformer_with_sparse_matrix_transformer():\n    X = np.array([[0, 1], [2, 3]])\n    ct = ColumnTransformer([(\"sparse\", SparseMatrixTrans(), [0])])\n    Xt = ct.fit_transform(X)\n    assert sparse.issparse(Xt)\n    assert_array_equal(Xt.toarray(), np.eye(2))\n"], "sample_475": ["    def test_filter_vertical_invalid_type(self):\n        class InvalidFilterVerticalModelAdmin(ModelAdmin):\n            filter_vertical = \"invalid_type\"\n\n        self.assertIsInvalid(\n            InvalidFilterVerticalModelAdmin,\n            ValidationTestModel,\n            \"The value of 'filter_vertical' must be a list or tuple.\",\n            id=\"admin.E017\",\n        )\n"], "sample_404": ["def test_variable_node_render(self):\n    template = self._engine().from_string(\"{{ var }}\")\n    context = Context({\"var\": \"test\"})\n    self.assertEqual(template.render(context), \"test\")\n"], "sample_149": ["    def test_non_unique_username_field(self):\n        errors = check_user_model(self.apps.get_models())\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'auth.W004')\n"], "sample_830": ["def test_get_blas_info():\n    blas_info = _get_blas_info()\n    assert isinstance(blas_info, dict)\n    assert 'macros' in blas_info\n    assert 'lib_dirs' in blas_info\n    assert 'cblas_libs' in blas_info\n"], "sample_414": ["def test_formfield_for_foreignkey(self):\n    \"\"\"\n    Test formfield_for_dbfield for a ForeignKey field.\n    \"\"\"\n    self.assertFormfield(Car, \"owner\", widgets.AutocompleteSelect)\n"], "sample_321": ["def test_csrf_token_rotation(self):\n    req = self._get_GET_csrf_cookie_request()\n    initial_token = req.META['CSRF_COOKIE']\n\n    # Rotate the token\n    rotate_token(req)\n\n    # Check that the token has been rotated\n    self.assertNotEqual(req.META['CSRF_COOKIE'], initial_token)\n"], "sample_714": ["def test_brier_score_loss():\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    expected_score = 0.037\n    assert_almost_equal(brier_score_loss(y_true, y_prob), expected_score)\n"], "sample_622": ["def test_bool_type_array_getitem():\n    x = np.array([1, 0, 1, 1, 0], dtype=\"i1\")\n    bool_array = coding.BoolTypeArray(x)\n    indexer = coding.indexing.BasicIndexer((slice(None),))\n    result = bool_array[indexer]\n    expected = np.array([True, False, True, True, False], dtype=bool)\n    assert_array_equal(result, expected)\n"], "sample_1051": ["def test_dotprint_float():\n    expr = Float(3.14)\n    result = dotprint(expr)\n    expected = 'digraph{\\n\\n# Graph style\\n\"ordering\"=\"out\"\\n\"rankdir\"=\"TD\"\\n\\n#########\\n# Nodes #\\n#########\\n\\n\"Float(3.14)_()\" [\"color\"=\"black\", \"label\"=\"Float\", \"shape\"=\"ellipse\"];\\n\\n#########\\n# Edges #\\n#########\\n\\n}\\n'\n    assert result == expected\n"], "sample_495": ["    def test_validate_number(self):\n        \"\"\"\n        Test the validate_number method of the Paginator class.\n        \"\"\"\n        paginator = Paginator(range(100), 10)\n\n        # Test valid page numbers\n        self.assertEqual(paginator.validate_number(1), 1)\n        self.assertEqual(paginator.validate_number(5), 5)\n        self.assertEqual(paginator.validate_number(10), 10)\n\n        # Test non-integer page numbers\n        with self.assertRaises(PageNotAnInteger):\n            paginator.validate_number('a')\n            paginator.validate_number(1.5)\n\n        # Test page numbers less than 1\n        with self.assertRaises(EmptyPage):\n            paginator.validate_number(0)\n            paginator.validate_number(-1)\n\n        # Test page numbers greater than num_pages\n        with self.assertRaises(EmptyPage):\n            paginator.validate_number(11)\n            paginator.validate_number(100)\n\n        # Test page numbers equal to 1 when allow_empty_first_page is True\n        paginator.allow_empty_first_page = True\n        self.assertEqual(paginator.validate_number(1), 1)\n"], "sample_589": ["def test_get_clean_interp_index(da):\n    index = get_clean_interp_index(da, \"time\", use_coordinate=True)\n    expected_index = pd.Index(pd.date_range(\"2000-01-01\", freq=\"D\", periods=11), name=\"time\")\n    assert_equal(index, expected_index)\n\n    index = get_clean_interp_index(da, \"time\", use_coordinate=False)\n    expected_index = np.arange(11, dtype=np.float64)\n    assert_array_equal(index, expected_index)\n\n    da[\"time\"] = pd.date_range(\"2000-01-01\", freq=\"2D\", periods=11)\n    with pytest.raises(ValueError):\n        get_clean_interp_index(da, \"time\", use_coordinate=True)\n\n    da[\"time\"] = pd.date_range(\"2000-01-01\", freq=\"D\", periods=11).repeat(2)\n    with pytest.raises(ValueError):\n        get_clean_interp_index(da, \"time\", use_coordinate=True)\n\n    da[\"time\"] = pd.MultiIndex.from_tuples([(i, i) for i in range(11)], names=[\"a\", \"b\"])\n    with pytest.raises(TypeError):\n        get_clean_interp_index(da, \"time\", use_coordinate=True)\n"], "sample_353": ["def test_create_superuser_with_password_validation_bypass(self):\n    out = StringIO()\n    call_command('createsuperuser', username='bob', stdin=MockTTY(), stdout=out)\n    self.assertIn('Superuser created successfully.', out.getvalue())\n    self.assertTrue(User.objects.filter(username='bob').exists())\n"], "sample_95": ["def test_patch_cache_control(self):\n    response = HttpResponse()\n    patch_cache_control(response, max_age=3600, private=True, no_cache=False)\n    self.assertEqual(response['Cache-Control'], 'max-age=3600, private')\n\n    patch_cache_control(response, max_age=1800, public=True)\n    self.assertEqual(response['Cache-Control'], 'max-age=1800, public')\n"], "sample_113": ["    def test_simplify_regex(self):\n        self.assertEqual(simplify_regex(r'^(?P<a>\\w+)/b/(\\w+)$'), '^<a>/b/<var>$')\n        self.assertEqual(simplify_regex(r'^(?P<a>\\w+)/b/(?P<c>\\w+)/$'), '^<a>/b/<c>/$')\n        self.assertEqual(simplify_regex(r'^(?P<a>\\w+)/b/(\\w+)'), '^<a>/b/<var>')\n        self.assertEqual(simplify_regex(r'^(?P<a>\\w+)/b/(?P<c>\\w+)'), '^<a>/b/<c>')\n        self.assertEqual(simplify_regex(r'^(?P<a>\\w+)/b/((x|y)\\w+)$'), '^<a>/b/<var>$')\n        self.assertEqual(simplify_regex(r'^(?P<a>\\w+)/b/((x|y)\\w+)'), '^<a>/b/<var>')\n"], "sample_944": ["def test_restify_and_stringify():\n    assert restify(MyClass1) == ':class:`test_util_typing.MyClass1`'\n    assert stringify(MyClass1) == 'test_util_typing.MyClass1'\n\n    assert restify(MyClass2) == ':class:`test_util_typing.MyClass2`'\n    assert stringify(MyClass2) == 'test_util_typing.<MyClass2>'\n\n    assert restify(MyInt) == ':class:`MyInt`'\n    assert stringify(MyInt) == 'MyInt'\n\n    assert restify(MyList[int]) == ':class:`test_util_typing.MyList`\\\\ [int]'\n    assert stringify(MyList[int]) == 'test_util_typing.MyList[int]'\n\n    assert restify(BrokenType) == ':obj:`test_util_typing.BrokenType`'\n    assert stringify(BrokenType) == 'test_util_typing.BrokenType'\n\n    assert restify(Optional[int]) == ':obj:`Optional`\\\\ [int]'\n    assert stringify(Optional[int]) == 'Optional[int]'\n\n    assert restify(Union[int, str]) == ':obj:`Union`\\\\ [int, str]'\n    assert stringify(Union[int, str]) == 'Union[int, str]'\n\n    assert restify(Callable[[int], str]) == ':class:`Callable`\\\\ [[int], str]'\n    assert stringify(Callable[[int], str]) == 'Callable[[int], str]'\n\n    assert restify(Integral) == ':class:`numbers.Integral`'\n    assert stringify(Integral) == 'numbers.Integral'\n\n    assert restify(Struct) == ':class:`struct.Struct`'\n    assert stringify(Struct) == 'struct.Struct'\n\n    assert restify(TracebackType) == ':class:`types.TracebackType`'\n    assert stringify(TracebackType) == 'types.TracebackType'\n\n   "], "sample_37": ["def test_maps_files(self):\n    for filename in self._file_list:\n        with fits.open(filename) as hdulist:\n            w = wcs.WCS(hdulist[0].header)\n            assert w.naxis == 2\n            assert w.wcs.naxis == 2\n            assert w.wcs.lngtyp == 'RA'\n            assert w.wcs.lattyp == 'DEC'\n            assert w.wcs.lng == 0\n            assert w.wcs.lat == 1\n            assert w.wcs.naxis == 2\n            assert w.wcs.lng == 0\n            assert w.wcs.lat == 1\n            assert w.wcs.lngtyp == 'RA'\n            assert w.wcs.lattyp == 'DEC'\n            assert w.wcs.alt == ' '\n            assert w.wcs.mjdobs == 0.0\n            assert w.wcs.equinox == 2000.0\n            assert w.wcs.radesys == 'ICRS'\n            assert w.wcs.specsys == 'TOPOCENT'\n            assert w.wcs.ssysobs == 0\n            assert w.wcs.ssyssrc == 0\n            assert w.wcs.obsgeo[0] == 0.0\n            assert w.wcs.obsgeo[1] == 0.0\n            assert w.wcs.obsgeo[2] == 0.0\n            assert w.wcs.dateobs == ' '\n            assert w.wcs.dateavg == ' '\n            assert w.wcs.dateref == ' '\n            assert w.wcs.timeobs == ' '\n            assert w.wcs.timeavg == ' '\n            assert w.wcs.timeref == ' '\n            assert w.wcs.obsra == 0.0\n            assert w.wcs.obsdec == 0.0\n            assert w.wcs.velosys == 0.0\n            assert w.wcs.zsource == 0.0\n            assert w.wcs.restfr"], "sample_878": ["def test_column_transformer_with_callable_columns():\n    # Test ColumnTransformer with callable columns\n    X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    transformer = ColumnTransformer(\n        transformers=[\n            (\"firstcolumn\", \"passthrough\", lambda X: [0]),\n            (\"secondcolumn\", DoubleTrans(), lambda X: [1]),\n        ]\n    )\n    X_transformed = transformer.fit_transform(X)\n    assert_array_equal(X_transformed, np.array([[1, 4], [4, 10], [7, 16]]))\n"], "sample_143": ["    def test_truncator_chars(self):\n        truncator = text.Truncator('This is a long text that needs to be truncated.')\n        result = truncator.chars(10)\n        self.assertEqual(result, 'This is a\u2026')\n"], "sample_502": ["def test_xlim():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], [4, 5, 6])\n    plt.xlim(2, 3)\n    assert ax.get_xlim() == (2, 3)\n"], "sample_158": ["    def test_check_unique(self):\n        class MyModel(models.Model):\n            m2m_field = models.ManyToManyField('self', unique=True)\n\n        field = MyModel._meta.get_field('m2m_field')\n        errors = field._check_unique()\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, 'fields.E330')\n"], "sample_1111": ["def test_textplot_str_complex_values():\n    x = Symbol('x')\n    expr = sqrt(x)\n    a = -1\n    b = 1\n    W = 5\n    H = 5\n    result = list(textplot_str(expr, a, b, W, H))\n    # Check that the output contains no complex values\n    assert all('j' not in line for line in result)\n"], "sample_40": ["def test_with_H0_equivalency():\n    # Test with_H0 equivalency with a custom H0 value\n    custom_H0 = 70 * u.km / u.s / u.Mpc\n    equiv = u.with_H0(custom_H0)\n    q = 1 * u.Mpc / u.littleh\n    assert_quantity_allclose(q.to(u.Mpc, equivalencies=equiv), 1 * u.Mpc / (custom_H0.value / 100))\n\n    # Test with_H0 equivalency with the default H0 value\n    equiv = u.with_H0()\n    q = 1 * u.Mpc / u.littleh\n    default_H0 = cosmology.default_cosmology.get().H0\n    assert_quantity_allclose(q.to(u.Mpc, equivalencies=equiv), 1 * u.Mpc / (default_H0.value / 100))\n"], "sample_580": ["def test_categorical_order_with_order_argument():\n    vector = pd.Series([\"b\", \"a\", \"c\", \"b\", np.nan])\n    order = [\"a\", \"b\", \"c\"]\n    assert categorical_order(vector, order) == order\n"], "sample_639": ["    def test_check_consistency(self):\n        checker = OtherBasicChecker()\n        checker.check_consistency()  # This should not raise an exception\n\n        checker.msgs[\"W0003\"] = (\n            \"Inconsistent checker part.\",\n            \"inconsistent-checker-part\",\n            \"This message id should cause an error.\",\n        )\n        with self.assertRaises(InvalidMessageError):\n            checker.check_consistency()\n"], "sample_704": ["def test_iterparentnodeids(nodeid: str, expected: List[str]) -> None:\n    result = list(nodes.iterparentnodeids(nodeid))\n    assert result == expected\n"], "sample_752": ["def test_isolation_forest_sparse_input():\n    # Test IsolationForest with sparse input\n    X = csc_matrix(iris.data)\n    y = iris.target\n\n    clf = IsolationForest(random_state=rng)\n    clf.fit(X)\n    y_pred = clf.predict(X)\n\n    assert_array_equal(y_pred.shape, y.shape)\n"], "sample_1024": ["def test_integer_nthroot():\n    assert integer_nthroot(8, 3) == (2, True)\n    assert integer_nthroot(27, 3) == (3, True)\n    assert integer_nthroot(26, 3) == (3, False)\n"], "sample_239": ["def test_formset_factory_with_custom_kwargs(self):\n    CustomKwargFormSet = formset_factory(CustomKwargForm, formset=BaseFormSet, extra=2, form_kwargs={'custom_kwarg': 'test'})\n    formset = CustomKwargFormSet()\n    for form in formset:\n        self.assertEqual(form.custom_kwarg, 'test')\n"], "sample_92": ["    def setUpTestData(cls):\n        cls.user = User.objects.create_user('test', 'test@example.com', 'test')\n        cls.group = Group.objects.create(name='test_group')\n        cls.user.groups.add(cls.group)\n        cls.permission = Permission.objects.create(\n            name='test_permission',\n            content_type=ContentType.objects.get_for_model(User),\n            codename='test_codename',\n        )\n        cls.group.permissions.add(cls.permission)\n"], "sample_224": ["def test_aggregate_with_filter(self):\n    # Test aggregate function with filter\n    avg_rating = Book.objects.filter(rating__gt=4).aggregate(Avg('rating'))\n    self.assertEqual(avg_rating['rating__avg'], 4.5)\n"], "sample_1072": ["def test_frac_rewrite():\n    assert frac(x).rewrite(floor) == x - floor(x)\n    assert frac(x).rewrite(ceiling) == x + ceiling(-x)\n"], "sample_609": ["def test_apply_ufunc_with_dask_gufunc_kwargs():\n    # Test apply_ufunc with dask='parallelized' and dask_gufunc_kwargs\n        return x + y\n\n    x = xr.DataArray(np.arange(10).reshape(2, 5), dims=(\"dim1\", \"dim2\"))\n    y = xr.DataArray(np.ones((5, 2)), dims=(\"dim2\", \"dim3\"))\n\n    result = apply_ufunc(\n        func,\n        x,\n        y,\n        input_core_dims=[[\"dim2\"], [\"dim2\"]],\n        output_core_dims=[[\"dim1\", \"dim3\"]],\n        dask=\"parallelized\",\n        dask_gufunc_kwargs={\"output_sizes\": {\"dim3\": 2}},\n    )\n\n    expected_result = xr.DataArray(\n        np.array([[1.0, 2.0], [6.0, 7.0], [11.0, 12.0], [16.0, 17.0], [21.0, 22.0]]),\n        dims=(\"dim2\", \"dim3\"),\n    )\n\n    assert_identical(result, expected_result)\n"], "sample_1202": ["def test_integer_nthroot():\n    assert integer_nthroot(8, 3) == (2, True)\n    assert integer_nthroot(27, 3) == (3, True)\n    assert integer_nthroot(26, 3) == (3, False)\n"], "sample_653": ["def test_log_capture_fixture_clear(caplog):\n    caplog.set_level(10)\n    logger = logging.getLogger(\"test_logger\")\n    logger.info(\"Test message\")\n    assert len(caplog.records) == 1\n    caplog.clear()\n    assert len(caplog.records) == 0\n"], "sample_739": ["def test_label_binarizer_sparse_output():\n    lb = LabelBinarizer(sparse_output=True)\n    y = [1, 2, 6, 4, 2]\n    lb.fit(y)\n    y_bin = lb.transform(y)\n    assert_true(issparse(y_bin))\n    assert_array_equal(y_bin.toarray(), label_binarize(y, classes=lb.classes_))\n"], "sample_579": ["def test_heatmap_with_mask(self):\n    mask = np.zeros_like(self.x_norm, dtype=bool)\n    mask[1, 2] = True\n    ax = mat.heatmap(self.df_norm, mask=mask)\n    assert np.isnan(ax.collections[0].get_array()[1, 2])\n"], "sample_47": ["    def test_get_traceback_data(self):\n        request = RequestFactory().get('/')\n        exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIsInstance(data, dict)\n        self.assertIn('is_email', data)\n        self.assertIn('unicode_hint', data)\n        # Add more assertions based on the expected data structure\n"], "sample_507": ["def test_update(self, data, locs):\n    unit_data = cat.UnitData()\n    unit_data.update(data)\n    assert list(unit_data._mapping.values()) == locs\n"], "sample_62": ["    def test_register_model(self):\n        self.site.register(Location, NameAdmin)\n        self.assertTrue(self.site.is_registered(Location))\n        self.assertIsInstance(self.site._registry[Location], NameAdmin)\n"], "sample_79": ["def test_pluralize_with_custom_suffix(self):\n    self.engine.filters['pluralize'] = pluralize\n    tests = [\n        (0, 'classes'),\n        (1, 'class'),\n        (2, 'classes'),\n    ]\n    self.check_values(*tests)\n"], "sample_301": ["    def test_zip_imported_module(self):\n        zip_filename = self.temporary_file('test_module.zip')\n        with zipfile.ZipFile(zip_filename, 'w') as zf:\n            zf.writestr('test_module.py', 'print(\"Hello, World!\")')\n        sys.path.insert(0, str(zip_filename))\n        self.addCleanup(sys.path.remove, str(zip_filename))\n        self.import_and_cleanup('test_module')\n        self.assertFileFound(zip_filename)\n"], "sample_193": ["    def test_check_table_uniqueness(self):\n        apps = Apps()\n        apps.models_ready = True\n\n        class Author(models.Model):\n            name = models.CharField(max_length=100)\n\n        class Book(models.Model):\n            title = models.CharField(max_length=100)\n            authors = models.ManyToManyField(Author, related_name='books')\n\n        field = Book._meta.get_field('authors')\n        errors = field._check_table_uniqueness()\n        self.assertEqual(len(errors), 0)\n\n        # Create a model with the same db_table as the m2m table\n        class ClashingModel(models.Model):\n            class Meta:\n                db_table = field.m2m_db_table()\n\n        errors = field._check_table_uniqueness()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'fields.E340')\n"], "sample_238": ["    def test_aggregate_functions(self):\n        # Test Abs function\n        self.assertEqual(Book.objects.aggregate(abs_pages=Abs('pages'))['abs_pages'], 1132)\n\n        # Test ACos function\n        self.assertAlmostEqual(Book.objects.aggregate(acos_rating=ACos('rating'))['acos_rating'], 0.0, places=5)\n\n        # Test ASin function\n        self.assertAlmostEqual(Book.objects.aggregate(asin_rating=ASin('rating'))['asin_rating'], 0.0, places=5)\n\n        # Test ATan function\n        self.assertAlmostEqual(Book.objects.aggregate(atan_rating=ATan('rating'))['atan_rating'], 0.0, places=5)\n\n        # Test ATan2 function\n        self.assertAlmostEqual(Book.objects.aggregate(atan2_pages_rating=ATan2('pages', 'rating'))['atan2_pages_rating'], 0.0, places=5)\n\n        # Test Ceil function\n        self.assertEqual(Book.objects.aggregate(ceil_price=Ceil('price'))['ceil_price'], 83)\n\n        # Test Cos function\n        self.assertAlmostEqual(Book.objects.aggregate(cos_rating=Cos('rating'))['cos_rating'], 1.0, places=5)\n\n        # Test Cot function\n        self.assertAlmostEqual(Book.objects.aggregate(cot_rating=Cot('rating'))['cot_rating'], 1.0, places=5)\n\n        # Test Degrees function\n        self.assertAlmostEqual(Book.objects.aggregate(degrees_rating=Degrees('rating'))['degrees_rating'], 0.0, places=5)\n\n        # Test Exp function\n        self.assertAlmostEqual(Book.objects.aggregate(exp_rating=Exp('rating'))['exp_rating'], 2.71828,"], "sample_182": ["def test_union_with_empty_queryset(self):\n    qs1 = Number.objects.filter(num__gt=5)\n    qs2 = Number.objects.none()\n    union_qs = qs1.union(qs2)\n    self.assertNumbersEqual(union_qs, [6, 7, 8, 9])\n"], "sample_743": ["def test_neighbors_base_with_callable_metric():\n    # Test NeighborsBase with a callable metric\n    X = iris.data\n    metric = lambda u, v: np.sqrt(np.sum((u - v) ** 2))\n    nbrs = neighbors.NeighborsBase(n_neighbors=3, algorithm='ball_tree', metric=metric)\n    nbrs.fit(X)\n    assert_equal(nbrs._fit_method, 'ball_tree')\n    assert_equal(nbrs.effective_metric_, metric)\n"], "sample_623": ["def test_to_netcdf_invalid_netcdf(engine):\n    ds = xr.Dataset({\"var\": (\"x\", np.arange(10))})\n    with pytest.raises(ValueError):\n        ds.to_netcdf(\"test.nc\", engine=engine, invalid_netcdf=True)\n"], "sample_956": ["def test_fetch_inventory_with_remote_uri(mock_read_from_url, mock_inventory_file, app):\n    uri = 'https://example.com'\n    inv = 'remote_inventory'\n    mock_read_from_url.return_value = mock.MagicMock()\n    mock_inventory_file.load.return_value = inventory_v2\n\n    invdata = fetch_inventory(app, uri, inv)\n\n    mock_read_from_url.assert_called_once_with(inv, config=app.config)\n    mock_inventory_file.load.assert_called_once_with(mock_read_from_url.return_value, uri, mock.ANY)\n    assert invdata == inventory_v2\n"], "sample_9": ["def test_custom_parser(parser):\n    data = \"<table><tr><th>col1</th><th>col2</th></tr><tr><td>1</td><td>2</td></tr></table>\"\n    t = Table.read(StringIO(data), format='html', htmldict={'parser': parser})\n    assert len(t) == 1\n    assert t['col1'][0] == 1\n    assert t['col2'][0] == 2\n"], "sample_591": ["def test_merge_with_overwrite_vars(self):\n    ds1 = xr.Dataset({'x': ('a', [1, 2, 3]), 'y': ('a', [4, 5, 6])})\n    ds2 = xr.Dataset({'x': ('a', [7, 8, 9]), 'z': ('a', [10, 11, 12])})\n    merged = xr.merge([ds1, ds2], overwrite_vars=['x'])\n    expected = xr.Dataset({'x': ('a', [7, 8, 9]), 'y': ('a', [4, 5, 6]), 'z': ('a', [10, 11, 12])})\n    assert_identical(merged, expected)\n"], "sample_582": ["def test_locate_app_with_invalid_app_name(runner):\n    module_name = \"flask.cli.test_apps.invalid_app_name\"\n    app_name = \"invalid_app\"\n    with pytest.raises(NoAppException) as exc_info:\n        locate_app(module_name, app_name)\n    assert str(exc_info.value) == f\"Failed to find attribute 'invalid_app' in '{module_name}'.\"\n"], "sample_794": ["def test_ridge_regression_solver_sparse_cg_with_intercept(solver):\n    X, y = make_regression(n_samples=100, n_features=5, noise=0.1, random_state=0)\n    X = sp.csr_matrix(X)\n    alpha = 1.0\n    coef, intercept = ridge_regression(X, y, alpha, solver=solver, return_intercept=True)\n    assert_equal(coef.shape, (5,))\n    assert_equal(np.isscalar(intercept), True)\n"], "sample_829": ["def test_incremental_pca_with_sparse_input():\n    X_sparse = sparse.csr_matrix(iris.data)\n    ipca = IncrementalPCA(n_components=2, batch_size=50)\n    X_transformed = ipca.fit_transform(X_sparse)\n    assert X_transformed.shape == (150, 2)\n"], "sample_514": ["def test_colorbar_extension_length():\n    fig_uniform = _colorbar_extension_length('uniform')\n    fig_proportional = _colorbar_extension_length('proportional')\n    return fig_uniform, fig_proportional\n"], "sample_383": ["    def test_related_in_lookup(self):\n        items = Item.objects.filter(creator__in=[self.a1, self.a2])\n        self.assertCountEqual(items, [self.i1, self.i2, self.i3])\n"], "sample_961": ["def test_parse_annotation(app):\n    env = app.builder.env\n    result = _parse_annotation(\"List[int]\", env)\n    assert len(result) == 3\n    assert isinstance(result[0], nodes.Text) and result[0].astext() == \"List\"\n    assert isinstance(result[1], nodes.Text) and result[1].astext() == \"[\"\n    assert isinstance(result[2], pending_xref) and result[2]['reftarget'] == \"int\"\n"], "sample_332": ["def test_formset_factory_with_custom_kwargs(self):\n    CustomKwargFormSet = formset_factory(CustomKwargForm, form_kwargs={'custom_kwarg': 'test'})\n    formset = CustomKwargFormSet()\n    for form in formset:\n        self.assertEqual(form.custom_kwarg, 'test')\n"], "sample_265": ["def test_get_templatetag_libraries(self):\n    custom_libraries = {'custom_lib': 'path.to.custom_lib'}\n    expected_libraries = {'custom_lib': 'path.to.custom_lib'}\n    expected_libraries.update(get_installed_libraries())\n\n    engine = self.engine_class({'OPTIONS': {'libraries': custom_libraries}})\n    libraries = engine.get_templatetag_libraries(custom_libraries)\n\n    self.assertEqual(libraries, expected_libraries)\n"], "sample_6": ["def test_angle_wrap_at():\n    a = Angle([-20.0, 150.0, 350.0] * u.deg)\n    wrapped = a.wrap_at(360 * u.deg)\n    assert_allclose(wrapped, Angle([340.0, 150.0, 350.0] * u.deg))\n\n    a.wrap_at(180 * u.deg, inplace=True)\n    assert_allclose(a, Angle([-20.0, 150.0, -10.0] * u.deg))\n"], "sample_269": ["    def test_get_javascript_catalog(self):\n        \"\"\"Test getting the JavaScript catalog for a supported language.\"\"\"\n        url = reverse('jsi18n')\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response['Content-Type'], 'text/javascript; charset=\"utf-8\"')\n        self.assertContains(response, 'django.catalog')\n"], "sample_38": ["def test_maps_wcs(self):\n    for filename in self._file_list:\n        with fits.open(filename) as hdulist:\n            header = hdulist[0].header\n            w = wcs.WCS(header)\n            assert w.naxis == 2\n            assert w.wcs.naxis == 2\n            assert w.wcs.lng == 0\n            assert w.wcs.lat == 1\n            assert w.wcs.lngtyp == 'RA'\n            assert w.wcs.lattyp == 'DEC'\n            assert w.wcs.cunit[0] == 'deg'\n            assert w.wcs.cunit[1] == 'deg'\n            assert w.wcs.ctype[0] == 'RA---TAN'\n            assert w.wcs.ctype[1] == 'DEC--TAN'\n            assert w.wcs.crval[0] == header['CRVAL1']\n            assert w.wcs.crval[1] == header['CRVAL2']\n            assert w.wcs.crpix[0] == header['CRPIX1']\n            assert w.wcs.crpix[1] == header['CRPIX2']\n            assert w.wcs.cdelt[0] == header['CDELT1']\n            assert w.wcs.cdelt[1] == header['CDELT2']\n            assert w.wcs.lonpole == header['LONPOLE']\n            assert w.wcs.latpole == header['LATPOLE']\n            assert w.wcs.radesys == header['RADESYS']\n            assert w.wcs.equinox == header['EQUINOX']\n            assert w.wcs.epoch == header['EPOCH']\n"], "sample_1172": ["def test_solve_poly_system_with_symbols():\n    x, y = symbols('x y')\n    eq1 = x*y - 2*y\n    eq2 = 2*y**2 - x**2\n    solution = solve_poly_system([eq1, eq2], x, y)\n    assert solution == [(0, 0), (2, -sqrt(2)), (2, sqrt(2))]\n"], "sample_118": ["    def test_year_lookup(self):\n        # Test YearExact lookup\n        self.assertSequenceEqual(\n            Article.objects.filter(pub_date__year_exact=2005),\n            [self.a1, self.a2, self.a3, self.a4, self.a5, self.a6, self.a7]\n        )\n        # Test YearGt lookup\n        self.assertSequenceEqual(\n            Article.objects.filter(pub_date__year_gt=2005),\n            []\n        )\n        # Test YearGte lookup\n        self.assertSequenceEqual(\n            Article.objects.filter(pub_date__year_gte=2005),\n            [self.a1, self.a2, self.a3, self.a4, self.a5, self.a6, self.a7]\n        )\n        # Test YearLt lookup\n        self.assertSequenceEqual(\n            Article.objects.filter(pub_date__year_lt=2005),\n            []\n        )\n        # Test YearLte lookup\n        self.assertSequenceEqual(\n            Article.objects.filter(pub_date__year_lte=2005),\n            [self.a1, self.a2, self.a3, self.a4, self.a5, self.a6, self.a7]\n        )\n"], "sample_549": ["def test_delete_masked_points_with_mixed_types(self):\n    x = np.array([1, 2, 3, 4, 5])\n    y = [10, 20, 30, 40, 50]\n    z = np.array([100, 200, 300, 400, 500])\n    w = \"abcde\"\n\n    x_new, y_new, z_new, w_new = delete_masked_points(x, y, z, w)\n\n    assert_array_equal(x_new, x)\n    assert_array_equal(y_new, y)\n    assert_array_equal(z_new, z)\n    assert w_new == w\n"], "sample_107": ["    def test_get_traceback_data(self):\n        request = RequestFactory().get('/')\n        exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIsInstance(data, dict)\n        self.assertIn('is_email', data)\n        self.assertIn('unicode_hint', data)\n        # Add more assertions based on the expected data structure\n"], "sample_776": ["def test_lars_path_residues():\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    alphas, active, coefs, residues = _lars_path_residues(X_train, y_train, X_test, y_test)\n    assert_greater(len(alphas), 0)\n    assert_greater(len(active), 0)\n    assert_greater(coefs.shape[0], 0)\n    assert_greater(coefs.shape[1], 0)\n    assert_greater(residues.shape[0], 0)\n    assert_greater(residues.shape[1], 0)\n"], "sample_485": ["def test_escapejs(self):\n    self.check_output(escapejs, \"test\", \"test\")\n    self.check_output(escapejs, \"test's\", \"test\\\\u0027s\")\n    self.check_output(escapejs, \"test\\\"s\", \"test\\\\u0022s\")\n    self.check_output(escapejs, \"test>s\", \"test\\\\u003Es\")\n    self.check_output(escapejs, \"test<s\", \"test\\\\u003Cs\")\n    self.check_output(escapejs, \"test&s\", \"test\\\\u0026s\")\n    self.check_output(escapejs, \"test=s\", \"test\\\\u003Ds\")\n    self.check_output(escapejs, \"test-s\", \"test\\\\u002Ds\")\n    self.check_output(escapejs, \"test;s\", \"test\\\\u003Bs\")\n    self.check_output(escapejs, \"test`s\", \"test\\\\u0060s\")\n    self.check_output(escapejs, \"test\\u2028s\", \"test\\\\u2028s\")\n    self.check_output(escapejs, \"test\\u2029s\", \"test\\\\u2029s\")\n    self.check_output(escapejs, \"\\x00\", \"\\\\u0000\")\n"], "sample_1022": ["def test_function_exponentiation():\n    transformations = standard_transformations + (function_exponentiation,)\n    expr = parse_expr('sin**4(x)', transformations=transformations)\n    assert expr == sympy.sin(sympy.Symbol('x'))**4\n"], "sample_20": ["def test_write_read_table_fits(self, tmp_path):\n    # Write a table to a FITS file\n    table = Table(self.data)\n    filename = str(tmp_path / \"test.fits\")\n    table.write(filename, format=\"fits\")\n\n    # Read the table back from the FITS file\n    read_table = Table.read(filename, format=\"fits\")\n\n    # Check that the data is the same\n    assert_array_equal(table[\"a\"], read_table[\"a\"])\n    assert_array_equal(table[\"b\"], read_table[\"b\"])\n    assert_allclose(table[\"c\"], read_table[\"c\"])\n"], "sample_245": ["    def test_no_location_option(self):\n        output, po_contents = self._run_makemessages(no_location=True)\n        self.assertNotIn('#:', po_contents)\n"], "sample_50": ["def test_runshell_db_with_all_parameters(self):\n    dbinfo = {\n        'host': 'localhost',\n        'port': 5432,\n        'database': 'testdb',\n        'user': 'testuser',\n        'password': 'testpassword'\n    }\n    expected_args = ['psql', '-U', 'testuser', '-h', 'localhost', '-p', '5432', 'testdb']\n    expected_pgpassword = 'testpassword'\n\n    args, pgpassword = self._run_it(dbinfo)\n\n    self.assertEqual(args, expected_args)\n    self.assertEqual(pgpassword, expected_pgpassword)\n"], "sample_162": ["    def test_no_location_option(self):\n        self.create_files({\n            'django.po': '',\n            'dirA/dirB/foo.py': \"msgid = 'test message'\",\n        })\n        output, po_contents = self._run_makemessages(no_location=True)\n        self.assertLocationCommentNotPresent(self.PO_FILE, 'test message', 'dirA', 'dirB', 'foo.py')\n"], "sample_1147": ["def test_latex_printing_of_ArraySymbol():\n    A = ArraySymbol('A', (3, 3))\n    assert latex(A) == 'A'\n"], "sample_734": ["def test_fowlkes_mallows_score():\n    labels_true = np.array([0, 0, 1, 1])\n    labels_pred = np.array([0, 0, 1, 1])\n    assert_almost_equal(fowlkes_mallows_score(labels_true, labels_pred), 1.0)\n\n    labels_true = np.array([0, 0, 1, 1])\n    labels_pred = np.array([1, 1, 0, 0])\n    assert_almost_equal(fowlkes_mallows_score(labels_true, labels_pred), 1.0)\n\n    labels_true = np.array([0, 0, 0, 0])\n    labels_pred = np.array([0, 1, 2, 3])\n    assert_almost_equal(fowlkes_mallows_score(labels_true, labels_pred), 0.0)\n"], "sample_172": ["def test_formfield_for_foreignkey_with_autocomplete(self):\n    \"\"\"\n    Test that formfield_for_dbfield returns an AutocompleteSelect widget for\n    ForeignKey fields when the field is in the autocomplete_fields list.\n    \"\"\"\n    self.assertFormfield(Car, 'owner', widgets.AutocompleteSelect, autocomplete_fields=('owner',))\n"], "sample_767": ["def test_column_transformer_with_callable_column_specifier():\n    ct = ColumnTransformer(\n        [(\"trans\", Trans(), lambda X: [0, 1])],\n        remainder='drop'\n    )\n    X = np.array([[0., 1., 2., 2.],\n                  [1., 1., 0., 1.]])\n    X_transformed = ct.fit_transform(X)\n    assert_array_equal(X_transformed, np.array([[0., 1.], [1., 1.]]))\n"], "sample_1044": ["def test_pow_as_content_primitive():\n    x = Symbol('x')\n    eq = (2 + 2*x)**y\n    c, p = eq.as_content_primitive()\n    assert c == 1\n    assert p == (2*(x + 1))**y\n"], "sample_620": ["def test_concat_dataarray_with_dim_as_coord():\n    da1 = DataArray(np.arange(6).reshape(2, 3), dims=(\"x\", \"y\"), coords={\"x\": [\"a\", \"b\"]})\n    da2 = DataArray(np.arange(6, 12).reshape(2, 3), dims=(\"x\", \"y\"), coords={\"x\": [\"c\", \"d\"]})\n    result = concat([da1, da2], dim=\"x\")\n    expected = DataArray(np.arange(12).reshape(4, 3), dims=(\"x\", \"y\"), coords={\"x\": [\"a\", \"b\", \"c\", \"d\"]})\n    assert_identical(result, expected)\n"], "sample_785": ["def test_build_repr():\n    # Test _build_repr function\n    clf = MockClassifier(a=1, allow_nd=True)\n    repr_str = _build_repr(clf)\n    assert repr_str == \"MockClassifier(a=1, allow_nd=True)\"\n"], "sample_213": ["    def test_image_field_update_dimension_fields(self):\n        # Create an instance of ImageField\n        image_field = ImageField(width_field='width', height_field='height')\n\n        # Create a mock instance with an image file\n        class MockInstance:\n            image = ImageFieldFile(None, image_field, 'test.jpg')\n            width = None\n            height = None\n\n        instance = MockInstance()\n\n        # Call update_dimension_fields method\n        image_field.update_dimension_fields(instance, force=True)\n\n        # Check if width and height fields are updated\n        self.assertIsNotNone(instance.width)\n        self.assertIsNotNone(instance.height)\n"], "sample_345": ["    def test_import_error_file(self):\n        filename = self.temporary_file('error_module.py')\n        filename.write_text('syntax error')\n        with self.assertRaises(SyntaxError):\n            self.import_and_cleanup('error_module')\n        self.assertFileFound(filename)\n        self.assertIn(filename, autoreload._error_files)\n        autoreload._error_files.clear()\n"], "sample_219": ["def test_expression_wrapper(self):\n    expr = ExpressionWrapper(F('num_employees'), output_field=IntegerField())\n    query = self.company_query.annotate(wrapped_employees=expr)\n    self.assertEqual(\n        str(query.query),\n        'SELECT \"tests_company\".\"name\", \"tests_company\".\"num_employees\", \"tests_company\".\"num_chairs\", '\n        '\"tests_company\".\"num_employees\" AS \"wrapped_employees\" FROM \"tests_company\" ORDER BY \"tests_company\".\"name\" ASC, '\n        '\"tests_company\".\"num_employees\" ASC, \"tests_company\".\"num_chairs\" ASC'\n    )\n"], "sample_1185": ["def test_compogen_decompogen_consistency():\n    f = sin(sqrt(cos(x**2 + 1)))\n    g_s = decompogen(f, x)\n    f_reconstructed = compogen(g_s, x)\n    assert f == f_reconstructed\n"], "sample_1189": ["def test_lambdify_with_tensorflow_eager_execution():\n    import tensorflow as tf\n    tf.compat.v1.enable_eager_execution()\n\n    f = Max(x, sin(x))\n    func = lambdify(x, f, 'tensorflow')\n\n    result = func(tf.constant(1.0))\n    assert result.numpy() == 1.0\n\n    var = tf.Variable(2.0)\n    result = func(var)\n    assert result.numpy() == 2.0\n\n    tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n    result = func(tensor)\n    assert (result.numpy() == [[1.0, 2.0], [3.0, 4.0]]).all()\n"], "sample_379": ["    def test_mark_safe_with_custom_safe_data(self):\n        custom_safe_data = customescape(\"<b>Test</b>\")\n        safe_string = mark_safe(custom_safe_data)\n        self.assertIsInstance(safe_string, SafeString)\n        self.assertEqual(safe_string, \"<<b>>Test<</b>>\")\n"], "sample_167": ["    def test_intword_large_numbers(self):\n        self.assertEqual(humanize.intword(1000000), '1.0 million')\n        self.assertEqual(humanize.intword(1200000), '1.2 million')\n        self.assertEqual(humanize.intword(1200000000), '1.2 billion')\n        self.assertEqual(humanize.intword(1200000000000), '1.2 trillion')\n        self.assertEqual(humanize.intword(1200000000000000), '1.2 quadrillion')\n        self.assertEqual(humanize.intword(1200000000000000000), '1.2 quintillion')\n        self.assertEqual(humanize.intword(1200000000000000000000), '1.2 sextillion')\n        self.assertEqual(humanize.intword(1200000000000000000000000), '1.2 septillion')\n        self.assertEqual(humanize.intword(1200000000000000000000000000), '1.2 octillion')\n        self.assertEqual(humanize.intword(1200000000000000000000000000000), '1.2 nonillion')\n        self.assertEqual(humanize.intword(1200000000000000000000000000000000), '1.2 decillion')\n        self.assertEqual(humanize.intword(1200000000000000000000000000000000000), '1.2 googol')\n"], "sample_421": ["def test_case_expression_with_when_then(self):\n    queryset = CaseTestModel.objects.annotate(\n        case_expression=Case(\n            When(integer=1, then=Value('one')),\n            When(integer=2, then=Value('two')),\n            default=Value('other'),\n            output_field=TextField(),\n        )\n    )\n    results = queryset.values('integer', 'case_expression')\n    expected_results = [\n        {'integer': 1, 'case_expression': 'one'},\n        {'integer': 2, 'case_expression': 'two'},\n        {'integer': 2, 'case_expression': 'two'},\n        {'integer': 3, 'case_expression': 'other'},\n        {'integer': 3, 'case_expression': 'other'},\n        {'integer': 3, 'case_expression': 'other'},\n        {'integer': 2, 'case_expression': 'two'},\n        {'integer': 3, 'case_expression': 'other'},\n        {'integer': 3, 'case_expression': 'other'},\n        {'integer': 4, 'case_expression': 'other'},\n    ]\n    self.assertEqual(list(results), expected_results)\n"], "sample_849": ["def test_validate_shuffle_split():\n    # Test with valid inputs\n    n_samples = 100\n    test_size = 0.2\n    train_size = 0.8\n    n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size)\n    assert n_train == 80\n    assert n_test == 20\n\n    # Test with invalid test_size\n    test_size = 1.2\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size, train_size)\n\n    # Test with invalid train_size\n    train_size = 1.2\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size, train_size)\n\n    # Test with invalid test_size and train_size\n    test_size = 0.9\n    train_size = 0.9\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size, train_size)\n\n    # Test with invalid test_size type\n    test_size = \"invalid\"\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size, train_size)\n\n    # Test with invalid train_size type\n    train_size = \"invalid\"\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size, train_size)\n"], "sample_12": ["def test_angle_wrap_at():\n    a = Angle([-20.0, 150.0, 350.0] * u.deg)\n    wrapped = a.wrap_at(360 * u.deg)\n    assert_allclose(wrapped.degree, [340.0, 150.0, 350.0])\n\n    a.wrap_at('180d', inplace=True)\n    assert_allclose(a.degree, [-20.0, 150.0, -10.0])\n"], "sample_523": ["def test_legend_set_draggable():\n    fig, ax = plt.subplots()\n    line, = ax.plot([1, 2, 3], [1, 2, 3], label='Test line')\n    legend = ax.legend()\n\n    # Test enabling draggable\n    draggable = legend.set_draggable(state=True)\n    assert isinstance(draggable, mlegend.DraggableLegend)\n    assert legend.get_draggable() is True\n\n    # Test disabling draggable\n    legend.set_draggable(state=False)\n    assert legend.get_draggable() is False\n"], "sample_68": ["    def test_get_traceback_data(self):\n        request = RequestFactory().get('/')\n        exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIsInstance(data, dict)\n        self.assertIn('is_email', data)\n        self.assertIn('unicode_hint', data)\n        # Add more assertions based on the expected data structure\n"], "sample_90": ["    def test_construct_instance_with_file_field(self):\n        form_data = {'file_field': SimpleUploadedFile(\"test.txt\", b\"file_content\")}\n        form = TextFileForm(data=form_data, files=form_data)\n        self.assertTrue(form.is_valid())\n        instance = construct_instance(form, TextFile())\n        self.assertEqual(instance.file_field.read(), b\"file_content\")\n"], "sample_381": ["def test_generate_altered_db_table(self):\n    changes = self.get_changes(\n        [self.author_with_db_table_options],\n        [self.author_with_new_db_table_options],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelTable\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Author\", table=\"author_two\")\n"], "sample_373": ["def test_get_return_data_type(self):\n    self.assertEqual(get_return_data_type('get_list'), 'List')\n    self.assertEqual(get_return_data_type('get_count'), 'Integer')\n    self.assertEqual(get_return_data_type('get_item'), '')\n"], "sample_261": ["    def test_parse_datetime_with_timezone(self):\n        value = '2022-01-01T12:34:56+03:00'\n        expected = datetime(2022, 1, 1, 12, 34, 56, tzinfo=get_fixed_timezone(180))\n        self.assertEqual(parse_datetime(value), expected)\n"], "sample_306": ["    def test_parse_datetime_with_timezone(self):\n        dt = parse_datetime('2022-01-01T12:34:56+02:00')\n        self.assertEqual(dt, datetime(2022, 1, 1, 12, 34, 56, tzinfo=get_fixed_timezone(120)))\n\n        dt = parse_datetime('2022-01-01T12:34:56-03:30')\n        self.assertEqual(dt, datetime(2022, 1, 1, 12, 34, 56, tzinfo=get_fixed_timezone(-210)))\n\n        dt = parse_datetime('2022-01-01T12:34:56Z')\n        self.assertEqual(dt, datetime(2022, 1, 1, 12, 34, 56, tzinfo=utc))\n"], "sample_1103": ["def test_pow_as_content_primitive():\n    assert (2**((1 + y)/2)).as_content_primitive() == (sqrt(2), 2**(y/2))\n"], "sample_411": ["def test_command_error_handling(self):\n    class ErrorCommand(BaseCommand):\n            raise CommandError(\"Test error message\")\n\n    with self.assertRaises(SystemExit) as cm:\n        management.call_command(\"error\")\n    self.assertEqual(cm.exception.code, 1)\n\n    with self.assertRaises(CommandError) as cm:\n        management.call_command(\"error\", traceback=True)\n    self.assertEqual(str(cm.exception), \"Test error message\")\n"], "sample_1168": ["def test_is_palindromic():\n    assert is_palindromic([1, 0, 1])\n    assert not is_palindromic('abcbb')\n    assert not is_palindromic('abcbb', 1)\n    assert is_palindromic('abcbb', 1, -1)\n    assert is_palindromic('abcbb', -4, -1)\n"], "sample_809": ["def test_sparse_matrix_with_continuous_features():\n    X = csr_matrix([[1, 0], [0, 1], [1, 1]])\n    y = np.array([0, 1, 2])\n    with assert_raises(ValueError):\n        mutual_info_regression(X, y)\n"], "sample_42": ["def test_with_H0_equivalency():\n    # Test with_H0 equivalency with a custom H0 value\n    custom_H0 = 70 * u.km / u.s / u.Mpc\n    equiv = u.with_H0(custom_H0)\n    q = 1 * u.Mpc / u.littleh\n    assert_quantity_allclose(q.to(u.Mpc, equivalencies=equiv), 1 * u.Mpc / (70 / 100))\n\n    # Test with_H0 equivalency with the default H0 value\n    equiv = u.with_H0()\n    q = 1 * u.Mpc / u.littleh\n    assert_quantity_allclose(q.to(u.Mpc, equivalencies=equiv), 1 * u.Mpc / cosmology.default_cosmology.get().H0.value * (u.km / u.s / u.Mpc))\n"], "sample_210": ["    def test_get_redirect_url(self):\n        request = self.client.get('/redirect/')\n        view = RedirectView.as_view(url='/new-url/')\n        response = view(request)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response.url, '/new-url/')\n"], "sample_800": ["    def test_outlier_corruption(self):\n        num_outliers = 35\n        expected_outliers = 30\n        decision = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\n        with self.assertRaises(AssertionError):\n            check_outlier_corruption(num_outliers, expected_outliers, decision)\n"], "sample_652": ["def test_idmaker():\n    argnames = [\"arg1\", \"arg2\"]\n    parametersets = [\n        fixtures.ParameterSet([\"val1\", \"val2\"], marks=[]),\n        fixtures.ParameterSet([\"val3\", \"val4\"], marks=[]),\n    ]\n    ids = idmaker(argnames, parametersets)\n    assert ids == [\"val1-val2\", \"val3-val4\"]\n"], "sample_862": ["def test_tfidf_vectorizer_with_custom_analyzer():\n    vectorizer = TfidfVectorizer(analyzer=lazy_analyze)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n    assert X.shape == (11, 1)\n    assert_array_almost_equal(X.toarray(), np.ones((11, 1)))\n"], "sample_729": ["def test_elastic_net_cv_with_multi_task_output():\n    X, y = load_boston(return_X_y=True)\n    y = np.column_stack((y, y))  # Create multi-task output\n    enet_cv = ElasticNetCV(cv=5, random_state=0)\n    with pytest.raises(ValueError, match=\"For multi-task outputs, use MultiTaskElasticNetCV\"):\n        enet_cv.fit(X, y)\n"], "sample_516": ["def test_pdf_custom_font():\n    fig, ax = plt.subplots()\n    font_path = findfont(FontProperties(family='serif'))\n    font = FT2Font(font_path)\n    text = ax.text(0.5, 0.5, 'Hello, World!', fontsize=20, font=font)\n    plt.savefig('pdf_custom_font.pdf')\n"], "sample_287": ["    def test_check_autocomplete_fields(self):\n        class InvalidAutocompleteFields(admin.ModelAdmin):\n            autocomplete_fields = 'title'\n\n        class InvalidAutocompleteFieldsItem(admin.ModelAdmin):\n            autocomplete_fields = ['invalid_field']\n\n        class ValidAutocompleteFieldsItem(admin.ModelAdmin):\n            autocomplete_fields = ['author']\n\n        class NoRelatedAdmin(admin.ModelAdmin):\n            autocomplete_fields = ['city']\n\n        class NoSearchFields(admin.ModelAdmin):\n            autocomplete_fields = ['state']\n\n        site = AdminSite()\n        site.register(Song, ValidAutocompleteFieldsItem)\n\n        self.assertEqual(\n            ModelAdminChecks(site)._check_autocomplete_fields(InvalidAutocompleteFields()),\n            must_be('a list or tuple', option='autocomplete_fields', obj=InvalidAutocompleteFields(), id='admin.E036')\n        )\n        self.assertEqual(\n            ModelAdminChecks(site)._check_autocomplete_fields_item(InvalidAutocompleteFieldsItem(), 'invalid_field', 'autocomplete_fields[0]'),\n            refer_to_missing_field(field='invalid_field', option='autocomplete_fields[0]', obj=InvalidAutocompleteFieldsItem(), id='admin.E037')\n        )\n        self.assertEqual(\n            ModelAdminChecks(site)._check_autocomplete_fields_item(NoRelatedAdmin(), 'city', 'autocomplete_fields[0]'),\n            [checks.Error(\n                'An admin for model \"City\" has to be registered to be referenced by InvalidAutocompleteFieldsItem.autocomplete_fields.',\n                obj=InvalidAutocompleteFieldsItem.__class__,\n                id='admin.E039',\n            )]\n        )\n        self.assertEqual(\n            ModelAdminChecks(site)._check_autocomplete_fields_item(NoSearchFields(), 'state', 'autocomplete_fields[0]'),\n"], "sample_880": ["def test_ovr_decision_function():\n    predictions = np.array([[0, 1, 0], [1, 0, 1]])\n    confidences = np.array([[0.8, 0.6, 0.7], [0.9, 0.5, 0.6]])\n    n_classes = 3\n    expected_output = np.array([[0.16666667, 0.53333333, -0.03333333],\n                               [0.03333333, -0.16666667, 0.53333333]])\n    assert_array_almost_equal(_ovr_decision_function(predictions, confidences, n_classes), expected_output)\n"], "sample_71": ["    def test_format_with_large_decimal(self):\n        number = Decimal('1' + '0' * 201)\n        result = nformat(number, decimal_sep='.', decimal_pos=None, grouping=0, thousand_sep='', force_grouping=False, use_l10n=None)\n        self.assertEqual(result, '1e201')\n"], "sample_562": ["def test_line2d_set_markevery():\n    fig, ax = plt.subplots()\n    x = np.linspace(0, 10, 100)\n    y = np.sin(x)\n    line, = ax.plot(x, y, marker='o', markevery=10)\n    assert len(line.get_markevery()) == 10\n    line.set_markevery(5)\n    assert len(line.get_markevery()) == 5\n"], "sample_180": ["    def test_unique_together_with_invalid_field(self):\n        class InvalidUniqueTogetherModel(models.Model):\n            field1 = models.CharField(max_length=10)\n            field2 = models.CharField(max_length=10)\n\n            class Meta:\n                unique_together = (('field1', 'invalid_field'),)\n\n        errors = InvalidUniqueTogetherModel.check()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'models.E012')\n        self.assertEqual(\n            str(errors[0]),\n            \"'unique_together' refers to the nonexistent field 'invalid_field'.\"\n        )\n"], "sample_1209": ["def test_prefix_multiplication():\n    assert kilo * meter == 1000 * meter\n    assert kilo * kibi == 1024 * kibi\n    assert kilo / kibi == 1000 / 1024\n    assert kibi / kilo == 1024 / 1000\n"], "sample_1130": ["def test_point_a1pt_theory():\n    q = dynamicsymbols('q')\n    qd = dynamicsymbols('q', 1)\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    B.set_ang_vel(N, 5 * B.y)\n    O = Point('O')\n    P = O.locatenew('P', q * B.x)\n    P.set_vel(B, qd * B.x)\n    O.set_vel(N, 0)\n    assert P.a1pt_theory(O, N, B) == qd.diff(N) * B.x - 25 * q * B.z\n"], "sample_494": ["    def test_serializer_factory_with_enum(self):\n        value = TextEnum.A\n        serializer = serializer_factory(value)\n        self.assertIsInstance(serializer, EnumSerializer)\n        serialized_value, imports = serializer.serialize()\n        self.assertEqual(serialized_value, \"test_module.TextEnum['A']\")\n        self.assertEqual(imports, {\"import test_module\"})\n"], "sample_116": ["    def test_make_template_fragment_key(self):\n        key = make_template_fragment_key('fragment_name')\n        self.assertEqual(key, 'template.cache.fragment_name.d41d8cd98f00b204e9800998ecf8427e')\n\n        key = make_template_fragment_key('fragment_name', vary_on=['arg1', 'arg2'])\n        self.assertEqual(key, 'template.cache.fragment_name.3858f62230ac3c915f300c664312c63f')\n"], "sample_295": ["def test_expression_wrapper_get_group_by_cols(self):\n    expr = ExpressionWrapper(F('num_employees'), output_field=IntegerField())\n    group_by_cols = expr.get_group_by_cols()\n    self.assertEqual(len(group_by_cols), 1)\n    self.assertIsInstance(group_by_cols[0], Col)\n    self.assertEqual(group_by_cols[0].target.name, 'num_employees')\n"], "sample_76": ["    def test_check_setting_language_code(self):\n        \"\"\"Test check_setting_language_code function.\"\"\"\n        with self.settings(LANGUAGE_CODE=self.valid_tags[0]):\n            self.assertEqual(check_setting_language_code(None), [])\n        with self.settings(LANGUAGE_CODE=self.invalid_tags[0]):\n            self.assertEqual(check_setting_language_code(None), [Error('You have provided an invalid value for the LANGUAGE_CODE setting: None.', id='translation.E001')])\n"], "sample_48": ["def test_aggregate_filter(self):\n    # Test the filter argument of Aggregate\n    books_after_2000 = Book.objects.filter(pubdate__year__gt=2000)\n    avg_rating_after_2000 = books_after_2000.aggregate(Avg('rating', filter=Q(price__gt=Decimal('30.00'))))\n    self.assertEqual(avg_rating_after_2000['rating__avg'], 4.0)\n"], "sample_333": ["def test_form_initialization(self):\n    data = {'first_name': 'John', 'last_name': 'Doe', 'birthday': '1990-01-01'}\n    form = Person(data=data)\n    self.assertTrue(form.is_bound)\n    self.assertEqual(form.data, data)\n    self.assertEqual(form.initial, {})\n    self.assertEqual(form.error_class, ErrorList)\n    self.assertEqual(form.label_suffix, ':')\n    self.assertFalse(form.empty_permitted)\n    self.assertIsNone(form._errors)\n    self.assertEqual(len(form.fields), 3)\n    self.assertIsInstance(form.fields['first_name'], CharField)\n    self.assertIsInstance(form.fields['last_name'], CharField)\n    self.assertIsInstance(form.fields['birthday'], DateField)\n"], "sample_577": ["def test_plot_with_no_layers(tips):\n    p = Plot(tips)\n    assert len(p._layers) == 0\n"], "sample_565": ["def test_inset_position():\n    fig, ax = plt.subplots()\n    ip = InsetPosition(ax, [0.5, 0.1, 0.4, 0.2])\n    ax_ins = plt.axes([0, 0, 1, 1])\n    ax_ins.set_axes_locator(ip)\n    bbox = ax_ins.get_position(original=False)\n    assert_array_almost_equal(bbox.bounds, [0.5, 0.1, 0.4, 0.2])\n"], "sample_1083": ["def test_asech_diff():\n    x = symbols('x')\n    assert asech(x).diff(x) == -1/(x*sqrt(1 - x**2))\n    assert asech(1).diff(x) == 0\n"], "sample_662": ["def test_collect_report_serialization(self):\n    nodeid = \"test_node\"\n    outcome = \"passed\"\n    longrepr = None\n    result = []\n    sections = [(\"Captured stdout\", \"Test output\")]\n    collect_report = CollectReport(nodeid, outcome, longrepr, result, sections)\n\n    serialized_report = collect_report._to_json()\n    deserialized_report = CollectReport._from_json(serialized_report)\n\n    assert deserialized_report.nodeid == nodeid\n    assert deserialized_report.outcome == outcome\n    assert deserialized_report.longrepr == longrepr\n    assert deserialized_report.result == result\n    assert deserialized_report.sections == sections\n"], "sample_410": ["    def setUp(self):\n        self.user = get_user_model().objects.create_user(username='testuser', password='testpassword')\n"], "sample_290": ["def test_deconstructible_objects_with_same_structure_are_considered_equal(self):\n    changes = self.get_changes(\n        [self.author_name_deconstructible_1],\n        [self.author_name_deconstructible_2],\n    )\n    self.assertNumberMigrations(changes, 'testapp', 0)\n"], "sample_525": ["def test_figure_align_labels():\n    fig, axs = plt.subplots(2, 2)\n    for ax in axs.flat:\n        ax.label_outer()\n    fig.align_labels()\n"], "sample_157": ["    def test_serialize_db_to_string(self):\n        test_connection = get_connection_copy()\n        db_creation = BaseDatabaseCreation(test_connection)\n\n        # Create some test data\n        Object.objects.create(name='Test Object')\n        ObjectReference.objects.create(referenced_object=Object.objects.get(name='Test Object'))\n\n        # Serialize the database to a string\n        serialized_data = db_creation.serialize_db_to_string()\n\n        # Check that the serialized data is not empty\n        self.assertIsNotNone(serialized_data)\n\n        # Check that the serialized data contains the test data\n        self.assertIn('Test Object', serialized_data)\n        self.assertIn('ObjectReference', serialized_data)\n"], "sample_338": ["def test_generate_altered_db_table(self):\n    changes = self.get_changes(\n        [self.author_with_db_table_options],\n        [self.author_with_new_db_table_options],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelTable\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Author\", table=\"author_two\")\n"], "sample_497": ["def test_max_n_locator_basic(self, vmin, vmax, expected):\n    locator = mticker.MaxNLocator(nbins=5)\n    locator.set_view_interval(vmin, vmax)\n    assert_array_equal(locator(), expected)\n"], "sample_46": ["    def test_uuid_iexact_lookup(self):\n        obj = UUIDModel.objects.create(uuid_field=uuid.uuid4())\n        uuid_str = str(obj.uuid_field).replace('-', '')\n        retrieved_obj = UUIDModel.objects.get(uuid_field__iexact=uuid_str)\n        self.assertEqual(obj, retrieved_obj)\n"], "sample_977": ["def test_mathematica_code():\n    assert mcode(exp(x)) == \"Exp[x]\"\n    assert mcode(sin(x)) == \"Sin[x]\"\n    assert mcode(cos(x)) == \"Cos[x]\"\n    assert mcode(x**y) == \"x^y\"\n    assert mcode(pi) == \"Pi\"\n    assert mcode(oo) == \"Infinity\"\n    assert mcode(-oo) == \"-Infinity\"\n    assert mcode(Tuple(x, y, z)) == \"{x, y, z}\"\n    assert mcode(f(x, y)) == \"f[x, y]\"\n    assert mcode(Integral(f(x), x)) == \"Hold[Integrate[f[x], x]]\"\n    assert mcode(Sum(f(x), (x, 1, n))) == \"Hold[Sum[f[x], {x, 1, n}]]\"\n    assert mcode(Derivative(f(x), x)) == \"Hold[D[f[x], x]]\"\n"], "sample_463": ["def test_generate_altered_db_table(self):\n    changes = self.get_changes(\n        [self.author_with_db_table_options],\n        [self.author_with_new_db_table_options],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelTable\"])\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, name=\"Author\", table=\"author_two\"\n    )\n"], "sample_440": ["    def test_bulk_create_with_ignore_conflicts(self):\n        Country.objects.bulk_create(self.data, ignore_conflicts=True)\n        self.assertEqual(Country.objects.count(), 4)\n        Country.objects.bulk_create(self.data, ignore_conflicts=True)\n        self.assertEqual(Country.objects.count(), 4)\n"], "sample_177": ["    def test_model_state_from_model_with_custom_base(self):\n        model = ModelWithCustomBase()\n        model_state = ModelState.from_model(model)\n        self.assertEqual(model_state.bases, ('tests.ModelWithCustomBase',))\n"], "sample_853": ["def test_transformed_target_regressor_with_custom_transformer():\n    class CustomTransformer(TransformerMixin, BaseEstimator):\n            return self\n\n            return np.log1p(y)\n\n            return np.expm1(y)\n\n    X, y = friedman\n    reg = TransformedTargetRegressor(regressor=LinearRegression(), transformer=CustomTransformer())\n    reg.fit(X, y)\n    y_pred = reg.predict(X)\n    assert_allclose(y_pred, np.expm1(reg.regressor_.predict(X)))\n"], "sample_933": ["def test_gettext_builder_compile_catalogs(app, status, warning):\n    app.builder.compile_catalogs({'test'}, 'test message')\n    assert 'test message' in status.getvalue()\n"], "sample_424": ["    def test_create_model_with_duplicate_field_names(self):\n        operation = migrations.CreateModel(\n            name=\"DuplicateFieldModel\",\n            fields=[\n                (\"field1\", models.CharField(max_length=10)),\n                (\"field1\", models.IntegerField()),\n            ],\n        )\n        with self.assertRaisesMessage(\n            ValueError, \"Found duplicate value field1 in CreateModel fields argument.\"\n        ):\n            operation.deconstruct()\n"], "sample_326": ["def test_urlize(self):\n    self.check_output(urlize, 'http://example.com', '<a href=\"http://example.com\">http://example.com</a>')\n    self.check_output(urlize, 'www.example.com', '<a href=\"http://www.example.com\">www.example.com</a>')\n    self.check_output(urlize, 'example@example.com', '<a href=\"mailto:example@example.com\">example@example.com</a>')\n    self.check_output(urlize, 'Visit http://example.com for more info.', 'Visit <a href=\"http://example.com\">http://example.com</a> for more info.')\n    self.check_output(urlize, '(http://example.com)', '(<a href=\"http://example.com\">http://example.com</a>)')\n    self.check_output(urlize, 'http://example.com.', '<a href=\"http://example.com\">http://example.com</a>.')\n    self.check_output(urlize, 'http://example.com,', '<a href=\"http://example.com\">http://example.com</a>,')\n"], "sample_351": ["def test_model_choice_field_to_python(self):\n    field = forms.ModelChoiceField(queryset=Category.objects.all())\n    value = self.c1.pk\n    result = field.to_python(value)\n    self.assertEqual(result, self.c1)\n"], "sample_448": ["    def test_check_constraint_validation(self):\n        product = Product(name='Test', price=10)\n        product.full_clean()  # Should not raise any error\n\n        product = Product(name='Test', price=-10)\n        with self.assertRaises(ValidationError):\n            product.full_clean()  # Should raise ValidationError due to price < 0\n"], "sample_17": ["    def test_shape(self):\n        self.check(np.shape, self.q)\n"], "sample_760": ["def test_make_scorer_with_custom_score_func():\n        return np.mean(y_true == y_pred)\n\n    scorer = make_scorer(custom_score_func)\n    y_true = np.array([0, 1, 1, 0])\n    y_pred = np.array([0, 1, 0, 1])\n    score = scorer(None, None, y_true, y_pred)\n    assert_almost_equal(score, 0.5)\n"], "sample_657": ["def test_get_empty_parameterset_mark(self, attr, modulename):\n    config = mock.Mock()\n    config.getini.return_value = \"skip\"\n    argnames = [\"arg1\", \"arg2\"]\n    func = mock.Mock()\n    func.__name__ = \"test_func\"\n    func.__code__ = mock.Mock()\n    func.__code__.co_filename = \"test_file.py\"\n    func.__code__.co_firstlineno = 10\n    mark = get_empty_parameterset_mark(config, argnames, func)\n    assert mark.name == \"skip\"\n    assert mark.args == ()\n    assert mark.kwargs == {\"reason\": \"got empty parameter set ('arg1', 'arg2'), function test_func at test_file.py:10\"}\n"], "sample_346": ["def test_method_decorator(self):\n    class TestClass:\n        @method_decorator(login_required)\n            return HttpResponse()\n\n    # Check if the method is decorated with login_required\n    self.assertTrue(hasattr(TestClass.test_method, '__wrapped__'))\n    self.assertEqual(TestClass.test_method.__wrapped__.__name__, 'login_required')\n\n    # Check if the method can be called without a request\n    with self.assertRaises(TypeError):\n        TestClass().test_method()\n"], "sample_922": ["def test_parse_annotation():\n    annotation = \"List[Union[int, str]]\"\n    result = _parse_annotation(annotation)\n    assert len(result) == 5\n    assert isinstance(result[0], pending_xref)\n    assert result[0].astext() == \"List\"\n    assert isinstance(result[1], addnodes.desc_sig_punctuation)\n    assert result[1].astext() == \"[\"\n    assert isinstance(result[2], pending_xref)\n    assert result[2].astext() == \"Union\"\n    assert isinstance(result[3], addnodes.desc_sig_punctuation)\n    assert result[3].astext() == \"[\"\n    assert isinstance(result[4], nodes.Text)\n    assert result[4].astext() == \"int, str]\"\n"], "sample_314": ["    def test_password_field(self):\n        form = UserChangeForm(instance=self.u1)\n        self.assertIsInstance(form.fields['password'], ReadOnlyPasswordHashField)\n        self.assertIsInstance(form.fields['password'].widget, ReadOnlyPasswordHashWidget)\n        self.assertIn('../password/', form.fields['password'].help_text)\n"], "sample_656": ["def test_capture_manager_fixture_control(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            print(\"from my_fixture\")\n\n            print(\"from test_fixture_capture\")\n\n            print(\"from test_no_fixture_capture\")\n        \"\"\"\n    )\n\n    result = testdir.runpytest()\n\n    result.stdout.fnmatch_lines(\n        [\n            \"*from test_fixture_capture*\",\n            \"*from my_fixture*\",\n            \"*from test_no_fixture_capture*\",\n        ]\n    )\n\n    # Check that the output is not captured globally\n    assert \"from my_fixture\" not in result.stdout.str()\n    assert \"from test_no_fixture_capture\" not in result.stdout.str()\n"], "sample_453": ["def test_prepopulated_fields_js_tag(self):\n    \"\"\"Test the prepopulated_fields_js_tag template tag.\"\"\"\n    request = self.request_factory.get('/admin/')\n    request.user = self.superuser\n\n    prepopulated_fields = [\n        {\n            'field': Article._meta.get_field('title'),\n            'dependencies': [Article._meta.get_field('author')],\n        }\n    ]\n\n    context = {\n        'adminform': ModelAdmin(Article, site),\n        'inline_admin_formsets': [],\n    }\n    context['adminform'].prepopulated_fields = prepopulated_fields\n\n    template = '{% load admin_modify %}{% prepopulated_fields_js %}'\n    rendered = self.render_template_string(template, context, request)\n\n    self.assertIn('prepopulated_fields_json', rendered.context)\n    self.assertIn('title', rendered.context['prepopulated_fields_json'])\n    self.assertIn('author', rendered.context['prepopulated_fields_json'])\n"], "sample_171": ["    def test_migration_plan(self):\n        out = io.StringIO()\n        call_command('migrate', 'migrations', plan=True, stdout=out)\n        output = out.getvalue()\n        self.assertIn('Planned operations:', output)\n        self.assertIn('0001_initial', output)\n        self.assertIn('Create model UnicodeModel', output)\n"], "sample_1208": ["def test_matrix_student_t_distribution():\n    v, n, p = symbols('v n p', positive=True)\n    M = MatrixStudentT('M', v, MatrixSymbol('A', n, p), MatrixSymbol('B', p, p), MatrixSymbol('C', n, n))\n    X = MatrixSymbol('X', n, p)\n    assert isinstance(density(M)(X), exp)\n    assert isinstance(sample(M), Matrix)\n"], "sample_1164": ["def test_cg_simp():\n    a = CG(1, 1, 0, 0, 1, 1)\n    b = CG(1, 0, 0, 0, 1, 0)\n    c = CG(1, -1, 0, 0, 1, -1)\n    assert cg_simp(a + b + c) == 3\n"], "sample_1122": ["def test_polar_lift_with_symbol():\n    p = Symbol('p', polar=True)\n    x = Symbol('x')\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*p) == 4*p\n"], "sample_78": ["    def test_dance_command(self):\n        command = dance.Command()\n        with mock.patch('sys.stdout', new_callable=StringIO) as mock_stdout:\n            command.handle()\n            self.assertIn('Dancing...', mock_stdout.getvalue())\n"], "sample_882": ["def test_mlp_classifier_partial_fit():\n    X, y = make_multilabel_classification(n_samples=100, n_features=20, n_classes=3, random_state=42)\n    classes = np.unique(y)\n    clf = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1, warm_start=True, random_state=42)\n\n    # First call to partial_fit\n    clf.partial_fit(X[:50], y[:50], classes=classes)\n    assert hasattr(clf, \"classes_\")\n    assert_array_equal(clf.classes_, classes)\n\n    # Second call to partial_fit\n    clf.partial_fit(X[50:], y[50:])\n    assert hasattr(clf, \"classes_\")\n    assert_array_equal(clf.classes_, classes)\n\n    # Predict on the whole dataset\n    y_pred = clf.predict(X)\n    assert y_pred.shape == (100, 3)\n"], "sample_347": ["    def test_make_aware_with_fixed_offset(self):\n        naive_dt = datetime.datetime(2022, 1, 1, 12, 0, 0)\n        aware_dt = timezone.make_aware(naive_dt, EAT)\n        self.assertEqual(aware_dt.tzinfo, EAT)\n        self.assertEqual(aware_dt.utcoffset(), datetime.timedelta(hours=3))\n"], "sample_397": ["def test_get_template_builtins(self):\n    engine = self.engine_class()\n    builtins = engine.get_template_builtins([\"django.template.defaulttags\"])\n    self.assertEqual(len(builtins), 1)\n    self.assertIsInstance(builtins[0], dict)\n"], "sample_390": ["    def test_serve_file(self):\n        file_path = path.join(media_dir, \"test.txt\")\n        with open(file_path, \"w\") as f:\n            f.write(\"Test content\")\n        url = f\"/{self.prefix}/test.txt\"\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.content, b\"Test content\")\n        self.assertEqual(response[\"Content-Type\"], \"text/plain\")\n        self.assertEqual(response[\"Last-Modified\"], http_date(path.getmtime(file_path)))\n"], "sample_386": ["def test_mark_safe_with_custom_safe_data(self):\n    custom_safe_data = customescape(\"Test <string>\")\n    safe_string = mark_safe(custom_safe_data)\n    self.assertIsInstance(safe_string, SafeString)\n    self.assertEqual(safe_string, \"Test <<string>>\")\n"], "sample_119": ["def test_add_filter_with_related_isnull(self):\n    query = Query(Author)\n    query.add_filter(('items__isnull', True))\n    self.assertEqual(len(query.where.children), 1)\n    self.assertIsInstance(query.where.children[0], RelatedIsNull)\n    self.assertEqual(query.where.children[0].lhs.field, Author._meta.get_field('items'))\n    self.assertTrue(query.where.children[0].rhs)\n"], "sample_881": ["def test_roc_curve_drop_intermediate(drop):\n    y_true = np.array([0, 0, 1, 1])\n    y_score = np.array([0.1, 0.4, 0.35, 0.8])\n    fpr, tpr, thresholds = roc_curve(y_true, y_score, drop_intermediate=drop)\n    if drop:\n        assert_array_equal(fpr, np.array([0., 0.5, 1.]))\n        assert_array_equal(tpr, np.array([0., 1., 1.]))\n        assert_array_equal(thresholds, np.array([1.8, 0.4, 0.1]))\n    else:\n        assert_array_equal(fpr, np.array([0., 0., 0.5, 0.5, 1.]))\n        assert_array_equal(tpr, np.array([0., 0.5, 0.5, 1., 1.]))\n        assert_array_equal(thresholds, np.array([1.8, 0.8, 0.4, 0.35, 0.1]))\n"], "sample_832": ["def test_bayesian_ridge_predict_std():\n    X = diabetes.data\n    y = diabetes.target\n    br = BayesianRidge()\n    br.fit(X, y)\n    y_mean, y_std = br.predict(X, return_std=True)\n    assert y_mean.shape == (len(y),)\n    assert y_std.shape == (len(y),)\n    assert_array_less(y_std, np.inf)\n    assert_array_less(0, y_std)\n"], "sample_231": ["    def test_get_traceback_data(self):\n        request = RequestFactory().get('/')\n        exc_type = ValueError\n        exc_value = ValueError(\"Test exception\")\n        tb = sys.exc_info()[2]\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIsInstance(data, dict)\n        self.assertEqual(data['exception_type'], 'ValueError')\n        self.assertEqual(data['exception_value'], 'Test exception')\n"], "sample_1019": ["def test_monotonic_sign():\n    x = Symbol('x', integer=True, nonnegative=True)\n    p = Symbol('p', integer=True, positive=True)\n    p2 = Symbol('p2', integer=True, positive=True)\n    assert _monotonic_sign(x + 1) == 1\n    assert _monotonic_sign(p - 1) == Dummy('neg', negative=True)\n    assert _monotonic_sign(x*p + 1) == 1\n    assert _monotonic_sign(p2*p + 1) == 2\n    assert _monotonic_sign(x - 1) is None\n"], "sample_21": ["def test_write_table_qdp():\n    # Create a sample table\n    table = Table()\n    table['a'] = [1, 2, 3]\n    table['b'] = [4, 5, 6]\n    table['b_err'] = [0.1, 0.2, 0.3]\n    table['c'] = [7, 8, 9]\n    table['c_perr'] = [0.4, 0.5, 0.6]\n    table['c_nerr'] = [0.7, 0.8, 0.9]\n\n    # Write the table to a QDP file\n    lines = _write_table_qdp(table)\n\n    # Read the table back from the QDP file\n    table_read = _read_table_qdp(lines)\n\n    # Check that the original and read tables are equal\n    assert table == table_read\n"], "sample_765": ["def test_brier_score_loss():\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    expected_score = 0.037\n    assert_almost_equal(brier_score_loss(y_true, y_prob), expected_score)\n"], "sample_253": ["    def test_zip_imported_module(self):\n        zip_filename = self.temporary_file('test.zip')\n        with zipfile.ZipFile(zip_filename, 'w') as zf:\n            zf.writestr('test_module.py', 'print(\"Hello, World!\")')\n        sys.path.insert(0, str(zip_filename))\n        self.addCleanup(sys.path.remove, str(zip_filename))\n        self.import_and_cleanup('test_module')\n        self.assertFileFound(zip_filename)\n"], "sample_246": ["def test_no_location_option(self):\n    self.run_in_tmp_dir()\n    self.write_file('django.py', 'from django.utils.translation import gettext as _\\n_(\"Hello, world!\")')\n    self._run_makemessages(no_location=True)\n    self.assertLocationCommentNotPresent(self.PO_FILE, None, 'django.py')\n"], "sample_796": ["def test_huber_regressor_with_sparse_input():\n    X, y = make_regression_with_outliers(n_samples=50, n_features=20)\n    X_sparse = sparse.csr_matrix(X)\n\n    huber = HuberRegressor()\n    huber.fit(X_sparse, y)\n\n    huber_dense = HuberRegressor()\n    huber_dense.fit(X, y)\n\n    assert_array_almost_equal(huber.coef_, huber_dense.coef_)\n    assert_almost_equal(huber.intercept_, huber_dense.intercept_)\n    assert_almost_equal(huber.scale_, huber_dense.scale_)\n"], "sample_35": ["def test_resolve_name():\n    # Test that resolve_name can handle additional parts\n    assert introspection.resolve_name('astropy.utils.introspection', 'resolve_name') == introspection.resolve_name\n\n    # Test that resolve_name raises ImportError for non-existent modules or objects\n    with pytest.raises(ImportError):\n        introspection.resolve_name('non_existent_module')\n    with pytest.raises(ImportError):\n        introspection.resolve_name('astropy.utils.introspection', 'non_existent_object')\n"], "sample_913": ["def test_parse_annotation():\n    annotation = \"List[Union[int, str]]\"\n    result = _parse_annotation(annotation)\n    expected = [\n        pending_xref('', nodes.Text('List'), refdomain='py', reftype='class', reftarget='List'),\n        addnodes.desc_sig_punctuation('', '['),\n        pending_xref('', nodes.Text('Union'), refdomain='py', reftype='class', reftarget='Union'),\n        addnodes.desc_sig_punctuation('', '['),\n        pending_xref('', nodes.Text('int'), refdomain='py', reftype='class', reftarget='int'),\n        addnodes.desc_sig_punctuation('', ', '),\n        pending_xref('', nodes.Text('str'), refdomain='py', reftype='class', reftarget='str'),\n        addnodes.desc_sig_punctuation('', ']'),\n        addnodes.desc_sig_punctuation('', ']'),\n    ]\n    assert result == expected\n"], "sample_508": ["def test_artist_set_get_clip_path():\n    fig, ax = plt.subplots()\n    rect = mpatches.Rectangle((0, 0), 1, 1)\n    ax.add_patch(rect)\n\n    # Test setting clip path with a patch\n    ax.set_clip_path(rect)\n    assert ax.get_clip_path() == mtransforms.TransformedPatchPath(rect)\n\n    # Test setting clip path with a path and transform\n    path = mpath.Path([(0, 0), (1, 1), (1, 0)])\n    transform = mtransforms.Affine2D()\n    ax.set_clip_path(path, transform)\n    assert ax.get_clip_path() == mtransforms.TransformedPath(path, transform)\n\n    # Test setting clip path to None\n    ax.set_clip_path(None)\n    assert ax.get_clip_path() is None\n\n    # Test setting clip path with invalid arguments\n    with pytest.raises(TypeError):\n        ax.set_clip_path(\"invalid\", transform)\n\n    plt.close(fig)\n"], "sample_865": ["def test_tree_classifier_with_class_weight():\n    X, y = datasets.make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=10, n_classes=2, weights=[0.1, 0.9], random_state=0)\n    clf = DecisionTreeClassifier(class_weight='balanced', random_state=0)\n    clf.fit(X, y)\n    y_pred = clf.predict(X)\n    assert accuracy_score(y, y_pred) > 0.9\n"], "sample_941": ["def test_restify():\n    assert restify(MyClass1) == ':class:`test_util_typing.MyClass1`'\n    assert restify(MyClass2) == ':class:`test_util_typing.MyClass2`'\n    assert restify(MyInt) == ':class:`MyInt`'\n    assert restify(MyList) == ':class:`test_util_typing.MyList`'\n    assert restify(BrokenType) == ':obj:`test_util_typing.BrokenType`'\n    assert restify(Struct) == ':class:`struct.Struct`'\n    assert restify(Optional[int]) == ':obj:`Optional`\\\\ [:obj:`int`]'\n    assert restify(Union[int, str]) == ':obj:`Union`\\\\ [:obj:`int`, :obj:`str`]'\n    assert restify(Union[int, str, None]) == ':obj:`Optional`\\\\ [:obj:`Union`\\\\ [:obj:`int`, :obj:`str`]]'\n    assert restify(Callable[[int], str]) == ':obj:`Callable`\\\\ [[:obj:`int`], :obj:`str`]'\n    assert restify(Dict[str, int]) == ':obj:`Dict`\\\\ [:obj:`str`, :obj:`int`]'\n    assert restify(Tuple[int, ...]) == ':obj:`Tuple`\\\\ [:obj:`int`, ...]'\n    assert restify(Generator[int, None, None]) == ':obj:`Generator`\\\\ [:obj:`int`, :obj:`None`, :obj:`None`]'\n"], "sample_109": ["    def test_multiple_select(self):\n        form = MultipleBandForm()\n        widget = form.fields['band'].widget\n        attrs = widget.build_attrs({'id': 'id_band', 'name': 'band'})\n        self.assertEqual(attrs['data-ajax--url'], '/admin/admin_widgets/band/autocomplete/')\n        self.assertEqual(attrs['data-allow-clear'], 'true')\n        self.assertEqual(attrs['data-placeholder'], '')\n        self.assertEqual(attrs['class'], 'admin-autocomplete')\n        self.assertEqual(attrs['multiple'], 'multiple')\n"], "sample_380": ["    def test_variance(self):\n        result = Book.objects.aggregate(variance=Variance('price'))\n        self.assertIsInstance(result['variance'], float)\n"], "sample_615": ["def test_apply_ufunc_with_dask_parallelized():\n    da = xr.DataArray(np.random.rand(10, 10), dims=(\"x\", \"y\"))\n    da_dask = da.chunk({\"x\": 5, \"y\": 5})\n\n        return x + y\n\n    result = apply_ufunc(func, da_dask, da_dask, dask=\"parallelized\")\n    assert_identical(result.compute(), func(da, da))\n"], "sample_605": ["def test_consolidate_slices():\n    slices = [slice(0, 5), slice(5, 10), slice(10, 15, 2)]\n    result = _consolidate_slices(slices)\n    expected = [slice(0, 10), slice(10, 15, 2)]\n    assert result == expected\n"], "sample_628": ["def test_spelling_checker_with_docstring(self):\n    node = astroid.extract_node(\n        \"\"\"\n            '''\n            This is a docstring with a speling mistake.\n            '''\n            pass\n        \"\"\"\n    )\n    with self.assertAddsMessages(\n        Message(\n            \"wrong-spelling-in-docstring\",\n            line=3,\n            args=(\"speling\", \"This is a docstring with a speling mistake.\", \"                       ^^^^^^\", self._get_msg_suggestions(\"speling\")),\n        )\n    ):\n        self.checker.visit_functiondef(node.body[0])\n"], "sample_583": ["def test_vectorized_indexer(self):\n    x = DataArray(np.arange(10), dims='x')\n    i = indexing.VectorizedIndexer((np.array([1, 3, 5]),))\n    expected = DataArray(np.array([1, 3, 5]), dims='x')\n    assert_array_equal(x[i], expected)\n"], "sample_170": ["    def test_get_traceback_data(self):\n        request = RequestFactory().get('/')\n        exc_type = TemplateDoesNotExist\n        exc_value = TemplateDoesNotExist('template.html')\n        tb = None\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertTrue(data['template_does_not_exist'])\n        self.assertEqual(data['postmortem'], [exc_value])\n"], "sample_241": ["def test_query_with_filtered_relation(self):\n    # Test that a query with a filtered relation is correctly handled\n    filtered_employees = Employee.objects.filter(salary__gt=20)\n    companies = Company.objects.filter(ceo__in=filtered_employees)\n    self.assertEqual(list(companies), [self.gmbh])\n"], "sample_772": ["def check_regression_toy(name):\n    \"\"\"Check regression on a toy dataset.\"\"\"\n    ForestRegressor = FOREST_REGRESSORS[name]\n\n    reg = ForestRegressor(n_estimators=10, random_state=1)\n    reg.fit(X, y)\n    assert_array_almost_equal(reg.predict(T), true_result)\n    assert_equal(10, len(reg))\n\n    reg = ForestRegressor(n_estimators=10, max_features=1, random_state=1)\n    reg.fit(X, y)\n    assert_array_almost_equal(reg.predict(T), true_result)\n    assert_equal(10, len(reg))\n\n    # also test apply\n    leaf_indices = reg.apply(X)\n    assert_equal(leaf_indices.shape, (len(X), reg.n_estimators))\n"], "sample_1097": ["def test_blockcut():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (1, 3))\n    assert isinstance(B, BlockMatrix)\n    assert ImmutableMatrix(B.blocks[0, 1]) == Matrix([[1, 2, 3]])\n"], "sample_1187": ["def test_integration_reduction_dynamic():\n    facets = [Segment2D(Point2D(0, 0), Point2D(1, 0)), Segment2D(Point2D(1, 0), Point2D(1, 1)), Segment2D(Point2D(1, 1), Point2D(0, 1)), Segment2D(Point2D(0, 1), Point2D(0, 0))]\n    index = 0\n    a = (0, 1)\n    b = 0\n    expr = x\n    degree = 1\n    dims = (x, y)\n    x_index = 1\n    y_index = 0\n    max_index = 1\n    x0 = (0, 0)\n    monomial_values = [[1, 0, 0, 0], [x, 1, 0, None]]\n    monom_index = 1\n    result = integration_reduction_dynamic(facets, index, a, b, expr, degree, dims, x_index, y_index, max_index, x0, monomial_values, monom_index)\n    assert result == Rational(1, 2)\n"], "sample_322": ["    def test_migration_plan_with_clean_start(self):\n        executor = MigrationExecutor(connection)\n        targets = [(\"migrations\", \"0001_initial\")]\n        plan = executor.migration_plan(targets, clean_start=True)\n        self.assertEqual(len(plan), 1)\n        self.assertEqual(plan[0][0].name, \"0001_initial\")\n        self.assertFalse(plan[0][1])\n"], "sample_912": ["def test_parse_annotation():\n    annotation = \"List[Union[int, str]]\"\n    result = _parse_annotation(annotation)\n    expected = [\n        pending_xref('', nodes.Text('List'), refdomain='py', reftype='class', reftarget='List'),\n        desc_sig_punctuation('', '['),\n        pending_xref('', nodes.Text('Union'), refdomain='py', reftype='class', reftarget='Union'),\n        desc_sig_punctuation('', '['),\n        pending_xref('', nodes.Text('int'), refdomain='py', reftype='class', reftarget='int'),\n        desc_sig_punctuation('', ', '),\n        pending_xref('', nodes.Text('str'), refdomain='py', reftype='class', reftarget='str'),\n        desc_sig_punctuation('', ']'),\n        desc_sig_punctuation('', ']'),\n    ]\n    assert result == expected\n"], "sample_155": ["    def test_file_response_with_filelike_object(self):\n        content = b'File content'\n        filelike = io.BytesIO(content)\n        response = FileResponse(filelike, as_attachment=True, filename='test.txt')\n        self.assertEqual(response.getvalue(), content)\n        self.assertEqual(response['Content-Disposition'], 'attachment; filename=\"test.txt\"')\n        self.assertEqual(response['Content-Type'], 'text/plain')\n        self.assertEqual(response['Content-Length'], str(len(content)))\n"], "sample_625": ["def test_apply_ufunc_with_dask_array_and_parallelized_dask():\n    import dask.array as da\n\n    da_a = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]), chunks=(2, 3))\n    da_b = da.from_array(np.array([[7, 8, 9], [10, 11, 12]]), chunks=(2, 3))\n\n    result = apply_ufunc(np.add, da_a, da_b, dask=\"parallelized\")\n\n    assert isinstance(result, da.Array)\n    assert_array_equal(result.compute(), np.array([[8, 10, 12], [14, 16, 18]]))\n"], "sample_137": ["    def test_parse_docstring(self):\n        title, body, metadata = parse_docstring(self.docstring)\n        self.assertEqual(title, \"This __doc__ output is required for testing. I copied this example from `admindocs` documentation.\")\n        self.assertIn(\"Display an individual :model:`myapp.MyModel`.\", body)\n        self.assertIn(\"**Context**\", body)\n        self.assertIn(\"**Template:**\", body)\n        self.assertIn(\":template:`myapp/my_template.html`\", body)\n        self.assertEqual(metadata, {'some_metadata': 'some data'})\n"], "sample_125": ["    def test_set_cookie_with_datetime_expires(self):\n        response = HttpResponse()\n        expires = datetime.now(utc) + timedelta(days=1)\n        response.set_cookie('name', 'value', expires=expires)\n        cookie = response.cookies['name']\n        self.assertEqual(cookie.value, 'value')\n        self.assertEqual(cookie['expires'], http_date(time.mktime(expires.timetuple())))\n"], "sample_457": ["    def test_check_constraint(self):\n        # Test the CheckConstraint class\n        check = models.Q(price__gt=0)\n        constraint = CheckConstraint(check=check, name=\"positive_price\")\n        self.assertEqual(constraint.check, check)\n        self.assertEqual(constraint.name, \"positive_price\")\n        self.assertEqual(constraint.violation_error_message, BaseConstraint.default_violation_error_message % {\"name\": \"positive_price\"})\n\n        # Test the validate method\n        product = Product(name=\"Test\", price=-1)\n        with self.assertRaises(ValidationError):\n            constraint.validate(Product, product)\n\n        product.price = 1\n        constraint.validate(Product, product)  # No exception should be raised\n"], "sample_67": ["def test_model_to_dict(self):\n    author = Author.objects.create(name='Test Author')\n    book = Book.objects.create(title='Test Book', author=author)\n    data = model_to_dict(book, fields=['title'])\n    self.assertEqual(data, {'title': 'Test Book'})\n"], "sample_627": ["def test_concat_with_positions():\n    datasets = create_concat_datasets(num_datasets=3)\n    concatenated = concat(datasets, dim=\"day\", positions=[[0, 1], [2, 3], [4, 5]])\n    expected_days = pd.Index([\"day1\", \"day2\", \"day3\", \"day4\", \"day5\", \"day6\"], name=\"day\")\n    assert_equal(concatenated.day, expected_days)\n"], "sample_606": ["def test_apply_ufunc_with_dask_gufunc_kwargs():\n    # Test apply_ufunc with dask='parallelized' and dask_gufunc_kwargs\n    x = xr.DataArray(np.arange(10), dims=\"x\")\n    y = xr.DataArray(np.arange(10, 20), dims=\"x\")\n\n        return a + b\n\n    result = apply_ufunc(\n        func,\n        x,\n        y,\n        input_core_dims=[[\"x\"], [\"x\"]],\n        output_core_dims=[[\"x\"]],\n        dask=\"parallelized\",\n        dask_gufunc_kwargs={\"output_sizes\": {\"x\": 10}},\n    )\n\n    assert_identical(result, x + y)\n"], "sample_867": ["def test_parameter_grid_with_empty_dict(klass):\n    param_grid = {}\n    grid = klass(param_grid)\n    assert list(grid) == [{}]\n    assert_grid_iter_equals_getitem(grid)\n"], "sample_178": ["def test_formset_factory_with_custom_kwargs(self):\n    CustomKwargFormSet = formset_factory(CustomKwargForm, formset=BaseFormSet, extra=2, form_kwargs={'custom_kwarg': 'test'})\n    formset = CustomKwargFormSet()\n    for form in formset:\n        self.assertEqual(form.custom_kwarg, 'test')\n"], "sample_1124": ["def test_sfield_with_expressions():\n    x = symbols(\"x\")\n    K, f = sfield((x*log(x) + 4*x**2)*exp(1/x + log(x)/3)/x**2)\n    assert K == FracField(symbols(\"x, exp(1/x), log(x), x**(1/3)\"), ZZ, lex)\n    assert f == (4*x**2*(exp(1/x)) + x*(exp(1/x))*(log(x)))/((x**(1/3))**5)\n"], "sample_100": ["    def test_zip_imported_module(self):\n        zip_filename = self.temporary_file('test.zip')\n        with zipfile.ZipFile(zip_filename, 'w') as zf:\n            zf.writestr('test_module.py', 'print(\"Hello, World!\")')\n        sys.path.insert(0, str(zip_filename))\n        self.addCleanup(sys.path.remove, str(zip_filename))\n        self.import_and_cleanup('test_module')\n        self.assertFileFound(zip_filename)\n"], "sample_755": ["def test_silhouette_score_with_sample_size():\n    X, y = datasets.make_blobs(n_samples=100, n_features=2, centers=2, random_state=42)\n    sample_size = 50\n    score = silhouette_score(X, y, sample_size=sample_size, random_state=42)\n    assert score >= -1 and score <= 1, \"Silhouette score should be between -1 and 1\"\n    assert len(silhouette_samples(X, y, sample_size=sample_size, random_state=42)) == sample_size, \"Silhouette samples should have the same size as the sample size\"\n"], "sample_879": ["def test_ordinal_encoder_encoded_missing_value():\n    X = [['Male', 1], ['Female', 3], ['Female', np.nan]]\n    enc = OrdinalEncoder(encoded_missing_value=-1)\n    X_trans = enc.fit_transform(X)\n    expected_trans = np.array([[1., 0.], [0., 1.], [0., -1.]])\n    assert_array_equal(X_trans, expected_trans)\n\n    X_inv = enc.inverse_transform(X_trans)\n    expected_inv = np.array([['Male', 1], ['Female', 3], ['Female', np.nan]], dtype=object)\n    assert_array_equal(X_inv, expected_inv)\n"], "sample_335": ["    def test_to_python_valid_input(self):\n        field = DecimalField(max_digits=5, decimal_places=2)\n        self.assertEqual(field.to_python('123.45'), decimal.Decimal('123.45'))\n"], "sample_222": ["    def test_file_locking(self):\n        with tempfile.NamedTemporaryFile() as temp:\n            with open(temp.name, 'wb') as f:\n                self.assertTrue(locks.lock(f, locks.LOCK_EX))\n                f.write(b'Django')\n                self.assertTrue(locks.unlock(f))\n\n            with open(temp.name, 'rb') as f:\n                self.assertEqual(f.read(), b'Django')\n"], "sample_392": ["def test_key_transform_factory(self):\n    factory = KeyTransformFactory(\"test_key\")\n    transform = factory(Value(\"test_value\"))\n    self.assertIsInstance(transform, KeyTransform)\n    self.assertEqual(transform.key_name, \"test_key\")\n    self.assertEqual(transform.source_expressions[0].value, \"test_value\")\n"], "sample_1109": ["def test_frac_rewrite():\n    assert frac(x).rewrite(floor) == x - floor(x)\n    assert frac(x).rewrite(ceiling) == x + ceiling(-x)\n"], "sample_310": ["def test_get_return_data_type(self):\n    self.assertEqual(get_return_data_type('get_list'), 'List')\n    self.assertEqual(get_return_data_type('get_count'), 'Integer')\n    self.assertEqual(get_return_data_type('get_item'), '')\n"], "sample_1053": ["def test_integer_nthroot():\n    assert integer_nthroot(8, 3) == (2, True)\n    assert integer_nthroot(27, 3) == (3, True)\n    assert integer_nthroot(26, 3) == (3, False)\n"], "sample_1129": ["def test_print_loggamma():\n    expr = loggamma(x)\n    assert pycode(expr, printer=SciPyPrinter) == \"scipy.special.gammaln(x)\"\n"], "sample_528": ["def test_use_with_list_of_styles():\n    with temp_style('style1', {'lines.linewidth': 2}), \\\n         temp_style('style2', {'axes.grid': True}):\n        style.use(['style1', 'style2'])\n        assert mpl.rcParams['lines.linewidth'] == 2\n        assert mpl.rcParams['axes.grid'] is True\n"], "sample_700": ["def test_evaluate_skip_marks(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.skip(reason=\"skipping this test\")\n            assert False\n\n            assert True\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(skipped=1, passed=1)\n    result.stdout.fnmatch_lines([\"*::test_skip SKIPPED*skipping this test\"])\n"], "sample_248": ["    def test_stdin_execution(self):\n        with captured_stdin() as stdin, captured_stdout() as stdout:\n            stdin.write(self.script_with_inline_function)\n            stdin.seek(0)\n            call_command('shell')\n            self.assertEqual(stdout.getvalue().strip(), __version__)\n"], "sample_519": ["def test_figure_align_labels():\n    fig, axs = plt.subplots(2, 2)\n    axs[0, 0].set_xlabel('XLabel 0')\n    axs[1, 1].set_xlabel('XLabel 1')\n    fig.align_xlabels()\n    axs[0, 0].set_ylabel('YLabel 0')\n    axs[1, 1].set_ylabel('YLabel 1')\n    fig.align_ylabels()\n"], "sample_1163": ["def test_sign_derivative():\n    x = Symbol('x', real=True)\n    assert sign(x)._eval_derivative(x) == 2 * DiracDelta(x)\n    assert sign(I*x)._eval_derivative(x) == 2 * DiracDelta(-I*x)\n"], "sample_747": ["def test_quantile_transformer_sparse_ignore_implicit_zeros():\n    X = sparse.csr_matrix([[0, 1], [2, 3]])\n    qt = QuantileTransformer(n_quantiles=10, ignore_implicit_zeros=True)\n    qt.fit(X)\n    X_trans = qt.transform(X)\n    assert_array_almost_equal(X_trans.toarray(), [[0, 0.5], [1, 1]])\n"], "sample_1021": ["def test_quaternion_rotation_matrix_conversion():\n    q = Quaternion(1, 2, 3, 4)\n    m = q.to_rotation_matrix()\n    q_from_m = Quaternion.from_rotation_matrix(m)\n    assert q.normalize() == q_from_m.normalize()\n"], "sample_641": ["def test_save_and_load_results(tmp_path):\n    base = \"test_base\"\n    results = LinterStats()\n    results.bad_names = BadNames()\n    results.bad_names.add(\"test_name\")\n\n    save_results(results, base, tmp_path)\n    loaded_results = load_results(base, tmp_path)\n\n    assert loaded_results is not None\n    assert loaded_results.bad_names == results.bad_names\n"], "sample_104": ["def test_hashed_name_with_fragment(self):\n    storage.staticfiles_storage.save('test.css', StringIO('body { background: url(image.png?#iefix); }'))\n    hashed_name = storage.staticfiles_storage.hashed_name('test.css')\n    self.assertIn('?#', hashed_name)\n    self.assertPostCondition()\n"], "sample_894": ["def test_classification_toy_warm_start(name):\n    \"\"\"Check classification on a toy dataset with warm_start.\"\"\"\n    ForestClassifier = FOREST_CLASSIFIERS[name]\n\n    clf = ForestClassifier(n_estimators=5, random_state=1, warm_start=True)\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T), true_result)\n    assert 5 == len(clf)\n\n    clf.set_params(n_estimators=10)\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(T), true_result)\n    assert 10 == len(clf)\n"], "sample_51": ["    def test_parse_datetime_with_timezone(self):\n        dt = parse_datetime('2022-01-01T12:34:56+02:00')\n        self.assertEqual(dt, datetime(2022, 1, 1, 12, 34, 56, tzinfo=get_fixed_timezone(120)))\n\n        dt = parse_datetime('2022-01-01T12:34:56-03:30')\n        self.assertEqual(dt, datetime(2022, 1, 1, 12, 34, 56, tzinfo=get_fixed_timezone(-210)))\n\n        dt = parse_datetime('2022-01-01T12:34:56Z')\n        self.assertEqual(dt, datetime(2022, 1, 1, 12, 34, 56, tzinfo=utc))\n"], "sample_355": ["    def test_user_creation(self):\n        user = User.objects.create_user(username='testuser', email='testuser@example.com', password='testpassword')\n        self.assertEqual(user.username, 'testuser')\n        self.assertEqual(user.email, 'testuser@example.com')\n        self.assertTrue(user.check_password('testpassword'))\n        self.assertFalse(user.is_staff)\n        self.assertFalse(user.is_superuser)\n"], "sample_461": ["def test_url_field_with_assume_scheme(self):\n    field = URLField(assume_scheme=\"https\")\n    self.assertEqual(field.clean(\"example.com\"), \"https://example.com\")\n    self.assertEqual(field.clean(\"http://example.com\"), \"http://example.com\")\n    self.assertEqual(field.clean(\"https://example.com\"), \"https://example.com\")\n    self.assertEqual(field.clean(\"ftp://example.com\"), \"ftp://example.com\")\n"], "sample_22": ["def test_matrix_product():\n    m1 = np.array([[1, 2], [3, 4]])\n    m2 = np.array([[5, 6], [7, 8]])\n    m3 = np.array([[9, 10], [11, 12]])\n    expected_result = np.matmul(np.matmul(m1, m2), m3)\n    result = matrix_product(m1, m2, m3)\n    assert_array_equal(result, expected_result)\n\n    # Test with deprecation warning\n    with pytest.warns(AstropyDeprecationWarning):\n        matrix_product(m1, m2)\n"], "sample_375": ["    def test_rename_field(self):\n        state = ProjectState()\n        state.add_model(ModelState('app', 'Model', {'old_name': models.CharField(max_length=10)}))\n        state.rename_field('app', 'model', 'old_name', 'new_name')\n        self.assertIn('new_name', state.models['app', 'model'].fields)\n        self.assertNotIn('old_name', state.models['app', 'model'].fields)\n"], "sample_539": ["def test_rectangle_selector_with_kwargs(ax, kwargs):\n    onselect = mock.Mock()\n    rs = widgets.RectangleSelector(ax, onselect, **kwargs)\n    assert rs.minspanx == kwargs.get('minspanx', 0)\n    assert rs.minspany == kwargs.get('minspany', 0)\n    assert rs.spancoords == kwargs.get('spancoords', 'data')\n    assert rs.useblit == kwargs.get('useblit', False)\n    assert rs._props == {**kwargs.get('props', {}), 'animated': rs.useblit}\n"], "sample_220": ["    def test_set_cookie_with_datetime_expires(self):\n        response = HttpResponse()\n        expires = datetime.utcnow() + timedelta(days=1)\n        response.set_cookie('name', 'value', expires=expires)\n        cookie = response.cookies['name']\n        self.assertEqual(cookie['expires'], http_date(time.mktime(expires.timetuple())))\n"], "sample_1128": ["def test_point_set_pos():\n    N = ReferenceFrame('N')\n    p1 = Point('p1')\n    p2 = Point('p2')\n    p1.set_pos(p2, 10 * N.x)\n    assert p1.pos_from(p2) == 10 * N.x\n    assert p2.pos_from(p1) == -10 * N.x\n\n    with raises(TypeError):\n        p1.set_pos(10, 10 * N.x)\n\n    with raises(TypeError):\n        p1.set_pos(p2, 'invalid')\n"], "sample_763": ["def test_check_non_negative():\n    X = np.array([[1, 2], [3, -4]])\n    with pytest.raises(ValueError, match=\"Negative values in data passed to test\"):\n        check_non_negative(X, \"test\")\n\n    X = sp.csr_matrix([[1, 2], [3, -4]])\n    with pytest.raises(ValueError, match=\"Negative values in data passed to test\"):\n        check_non_negative(X, \"test\")\n\n    X = np.array([[1, 2], [3, 4]])\n    check_non_negative(X, \"test\")  # should not raise an error\n\n    X = sp.csr_matrix([[1, 2], [3, 4]])\n    check_non_negative(X, \"test\")  # should not raise an error\n"], "sample_1067": ["def test_mul_as_coefficients_dict():\n    x, y = symbols('x y')\n    expr = 3*x*y\n    coeff_dict = expr.as_coefficients_dict()\n    assert coeff_dict[x*y] == 3\n"], "sample_207": ["    def test_key_transform_factory(self):\n        factory = KeyTransformFactory('key')\n        transform = factory(Value('{\"key\": \"value\"}'))\n        self.assertIsInstance(transform, KeyTransform)\n        self.assertEqual(transform.key_name, 'key')\n"], "sample_943": ["def test_separate_modules(apidoc):\n    assert (apidoc.outdir / 'test_module.rst').exists()\n    assert (apidoc.outdir / 'test_package.test_module.rst').exists()\n"], "sample_498": ["def test_legend_set_draggable():\n    fig, ax = plt.subplots()\n    line, = ax.plot([1, 2, 3], [1, 2, 3], label='Test line')\n    legend = ax.legend()\n\n    # Test setting draggable to True\n    draggable = legend.set_draggable(state=True)\n    assert isinstance(draggable, mlegend.DraggableLegend)\n    assert legend.get_draggable() is True\n\n    # Test setting draggable to False\n    legend.set_draggable(state=False)\n    assert legend.get_draggable() is False\n"], "sample_517": ["def test_annotation_contains():\n    fig, ax = plt.subplots()\n    ann = ax.annotate(\"Test\", xy=(0.5, 0.5), xytext=(0.6, 0.6),\n                      arrowprops=dict(arrowstyle=\"->\"))\n    event = MouseEvent(\"button_press_event\", fig.canvas, 0, 0,\n                       guiEvent=None, button=1, xdata=0.55, ydata=0.55)\n    contains, info = ann.contains(event)\n    assert contains\n"], "sample_703": ["def test_evaluate_with_identifiers():\n        return s in [\"test1\", \"test2\"]\n\n    assert evaluate(\"test1\", matcher) is True\n    assert evaluate(\"test2\", matcher) is True\n    assert evaluate(\"test3\", matcher) is False\n    assert evaluate(\"test1 or test3\", matcher) is True\n    assert evaluate(\"test1 and test3\", matcher) is False\n    assert evaluate(\"not test1\", matcher) is False\n    assert evaluate(\"not test3\", matcher) is True\n"], "sample_677": ["def test_evaluate_with_identifiers():\n        return s in [\"test1\", \"test2\"]\n\n    assert evaluate(\"test1\", matcher) is True\n    assert evaluate(\"test2\", matcher) is True\n    assert evaluate(\"test3\", matcher) is False\n    assert evaluate(\"not test1\", matcher) is False\n    assert evaluate(\"test1 or test3\", matcher) is True\n    assert evaluate(\"test1 and test3\", matcher) is False\n    assert evaluate(\"(test1 or test3) and test2\", matcher) is True\n"], "sample_376": ["    def test_store_and_retrieve_messages(self):\n        storage = self.get_storage()\n        response = self.get_response()\n        messages = [Message(constants.INFO, 'Test message 1'), Message(constants.ERROR, 'Test message 2')]\n        unstored_messages = storage._store(messages, response)\n        self.assertEqual(unstored_messages, [])\n        retrieved_messages, all_retrieved = storage._get()\n        self.assertEqual(retrieved_messages, messages)\n        self.assertTrue(all_retrieved)\n"], "sample_185": ["    def test_localize_input_with_datetime(self):\n        value = datetime.datetime(2022, 1, 1, 12, 34, 56)\n        with patch_formats('en', DATETIME_INPUT_FORMATS=['%Y-%m-%d %H:%M:%S']):\n            result = localize_input(value)\n            self.assertEqual(result, '2022-01-01 12:34:56')\n"], "sample_405": ["    def test_add_index(self):\n        operation = migrations.AddIndex(\"TestModel\", models.Index(fields=[\"field1\", \"field2\"], name=\"test_index\"))\n        state = ProjectState()\n        state.add_model(ModelState(\"app_label\", \"TestModel\", [(\"field1\", models.CharField(max_length=100)), (\"field2\", models.IntegerField())]))\n\n        # Test state_forwards\n        operation.state_forwards(\"app_label\", state)\n        self.assertEqual(len(state.models[\"app_label\", \"testmodel\"].options[\"indexes\"]), 1)\n        self.assertEqual(state.models[\"app_label\", \"testmodel\"].options[\"indexes\"][0].name, \"test_index\")\n\n        # Test database_forwards\n        with connection.schema_editor() as schema_editor:\n            with atomic():\n                operation.database_forwards(\"app_label\", schema_editor, state, state)\n                self.assertIn(\"test_index\", connection.introspection.get_constraints(connection.cursor(), \"app_label_testmodel\"))\n\n        # Test database_backwards\n        with connection.schema_editor() as schema_editor:\n            with atomic():\n                operation.database_backwards(\"app_label\", schema_editor, state, state)\n                self.assertNotIn(\"test_index\", connection.introspection.get_constraints(connection.cursor(), \"app_label_testmodel\"))\n"], "sample_707": ["def test_iterparentnodeids(nodeid: str, expected: List[str]) -> None:\n    result = list(nodes.iterparentnodeids(nodeid))\n    assert result == expected\n"], "sample_1014": ["def test_mutable_dense_ndim_array_getitem():\n    a = MutableDenseNDimArray([0, 1, 2, 3], (2, 2))\n    assert a[0, 0] == 0\n    assert a[1, 1] == 3\n\n    i, j = symbols('i j')\n    assert a[i, j] == IndexedBase('[[0, 1], [2, 3]]')[i, j]\n    assert a[i, j].subs({i: 1, j: 1}) == 3\n\n    b = MutableDenseNDimArray([i for i in range(8)], (2, 2, 2))\n    assert b[0, :, 1] == MutableDenseNDimArray([0, 2], (2,))\n    assert b[:, 1, :] == MutableDenseNDimArray([[4, 5], [6, 7]], (2, 2))\n"], "sample_402": ["    def test_disallowed_user_agent(self):\n        user_agent = \"DisallowedUserAgent\"\n        request = self.rf.get(\"/\", HTTP_USER_AGENT=user_agent)\n        with self.settings(DISALLOWED_USER_AGENTS=[re.compile(user_agent)]):\n            with self.assertRaises(PermissionDenied):\n                CommonMiddleware().process_request(request)\n"], "sample_742": ["def test_logistic_regression_path():\n    # Test logistic_regression_path function\n    coefs, Cs, n_iter = logistic_regression_path(X, Y1, Cs=10)\n    assert_equal(coefs.shape, (10, 3))\n    assert_equal(Cs.shape, (10,))\n    assert_equal(n_iter.shape, (10,))\n\n    # Test logistic_regression_path function with multinomial\n    coefs, Cs, n_iter = logistic_regression_path(X, Y2, Cs=10, multi_class='multinomial')\n    assert_equal(coefs.shape, (10, 3, 3))\n    assert_equal(Cs.shape, (10,))\n    assert_equal(n_iter.shape, (10,))\n"], "sample_442": ["    def test_sign_and_unsign_object(self):\n        obj = {'key': 'value'}\n        signed_obj = signing.dumps(obj)\n        unsigned_obj = signing.loads(signed_obj)\n        self.assertEqual(obj, unsigned_obj)\n"], "sample_173": ["def test_date_extract_sql(self):\n    with self.assertRaisesMessage(NotImplementedError, self.may_require_msg % 'date_extract_sql'):\n        self.ops.date_extract_sql('year', 'field_name')\n"], "sample_691": ["def test_faulthandler_timeout(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import time\n\n            time.sleep(1)\n        \"\"\"\n    )\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        faulthandler_timeout = 0.5\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*Dumping the traceback*\"])\n    result.assert_outcomes(failed=1)\n"], "sample_428": ["    def test_format_large_float(self):\n        number = 1.23456789e100\n        result = nformat(number, decimal_sep='.', decimal_pos=2, grouping=3, thousand_sep=',')\n        self.assertEqual(result, '1.23e100')\n"], "sample_1134": ["compilation error"], "sample_1190": ["def test_extend_unit_system():\n    new_system = SI.extend([Quantity('new_unit')], name=\"NewSystem\", description=\"A new unit system\")\n    assert new_system.name == \"NewSystem\"\n    assert new_system.descr == \"A new unit system\"\n    assert len(new_system._base_units) == len(SI._base_units) + 1\n    assert Quantity('new_unit') in new_system._units\n"], "sample_719": ["def test_tfidf_vectorizer_with_custom_analyzer():\n    vectorizer = TfidfVectorizer(analyzer=lazy_analyze)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n    assert_equal(X.shape, (11, 1))\n    assert_equal(vectorizer.vocabulary_, {'the_ultimate_feature': 0})\n"], "sample_1181": ["def test_print_ArrayDiagonal():\n    expr = ArrayDiagonal(Array([[1, 2], [3, 4]]), (0, 1))\n    printer = NumPyPrinter()\n    assert printer._print(expr) == \"numpy.diagonal(numpy.array([[1, 2], [3, 4]]), 0, axis1=0, axis2=1)\"\n"], "sample_98": ["    def setUpClass(cls):\n        super().setUpClass()\n        cls.server_thread = LiveServerThread(\n            WSGIServer,\n            QuietWSGIRequestHandler,\n            {'address': 'localhost', 'port': 0},\n            cls.live_server_url_test,\n        )\n        cls.server_thread.daemon = True\n        cls.server_thread.start()\n"], "sample_868": ["def test_silhouette_score_consistency():\n    X = rng.rand(10, 2)\n    labels = rng.randint(2, size=10)\n    score1 = silhouette_score(X, labels)\n    score2 = silhouette_score(X[::-1], labels[::-1])\n    assert_allclose(score1, score2)\n"], "sample_636": ["def test_similar_code_checker_with_imports(capsys):\n    with _patch_streams(capsys.out):\n        Run([join(DATA, \"import1.py\"), join(DATA, \"import2.py\"), \"--ignore-imports\"])\n        out, _ = capsys.readouterr()\n        assert \"4 similar lines in 2 files\" in out\n        assert \"import1.py\" in out\n        assert \"import2.py\" in out\n"], "sample_500": ["def test_colorbar_extension_length():\n    fig_uniform = _colorbar_extension_length('uniform')\n    fig_proportional = _colorbar_extension_length('proportional')\n    return fig_uniform, fig_proportional\n"], "sample_75": ["def test_prefetch_related_with_filter(self):\n    with CaptureQueriesContext(connection) as ctx:\n        readers = Reader.objects.prefetch_related(\n            Prefetch('books_read', queryset=Book.objects.filter(title__startswith='W'))\n        )\n        for reader in readers:\n            # Trigger the prefetch\n            reader.books_read.all()\n\n    # Check that the prefetch query was executed with the correct filter\n    self.assertEqual(len(ctx.captured_queries), 2)\n    self.assertWhereContains(ctx.captured_queries[1]['sql'], \"WHERE `tests_book`.`title` LIKE 'W%'\")\n"], "sample_89": ["    def test_import_error_file(self):\n        filename = self.temporary_file('error_module.py')\n        filename.write_text('syntax error')\n        sys.path.insert(0, str(filename.parent))\n        self.addCleanup(sys.path.remove, str(filename.parent))\n        with self.assertRaises(SyntaxError):\n            self.import_and_cleanup('error_module')\n        self.assertFileFound(filename)\n        self.assertIn(filename, autoreload._error_files)\n"], "sample_847": ["def test_multi_task_elastic_net_cv_with_single_task():\n    X = np.array([[0, 0], [1, 1], [2, 2]])\n    y = np.array([0, 1, 2])\n    with pytest.raises(ValueError, match=\"For mono-task outputs, use ElasticNet\"):\n        MultiTaskElasticNetCV().fit(X, y)\n"], "sample_692": ["def test_tmp_path_factory_from_config(monkeypatch: MonkeyPatch) -> None:\n    class MockConfig:\n        class MockOption:\n            basetemp = None\n\n        class MockTrace:\n                return None\n\n        option = MockOption()\n        trace = MockTrace()\n\n    config = MockConfig()\n    factory = TempPathFactory.from_config(config, _ispytest=True)\n    assert factory._given_basetemp is None\n    assert factory._trace is None\n    assert factory._basetemp is None\n\n    monkeypatch.setenv(\"PYTEST_DEBUG_TEMPROOT\", \"/tmp/pytest\")\n    factory = TempPathFactory.from_config(config, _ispytest=True)\n    assert factory._given_basetemp is None\n    assert factory._trace is None\n    assert factory._basetemp is None\n    assert factory.getbasetemp().parent == Path(\"/tmp/pytest\").resolve()\n"], "sample_795": ["    def test_check_outlier_corruption(self):\n        # Test that the function correctly identifies corruption in the number of outliers\n        num_outliers = 25\n        expected_outliers = 30\n        decision = np.random.rand(100)\n        decision[num_outliers:expected_outliers] = np.mean(decision[num_outliers:expected_outliers])\n        with self.assertRaises(AssertionError):\n            check_outlier_corruption(num_outliers, expected_outliers, decision)\n"], "sample_0": ["def test_pickle_unpickle(UncertClass):\n    uncert = UncertClass([1, 2, 3], unit='m')\n    pickled = pickle.dumps(uncert)\n    unpickled = pickle.loads(pickled)\n    assert_array_equal(uncert.array, unpickled.array)\n    assert uncert.unit == unpickled.unit\n    assert uncert.parent_nddata is None\n    assert unpickled.parent_nddata is None\n"], "sample_559": ["def test_axes_set_aspect():\n    fig, ax = plt.subplots()\n    ax.set_aspect('equal')\n    assert ax.get_aspect() == 'equal'\n    ax.set_aspect('auto')\n    assert ax.get_aspect() == 'auto'\n    ax.set_aspect(2)\n    assert ax.get_aspect() == 2\n    with pytest.raises(ValueError):\n        ax.set_aspect('invalid')\n"], "sample_684": ["def test_frame_eval():\n    frame = Frame(sys._getframe())\n    result = frame.eval(\"1 + 2\")\n    assert result == 3\n"], "sample_393": ["def test_no_location_option(self):\n    output, po_contents = self._run_makemessages(no_location=True)\n    self.assertNotIn(\"#: \", po_contents)\n"], "sample_477": ["def test_random_filter_with_empty_list(self):\n    output = self.engine.render_to_string(\"random02\", {\"c\": []})\n    self.assertEqual(output, \"\")\n"], "sample_1139": ["def test_complex_region_from_real():\n    unit = Interval(0, 1)\n    region = ComplexRegion.from_real(unit)\n    assert region == CartesianComplexRegion(ProductSet(unit, FiniteSet(0)))\n"], "sample_520": ["def test_text_3d_get_position_3d():\n    text = art3d.Text3D(x=1, y=2, z=3, text='Test')\n    assert text.get_position_3d() == (1, 2, 3)\n"], "sample_105": ["    def test_get_redirect_url(self):\n        view = RedirectView.as_view(url='/redirect-url/')\n        request = self.rf.get('/some-url/')\n        response = view(request)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response.url, '/redirect-url/')\n"], "sample_988": ["def test_number_symbol_approximation():\n    assert S.Pi.approximation(Float) == Interval(Float('3.141592653589793'), Float('3.1415926535897932'))\n"], "sample_1008": ["def test_variable_map():\n    A = ReferenceFrame('A')\n    q = dynamicsymbols('q')\n    B = A.orientnew('B', 'Axis', [q, A.z])\n    mapping = A.variable_map(B)\n    assert mapping[A.x] == B.x*cos(q) - B.y*sin(q)\n    assert mapping[A.y] == B.x*sin(q) + B.y*cos(q)\n    assert mapping[A.z] == B.z\n"], "sample_937": ["compilation error"], "sample_225": ["    def test_add_action(self):\n            pass\n\n        site.add_action(custom_action, name='custom_action')\n        self.assertIn('custom_action', dict(site.actions))\n"], "sample_896": ["def test_nmf_with_sparse_input(Estimator, solver):\n    X = sp.csr_matrix([[1, 1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])\n    model = Estimator(n_components=2, init='random', random_state=0, **solver)\n    W = model.fit_transform(X)\n    H = model.components_\n    assert W.shape == (6, 2)\n    assert H.shape == (2, 2)\n"], "sample_328": ["def test_bulk_update_with_f_expressions(self):\n    Note.objects.bulk_update(self.notes, ['note'], batch_size=5)\n    Note.objects.bulk_update(self.notes, [F('note') + ' updated'], batch_size=5)\n    for note in self.notes:\n        note.refresh_from_db()\n        self.assertEqual(note.note, str(self.notes.index(note)) + ' updated')\n"], "sample_101": ["def test_wsgi_handler_file_response(self):\n    environ = {\n        'REQUEST_METHOD': 'GET',\n        'PATH_INFO': '/test/',\n        'wsgi.input': b'',\n        'wsgi.url_scheme': 'http',\n        'wsgi.file_wrapper': FileResponse,\n    }\n    start_response = lambda status, headers: None\n    handler = WSGIHandler()\n    response = handler(environ, start_response)\n    self.assertIsInstance(response, FileResponse)\n"], "sample_982": ["def test_udivisor_sigma():\n    assert udivisor_sigma(18, 0) == 4\n    assert udivisor_sigma(74, 1) == 114\n    assert udivisor_sigma(36, 3) == 47450\n    assert udivisor_sigma(111) == 152\n"], "sample_621": ["def test_asarray_tuplesafe():\n    # Test with a tuple\n    result = _asarray_tuplesafe((1, 2, 3))\n    assert isinstance(result, np.ndarray)\n    assert np.array_equal(result, np.array([1, 2, 3], dtype=object))\n\n    # Test with a list\n    result = _asarray_tuplesafe([1, 2, 3])\n    assert isinstance(result, np.ndarray)\n    assert np.array_equal(result, np.array([1, 2, 3]))\n\n    # Test with a 2D array\n    result = _asarray_tuplesafe([[1, 2], [3, 4]])\n    assert isinstance(result, np.ndarray)\n    assert np.array_equal(result, np.array([[1, 2], [3, 4]], dtype=object))\n"], "sample_476": ["def test_image_field_save_form_data(self):\n    \"\"\"\n    Test the save_form_data method of ImageField.\n    \"\"\"\n    instance = self.PersonModel()\n    self.PersonModel.mugshot.save_form_data(instance, self.file1)\n    self.assertEqual(instance.mugshot, \"4x8.png\")\n\n    self.PersonModel.mugshot.save_form_data(instance, None)\n    self.assertEqual(instance.mugshot, \"\")\n"], "sample_215": ["    def test_get_traceback_data(self):\n        request = RequestFactory().get('/')\n        exc_type = ValueError\n        exc_value = ValueError(\"Test exception\")\n        tb = sys.exc_info()[2]\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIsInstance(data, dict)\n        self.assertEqual(data['exception_type'], 'ValueError')\n        self.assertEqual(data['exception_value'], 'Test exception')\n"], "sample_708": ["def test_source_getstatementrange():\n    source = Source([\"def foo():\", \"    if True:\", \"        pass\", \"    return 1\"])\n    start, end = source.getstatementrange(2)\n    assert start == 1\n    assert end == 4\n"], "sample_134": ["    def test_serializer_factory_with_enum(self):\n        value = TextEnum.A\n        serializer = serializer_factory(value)\n        self.assertIsInstance(serializer, EnumSerializer)\n        serialized_value, imports = serializer.serialize()\n        self.assertEqual(serialized_value, \"TestEnum.A['A']\")\n        self.assertEqual(imports, {\"import __main__\"})\n"], "sample_249": ["    def test_test_db_signature(self):\n        test_connection = get_connection_copy()\n        db_creation = BaseDatabaseCreation(test_connection)\n        settings_dict = test_connection.settings_dict\n        expected_signature = (\n            settings_dict['HOST'],\n            settings_dict['PORT'],\n            settings_dict['ENGINE'],\n            TEST_DATABASE_PREFIX + settings_dict['NAME'],\n        )\n        self.assertEqual(db_creation.test_db_signature(), expected_signature)\n"], "sample_1192": ["def test_disambiguate():\n    x, y = symbols('x y')\n    ix = Symbol('x', integer=True)\n    vx = Symbol('x')\n    assert disambiguate(vx + ix) == (x + x_1,)\n"], "sample_1112": ["def test_is_palindromic():\n    assert is_palindromic(12321)\n    assert not is_palindromic(12345)\n    assert is_palindromic(123321, 10)\n    assert not is_palindromic(123321, 8)\n    assert is_palindromic(0x12321, 16)\n    assert not is_palindromic(0x12345, 16)\n"], "sample_1000": ["def test_octave_code_with_custom_functions():\n    f = Function('f')\n    g = Function('g')\n    custom_functions = {\n        \"f\": \"existing_octave_fcn\",\n        \"g\": [(lambda x: x.is_Matrix, \"my_mat_fcn\"),\n              (lambda x: not x.is_Matrix, \"my_fcn\")]\n    }\n    mat = Matrix([[1, x]])\n    assert mcode(f(x) + g(x) + g(mat), user_functions=custom_functions) == 'existing_octave_fcn(x) + my_fcn(x) + my_mat_fcn([1 x])'\n"], "sample_1001": ["def test_latex_Quaternion():\n    q = Quaternion(1, 2, 3, 4)\n    assert latex(q) == \"1 + 2\\\\mathbf{i} + 3\\\\mathbf{j} + 4\\\\mathbf{k}\"\n"], "sample_870": ["def test_predict_before_fit(kernel):\n    gpr = GaussianProcessRegressor(kernel=kernel)\n    y_mean = gpr.predict(X2)\n    assert y_mean.shape == (X2.shape[0],)\n    y_mean, y_std = gpr.predict(X2, return_std=True)\n    assert y_mean.shape == (X2.shape[0],)\n    assert y_std.shape == (X2.shape[0],)\n    y_mean, y_cov = gpr.predict(X2, return_cov=True)\n    assert y_mean.shape == (X2.shape[0],)\n    assert y_cov.shape == (X2.shape[0], X2.shape[0])\n"], "sample_1186": ["def test_array_derivative():\n    A = ImmutableDenseNDimArray([[x, y], [1, x*y]])\n    B = A.diff(x)\n    assert B == ImmutableDenseNDimArray([[1, 0], [0, y]])\n"], "sample_366": ["    def test_parse_datetime_with_timezone(self):\n        value = \"2022-01-01T12:34:56+03:00\"\n        expected = datetime(2022, 1, 1, 12, 34, 56, tzinfo=get_fixed_timezone(180))\n        self.assertEqual(parse_datetime(value), expected)\n"], "sample_251": ["    def test_expression_wrapper_with_output_field(self):\n        annotated = Book.objects.annotate(\n            price_plus_tax=ExpressionWrapper(F('price') * Decimal('1.08'), output_field=FloatField())\n        )\n        self.assertEqual(annotated[0].price_plus_tax, float(self.b1.price * Decimal('1.08')))\n"], "sample_737": ["def test_hashing_vectorizer_alternate_sign():\n    vectorizer = HashingVectorizer(alternate_sign=True)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n    assert_true((X.data > 0).all())\n    assert_true((X.data < 1).all())\n"], "sample_26": ["def test_section_slicing(self):\n    data = np.arange(24).reshape(2, 3, 4)\n    hdu = fits.ImageHDU(data)\n\n    # Test slicing along each axis\n    assert_equal(hdu.section[0, :, :], data[0, :, :])\n    assert_equal(hdu.section[:, 1, :], data[:, 1, :])\n    assert_equal(hdu.section[:, :, 2], data[:, :, 2])\n\n    # Test slicing with step\n    assert_equal(hdu.section[::2, :, :], data[::2, :, :])\n    assert_equal(hdu.section[:, ::3, :], data[:, ::3, :])\n    assert_equal(hdu.section[:, :, ::4], data[:, :, ::4])\n\n    # Test slicing with negative indices\n    assert_equal(hdu.section[-1, :, :], data[-1, :, :])\n    assert_equal(hdu.section[:, -2, :], data[:, -2, :])\n    assert_equal(hdu.section[:, :, -3], data[:, :, -3])\n\n    # Test slicing with a combination of positive and negative indices\n    assert_equal(hdu.section[1, -2, :], data[1, -2, :])\n    assert_equal(hdu.section[-1, 2, ::2], data[-1, 2, ::2])\n\n    # Test slicing with Ellipsis\n    assert_equal(hdu.section[..., 2], data[..., 2])\n    assert_equal(hdu.section[1, ..., 2], data[1, ..., 2])\n\n    # Test slicing with a combination of Ellipsis and other indices\n    assert_equal(hdu.section[1, ..., 2:], data[1, ..., 2:])\n    assert_equal(hdu.section[..., 2:, 1], data[..., 2:, 1])\n\n    # Test slicing with boolean indices\n    bool"], "sample_902": ["def test_pipeline_with_none_transformer():\n    # Test that a pipeline with a None transformer works correctly\n    pipeline = Pipeline([\n        ('transformer1', Transf()),\n        ('none_transformer', None),\n        ('transformer2', Transf())\n    ])\n\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n\n    pipeline.fit(X, y)\n    X_transformed = pipeline.transform(X)\n\n    assert_array_equal(X_transformed, X)\n"], "sample_417": ["    def test_floatformat_with_arg(self):\n        output = self.engine.render_to_string(\n            \"floatformat02\", {\"c\": 34.23234, \"d\": 34.00000}\n        )\n        self.assertEqual(output, \"34.232 34.000\")\n"], "sample_790": ["def test_kernel_pca_precomputed_kernel():\n    # Test KernelPCA with precomputed kernel\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    K = rbf_kernel(X)\n    kpca = KernelPCA(n_components=2, kernel='precomputed')\n    X_transformed = kpca.fit_transform(K)\n    assert_equal(X_transformed.shape, (3, 2))\n"], "sample_681": ["def test_log_cli_enabled(pytester: Testdir) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import logging\n        import pytest\n\n            caplog.set_level(logging.INFO)\n            logging.info(\"Test log message\")\n            assert \"Test log message\" in caplog.text\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n"], "sample_904": ["def test_standard_domain_get_full_qualified_name(app):\n    domain = StandardDomain(app.env)\n    node = pending_xref('', reftype='option', reftarget='-o output', std:program='sphinx-build')\n    assert domain.get_full_qualified_name(node) == 'sphinx-build.-o'\n"], "sample_2": ["def test_ccddata_header_setter():\n    ccd = create_ccd_data()\n    new_header = fits.Header({'new_key': 'new_value'})\n    ccd.header = new_header\n    assert ccd.header is new_header\n    assert ccd.meta is new_header\n"], "sample_135": ["    def test_date_format_with_time_specifiers(self):\n        dt = datetime(2022, 1, 1, 12, 30, 45)\n        with self.assertRaises(TypeError):\n            format(dt, 'jS F Y H:i')\n"], "sample_356": ["def test_generate_altered_order_with_respect_to(self):\n    changes = self.get_changes(\n        [self.author_with_book],\n        [self.author_with_book_order_wrt],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterOrderWithRespectTo\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Author\", order_with_respect_to=\"book\")\n"], "sample_294": ["def test_process_view_with_bad_origin(self):\n    req = self._get_GET_csrf_cookie_request()\n    req.META['HTTP_ORIGIN'] = 'http://evil.com'\n    response = self.middleware.process_view(req, token_view, (), {})\n    self.assertEqual(response.status_code, 403)\n    self.assertEqual(response.reason_phrase, REASON_BAD_ORIGIN % 'http://evil.com')\n"], "sample_699": ["def test_get_checker(pytester: Pytester) -> None:\n    checker = _get_checker()\n    assert checker.check_output(\"1.0\", \"1.0000000000000001\", checker.NUMBER)\n    assert checker.check_output(\"u'text'\", \"'text'\", checker.ALLOW_UNICODE)\n    assert checker.check_output(\"b'bytes'\", \"'bytes'\", checker.ALLOW_BYTES)\n"], "sample_1048": ["def test_parabola_intersection_with_line():\n    p1 = Parabola(Point(0, 0), Line(Point(5, 8), Point(7, 8)))\n    l1 = Line(Point(1, -2), Point(-1, -2))\n    assert p1.intersection(l1) == [Point2D(-4, -2), Point2D(4, -2)]\n"], "sample_1165": ["def test_quaternion_division():\n    q1 = Quaternion(1, 2, 3, 4)\n    q2 = Quaternion(5, 6, 7, 8)\n    result = q1 / q2\n    expected = q1 * q2.inverse()\n    assert result == expected\n"], "sample_784": ["def test_calibration_curve_normalize():\n    y_true = np.array([0, 0, 1, 1])\n    y_prob = np.array([0.1, 0.3, 0.8, 0.9])\n    prob_true, prob_pred = calibration_curve(y_true, y_prob, normalize=True)\n    assert_array_almost_equal(prob_pred, [0.2, 0.8])\n    assert_array_almost_equal(prob_true, [0.0, 1.0])\n"], "sample_230": ["def test_json_field_encoder(self):\n    class TestForm(Form):\n        json_field = JSONField(encoder=DjangoJSONEncoder)\n\n    data = {'json_field': {'key': 'value'}}\n    form = TestForm(data)\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data['json_field'], {'key': 'value'})\n    self.assertEqual(form.as_p(), '<p><label for=\"id_json_field\">Json field:</label> <textarea name=\"json_field\" cols=\"40\" rows=\"10\" required id=\"id_json_field\">{\"key\": \"value\"}</textarea></p>')\n"], "sample_644": ["def test_check_import_as_rename(self):\n    \"\"\"Test the _check_import_as_rename method.\"\"\"\n    node = astroid.parse(\"import os as os\").body[0]\n    with self.assertAddsMessages(\n        MessageTest(\"useless-import-alias\", node=node, confidence=HIGH)\n    ):\n        self.checker._check_import_as_rename(node)\n"], "sample_227": ["    def test_generic_relation_filter(self):\n        bookmark_admin = BookmarkAdminWithGenericRelationFilter(Bookmark, site)\n        request = self.request_factory.get('/')\n        request.user = self.alfred\n        changelist = bookmark_admin.get_changelist_instance(request)\n        filters = changelist.get_filters(request)\n        filter_spec = filters['content_object__title']\n        choices = list(filter_spec.choices(changelist))\n        self.assertEqual(len(choices), 4)\n        self.assertEqual(choices[0]['display'], 'Djangonaut: an art of living')\n        self.assertEqual(choices[1]['display'], 'Django: a biography')\n        self.assertEqual(choices[2]['display'], 'The Django Book')\n        self.assertEqual(choices[3]['display'], 'Guitar for dummies')\n"], "sample_228": ["def test_formset_factory_with_custom_kwargs(self):\n    CustomKwargFormSet = formset_factory(CustomKwargForm, formset=BaseFormSet, extra=2, form_kwargs={'custom_kwarg': 'test'})\n    formset = CustomKwargFormSet()\n    for form in formset:\n        self.assertEqual(form.custom_kwarg, 'test')\n"], "sample_370": ["def test_forward_many_to_one_descriptor_get_object(self):\n    # Test the get_object method of ForwardManyToOneDescriptor\n    author = Author.objects.get(name='Charlotte')\n    book = author.first_book\n    self.assertEqual(book.title, 'Poems')\n\n    # Test the case when the related object does not exist\n    author = Author.objects.get(name='Anne')\n    author.first_book = None\n    author.save()\n    with self.assertRaises(Author.first_book.RelatedObjectDoesNotExist):\n        author.first_book\n"], "sample_954": ["def test_nested_inline_transform(app, status, warning):\n    from sphinx.writers.manpage import NestedInlineTransform\n    from docutils import nodes\n\n    # Create a simple document with nested inline nodes\n    document = nodes.document()\n    paragraph = nodes.paragraph()\n    strong = nodes.strong()\n    emphasis = nodes.emphasis(text='var')\n    literal = nodes.literal(text='1')\n    strong.append(nodes.Text('foo='))\n    strong.append(emphasis)\n    strong.append(nodes.Text(' &bar='))\n    strong.append(literal)\n    paragraph.append(strong)\n    document.append(paragraph)\n\n    # Apply the NestedInlineTransform\n    transform = NestedInlineTransform(document)\n    transform.apply()\n\n    # Check the result\n    assert len(paragraph) == 4\n    assert isinstance(paragraph[0], nodes.strong)\n    assert paragraph[0].astext() == 'foo='\n    assert isinstance(paragraph[1], nodes.emphasis)\n    assert paragraph[1].astext() == 'var'\n    assert isinstance(paragraph[2], nodes.strong)\n    assert paragraph[2].astext() == '&bar='\n    assert isinstance(paragraph[3], nodes.literal)\n    assert paragraph[3].astext() == '1'\n"], "sample_340": ["    def test_check_consistent_history(self):\n        \"\"\"\n        Test that check_consistent_history raises InconsistentMigrationHistory\n        if any applied migrations have unapplied dependencies.\n        \"\"\"\n        # Create a migration graph with an applied migration that depends on an\n        # unapplied migration.\n        self.write_migration(\n            '0001_initial',\n            \"\"\"\n            from django.db import migrations\n\n            class Migration(migrations.Migration):\n                dependencies = [\n                    ('app', '0002_second'),\n                ]\n                operations = []\n            \"\"\",\n        )\n        self.write_migration(\n            '0002_second',\n            \"\"\"\n            from django.db import migrations\n\n            class Migration(migrations.Migration):\n                dependencies = []\n                operations = []\n            \"\"\",\n        )\n        self.migrate()\n        # Check that check_consistent_history raises InconsistentMigrationHistory.\n        loader = MigrationLoader(connection)\n        with self.assertRaises(InconsistentMigrationHistory):\n            loader.check_consistent_history(connection)\n"], "sample_419": ["def test_formset_with_custom_kwarg(self):\n    CustomKwargFormSet = formset_factory(CustomKwargForm, formset=BaseFormSet, extra=2)\n    formset = CustomKwargFormSet(form_kwargs={\"custom_kwarg\": \"test\"})\n    for form in formset:\n        self.assertEqual(form.custom_kwarg, \"test\")\n"], "sample_963": ["def test_restify():\n    assert restify(MyClass1) == ':py:class:`test_util_typing.MyClass1`'\n    assert restify(MyClass2) == ':py:class:`test_util_typing.MyClass2`'\n    assert restify(MyInt) == ':py:class:`test_util_typing.MyInt`'\n    assert restify(MyList[int]) == ':py:class:`test_util_typing.MyList`\\\\ [:py:class:`int`]'\n    assert restify(Optional[int]) == ':py:obj:`~typing.Optional`\\\\ [:py:class:`int`]'\n    assert restify(Union[int, str]) == ':py:obj:`~typing.Union`\\\\ [:py:class:`int`, :py:class:`str`]'\n    assert restify(Callable[[int], str]) == ':py:obj:`~typing.Callable`\\\\ [[:py:class:`int`], :py:class:`str`]'\n    assert restify(Struct('i')) == ':py:class:`struct.Struct`'\n    assert restify(TracebackType) == ':py:class:`types.TracebackType`'\n    assert restify(BrokenType) == \"<class 'test_util_typing.BrokenType'>\"\n"], "sample_1090": ["compilation error"], "sample_268": ["    def test_zip_imported_module(self):\n        zip_filename = self.temporary_file('test.zip')\n        with zipfile.ZipFile(zip_filename, 'w') as zf:\n            zf.writestr('test_module.py', 'print(\"Hello, World!\")')\n        sys.path.insert(0, str(zip_filename))\n        self.addCleanup(sys.path.remove, str(zip_filename))\n        self.import_and_cleanup('test_module')\n        self.assertFileFound(zip_filename)\n"], "sample_63": ["def test_render_to_string_with_context(self):\n    template_name = 'test_template.html'\n    context = {'key': 'value'}\n    rendered = self.engine.render_to_string(template_name, context)\n    self.assertIn('value', rendered)\n"], "sample_1039": ["def test_print_MatrixSymbol():\n    A = MatrixSymbol('A', 2, 2)\n    assert mathml(A, printer='presentation') == '<mi mathvariant=\"bold\">A</mi>'\n"], "sample_361": ["    def test_urlize(self):\n        self.check_output(urlize, 'http://example.com', '<a href=\"http://example.com\">http://example.com</a>')\n        self.check_output(urlize, 'www.example.com', '<a href=\"http://www.example.com\">www.example.com</a>')\n        self.check_output(urlize, 'example@example.com', '<a href=\"mailto:example@example.com\">example@example.com</a>')\n        self.check_output(urlize, '(http://example.com)', '(<a href=\"http://example.com\">http://example.com</a>)')\n        self.check_output(urlize, 'http://example.com.', '<a href=\"http://example.com\">http://example.com</a>.')\n        self.check_output(urlize, 'http://example.com/path?query=value', '<a href=\"http://example.com/path?query=value\">http://example.com/path?query=value</a>')\n"], "sample_240": ["    def test_check_token_with_legacy_token(self):\n        user = User.objects.create_user(username='testuser', password='testpassword')\n        now = datetime.now()\n        token_generator = MockedPasswordResetTokenGenerator(now)\n        token = token_generator.make_token(user)\n\n        # Manually modify the token to simulate a legacy token\n        ts_b36, hash_string = token.split(\"-\")\n        legacy_ts_b36 = int_to_base36(int(ts_b36) // (24 * 60 * 60))\n        legacy_token = f\"{legacy_ts_b36}-{hash_string}\"\n\n        self.assertTrue(token_generator.check_token(user, legacy_token))\n"], "sample_651": ["def test_warnings_recorder_pop(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        import warnings\n\n            with pytest.warns(UserWarning) as record:\n                warnings.warn(\"User Warning 1\", UserWarning)\n                warnings.warn(\"User Warning 2\", UserWarning)\n\n            assert len(record) == 2\n            assert str(record.pop(UserWarning).message) == \"User Warning 1\"\n            assert len(record) == 1\n            assert str(record.pop(UserWarning).message) == \"User Warning 2\"\n            assert len(record) == 0\n\n            with pytest.raises(AssertionError):\n                record.pop(UserWarning)\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n"], "sample_112": ["def test_prepopulated_fields_js(self):\n    \"\"\"Test the prepopulated_fields_js function.\"\"\"\n    # Create a mock context\n    context = {\n        'adminform': ModelAdmin(Article, site).get_form(self.request)(instance=self.article),\n        'inline_admin_formsets': [\n            [ModelAdmin(Question, site).get_formset(self.request)(instance=self.article)]\n        ]\n    }\n\n    # Call the function\n    result = prepopulated_fields_js(context)\n\n    # Check that the function returns the expected context\n    self.assertIn('prepopulated_fields', result)\n    self.assertIn('prepopulated_fields_json', result)\n\n    # Check that the prepopulated_fields_json is a valid JSON string\n    import json\n    json.loads(result['prepopulated_fields_json'])\n"], "sample_900": ["def test_mlp_classifier_activation(activation):\n    clf = MLPClassifier(activation=activation, random_state=0, max_iter=100)\n    clf.fit(X_iris, y_iris)\n    assert clf.score(X_iris, y_iris) > 0.9\n"], "sample_533": ["def test_contour_labeler_event_handler():\n    fig, ax = plt.subplots()\n    X, Y = np.meshgrid(np.linspace(-3, 3, 256), np.linspace(-3, 3, 256))\n    Z = (1 - X/2 + X**5 + Y**3) * np.exp(-X**2 - Y**2)\n    cs = ax.contour(X, Y, Z)\n\n    # Test button_press_event\n    event = type('Event', (), {'name': 'button_press_event', 'button': 1, 'x': 0, 'y': 0, 'inaxes': ax})\n    _contour_labeler_event_handler(cs, inline=True, inline_spacing=5, event=event)\n    assert len(cs.labelTexts) == 1\n\n    # Test key_press_event\n    event = type('Event', (), {'name': 'key_press_event', 'key': 'a', 'inaxes': ax})\n    _contour_labeler_event_handler(cs, inline=True, inline_spacing=5, event=event)\n    assert len(cs.labelTexts) == 2\n\n    # Test button_press_event to remove label\n    event = type('Event', (), {'name': 'button_press_event', 'button': 3, 'inaxes': ax})\n    _contour_labeler_event_handler(cs, inline=True, inline_spacing=5, event=event)\n    assert len(cs.labelTexts) == 1\n\n    # Test key_press_event to remove label\n    event = type('Event', (), {'name': 'key_press_event', 'key': 'backspace', 'inaxes': ax})\n    _contour_labeler_event_handler(cs, inline=True, inline_spacing=5, event=event)\n    assert len(cs.labelTexts) == 0\n\n    plt.close(fig)\n"], "sample_578": ["def test_bar_color(self):\n    variables = {\"x\": [1, 2, 3], \"y\": [4, 5, 6]}\n    mark_kws = {\"color\": \"red\"}\n    layer_kws = {}\n\n    bars = self.plot_bars(variables, mark_kws, layer_kws)\n\n    for bar in bars:\n        assert_array_equal(bar.get_facecolor(), to_rgba(\"red\"))\n"], "sample_126": ["def test_generate_altered_managers_with_custom_queryset_and_manager(self):\n    before_states = [self.other_pony]\n    after_states = [self.other_pony_food]\n    changes = self.get_changes(before_states, after_states)\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AlterModelManagers'])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0,\n                                   name='Pony',\n                                   managers=[\n                                       ('food_qs', FoodQuerySet.as_manager()),\n                                       ('food_mgr', FoodManager('a', 'b')),\n                                       ('food_mgr_kwargs', FoodManager('x', 'y', 3, 4)),\n                                   ])\n"], "sample_262": ["def test_lazy_object_initialization(self):\n        return \"Test String\"\n\n    lazy_obj = SimpleLazyObject(setup_func)\n    self.assertEqual(lazy_obj._wrapped, empty)\n    self.assertEqual(str(lazy_obj), \"Test String\")\n    self.assertIsNot(lazy_obj._wrapped, empty)\n"], "sample_148": ["def test_collect_with_related_objects(self):\n    self._connect(1, 0)\n    self._connect(2, 0)\n    self._connect(3, 1)\n    self._collect(0)\n    self._check([0, [1, [3], 2]])\n"], "sample_722": ["def test_kmeans_predict_csr():\n    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X_csr)\n    labels = kmeans.predict(X_csr)\n    assert_array_equal(labels, true_labels)\n"], "sample_989": ["def test_integer_nthroot():\n    assert integer_nthroot(8, 3) == (2, True)\n    assert integer_nthroot(27, 3) == (3, True)\n    assert integer_nthroot(26, 3) == (3, False)\n"], "sample_695": ["def test_iterparentnodeids(nodeid: str, expected: List[str]) -> None:\n    result = list(nodes.iterparentnodeids(nodeid))\n    assert result == expected\n"], "sample_139": ["def test_get_changelist_instance_with_search_fields(self):\n    request = self._mocked_authenticated_request('/admin/admin_changelist/child/', self.superuser)\n    request.GET = {SEARCH_VAR: 'test'}\n    cl = ChildAdmin(Child, custom_site).get_changelist_instance(request)\n    self.assertEqual(cl.search_fields, ['name', 'parent__name'])\n    self.assertEqual(cl.query, 'test')\n"], "sample_938": ["def test_default_man_pages(app):\n    config = Config({\n        'project': 'Test Project',\n        'release': '1.0',\n        'author': 'Test Author',\n        'master_doc': 'index'\n    })\n    result = default_man_pages(config)\n    assert result == [('index', 'testproject', 'Test Project 1.0', ['Test Author'], 1)]\n"], "sample_7": ["def test_column_with_quantity_data(self):\n    data = [1, 2, 3] * u.m\n    col = table.Column(data=data, name='distance')\n    assert_array_equal(col.data, [1, 2, 3])\n    assert col.unit == u.m\n"], "sample_503": ["def test_line2d_set_data():\n    line = mlines.Line2D([1, 2, 3], [4, 5, 6])\n    line.set_data([7, 8, 9], [10, 11, 12])\n    assert_array_equal(line.get_xdata(), [7, 8, 9])\n    assert_array_equal(line.get_ydata(), [10, 11, 12])\n"], "sample_632": ["def test_ignore_signatures():\n    linter = PyLinter()\n    linter.set_option(\"ignore-signatures\", True)\n    checker = similar.SimilarChecker(linter)\n    checker.open()\n    with open(SIMILAR6) as stream:\n        checker.process_module(stream)\n    checker.close()\n    assert linter.stats[\"nb_duplicated_lines\"] == 0\n"], "sample_372": ["def test_is_callback(self):\n    resolver = get_resolver()\n    self.assertTrue(resolver._is_callback('urlpatterns_reverse.views.empty_view'))\n    self.assertFalse(resolver._is_callback('nonexistent_view'))\n"], "sample_1046": ["def test_tensor_mul_with_scalar():\n    Lorentz = TensorIndexType('Lorentz', dummy_fmt='L')\n    i, j = tensor_indices('i,j', Lorentz)\n    A = tensorhead('A', [Lorentz]*2, [[1]*2])\n    t = A(i, j) * 2\n    assert t == 2 * A(i, j)\n"], "sample_412": ["def test_escapejs(self):\n    self.check_output(escapejs, \"test\", \"test\")\n    self.check_output(escapejs, \"test'test\", \"test\\\\u0027test\")\n    self.check_output(escapejs, \"test\\\"test\", \"test\\\\u0022test\")\n    self.check_output(escapejs, \"test>test\", \"test\\\\u003Etest\")\n    self.check_output(escapejs, \"test<test\", \"test\\\\u003Ctest\")\n    self.check_output(escapejs, \"test&test\", \"test\\\\u0026test\")\n    self.check_output(escapejs, \"test=test\", \"test\\\\u003Dtest\")\n    self.check_output(escapejs, \"test-test\", \"test\\\\u002Dtest\")\n    self.check_output(escapejs, \"test;test\", \"test\\\\u003Btest\")\n    self.check_output(escapejs, \"test`test\", \"test\\\\u0060test\")\n    self.check_output(escapejs, \"test\\u2028test\", \"test\\\\u2028test\")\n    self.check_output(escapejs, \"test\\u2029test\", \"test\\\\u2029test\")\n    self.check_output(escapejs, \"\\x00test\", \"\\\\u0000test\")\n"], "sample_408": ["def test_generate_altered_db_table(self):\n    changes = self.get_changes(\n        [self.author_with_db_table_options],\n        [self.author_with_new_db_table_options],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelTable\"])\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, name=\"Author\", table=\"author_two\"\n    )\n"], "sample_1178": ["def test_augmented_assignment_classes():\n    assert aug_assign(x, '+', y) == AddAugmentedAssignment(x, y)\n    assert aug_assign(x, '-', y) == SubAugmentedAssignment(x, y)\n    assert aug_assign(x, '*', y) == MulAugmentedAssignment(x, y)\n    assert aug_assign(x, '/', y) == DivAugmentedAssignment(x, y)\n    assert aug_assign(x, '%', y) == ModAugmentedAssignment(x, y)\n"], "sample_354": ["def test_create_superuser_with_invalid_password(self):\n    out = StringIO()\n    call_command('createsuperuser', username='bob', stdin=MockTTY(), stdout=out)\n    self.assertIn('Bypass password validation and create user anyway? [y/N]: ', out.getvalue())\n    self.assertIn('Superuser created successfully.', out.getvalue())\n"], "sample_789": ["def test_adaboost_classifier_with_sample_weights():\n    X, y = iris.data, iris.target\n    sample_weight = np.ones(len(y)) / len(y)\n    clf = AdaBoostClassifier(n_estimators=10, random_state=rng)\n    clf.fit(X, y, sample_weight=sample_weight)\n    assert_equal(len(clf.estimators_), 10)\n    assert_array_less(clf.estimator_errors_, 0.5)\n    assert_array_less(clf.feature_importances_, 1.0)\n    assert_array_less(0.0, clf.feature_importances_)\n    assert_equal(clf.feature_importances_.shape, (X.shape[1],))\n"], "sample_567": ["def test_annotation_contains():\n    fig, ax = plt.subplots()\n    ann = Annotation(\"Test\", xy=(0.5, 0.5), xytext=(0.6, 0.6), xycoords='data')\n    ax.add_artist(ann)\n\n    event = MouseEvent('button_press_event', fig.canvas, 0, 0, button=1, xdata=0.55, ydata=0.55)\n    contains, _ = ann.contains(event)\n    assert contains\n\n    event = MouseEvent('button_press_event', fig.canvas, 0, 0, button=1, xdata=0.7, ydata=0.7)\n    contains, _ = ann.contains(event)\n    assert not contains\n"], "sample_543": ["def test_button_callback(ax):\n    callback = mock.Mock()\n    button = widgets.Button(ax, 'Test')\n    button.on_clicked(callback)\n    event = mock_event('button_press_event', ax)\n    do_event(button, event)\n    event = mock_event('button_release_event', ax)\n    do_event(button, event)\n    callback.assert_called_once()\n"], "sample_344": ["    def test_rename_field(self):\n        state = ProjectState()\n        state.add_model(ModelState('app', 'Model', {'old_field': models.CharField(max_length=10)}))\n        state.rename_field('app', 'model', 'old_field', 'new_field')\n        self.assertIn('new_field', state.models['app', 'model'].fields)\n        self.assertNotIn('old_field', state.models['app', 'model'].fields)\n"], "sample_307": ["    def test_date_format_with_time_specifiers(self):\n        dt = datetime(2022, 1, 1, 12, 30, 45)\n        with self.assertRaises(TypeError):\n            format(dt, 'jS F Y H:i')\n"], "sample_613": ["def test_consolidate_slices():\n    slices = [slice(0, 5), slice(5, 10), slice(10, 15, 2)]\n    result = _consolidate_slices(slices)\n    assert result == [slice(0, 10), slice(10, 15, 2)]\n\n    slices = [slice(0, 5), slice(6, 10), slice(10, 15, 2)]\n    result = _consolidate_slices(slices)\n    assert result == slices\n\n    slices = [slice(0, 5), 10]\n    with pytest.raises(ValueError):\n        _consolidate_slices(slices)\n"], "sample_966": ["def test_parse_annotation(app):\n    env = app.builder.env\n    annotation = \"List[Union[int, str]]\"\n    result = _parse_annotation(annotation, env)\n    expected = [pending_xref('', 'List', refdomain='py', reftype='class', reftarget='typing.List'),\n                addnodes.desc_sig_punctuation('', '['),\n                pending_xref('', 'Union', refdomain='py', reftype='class', reftarget='typing.Union'),\n                addnodes.desc_sig_punctuation('', '['),\n                pending_xref('', 'int', refdomain='py', reftype='class', reftarget='int'),\n                addnodes.desc_sig_punctuation('', ','),\n                addnodes.desc_sig_space(),\n                pending_xref('', 'str', refdomain='py', reftype='class', reftarget='str'),\n                addnodes.desc_sig_punctuation('', ']'),\n                addnodes.desc_sig_punctuation('', ']')]\n    assert_node(result, expected)\n"], "sample_282": ["    def test_bound_field_str(self):\n        form = ComplexFieldForm(data={'field1_0': 'John', 'field1_1': ['J', 'P'], 'field1_2_0': '2022-01-01', 'field1_2_1': '12:00:00'})\n        bound_field = form['field1']\n        self.assertEqual(str(bound_field), bound_field.as_widget())\n"], "sample_1077": ["def test_complex_region_intersection():\n    a = Interval(2, 3)\n    b = Interval(4, 6)\n    c = Interval(1, 8)\n    c1 = ComplexRegion(a*b)\n    c2 = ComplexRegion(Union(a*b, b*c))\n    intersection = c1.intersect(c2)\n    assert intersection == c1\n"], "sample_58": ["def test_form_initialization(self):\n    data = {'first_name': 'John', 'last_name': 'Doe', 'birthday': '1990-01-01'}\n    form = Person(data=data)\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data, data)\n"], "sample_401": ["def test_formset_with_custom_kwargs(self):\n    CustomKwargFormSet = formset_factory(CustomKwargForm, formset=BaseFormSet, extra=2)\n    formset = CustomKwargFormSet(form_kwargs={'custom_kwarg': 'test'})\n    for form in formset:\n        self.assertEqual(form.custom_kwarg, 'test')\n"], "sample_573": ["def test_polyfit_with_groupby(self, df):\n    groupby = GroupBy(df, \"color\")\n    stat = PolyFit(order=2, gridsize=100)\n    result = stat(df, groupby, None, None)\n\n    assert isinstance(result, pd.DataFrame)\n    assert \"x\" in result.columns\n    assert \"y\" in result.columns\n    assert len(result) == 3 * stat.gridsize  # 3 groups in the test data\n"], "sample_474": ["    def setUpTestData(cls):\n        cls.john = Author.objects.create(name=\"John Smith\", alias=\"smithj\")\n        cls.elena = Author.objects.create(name=\"\u00c9lena Jordan\", alias=\"elena\")\n        cls.rhonda = Author.objects.create(name=\"Rhonda\")\n"], "sample_468": ["def test_request_context_bind_template(self):\n    request = HttpRequest()\n    engine = Engine()\n    template = Template(\"\", engine=engine)\n    context = RequestContext(request)\n\n    with mock.patch.object(engine, 'template_context_processors', [lambda r: {'processor_key': 'processor_value'}]):\n        with context.bind_template(template):\n            self.assertEqual(context['processor_key'], 'processor_value')\n        self.assertNotIn('processor_key', context)\n"], "sample_939": ["compilation error"], "sample_1023": ["def test_cycle_length():\n    func = lambda i: (i**2 + 1) % 51\n    mu, lam = next(cycle_length(func, 4))\n    assert mu == 2 and lam == 6\n"], "sample_777": ["def test_classification_toy_with_sample_weight(presort, loss):\n    # Check classification on a toy dataset with sample weights.\n    sample_weight = np.array([1, 1, 1, 2, 2, 2])\n    clf = GradientBoostingClassifier(loss=loss, n_estimators=10,\n                                     random_state=1, presort=presort)\n\n    clf.fit(X, y, sample_weight=sample_weight)\n    assert_array_equal(clf.predict(T), true_result)\n    assert_equal(10, len(clf.estimators_))\n\n    deviance_decrease = (clf.train_score_[:-1] - clf.train_score_[1:])\n    assert np.any(deviance_decrease >= 0.0)\n\n    leaves = clf.apply(X)\n    assert_equal(leaves.shape, (6, 10, 1))\n"], "sample_505": ["def test_date_ticker_factory():\n    span = 10\n    tz = dateutil.tz.gettz('UTC')\n    numticks = 5\n    locator, formatter = mdates.date_ticker_factory(span, tz, numticks)\n    assert isinstance(locator, mdates.DayLocator)\n    assert isinstance(formatter, mdates.DateFormatter)\n    assert formatter.fmt == '%b %d'\n"], "sample_899": ["    def test_check_estimator_sparse_data(self):\n        estimator = NoSparseClassifier()\n        with self.assertRaises(ValueError):\n            check_estimator_sparse_data(\"NoSparseClassifier\", estimator)\n"], "sample_721": ["def test_check_memory():\n    # Test with None\n    memory = check_memory(None)\n    assert isinstance(memory, sklearn.externals.joblib.Memory)\n\n    # Test with a string\n    memory = check_memory('cache_dir')\n    assert isinstance(memory, sklearn.externals.joblib.Memory)\n    assert memory.location == 'cache_dir'\n\n    # Test with a joblib.Memory object\n    memory_obj = sklearn.externals.joblib.Memory(location='cache_dir')\n    memory = check_memory(memory_obj)\n    assert memory is memory_obj\n\n    # Test with an invalid object\n    with pytest.raises(ValueError):\n        check_memory('invalid_object')\n"], "sample_915": ["def test_signature_from_str():\n    sig = inspect.signature_from_str(\"(a: int, b: str = 'default') -> bool\")\n    assert str(sig) == \"(a: int, b: str = 'default') -> bool\"\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.parameters['b'].default == 'default'\n    assert sig.return_annotation == bool\n"], "sample_649": ["def test_log_cli_enabled(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import logging\n\n            caplog._config.getoption = lambda x: 'INFO' if x == '--log-cli-level' else None\n            caplog._config.getini = lambda x: True if x == 'log_cli' else None\n            caplog._config.pluginmanager.get_plugin = lambda x: TerminalReporter(cast(CaptureManager, None)) if x == 'terminalreporter' else None\n\n            assert caplog._log_cli_enabled() == True\n        \"\"\"\n    )\n\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n"], "sample_680": ["def test_evaluate_xfail_marks(self, pytestconfig):\n    @pytest.mark.xfail(reason=\"Expected failure\")\n        assert False\n\n    item = pytestconfig.getitemcollector().collect(test_func)\n    xfailed = evaluate_xfail_marks(item)\n    assert xfailed is not None\n    assert xfailed.reason == \"Expected failure\"\n    assert xfailed.run is True\n    assert xfailed.strict is False\n    assert xfailed.raises is None\n"], "sample_551": ["def test_line_collection_2d_to_3d():\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n\n    x = np.linspace(0, 1, 100)\n    y = np.sin(x * 2 * np.pi) / 2 + 0.5\n    z = np.linspace(0, 1, 100)\n\n    points = np.array([x, y]).T.reshape(-1, 1, 2)\n    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n\n    lc = art3d.Line3DCollection(segments, zs=z, zdir='y')\n    ax.add_collection(lc)\n\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_zlim(0, 1)\n\n    plt.close(fig)\n"], "sample_839": ["def test_hashing_vectorizer_alternate_sign():\n    vectorizer = HashingVectorizer(alternate_sign=True)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n    assert np.all(np.abs(X.data) == 1)\n    assert np.all(np.diff(np.sort(np.unique(X.data))) == 2)\n"], "sample_782": ["def test_column_transformer_with_sparse_matrix_transformer():\n    X = np.array([[0, 1], [2, 3]])\n    ct = ColumnTransformer([(\"sparse\", SparseMatrixTrans(), [0])])\n    X_transformed = ct.fit_transform(X)\n    assert sparse.issparse(X_transformed)\n    assert_array_equal(X_transformed.toarray(), np.eye(2))\n"], "sample_945": ["def test_parse_annotation():\n    env = Mock()\n    env.config.python_use_unqualified_type_names = False\n    result = _parse_annotation(\"List[int]\", env)\n    assert len(result) == 5\n    assert isinstance(result[0], nodes.Text)\n    assert result[0].astext() == \"List\"\n    assert isinstance(result[1], pending_xref)\n    assert result[1]['reftarget'] == \"List\"\n    assert isinstance(result[2], addnodes.desc_sig_punctuation)\n    assert result[2].astext() == \"[\"\n    assert isinstance(result[3], nodes.Text)\n    assert result[3].astext() == \"int\"\n    assert isinstance(result[4], addnodes.desc_sig_punctuation)\n    assert result[4].astext() == \"]\"\n"], "sample_571": ["def test_regplot_with_numpy_arrays():\n    x = np.array(TestLinearPlotter.df[\"x\"])\n    y = np.array(TestLinearPlotter.df[\"y\"])\n    ax = lm.regplot(x=x, y=y)\n    assert isinstance(ax, mpl.axes.Axes)\n"], "sample_163": ["    def test_login_view_get(self):\n        response = self.client.get(reverse('login'))\n        self.assertEqual(response.status_code, 200)\n        self.assertTemplateUsed(response, 'registration/login.html')\n"], "sample_637": ["    def test_use_symbolic_message_instead(self):\n        with set_config(disable=(\"I0023\",)):\n            self.checker.linter._by_id_managed_msgs = [\n                (\"test_module\", \"I0023\", \"symbolic-message\", 1, False)\n            ]\n            node = self.checker.linter.astroid_cache.parse(\"test_module\")\n            self.checker.process_module(node)\n            self.assertEqual(len(self.checker.messages), 1)\n            msg = self.checker.messages[0]\n            self.assertEqual(msg.symbol, \"use-symbolic-message-instead\")\n            self.assertEqual(msg.line, 1)\n            self.assertEqual(msg.msg, \"'I0023' is cryptic: use '# pylint: enable=symbolic-message' instead\")\n"], "sample_667": ["def test_ensure_relative_to_basetemp(tmp_path_factory):\n    basename = \"test_dir\"\n    result = tmp_path_factory._ensure_relative_to_basetemp(basename)\n    assert result == basename\n\n    with pytest.raises(ValueError):\n        tmp_path_factory._ensure_relative_to_basetemp(\"../invalid_dir\")\n"], "sample_337": ["    def test_compare_masked_tokens(self):\n        # Test that _compare_masked_tokens returns True for equivalent tokens\n        self.assertTrue(equivalent_tokens(MASKED_TEST_SECRET1, MASKED_TEST_SECRET1))\n        self.assertTrue(equivalent_tokens(MASKED_TEST_SECRET2, MASKED_TEST_SECRET2))\n\n        # Test that _compare_masked_tokens returns False for non-equivalent tokens\n        self.assertFalse(equivalent_tokens(MASKED_TEST_SECRET1, MASKED_TEST_SECRET2))\n        self.assertFalse(equivalent_tokens(MASKED_TEST_SECRET2, MASKED_TEST_SECRET1))\n"], "sample_59": ["def test_model_save_base_with_update_fields(self):\n    article = Article.objects.create(title='Test Article', content='Initial content')\n    article.save_base(update_fields=['content'])\n    article.refresh_from_db()\n    self.assertEqual(article.content, 'Initial content')\n    article.content = 'Updated content'\n    article.save_base(update_fields=['content'])\n    article.refresh_from_db()\n    self.assertEqual(article.content, 'Updated content')\n"], "sample_1085": ["def test_integer_nthroot():\n    assert integer_nthroot(8, 3) == (2, True)\n    assert integer_nthroot(27, 3) == (3, True)\n    assert integer_nthroot(26, 3) == (3, False)\n"], "sample_54": ["    def test_file_response_with_filelike_object(self):\n        content = b'File content'\n        filelike = io.BytesIO(content)\n        response = FileResponse(filelike, as_attachment=True, filename='test.txt')\n        self.assertEqual(response.getvalue(), content)\n        self.assertEqual(response['Content-Disposition'], 'attachment; filename=\"test.txt\"')\n        self.assertEqual(response['Content-Type'], 'text/plain')\n        self.assertEqual(response['Content-Length'], str(len(content)))\n"], "sample_491": ["    def test_bound_field_subwidgets(self):\n        form = FrameworkForm()\n        bound_field = form[\"language\"]\n        subwidgets = bound_field.subwidgets\n        self.assertEqual(len(subwidgets), 2)\n        self.assertEqual(subwidgets[0].data[\"value\"], \"P\")\n        self.assertEqual(subwidgets[1].data[\"value\"], \"J\")\n"], "sample_327": ["def test_json_field_encoder(self):\n    class TestForm(Form):\n        json_field = JSONField(encoder=DjangoJSONEncoder)\n\n    data = {'json_field': {'key': 'value'}}\n    form = TestForm(data)\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data['json_field'], {'key': 'value'})\n    self.assertEqual(form.as_p(), '<p><label for=\"id_json_field\">Json field:</label> <textarea name=\"json_field\" cols=\"40\" rows=\"10\" required id=\"id_json_field\">{\"key\": \"value\"}</textarea></p>')\n"], "sample_450": ["    def test_get_admin_log_for_user(self):\n        response = self.client.get(reverse('admin:index'))\n        self.assertContains(response, 'get_admin_log 10 as admin_log for_user {}'.format(self.user.pk))\n        self.assertContains(response, escape(str(self.a1)))\n"], "sample_856": ["def test_leave_p_out():\n    lpo = LeavePOut(p=2)\n    X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n    y = np.array([1, 2, 3, 4])\n    expected_splits = [\n        (np.array([2, 3]), np.array([0, 1])),\n        (np.array([1, 3]), np.array([0, 2])),\n        (np.array([1, 2]), np.array([0, 3])),\n        (np.array([0, 3]), np.array([1, 2])),\n        (np.array([0, 2]), np.array([1, 3])),\n        (np.array([0, 1]), np.array([2, 3]))\n    ]\n    for i, (train_index, test_index) in enumerate(lpo.split(X)):\n        assert_array_equal(train_index, expected_splits[i][0])\n        assert_array_equal(test_index, expected_splits[i][1])\n"], "sample_875": ["def test_brier_score_loss():\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    expected_score = 0.037\n    assert_almost_equal(brier_score_loss(y_true, y_prob), expected_score)\n"], "sample_980": ["def test_commutes_with():\n    p = Permutation([1, 4, 3, 0, 2, 5])\n    q = Permutation([0, 1, 2, 3, 4, 5])\n    assert p.commutes_with(q) == True\n    q = Permutation([2, 3, 5, 4, 1, 0])\n    assert p.commutes_with(q) == False\n"], "sample_824": ["def test_pairwise_distances_chunked_reduce_func_output_length():\n    X = np.random.RandomState(0).rand(5, 3)\n    r = .2\n\n        neigh = [np.flatnonzero(d < r) for d in D_chunk]\n        avg_dist = (D_chunk * (D_chunk < r)).mean(axis=1)\n        return neigh, avg_dist, avg_dist  # extra output\n\n    gen = pairwise_distances_chunked(X, reduce_func=reduce_func)\n    with assert_raises_regexp(ValueError, \"Expected same length as input: 1\"):\n        next(gen)\n"], "sample_438": ["def test_model_save_and_delete(self):\n    # Test saving a model instance\n    post = Post(title=\"Test Post\")\n    post.save()\n    self.assertIsNotNone(post.id)\n\n    # Test deleting a model instance\n    post_id = post.id\n    post.delete()\n    with self.assertRaises(Post.DoesNotExist):\n        Post.objects.get(id=post_id)\n"], "sample_671": ["def test_xfail_no_run(self, pytestconfig):\n    class DummyItem:\n            self.config = pytestconfig\n            self._store = {}\n\n    item = DummyItem()\n    item._store[evalxfail_key] = MarkEvaluator(item, \"xfail\", \"True\", run=False)\n\n    with pytest.raises(pytest.xfail.Exception):\n        check_xfail_no_run(item)\n"], "sample_564": ["def test_plot_surface_with_custom_facecolors(fig):\n    ax = fig.add_subplot(111, projection='3d')\n    X, Y = np.meshgrid(np.linspace(-1, 1, 10), np.linspace(-1, 1, 10))\n    Z = np.sin(np.sqrt(X**2 + Y**2))\n    facecolors = np.random.rand(10, 10, 4)\n    ax.plot_surface(X, Y, Z, facecolors=facecolors)\n"], "sample_1078": ["def test_indexed_base_strides():\n    A = IndexedBase('A', strides=(2, 3))\n    i, j = symbols('i j', integer=True)\n    assert A[i, j].strides == (2, 3)\n"], "sample_1131": ["def test_print_loggamma():\n    expr = loggamma(x)\n    result = pycode(expr, printer=SciPyPrinter)\n    assert result == \"scipy.special.gammaln(x)\"\n"], "sample_787": ["def test_brier_score_loss():\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    expected_score = 0.037\n    assert_almost_equal(brier_score_loss(y_true, y_prob), expected_score)\n"], "sample_1108": ["def test_is_palindromic():\n    assert is_palindromic([1, 0, 1])\n    assert not is_palindromic('abcbb')\n    assert not is_palindromic('abcbb', 1)\n    assert is_palindromic('abcbb', 1, -1)\n    assert is_palindromic('abcbb', -4, -1)\n"], "sample_820": ["def test_voting_classifier_predict_proba():\n    clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=1)\n    clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n    clf3 = GaussianNB()\n    X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n    y = np.array([1, 1, 1, 2, 2, 2])\n    eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft')\n    eclf = eclf.fit(X, y)\n    proba = eclf.predict_proba(X)\n    assert proba.shape == (6, 2)\n    assert_array_almost_equal(proba.sum(axis=1), np.ones(6))\n"], "sample_221": ["def test_pickleability_with_filters(self):\n    qs = Happening.objects.filter(id=self.happening.id)\n    self.assert_pickles(qs)\n"], "sample_999": ["def test_latex_Quaternion():\n    q = Quaternion(1, 2, 3, 4)\n    assert latex(q) == \"1 + 2\\\\, i + 3\\\\, j + 4\\\\, k\"\n"], "sample_821": ["def test_affinity_propagation_convergence_warning():\n    # Test that a ConvergenceWarning is raised when affinity propagation\n    # does not converge\n    X = np.array([[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0]])\n    af = AffinityPropagation(max_iter=1, convergence_iter=1)\n    with pytest.warns(ConvergenceWarning):\n        af.fit(X)\n    assert_array_equal(af.labels_, [-1] * X.shape[0])\n    assert_array_equal(af.cluster_centers_indices_, [])\n"], "sample_284": ["def test_hashed_name_with_fragment(self):\n    storage.staticfiles_storage.save('test.css', StringIO('body { background: url(image.png?#fragment); }'))\n    hashed_name = storage.staticfiles_storage.hashed_name('test.css')\n    self.assertIn('?#fragment', hashed_name)\n    self.assertPostCondition()\n"], "sample_349": ["    def test_build_attrs(self):\n        field = Album._meta.get_field('band')\n        widget = AutocompleteSelect(field, admin.site)\n        attrs = widget.build_attrs({})\n        self.assertEqual(attrs['data-ajax--url'], '/admin/autocomplete/')\n        self.assertEqual(attrs['data-app-label'], 'admin_widgets')\n        self.assertEqual(attrs['data-model-name'], 'band')\n        self.assertEqual(attrs['data-field-name'], 'band')\n        self.assertEqual(attrs['data-theme'], 'admin-autocomplete')\n        self.assertEqual(attrs['data-allow-clear'], 'true')\n        self.assertEqual(attrs['data-placeholder'], '')\n        self.assertIn('admin-autocomplete', attrs['class'])\n"], "sample_960": ["def test_parse_annotation(app):\n    env = app.builder.env\n    result = _parse_annotation(\"List[int]\", env)\n    assert len(result) == 3\n    assert isinstance(result[0], pending_xref)\n    assert result[0].get('reftarget') == 'List'\n    assert result[1].astext() == '['\n    assert isinstance(result[2], pending_xref)\n    assert result[2].get('reftarget') == 'int'\n"], "sample_4": ["def test_write_html_table_latex_names(self, cosmo, tmp_path):\n    \"\"\"Test writing a Cosmology to an HTML table with latex names.\"\"\"\n    file = tmp_path / \"cosmo.html\"\n    write_html_table(cosmo, file, latex_names=True)\n    assert file.exists()\n\n    # Read the table back in and check that the column names are correct\n    table = QTable.read(file, format=\"ascii.html\")\n    for name, latex in _FORMAT_TABLE.items():\n        if name in cosmo.__parameters__:\n            assert latex in table.colnames\n"], "sample_464": ["def test_file_response_with_unseekable_file(self):\n    content = b\"This is a test content.\"\n    unseekable_file = UnseekableBytesIO(content)\n    response = FileResponse(unseekable_file)\n    self.assertEqual(response.getvalue(), content)\n"], "sample_1055": ["def test_decipher_bifid():\n    msg = \"HELLO WORLD\"\n    key = \"KEY\"\n    symbols = bifid10\n    ct = encipher_bifid(msg, key, symbols)\n    pt = decipher_bifid(ct, key, symbols)\n    assert pt == msg\n"], "sample_1070": ["def test_lambertw_fdiff():\n    x = symbols('x')\n    k = symbols('k')\n    assert LambertW(x).fdiff() == LambertW(x)/(x*(1 + LambertW(x)))\n    assert LambertW(x, k).fdiff() == LambertW(x, k)/(x*(1 + LambertW(x, k)))\n    raises(ArgumentIndexError, lambda: LambertW(x).fdiff(2))\n"], "sample_1127": ["def test_coset_as_list():\n    a = Permutation(1, 2)\n    b = Permutation(0, 1)\n    G = PermutationGroup([a, b])\n    cst = Coset(a, G, dir=\"+\")\n    assert cst.as_list() == [Permutation(0, 2, 1), Permutation(1, 2)]\n"], "sample_518": ["def test_fancyarrowpatch_set_positions():\n    arrow = FancyArrowPatch((0, 0), (1, 1))\n    arrow.set_positions((2, 2), (3, 3))\n    assert_array_equal(arrow._posA_posB, [(2, 2), (3, 3)])\n"], "sample_654": ["def test_fixture_request_getfixturevalue(pytester):\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            return 42\n\n            assert my_fixture == 42\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n"], "sample_574": ["def test_continuous_tick_locator(self, x):\n    locator = mpl.ticker.FixedLocator([0.2, 0.5, 0.8])\n    a = self.setup_ticks(x, locator=locator)\n    assert_array_equal(a.get_majorticklocs(), [0.2, 0.5, 0.8])\n"], "sample_648": ["def test_extract_from_with_force_tuple(self, attr):\n    parameterset = (1, 2)\n    force_tuple = True\n    result = getattr(ParameterSet, attr).extract_from(parameterset, force_tuple=force_tuple)\n    assert result.values == parameterset\n    assert result.marks == []\n    assert result.id is None\n"], "sample_596": ["def test_concat_with_dataarray_dim():\n    da1 = DataArray(np.random.rand(3, 4), dims=('x', 'y'), name='a')\n    da2 = DataArray(np.random.rand(3, 4), dims=('x', 'y'), name='a')\n    result = concat([da1, da2], dim=da1.x)\n    assert result.dims == ('x', 'y')\n    assert_array_equal(result.sel(x=slice(0, 3)), da1)\n    assert_array_equal(result.sel(x=slice(3, 6)), da2)\n"], "sample_891": ["def test_roc_curve_drop_intermediate(drop):\n    y_true = np.array([0, 0, 1, 1])\n    y_score = np.array([0.1, 0.4, 0.35, 0.8])\n    fpr, tpr, thresholds = roc_curve(y_true, y_score, drop_intermediate=drop)\n    if drop:\n        assert len(fpr) == 3\n        assert len(tpr) == 3\n        assert len(thresholds) == 3\n    else:\n        assert len(fpr) == 5\n        assert len(tpr) == 5\n        assert len(thresholds) == 5\n"], "sample_229": ["def test_union_with_empty_queryset(self):\n    qs1 = Number.objects.filter(num__gt=5)\n    qs2 = Number.objects.none()\n    union_qs = qs1.union(qs2)\n    self.assertNumbersEqual(union_qs, [6, 7, 8, 9])\n"], "sample_535": ["def test_table_edges():\n    fig, ax = plt.subplots()\n    data = np.array([[1, 2], [3, 4]])\n    table = ax.table(cellText=data, loc='center')\n\n    # Test 'open' edge setting\n    table.edges = 'open'\n    assert all(cell.visible_edges == '' for cell in table.get_celld().values())\n\n    # Test 'closed' edge setting\n    table.edges = 'closed'\n    assert all(cell.visible_edges == 'BRTL' for cell in table.get_celld().values())\n\n    # Test 'horizontal' edge setting\n    table.edges = 'horizontal'\n    assert all(cell.visible_edges == 'BT' for cell in table.get_celld().values())\n\n    # Test 'vertical' edge setting\n    table.edges = 'vertical'\n    assert all(cell.visible_edges == 'RL' for cell in table.get_celld().values())\n\n    # Test custom edge setting\n    table.edges = 'TR'\n    assert all(cell.visible_edges == 'TR' for cell in table.get_celld().values())\n"], "sample_286": ["def test_model_save_base_with_update_fields(self):\n    article = Article.objects.create(title='Test Article', content='Test Content')\n    article.title = 'Updated Title'\n    article.save_base(update_fields=['title'])\n    article.refresh_from_db()\n    self.assertEqual(article.title, 'Updated Title')\n    self.assertEqual(article.content, 'Test Content')\n"], "sample_471": ["    def test_decimal_field_to_python(self):\n        field = DecimalField()\n        self.assertEqual(field.to_python('123.45'), Decimal('123.45'))\n        self.assertEqual(field.to_python('123'), Decimal('123'))\n        self.assertEqual(field.to_python(''), None)\n        self.assertEqual(field.to_python(None), None)\n        with self.assertRaises(ValidationError):\n            field.to_python('abc')\n"], "sample_426": ["    def test_time_strings_customization(self):\n        custom_time_strings = {\n            \"year\": npgettext_lazy(\"%(num)d yr\", \"%(num)d yrs\", \"num\"),\n            \"month\": npgettext_lazy(\"%(num)d mo\", \"%(num)d mos\", \"num\"),\n            \"week\": npgettext_lazy(\"%(num)d wk\", \"%(num)d wks\", \"num\"),\n            \"day\": npgettext_lazy(\"%(num)d d\", \"%(num)d d\", \"num\"),\n            \"hour\": npgettext_lazy(\"%(num)d hr\", \"%(num)d hrs\", \"num\"),\n            \"minute\": npgettext_lazy(\"%(num)d min\", \"%(num)d mins\", \"num\"),\n        }\n        result = timesince(self.t - self.oneweek - 2 * self.oneday - 3 * self.onehour - 4 * self.oneminute, self.t, time_strings=custom_time_strings)\n        self.assertEqual(result, \"1 wk, 2 d, 3 hrs, 4 mins\")\n"], "sample_801": ["def test_set_params():\n    lr = LogisticRegression(C=1.0, penalty='l2')\n    lr.set_params(C=2.0, penalty='l1')\n    assert lr.C == 2.0\n    assert lr.penalty == 'l1'\n"], "sample_283": ["    def test_runshell(self):\n        with mock.patch('subprocess.run') as mock_run:\n            with mock.patch('signal.signal') as mock_signal:\n                client = DatabaseClient(connection)\n                client.runshell(['-c', 'SELECT 1;'])\n                mock_signal.assert_called_with(signal.SIGINT, signal.SIG_IGN)\n                mock_run.assert_called_with([client.executable_name, '-c', 'SELECT 1;'], env=mock.ANY)\n"], "sample_733": ["def test_hashing_vectorizer_alternate_sign():\n    vectorizer = HashingVectorizer(alternate_sign=True)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n    assert_true((X.data > 0).all())\n"], "sample_716": ["def test_ridge_regression_with_sample_weight():\n    X, y = make_regression(n_samples=100, n_features=2, random_state=0)\n    sample_weight = np.random.rand(100)\n    coef_weighted = ridge_regression(X, y, alpha=1.0, sample_weight=sample_weight)\n    coef_unweighted = ridge_regression(X, y, alpha=1.0)\n    assert_true(np.any(coef_weighted != coef_unweighted))\n"], "sample_833": ["def test_logistic_regression_cv_binary():\n    X, y = make_classification(n_samples=100, n_features=20, n_classes=2, random_state=42)\n    clf = LogisticRegressionCV(cv=5, random_state=42)\n    clf.fit(X, y)\n    assert_greater(clf.score(X, y), 0.9)\n    assert_equal(len(clf.Cs_), 10)\n    assert_equal(clf.Cs_.shape, (10,))\n    assert_equal(clf.coef_.shape, (1, 20))\n    assert_equal(clf.intercept_.shape, (1,))\n    assert_equal(clf.scores_.shape, (1, 5, 10))\n    assert_equal(clf.coefs_paths_.shape, (1, 5, 10, 20))\n    assert_equal(clf.n_iter_.shape, (1, 5, 10))\n"], "sample_986": ["def test_evalf_atan():\n    assert NS(atan(1), 15) == \"0.785398163397448\"\n    assert NS(atan(0), 15) == \"0.0\"\n    assert NS(atan(oo), 15) == \"1.57079632679490\"\n    assert NS(atan(ninf), 15) == \"-1.57079632679490\"\n"], "sample_120": ["    def test_uuid_serializer(self):\n        value = uuid.uuid4()\n        serializer = serializer_factory(value)\n        self.assertEqual(serializer.serialize(), (f\"uuid.{repr(value)}\", {\"import uuid\"}))\n"], "sample_594": ["def test_format_timedelta():\n    # Test formatting of timedelta objects\n    td = pd.Timedelta(days=2, hours=3, minutes=4, seconds=5)\n    assert formatting.format_timedelta(td) == \"2 days 03:04:05\"\n    assert formatting.format_timedelta(td, timedelta_format=\"date\") == \"2 days\"\n    assert formatting.format_timedelta(td, timedelta_format=\"time\") == \"03:04:05\"\n"], "sample_1200": ["def test_get_dimensional_expr():\n    # Test get_dimensional_expr method with various expressions\n    assert SI.get_dimensional_expr(meter) == length\n    assert SI.get_dimensional_expr(meter * second) == length * time\n    assert SI.get_dimensional_expr(meter / second) == length / time\n    assert SI.get_dimensional_expr(meter ** 2) == length ** 2\n    assert SI.get_dimensional_expr(sqrt(meter)) == length ** Rational(1, 2)\n    assert SI.get_dimensional_expr(sin(meter)) == length\n    assert SI.get_dimensional_expr(diff(meter, second)) == length / time\n    assert SI.get_dimensional_expr(integrate(meter, second)) == length * time\n    assert SI.get_dimensional_expr(Function('f')(meter)) == S.One\n    assert SI.get_dimensional_expr(Function('f')(meter, second)) == S.One\n"], "sample_13": ["def test_angle_subtraction():\n    a = Angle('10d')\n    b = Angle('5d')\n    c = a - b\n    assert_allclose(c.degree, 5.0)\n"], "sample_921": ["def test_signature_from_str():\n    sig = inspect.signature_from_str(\"(a: int, b: str = 'default', *args, **kwargs) -> None\")\n    assert str(sig) == \"(a: int, b: str = 'default', *args, **kwargs) -> None\"\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].default == 'default'\n    assert sig.parameters['args'].kind == Parameter.VAR_POSITIONAL\n    assert sig.parameters['kwargs'].kind == Parameter.VAR_KEYWORD\n    assert sig.return_annotation == None\n"], "sample_456": ["def test_formset_with_custom_kwargs(self):\n    CustomKwargFormSet = formset_factory(CustomKwargForm, extra=2, form_kwargs={\"custom_kwarg\": \"test\"})\n    formset = CustomKwargFormSet()\n    for form in formset:\n        self.assertEqual(form.custom_kwarg, \"test\")\n"], "sample_585": ["def test_consolidate_slices():\n    slices = [slice(0, 5), slice(5, 10), slice(10, 15, 2)]\n    result = _consolidate_slices(slices)\n    expected = [slice(0, 10), slice(10, 15, 2)]\n    assert result == expected\n"], "sample_147": ["def test_union_with_empty_queryset(self):\n    qs1 = Number.objects.filter(num__gt=5)\n    qs2 = Number.objects.none()\n    union_qs = qs1.union(qs2)\n    self.assertNumbersEqual(union_qs, [6, 7, 8, 9])\n"], "sample_160": ["    def test_format_with_large_decimal(self):\n        number = Decimal('1' + '0' * 201)\n        result = nformat(number, decimal_sep='.', decimal_pos=None, grouping=0, thousand_sep='', force_grouping=False, use_l10n=None)\n        self.assertEqual(result, '1e201')\n"], "sample_1197": ["def test_extend_unit_system():\n    new_unit_system = SI.extend([Quantity('new_unit')], name=\"NewSystem\", description=\"Extended SI with new unit\")\n    assert new_unit_system.name == \"NewSystem\"\n    assert new_unit_system.descr == \"Extended SI with new unit\"\n    assert Quantity('new_unit') in new_unit_system._units\n    assert Quantity('new_unit') in new_unit_system._base_units\n    assert new_unit_system.get_dimension_system() == SI.get_dimension_system()\n"], "sample_751": ["def test_adaboost_classifier_with_sparse_input():\n    X_sparse = csc_matrix(X)\n    clf = AdaBoostClassifier(n_estimators=10, random_state=rng)\n    clf.fit(X_sparse, y_class)\n    assert_array_equal(clf.predict(X_sparse), clf.predict(X))\n"], "sample_892": ["def test_adaboost_classifier_predict_proba():\n    clf = AdaBoostClassifier(n_estimators=10, random_state=rng)\n    clf.fit(iris.data, iris.target)\n    proba = clf.predict_proba(iris.data)\n    assert proba.shape == (iris.target.size, len(np.unique(iris.target)))\n    assert_array_less(0, proba)\n    assert_array_less(proba, 1)\n    assert_array_almost_equal(np.sum(proba, axis=1), np.ones(iris.target.size))\n"], "sample_860": ["def test_check_scalar():\n    # Test with valid input\n    check_scalar(5, \"test_param\", int, min_val=0, max_val=10)\n\n    # Test with invalid type\n    with pytest.raises(TypeError):\n        check_scalar(\"5\", \"test_param\", int)\n\n    # Test with value out of bounds\n    with pytest.raises(ValueError):\n        check_scalar(15, \"test_param\", int, min_val=0, max_val=10)\n"], "sample_995": ["def test_integer_nthroot():\n    assert integer_nthroot(8, 3) == (2, True)\n    assert integer_nthroot(27, 3) == (3, True)\n    assert integer_nthroot(26, 3) == (3, False)\n"], "sample_1205": ["def test_poly_ring_drop_to_ground():\n    R, x, y, z = ring(\"x,y,z\", ZZ)\n    f = x**2 + y**2 + z**2\n    g = f.drop_to_ground(x)\n    assert g == y**2 + z**2 + sqrt(x**2)\n"], "sample_198": ["def test_expression_wrapper(self):\n    expr = ExpressionWrapper(Value(1), output_field=IntegerField())\n    self.assertEqual(str(expr), '1')\n    self.assertEqual(expr.output_field, IntegerField())\n"], "sample_191": ["    def test_zip_imported_module(self):\n        zip_filename = self.temporary_file('test_module.zip')\n        with zipfile.ZipFile(zip_filename, 'w') as zf:\n            zf.writestr('test_module.py', 'print(\"Hello, World!\")')\n        sys.path.insert(0, str(zip_filename))\n        self.addCleanup(sys.path.remove, str(zip_filename))\n        self.import_and_cleanup('test_module')\n        self.assertFileFound(zip_filename)\n"], "sample_629": ["def test_expand_modules():\n    files_or_modules = [\"test_module.py\", \"test_package\"]\n    ignore_list = [\"__pycache__\"]\n    ignore_list_re = [re.compile(\".*_test.py\")]\n    ignore_list_paths_re = [re.compile(\"/tmp/.*\")]\n\n    result, errors = expand_modules(files_or_modules, ignore_list, ignore_list_re, ignore_list_paths_re)\n\n    assert len(result) > 0\n    assert len(errors) == 0\n    assert all(\"path\" in item for item in result)\n    assert all(\"name\" in item for item in result)\n    assert all(\"isarg\" in item for item in result)\n    assert all(\"basepath\" in item for item in result)\n    assert all(\"basename\" in item for item in result)\n"], "sample_537": ["def test_stride_windows_noverlap_greater_than_n(self, shape):\n    x = np.arange(10).reshape(shape)\n    NFFT = 5\n    noverlap = 6\n    with pytest.raises(ValueError, match=\"noverlap must be less than n\"):\n        mlab.stride_windows(x, NFFT, noverlap)\n"], "sample_607": ["def test_detect_parameters():\n    params = plugins.detect_parameters(DummyBackendEntrypoint1.open_dataset)\n    assert params == (\"filename_or_obj\", \"decoder\")\n\n    with pytest.raises(TypeError):\n        plugins.detect_parameters(DummyBackendEntrypointArgs.open_dataset)\n\n    with pytest.raises(TypeError):\n        plugins.detect_parameters(DummyBackendEntrypointKwargs.open_dataset)\n"], "sample_164": ["def test_require_debug_true_filter(self):\n    f = RequireDebugTrue()\n    record = logging.LogRecord('name', logging.INFO, 'pathname', 'lineno', 'msg', [], None)\n    self.assertEqual(f.filter(record), True)\n"], "sample_106": ["    def test_patch_cache_control(self):\n        response = HttpResponse()\n        patch_cache_control(response, max_age=3600, public=True)\n        self.assertEqual(response['Cache-Control'], 'max-age=3600, public')\n\n        patch_cache_control(response, private=True)\n        self.assertEqual(response['Cache-Control'], 'max-age=3600')\n\n        patch_cache_control(response, max_age=1800)\n        self.assertEqual(response['Cache-Control'], 'max-age=1800')\n"], "sample_16": ["    def test_shape(self):\n        self.check(np.shape)\n"], "sample_897": ["def test_PartialDependenceDisplay_from_estimator_with_categorical_features(diabetes, clf_diabetes, grid_resolution):\n    # Test PartialDependenceDisplay.from_estimator with categorical features\n    X = np.hstack((diabetes.data, np.random.choice([0, 1], size=(diabetes.data.shape[0], 1))))\n    feature_names = np.append(diabetes.feature_names, 'categorical_feature')\n    categorical_features = ['categorical_feature']\n\n    display = PartialDependenceDisplay.from_estimator(\n        clf_diabetes,\n        X,\n        features=[0, 'categorical_feature'],\n        feature_names=feature_names,\n        categorical_features=categorical_features,\n        grid_resolution=grid_resolution,\n    )\n\n    assert len(display.features) == 2\n    assert display.feature_names == list(feature_names)\n    assert display.is_categorical == [(False,), (True,)]\n    assert display.pd_results[0]['grid_values'][0].shape == (grid_resolution,)\n    assert display.pd_results[1]['grid_values'][0].shape == (2,)  # categorical feature\n"], "sample_618": ["def test_broadcast_compat_data():\n    var = xr.Variable((\"x\", \"y\"), np.arange(6).reshape(2, 3))\n    broadcast_dims = (\"z\",)\n    core_dims = (\"x\", \"y\")\n    expected_data = np.arange(6).reshape(1, 2, 3)\n    assert_array_equal(broadcast_compat_data(var, broadcast_dims, core_dims), expected_data)\n"], "sample_992": ["def test_print_Mod():\n    expr = Mod(x, y)\n    printer = PythonCodePrinter()\n    assert printer.doprint(expr) == '(x % y)'\n"], "sample_541": ["def test_button_callback(ax):\n        callback.called = True\n\n    callback.called = False\n    button = widgets.Button(ax, 'Test')\n    button.on_clicked(callback)\n    event = mock_event(button, 'button_press_event')\n    do_event(button, event)\n    event = mock_event(button, 'button_release_event')\n    do_event(button, event)\n    assert callback.called\n"], "sample_330": ["    def test_callproc(self):\n        db = connections[DEFAULT_DB_ALIAS]\n        cursor = CursorWrapper(mock.Mock(), db)\n        procname = \"test_proc\"\n        params = (1, 2, 3)\n        kparams = {\"key1\": \"value1\", \"key2\": \"value2\"}\n\n        # Test callproc with params and kparams\n        with mock.patch.object(db, 'validate_no_broken_transaction') as mock_validate:\n            with mock.patch.object(db, 'wrap_database_errors') as mock_wrap:\n                cursor.callproc(procname, params, kparams)\n                mock_validate.assert_called_once()\n                mock_wrap.assert_called_once()\n                cursor.cursor.callproc.assert_called_once_with(procname, params, kparams)\n\n        # Test callproc with only params\n        cursor.cursor.callproc.reset_mock()\n        with mock.patch.object(db, 'validate_no_broken_transaction') as mock_validate:\n            with mock.patch.object(db, 'wrap_database_errors') as mock_wrap:\n                cursor.callproc(procname, params)\n                mock_validate.assert_called_once()\n                mock_wrap.assert_called_once()\n                cursor.cursor.callproc.assert_called_once_with(procname, params)\n\n        # Test callproc with no params\n        cursor.cursor.callproc.reset_mock()\n        with mock.patch.object(db, 'validate_no_broken_transaction') as mock_validate:\n            with mock.patch.object(db, 'wrap_database_errors') as mock_wrap:\n                cursor.callproc(procname)\n                mock_validate.assert_called_once()\n                mock_wrap.assert_called_once()\n                cursor.cursor.callproc.assert_called_once_with(procname)\n\n        # Test callproc with kparams but not supported by the database backend\n        db.features.supports"], "sample_481": ["def test_join_with_custom_separator(self):\n    output = self.engine.render_to_string(\"join02\", {\"a\": [\"one\", \"two\", \"three\"]})\n    self.assertEqual(output, \"one and two and three\")\n"], "sample_499": ["def test_legend_set_draggable():\n    fig, ax = plt.subplots()\n    line, = ax.plot([1, 2, 3], [1, 2, 3], label='Test line')\n    legend = ax.legend()\n\n    # Test enabling draggable\n    draggable = legend.set_draggable(True)\n    assert isinstance(draggable, mlegend.DraggableLegend)\n    assert legend.get_draggable() is True\n\n    # Test disabling draggable\n    legend.set_draggable(False)\n    assert legend.get_draggable() is False\n"], "sample_858": ["def test_voting_classifier_with_sample_weights():\n    clf1 = LogisticRegression(multi_class='multinomial', random_state=1)\n    clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n    clf3 = GaussianNB()\n    X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n    y = np.array([1, 1, 1, 2, 2, 2])\n    sample_weight = np.array([1, 1, 2, 1, 1, 2])\n    eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n    eclf = eclf.fit(X, y, sample_weight=sample_weight)\n    assert_array_equal(eclf.predict(X), [1, 1, 1, 2, 2, 2])\n"], "sample_1121": ["def test_eval_expand_mul():\n    expr = (x + y)*(a + b)\n    expanded = expr._eval_expand_mul()\n    assert expanded == x*a + x*b + y*a + y*b\n"], "sample_406": ["    def test_manager_str(self):\n        manager = Article.objects\n        self.assertEqual(str(manager), \"tests.Article.objects\")\n"], "sample_1196": ["def test_contains_with_interval():\n    x = Symbol('x')\n    assert Contains(x, Interval(0, 1)) == (x >= 0) & (x <= 1)\n    assert Contains(2, Interval(0, 1)) is S.false\n    assert Contains(x, Interval(0, oo)) == (x >= 0)\n    assert Contains(-1, Interval(0, oo)) is S.false\n"], "sample_93": ["def test_expression_wrapper(self):\n    expr = ExpressionWrapper(Value(1), output_field=IntegerField())\n    self.assertEqual(str(expr), '1')\n    self.assertEqual(expr.output_field, IntegerField())\n"], "sample_810": ["def test_pipeline_fit_transform_with_fit_params():\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([0, 1, 0])\n    pipeline = make_pipeline(TransfFitParams(), Mult(mult=2))\n    pipeline.fit(X, y, mult__mult=3)\n    X_transformed = pipeline.transform(X)\n    assert_array_equal(X_transformed, np.array([[3, 6], [9, 12], [15, 18]]))\n    assert pipeline.named_steps['mult'].fit_params == {'mult': 3}\n"], "sample_433": ["def test_deconstructible_object_changes(self):\n    changes = self.get_changes(\n        [self.author_name_deconstructible_1],\n        [self.author_name_deconstructible_2],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, max_length=200)\n    self.assertEqual(\n        changes[\"testapp\"][0].operations[0].field.default,\n        DeconstructibleObject(),\n    )\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_1],\n        [self.author_name_deconstructible_3],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, max_length=200)\n    self.assertEqual(\n        changes[\"testapp\"][0].operations[0].field.default,\n        models.IntegerField(),\n    )\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_list_1],\n        [self.author_name_deconstructible_list_2],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, max_length=200)\n    self.assertEqual(\n        changes[\"testapp\"][0].operations[0].field.default,\n        [DeconstructibleObject(), 123],\n    )\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_list_1],\n        [self.author_name_deconstructible_list_"], "sample_83": ["    def test_filter_registration(self):\n        @self.library.filter\n            return value.upper()\n\n        self.assertIn('test_filter', self.library.filters)\n        self.assertEqual(self.library.filters['test_filter'], test_filter)\n        self.assertEqual(self.library.filters['test_filter']('test'), 'TEST')\n"], "sample_43": ["def test_regular_events_fitness():\n    dt = 0.05\n    t = dt * np.arange(1000)\n    x = np.zeros(len(t))\n    x[np.random.randint(0, len(t), len(t) // 10)] = 1\n    fitfunc = RegularEvents(dt=dt)\n    M_k = (t[-1] - t[:-1]) / dt\n    N_k = np.cumsum(x[::-1])[::-1]\n    fitness_values = fitfunc.fitness(T_k=M_k * dt, N_k=N_k)\n    assert len(fitness_values) == len(t)\n    assert np.all(fitness_values >= 0)\n"], "sample_861": ["def test_parameter_grid_with_empty_dict(klass):\n    param_grid = {}\n    grid = klass(param_grid)\n    assert list(grid) == [{}]\n    assert_grid_iter_equals_getitem(grid)\n"], "sample_711": ["def test_iterparentnodeids(nodeid: str, expected: List[str]) -> None:\n    result = list(nodes.iterparentnodeids(nodeid))\n    assert result == expected\n"], "sample_658": ["def test_doctest_item_setup(mocker):\n    class MockTest:\n        examples = []\n        globs = {}\n\n    mock_fixture_request = mocker.Mock()\n    mock_fixture_request.getfixturevalue.return_value = {\"mock_fixture\": \"mock_value\"}\n    mock_setup_fixtures = mocker.patch(\"_pytest.doctest._setup_fixtures\", return_value=mock_fixture_request)\n\n    doctest_item = DoctestItem(\"test_name\", None, None, MockTest())\n    doctest_item.setup()\n\n    assert doctest_item.fixture_request == mock_fixture_request\n    assert doctest_item.dtest.globs == {\"getfixture\": mock_fixture_request.getfixturevalue, \"mock_fixture\": \"mock_value\"}\n    mock_setup_fixtures.assert_called_once_with(doctest_item)\n"], "sample_663": ["def test_in_venv(tmpdir):\n    # Test when path is not a directory\n    assert not _in_venv(tmpdir.join(\"not_a_dir\"))\n\n    # Test when path is a directory but does not contain a virtual environment\n    tmpdir.mkdir(\"no_venv\")\n    assert not _in_venv(tmpdir.join(\"no_venv\"))\n\n    # Test when path is a directory containing a virtual environment\n    venv_dir = tmpdir.mkdir(\"venv\")\n    if sys.platform.startswith(\"win\"):\n        venv_dir.mkdir(\"Scripts\").join(\"activate\").write(\"\")\n    else:\n        venv_dir.mkdir(\"bin\").join(\"activate\").write(\"\")\n    assert _in_venv(venv_dir)\n"], "sample_1198": ["def test_parse_function_with_multiple_arguments():\n    result = parse_mathematica(\"f[x, y, z]\")\n    expected = Function(\"f\")(x, y, z)\n    assert result == expected\n"], "sample_1017": ["def test_as_Boolean():\n    assert as_Boolean(True) is S.true\n    assert as_Boolean(False) is S.false\n    assert as_Boolean(1) is S.true\n    assert as_Boolean(0) is S.false\n    assert as_Boolean(x) == x\n    assert as_Boolean(Boolean(True)) is S.true\n    assert as_Boolean(Boolean(False)) is S.false\n    with raises(TypeError):\n        as_Boolean('True')\n"], "sample_1015": ["def test_print_ccode_with_custom_functions():\n    custom_functions = {\n        \"ceiling\": \"CEIL\",\n        \"Abs\": [(lambda x: not x.is_integer, \"fabs\"),\n                (lambda x: x.is_integer, \"ABS\")],\n        \"func\": \"f\"\n    }\n    func = Function('func')\n    expr = func(Abs(x) + ceiling(x))\n    result = ccode(expr, standard='C89', user_functions=custom_functions)\n    assert result == 'f(fabs(x) + CEIL(x))'\n"], "sample_1149": ["def test_singleton_registry():\n    class TestSingleton(Basic, metaclass=Singleton):\n        pass\n\n    assert TestSingleton() is TestSingleton()\n    assert S.TestSingleton is TestSingleton()\n\n    # Test that a duplicate class overwrites the old one\n    class TestSingleton(Basic, metaclass=Singleton):\n        pass\n\n    assert TestSingleton() is not S.TestSingleton\n"], "sample_323": ["    def test_migrate_all_backwards(self):\n        executor = MigrationExecutor(connection)\n        plan = [\n            (executor.loader.graph.nodes[('migrations', '0001_initial')], True),\n            (executor.loader.graph.nodes[('migrations2', '0001_initial')], True),\n        ]\n        full_plan = executor.migration_plan(executor.loader.graph.leaf_nodes(), clean_start=True)\n        state = executor._migrate_all_backwards(plan, full_plan, fake=False)\n        self.assertNotIn(('migrations', '0001_initial'), executor.recorder.applied_migrations())\n        self.assertNotIn(('migrations2', '0001_initial'), executor.recorder.applied_migrations())\n"], "sample_766": ["def test_sparse_encode_positive_constraint():\n    # Test that positive constraint is raised for unsupported methods\n    with assert_raises(ValueError):\n        sparse_encode(X, X, algorithm='lars', positive=True)\n\n    with assert_raises(ValueError):\n        sparse_encode(X, X, algorithm='omp', positive=True)\n"], "sample_886": ["def test_wrap_in_pandas_container():\n    data = np.array([[1, 2], [3, 4]])\n    columns = [\"col1\", \"col2\"]\n    index = [\"row1\", \"row2\"]\n\n    df = _wrap_in_pandas_container(data, columns=columns, index=index)\n\n    assert isinstance(df, pd.DataFrame)\n    assert_array_equal(df.columns, columns)\n    assert_array_equal(df.index, index)\n    assert_array_equal(df.values, data)\n\n    with pytest.raises(ValueError):\n        _wrap_in_pandas_container(csr_matrix(data), columns=columns, index=index)\n"], "sample_557": ["def test_figure_align_labels():\n    fig, axs = plt.subplots(2, 2)\n    for tick in axs[0, 0].get_xticklabels():\n        tick.set_rotation(55)\n    axs[0, 0].set_xlabel('XLabel 0')\n    axs[0, 1].set_xlabel('XLabel 1')\n    fig.align_xlabels()\n    fig.align_ylabels()\n    fig.align_labels()\n"], "sample_1146": ["def test_latex_printing_of_ArraySymbol():\n    A = ArraySymbol('A', (3, 3))\n    assert latex(A) == 'A'\n"], "sample_358": ["    def test_references_table(self):\n        self.assertTrue(self.reference.references_table('table'))\n        self.assertFalse(self.reference.references_table('other_table'))\n"], "sample_69": ["    def test_import_error_file(self):\n        filename = self.temporary_file('error_module.py')\n        filename.write_text('syntax error')\n        with self.assertRaises(SyntaxError):\n            self.import_and_cleanup('error_module')\n        self.assertFileFound(filename)\n        self.clear_autoreload_caches()\n        self.assertFileNotFound(filename)\n"], "sample_515": ["def test_colorbar_orientation():\n    \"\"\"\n    Test colorbar orientation.\n    \"\"\"\n    fig, ax = plt.subplots(2, 1, figsize=(6, 10))\n    data = np.random.rand(10, 10)\n    im = ax[0].imshow(data, cmap='viridis')\n    fig.colorbar(im, ax=ax[0], orientation='vertical')\n    im = ax[1].imshow(data, cmap='viridis')\n    fig.colorbar(im, ax=ax[1], orientation='horizontal')\n    plt.close(fig)\n"], "sample_510": ["def test_xlim():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], [4, 5, 6])\n    plt.xlim(2, 3)\n    assert ax.get_xlim() == (2, 3)\n"], "sample_341": ["def test_formset_factory_with_custom_kwargs(self):\n    CustomKwargFormSet = formset_factory(CustomKwargForm, form_kwargs={'custom_kwarg': 'test'})\n    formset = CustomKwargFormSet()\n    for form in formset:\n        self.assertEqual(form.custom_kwarg, 'test')\n"], "sample_223": ["def test_filter_with_complex_annotation(self):\n    annotated_items = Item.objects.annotate(tag_count=Count('tags'))\n    filtered_items = annotated_items.filter(tag_count__gt=1)\n    self.assertEqual(list(filtered_items), [self.i1, self.i2])\n"], "sample_1162": ["def test_nfloat():\n    expr = comm_x**4 + comm_x/2 + cos(pi/3) + 1 + sqrt(noncomm_x)\n    result = nfloat(expr)\n    assert result == comm_x**4 + 0.5*comm_x + sqrt(noncomm_x) + 1.5\n\n    expr = comm_x**4 + sqrt(noncomm_x)\n    result = nfloat(expr, exponent=True)\n    assert result == comm_x**4.0 + noncomm_x**0.5\n"], "sample_146": ["    def test_check_setting_language_code(self):\n        \"\"\"Test check_setting_language_code function.\"\"\"\n        with override_settings(LANGUAGE_CODE=self.valid_tags[0]):\n            self.assertEqual(check_setting_language_code(None), [])\n        with override_settings(LANGUAGE_CODE=self.invalid_tags[0]):\n            self.assertEqual(check_setting_language_code(None), [Error('You have provided an invalid value for the LANGUAGE_CODE setting: None.', id='translation.E001')])\n"], "sample_291": ["    def test_get_redirect_url(self):\n        view = RedirectView.as_view(url='/redirect-url/')\n        request = self.rf.get('/some-url/')\n        response = view(request)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response.url, '/redirect-url/')\n"], "sample_754": ["def test_sparse_pca_transform(norm_comp):\n    n_components = 3\n    n_samples = 10\n    image_size = (10, 10)\n    random_state = 42\n\n    Y, U, V = generate_toy_data(n_components, n_samples, image_size, random_state)\n\n    sparse_pca = SparsePCA(n_components=n_components, random_state=random_state, normalize_components=norm_comp)\n    sparse_pca.fit(Y)\n\n    U_transformed = sparse_pca.transform(Y)\n\n    assert_equal(U_transformed.shape, (n_samples, n_components))\n    assert_allclose(np.linalg.norm(U_transformed, axis=1), np.ones(n_samples), atol=1e-3)\n"], "sample_29": ["def test_write_latex_with_custom_cls(cosmo, tmp_path):\n    \"\"\"Test write_latex with a custom cls.\"\"\"\n    file = tmp_path / \"test.tex\"\n    write_latex(cosmo, file, cls=Table)\n    assert file.read_text() != \"\"\n"], "sample_799": ["def test_cross_validate_with_fit_params():\n    clf = MockClassifier()\n    fit_params = {'sample_weight': np.ones(X.shape[0]),\n                  'class_prior': np.ones(len(np.unique(y))),\n                  'sparse_sample_weight': coo_matrix(np.ones(X.shape[0])),\n                  'sparse_param': P_sparse,\n                  'dummy_int': 42,\n                  'dummy_str': 'test',\n                  'dummy_obj': object()}\n    cv_results = cross_validate(clf, X, y, fit_params=fit_params)\n    assert_equal(clf.dummy_int, fit_params['dummy_int'])\n    assert_equal(clf.dummy_str, fit_params['dummy_str'])\n    assert_equal(clf.dummy_obj, fit_params['dummy_obj'])\n"], "sample_114": ["def test_generate_altered_managers_with_custom_managers(self):\n    before_states = [self.other_pony]\n    after_states = [self.other_pony_food]\n    changes = self.get_changes(before_states, after_states)\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AlterModelManagers'])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0,\n                                   name='Pony',\n                                   managers=[\n                                       ('food_qs', FoodQuerySet.as_manager()),\n                                       ('food_mgr', FoodManager('a', 'b')),\n                                       ('food_mgr_kwargs', FoodManager('x', 'y', 3, 4)),\n                                   ])\n"], "sample_804": ["def test_ordinal_encoder_inverse_transform():\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    X_transformed = enc.transform(X)\n    X_inverse = enc.inverse_transform(X_transformed)\n    assert_array_equal(X, X_inverse)\n"], "sample_509": ["def test_num2timedelta():\n    x = [1.0, 2.0, 3.0]\n    expected = [datetime.timedelta(days=1), datetime.timedelta(days=2), datetime.timedelta(days=3)]\n    assert mdates.num2timedelta(x) == expected\n"], "sample_872": ["def test_roc_curve_drop_intermediate(drop):\n    y_true = np.array([0, 0, 1, 1])\n    y_score = np.array([0.1, 0.4, 0.35, 0.8])\n    fpr, tpr, thresholds = roc_curve(y_true, y_score, drop_intermediate=drop)\n    if drop:\n        assert len(fpr) == 3\n        assert len(tpr) == 3\n        assert len(thresholds) == 3\n    else:\n        assert len(fpr) == 5\n        assert len(tpr) == 5\n        assert len(thresholds) == 5\n"], "sample_1079": ["def test_point_canberra_distance():\n    p1 = Point(1, 1)\n    p2 = Point(3, 3)\n    assert p1.canberra_distance(p2) == 1\n\n    p1 = Point(0, 0)\n    p2 = Point(3, 3)\n    assert p1.canberra_distance(p2) == 2\n\n    p1 = Point(0, 0, 0)\n    p2 = Point(3, 3, 3)\n    assert p1.canberra_distance(p2) == 3\n\n    p1 = Point(1, 2, 3)\n    p2 = Point(4, 5, 6)\n    assert p1.canberra_distance(p2) == sqrt(3)\n\n    p1 = Point(0, 0, 0)\n    p2 = Point(0, 0, 0)\n    with raises(ValueError):\n        p1.canberra_distance(p2)\n"], "sample_1194": ["def test_julia_code_relational():\n    assert julia_code(x > y) == \"x > y\"\n    assert julia_code(x < y) == \"x < y\"\n    assert julia_code(x >= y) == \"x >= y\"\n    assert julia_code(x <= y) == \"x <= y\"\n    assert julia_code(x == y) == \"x == y\"\n    assert julia_code(x != y) == \"x != y\"\n"], "sample_176": ["def test_deconstructible_objects_are_compared_correctly(self):\n    questioner = MigrationQuestioner(specified_apps=[\"testapp\"])\n    changes = self.get_changes(\n        [self.author_name_deconstructible_1],\n        [self.author_name_deconstructible_2],\n        questioner,\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 0)\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_1],\n        [self.author_name_deconstructible_3],\n        questioner,\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"RemoveField\", \"AddField\"])\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_1],\n        [self.author_name_deconstructible_4],\n        questioner,\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_list_1],\n        [self.author_name_deconstructible_list_2],\n        questioner,\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 0)\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_list_1],\n        [self.author_name_deconstructible_list_3],\n        questioner,\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_tuple_1],\n        [self.author_name_deconstructible_tuple_2],\n        questioner,\n    )\n   "], "sample_805": ["def test_mean_tweedie_deviance_invalid_p():\n    y_true = np.array([2, 0, 1, 4])\n    y_pred = np.array([0.5, 0.5, 2., 2.])\n    with assert_raises_regex(ValueError, \"Tweedie deviance is only defined for p<=0 and p>=1.\"):\n        mean_tweedie_deviance(y_true, y_pred, p=1.5)\n"], "sample_885": ["def test_generate_invalid_param_val_interval_real_not_int():\n    interval = Interval(\"real_not_int\", 0, 1, closed=\"both\")\n    constraints = [interval]\n    invalid_val = generate_invalid_param_val(interval, constraints)\n    assert isinstance(invalid_val, Integral)\n"], "sample_168": ["    def test_stale_content_type_deletion(self):\n        with mock.patch('builtins.input', return_value='yes'):\n            with captured_stdout() as stdout:\n                call_command('remove_stale_contenttypes', interactive=True, verbosity=2)\n                output = stdout.getvalue()\n                self.assertIn(\"Deleting stale content type 'contenttypes_tests | Fake'\", output)\n        self.assertEqual(ContentType.objects.count(), self.before_count)\n"], "sample_348": ["    def test_model_form_defines_fields(self):\n        class MyModelForm(forms.ModelForm):\n            class Meta:\n                model = ValidationTestModel\n                fields = ['field1', 'field2']\n\n        class MyModelAdmin(ModelAdmin):\n            form = MyModelForm\n\n        self.assertIsValid(MyModelAdmin, ValidationTestModel)\n"], "sample_377": ["    def test_get_traceback_data(self):\n        request = HttpRequest()\n        exc_type = Exception\n        exc_value = Exception(\"Test exception\")\n        tb = exc_value.__traceback__\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIsInstance(data, dict)\n        self.assertIn('exception_type', data)\n        self.assertIn('exception_value', data)\n        self.assertIn('frames', data)\n"], "sample_1043": ["def test_mathematica_code():\n    assert mcode(exp(x)) == \"Exp[x]\"\n    assert mcode(sin(x)) == \"Sin[x]\"\n    assert mcode(cos(x)) == \"Cos[x]\"\n    assert mcode(conjugate(x)) == \"Conjugate[x]\"\n    assert mcode(Max(x, y)) == \"Max[x, y]\"\n    assert mcode(Min(x, y)) == \"Min[x, y]\"\n    assert mcode(Integral(f(x), x)) == \"Hold[Integrate[f[x], x]]\"\n    assert mcode(Sum(f(x), (x, 1, n))) == \"Hold[Sum[f[x], {x, 1, n}]]\"\n    assert mcode(Derivative(f(x), x)) == \"Hold[D[f[x], x]]\"\n"], "sample_1123": ["def test_condition_set_subs():\n    c = ConditionSet(x, x < 1, {x, z})\n    assert c.subs(x, y) == ConditionSet(x, x < 1, FiniteSet(y, z))\n    assert c.subs(x, y).subs(x, y) == ConditionSet(y, y < 1, FiniteSet(y, z))\n    raises(ValueError, lambda: c.subs(y, 1))\n"], "sample_1107": ["def test_rotations():\n    assert list(rotations([1, 2, 3])) == [[1, 2, 3], [2, 3, 1], [3, 1, 2]]\n    assert list(rotations([1, 2, 3], -1)) == [[1, 2, 3], [3, 1, 2], [2, 3, 1]]\n"], "sample_129": ["def test_floatformat_with_args(self):\n    self.engine.assert_output(\n        self.templates['floatformat02'],\n        {'c': Decimal('34.232'), 'd': Decimal('34.000'), 'e': 'invalid', 'f': '2'},\n        '34.232 34 34.232',\n    )\n"], "sample_189": ["    def setUp(self):\n        self.cache = caches[DEFAULT_CACHE_ALIAS]\n"], "sample_136": ["    def test_get_full_path(self):\n        request = HttpRequest()\n        request.path = '/test/'\n        request.META = {'QUERY_STRING': 'param1=value1&param2=value2'}\n        self.assertEqual(request.get_full_path(), '/test/?param1=value1&param2=value2')\n\n        request.path = '/test'\n        self.assertEqual(request.get_full_path(force_append_slash=True), '/test/?param1=value1&param2=value2')\n\n        request.path = '/test/'\n        request.META = {}\n        self.assertEqual(request.get_full_path(), '/test/')\n"], "sample_447": ["    def test_expression_wrapper_annotation(self):\n        authors = Author.objects.annotate(\n            lower_name=ExpressionWrapper(Lower('name'), output_field=CharField())\n        )\n        self.assertEqual(authors.first().lower_name, 'adrian holovaty')\n"], "sample_80": ["def test_build_filter_with_transform(self):\n    query = Query(Author)\n    filter_expr = ('name__lower', 'test')\n    clause, _ = query.build_filter(filter_expr)\n    self.assertEqual(len(clause.children), 1)\n    lookup = clause.children[0]\n    self.assertIsInstance(lookup, Exact)\n    self.assertIsInstance(lookup.lhs, Lower)\n    self.assertIsInstance(lookup.lhs.lhs, SimpleCol)\n    self.assertEqual(lookup.lhs.lhs.field, Author._meta.get_field('name'))\n"], "sample_257": ["    def test_key_transform_factory(self):\n        factory = KeyTransformFactory('key')\n        transform = factory(F('field'))\n        self.assertIsInstance(transform, KeyTransform)\n        self.assertEqual(transform.key_name, 'key')\n        self.assertEqual(transform.source_expressions[0], F('field'))\n"], "sample_1030": ["def test_idiff():\n    x, y, a = symbols('x y a')\n    eq = x**2 + y**2 - 4\n    assert idiff(eq, y, x) == -x/y\n    assert idiff(eq, y, x, 2).simplify() == -(x**2 + y**2)/y**3\n    assert idiff(x + a + y, y, x) == -1\n    assert idiff(x + a + y, [y, a], x) == -Derivative(a, x) - 1\n"], "sample_895": ["def test_column_transformer_with_callable_columns():\n    # Test ColumnTransformer with callable columns\n    X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    ct = ColumnTransformer(\n        transformers=[\n            (\"double\", DoubleTrans(), lambda X: [0, 2]),\n            (\"standard\", StandardScaler(), lambda X: [1]),\n        ]\n    )\n    X_transformed = ct.fit_transform(X)\n    assert_allclose(X_transformed, [[-1.22474487, 0.0, 6.0], [-1.22474487, 0.0, 12.0], [1.22474487, 0.0, 18.0]])\n"], "sample_199": ["    def test_expression_wrapper(self):\n        # Test ExpressionWrapper with a simple expression\n        expr = ExpressionWrapper(F('age') + 10, output_field=IntegerField())\n        author = Author.objects.annotate(new_age=expr).get(name='Adrian Holovaty')\n        self.assertEqual(author.new_age, 44)\n\n        # Test ExpressionWrapper with a complex expression\n        expr = ExpressionWrapper(F('price') * F('pages'), output_field=FloatField())\n        book = Book.objects.annotate(total_cost=expr).get(name='The Definitive Guide to Django: Web Development Done Right')\n        self.assertEqual(book.total_cost, 134100.0)\n"], "sample_292": ["def test_origin_verified(self):\n    middleware = CsrfViewMiddleware()\n\n    # Test with a matching origin\n    request = TestingHttpRequest()\n    request.META['HTTP_ORIGIN'] = 'http://testserver'\n    self.assertTrue(middleware._origin_verified(request))\n\n    # Test with a matching origin in CSRF_TRUSTED_ORIGINS\n    with self.settings(CSRF_TRUSTED_ORIGINS=['http://trusted.com']):\n        request = TestingHttpRequest()\n        request.META['HTTP_ORIGIN'] = 'http://trusted.com'\n        self.assertTrue(middleware._origin_verified(request))\n\n    # Test with a matching subdomain in CSRF_TRUSTED_ORIGINS\n    with self.settings(CSRF_TRUSTED_ORIGINS=['https://*.trusted.com']):\n        request = TestingHttpRequest()\n        request.META['HTTP_ORIGIN'] = 'https://sub.trusted.com'\n        self.assertTrue(middleware._origin_verified(request))\n\n    # Test with a non-matching origin\n    request = TestingHttpRequest()\n    request.META['HTTP_ORIGIN'] = 'http://evil.com'\n    self.assertFalse(middleware._origin_verified(request))\n"], "sample_460": ["    def test_admin_site_check(self):\n        errors = site.check(None)\n        self.assertEqual(errors, [])\n"], "sample_769": ["def test_brier_score_loss():\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    expected_score = 0.037\n    assert_almost_equal(brier_score_loss(y_true, y_prob), expected_score)\n"], "sample_36": ["def test_biweight_midvariance_modify_sample_size():\n    # Test biweight_midvariance with modify_sample_size=True\n    with NumpyRNGContext(12345):\n        data = normal(0, 1, 100)\n        bivar = biweight_midvariance(data, modify_sample_size=True)\n        assert_allclose(bivar, 0.97362869104, rtol=1e-5)\n"], "sample_768": ["def test_leave_p_out_with_invalid_p():\n    with assert_raises(ValueError):\n        LeavePOut(p=0)\n"], "sample_235": ["    def test_savepoint_commit(self):\n        sid = connection.savepoint()\n        self.do(1)\n        connection.savepoint_commit(sid)\n        self.assertDone([1])\n"], "sample_646": ["def test_pytest_pycollect_makeitem(pytester: Pytester, monkeypatch: MonkeyPatch):\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n\n        class TestMyClass(unittest.TestCase):\n                self.assertEqual(1, 1)\n        \"\"\"\n    )\n\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n\n    # Test that the function returns None when unittest is not imported\n    monkeypatch.delitem(sys.modules, \"unittest\")\n    from my_code_file import pytest_pycollect_makeitem\n    assert pytest_pycollect_makeitem(None, \"name\", object) is None\n"], "sample_33": ["def test_did_you_mean():\n    candidates = ['apple', 'banana', 'cherry', 'date', 'elderberry']\n    assert misc.did_you_mean('aple', candidates) == 'Did you mean apple?'\n    assert misc.did_you_mean('grape', candidates) == ''\n"], "sample_87": ["    def test_import_error_file(self):\n        filename = self.temporary_file('error_module.py')\n        filename.write_text('syntax error')\n        with self.assertRaises(SyntaxError):\n            self.import_and_cleanup('error_module')\n        self.assertFileFound(filename)\n        self.assertIn(filename, autoreload._error_files)\n        autoreload._error_files.clear()\n        self.assertFileNotFound(filename)\n"], "sample_931": ["def test_parse_annotation(app):\n    env = app.builder.env\n    annotation = \"List[Union[int, str]]\"\n    result = _parse_annotation(annotation, env)\n    expected = [\n        pending_xref('', nodes.Text('List'), refdomain='py', reftype='class', reftarget='List'),\n        addnodes.desc_sig_punctuation('', '['),\n        pending_xref('', nodes.Text('Union'), refdomain='py', reftype='class', reftarget='Union'),\n        addnodes.desc_sig_punctuation('', '['),\n        nodes.Text('int'),\n        addnodes.desc_sig_punctuation('', ', '),\n        nodes.Text('str'),\n        addnodes.desc_sig_punctuation('', ']'),\n        addnodes.desc_sig_punctuation('', ']'),\n    ]\n    assert_node(result, expected)\n"], "sample_1167": ["def test_latex_printing_of_ArraySymbol():\n    A = ArraySymbol('A', (3, 3))\n    assert latex(A) == 'A'\n"], "sample_44": ["def test_function_unit_creation():\n    for pu in pu_sample:\n        for lu in lu_units:\n            fu = lu(pu)\n            assert isinstance(fu, FunctionUnitBase)\n            assert fu.physical_unit == pu\n            assert fu.function_unit == lu\n"], "sample_866": ["def test_affinity_propagation_convergence_warning():\n    # Test that a ConvergenceWarning is raised when affinity propagation does not converge\n    # Create a similarity matrix where all similarities are equal and preferences are smaller\n    S = np.ones((10, 10))\n    preference = np.full(10, 0.5)\n    with assert_warns(ConvergenceWarning):\n        affinity_propagation(S, preference)\n"], "sample_342": ["def test_serialize_result(self):\n    \"\"\"Test the serialize_result method of AutocompleteJsonView.\"\"\"\n    request = self.factory.get(self.url, self.opts)\n    request.user = self.user\n    view = AutocompleteJsonView(**self.as_view_args)\n    view.setup(request)\n    view.process_request(request)\n    obj = Answer.objects.first()\n    to_field_name = 'question'\n    result = view.serialize_result(obj, to_field_name)\n    self.assertEqual(result['id'], str(getattr(obj, to_field_name)))\n    self.assertEqual(result['text'], str(obj))\n"], "sample_61": ["    def test_ascii_username_validator(self):\n        validator = ASCIIUsernameValidator()\n        valid_usernames = ['username', 'user.name', 'user@name', 'user+name', 'user-name', 'user_name', 'user123']\n        invalid_usernames = ['user\u00f1ame', 'user$name', 'user name', '']\n\n        for username in valid_usernames:\n            self.assertIsNone(validator(username))\n\n        for username in invalid_usernames:\n            with self.assertRaises(ValidationError):\n                validator(username)\n"], "sample_1179": ["def test_print_Quaternion():\n    q = Quaternion(1, 2, 3, 4)\n    assert sstr(q) == \"1 + 2*i + 3*j + 4*k\"\n"], "sample_201": ["    def test_encode_decode_safedata(self):\n        storage = CookieStorage(None)\n        message = Message(constants.INFO, mark_safe(\"This is a safe message\"))\n        encoded_data = storage._encode([message])\n        decoded_data = storage._decode(encoded_data)\n        self.assertEqual(len(decoded_data), 1)\n        self.assertIsInstance(decoded_data[0].message, SafeData)\n        self.assertEqual(decoded_data[0].message, \"This is a safe message\")\n"], "sample_429": ["    def test_prohibit_null_characters_validator_with_message(self):\n        validator = ProhibitNullCharactersValidator(message=\"Custom error message\")\n        with self.assertRaisesMessage(ValidationError, \"Custom error message\"):\n            validator(\"\\x00something\")\n"], "sample_540": ["def test_null_movie_writer(anim):\n    \"\"\"Test NullMovieWriter.\"\"\"\n    writer = NullMovieWriter()\n    with writer.saving(anim._fig, 'test.mp4', 100):\n        for _ in range(5):\n            writer.grab_frame()\n    assert writer._count == 5\n    assert writer.fig is anim._fig\n    assert writer.outfile == 'test.mp4'\n    assert writer.dpi == 100\n    assert writer.args == ()\n    assert writer.savefig_kwargs == {}\n"], "sample_395": ["    def test_watch_for_template_changes(self):\n        sender = mock.Mock()\n        autoreload.watch_for_template_changes(sender)\n        sender.watch_dir.assert_called_with(EXTRA_TEMPLATES_DIR, \"**/*\")\n"], "sample_1191": ["def test_hermite_normal_form_modulo_D():\n    A = DomainMatrix([[ZZ(12), ZZ(6), ZZ(4)],\n                      [ZZ(3), ZZ(9), ZZ(6)],\n                      [ZZ(2), ZZ(16), ZZ(14)]], (3, 3), ZZ)\n    D = ZZ(30)\n    expected_result = DomainMatrix([[ZZ(10), ZZ(0), ZZ(2)],\n                                   [ZZ(0), ZZ(15), ZZ(3)],\n                                   [ZZ(0), ZZ(0), ZZ(2)]], (3, 3), ZZ)\n    assert hermite_normal_form(A, D=D) == expected_result\n"], "sample_877": ["def test_isotonic_regression_sample_weight():\n    # Test isotonic regression with sample weights\n    rng = np.random.RandomState(0)\n    X = np.arange(10)\n    y = rng.randn(10)\n    sample_weight = rng.rand(10)\n\n    # Fit isotonic regression with sample weights\n    iso_reg = IsotonicRegression().fit(X, y, sample_weight=sample_weight)\n\n    # Check that the fitted values are correct\n    y_pred = iso_reg.predict(X)\n    y_expected = isotonic_regression(y, sample_weight=sample_weight)\n    assert_array_almost_equal(y_pred, y_expected)\n\n    # Check that the interpolation function is correct\n    X_new = np.linspace(0, 9, 100)\n    y_new_expected = np.interp(X_new, X, y_pred)\n    y_new = iso_reg.predict(X_new)\n    assert_array_almost_equal(y_new, y_new_expected)\n"], "sample_920": ["    def test_numpy_docstring(self):\n        docstring = '''One line summary.\n\n        Extended description.\n\n        Parameters\n        ----------\n        arg1 : int\n            Description of `arg1`\n        arg2 : str\n            Description of `arg2`\n\n        Returns\n        -------\n        str\n            Description of return value.\n        '''\n        config = Config(napoleon_use_param=True, napoleon_use_rtype=True)\n        expected_output = '''One line summary.\n\n        Extended description.\n\n        :param arg1: Description of `arg1`\n        :type arg1: int\n        :param arg2: Description of `arg2`\n        :type arg2: str\n\n        :returns: Description of return value.\n        :rtype: str\n        '''\n        self.assertEqual(str(NumpyDocstring(docstring, config)), dedent(expected_output).strip())\n"], "sample_299": ["    def test_check_default_cache_is_configured(self):\n        errors = check_default_cache_is_configured(None)\n        self.assertEqual(errors, [])\n\n        with override_settings(CACHES=self.INVALID_CACHES_CONFIGURATION):\n            errors = check_default_cache_is_configured(None)\n            self.assertEqual(errors, [E001])\n"], "sample_73": ["def test_hashed_name_with_fragment(self):\n    storage.staticfiles_storage.save('test.css', StringIO('body { background: url(\"image.png?#iefix\"); }'))\n    hashed_name = storage.staticfiles_storage.hashed_name('test.css')\n    self.assertIn('?#iefix', hashed_name)\n    self.assertPostCondition()\n"], "sample_808": ["def test_isolation_forest_sparse_input():\n    X = csc_matrix(iris.data)\n    clf = IsolationForest(random_state=rng)\n    clf.fit(X)\n    y_pred = clf.predict(X)\n    assert_array_equal(y_pred.shape, (X.shape[0],))\n"], "sample_548": ["def test_colorbar_extension_length():\n    fig_uniform = _colorbar_extension_length('uniform')\n    fig_proportional = _colorbar_extension_length('proportional')\n    return fig_uniform, fig_proportional\n"], "sample_950": ["def test_parse_annotation():\n    env = Mock()\n    env.config.python_use_unqualified_type_names = False\n    result = _parse_annotation(\"List[int]\", env)\n    assert len(result) == 5\n    assert isinstance(result[0], nodes.Text)\n    assert result[0].astext() == \"List\"\n    assert isinstance(result[1], pending_xref)\n    assert result[1]['reftarget'] == \"List\"\n    assert isinstance(result[2], desc_sig_punctuation)\n    assert result[2].astext() == \"[\"\n    assert isinstance(result[3], nodes.Text)\n    assert result[3].astext() == \"int\"\n    assert isinstance(result[4], desc_sig_punctuation)\n    assert result[4].astext() == \"]\"\n"], "sample_1094": ["def test_basic_subs():\n    x, y, z = symbols('x y z')\n    expr = x + y\n    new_expr = expr.subs(x, z)\n    assert new_expr == z + y\n"], "sample_822": ["def test_pairwise_distances_chunked_with_reduce_func():\n    X = np.random.RandomState(0).rand(5, 3)\n    r = .2\n\n        neigh = [np.flatnonzero(d < r) for d in D_chunk]\n        avg_dist = (D_chunk * (D_chunk < r)).mean(axis=1)\n        return neigh, avg_dist\n\n    gen = pairwise_distances_chunked(X, reduce_func=reduce_func)\n    neigh, avg_dist = next(gen)\n\n    assert_array_equal(neigh, [np.array([0, 3]), np.array([1]), np.array([2]), np.array([0, 3]), np.array([4])])\n    assert_array_almost_equal(avg_dist, [0.039, 0.0, 0.0, 0.039, 0.0])\n"], "sample_664": ["def test_deprecated_warnings():\n    with pytest.warns(deprecated.FUNCARGNAMES):\n        class TestClass:\n            funcargnames = []\n\n    with pytest.warns(deprecated.RESULT_LOG):\n        pytest.main(['--result-log=log.txt'])\n\n    with pytest.warns(deprecated.FIXTURE_POSITIONAL_ARGUMENTS):\n        @pytest.fixture('arg1', 'arg2')\n            pass\n\n    with pytest.warns(deprecated.JUNIT_XML_DEFAULT_FAMILY):\n        pytest.main(['--junit-xml=report.xml'])\n"], "sample_1086": ["def test_print_Tr():\n    A = Matrix([[1, 2], [3, 4]])\n    assert sstr(Tr(A)) == \"Tr(Matrix([[1, 2], [3, 4]]))\"\n"], "sample_624": ["def test_format_timedelta():\n    # Test formatting of timedelta objects\n    td = pd.Timedelta(days=2, hours=3, minutes=4, seconds=5)\n    assert formatting.format_timedelta(td) == \"2 days 03:04:05\"\n    assert formatting.format_timedelta(td, timedelta_format=\"date\") == \"2 days\"\n    assert formatting.format_timedelta(td, timedelta_format=\"time\") == \"03:04:05\"\n"], "sample_214": ["    def test_key_transform_factory(self):\n        key_name = 'test_key'\n        factory = KeyTransformFactory(key_name)\n        transform = factory()\n        self.assertIsInstance(transform, KeyTransform)\n        self.assertEqual(transform.key_name, key_name)\n"], "sample_1033": ["def test_as_coefficients_dict():\n    expr = 3*x + a*x + 4\n    result = expr.as_coefficients_dict()\n    assert result == {1: 4, x: 3, a*x: 1}\n    assert result[a] == 0\n"], "sample_1093": ["def test_print_MatrixSolve():\n    A = MatrixSymbol('A', 3, 3)\n    b = MatrixSymbol('b', 3, 1)\n    expr = MatrixSolve(A, b)\n    result = pycode(expr, printer=NumPyPrinter)\n    assert result == \"numpy.linalg.solve(A, b)\"\n"], "sample_728": ["def test_make_classification_shuffle():\n    X, y = make_classification(n_samples=100, n_features=20, shuffle=True, random_state=42)\n    X_shuffled, y_shuffled = make_classification(n_samples=100, n_features=20, shuffle=False, random_state=42)\n    assert_true(not np.array_equal(X, X_shuffled))\n    assert_true(not np.array_equal(y, y_shuffled))\n"], "sample_702": ["def test_syspathinsert(pytester: Pytester) -> None:\n    original_sys_path = sys.path.copy()\n    pytester.syspathinsert()\n    assert sys.path[0] == str(pytester.path)\n    sys.path = original_sys_path\n"], "sample_1020": ["def test_mathematica_code():\n    assert mcode(exp(x)) == \"Exp[x]\"\n    assert mcode(sin(x)) == \"Sin[x]\"\n    assert mcode(cos(x)) == \"Cos[x]\"\n    assert mcode(pi) == \"Pi\"\n    assert mcode(oo) == \"Infinity\"\n    assert mcode(-oo) == \"-Infinity\"\n    assert mcode(Tuple(x, y, z)) == \"{x, y, z}\"\n    assert mcode(f(x, y)) == \"f[x, y]\"\n    assert mcode(Integral(f(x), x)) == \"Hold[Integrate[f[x], x]]\"\n    assert mcode(Sum(f(x), (x, 1, n))) == \"Hold[Sum[f[x], {x, 1, n}]]\"\n    assert mcode(Derivative(f(x), x)) == \"Hold[D[f[x], x]]\"\n    assert mcode(Max(x, y, z)) == \"Max[x, y, z]\"\n    assert mcode(Min(x, y, z)) == \"Min[x, y, z]\"\n    assert mcode(conjugate(x)) == \"Conjugate[x]\"\n"], "sample_237": ["    def test_non_unique_username_field(self):\n        errors = check_user_model(self.apps.get_app_configs())\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'auth.W004')\n"], "sample_978": ["def test_bspline_basis_set_with_repeated_knots():\n    d = 1\n    knots = [0, 0, 2, 3, 4]\n    splines = bspline_basis_set(d, knots, x)\n    expected_spline = Piecewise((-x/2 + 1, And(x >= 0, x <= 2)), (0, True))\n    assert splines[0] == expected_spline\n"], "sample_66": ["def test_get_full_path_with_query_string(self):\n    request = HttpRequest()\n    request.path = '/test/'\n    request.META['QUERY_STRING'] = 'param1=value1&param2=value2'\n    full_path = request.get_full_path()\n    self.assertEqual(full_path, '/test/?param1=value1&param2=value2')\n"], "sample_24": ["    def test_shape(self):\n        self.check(np.shape)\n        self.check(np.size)\n        self.check(np.ndim)\n"], "sample_218": ["    def test_extract_functions(self):\n        dt = datetime(2022, 3, 14, 10, 30, 45)\n        obj = self.create_model(dt, dt + timedelta(days=1))\n\n        self.assertEqual(DTModel.objects.filter(start_datetime__year=ExtractYear('start_datetime')).count(), 1)\n        self.assertEqual(DTModel.objects.filter(start_datetime__iso_year=ExtractIsoYear('start_datetime')).count(), 1)\n        self.assertEqual(DTModel.objects.filter(start_datetime__month=ExtractMonth('start_datetime')).count(), 1)\n        self.assertEqual(DTModel.objects.filter(start_datetime__day=ExtractDay('start_datetime')).count(), 1)\n        self.assertEqual(DTModel.objects.filter(start_datetime__week=ExtractWeek('start_datetime')).count(), 1)\n        self.assertEqual(DTModel.objects.filter(start_datetime__week_day=ExtractWeekDay('start_datetime')).count(), 1)\n        self.assertEqual(DTModel.objects.filter(start_datetime__iso_week_day=ExtractIsoWeekDay('start_datetime')).count(), 1)\n        self.assertEqual(DTModel.objects.filter(start_datetime__quarter=ExtractQuarter('start_datetime')).count(), 1)\n        self.assertEqual(DTModel.objects.filter(start_datetime__hour=ExtractHour('start_datetime')).count(), 1)\n        self.assertEqual(DTModel.objects.filter(start_datetime__minute=ExtractMinute('start_datetime')).count(), 1)\n        self.assertEqual(DTModel.objects.filter(start_datetime__second=ExtractSecond('start_datetime')).count(), 1)\n"], "sample_813": ["def test_bayesian_ridge_fit_intercept_false():\n    X = diabetes.data\n    y = diabetes.target\n    clf = BayesianRidge(fit_intercept=False)\n    clf.fit(X, y)\n    assert_equal(clf.intercept_, 0.0)\n    assert_array_almost_equal(clf.coef_, np.dot(np.dot(pinvh(np.dot(X.T, X)), X.T), y))\n"], "sample_736": ["def test_logistic_regression_path():\n    X = np.array([[0, 0], [1, 1], [2, 2], [3, 3]])\n    y = np.array([0, 0, 1, 1])\n    Cs = [1.0, 0.1]\n    coefs, Cs_out, n_iter = logistic_regression_path(X, y, Cs=Cs)\n    assert_equal(len(coefs), len(Cs))\n    assert_array_equal(Cs_out, Cs)\n    assert_equal(n_iter.shape, (len(Cs),))\n"], "sample_110": ["def test_pickleability_with_filters(self):\n    qs = Happening.objects.filter(name='Test')\n    self.assert_pickles(qs)\n"], "sample_166": ["    def test_salted_hmac(self):\n        key_salt = 'test_salt'\n        value = 'test_value'\n        secret = 'test_secret'\n        algorithm = 'sha256'\n        result = salted_hmac(key_salt, value, secret, algorithm=algorithm)\n        expected_result = hmac.new(\n            hashlib.sha256(key_salt.encode() + secret.encode()).digest(),\n            msg=value.encode(),\n            digestmod=hashlib.sha256\n        )\n        self.assertEqual(result.hexdigest(), expected_result.hexdigest())\n"], "sample_209": ["def test_model_save_base_with_update_fields(self):\n    article = Article.objects.create(title='Test Article', content='Initial content')\n    article.save_base(update_fields=['content'])\n    article.refresh_from_db()\n    self.assertEqual(article.title, 'Test Article')\n    self.assertEqual(article.content, 'Initial content')\n\n    article.content = 'Updated content'\n    article.save_base(update_fields=['content'])\n    article.refresh_from_db()\n    self.assertEqual(article.title, 'Test Article')\n    self.assertEqual(article.content, 'Updated content')\n"], "sample_277": ["def test_combine_with_empty_q(self):\n    q1 = Q(name='test')\n    q2 = Q()\n    combined = q1 & q2\n    self.assertEqual(combined, q1)\n    combined = q2 & q1\n    self.assertEqual(combined, q1)\n"], "sample_41": ["def test_unit_conversion_with_equivalencies():\n    # Test unit conversion with equivalencies\n    equivalencies = [(u.m, u.cm, lambda x: x * 100, lambda x: x / 100)]\n    assert_allclose(u.m.to(u.cm, equivalencies=equivalencies), 100)\n    assert_allclose(u.cm.to(u.m, equivalencies=equivalencies), 0.01)\n"], "sample_592": ["def test_format_timedelta():\n    # Test formatting of timedelta objects\n    td = pd.Timedelta(days=2, hours=3, minutes=4, seconds=5)\n    assert formatting.format_timedelta(td) == \"2 days 03:04:05\"\n    assert formatting.format_timedelta(td, timedelta_format=\"date\") == \"2 days\"\n    assert formatting.format_timedelta(td, timedelta_format=\"time\") == \"03:04:05\"\n"], "sample_526": ["def test_date_ticker_factory():\n    span = 10\n    numticks = 5\n    locator, formatter = mdates.date_ticker_factory(span, numticks=numticks)\n    assert isinstance(locator, mdates.DayLocator)\n    assert isinstance(formatter, mdates.DateFormatter)\n    assert formatter.fmt == '%b %d'\n"], "sample_289": ["    def test_ordered_set_operations(self):\n        s = OrderedSet(['a', 'b', 'c'])\n        s.add('d')\n        self.assertEqual(len(s), 4)\n        self.assertIn('a', s)\n        self.assertNotIn('e', s)\n        s.remove('b')\n        self.assertEqual(len(s), 3)\n        self.assertNotIn('b', s)\n        s.discard('c')\n        self.assertEqual(len(s), 2)\n        self.assertNotIn('c', s)\n        s.discard('z')  # should not raise an error\n        self.assertTrue(bool(s))\n        s.remove('a')\n        s.remove('d')\n        self.assertFalse(bool(s))\n"], "sample_470": ["def test_lazy_object(self):\n        return \"Lazy Object\"\n\n    lazy_obj = SimpleLazyObject(setup_func)\n    self.assertEqual(str(lazy_obj), \"Lazy Object\")\n    self.assertEqual(lazy_obj._wrapped, \"Lazy Object\")\n"], "sample_121": ["    def test_unique_together_with_invalid_field(self):\n        class InvalidUniqueTogetherModel(models.Model):\n            field1 = models.CharField(max_length=10)\n            field2 = models.CharField(max_length=10)\n\n            class Meta:\n                unique_together = (('field1', 'invalid_field'),)\n\n        errors = InvalidUniqueTogetherModel.check()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'models.E012')\n        self.assertEqual(str(errors[0]), \"'unique_together' refers to the nonexistent field 'invalid_field'.\")\n"], "sample_1206": ["def test_integer_nthroot():\n    assert integer_nthroot(8, 3) == (2, True)\n    assert integer_nthroot(27, 3) == (3, True)\n    assert integer_nthroot(26, 3) == (3, False)\n"], "sample_929": ["def test_parse_annotation(app):\n    env = Mock()\n    env.ref_context = {}\n    result = _parse_annotation(\"List[int]\", env)\n    assert len(result) == 5\n    assert isinstance(result[0], nodes.Text)\n    assert result[0].astext() == \"List\"\n    assert isinstance(result[1], pending_xref)\n    assert result[1]['reftarget'] == \"int\"\n"], "sample_674": ["def test_ischildnode(baseid, nodeid, expected):\n    assert nodes.ischildnode(baseid, nodeid) == expected\n"], "sample_887": ["def test_calibrated_classifier_cv_with_sample_weights(data, method, ensemble):\n    X, y = data\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n    sample_weight = np.random.rand(len(y_train))\n\n    clf = CalibratedClassifierCV(method=method, ensemble=ensemble)\n    clf.fit(X_train, y_train, sample_weight=sample_weight)\n    proba = clf.predict_proba(X_test)\n\n    assert proba.shape == (len(y_test), 2)\n    assert np.all(proba >= 0) and np.all(proba <= 1)\n"], "sample_957": ["def test_restify():\n    assert restify(MyClass1) == ':class:`test_util_typing.MyClass1`'\n    assert restify(MyClass2) == ':class:`test_util_typing.MyClass2`'\n    assert restify(T) == ':obj:`~typing.T`'\n    assert restify(MyInt) == ':class:`MyInt`'\n    assert restify(MyList[int]) == ':class:`test_util_typing.MyList`\\\\ [:class:`int`]'\n    assert restify(Optional[int]) == ':obj:`~typing.Optional`\\\\ [:class:`int`]'\n    assert restify(Union[int, str]) == ':obj:`~typing.Union`\\\\ [:class:`int`, :class:`str`]'\n    assert restify(Union[int, None]) == ':obj:`~typing.Optional`\\\\ [:class:`int`]'\n    assert restify(Union[int, str, None]) == ':obj:`~typing.Optional`\\\\ [:obj:`~typing.Union`\\\\ [:class:`int`, :class:`str`]]'\n    assert restify(Callable[[int], str]) == ':obj:`~typing.Callable`\\\\ [[:class:`int`], :class:`str`]'\n    assert restify(Struct('i')) == ':class:`struct.Struct`'\n    assert restify(TracebackType) == ':class:`types.TracebackType`'\n    assert restify(BrokenType) == \"<class 'test_util_typing.BrokenType'>\"\n"], "sample_25": ["def test_card_fromstring_bytes(self):\n    image = b\"KEYWORD= 'value' / comment\"\n    card = fits.Card.fromstring(image)\n    assert card.keyword == \"KEYWORD\"\n    assert card.value == \"value\"\n    assert card.comment == \"comment\"\n"], "sample_151": ["def test_deconstructible_objects(self):\n    questioner = MigrationQuestioner(specified_apps=[\"testapp\"], dry_run=True)\n    changes = self.get_changes(\n        [self.author_name_deconstructible_1],\n        [self.author_name_deconstructible_2],\n        questioner,\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=DeconstructibleObject())\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_1],\n        [self.author_name_deconstructible_3],\n        questioner,\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=models.IntegerField())\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_3],\n        [self.author_name_deconstructible_4],\n        questioner,\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=models.IntegerField())\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_list_1],\n        [self.author_name_deconstructible_list_2],\n        questioner,\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=[Deconstructible"], "sample_697": ["def test_ensure_relative_to_basetemp(tmp_path_factory: TempPathFactory):\n    # Test that _ensure_relative_to_basetemp raises ValueError for absolute paths\n    with pytest.raises(ValueError):\n        tmp_path_factory._ensure_relative_to_basetemp(str(Path(\"/absolute/path\")))\n\n    # Test that _ensure_relative_to_basetemp raises ValueError for paths outside basetemp\n    with pytest.raises(ValueError):\n        tmp_path_factory._ensure_relative_to_basetemp(\"../outside_basetemp\")\n\n    # Test that _ensure_relative_to_basetemp returns the basename for valid relative paths\n    assert tmp_path_factory._ensure_relative_to_basetemp(\"valid_path\") == \"valid_path\"\n"], "sample_844": ["def test_xi_cluster(r_plot, predecessor_plot, ordering, xi, min_samples, min_cluster_size, predecessor_correction, expected_clusters):\n    clusters = _xi_"], "sample_890": ["def test_sequential_feature_selector_with_classifier():\n    # Test SequentialFeatureSelector with a classifier\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=10, random_state=42)\n    knn = KNeighborsClassifier(n_neighbors=3)\n    sfs = SequentialFeatureSelector(knn, n_features_to_select=5, direction='forward')\n    sfs.fit(X, y)\n    assert sfs.n_features_to_select_ == 5\n    assert_array_equal(sfs.get_support(), np.array([True, False, True, True, False, True, False, False, False, False,\n                                                    False, False, False, False, False, False, False, False, False, False]))\n"], "sample_599": ["def test_cf_mask_coder():\n    data = np.array([1, 2, np.nan, 4])\n    var = xr.Variable(\"x\", data, attrs={\"_FillValue\": np.nan})\n\n    coder = variables.CFMaskCoder()\n    encoded_var = coder.encode(var)\n    assert np.isnan(encoded_var.data).sum() == 0\n\n    decoded_var = coder.decode(encoded_var)\n    assert_equal(decoded_var, var)\n"], "sample_1018": ["def test_print_Matrix():\n    A = MatrixSymbol('A', 3, 3)\n    B = MatrixSymbol('B', 3, 3)\n    mat = A * B\n    code = fcode(mat, A)\n    expected = \"      A(1, 1) = A(1, 1)*B(1, 1) + A(1, 2)*B(2, 1) + A(1, 3)*B(3, 1)\\n\" \\\n               \"      A(1, 2) = A(1, 1)*B(1, 2) + A(1, 2)*B(2, 2) + A(1, 3)*B(3, 2)\\n\" \\\n               \"      A(1, 3) = A(1, 1)*B(1, 3) + A(1, 2)*B(2, 3) + A(1, 3)*B(3, 3)\\n\" \\\n               \"      A(2, 1) = A(2, 1)*B(1, 1) + A(2, 2)*B(2, 1) + A(2, 3)*B(3, 1)\\n\" \\\n               \"      A(2, 2) = A(2, 1)*B(1, 2) + A(2, 2)*B(2, 2) + A(2, 3)*B(3, 2)\\n\" \\\n               \"      A(2, 3) = A(2, 1)*B(1, 3) + A(2, 2)*B(2, 3) + A(2, 3)*B(3, 3)\\n\" \\\n               \"      A(3, 1) = A(3, 1)*B(1, 1) + A(3, 2)*B(2, 1) + A(3, 3)*B(3, 1)\\n\" \\\n               \"      A(3, 2) = A(3, 1)*B(1, 2) + A(3, 2)*B(2, "], "sample_138": ["def test_manifest_files_mixin(self):\n    # Test the ManifestFilesMixin class\n    manifest_storage = storage.StaticFilesStorage(location=self.temp_dir)\n    mixin = storage.ManifestFilesMixin(location=self.temp_dir, manifest_storage=manifest_storage)\n\n    # Test load_manifest method\n    manifest_content = '{\"version\": \"1.0\", \"paths\": {\"test.css\": \"test.12345678.css\"}}'\n    with mock.patch.object(manifest_storage, 'open', return_value=StringIO(manifest_content)):\n        self.assertEqual(mixin.load_manifest(), {\"test.css\": \"test.12345678.css\"})\n\n    # Test save_manifest method\n    mixin.hashed_files = {\"test.css\": \"test.12345678.css\"}\n    mixin.save_manifest()\n    with open(os.path.join(self.temp_dir, mixin.manifest_name)) as manifest_file:\n        self.assertEqual(json.load(manifest_file), {\"paths\": {\"test.css\": \"test.12345678.css\"}, \"version\": \"1.0\"})\n\n    # Test stored_name method\n    self.assertEqual(mixin.stored_name(\"test.css\"), \"test.12345678.css\")\n\n    self.assertPostCondition()\n"], "sample_750": ["def test_omp_with_tol():\n    tol = 1e-3\n    coef = orthogonal_mp(X, y, tol=tol)\n    residual = y - np.dot(X, coef)\n    assert_true(np.all(np.linalg.norm(residual, axis=0) <= tol))\n"], "sample_1002": ["def test_integer_nthroot():\n    assert integer_nthroot(8, 3) == (2, True)\n    assert integer_nthroot(27, 3) == (3, True)\n    assert integer_nthroot(26, 3) == (3, False)\n"], "sample_324": ["def test_csrf_token_rotation(self):\n    req = self._get_GET_csrf_cookie_request()\n    initial_token = get_token(req)\n\n    # Rotate the token\n    rotate_token(req)\n    new_token = get_token(req)\n\n    # Check that the tokens are different\n    self.assertNotEqual(initial_token, new_token)\n\n    # Check that a POST request with the initial token is rejected\n    post_req = self._get_POST_csrf_cookie_request(post_token=initial_token)\n    response = CsrfViewMiddleware().process_view(post_req, token_view, (), {})\n    self.assertEqual(response.status_code, 403)\n    self.assertEqual(response.reason_phrase, REASON_CSRF_TOKEN_MISSING)\n\n    # Check that a POST request with the new token is accepted\n    post_req = self._get_POST_csrf_cookie_request(post_token=new_token)\n    response = CsrfViewMiddleware().process_view(post_req, token_view, (), {})\n    self.assertIsNone(response)\n"], "sample_179": ["    def test_unique_together_with_invalid_field(self):\n        class InvalidUniqueTogetherModel(models.Model):\n            field1 = models.CharField(max_length=10)\n            field2 = models.CharField(max_length=10)\n\n            class Meta:\n                unique_together = (('field1', 'invalid_field'),)\n\n        errors = InvalidUniqueTogetherModel.check()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'models.E012')\n        self.assertEqual(\n            str(errors[0]),\n            \"'unique_together' refers to the nonexistent field 'invalid_field'.\"\n        )\n"], "sample_451": ["    def test_parse_docstring(self):\n        title, body, metadata = parse_docstring(self.docstring)\n        self.assertEqual(title, \"This __doc__ output is required for testing. I copied this example from `admindocs` documentation.\")\n        self.assertIn(\"Display an individual :model:`myapp.MyModel`.\", body)\n        self.assertIn(\":template:`myapp/my_template.html`\", body)\n        self.assertEqual(metadata, {\"some_metadata\": \"some data\"})\n"], "sample_608": ["def test_format_timedelta():\n    # Test formatting of timedelta with different formats\n    td = pd.Timedelta(days=2, hours=3, minutes=4, seconds=5)\n    assert formatting.format_timedelta(td) == \"2 days 03:04:05\"\n    assert formatting.format_timedelta(td, timedelta_format=\"date\") == \"2 days\"\n    assert formatting.format_timedelta(td, timedelta_format=\"time\") == \"03:04:05\"\n"], "sample_1041": ["def test_matrix_element_derivative():\n    M = MatrixSymbol('M', n, n)\n    v = MatrixSymbol('v', n, 1)\n    i, j = symbols('i j', integer=True)\n    me = MatrixElement(M, i, j)\n    dv = MatrixElement(v, i, 0)\n    assert me._eval_derivative(dv) == KroneckerDelta(i, j)\n"], "sample_298": ["    def test_check_token_with_valid_token(self):\n        user = User.objects.create_user(username='testuser', password='12345')\n        now = datetime.now()\n        token_generator = MockedPasswordResetTokenGenerator(now)\n        token = token_generator.make_token(user)\n        self.assertTrue(token_generator.check_token(user, token))\n"], "sample_94": ["def test_create_superuser_with_password_validation_bypass(self):\n    out = StringIO()\n    call_command('createsuperuser', username='bob', interactive=True, stdin=MockTTY(), stdout=out)\n    self.assertIn('Superuser created successfully.', out.getvalue())\n    self.assertTrue(User.objects.filter(username='bob').exists())\n"], "sample_1095": ["def test_applied_permutation():\n    p = Permutation(0, 1, 2)\n    x = Symbol('x')\n    ap = p.apply(x)\n    assert isinstance(ap, AppliedPermutation)\n    assert ap.subs(x, 1) == 2\n"], "sample_638": ["def test_run_with_invalid_format(mock_graphviz, capsys):\n    with pytest.raises(SystemExit) as pytest_wrapped_e:\n        with fix_import_path([\"data\"]):\n            main.Run([\"-o\", \"XYZ\"])\n    out, err = capsys.readouterr()\n    assert \"Format XYZ is not supported natively.\" in out\n    assert pytest_wrapped_e.type == SystemExit\n    assert pytest_wrapped_e.value.code == 1\n"], "sample_288": ["    def test_key_transform_factory(self):\n        factory = KeyTransformFactory('key')\n        transform = factory(F('field'))\n        self.assertIsInstance(transform, KeyTransform)\n        self.assertEqual(transform.key_name, 'key')\n        self.assertEqual(transform.lhs, F('field'))\n"], "sample_489": ["def test_bulk_create_with_ignore_conflicts(self):\n    Country.objects.bulk_create(self.data, ignore_conflicts=True)\n    self.assertEqual(Country.objects.count(), 4)\n    Country.objects.bulk_create(self.data, ignore_conflicts=True)\n    self.assertEqual(Country.objects.count(), 4)\n"], "sample_445": ["    def test_time_strings(self):\n        custom_time_strings = {\n            \"year\": npgettext_lazy(\"%(num)d yr\", \"%(num)d yrs\", \"num\"),\n            \"month\": npgettext_lazy(\"%(num)d mo\", \"%(num)d mos\", \"num\"),\n            \"week\": npgettext_lazy(\"%(num)d wk\", \"%(num)d wks\", \"num\"),\n            \"day\": npgettext_lazy(\"%(num)d d\", \"%(num)d d\", \"num\"),\n            \"hour\": npgettext_lazy(\"%(num)d hr\", \"%(num)d hrs\", \"num\"),\n            \"minute\": npgettext_lazy(\"%(num)d min\", \"%(num)d mins\", \"num\"),\n        }\n        result = timesince(self.t - self.oneyear - self.onemonth - self.oneweek - self.oneday - self.onehour - self.oneminute, self.t, time_strings=custom_time_strings)\n        self.assertEqual(result, \"1 yr, 1 mo, 1 wk, 1 d, 1 hr, 1 min\")\n"], "sample_278": ["def test_filtered_relation(self):\n    # Test the FilteredRelation class\n    filtered_relation = FilteredRelation('employee', condition=Q(salary__gt=20))\n    self.assertEqual(filtered_relation.relation_name, 'employee')\n    self.assertEqual(filtered_relation.condition, Q(salary__gt=20))\n\n    # Test the clone method\n    clone = filtered_relation.clone()\n    self.assertEqual(clone.relation_name, 'employee')\n    self.assertEqual(clone.condition, Q(salary__gt=20))\n    self.assertIsNot(clone, filtered_relation)\n\n    # Test the __eq__ method\n    self.assertEqual(filtered_relation, clone)\n    self.assertNotEqual(filtered_relation, FilteredRelation('employee', condition=Q(salary__gt=30)))\n\n    # Test the resolve_expression method\n    with self.assertRaises(NotImplementedError):\n        filtered_relation.resolve_expression()\n\n    # Test the as_sql method\n    with self.assertRaises(NotImplementedError):\n        filtered_relation.as_sql(None, None)\n"], "sample_807": ["def test_calibration_curve_with_sparse_input():\n    y_true = np.array([0, 0, 1, 1])\n    y_prob = np.array([0.1, 0.2, 0.8, 0.9])\n    y_prob_sparse = sparse.csr_matrix(y_prob)\n\n    prob_true, prob_pred = calibration_curve(y_true, y_prob, n_bins=2)\n    prob_true_sparse, prob_pred_sparse = calibration_curve(y_true, y_prob_sparse, n_bins=2)\n\n    assert_array_almost_equal(prob_true, prob_true_sparse)\n    assert_array_almost_equal(prob_pred, prob_pred_sparse)\n"], "sample_32": ["    def test_w(self):\n        cosmo = self._cls(**self._cls_args, **self._cls_kwargs)\n        z = np.array([0.0, 0.5, 1.0])\n        w = cosmo.w(z)\n        expected_w = self._cls_kwargs[\"w0\"] + self._cls_kwargs[\"wz\"] * z\n        np.testing.assert_allclose(w, expected_w)\n"], "sample_771": ["def test_power_transform_yeo_johnson():\n    X = np.array([[1, 2], [3, 2], [4, 5]])\n    pt = PowerTransformer(method='yeo-johnson')\n    X_trans = pt.fit_transform(X)\n    X_inv = pt.inverse_transform(X_trans)\n    assert_array_almost_equal(X, X_inv)\n"], "sample_11": ["def test_sliced_low_level_wcs_pixel_bounds():\n    sliced_wcs = SlicedLowLevelWCS(WCS_SPECTRAL_CUBE, (slice(1, 10), slice(2, 18), slice(5, 14)))\n    assert_equal(sliced_wcs.pixel_bounds, ((-0, 9), (-0, 16), (0, 9)))\n"], "sample_1065": ["def test_subfactorial():\n    n = Symbol('n', integer=True)\n    assert subfactorial(n + 1) == subfactorial(n + 1)\n    assert subfactorial(5) == 44\n    assert subfactorial(0) == 1\n    assert subfactorial(1) == 0\n    assert subfactorial(n).is_even == (n.is_odd and n.is_nonnegative)\n    assert subfactorial(n).is_integer == (n.is_integer and n.is_nonnegative)\n    assert subfactorial(n).rewrite(uppergamma) == uppergamma(n + 1, -1)/S.Exp1\n    assert subfactorial(n).is_nonnegative == (n.is_integer and n.is_nonnegative)\n    assert subfactorial(n).is_odd == (n.is_even and n.is_nonnegative)\n"], "sample_86": ["def test_lazy_object(self):\n        return \"Test String\"\n\n    lazy_obj = SimpleLazyObject(setup_func)\n    self.assertEqual(lazy_obj._wrapped, empty)\n    self.assertEqual(str(lazy_obj), \"Test String\")\n    self.assertIsInstance(lazy_obj._wrapped, str)\n"], "sample_1199": ["def test_tensor_product_simp_with_commutator():\n    e = TensorProduct(A, Comm(B, C))\n    assert tensor_product_simp(e) == TensorProduct(A, Comm(B, C))\n"], "sample_1080": ["def test_refine_sign_complex():\n    y = Symbol('y', complex=True)\n    expr = sign(y)\n    assert refine(expr, Q.positive(re(y))) == 1\n    assert refine(expr, Q.negative(re(y))) == -1\n    assert refine(expr, Q.zero(re(y)) & Q.positive(im(y))) == I\n    assert refine(expr, Q.zero(re(y)) & Q.negative(im(y))) == -I\n"], "sample_783": ["def test_simple_imputer_with_constant_strategy():\n    X = np.array([[1, 2, np.nan], [3, np.nan, 5], [6, 7, 8]])\n    X_true = np.array([[1, 2, 0], [3, 0, 5], [6, 7, 8]])\n    strategy = \"constant\"\n    fill_value = 0\n    missing_values = np.nan\n    statistics = np.full(X.shape[1], fill_value)\n\n    _check_statistics(X, X_true, strategy, statistics, missing_values)\n"], "sample_563": ["def test_offsetbox_get_bbox():\n    ob = OffsetBox()\n    ob.set_width(100)\n    ob.set_height(50)\n    bbox = ob.get_bbox(None)\n    assert bbox.width == 100\n    assert bbox.height == 50\n    assert bbox.x0 == 0\n    assert bbox.y0 == 0\n"], "sample_211": ["    def test_get_redirect_url(self):\n        view = RedirectView.as_view(url='/redirect-url/')\n        request = self.rf.get('/some-url/')\n        response = view(request)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response.url, '/redirect-url/')\n"], "sample_740": ["def test_check_array_accept_large_sparse():\n    # Test that check_array raises an error when accept_large_sparse is False\n    # and the input is a large sparse matrix\n    X = sp.csr_matrix((10000, 10000), dtype=np.float64)\n    with pytest.raises(ValueError, match=\"Only sparse matrices with 32-bit integer indices are accepted\"):\n        check_array(X, accept_large_sparse=False)\n"], "sample_595": ["def test_str_accessor_replace(dtype):\n    da = xr.DataArray([\"some\", \"text\", \"in\", \"an\", \"array\"], dtype=dtype)\n    replaced = da.str.replace(\"e\", \"a\")\n    expected = xr.DataArray([\"soma\", \"tataxt\", \"in\", \"an\", \"arraay\"], dtype=dtype)\n    assert_equal(replaced, expected)\n"], "sample_123": ["    def test_urlunquote(self):\n        self.assertEqual(urlunquote('%E2%9C%93'), '\u2713')\n        self.assertEqual(urlunquote('%E2%9C%93%20%E2%9C%93'), '\u2713 \u2713')\n"], "sample_735": ["def test_gaussian_mixture_bic_aic():\n    rng = np.random.RandomState(0)\n    data = RandomData(rng)\n\n    for covariance_type in COVARIANCE_TYPE:\n        gmm = GaussianMixture(n_components=data.n_components,\n                              covariance_type=covariance_type,\n                              random_state=rng)\n        gmm.fit(data.X[covariance_type])\n\n        # Test BIC and AIC methods\n        bic = gmm.bic(data.X[covariance_type])\n        aic = gmm.aic(data.X[covariance_type])\n\n        assert_greater(bic, 0)\n        assert_greater(aic, 0)\n        assert_greater(bic, aic)\n"], "sample_932": ["def test_function_pointer_to_member():\n    input = \"void (C::*pmf)(int)\"\n    idDict = {1: \"C::pmf\"}\n    output = \"void (C::*pmf)(int)\"\n    check(\"function\", input, idDict, output)\n"], "sample_99": ["    def test_extract_year(self):\n        dt_model = self.create_model(datetime(2022, 3, 15), datetime(2022, 6, 20))\n        self.assertEqual(DTModel.objects.filter(start_datetime__year=ExtractYear(F('start_datetime'))).count(), 1)\n        self.assertEqual(DTModel.objects.filter(start_datetime__year__gt=ExtractYear(F('start_datetime'))).count(), 0)\n"], "sample_378": ["def test_bulk_update_with_f_expressions(self):\n    self.create_tags()\n    notes = Note.objects.all()\n    notes.update(tag=F('id'))\n    for note in notes:\n        self.assertEqual(note.tag_id, note.id)\n"], "sample_130": ["def test_add_filter_with_related_isnull(self):\n    query = Query(Author)\n    query.add_filter(('items__isnull', True))\n    self.assertEqual(len(query.where.children), 1)\n    self.assertIsInstance(query.where.children[0], RelatedIsNull)\n    self.assertEqual(query.where.children[0].lhs.field, Author._meta.get_field('items'))\n    self.assertTrue(query.where.children[0].rhs)\n"], "sample_23": ["def test_angle_to_string_format():\n    a = Angle(45, unit=u.degree)\n    assert a.to_string(format='unicode') == '45\u00b000\u203200\u2033'\n    assert a.to_string(format='latex') == '$45^\\circ00{}^\\prime00{}^{\\prime\\prime}$'\n    assert a.to_string(format='latex_inline') == '$45^\\circ00{}^\\prime00{}^{\\prime\\prime}$'\n    with pytest.raises(ValueError):\n        a.to_string(format='invalid_format')\n"], "sample_1135": ["def test_mul_eval_expand_mul():\n    expr = (x + y)*(a + b)\n    expanded = expr._eval_expand_mul()\n    assert expanded == x*a + x*b + y*a + y*b\n"], "sample_556": ["def test_figure_align_labels():\n    fig, axs = plt.subplots(2, 2)\n    for ax in axs.flat:\n        ax.label_outer()\n    fig.align_labels()\n"], "sample_371": ["    def test_get_traceback_data(self):\n        request = HttpRequest()\n        exc_type = Exception\n        exc_value = Exception(\"Test exception\")\n        tb = exc_value.__traceback__\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIsInstance(data, dict)\n        self.assertEqual(data['exception_type'], 'Exception')\n        self.assertEqual(data['exception_value'], 'Test exception')\n"], "sample_384": ["def test_bulk_update_with_f_expressions(self):\n    self.create_tags()\n    notes = Note.objects.all()\n    updated_notes = notes.bulk_update(notes, {'note': F('misc'), 'tag': F('tags__first')})\n    self.assertEqual(updated_notes, 10)\n    for note in notes:\n        note.refresh_from_db()\n        self.assertEqual(note.note, note.misc)\n        self.assertEqual(note.tag, self.tags[int(note.misc)])\n"], "sample_203": ["    def test_valid_email(self):\n        validator = validators.EmailValidator()\n        valid_emails = ['test@example.com', 'test.user@example.co.uk', 'test_user@example.com']\n        for email in valid_emails:\n            self.assertIsNone(validator(email))\n"], "sample_918": ["def test_parse_annotation():\n    annotation = \"List[Union[int, str]]\"\n    result = _parse_annotation(annotation)\n    expected = [\n        pending_xref('', nodes.Text('List'), refdomain='py', reftype='class', reftarget='List'),\n        addnodes.desc_sig_punctuation('', '['),\n        pending_xref('', nodes.Text('Union'), refdomain='py', reftype='class', reftarget='Union'),\n        addnodes.desc_sig_punctuation('', '['),\n        pending_xref('', nodes.Text('int'), refdomain='py', reftype='class', reftarget='int'),\n        addnodes.desc_sig_punctuation('', ', '),\n        pending_xref('', nodes.Text('str'), refdomain='py', reftype='class', reftarget='str'),\n        addnodes.desc_sig_punctuation('', ']'),\n        addnodes.desc_sig_punctuation('', ']'),\n    ]\n    assert result == expected\n"], "sample_369": ["def test_deconstructible_objects_are_compared_correctly(self):\n    changes = self.get_changes([self.author_name_deconstructible_1], [self.author_name_deconstructible_2])\n    self.assertNumberMigrations(changes, 'testapp', 0)\n\n    changes = self.get_changes([self.author_name_deconstructible_1], [self.author_name_deconstructible_3])\n    self.assertNumberMigrations(changes, 'testapp', 1)\n\n    changes = self.get_changes([self.author_name_deconstructible_3], [self.author_name_deconstructible_4])\n    self.assertNumberMigrations(changes, 'testapp', 1)\n\n    changes = self.get_changes([self.author_name_deconstructible_list_1], [self.author_name_deconstructible_list_2])\n    self.assertNumberMigrations(changes, 'testapp', 0)\n\n    changes = self.get_changes([self.author_name_deconstructible_list_1], [self.author_name_deconstructible_list_3])\n    self.assertNumberMigrations(changes, 'testapp', 1)\n\n    changes = self.get_changes([self.author_name_deconstructible_tuple_1], [self.author_name_deconstructible_tuple_2])\n    self.assertNumberMigrations(changes, 'testapp', 0)\n\n    changes = self.get_changes([self.author_name_deconstructible_tuple_1], [self.author_name_deconstructible_tuple_3])\n    self.assertNumberMigrations(changes, 'testapp', 1)\n\n    changes = self.get_changes([self.author_name_deconstructible_dict_1], [self.author_name_deconstructible_dict_2])\n    self.assertNumberMigrations(changes, 'testapp', 0)\n\n    changes = self.get_changes([self.author_name_deconstructible_dict_1], [self.author_name"], "sample_974": ["def test_ccode_for_loop():\n    i = symbols('i', integer=True)\n    expr = For(i, Range(0, 10), Assignment(x, x + i))\n    result = ccode(expr)\n    expected = \"for (i = 0; i < 10; i += 1) {\\n   x = x + i;\\n}\"\n    assert result == expected\n"], "sample_388": ["    def setUp(self):\n        self.patched_settings = modify_settings(\n            MIDDLEWARE={\"append\": self.middleware},\n        )\n        self.patched_settings.enable()\n"], "sample_817": ["def test_variance_threshold():\n    X = np.array(data)\n    selector = VarianceThreshold(threshold=1.5)\n    selector.fit(X)\n    expected_variances = np.var(X, axis=0)\n    assert_array_equal(selector.variances_, expected_variances)\n    expected_support = np.array([False, True, True, True, False])\n    assert_array_equal(selector._get_support_mask(), expected_support)\n"], "sample_259": ["def test_prefetch_related_objects_with_prefetch(self):\n    authors = Author.objects.all()\n    prefetch_related_objects(authors, Prefetch('books_written', queryset=Book.objects.filter(title__startswith='W')))\n    for author in authors:\n        self.assertTrue(hasattr(author, '_prefetched_objects_cache'))\n        self.assertIn('books_written', author._prefetched_objects_cache)\n        books = author._prefetched_objects_cache['books_written']\n        self.assertEqual(len(books), 1 if author == self.author3 else 0)\n        if author == self.author3:\n            self.assertEqual(books[0].title, 'Wuthering Heights')\n"], "sample_169": ["    def test_serializer_with_json_field(self):\n        obj = JSONModel.objects.create(json_field={'key': 'value'})\n        serialized_data = serializers.serialize('xml', JSONModel.objects.all())\n        deserialized_data = list(serializers.deserialize('xml', serialized_data))\n        self.assertEqual(len(deserialized_data), 1)\n        self.assertEqual(deserialized_data[0].object.json_field, {'key': 'value'})\n"], "sample_561": ["def test_marker_transform():\n    marker = markers.MarkerStyle('o')\n    transformed_marker = marker.transformed(Affine2D().scale(2))\n    assert transformed_marker.get_transform().get_matrix()[0, 0] == 2\n"], "sample_374": ["def test_prefetch_related_objects_with_empty_queryset(self):\n    # Test prefetch_related_objects with an empty queryset\n    empty_queryset = Book.objects.none()\n    prefetch_related_objects(empty_queryset, 'authors')\n    self.assertEqual(len(empty_queryset), 0)\n"], "sample_910": ["def test_is_suppressed_warning():\n    assert is_suppressed_warning('ref.python', None, ['ref.python'])\n    assert is_suppressed_warning('ref.python', 'module', ['ref.python.module'])\n    assert is_suppressed_warning('ref.python', 'module', ['ref.python.*'])\n    assert not is_suppressed_warning('ref.python', 'module', ['ref.python.class'])\n    assert not is_suppressed_warning('ref.cpp', None, ['ref.python'])\n    assert not is_suppressed_warning(None, None, ['ref.python'])\n"], "sample_720": ["def test_quantile_transformer_invalid_n_quantiles():\n    X = np.array([[1], [2], [3]])\n    qt = QuantileTransformer(n_quantiles=0)\n    assert_raises(ValueError, qt.fit, X)\n"], "sample_792": ["def test_gaussian_nb_partial_fit():\n    gnb = GaussianNB()\n    gnb.partial_fit(X1[:5], y1[:5], np.unique(y1))\n    assert_array_almost_equal(gnb.predict(X1[5:]), y1[5:])\n    gnb.partial_fit(X1[5:], y1[5:])\n    assert_array_almost_equal(gnb.predict(X1), y1)\n"], "sample_955": ["compilation error"], "sample_869": ["def test_brier_score_loss():\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    expected_score = 0.037\n    assert_almost_equal(brier_score_loss(y_true, y_prob), expected_score)\n"], "sample_1177": ["def test_sign_derivative():\n    x = Symbol('x', real=True)\n    assert sign(x)._eval_derivative(x) == 2 * DiracDelta(x)\n    assert sign(I*x)._eval_derivative(x) == -2 * I * DiracDelta(I*x)\n"], "sample_965": ["def test_signature_from_str():\n    sig = inspect.signature_from_str(\"(a: int, b: str = 'default')\")\n    assert str(sig) == \"(a: int, b: str = 'default')\"\n"], "sample_775": ["def test_estimator_pretty_printer_with_changed_only():\n    set_config(print_changed_only=True)\n    pipeline = make_pipeline(StandardScaler(), LogisticRegression(C=1.0, penalty='l2'))\n    pipeline.set_params(logisticregression__C=0.5)\n    printer = _EstimatorPrettyPrinter(compact=True)\n    output = printer.pformat(pipeline)\n    assert \"C=0.5\" in output\n    assert \"penalty='l2'\" not in output\n"], "sample_325": ["    def test_bound_field_subwidgets(self):\n        form = PersonNew(data={'first_name': 'John', 'last_name': 'Doe', 'birthday': '1990-01-01'})\n        bound_field = form['first_name']\n        subwidgets = bound_field.subwidgets\n        self.assertEqual(len(subwidgets), 1)\n        self.assertEqual(subwidgets[0].id_for_label, 'first_name_id')\n"], "sample_205": ["def test_validation_error_message_dict(self):\n    error = ValidationError({'field1': ['Error 1'], 'field2': ['Error 2']})\n    self.assertEqual(error.message_dict, {'field1': ['Error 1'], 'field2': ['Error 2']})\n"], "sample_85": ["def test_m2m_field_deconstruct(self):\n    m2m_field = models.ManyToManyField(M2MTo, through='custom_through_model')\n    name, path, args, kwargs = m2m_field.deconstruct()\n    self.assertEqual(name, 'ManyToManyField')\n    self.assertEqual(path, 'django.db.models.fields.related')\n    self.assertEqual(args, [])\n    self.assertEqual(kwargs, {'to': 'custom_through_model', 'through': 'custom_through_model'})\n"], "sample_634": ["def test_expand_modules_with_ignore_list_re(self):\n    ignore_list_re = [re.compile(r'test_.*\\.py')]\n    files_or_modules = ['test_file.py', 'valid_file.py']\n    result, errors = expand_modules(files_or_modules, [], ignore_list_re, [])\n    assert len(result) == 1\n    assert result[0]['name'] == 'valid_file'\n"], "sample_909": ["    def test_numpy_docstring(self):\n        docstring = '''One line summary.\n\n        Extended description.\n\n        Parameters\n        ----------\n        arg1 : int\n            Description of `arg1`\n        arg2 : str\n            Description of `arg2`\n\n        Returns\n        -------\n        str\n            Description of return value.\n        '''\n        config = Config(napoleon_use_param=True, napoleon_use_rtype=True)\n        expected_output = '''One line summary.\n\n        Extended description.\n\n        :param arg1: Description of `arg1`\n        :type arg1: int\n        :param arg2: Description of `arg2`\n        :type arg2: str\n\n        :returns: Description of return value.\n        :rtype: str\n        '''\n        self.assertEqual(str(NumpyDocstring(docstring, config)), dedent(expected_output).strip())\n"], "sample_612": ["def test_consolidate_slices():\n    slices = [slice(0, 5), slice(5, 10), slice(10, 15, 2)]\n    result = _consolidate_slices(slices)\n    expected = [slice(0, 10), slice(10, 15, 2)]\n    assert result == expected\n"], "sample_399": ["def test_aggregate_with_filter(self):\n    # Test aggregate with filter\n    result = Book.objects.filter(publisher=self.p1).aggregate(Avg('pages'))\n    self.assertEqual(result['pages__avg'], 382.0)\n"], "sample_91": ["def test_page_not_found(self):\n    \"\"\"Test the page_not_found view\"\"\"\n    request = self.request_factory.get('/nonexistent_url/')\n    response = page_not_found(request, Http404())\n    self.assertEqual(response.status_code, 404)\n    self.assertContains(response, 'Not Found')\n    self.assertContains(response, 'The requested resource was not found on this server.')\n"], "sample_1104": ["def test_print_Tr():\n    A = Matrix([[1, 2], [3, 4]])\n    assert sstr(Tr(A)) == \"Tr(Matrix([[1, 2], [3, 4]]))\"\n"], "sample_293": ["def test_is_callback(self):\n    resolver = get_resolver()\n    self.assertTrue(resolver._is_callback('urlpatterns_reverse.views.empty_view'))\n    self.assertFalse(resolver._is_callback('nonexistent_view'))\n"], "sample_56": ["    def test_check_autocomplete_fields(self):\n        class InvalidAutocompleteFields(admin.ModelAdmin):\n            autocomplete_fields = 'title'\n\n        class InvalidAutocompleteFieldsItem(admin.ModelAdmin):\n            autocomplete_fields = ['invalid_field']\n\n        class ValidAutocompleteFieldsItem(admin.ModelAdmin):\n            autocomplete_fields = ['author']\n\n        class NoRelatedAdmin(admin.ModelAdmin):\n            autocomplete_fields = ['city']\n\n        class NoSearchFields(admin.ModelAdmin):\n            autocomplete_fields = ['state']\n\n        site = AdminSite()\n        site.register(Song, ValidAutocompleteFieldsItem)\n\n        self.assertEqual(\n            ModelAdminChecks()._check_autocomplete_fields(InvalidAutocompleteFields()),\n            must_be('a list or tuple', option='autocomplete_fields', obj=InvalidAutocompleteFields(), id='admin.E036')\n        )\n        self.assertEqual(\n            ModelAdminChecks()._check_autocomplete_fields_item(InvalidAutocompleteFieldsItem(), 'invalid_field', 'autocomplete_fields[0]'),\n            refer_to_missing_field(field='invalid_field', option='autocomplete_fields[0]', obj=InvalidAutocompleteFieldsItem(), id='admin.E037')\n        )\n        self.assertEqual(\n            ModelAdminChecks()._check_autocomplete_fields_item(ValidAutocompleteFieldsItem(), 'author', 'autocomplete_fields[0]'),\n            []\n        )\n        self.assertEqual(\n            ModelAdminChecks()._check_autocomplete_fields_item(NoRelatedAdmin(), 'city', 'autocomplete_fields[0]'),\n            [checks.Error(\n                \"An admin for model \\\"City\\\" has to be registered to be referenced by ValidAutocompleteFieldsItem.autocomplete_fields.\",\n                obj=NoRelatedAdmin.__class__,\n                id='admin.E039',\n            )]\n        )\n       "], "sample_260": ["def test_alter_model_options_with_delete_model(self):\n    operations = [\n        migrations.CreateModel(\n            name='TestModel',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n            ],\n        ),\n        migrations.AlterModelOptions(\n            name='TestModel',\n            options={'verbose_name': 'New Verbose Name'},\n        ),\n        migrations.DeleteModel(\n            name='TestModel',\n        ),\n    ]\n    expected = []\n    self.assertOptimizesTo(operations, expected)\n"], "sample_889": ["def test_calibrated_classifier_cv_with_sample_weights(data, method, ensemble):\n    X, y = data\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n    sample_weight = np.random.rand(y_train.shape[0])\n\n    clf = CalibratedClassifierCV(method=method, ensemble=ensemble)\n    clf.fit(X_train, y_train, sample_weight=sample_weight)\n    proba = clf.predict_proba(X_test)\n\n    assert proba.shape == (X_test.shape[0], 2)\n    assert np.all(proba >= 0) and np.all(proba <= 1)\n"], "sample_1175": ["compilation error"], "sample_389": ["    def test_get_host(self):\n        request = HttpRequest()\n        request.META = {\"HTTP_HOST\": \"example.com\"}\n        self.assertEqual(request.get_host(), \"example.com\")\n"], "sample_336": ["def test_extend_tried(self):\n    tried = []\n    pattern = 'test_pattern'\n    sub_tried = [['sub_pattern1'], ['sub_pattern2']]\n    URLResolver._extend_tried(tried, pattern, sub_tried)\n    self.assertEqual(tried, [['test_pattern', 'sub_pattern1'], ['test_pattern', 'sub_pattern2']])\n"], "sample_276": ["def test_get_return_data_type(self):\n    self.assertEqual(get_return_data_type('get_list'), 'List')\n    self.assertEqual(get_return_data_type('get_count'), 'Integer')\n    self.assertEqual(get_return_data_type('get_item'), '')\n"], "sample_757": ["def test_ordinal_encoder_inverse_transform():\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    X_transformed = enc.transform(X)\n    X_inverse = enc.inverse_transform(X_transformed)\n    assert_array_equal(X, X_inverse)\n"], "sample_1166": ["def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n"], "sample_128": ["    def test_index_creation_and_deletion(self):\n        index = Index(fields=['title'], name='test_index')\n        sql = index.create_sql(Article, connection.schema_editor())\n        self.assertIn('CREATE INDEX', sql)\n        self.assertIn('test_index', sql)\n        self.assertIn('title', sql)\n\n        remove_sql = index.remove_sql(Article, connection.schema_editor())\n        self.assertIn('DROP INDEX', remove_sql)\n        self.assertIn('test_index', remove_sql)\n"], "sample_803": ["def test_roc_auc_score_max_fpr(drop):\n    y_true = np.array([0, 0, 1, 1])\n    y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n    max_fpr = 0.5\n    expected_auc = _partial_roc_auc_score(y_true, y_scores, max_fpr)\n    assert_almost_equal(roc_auc_score(y_true, y_scores, max_fpr=max_fpr), expected_auc)\n"], "sample_28": ["def test_card_fromstring_with_bytes(self):\n    image = b\"KEYWORD= 'value' / comment\"\n    card = fits.Card.fromstring(image)\n    assert card.keyword == \"KEYWORD\"\n    assert card.value == \"value\"\n    assert card.comment == \"comment\"\n"], "sample_883": ["def test_bayesian_ridge_n_iter_deprecation():\n    X, y = diabetes.data, diabetes.target\n    br = BayesianRidge(n_iter=100)\n    with pytest.warns(FutureWarning, match=\"'n_iter' was renamed to 'max_iter'\"):\n        br.fit(X, y)\n    assert br.n_iter_ == 100\n"], "sample_511": ["def test_set_cmap():\n    plt.set_cmap('viridis')\n    assert plt.rcParams['image.cmap'] == 'viridis'\n    im = plt.gci()\n    if im is not None:\n        assert im.get_cmap().name == 'viridis'\n"], "sample_676": ["def test_plugin_nameversions(input, expected):\n    assert _plugin_nameversions(input) == expected\n"], "sample_152": ["def test_restricted_error_raised_for_restricted_objects(self):\n    # Create a restricted object\n    restricted_obj = R.objects.create()\n    # Create an object that references the restricted object\n    obj = MR.objects.create(r=restricted_obj)\n    # Create a collector and collect the object\n    collector = Collector(using=connection.alias)\n    collector.collect([obj])\n    # Check that a RestrictedError is raised when deleting the object\n    with self.assertRaises(RestrictedError):\n        collector.delete()\n"], "sample_247": ["    def test_aggregate_annotation(self):\n        authors = Author.objects.annotate(num_books=Count('book')).order_by('num_books')\n        self.assertEqual(authors[0].num_books, 1)\n        self.assertEqual(authors[1].num_books, 1)\n        self.assertEqual(authors[2].num_books, 1)\n        self.assertEqual(authors[3].num_books, 2)\n        self.assertEqual(authors[4].num_books, 2)\n        self.assertEqual(authors[5].num_books, 3)\n        self.assertEqual(authors[6].num_books, 3)\n        self.assertEqual(authors[7].num_books, 3)\n        self.assertEqual(authors[8].num_books, 4)\n\n        authors = Author.objects.annotate(num_books=Count('book', distinct=True)).order_by('num_books')\n        self.assertEqual(authors[0].num_books, 1)\n        self.assertEqual(authors[1].num_books, 1)\n        self.assertEqual(authors[2].num_books, 1)\n        self.assertEqual(authors[3].num_books, 2)\n        self.assertEqual(authors[4].num_books, 2)\n        self.assertEqual(authors[5].num_books, 3)\n        self.assertEqual(authors[6].num_books, 3)\n        self.assertEqual(authors[7].num_books, 3)\n        self.assertEqual(authors[8].num_books, 4)\n\n        authors = Author.objects.annotate(num_books=Count('book', filter=Q(book__rating__gt=4))).order_by('num_books')\n        self.assertEqual(authors[0].num_books, 0)\n        self.assertEqual(authors[1].num_books, 0)\n        self.assertEqual(authors[2].num_books, 0)\n        self."], "sample_715": ["def test_cross_validate_with_multimetric_scoring():\n    estimator = MockClassifier()\n    scoring = {'accuracy': make_scorer(accuracy_score),\n               'precision': make_scorer(precision_score, average='macro')}\n    cv_results = cross_validate(estimator, X, y, scoring=scoring, cv=3)\n    assert_equal(sorted(cv_results.keys()),\n                 ['fit_time', 'score_time', 'test_accuracy', 'test_precision'])\n    assert_equal(cv_results['test_accuracy'].shape, (3,))\n    assert_equal(cv_results['test_precision'].shape, (3,))\n"], "sample_544": ["def test_image_interps():\n    fig, axs = plt.subplots(2, 2, figsize=(6, 6))\n    data = np.arange(100).reshape((10, 10))\n\n    for ax, interp in zip(axs.flat, ['nearest', 'bilinear', 'bicubic', 'none']):\n        ax.imshow(data, interpolation=interp)\n        ax.set_title(f'Interpolation: {interp}')\n\n    plt.tight_layout()\n"], "sample_545": ["def test_figure_align_labels():\n    fig, axs = plt.subplots(2, 2)\n    for ax in axs.flat:\n        ax.label_outer()\n    fig.align_labels()\n"], "sample_640": ["compilation error"], "sample_698": ["def test_colored_level_formatter():\n    terminalwriter = TerminalWriter()\n    formatter = ColoredLevelFormatter(terminalwriter, \"%(levelname)s: %(message)s\")\n    record = logging.LogRecord(\"test_logger\", logging.INFO, \"test_module\", 123, \"Test message\", (), None)\n    formatted_message = formatter.format(record)\n    assert \"INFO\" in formatted_message\n    assert \"Test message\" in formatted_message\n    assert \"\\x1b[32m\" in formatted_message  # Green color for INFO level\n    assert \"\\x1b[0m\" in formatted_message  # Reset color at the end\n"], "sample_423": ["def test_deconstructible_objects_are_compared_correctly(self):\n    changes = self.get_changes(\n        [self.author_name_deconstructible_1],\n        [self.author_name_deconstructible_2],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 0)\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_1],\n        [self.author_name_deconstructible_3],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_1],\n        [self.author_name_deconstructible_4],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_list_1],\n        [self.author_name_deconstructible_list_2],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 0)\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_list_1],\n        [self.author_name_deconstructible_list_3],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_tuple_1],\n        [self.author_name_deconstructible_tuple_2],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 0)\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_tuple_1],\n        [self.author_name_deconstructible_tuple_3],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_dict_1],\n        [self.author"], "sample_911": ["compilation error"], "sample_1169": ["def test_contraction():\n    p, q = symbols('p,q')\n    a, b = symbols('a,b', above_fermi=True)\n    i, j = symbols('i,j', below_fermi=True)\n\n    assert contraction(F(a), Fd(b)) == KroneckerDelta(a, b)\n    assert contraction(Fd(i), F(j)) == KroneckerDelta(i, j)\n    assert contraction(Fd(p), F(q)) == KroneckerDelta(Dummy('i', below_fermi=True), q) * KroneckerDelta(p, q)\n    assert contraction(F(p), Fd(q)) == KroneckerDelta(Dummy('a', above_fermi=True), q) * KroneckerDelta(p, q)\n    assert contraction(F(p), F(q)) == 0\n    assert contraction(Fd(p), Fd(q)) == 0\n\n    with raises(ContractionAppliesOnlyToFermions):\n        contraction(B(p), Bd(q))\n"], "sample_660": ["def test_add_global_property(self):\n    logxml = LogXML(\"junit.xml\", \"prefix\")\n    logxml.add_global_property(\"key\", \"value\")\n    properties_node = logxml._get_global_properties_node()\n    assert properties_node.tag == \"properties\"\n    property_node = properties_node.get_unique_child\n    assert property_node.tag == \"property\"\n    property_node.assert_attr(name=\"key\", value=\"value\")\n"], "sample_798": ["def test_ridge_regression_solver_convergence(solver):\n    # Test that the solver converges for a simple case\n    X = np.array([[1, 0], [0, 1], [0, 0]])\n    y = np.array([1, 1, 0])\n    alpha = 0.1\n    coef, n_iter = ridge_regression(X, y, alpha, solver=solver, return_n_iter=True)\n    assert_greater(n_iter, 0)\n"], "sample_1188": ["def test_pretty_print_Integral():\n    expr = Integral(f(b), (b, 0, 1))\n    assert pretty(expr) == \"\u222b\\n\u23a7\u23aa\u23a8\u23aa\u23a9\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa f(b) db\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n\u23aa\u23aa\u23aa\\n"], "sample_97": ["    def test_zip_imported_module(self):\n        zip_filename = self.temporary_file('test.zip')\n        with zipfile.ZipFile(zip_filename, 'w') as zf:\n            zf.writestr('test_module.py', 'print(\"Hello, World!\")')\n        sys.path.insert(0, str(zip_filename))\n        self.addCleanup(sys.path.remove, str(zip_filename))\n        self.import_and_cleanup('test_module')\n        self.assertFileFound(zip_filename)\n"], "sample_851": ["def test_mean_tweedie_deviance_power_zero():\n    y_true = [2, 0, 1, 4]\n    y_pred = [2.5, 0.5, 1.2, 3.8]\n    expected_deviance = mean_squared_error(y_true, y_pred)\n    assert_almost_equal(mean_tweedie_deviance(y_true, y_pred, power=0), expected_deviance)\n"], "sample_449": ["    def test_handle_one_request(self):\n        request = self.request_factory.get('/')\n        environ = WSGIRequest(request).environ\n        stdout = UnclosableBytesIO()\n        stderr = BytesIO()\n        handler = WSGIRequestHandler(Stub(rfile=BytesIO(), wfile=stdout, get_stderr=lambda: stderr), ('127.0.0.1', 80), Stub(base_environ=environ))\n        handler.handle_one_request()\n        self.assertIn(b'HTTP/1.1 200 OK', stdout.getvalue())\n"], "sample_756": ["def test_optics_min_cluster_size():\n    # Test that min_cluster_size parameter works correctly\n    optics = OPTICS(min_cluster_size=0.1)\n    optics.fit(X)\n    assert len(np.unique(optics.labels_)) > 6  # There should be more than 6 clusters\n\n    optics = OPTICS(min_cluster_size=0.5)\n    optics.fit(X)\n    assert len(np.unique(optics.labels_)) <= 6  # There should be 6 or fewer clusters\n"], "sample_115": ["    def test_get_traceback_data(self):\n        request = RequestFactory().get('/')\n        exc_type = TemplateDoesNotExist\n        exc_value = TemplateDoesNotExist('template.html')\n        tb = None\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertTrue(data['template_does_not_exist'])\n        self.assertEqual(data['postmortem'], [exc_value])\n"], "sample_778": ["def test_nmf_sparse_input():\n    # Test NMF with sparse input\n    X = sp.csr_matrix([[1, 2], [3, 4]])\n    nmf = NMF(n_components=2, init='random', random_state=0)\n    W = nmf.fit_transform(X)\n    H = nmf.components_\n    assert_array_almost_equal(X.toarray(), np.dot(W, H))\n"], "sample_72": ["    def test_uuid_serializer(self):\n        value = uuid.uuid4()\n        serializer = serializer_factory(value)\n        self.assertIsInstance(serializer, UUIDSerializer)\n        serialized, imports = serializer.serialize()\n        self.assertEqual(serialized, \"uuid.%s\" % repr(value))\n        self.assertEqual(imports, {\"import uuid\"})\n"], "sample_846": ["def test_column_transformer_with_callable_column_specifier():\n    ct = ColumnTransformer(\n        [(\"trans\", Trans(), lambda X: [0, 1])],\n        remainder='drop'\n    )\n    X = np.array([[0., 1., 2., 2.],\n                  [1., 1., 0., 1.]])\n    X_transformed = ct.fit_transform(X)\n    assert_array_equal(X_transformed, np.array([[0., 1.],\n                                                [1., 1.]]))\n"], "sample_538": ["def test_transformed_patch_path():\n    patch = mpatches.Circle((0, 0), radius=1)\n    transformed_patch_path = mtransforms.TransformedPatchPath(patch)\n    transformed_path, affine = transformed_patch_path.get_transformed_path_and_affine()\n    assert isinstance(transformed_path, Path)\n    assert isinstance(affine, mtransforms.Affine2D)\n"], "sample_850": ["def test_skewed_chi2_sampler():\n    skewedness = 0.01\n    n_components = 10\n    random_state = 0\n    chi2_feature = SkewedChi2Sampler(skewedness=skewedness,\n                                     n_components=n_components,\n                                     random_state=random_state)\n    X_features = chi2_feature.fit_transform(X, Y)\n    assert X_features.shape == (300, n_components)\n    assert_raises(ValueError, chi2_feature.transform, -X)\n"], "sample_174": ["def test_date_extract_sql(self):\n    with self.assertRaisesMessage(NotImplementedError, self.may_require_msg % 'date_extract_sql'):\n        self.ops.date_extract_sql('year', 'field_name')\n"], "sample_88": ["    def test_attach_file(self):\n        temp_dir = tempfile.mkdtemp()\n        try:\n            file_path = os.path.join(temp_dir, 'test.txt')\n            with open(file_path, 'w') as f:\n                f.write('Test content')\n\n            email = EmailMessage(\n                subject='Test email',\n                body='Test body',\n                from_email='from@example.com',\n                to=['to@example.com'],\n            )\n            email.attach_file(file_path)\n\n            attachments = self.get_decoded_attachments(email)\n            self.assertEqual(len(attachments), 1)\n            filename, content, mimetype = attachments[0]\n            self.assertEqual(filename, 'test.txt')\n            self.assertEqual(content, b'Test content')\n            self.assertEqual(mimetype, 'text/plain')\n        finally:\n            shutil.rmtree(temp_dir)\n"], "sample_552": ["def test_figure_align_labels():\n    fig, axs = plt.subplots(2, 2)\n    for ax in axs.flat:\n        ax.label_outer()\n    fig.align_labels()\n"], "sample_706": ["def test_not_expression():\n    assert evaluate(\"not test\", lambda x: x == \"test\") is False\n    assert evaluate(\"not not test\", lambda x: x == \"test\") is True\n"], "sample_315": ["    def setUp(self):\n        super().setUp()\n        self.factory = RequestFactory()\n        self.middleware = LocaleMiddleware()\n"], "sample_601": ["def test_season(self, field):\n    result = self.times_data.dt[field]\n    expected = self.times.to_series().dt[field]\n    assert_array_equal(result, expected)\n"], "sample_1092": ["def test_cse_with_matrices():\n    A = Matrix([[x + y, z], [w, x + z]])\n    B = Matrix([[x + y, z + 1], [w + 1, x + z + 1]])\n    replacements, reduced_exprs = cse([A, B])\n    assert len(replacements) == 2\n    assert reduced_exprs == [Matrix([[x0, z], [w, x + z]]), Matrix([[x0, z + 1], [w + 1, x + z + 1]])]\n"], "sample_600": ["def test_cf_scale_offset_coder():\n    data = np.array([1, 2, 3], dtype=np.float32)\n    scale_factor = 2.0\n    add_offset = 1.0\n    encoded_data = (data - add_offset) / scale_factor\n    variable = xr.Variable(\"x\", encoded_data, attrs={\"scale_factor\": scale_factor, \"add_offset\": add_offset})\n\n    coder = variables.CFScaleOffsetCoder()\n    decoded_variable = coder.decode(variable)\n\n    assert_allclose(decoded_variable.data, data)\n"], "sample_1031": ["def test_planck_units():\n    from sympy.physics.units.definitions import (\n        planck_mass, planck_time, planck_temperature, planck_length, planck_charge,\n        planck_area, planck_volume, planck_momentum, planck_energy, planck_force,\n        planck_power, planck_density, planck_energy_density, planck_intensity,\n        planck_angular_frequency, planck_pressure, planck_current, planck_voltage,\n        planck_impedance, planck_acceleration\n    )\n    from sympy.physics.units.definitions import (\n        hbar, speed_of_light, G, boltzmann, electric_constant\n    )\n    from sympy.core.numbers import sqrt\n\n    assert planck_mass == sqrt(hbar*speed_of_light/G)\n    assert planck_time == sqrt(hbar*G/speed_of_light**5)\n    assert planck_temperature == sqrt(hbar*speed_of_light**5/G/boltzmann**2)\n    assert planck_length == sqrt(hbar*G/speed_of_light**3)\n    assert planck_charge == sqrt(4*pi*electric_constant*hbar*speed_of_light)\n    assert planck_area == planck_length**2\n    assert planck_volume == planck_length**3\n    assert planck_momentum == planck_mass * speed_of_light\n    assert planck_energy == planck_mass * speed_of_light**2\n    assert planck_force == planck_energy / planck_length\n    assert planck_power == planck_energy / planck_time\n    assert planck_density == planck_mass / planck_length**3\n    assert planck_energy_density == planck_energy / planck_length**3\n    assert planck_intensity == planck_energy_density * speed_of_light\n    assert planck_angular_frequency == 1 / planck_time\n    assert plan"], "sample_764": ["def test_column_transformer_with_callable_column_specifier():\n    ct = ColumnTransformer(\n        [(\"trans\", Trans(), lambda X: [0, 1]),\n         (\"doubletrans\", DoubleTrans(), lambda X: [2, 3])])\n    X = np.array([[0., 1., 2., 2.],\n                  [1., 1., 0., 1.]])\n    X_transformed = ct.fit_transform(X)\n    assert_array_equal(X_transformed, np.array([[0., 1., 4., 4.],\n                                                [1., 1., 0., 2.]]))\n"], "sample_836": ["def test_ovr_decision_function():\n    # Test the _ovr_decision_function function\n    predictions = np.array([[0, 1, 0], [1, 0, 1]])\n    confidences = np.array([[0.9, 0.8, 0.7], [0.6, 0.5, 0.4]])\n    n_classes = 3\n    expected_output = np.array([[0.03333333, 0.96666667, -0.03333333],\n                                [-0.03333333, 0.03333333, 0.96666667]])\n    assert_array_almost_equal(_ovr_decision_function(predictions, confidences, n_classes), expected_output)\n"], "sample_560": ["def test_legend_set_loc():\n    fig, ax = plt.subplots()\n    legend = ax.legend(['label1', 'label2'], loc='upper right')\n    assert legend._loc == 1\n    legend.set_loc('lower left')\n    assert legend._loc == 3\n    legend.set_loc((0.5, 0.5))\n    assert legend._loc == (0.5, 0.5)\n    legend.set_loc(4)\n    assert legend._loc == 4\n    with pytest.raises(ValueError):\n        legend.set_loc('invalid_loc')\n    with pytest.raises(ValueError):\n        legend.set_loc((0.5, 0.5, 0.5))\n    with pytest.raises(ValueError):\n        legend.set_loc(11)\n"], "sample_685": ["def test_log_capture_fixture_at_level(caplog):\n    caplog.set_level(logging.INFO)\n    logger.debug(\"This message should not be captured\")\n    logger.info(\"This message should be captured\")\n    with caplog.at_level(logging.DEBUG):\n        logger.debug(\"This message should be captured\")\n    logger.info(\"This message should be captured\")\n    assert len(caplog.records) == 3\n    assert caplog.record_tuples == [\n        (__name__, logging.INFO, \"This message should be captured\"),\n        (__name__, logging.DEBUG, \"This message should be captured\"),\n        (__name__, logging.INFO, \"This message should be captured\"),\n    ]\n"], "sample_843": ["def test_kernel_call_with_eval_gradient(kernel):\n    K, K_gradient = kernel(X, eval_gradient=True)\n    assert K.shape == (X.shape[0], X.shape[0])\n    assert K_gradient.shape == (X.shape[0], X.shape[0], kernel.n_dims)\n"], "sample_1158": ["def test_sympify_with_numpy_array():\n    a = numpy.array([1, 2, 3])\n    result = sympify(a)\n    assert isinstance(result, ImmutableDenseNDimArray)\n    assert result.shape == (3,)\n    assert result.tolist() == [1, 2, 3]\n"], "sample_587": ["def test_merge_variables_compat_override(self):\n    var1 = xr.Variable((\"x\",), np.array([1, 2, 3]))\n    var2 = xr.Variable((\"x\",), np.array([4, 5, 6]))\n    variables = merge.merge_variables([{var1.name: var1}, {var1.name: var2}], compat=\"override\")\n    xr.testing.assert_equal(variables[var1.name], var2)\n"], "sample_970": ["def test_signature_from_str():\n    sig = inspect.signature_from_str(\"(a: int, b: str = 'default')\")\n    assert str(sig) == \"(a: int, b: str = 'default')\"\n"], "sample_150": ["def test_check_database_backends_with_errors(self, mock_check):\n    mock_check.return_value = [\n        checks.Error('Error message 1', id='database.E001'),\n        checks.Warning('Warning message 1', id='database.W001'),\n    ]\n\n    with self.assertRaises(SystemCheckError) as context:\n        self.command.check(databases=['default', 'other'])\n\n    self.assertIn('SystemCheckError: System check identified some issues:', str(context.exception))\n    self.assertIn('ERRORS:', str(context.exception))\n    self.assertIn('Error message 1', str(context.exception))\n    self.assertIn('WARNINGS:', str(context.exception))\n    self.assertIn('Warning message 1', str(context.exception))\n"], "sample_972": ["def test_restify():\n    assert restify(MyClass1) == ':py:class:`test_util_typing.MyClass1`'\n    assert restify(MyClass2) == ':py:class:`test_util_typing.MyClass2`'\n    assert restify(MyInt) == ':py:class:`test_util_typing.MyInt`'\n    assert restify(MyList[int]) == ':py:class:`test_util_typing.MyList`\\\\ [:py:class:`int`]'\n    assert restify(Optional[int]) == ':py:obj:`~typing.Optional`\\\\ [:py:class:`int`]'\n    assert restify(Union[int, str]) == ':py:obj:`~typing.Union`\\\\ [:py:class:`int`, :py:class:`str`]'\n    assert restify(Callable[[int], str]) == ':py:obj:`~typing.Callable`\\\\ [[:py:class:`int`], :py:class:`str`]'\n    assert restify(Struct) == ':py:class:`struct.Struct`'\n    assert restify(TracebackType) == ':py:class:`types.TracebackType`'\n    assert restify(BrokenType) == ':py:class:`test_util_typing.BrokenType`'\n"], "sample_1105": ["def test_matmul_entry():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    M = MatMul(A, B)\n    assert M._entry(0, 0) == A[0, 0]*B[0, 0] + A[0, 1]*B[1, 0]\n    assert M._entry(0, 1) == A[0, 0]*B[0, 1] + A[0, 1]*B[1, 1]\n"], "sample_916": ["def test_function_pointer_declaration():\n    input = \"void (*func)(int)\"\n    idDict = {1: \"func\"}\n    output = \"void (*func)(int)\"\n    check(\"function\", input, idDict, output)\n"], "sample_320": ["    def test_add_index_state_forwards(self):\n        operation = migrations.AddIndex(\"TestModel\", models.Index(fields=[\"field1\", \"field2\"], name=\"test_index\"))\n        state = ProjectState()\n        state.add_model(ModelState(\"app_label\", \"TestModel\", [(\"field1\", models.CharField()), (\"field2\", models.CharField())]))\n        operation.state_forwards(\"app_label\", state)\n        self.assertEqual(len(state.models[\"app_label\", \"testmodel\"].options[\"indexes\"]), 1)\n        self.assertEqual(state.models[\"app_label\", \"testmodel\"].options[\"indexes\"][0].name, \"test_index\")\n"], "sample_1157": ["def test_function_exponentiation():\n    transformations = standard_transformations + (function_exponentiation,)\n    expr = parse_expr('sin**4(x)', transformations=transformations)\n    assert expr == sin(x)**4\n"], "sample_947": ["def test_parse_function_pointer():\n    input = \"void (*func)(int)\"\n    idDict = {1: \"func\"}\n    output = \"void (*func)(int)\"\n    check(\"function\", input, idDict, output)\n"], "sample_874": ["def test_step_selector_transform():\n    selector = StepSelector(step=2)\n    selector.fit(X, y)\n    X_transformed = selector.transform(X)\n    assert_array_equal(X_transformed, Xt)\n"], "sample_1005": ["def test_latex_Quaternion():\n    q = Quaternion(1, 2, 3, 4)\n    assert latex(q) == \"1 + 2\\\\mathbf{i} + 3\\\\mathbf{j} + 4\\\\mathbf{k}\"\n"], "sample_1153": ["def test_polar_lift_with_symbol():\n    x = Symbol('x')\n    assert polar_lift(x) == polar_lift(x)\n"], "sample_924": ["def test_cpp_domain_function_pointer():\n    check('function', 'void (*{key}f)(int)', {1: 'f'}, 'void (*f)(int)')\n"], "sample_308": ["    def test_date_format_with_time_specifiers(self):\n        dt = datetime(2022, 1, 1, 12, 30, 45)\n        with self.assertRaises(TypeError):\n            format(dt, 'jS F Y H:i')\n"], "sample_232": ["    def test_call(self):\n        key_name = 'test_key'\n        factory = KeyTransformFactory(key_name)\n        transform = factory()\n        self.assertIsInstance(transform, KeyTransform)\n        self.assertEqual(transform.key_name, key_name)\n"], "sample_610": ["def test_parsed_string_to_bounds(date_type):\n    parsed = date_dict(year=\"2000\", month=\"02\", day=\"29\", hour=\"12\", minute=\"34\", second=\"56\")\n    start, end = _parsed_string_to_bounds(date_type, \"second\", parsed)\n    assert start == date_type(2000, 2, 29, 12, 34, 56)\n    assert end == date_type(2000, 2, 29, 12, 34, 57) - timedelta(microseconds=1)\n"], "sample_455": ["    def test_check_constraint_validation(self):\n        product = Product(name=\"Test\", price=10)\n        product.full_clean()  # This should not raise any error\n\n        product = Product(name=\"Test\", price=-10)\n        with self.assertRaises(ValidationError):\n            product.full_clean()  # This should raise a ValidationError\n"], "sample_576": ["def test_scale_method(self):\n    p = Plot(x=[1, 2, 3], y=[4, 5, 6])\n    p = p.scale(x=\"log\", y=Continuous(trans=\"sqrt\"))\n    assert isinstance(p._scales[\"x\"], Continuous)\n    assert p._scales[\"x\"].transform == \"log\"\n    assert isinstance(p._scales[\"y\"], Continuous)\n    assert p._scales[\"y\"].transform == \"sqrt\"\n"], "sample_724": ["def test_imputer_with_most_frequent_strategy():\n    \"\"\"Test Imputer with the 'most_frequent' strategy.\"\"\"\n    X = np.array([[1, 2, 3],\n                  [4, np.nan, 6],\n                  [7, 8, np.nan],\n                  [10, 11, 12]])\n    X_true = np.array([[1, 2, 3],\n                       [4, 2, 6],\n                       [7, 8, 3],\n                       [10, 11, 12]])\n    statistics = np.array([1, 2, 3])\n    _check_statistics(X, X_true, \"most_frequent\", statistics, np.nan)\n"], "sample_242": ["def test_year_lookup_bounds(self):\n    lookup = YearLookup()\n    lookup.lhs = mock.Mock()\n    lookup.lhs.lhs = mock.Mock()\n    lookup.lhs.lhs.output_field = DateTimeField()\n    connection = mock.Mock()\n    connection.ops.year_lookup_bounds_for_datetime_field.return_value = (datetime(2022, 1, 1), datetime(2022, 12, 31))\n    bounds = lookup.year_lookup_bounds(connection, 2022)\n    self.assertEqual(bounds, (datetime(2022, 1, 1), datetime(2022, 12, 31)))\n    connection.ops.year_lookup_bounds_for_date_field.return_value = (datetime(2022, 1, 1).date(), datetime(2022, 12, 31).date())\n    lookup.lhs.lhs.output_field = mock.Mock()\n    bounds = lookup.year_lookup_bounds(connection, 2022)\n    self.assertEqual(bounds, (datetime(2022, 1, 1).date(), datetime(2022, 12, 31).date()))\n"], "sample_842": ["def test_kernel_clone(kernel):\n    cloned_kernel = clone(kernel)\n    assert type(cloned_kernel) == type(kernel)\n    assert cloned_kernel.get_params() == kernel.get_params()\n"], "sample_1026": ["def test_lambdify_with_tensorflow():\n    expr = Max(x, sin(x))\n    func = lambdify(x, expr, 'tensorflow')\n    result = func(tensorflow.constant(1.0))\n    sess = tensorflow.Session()\n    assert sess.run(result) == 1.0\n"], "sample_153": ["def test_check_database_backends(self, mock_check):\n    mock_check.return_value = []\n    errors = check_database_backends(databases=['default', 'other'])\n    self.assertEqual(errors, [])\n    mock_check.assert_has_calls([mock.call(databases=['default', 'other']), mock.call(databases=['default', 'other'])])\n"], "sample_1056": ["def test_lambdarepr_Piecewise():\n    expr = Piecewise((a, x < b), (c, True))\n    result = lambdarepr(expr, {\"x\": x, \"a\": a, \"b\": b, \"c\": c})\n    assert result == \"((a) if ((x) < (b)) else (c))\"\n"], "sample_1076": ["def test_print_MatrixSolve():\n    A = MatrixSymbol('A', 3, 3)\n    b = MatrixSymbol('b', 3, 1)\n    expr = MatrixSolve(A, b)\n    result = pycode(expr, printer=NumPyPrinter)\n    assert result == \"numpy.linalg.solve(A, b)\"\n"], "sample_1057": ["def test_render_as_module():\n    from sympy import symbols\n\n    x, y = symbols('x y')\n    content = Print(x + y)\n    result = render_as_module(content)\n\n    assert \"from sympy import symbols\" in result\n    assert \"from sympy.codegen.ast import Print\" in result\n    assert \"print(x + y)\" in result\n"], "sample_196": ["    def test_date_extract_sql(self):\n        with self.assertRaises(NotImplementedError) as context:\n            self.ops.date_extract_sql('year', 'field_name')\n        self.assertEqual(str(context.exception), self.may_require_msg % 'date_extract_sql')\n"], "sample_1106": ["def test_matadd_doit():\n    A = MatrixSymbol('A', 2, 2)\n    B = eye(2)\n    C = Matrix([[1, 2], [3, 4]])\n    X = MatAdd(A, B, C)\n    Y = X.doit()\n    assert Y == Matrix([[A[0, 0] + 1, A[0, 1] + 2], [A[1, 0] + 3, A[1, 1] + 4]])\n"], "sample_1088": ["def test_viete():\n    f = a*x**3 + b*x**2 + c*x + d\n    roots = [r1, r2, r3]\n    result = viete(f, roots, x)\n    expected = [(r1 + r2 + r3, -b/a), (r1*r2 + r1*r3 + r2*r3, c/a), (-r1*r2*r3, d/a)]\n    assert result == expected\n"], "sample_1068": ["compilation error"], "sample_973": ["def test_signature_from_str():\n    sig = inspect.signature_from_str(\"(a: int, b: str = 'default')\")\n    assert str(sig) == \"(a: int, b: str = 'default')\"\n"], "sample_1154": ["def test_linsolve_complex_coefficients():\n    eqs = [Eq(x + I*y, 1 + 2*I), Eq(x - I*y, 2 - I)]\n    sol = _linsolve(eqs, [x, y])\n    assert sol == {x: 3/2, y: 3/2*I}\n"], "sample_1119": ["def test_matrix_inverse_mod():\n    A = Matrix([[3, 6], [4, 8]])\n    m = 10\n    A_inv_mod = A.inv_mod(m)\n    assert (A * A_inv_mod) % m == eye(2)\n"], "sample_1036": ["def test_matmul_with_symbolic_dimensions():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    C = A * B\n    assert C.shape == (n, l)\n"], "sample_927": ["def test_function_pointer():\n    input = \"void (*{key}foo)(int)\"\n    idDict = {1: \"foo\"}\n    output = \"void ({key}foo)(int)\"\n    check(\"function\", input, idDict, output)\n"], "sample_588": ["def test_infer_concat_order_from_positions():\n    datasets = [\n        Dataset({'a': DataArray([1, 2, 3], dims='x')}),\n        Dataset({'a': DataArray([4, 5, 6], dims='x')}),\n        Dataset({'a': DataArray([7, 8, 9], dims='x')}),\n    ]\n    expected_result = OrderedDict([\n        ((0,), datasets[0]),\n        ((1,), datasets[1]),\n        ((2,), datasets[2]),\n    ])\n    assert_combined_tile_ids_equal(_infer_concat_order_from_positions(datasets), expected_result)\n"], "sample_430": ["def test_deconstructible_objects_are_compared_correctly(self):\n    changes = self.get_changes(\n        [self.author_name_deconstructible_1],\n        [self.author_name_deconstructible_2],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 0)\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_1],\n        [self.author_name_deconstructible_3],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_3],\n        [self.author_name_deconstructible_4],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_list_1],\n        [self.author_name_deconstructible_list_2],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 0)\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_list_1],\n        [self.author_name_deconstructible_list_3],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_tuple_1],\n        [self.author_name_deconstructible_tuple_2],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 0)\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_tuple_1],\n        [self.author_name_deconstructible_tuple_3],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n\n    changes = self.get_changes(\n        [self.author_name_deconstructible_dict_1],\n        [self.author"], "sample_959": ["def test_function_pointer_declaration():\n    input = \"void (*{key}foo)(int)\"\n    idDict = {1: \"foo\"}\n    output = \"void ({key}foo)(int)\"\n    check(\"function\", input, idDict, output)\n"], "sample_1118": ["def test_matpow_derivative():\n    x = symbols('x')\n    M = MatrixSymbol('M', 1, 1)\n    MP = MatPow(M, x)\n    dMP = MP.diff(x)\n    assert dMP == x*M**(x-1)\n"], "sample_969": ["def test_restify():\n    assert restify(MyClass1) == ':py:class:`test_util_typing.MyClass1`'\n    assert restify(MyClass2) == ':py:class:`test_util_typing.MyClass2`'\n    assert restify(MyInt) == ':py:class:`test_util_typing.MyInt`'\n    assert restify(MyList[int]) == ':py:class:`test_util_typing.MyList`\\\\ [:py:class:`int`]'\n    assert restify(Optional[int]) == ':py:obj:`~typing.Optional`\\\\ [:py:class:`int`]'\n    assert restify(Union[int, str]) == ':py:obj:`~typing.Union`\\\\ [:py:class:`int`, :py:class:`str`]'\n    assert restify(Callable[[int], str]) == ':py:obj:`~typing.Callable`\\\\ [[:py:class:`int`], :py:class:`str`]'\n    assert restify(Struct) == ':py:class:`struct.Struct`'\n    assert restify(TracebackType) == ':py:class:`types.TracebackType`'\n    assert restify(BrokenType) == ':py:class:`test_util_typing.BrokenType`'\n"], "sample_1141": ["compilation error"], "sample_1174": ["def test_unpolarify_with_exponents_only():\n    x, y = symbols('x y')\n    eq = exp_polar(x + I*y)\n    res = unpolarify(eq, exponents_only=True)\n    assert res == exp(x)*(cos(y) + I*sin(y))\n"], "sample_133": ["    def test_get_paths(self):\n        \"\"\"Test the get_paths method of JavaScriptCatalog.\"\"\"\n        view = JavaScriptCatalog()\n        packages = ['django.contrib.admin', 'django.contrib.auth']\n        paths = view.get_paths(packages)\n        self.assertEqual(len(paths), 2)\n        self.assertTrue(path.exists(paths[0]))\n        self.assertTrue(path.exists(paths[1]))\n"], "sample_1058": ["def test_print_Mod():\n    expr = Mod(x, y)\n    printer = PythonCodePrinter()\n    result = printer._print_Mod(expr)\n    assert result == \"x % y\"\n"], "sample_828": ["def test_pairwise_distances_chunked_reduce_func_output_length():\n    X = np.random.RandomState(0).rand(5, 3)\n    r = .2\n\n        neigh = [np.flatnonzero(d < r) for d in D_chunk]\n        avg_dist = (D_chunk * (D_chunk < r)).mean(axis=1)\n        return neigh, avg_dist, avg_dist  # extra output\n\n    gen = pairwise_distances_chunked(X, reduce_func=reduce_func)\n    with assert_raises_regexp(ValueError, \"Expected same length as input: 1\"):\n        next(gen)\n"], "sample_827": ["def test_csc_median_axis_0():\n    rng = RandomState(0)\n    X = sp.csc_matrix(rng.randn(10, 5))\n    expected_median = np.median(X.toarray(), axis=0)\n    computed_median = csc_median_axis_0(X)\n    assert_array_almost_equal(expected_median, computed_median)\n"], "sample_154": ["def test_check_database_backends(self, mock_check):\n    mock_check.return_value = []\n    issues = check_database_backends(databases=self.databases)\n    self.assertEqual(len(issues), 0)\n    mock_check.assert_called()\n"], "sample_319": ["def test_generate_altered_db_table_comment(self):\n    changes = self.get_changes(\n        [self.author_with_db_table_comment],\n        [self.author_with_new_db_table_options],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelTableComment\"])\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, table_comment=None\n    )\n"], "sample_415": ["    def test_check_constraint_validate(self):\n        constraint = CheckConstraint(check=Q(price__gt=0), name=\"positive_price\")\n        product = Product(name=\"Test\", price=-1)\n        with self.assertRaises(ValidationError):\n            constraint.validate(Product, product)\n"], "sample_826": ["def test_ordinal_encoder_inverse_transform():\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    X_transformed = enc.transform(X)\n    X_inverse = enc.inverse_transform(X_transformed)\n    assert_array_equal(X, X_inverse)\n"], "sample_781": ["def check_classification_iris(name):\n    \"\"\"Check classification on the iris dataset.\"\"\"\n    ForestClassifier = FOREST_CLASSIFIERS[name]\n\n    clf = ForestClassifier(n_estimators=10, random_state=0)\n    clf.fit(iris.data, iris.target)\n    score = clf.score(iris.data, iris.target)\n    assert_greater(score, 0.9)\n\n    # also test apply\n    leaf_indices = clf.apply(iris.data)\n    assert_equal(leaf_indices.shape, (iris.data.shape[0], clf.n_estimators))\n"], "sample_195": ["    def test_datetime_cast_date_sql(self):\n        tzname = 'UTC'\n        field_name = 'test_field'\n        expected_sql = 'django_datetime_cast_date(test_field, \\'UTC\\', \\'UTC\\')'\n        self.assertEqual(self.ops.datetime_cast_date_sql(field_name, tzname), expected_sql)\n"], "sample_1152": ["def test_powdenest_with_symbols():\n    i, j = symbols('i j', integer=True)\n    assert powdenest((x**i)**j, force=True) == x**(i*j)\n"], "sample_934": ["def test_parse_function_pointer():\n    input = \"void (*func)(int)\"\n    idDict = {1: \"func\"}\n    output = \"void (*func)(int)\"\n    check(\"function\", input, idDict, output)\n"], "sample_132": ["    def test_get_traceback_data(self):\n        request = RequestFactory().get('/')\n        exc_type = TemplateDoesNotExist\n        exc_value = TemplateDoesNotExist('template.html')\n        tb = None\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertTrue(data['template_does_not_exist'])\n        self.assertIsNotNone(data['postmortem'])\n"], "sample_731": ["def test_fetch_california_housing_return_X_y():\n    \"\"\"Test that fetch_california_housing returns X and y when return_X_y is True.\"\"\"\n    data, target = fetch_california_housing(return_X_y=True)\n    assert data.shape == (20640, 8)\n    assert target.shape == (20640,)\n"], "sample_603": ["def test_dataset_repr(dataset):\n    result = fh.dataset_repr(dataset)\n    assert isinstance(result, str)\n    assert \"xarray.Dataset\" in result\n    assert \"Dimensions\" in result\n    assert \"Coordinates\" in result\n    assert \"Data variables\" in result\n    assert \"Attributes\" in result\n"], "sample_935": ["def test_parse_function_with_template_introduction():\n    input = \"void f(int) requires A<T>{};\"\n    idDict = {1: \"f_int_\"}\n    output = \"void f(int) requires A<T>\"\n    check(\"function\", input, idDict, output)\n"], "sample_923": ["compilation error"], "sample_302": ["    def test_settings_to_cmd_args_env(self):\n        settings_dict = {\n            'HOST': 'localhost',\n            'PORT': 5432,\n            'NAME': 'test_db',\n            'USER': 'test_user',\n            'PASSWORD': 'test_password',\n            'OPTIONS': {\n                'passfile': '/path/to/passfile',\n                'service': 'test_service',\n                'sslmode': 'require',\n                'sslrootcert': '/path/to/sslrootcert',\n                'sslcert': '/path/to/sslcert',\n                'sslkey': '/path/to/sslkey',\n            }\n        }\n        parameters = ['-c', 'SELECT 1']\n        expected_args = [\n            'psql', '-U', 'test_user', '-h', 'localhost', '-p', '5432', 'test_db', '-c', 'SELECT 1'\n        ]\n        expected_env = {\n            'PGPASSWORD': 'test_password',\n            'PGSERVICE': 'test_service',\n            'PGSSLMODE': 'require',\n            'PGSSLROOTCERT': '/path/to/sslrootcert',\n            'PGSSLCERT': '/path/to/sslcert',\n            'PGSSLKEY': '/path/to/sslkey',\n            'PGPASSFILE': '/path/to/passfile',\n        }\n        args, env = DatabaseClient.settings_to_cmd_args_env(settings_dict, parameters)\n        self.assertEqual(args, expected_args)\n        self.assertEqual(env, expected_env)\n"], "sample_732": ["def test_fetch_kddcup99_subset_SA():\n    try:\n        data = fetch_kddcup99(subset='SA', percent10=True, download_if_missing=False)\n    except IOError:\n        raise SkipTest(\"Data not found and download_if_missing is False\")\n\n    assert_equal(data.data.shape, (976158, 41))\n    assert_equal(data.target.shape, (976158,))\n    assert_equal(len(set(data.target)), 2)  # 'normal.' and one abnormal type\n\n    check_return_X_y(partial(fetch_kddcup99, subset='SA', percent10=True, download_if_missing=False))\n"], "sample_575": ["def test_continuous_tick_locator(self, x):\n    locator = mpl.ticker.FixedLocator([0.2, 0.5, 0.8])\n    a = self.setup_ticks(x, locator=locator)\n    assert_array_equal(a.major.locator(), [0.2, 0.5, 0.8])\n"], "sample_926": ["def test_parse_declaration_function_pointer():\n    input = \"void (*func)(int)\"\n    idDict = {1: \"func\"}\n    output = \"void (*func)(int)\"\n    check(\"function\", input, idDict, output)\n"], "sample_279": ["    def test_check_constraint(self):\n        check = models.Q(price__gt=0)\n        constraint = CheckConstraint(check=check, name='positive_price')\n        self.assertEqual(constraint.check, check)\n        self.assertEqual(constraint.name, 'positive_price')\n\n        # Test constraint_sql\n        with mock.patch('django.db.models.constraints.CheckConstraint._get_check_sql') as mock_get_check_sql:\n            mock_get_check_sql.return_value = 'price > 0'\n            sql = constraint.constraint_sql(Product, connection.schema_editor())\n            self.assertEqual(sql, 'CHECK (price > 0)')\n\n        # Test create_sql\n        with mock.patch('django.db.models.constraints.CheckConstraint._get_check_sql') as mock_get_check_sql:\n            mock_get_check_sql.return_value = 'price > 0'\n            sql = constraint.create_sql(Product, connection.schema_editor())\n            self.assertEqual(sql, 'ALTER TABLE \"products_product\" ADD CONSTRAINT \"positive_price\" CHECK (price > 0)')\n\n        # Test remove_sql\n        sql = constraint.remove_sql(Product, connection.schema_editor())\n        self.assertEqual(sql, 'ALTER TABLE \"products_product\" DROP CONSTRAINT \"positive_price\"')\n\n        # Test deconstruct\n        path, args, kwargs = constraint.deconstruct()\n        self.assertEqual(path, 'django.db.models.CheckConstraint')\n        self.assertEqual(args, ())\n        self.assertEqual(kwargs, {'name': 'positive_price', 'check': check})\n\n        # Test clone\n        cloned_constraint = constraint.clone()\n        self.assertEqual(cloned_constraint.check, check)\n        self.assertEqual(cloned_constraint.name, 'positive_price')\n"], "sample_611": ["def test_rule_code(offset, expected_rule_code):\n    assert offset.rule_code() == expected_rule_code\n"], "sample_1064": ["def test_tensorflow_code_CodegenArrayTensorProduct():\n    A = MatrixSymbol(\"A\", 2, 3)\n    B = MatrixSymbol(\"B\", 3, 4)\n    expr = CodegenArrayTensorProduct(A, B)\n    _compare_tensorflow_matrix([A, B], expr)\n"], "sample_948": ["def test_function_declaration_with_template_introduction():\n    input = \"void {key}f(int) requires A<T>()\"\n    idDict = {1: \"f\"}\n    output = \"void {key}f(int) requires A<T>()\"\n    check(\"function\", input, idDict, output)\n"], "sample_1069": ["compilation error"], "sample_1125": ["def test_operator_multiplication():\n    A = Operator('A')\n    I = IdentityOperator()\n    assert A * I == A\n"], "sample_723": ["compilation error"], "sample_1142": ["def test_matrix_element_derivative():\n    M = MatrixSymbol('M', n, n)\n    v = MatrixSymbol('v', n, 1)\n    i, j = symbols('i j', integer=True)\n    elem = MatrixElement(M, i, j)\n    deriv = elem.diff(v)\n    assert deriv == KroneckerDelta(i, v.args[1], (0, n-1)) * KroneckerDelta(j, v.args[2], (0, n-1))\n"], "sample_309": ["    def test_parse_http_date(self):\n        # Test RFC1123 format\n        self.assertEqual(parse_http_date('Sun, 06 Nov 1994 08:49:37 GMT'), 784111777)\n        # Test RFC850 format\n        self.assertEqual(parse_http_date('Sunday, 06-Nov-94 08:49:37 GMT'), 784111777)\n        # Test ASCTIME format\n        self.assertEqual(parse_http_date('Sun Nov  6 08:49:37 1994'), 784111777)\n        # Test invalid date format\n        with self.assertRaises(ValueError):\n            parse_http_date('Invalid Date')\n"], "sample_1038": ["def test_matrix_element_derivative():\n    M = MatrixSymbol('M', n, n)\n    N = MatrixSymbol('N', n, n)\n    V = MatrixElement(M, i, j)\n    W = MatrixElement(N, i, j)\n    dV = diff(V, W)\n    assert dV == KroneckerDelta(M, N)\n"], "sample_431": ["def test_model_save_base_with_update_fields(self):\n    article = Article.objects.create(title=\"Test Article\", content=\"Test Content\")\n    article.content = \"Updated Content\"\n    article.save_base(update_fields=[\"content\"])\n    article.refresh_from_db()\n    self.assertEqual(article.content, \"Updated Content\")\n"], "sample_604": ["def test_format_timedelta(self):\n    # Test formatting of timedelta objects\n    td = pd.Timedelta(days=2, hours=3, minutes=4, seconds=5)\n    assert formatting.format_timedelta(td) == \"2 days 03:04:05\"\n    assert formatting.format_timedelta(td, timedelta_format=\"date\") == \"2 days\"\n    assert formatting.format_timedelta(td, timedelta_format=\"time\") == \"03:04:05\"\n"], "sample_917": ["def test_cpp_domain_function_pointer():\n    check(\"function\", \"void (*func)(int)\", {1: \"func\"}, \"void (*func)(int)\")\n"], "sample_1159": ["def test_common_assumptions():\n    exprs = [sqrt(2), 3, pi, I, oo, -oo]\n    result = common_assumptions(exprs)\n    expected = {'commutative': True, 'composite': False, 'extended_real': False, 'imaginary': False, 'odd': False}\n    assert result == expected\n"], "sample_1173": ["def test_convert_xor():\n    s = \"2 ^ 3\"\n    result = parse_expr(s, transformations=(convert_xor,))\n    expected = Pow(2, 3)\n    assert result == expected\n"], "sample_1034": ["def test_WGate_representation():\n    nqubits = 2\n    wgate = WGate(nqubits)\n    basis_states = superposition_basis(nqubits)\n    expected_matrix = (2/sqrt(2**nqubits)) * Matrix([[1, 1, 1, 1],\n                                                     [1, -1, 1, -1],\n                                                     [1, 1, -1, -1],\n                                                     [1, -1, -1, 1]]) - Matrix.eye(4)\n    assert represent(wgate, basis_states) == expected_matrix\n"], "sample_437": ["def test_set_autocommit_with_broken_autocommit(self, mock_ensure_connection):\n    wrapper = BaseDatabaseWrapper({'AUTOCOMMIT': False})\n    wrapper._start_transaction_under_autocommit = MagicMock()\n    wrapper.set_autocommit(False, force_begin_transaction_with_broken_autocommit=True)\n    wrapper._start_transaction_under_autocommit.assert_called_once()\n"], "sample_1155": ["def test_construct_domain_with_complex_numbers():\n    expressions = [2 + 3*I, 4 - 5*I]\n    K, elements = construct_domain(expressions)\n    assert K == ZZ_I\n    assert elements == [2 + 3*I, 4 - 5*I]\n"], "sample_1037": ["def test_matmul_entry():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    M = MatMul(A, B, C)\n    assert M._entry(0, 0) == Sum(A[0, k]*B[k, 0]*C[0, 0], (k, 0, 1))\n"], "sample_1063": ["def test_lambdify_with_tensorflow_eager_execution():\n    if tensorflow:\n        tf = tensorflow\n        tf.compat.v1.enable_eager_execution()\n        f = Max(x, sin(x))\n        func = lambdify(x, f, 'tensorflow')\n        result = func(tf.constant(1.0))\n        assert result.numpy() == 1.0\n        var = tf.Variable(2.0)\n        result = func(var)\n        assert result.numpy() == 2.0\n        tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n        result = func(tensor)\n        assert (result.numpy() == [[1.0, 2.0], [3.0, 4.0]]).all()\n"], "sample_586": ["def test_concat_dataarray_with_different_names():\n    arr1 = DataArray(np.arange(10), name='A')\n    arr2 = DataArray(np.arange(10, 20), name='B')\n    with pytest.raises(ValueError):\n        concat([arr1, arr2], dim='dim')\n"], "sample_780": ["def test_latent_dirichlet_allocation_partial_fit():\n    n_components, X = _build_sparse_mtx()\n    lda = LatentDirichletAllocation(n_components=n_components, random_state=0)\n    lda.partial_fit(X)\n    assert_equal(lda.components_.shape, (n_components, X.shape[1]))\n    assert_greater_equal(np.min(lda.components_), 0)\n"], "sample_1075": ["def test_beta_function_properties():\n    x, y = Symbol('x'), Symbol('y')\n\n    # Test the property B(a, 1) = 1/a\n    assert beta(x, 1) == 1/x\n\n    # Test the property B(a, b) = B(b, a)\n    assert beta(x, y) == beta(y, x)\n\n    # Test the property B(a, b) = Gamma(a) * Gamma(b) / Gamma(a + b)\n    assert beta(x, y) == expand_func(beta(x, y))\n\n    # Test the derivative of beta function with respect to x\n    assert diff(beta(x, y), x) == beta(x, y)*(digamma(x) - digamma(x + y))\n\n    # Test the derivative of beta function with respect to y\n    assert diff(beta(x, y), y) == beta(x, y)*(digamma(y) - digamma(x + y))\n\n    # Test the derivative of beta function with invalid argindex\n    with raises(ArgumentIndexError):\n        diff(beta(x, y), 3)\n\n    # Test the conjugate of beta function\n    assert conjugate(beta(x, y)) == beta(conjugate(x), conjugate(y))\n"], "sample_906": ["def test_parse_function_pointer():\n    input = \"void (*func)(int)\"\n    idDict = {1: \"func\"}\n    output = \"void (*func)(int)\"\n    check(\"function\", input, idDict, output)\n"], "sample_825": ["def test_pls_regression_predict():\n    X = np.array([[0., 0., 1.], [1., 0., 0.], [2., 2., 2.], [2., 5., 4.]])\n    Y = np.array([[0.1, -0.2], [0.9, 1.1], [6.2, 5.9], [11.9, 12.3]])\n    pls2 = PLSRegression(n_components=2)\n    pls2.fit(X, Y)\n    Y_pred = pls2.predict(X)\n    assert_array_almost_equal(Y_pred, np.array([[0.09999999, -0.2], [0.9, 1.1], [6.2, 5.9], [11.9, 12.3]]), decimal=5)\n"], "sample_1004": ["def test_condition_set_subs():\n    c = ConditionSet(x, x < 1, {x, z})\n    assert c.subs(x, y) == ConditionSet(x, x < 1, {y, z})\n    assert c.subs(x, y).subs(x, w) == ConditionSet(w, w < 1, {y, z})\n    raises(ValueError, lambda: c.subs(x, 1))\n"], "sample_958": ["def test_parse_function_pointer():\n    input = \"void (*func)(int)\"\n    idDict = {1: \"func\"}\n    output = \"void (*func)(int)\"\n    check(\"function\", input, idDict, output)\n"], "sample_303": ["    def test_runshell(self, mock_run):\n        parameters = {'param1': 'value1'}\n        settings_dict = {'setting1': 'value1'}\n        self.client.connection.settings_dict = settings_dict\n        self.client.settings_to_cmd_args_env = mock.MagicMock(return_value=(['cmd', 'arg1'], {'env1': 'value1'}))\n\n        self.client.runshell(parameters)\n\n        self.client.settings_to_cmd_args_env.assert_called_once_with(settings_dict, parameters)\n        mock_run.assert_called_once_with(['cmd', 'arg1'], env={'env1': 'value1', **os.environ}, check=True)\n"], "sample_1126": ["def test_dagger_properties():\n    A = Operator('A')\n    B = Operator('B')\n\n    # Test associativity\n    assert Dagger(A * B) == Dagger(B) * Dagger(A)\n\n    # Test distributivity\n    assert Dagger(A + B) == Dagger(A) + Dagger(B)\n\n    # Test identity operator\n    assert Dagger(IdentityOperator()) == IdentityOperator()\n\n    # Test complex numbers and matrices\n    m = Matrix([[1, I], [2, I]])\n    assert Dagger(m) == Matrix([[1, 2], [-I, -I]])\n"], "sample_1117": ["def test_ask_square_handler():\n    assert ask(Q.square(X), Q.square(X)) is True\n    assert ask(Q.square(Y), Q.square(Y)) is False\n    assert ask(Q.square(A1x1), Q.square(A1x1)) is True\n    assert ask(Q.square(C0x0), Q.square(C0x0)) is True\n"], "sample_1035": ["def test_measure_partial():\n    from sympy.physics.quantum.qubit import Qubit, measure_partial\n    from sympy.physics.quantum.gate import H\n    q = H(0)*H(1)*Qubit('00')\n    result = measure_partial(q, (0,))\n    assert len(result) == 2\n    assert result[0][1] == 0.5\n    assert result[1][1] == 0.5\n"], "sample_1116": ["def test_inverse_properties():\n    assert Inverse(C * D) == Inverse(D) * Inverse(C)\n    assert Inverse(C).inverse() == C\n    assert Inverse(C).doit(inv_expand=False) == Inverse(C)\n    assert Inverse(C).doit(deep=False) == C.inverse()\n    assert Inverse(C)._eval_determinant() == 1 / C.det()\n    assert Inverse(C).shape == C.shape\n    assert Inverse(C).arg == C\n    assert Inverse(C).exp == S.NegativeOne\n    assert Inverse(C).is_Inverse == True\n    assert Inverse(C)._eval_inverse() == C\n"], "sample_779": ["    def test_check_outlier_corruption(self):\n        num_outliers = 10\n        expected_outliers = 11\n        decision = np.array([1, 2, 3, 4, 5, 6, 7, 7, 7, 8, 9, 10])\n        with self.assertRaises(AssertionError):\n            check_outlier_corruption(num_outliers, expected_outliers, decision)\n"], "sample_454": ["    def test_exclusion_constraint(self):\n        # Create a model with an exclusion constraint\n        class ExclusionModel(models.Model):\n            start_date = models.DateField()\n            end_date = models.DateField()\n\n            class Meta:\n                constraints = [\n                    ExclusionConstraint(\n                        name=\"exclude_overlapping_dates\",\n                        expressions=[\n                            (\"start_date\", \"&&\"),\n                            (\"end_date\", \"&&\"),\n                        ],\n                    )\n                ]\n\n        # Test that the constraint is created correctly\n        with connection.schema_editor() as schema_editor:\n            schema_editor.create_model(ExclusionModel)\n            constraints = get_constraints(ExclusionModel._meta.db_table)\n            self.assertIn(\"exclude_overlapping_dates\", constraints)\n\n        # Test that the constraint is enforced\n        ExclusionModel.objects.create(start_date=\"2022-01-01\", end_date=\"2022-01-10\")\n        with self.assertRaises(IntegrityError):\n            ExclusionModel.objects.create(start_date=\"2022-01-05\", end_date=\"2022-01-15\")\n\n        # Test that the constraint can be removed\n        with connection.schema_editor() as schema_editor:\n            schema_editor.delete_model(ExclusionModel)\n            constraints = get_constraints(ExclusionModel._meta.db_table)\n            self.assertNotIn(\"exclude_overlapping_dates\", constraints)\n"], "sample_1087": ["def test_swinnerton_dyer_poly():\n    assert swinnerton_dyer_poly(1, x) == x**2 - 2\n    assert swinnerton_dyer_poly(2, x) == x**4 - 10*x**2 + 1\n    assert swinnerton_dyer_poly(3, x) == x**8 - 40*x**6 + 352*x**4 - 960*x**2 + 576\n    assert swinnerton_dyer_poly(4, x) == x**16 - 120*x**14 + 5920*x**12 - 156800*x**10 + 2257920*x**8 - 17612800*x**6 + 70425600*x**4 - 129024000*x**2 + 80640000\n"], "sample_243": ["def test_build_filter_with_transform(self):\n    query = Query(Author)\n    filter_expr = ('name__lower', 'john doe')\n    clause, _ = query.build_filter(filter_expr)\n    self.assertEqual(len(clause.children), 1)\n    lookup = clause.children[0]\n    self.assertIsInstance(lookup, Exact)\n    self.assertIsInstance(lookup.lhs, Lower)\n    self.assertIsInstance(lookup.lhs.lhs, Col)\n    self.assertEqual(lookup.lhs.lhs.target, Author._meta.get_field('name'))\n"], "sample_1025": ["def test_print_Mod():\n    expr = Mod(x, y)\n    printer = PythonCodePrinter()\n    result = printer._print_Mod(expr)\n    assert result == 'x % y'\n"], "sample_976": ["def test_symbol_assumptions():\n    x = Symbol('x', real=True, positive=True)\n    assert x.is_real is True\n    assert x.is_positive is True\n    assert x.is_commutative is True\n\n    y = Symbol('y', commutative=False)\n    assert y.is_commutative is False\n\n    z = Symbol('z', integer=True)\n    assert z.is_integer is True\n\n    w = Symbol('w', finite=True)\n    assert w.is_finite is True\n\n    raises(ValueError, lambda: Symbol('a', commutative=None))\n"], "sample_907": ["def test_parse_function_with_template_introduction():\n    input = \"void f(T) requires A<T> { }\"\n    idDict = {1: \"f\"}\n    output = \"void f(T) requires A<T>\"\n    _check(\"function\", input, idDict, output)\n"], "sample_873": ["def test_step_selector():\n    selector = StepSelector(step=2)\n    selector.fit(X, y)\n\n    assert_array_equal(selector.get_support(), support)\n    assert_array_equal(selector.get_support(indices=True), support_inds)\n    assert_array_equal(selector.transform(X), Xt)\n    assert_array_equal(selector.inverse_transform(Xt), Xinv)\n    assert_array_equal(selector.get_feature_names_out(feature_names), feature_names_t)\n"]}, "raw_scored_generations": {"sample_0": [false], "sample_3": [false], "sample_1": [true], "sample_2": [true], "sample_4": [false], "sample_5": [false], "sample_6": [true], "sample_7": [false], "sample_8": [false], "sample_9": [true], "sample_10": [false], "sample_11": [false], "sample_12": [true], "sample_13": [true], "sample_14": [false], "sample_15": [false], "sample_16": [false], "sample_17": [false], "sample_18": [false], "sample_19": [false], "sample_20": [false], "sample_21": [false], "sample_22": [false], "sample_23": [false], "sample_24": [false], "sample_25": [false], "sample_26": [false], "sample_27": [false], "sample_28": [false], "sample_29": [false], "sample_30": [false], "sample_31": [false], "sample_32": [true], "sample_33": [true], "sample_34": [true], "sample_35": [true], "sample_36": [false], "sample_37": [false], "sample_38": [false], "sample_39": [false], "sample_40": [false], "sample_41": [true], "sample_42": [false], "sample_43": [false], "sample_44": [false], "sample_45": [false], "sample_46": [false], "sample_47": [true], "sample_48": [true], "sample_49": [true], "sample_50": [true], "sample_51": [false], "sample_52": [true], "sample_54": [true], "sample_53": [false], "sample_55": [false], "sample_58": [false], "sample_56": [false], "sample_57": [true], "sample_59": [false], "sample_60": [true], "sample_61": [false], "sample_62": [false], "sample_63": [true], "sample_64": [false], "sample_65": [false], "sample_67": [false], "sample_66": [false], "sample_68": [true], "sample_69": [false], "sample_70": [false], "sample_71": [false], "sample_72": [false], "sample_73": [true], "sample_75": [true], "sample_74": [true], "sample_76": [true], "sample_77": [false], "sample_78": [false], "sample_79": [false], "sample_80": [false], "sample_82": [true], "sample_81": [true], "sample_83": [false], "sample_85": [true], "sample_84": [false], "sample_86": [false], "sample_88": [true], "sample_87": [false], "sample_89": [false], "sample_90": [false], "sample_91": [true], "sample_92": [false], "sample_93": [true], "sample_94": [false], "sample_95": [false], "sample_98": [false], "sample_96": [true], "sample_99": [true], "sample_97": [true], "sample_100": [true], "sample_102": [true], "sample_101": [true], "sample_103": [false], "sample_104": [true], "sample_107": [true], "sample_106": [false], "sample_105": [true], "sample_108": [false], "sample_109": [false], "sample_111": [true], "sample_110": [true], "sample_112": [true], "sample_113": [false], "sample_114": [true], "sample_115": [true], "sample_116": [false], "sample_117": [true], "sample_118": [false], "sample_119": [false], "sample_120": [false], "sample_121": [false], "sample_122": [false], "sample_123": [false], "sample_124": [false], "sample_125": [false], "sample_126": [true], "sample_127": [true], "sample_128": [false], "sample_129": [false], "sample_130": [false], "sample_131": [false], "sample_132": [true], "sample_133": [true], "sample_135": [false], "sample_134": [false], "sample_136": [true], "sample_139": [true], "sample_137": [false], "sample_138": [true], "sample_140": [false], "sample_141": [true], "sample_142": [false], "sample_143": [true], "sample_144": [false], "sample_145": [true], "sample_146": [true], "sample_147": [true], "sample_148": [false], "sample_151": [false], "sample_149": [false], "sample_152": [true], "sample_150": [false], "sample_153": [false], "sample_154": [false], "sample_155": [true], "sample_156": [false], "sample_157": [false], "sample_158": [true], "sample_159": [false], "sample_160": [false], "sample_161": [true], "sample_162": [true], "sample_163": [true], "sample_164": [false], "sample_165": [false], "sample_166": [false], "sample_167": [false], "sample_168": [true], "sample_169": [false], "sample_171": [false], "sample_170": [true], "sample_172": [true], "sample_173": [true], "sample_174": [true], "sample_175": [true], "sample_176": [true], "sample_177": [false], "sample_178": [true], "sample_180": [false], "sample_179": [false], "sample_182": [true], "sample_181": [true], "sample_183": [true], "sample_184": [false], "sample_185": [true], "sample_186": [false], "sample_187": [true], "sample_188": [true], "sample_189": [false], "sample_190": [true], "sample_191": [true], "sample_192": [true], "sample_193": [true], "sample_194": [false], "sample_195": [false], "sample_196": [true], "sample_198": [true], "sample_197": [false], "sample_199": [false], "sample_200": [true], "sample_201": [false], "sample_202": [false], "sample_203": [true], "sample_204": [false], "sample_205": [false], "sample_206": [false], "sample_207": [true], "sample_208": [true], "sample_209": [false], "sample_210": [false], "sample_211": [true], "sample_213": [false], "sample_212": [false], "sample_214": [false], "sample_215": [true], "sample_216": [true], "sample_217": [true], "sample_218": [true], "sample_219": [true], "sample_220": [false], "sample_221": [true], "sample_222": [true], "sample_223": [true], "sample_224": [true], "sample_225": [false], "sample_226": [true], "sample_227": [false], "sample_228": [true], "sample_229": [true], "sample_230": [false], "sample_231": [true], "sample_232": [false], "sample_233": [true], "sample_234": [true], "sample_235": [true], "sample_236": [true], "sample_237": [false], "sample_238": [false], "sample_239": [true], "sample_240": [false], "sample_241": [true], "sample_242": [false], "sample_243": [false], "sample_244": [true], "sample_245": [true], "sample_246": [false], "sample_247": [false], "sample_248": [false], "sample_249": [true], "sample_250": [false], "sample_251": [false], "sample_252": [false], "sample_253": [true], "sample_254": [true], "sample_256": [true], "sample_255": [true], "sample_257": [true], "sample_258": [true], "sample_259": [true], "sample_260": [true], "sample_261": [true], "sample_262": [false], "sample_263": [false], "sample_264": [false], "sample_265": [true], "sample_266": [false], "sample_267": [true], "sample_268": [true], "sample_269": [false], "sample_270": [true], "sample_271": [true], "sample_272": [false], "sample_273": [false], "sample_274": [false], "sample_275": [true], "sample_276": [true], "sample_277": [false], "sample_278": [true], "sample_279": [false], "sample_280": [true], "sample_281": [true], "sample_282": [true], "sample_283": [false], "sample_284": [true], "sample_285": [true], "sample_286": [false], "sample_287": [false], "sample_288": [true], "sample_289": [true], "sample_290": [true], "sample_291": [true], "sample_292": [true], "sample_293": [false], "sample_294": [true], "sample_295": [true], "sample_296": [false], "sample_297": [true], "sample_298": [true], "sample_299": [true], "sample_300": [false], "sample_301": [true], "sample_302": [false], "sample_303": [false], "sample_304": [false], "sample_305": [true], "sample_306": [false], "sample_307": [false], "sample_308": [false], "sample_309": [true], "sample_310": [true], "sample_312": [true], "sample_311": [true], "sample_313": [false], "sample_314": [true], "sample_315": [false], "sample_316": [false], "sample_317": [false], "sample_318": [false], "sample_319": [true], "sample_320": [true], "sample_321": [true], "sample_322": [true], "sample_323": [false], "sample_324": [true], "sample_325": [true], "sample_326": [false], "sample_327": [false], "sample_328": [true], "sample_329": [false], "sample_330": [false], "sample_331": [true], "sample_332": [true], "sample_333": [false], "sample_334": [false], "sample_335": [true], "sample_336": [false], "sample_337": [false], "sample_338": [true], "sample_339": [false], "sample_340": [false], "sample_341": [true], "sample_342": [true], "sample_343": [false], "sample_344": [true], "sample_345": [false], "sample_346": [false], "sample_347": [true], "sample_348": [false], "sample_349": [false], "sample_350": [true], "sample_351": [true], "sample_352": [false], "sample_353": [false], "sample_354": [false], "sample_355": [true], "sample_356": [true], "sample_357": [true], "sample_358": [true], "sample_359": [false], "sample_360": [false], "sample_361": [false], "sample_362": [true], "sample_363": [true], "sample_364": [true], "sample_365": [false], "sample_366": [true], "sample_367": [true], "sample_368": [false], "sample_369": [false], "sample_370": [true], "sample_371": [false], "sample_372": [false], "sample_373": [true], "sample_374": [true], "sample_375": [true], "sample_376": [false], "sample_377": [false], "sample_378": [true], "sample_379": [false], "sample_380": [false], "sample_381": [true], "sample_382": [false], "sample_383": [true], "sample_384": [true], "sample_385": [false], "sample_386": [true], "sample_387": [true], "sample_388": [false], "sample_389": [false], "sample_390": [false], "sample_391": [true], "sample_392": [false], "sample_393": [false], "sample_394": [false], "sample_395": [false], "sample_396": [true], "sample_397": [true], "sample_398": [false], "sample_399": [true], "sample_400": [true], "sample_401": [true], "sample_402": [false], "sample_403": [false], "sample_404": [true], "sample_405": [false], "sample_406": [false], "sample_407": [true], "sample_408": [true], "sample_409": [false], "sample_410": [false], "sample_411": [false], "sample_412": [false], "sample_413": [true], "sample_414": [true], "sample_415": [false], "sample_416": [false], "sample_417": [false], "sample_418": [false], "sample_419": [true], "sample_420": [false], "sample_421": [true], "sample_422": [true], "sample_423": [false], "sample_424": [false], "sample_425": [false], "sample_426": [false], "sample_427": [true], "sample_428": [false], "sample_429": [true], "sample_430": [false], "sample_431": [false], "sample_432": [true], "sample_433": [false], "sample_434": [false], "sample_435": [true], "sample_436": [false], "sample_437": [false], "sample_438": [false], "sample_439": [false], "sample_440": [true], "sample_441": [true], "sample_442": [true], "sample_443": [false], "sample_444": [true], "sample_445": [false], "sample_446": [false], "sample_447": [true], "sample_448": [false], "sample_449": [false], "sample_450": [false], "sample_451": [false], "sample_453": [true], "sample_452": [false], "sample_454": [false], "sample_455": [false], "sample_456": [true], "sample_457": [false], "sample_458": [false], "sample_459": [true], "sample_460": [true], "sample_461": [false], "sample_462": [false], "sample_463": [true], "sample_464": [false], "sample_465": [true], "sample_466": [false], "sample_467": [true], "sample_469": [true], "sample_468": [false], "sample_470": [false], "sample_471": [false], "sample_472": [true], "sample_473": [false], "sample_474": [false], "sample_475": [true], "sample_476": [true], "sample_477": [false], "sample_478": [true], "sample_479": [true], "sample_480": [false], "sample_481": [false], "sample_482": [false], "sample_483": [false], "sample_484": [false], "sample_485": [false], "sample_486": [false], "sample_487": [true], "sample_488": [false], "sample_489": [true], "sample_490": [false], "sample_491": [true], "sample_492": [false], "sample_493": [true], "sample_494": [false], "sample_495": [true], "sample_496": [true], "sample_497": [false], "sample_498": [true], "sample_499": [true], "sample_500": [false], "sample_501": [true], "sample_502": [true], "sample_503": [true], "sample_504": [false], "sample_505": [true], "sample_506": [false], "sample_507": [false], "sample_508": [false], "sample_509": [true], "sample_510": [true], "sample_511": [true], "sample_512": [true], "sample_513": [true], "sample_514": [false], "sample_515": [false], "sample_516": [false], "sample_517": [false], "sample_518": [true], "sample_519": [false], "sample_520": [false], "sample_521": [false], "sample_522": [false], "sample_523": [true], "sample_524": [false], "sample_525": [false], "sample_526": [false], "sample_527": [true], "sample_528": [true], "sample_529": [true], "sample_530": [false], "sample_531": [false], "sample_532": [false], "sample_533": [false], "sample_534": [false], "sample_535": [false], "sample_536": [false], "sample_537": [false], "sample_538": [true], "sample_539": [false], "sample_540": [true], "sample_541": [false], "sample_542": [false], "sample_543": [false], "sample_544": [false], "sample_545": [false], "sample_546": [true], "sample_547": [false], "sample_548": [false], "sample_549": [false], "sample_550": [true], "sample_551": [false], "sample_552": [false], "sample_553": [true], "sample_554": [false], "sample_555": [true], "sample_556": [false], "sample_557": [false], "sample_558": [true], "sample_559": [false], "sample_560": [true], "sample_561": [false], "sample_562": [false], "sample_563": [false], "sample_564": [false], "sample_565": [false], "sample_566": [false], "sample_567": [false], "sample_568": [false], "sample_569": [false], "sample_570": [false], "sample_571": [true], "sample_572": [false], "sample_573": [false], "sample_574": [false], "sample_575": [false], "sample_576": [false], "sample_577": [false], "sample_578": [false], "sample_579": [false], "sample_580": [true], "sample_581": [true], "sample_582": [false], "sample_583": [false], "sample_584": [false], "sample_585": [true], "sample_586": [false], "sample_587": [false], "sample_588": [false], "sample_589": [false], "sample_590": [true], "sample_591": [false], "sample_592": [false], "sample_593": [true], "sample_594": [false], "sample_595": [false], "sample_596": [false], "sample_597": [false], "sample_598": [false], "sample_599": [false], "sample_600": [false], "sample_601": [false], "sample_602": [false], "sample_603": [true], "sample_604": [false], "sample_605": [true], "sample_606": [false], "sample_607": [true], "sample_608": [false], "sample_609": [false], "sample_610": [false], "sample_611": [false], "sample_612": [true], "sample_613": [true], "sample_614": [false], "sample_615": [false], "sample_616": [false], "sample_617": [false], "sample_618": [false], "sample_619": [false], "sample_620": [true], "sample_621": [false], "sample_622": [false], "sample_623": [false], "sample_624": [false], "sample_625": [false], "sample_626": [false], "sample_627": [false], "sample_628": [false], "sample_629": [false], "sample_630": [false], "sample_631": [false], "sample_632": [false], "sample_633": [false], "sample_634": [false], "sample_635": [false], "sample_636": [false], "sample_637": [false], "sample_638": [false], "sample_639": [false], "sample_640": [false], "sample_641": [false], "sample_642": [false], "sample_643": [false], "sample_644": [false], "sample_645": [true], "sample_646": [false], "sample_647": [false], "sample_648": [false], "sample_649": [false], "sample_650": [false], "sample_651": [false], "sample_652": [false], "sample_653": [false], "sample_654": [false], "sample_655": [false], "sample_656": [false], "sample_657": [false], "sample_658": [false], "sample_659": [false], "sample_660": [false], "sample_661": [false], "sample_662": [false], "sample_663": [false], "sample_664": [false], "sample_665": [false], "sample_666": [false], "sample_667": [true], "sample_668": [false], "sample_669": [false], "sample_670": [false], "sample_671": [false], "sample_672": [false], "sample_673": [false], "sample_674": [true], "sample_675": [false], "sample_676": [false], "sample_677": [false], "sample_678": [false], "sample_679": [false], "sample_680": [false], "sample_681": [false], "sample_682": [false], "sample_683": [false], "sample_684": [true], "sample_685": [true], "sample_686": [false], "sample_687": [true], "sample_688": [false], "sample_689": [false], "sample_690": [false], "sample_691": [false], "sample_692": [false], "sample_693": [false], "sample_694": [false], "sample_695": [true], "sample_696": [false], "sample_697": [true], "sample_698": [false], "sample_699": [false], "sample_700": [false], "sample_701": [false], "sample_702": [true], "sample_703": [false], "sample_704": [true], "sample_705": [true], "sample_706": [true], "sample_707": [true], "sample_708": [false], "sample_709": [true], "sample_710": [false], "sample_711": [true], "sample_712": [false], "sample_713": [false], "sample_714": [false], "sample_715": [false], "sample_716": [true], "sample_717": [true], "sample_718": [false], "sample_719": [true], "sample_720": [true], "sample_721": [false], "sample_722": [true], "sample_723": [false], "sample_724": [false], "sample_725": [false], "sample_726": [true], "sample_727": [false], "sample_728": [true], "sample_729": [true], "sample_730": [true], "sample_731": [true], "sample_732": [true], "sample_733": [false], "sample_734": [true], "sample_735": [true], "sample_736": [true], "sample_737": [false], "sample_738": [true], "sample_739": [true], "sample_740": [false], "sample_741": [false], "sample_742": [false], "sample_743": [false], "sample_744": [true], "sample_745": [true], "sample_746": [false], "sample_747": [false], "sample_748": [false], "sample_749": [false], "sample_750": [true], "sample_751": [true], "sample_752": [true], "sample_753": [false], "sample_754": [false], "sample_755": [false], "sample_756": [false], "sample_757": [false], "sample_758": [false], "sample_759": [false], "sample_760": [false], "sample_761": [false], "sample_762": [true], "sample_763": [true], "sample_764": [true], "sample_765": [false], "sample_766": [true], "sample_767": [true], "sample_768": [false], "sample_769": [false], "sample_770": [true], "sample_771": [true], "sample_772": [false], "sample_773": [true], "sample_774": [false], "sample_775": [true], "sample_776": [true], "sample_777": [true], "sample_778": [false], "sample_779": [true], "sample_780": [true], "sample_781": [true], "sample_782": [false], "sample_783": [false], "sample_784": [false], "sample_785": [true], "sample_786": [false], "sample_787": [false], "sample_788": [false], "sample_789": [false], "sample_790": [true], "sample_791": [false], "sample_792": [false], "sample_793": [true], "sample_794": [false], "sample_795": [false], "sample_796": [true], "sample_797": [true], "sample_798": [false], "sample_799": [false], "sample_800": [true], "sample_801": [true], "sample_802": [false], "sample_803": [true], "sample_804": [false], "sample_805": [false], "sample_806": [false], "sample_807": [false], "sample_808": [true], "sample_809": [false], "sample_810": [false], "sample_811": [false], "sample_812": [false], "sample_813": [false], "sample_814": [false], "sample_815": [false], "sample_816": [false], "sample_817": [false], "sample_818": [true], "sample_819": [true], "sample_820": [true], "sample_821": [true], "sample_822": [false], "sample_823": [false], "sample_824": [false], "sample_825": [false], "sample_826": [false], "sample_827": [true], "sample_828": [false], "sample_829": [true], "sample_830": [false], "sample_831": [false], "sample_832": [true], "sample_833": [false], "sample_834": [true], "sample_835": [true], "sample_836": [false], "sample_837": [false], "sample_838": [false], "sample_839": [false], "sample_840": [true], "sample_841": [true], "sample_842": [true], "sample_843": [true], "sample_844": [false], "sample_845": [true], "sample_846": [true], "sample_847": [true], "sample_848": [true], "sample_849": [true], "sample_850": [true], "sample_851": [true], "sample_852": [false], "sample_853": [false], "sample_854": [true], "sample_855": [true], "sample_856": [true], "sample_857": [true], "sample_858": [true], "sample_859": [true], "sample_860": [true], "sample_861": [false], "sample_862": [true], "sample_863": [false], "sample_864": [true], "sample_865": [true], "sample_866": [false], "sample_867": [false], "sample_868": [true], "sample_869": [false], "sample_870": [true], "sample_871": [true], "sample_872": [false], "sample_873": [true], "sample_874": [true], "sample_875": [false], "sample_876": [false], "sample_877": [true], "sample_878": [true], "sample_879": [false], "sample_880": [false], "sample_881": [false], "sample_882": [false], "sample_883": [false], "sample_884": [false], "sample_885": [false], "sample_886": [false], "sample_887": [true], "sample_888": [true], "sample_889": [true], "sample_890": [false], "sample_891": [false], "sample_892": [true], "sample_893": [true], "sample_894": [true], "sample_895": [false], "sample_896": [true], "sample_897": [true], "sample_898": [false], "sample_899": [false], "sample_900": [false], "sample_901": [true], "sample_902": [true], "sample_903": [true], "sample_904": [false], "sample_905": [false], "sample_906": [false], "sample_907": [false], "sample_908": [false], "sample_909": [false], "sample_910": [false], "sample_911": [false], "sample_912": [false], "sample_913": [false], "sample_914": [false], "sample_915": [false], "sample_916": [false], "sample_917": [false], "sample_918": [false], "sample_919": [false], "sample_920": [false], "sample_921": [false], "sample_922": [false], "sample_923": [false], "sample_924": [false], "sample_925": [false], "sample_926": [false], "sample_927": [false], "sample_928": [false], "sample_929": [false], "sample_930": [false], "sample_931": [false], "sample_932": [false], "sample_933": [false], "sample_934": [false], "sample_935": [false], "sample_936": [false], "sample_937": [false], "sample_938": [false], "sample_939": [false], "sample_940": [false], "sample_941": [false], "sample_942": [false], "sample_943": [false], "sample_944": [false], "sample_945": [false], "sample_946": [false], "sample_947": [false], "sample_948": [false], "sample_949": [false], "sample_950": [false], "sample_951": [false], "sample_952": [false], "sample_953": [true], "sample_954": [false], "sample_955": [false], "sample_956": [false], "sample_957": [false], "sample_958": [false], "sample_959": [false], "sample_960": [false], "sample_961": [false], "sample_962": [false], "sample_963": [false], "sample_964": [false], "sample_965": [false], "sample_966": [false], "sample_967": [true], "sample_968": [false], "sample_969": [false], "sample_970": [false], "sample_971": [false], "sample_972": [false], "sample_973": [false], "sample_974": [false], "sample_975": [true], "sample_976": [true], "sample_977": [false], "sample_978": [true], "sample_979": [false], "sample_980": [true], "sample_981": [true], "sample_982": [true], "sample_983": [false], "sample_984": [false], "sample_985": [false], "sample_986": [false], "sample_987": [false], "sample_988": [false], "sample_989": [false], "sample_990": [true], "sample_991": [false], "sample_992": [false], "sample_993": [false], "sample_994": [false], "sample_995": [false], "sample_996": [true], "sample_997": [true], "sample_998": [false], "sample_999": [false], "sample_1000": [true], "sample_1001": [false], "sample_1002": [false], "sample_1003": [true], "sample_1004": [false], "sample_1005": [false], "sample_1006": [true], "sample_1007": [true], "sample_1008": [false], "sample_1009": [true], "sample_1010": [false], "sample_1011": [false], "sample_1012": [true], "sample_1013": [false], "sample_1014": [false], "sample_1015": [false], "sample_1016": [true], "sample_1017": [false], "sample_1018": [false], "sample_1019": [false], "sample_1020": [false], "sample_1021": [true], "sample_1022": [true], "sample_1023": [false], "sample_1024": [false], "sample_1025": [true], "sample_1026": [false], "sample_1027": [true], "sample_1028": [true], "sample_1029": [false], "sample_1030": [false], "sample_1031": [false], "sample_1032": [false], "sample_1033": [true], "sample_1034": [false], "sample_1035": [false], "sample_1036": [true], "sample_1037": [false], "sample_1038": [false], "sample_1039": [false], "sample_1040": [false], "sample_1041": [false], "sample_1042": [false], "sample_1043": [false], "sample_1044": [false], "sample_1045": [false], "sample_1046": [true], "sample_1047": [false], "sample_1048": [false], "sample_1049": [false], "sample_1050": [true], "sample_1051": [false], "sample_1052": [false], "sample_1053": [false], "sample_1054": [true], "sample_1055": [true], "sample_1056": [false], "sample_1057": [false], "sample_1058": [true], "sample_1059": [true], "sample_1060": [true], "sample_1061": [true], "sample_1062": [true], "sample_1063": [true], "sample_1064": [false], "sample_1065": [true], "sample_1066": [false], "sample_1067": [true], "sample_1068": [false], "sample_1069": [false], "sample_1070": [true], "sample_1071": [true], "sample_1072": [true], "sample_1073": [true], "sample_1074": [true], "sample_1075": [false], "sample_1076": [false], "sample_1077": [true], "sample_1078": [false], "sample_1079": [false], "sample_1080": [false], "sample_1081": [true], "sample_1082": [true], "sample_1083": [true], "sample_1084": [false], "sample_1085": [false], "sample_1086": [false], "sample_1087": [false], "sample_1088": [false], "sample_1089": [true], "sample_1090": [false], "sample_1091": [false], "sample_1092": [false], "sample_1093": [false], "sample_1094": [true], "sample_1095": [true], "sample_1096": [false], "sample_1097": [true], "sample_1098": [true], "sample_1099": [false], "sample_1100": [false], "sample_1101": [true], "sample_1102": [true], "sample_1103": [false], "sample_1104": [false], "sample_1105": [true], "sample_1106": [false], "sample_1107": [true], "sample_1108": [true], "sample_1109": [true], "sample_1110": [false], "sample_1111": [true], "sample_1112": [true], "sample_1113": [false], "sample_1114": [false], "sample_1115": [true], "sample_1116": [false], "sample_1117": [false], "sample_1118": [false], "sample_1119": [false], "sample_1120": [false], "sample_1121": [true], "sample_1122": [false], "sample_1123": [false], "sample_1124": [false], "sample_1125": [true], "sample_1126": [true], "sample_1127": [false], "sample_1128": [true], "sample_1129": [false], "sample_1130": [false], "sample_1131": [false], "sample_1132": [true], "sample_1133": [true], "sample_1134": [false], "sample_1135": [true], "sample_1136": [false], "sample_1137": [false], "sample_1138": [true], "sample_1139": [false], "sample_1140": [false], "sample_1141": [false], "sample_1142": [false], "sample_1143": [false], "sample_1144": [true], "sample_1145": [false], "sample_1146": [true], "sample_1147": [true], "sample_1148": [false], "sample_1149": [false], "sample_1150": [false], "sample_1151": [true], "sample_1152": [true], "sample_1153": [false], "sample_1154": [false], "sample_1155": [false], "sample_1156": [true], "sample_1157": [false], "sample_1158": [false], "sample_1159": [false], "sample_1160": [false], "sample_1161": [true], "sample_1162": [false], "sample_1163": [false], "sample_1164": [false], "sample_1165": [true], "sample_1166": [false], "sample_1167": [true], "sample_1168": [true], "sample_1169": [false], "sample_1170": [false], "sample_1171": [false], "sample_1172": [true], "sample_1173": [true], "sample_1174": [false], "sample_1175": [false], "sample_1176": [false], "sample_1177": [false], "sample_1178": [true], "sample_1179": [true], "sample_1180": [true], "sample_1181": [true], "sample_1182": [true], "sample_1183": [false], "sample_1184": [false], "sample_1185": [true], "sample_1186": [true], "sample_1187": [false], "sample_1188": [false], "sample_1189": [false], "sample_1190": [true], "sample_1191": [false], "sample_1192": [false], "sample_1193": [false], "sample_1194": [false], "sample_1195": [false], "sample_1196": [false], "sample_1197": [false], "sample_1198": [true], "sample_1199": [true], "sample_1200": [false], "sample_1201": [false], "sample_1202": [false], "sample_1203": [true], "sample_1204": [true], "sample_1205": [false], "sample_1206": [false], "sample_1207": [false], "sample_1208": [false], "sample_1209": [false]}}