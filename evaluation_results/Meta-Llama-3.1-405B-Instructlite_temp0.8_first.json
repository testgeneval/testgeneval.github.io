{"raw_generations": {"sample_67": ["    def test_float_serializer(self):\n        serializer = BaseSerializer(1.0)\n        string, imports = serializer_factory(serializer.value).serialize()\n        self.assertEqual(string, \"1.0\")\n        self.assertEqual(imports, set())\n\n        serializer = BaseSerializer(float(\"inf\"))\n        string, imports = serializer_factory(serializer.value).serialize()\n        self.assertEqual(string, 'float(\"inf\")')\n        self.assertEqual(imports, set())\n\n        serializer = BaseSerializer(float(\"-inf\"))\n        string, imports = serializer_factory(serializer.value).serialize()\n        self.assertEqual(string, 'float(\"-inf\")')\n        self.assertEqual(imports, set())\n\n        serializer = BaseSerializer(float(\"nan\"))\n        string, imports = serializer_factory(serializer.value).serialize()\n        self.assertEqual(string, 'float(\"nan\")')\n        self.assertEqual(imports, set())\n", "def test_serializer_float(self):\n    serializer = serializer_factory(1.0)\n    self.assertEqual(serializer.serialize(), (\"1.0\", set()))\n\n    serializer = serializer_factory(float(\"inf\"))\n    self.assertEqual(serializer.serialize(), (\"float('inf')\", set()))\n\n    serializer = serializer_factory(float(\"-inf\"))\n    self.assertEqual(serializer.serialize(), (\"float('-inf')\", set()))\n\n    serializer = serializer_factory(float(\"nan\"))\n    self.assertEqual(serializer.serialize(), (\"float('nan')\", set()))\n", "    def test_serializer_factory_float(self):\n        value = float('inf')\n        serializer = serializer_factory(value)\n        self.assertIsInstance(serializer, FloatSerializer)\n        string, imports = serializer.serialize()\n        self.assertEqual(string, 'float(\"inf\")')\n        self.assertEqual(imports, set())\n", "def test_serializer_float(self):\n    float_value = 1.23456789\n    serializer = BaseSerializer(float_value)\n    serialized, imports = serializer.serialize()\n    self.assertEqual(serialized, repr(float_value))\n    self.assertEqual(imports, set())\n\n    nan_value = float(\"nan\")\n    serializer = FloatSerializer(nan_value)\n    serialized, imports = serializer.serialize()\n    self.assertEqual(serialized, \"float('nan')\")\n    self.assertEqual(imports, set())\n\n    inf_value = float(\"inf\")\n    serializer = FloatSerializer(inf_value)\n    serialized, imports = serializer.serialize()\n    self.assertEqual(serialized, \"float('inf')\")\n    self.assertEqual(imports, set())\n", "    def test_float_serializer(self):\n        serializer = BaseSerializer(1.5)\n        string, imports = serializer_factory(serializer.value).serialize()\n        self.assertEqual(string, repr(serializer.value))\n        self.assertEqual(imports, set())\n\n        serializer = BaseSerializer(float(\"inf\"))\n        string, imports = serializer_factory(serializer.value).serialize()\n        self.assertEqual(string, \"float('inf')\")\n        self.assertEqual(imports, set())\n\n        serializer = BaseSerializer(float(\"-inf\"))\n        string, imports = serializer_factory(serializer.value).serialize()\n        self.assertEqual(string, \"float('-inf')\")\n        self.assertEqual(imports, set())\n\n        serializer = BaseSerializer(float(\"nan\"))\n        string, imports = serializer_factory(serializer.value).serialize()\n        self.assertEqual(string, \"float('nan')\")\n        self.assertEqual(imports, set())\n"], "sample_97": ["def test_label_binarize_sparse_output():\n    # Test label_binarize with sparse output\n    Y = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n    Y_sparse = csr_matrix(Y)\n    Y_bin = label_binarize([0, 1, 2], classes=[0, 1, 2], sparse_output=True)\n    assert_true(issparse(Y_bin))\n    assert_array_equal(Y_sparse.toarray(), Y_bin.toarray())\n", "def test_label_binarize_with_unseen_labels():\n    # Test label_binarize with unseen labels\n    y = [1, 2, 3]\n    classes = [1, 2, 3, 4]\n    Y = label_binarize(y, classes)\n    assert_array_equal(toarray(Y), [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0]])\n\n    lb = LabelBinarizer()\n    lb.fit([1, 2, 3])\n    Y = lb.transform([1, 2, 3, 4])\n    assert_raises(ValueError, lambda: toarray(Y))\n\n    lb = LabelBinarizer()\n    Y = lb.fit_transform([1, 2, 3, 4])\n    assert_array_equal(toarray(Y), [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n", "def test_label_binarize_multilabel_indicator():\n    # Test label_binarize with multilabel-indicator y\n    y = [[0, 1], [1, 0], [0, 1]]\n    classes = [0, 1]\n    Y = label_binarize(y, classes)\n    assert_array_equal(toarray(Y), [[0, 1], [1, 0], [0, 1]])\n", "def test_label_binarize_pos_label_zero():\n    # Test that label_binarize handles pos_label=0 correctly.\n    y = [1, 2, 3]\n    classes = [1, 2, 3]\n    Y = label_binarize(y, classes, neg_label=-1, pos_label=0)\n    assert_array_equal(Y, [[0, -1, -1], [-1, 0, -1], [-1, -1, 0]])\n", "def test_label_binarizer_set_y_values():\n    # Test that LabelBinarizer raises an error when y contains unseen values\n    lb = LabelBinarizer()\n    X = [[1, 2], [3, 4]]\n    y = [0, 1, 2]\n    lb.fit(y)\n    y_new = [0, 1, 3]\n\n    assert_raise_message(ValueError,\n                         \"y contains previously unseen labels: [3]\",\n                         lb.transform, y_new)\n"], "sample_7": ["    def test_common_roots(self):\n        paths = [Path('/home/user/project/file1.py'), Path('/home/user/project/file2.py')]\n        self.assertEqual(autoreload.common_roots(paths), (Path('/home/user/project'),))\n", "def test_iter_modules_and_files_with_zipfile(self):\n    # Create a temporary zip file with a .py file inside it.\n    with tempfile.NamedTemporaryFile(suffix='.zip') as tmp_file:\n        with zipfile.ZipFile(tmp_file.name, 'w') as zip_file:\n            zip_file.writestr('module.py', b'')\n        # Add the zip file to sys.path and reimport modules.\n        with extend_sys_path(tmp_file.name):\n            self.import_and_cleanup('module')\n            self.assertFileFound(Path(tmp_file.name))\n", "def test_iter_modules_and_files_with_zip_importer(self):\n    with tempfile.NamedTemporaryFile(suffix='.zip', delete=False) as tmp_file:\n        with zipfile.ZipFile(tmp_file.name, 'w') as zip_file:\n            zip_file.writestr('test.py', '')\n        sys.path.append(tmp_file.name)\n        self.import_and_cleanup('test')\n        self.assertFileFound(Path(tmp_file.name))\n    self.clear_autoreload_caches()\n    self.assertNotIn(tmp_file.name, list(autoreload.iter_all_python_module_files()))\n", "    def test_get_roots(self):\n        reloader = autoreload.WatchmanReloader()\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            tmp_dir_path = Path(tmp_dir)\n            file1 = tmp_dir_path / 'file1.py'\n            file2 = tmp_dir_path / 'subdir' / 'file2.py'\n            file1.touch()\n            file2.parent.mkdir(exist_ok=True)\n            file2.touch()\n\n            watched_files = [file1, file2]\n            roots = reloader.watched_roots(watched_files)\n\n            self.assertEqual(roots, {tmp_dir_path})\n", "    def test_check_availability(self):\n        with mock.patch('django.utils.autoreload.pywatchman.client') as client:\n            client.return_value.capabilityCheck.return_value = {'version': '4.9'}\n            self.assertIsNone(autoreload.WatchmanReloader.check_availability())\n\n            client.return_value.capabilityCheck.return_value = {'version': '4.8'}\n            with self.assertRaises(WatchmanUnavailable):\n                autoreload.WatchmanReloader.check_availability()\n\n            client.return_value.capabilityCheck.side_effect = Exception\n            with self.assertRaises(WatchmanUnavailable):\n                autoreload.WatchmanReloader.check_availability()\n"], "sample_44": ["def test_ModelChoiceField_choices_accepts_callables(self):\n    f = forms.ModelChoiceField(Category.objects.all(), required=False)\n    g = forms.ModelChoiceField(lambda: Category.objects.all(), required=False)\n    self.assertEqual(list(f.choices), list(g.choices))\n", "def test_modelchoicefield_choices_with_duplicate_values(self):\n    field = forms.ModelChoiceField(Category.objects.all(), to_field_name='slug')\n    choices = list(field.choices)\n    self.assertEqual(len(choices), 3)\n    # Ensure that choices with duplicate values are removed.\n    Category.objects.create(name='Another test', slug='test', url='another-test')\n    field = forms.ModelChoiceField(Category.objects.all(), to_field_name='slug')\n    choices = list(field.choices)\n    self.assertEqual(len(choices), 3)\n", "def test_ModelChoiceIterator(self):\n    field = forms.ModelChoiceField(Category.objects.all())\n    iterator = ModelChoiceIterator(field)\n    self.assertEqual(len(iterator), Category.objects.count())\n    for value, label in iterator:\n        self.assertIsInstance(value, ModelChoiceIteratorValue)\n        self.assertIsInstance(label, str)\n    # Test that the iterator is exhausted after iteration.\n    self.assertEqual(list(iterator), [])\n", "def test_ModelChoiceField_choices_accepts_queryset(self):\n    field = forms.ModelChoiceField(Category.objects.all())\n    self.assertEqual(len(field.choices), 3)\n", "def test_ModelChoiceIterator(self):\n    f = forms.ModelChoiceField(Category.objects.all())\n    iterator = ModelChoiceIterator(f)\n    self.assertEqual(len(iterator), 3)\n\n    # Test the iterator with a queryset that uses prefetch_related()\n    f = forms.ModelChoiceField(Category.objects.prefetch_related('article_set').all())\n    iterator = ModelChoiceIterator(f)\n    self.assertEqual(len(iterator), 3)\n\n    # Test the iterator with a queryset that uses None as its query value\n    f = forms.ModelChoiceField(Category.objects.none())\n    iterator = ModelChoiceIterator(f)\n    self.assertEqual(len(iterator), 0)\n\n    # Test that choices are correctly generated for an iterator with a queryset\n    # that has values for the field's to_field_name parameter.\n    f = forms.ModelChoiceField(Category.objects.all(), to_field_name='slug')\n    iterator = ModelChoiceIterator(f)\n    expected_choices = [\n        ('', '---------'),\n        (self.c1.slug, str(self.c1)),\n        (self.c2.slug, str(self.c2)),\n        (self.c3.slug, str(self.c3)),\n    ]\n    self.assertEqual(list(iterator), expected_choices)\n"], "sample_150": ["def test_solve_poly_system():\n    # Test for solving bivariate polynomial systems.\n    f = x**2 + y**2 - 1\n    g = x - y\n\n    assert solve_poly_system((f, g), x, y) == [(sqrt(2)/2, sqrt(2)/2),\n                                               (-sqrt(2)/2, -sqrt(2)/2)]\n\n    # Test for solving system of three polynomials with two variables.\n    f = x + y\n    g = x - y\n    h = 2*x\n\n    assert solve_poly_system((f, g, h), x, y) == [(0, 0)]\n", "def test_solve_biquadratic():\n    # two linear terms\n    f = Poly(x + y - 3, x, y)\n    g = Poly(2*x + y - 3, x, y)\n    assert solve_biquadratic(f, g, dict=True) == [{x: 0, y: 3}]\n\n    # one linear term and one quadratic term\n    f = Poly(x + y - 3, x, y)\n    g = Poly(x**2 + y**2 - 5, x, y)\n    assert solve_biquadratic(f, g, dict=True) == [{x: 1, y: 2}, {x: 3, y: 0}]\n\n    # two quadratic terms with no solution\n    f = Poly(x**2 + y**2 - 1, x, y)\n    g = Poly(x**2 + y**2 - 2, x, y)\n    assert solve_biquadratic(f, g) == []\n\n    # two quadratic terms with infinite solutions\n    f = Poly(x**2 + y**2, x, y)\n    g = Poly(2*x**2 + 2*y**2, x, y)\n    raises(SolveFailed, lambda: solve_biquadratic(f, g))\n", "def test_solve_poly_system():\n    # test for solving bivariate polynomial equations\n    f = Poly(x**2 + y - 1, x, y)\n    g = Poly(x + y**2 - 1, x, y)\n    assert solve_poly_system((f, g), x, y) == [(0, -1), (1, 0)]\n\n    # test for solving system of more than two polynomials\n    f = Poly(x**2 + y - z, x, y, z)\n    g = Poly(x + y**2 - z, x, y, z)\n    h = Poly(z**3 - x - y, x, y, z)\n    raises(NotImplementedError, lambda: solve_poly_system((f, g, h), x, y, z))\n", "def test_solve_biquadratic():\n    assert solve_biquadratic(\n        Poly(x**2 + y, x, y, domain='ZZ'),\n        Poly(x + y**2 - 3, x, y, domain='ZZ'),\n        Options((x, y), {'domain': 'ZZ'})\n    ) == [(1/3, -1/3 + sqrt(13)/3), (1/3, -sqrt(13)/3 - 1/3)]\n", "def test_solve_biquadratic():\n    # simple case\n    f = Poly(x**2 + y, x, y)\n    g = Poly(x + y**2, x, y)\n    assert solve_biquadratic(f, g, dict=True) == [{x: 0, y: 0}, {x: -1, y: -1}]\n\n    # no solution\n    f = Poly(x**2 + 1, x, y)\n    g = Poly(x + y**2, x, y)\n    assert solve_biquadratic(f, g) == []\n\n    # only one generator is given\n    f = Poly(x**2 + 1, x)\n    g = Poly(x + 1, x)\n    raises(SolveFailed, lambda: solve_biquadratic(f, g))\n\n    # polynomials have more than two generators\n    f = Poly(x**2 + y**2 + z, x, y, z)\n    g = Poly(x + y + z, x, y, z)\n    raises(SolveFailed, lambda: solve_biquadratic(f, g))\n"], "sample_84": ["def test_pytest_pyfunc_call(pytester):\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n            assert 1 + 1 == 2\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n", "def test_show_fixtures_per_test(pytester):\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            return 1\n\n            pass\n\n            pass\n\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--fixtures-per-test\")\n    assert result.ret == 0\n    output = result.stdout.str()\n    assert \"fixtures used by test_foo.py::test_foo\" in output\n    assert \"arg\" in output\n    assert \"fixtures used by test_foo.py::test_bar\" in output\n    assert \"arg\" in output\n    assert \"fixtures used by test_foo.py::test_baz\" not in output\n", "def test_show_fixtures_per_test(pytester):\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            pass\n\n        @pytest.fixture\n            pass\n\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--fixtures-per-test\")\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"*- fixtures used by test_foo -*\", \"*foo*\", \"*bar*\"])\n", "def test_pyobj_property_owns_marks(testdir):\n    \"\"\"Test that pyobj property owns marks (#4569)\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        pytestmark = pytest.mark.skip\n\n            pass\n    \"\"\"\n    )\n    items, _ = testdir.inline_genitems()\n    assert len(items) == 1\n    assert list(items[0].iter_markers(name=\"skip\"))\n", "def test_fixture_request_with_scope_function():\n    \"\"\"Test that a FixtureRequest with scope \"function\" can be used to get fixtures.\"\"\"\n    request = FixtureRequest(Node(), _ispytest=True)\n    assert request.scope == \"function\"\n    with pytest.raises(FixtureLookupError):\n        request.getfixturevalue(\"non_existent_fixture\")\n"], "sample_134": ["def test_PythonCodePrinter_tensor_product():\n    M = MatrixSymbol(\"M\", 2, 2)\n    N = MatrixSymbol(\"N\", 2, 2)\n    M_t_N = CodegenArrayTensorProduct(M, N)\n    assert NumPyPrinter().doprint(M_t_N) == 'numpy.einsum(\"ij,jk->ik\", M, N)'\n", "def test_pycode_log1p():\n    f = lambdify(x, log1p(x), 'numpy')\n    assert str(f) == 'numpy.log1p(x)'\n", "def test_print_CodegenArrayElementwiseAdd():\n    n = 10\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    C = MatrixSymbol('C', n, n)\n\n    cg = CodegenArrayElementwiseAdd(A, B, C)\n    assert NumPyPrinter().doprint(cg) == \"numpy.add(numpy.add(A, B), C)\"\n", "def test_codegen_array_contraction():\n    M = MatrixSymbol(\"M\", 3, 3)\n    N = MatrixSymbol(\"N\", 3, 3)\n    cg = CodegenArrayContraction(CodegenArrayTensorProduct(M, N), (1, 0))\n    assert NumPyPrinter().doprint(cg) == \"numpy.einsum('ij,jk->ik', M, N)\"\n", "def test_print_CodegenArrayElementwiseAdd():\n    n = 3\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    C = CodegenArrayElementwiseAdd(A, B)\n    assert NumPyPrinter().doprint(C) == 'numpy.add(A, B)'\n"], "sample_60": ["    def test_serialize_float(self):\n        float_value = 3.14\n        serializer = BaseSerializer(float_value)\n        serialized_value, imports = serializer.serialize()\n        self.assertEqual(serialized_value, repr(float_value))\n        self.assertEqual(imports, set())\n", "    def test_serializer_factory_with_lazy_object(self):\n        lazy_obj = SimpleLazyObject(lambda: \"lazy_value\")\n        serializer = serializer_factory(lazy_obj)\n        self.assertIsInstance(serializer, BaseSimpleSerializer)\n        serialized_value, imports = serializer.serialize()\n        self.assertEqual(serialized_value, \"'lazy_value'\")\n        self.assertEqual(imports, set())\n", "    def test_serialize_float(self):\n        value = float('nan')\n        serializer = FloatSerializer(value)\n        serialized, imports = serializer.serialize()\n        self.assertEqual(serialized, 'float(\"nan\")')\n        self.assertEqual(imports, set())\n", "    def test_float_serializer_with_nan(self):\n        value = float(\"nan\")\n        serializer = FloatSerializer(value)\n        serialized_value, imports = serializer.serialize()\n        self.assertEqual(serialized_value, \"float('nan')\")\n        self.assertEqual(imports, set())\n", "def test_serialize_float(self):\n    writer = OperationWriter(value=1.5, indentation=0)\n    string, imports = writer.serialize()\n    self.assertEqual(string, '1.5')\n    self.assertEqual(imports, set())\n\n    writer = OperationWriter(value=float('inf'), indentation=0)\n    string, imports = writer.serialize()\n    self.assertEqual(string, \"float('inf')\")\n    self.assertEqual(imports, set())\n\n    writer = OperationWriter(value=float('nan'), indentation=0)\n    string, imports = writer.serialize()\n    self.assertEqual(string, \"float('nan')\")\n    self.assertEqual(imports, set())\n"], "sample_47": ["def test_migration_plan_with_replaced_migrations(self):\n    \"\"\"\n    Test that replaced migrations are properly removed from the plan.\n    \"\"\"\n    # Create a migration graph with some replaced migrations\n    graph = MigrationGraph()\n    graph.add_node((\"app\", \"0001\"), None)\n    graph.add_node((\"app\", \"0002\"), (\"app\", \"0001\"))\n    graph.add_node((\"app\", \"0003\"), (\"app\", \"0002\"))\n    graph.add_replacement((\"app\", \"0002\"), (\"app\", \"0002_squashed\"))\n\n    # Create an executor with this graph\n    executor = MigrationExecutor(connection, progress_callback=None)\n    executor.loader.graph = graph\n\n    # Generate a plan to migrate up to 0003\n    plan = executor.migration_plan([(\"app\", \"0003\")])\n\n    # The plan should not include the replaced migration\n    self.assertNotIn((\"app\", \"0002\"), [m[0] for m in plan])\n    self.assertIn((\"app\", \"0002_squashed\"), [m[0] for m in plan])\n", "def test_migration_plan_with_replaced_migrations(self):\n    \"\"\"\n    Test that replaced migrations are properly handled in the migration plan.\n    \"\"\"\n    # Create a migration graph with some replaced migrations\n    migration_graph = MigrationGraph()\n    migration_graph.add_node((\"app\", \"0001_initial\"), None)\n    migration_graph.add_node((\"app\", \"0002_second\"), (\"app\", \"0001_initial\"))\n    migration_graph.add_node((\"app\", \"0003_third\"), (\"app\", \"0002_second\"))\n    migration_graph.add_replacement((\"app\", \"0004_replacement\"), ((\"app\", \"0001_initial\"), (\"app\", \"0002_second\")))\n\n    # Create an executor and load the graph into it\n    executor = MigrationExecutor(connection)\n    executor.loader.graph = migration_graph\n\n    # Get the migration plan for the replacement migration\n    targets = [(\"app\", \"0004_replacement\")]\n    plan = executor.migration_plan(targets)\n\n    # Check that the replaced migrations are not in the plan\n    self.assertNotIn((\"app\", \"0001_initial\"), [m[0] for m in plan])\n    self.assertNotIn((\"app\", \"0002_second\"), [m[0] for m in plan])\n    self.assertIn((\"app\", \"0004_replacement\"), [m[0] for m in plan])\n", "def test_migration_plan_with_replacements(self):\n    \"\"\"\n    Test migration plan with replacements.\n    \"\"\"\n    recorder = MigrationRecorder(connection)\n    recorder.record_applied(\"migrations\", \"0001_initial\")\n    recorder.record_applied(\"migrations\", \"0002_second\")\n    executor = MigrationExecutor(connection)\n    targets = [(\"migrations\", \"0003_third\")]\n    plan = executor.migration_plan(targets)\n    self.assertEqual(len(plan), 1)\n    self.assertEqual(plan[0][0].name, \"0003_third\")\n    self.assertFalse(plan[0][1])  # applied is False\n\n    # Test that replacement migrations are recorded as applied\n    executor.check_replacements()\n    self.assertIn((\"migrations\", \"0003_third\"), recorder.applied_migrations())\n", "def test_migration_plan_with_replacements(self):\n    \"\"\"\n    Tests the migration plan with replacements.\n    \"\"\"\n    # Create a mock migration graph with a replacement migration\n    graph = MigrationGraph()\n    graph.add_node((\"app\", \"0001_initial\"), None)\n    graph.add_node((\"app\", \"0002_second\"), [(\"app\", \"0001_initial\")])\n    graph.add_node((\"app\", \"0003_third\"), [(\"app\", \"0002_second\")])\n    graph.add_replacement((\"app\", \"0004_replacement\"), [(\"app\", \"0001_initial\"), (\"app\", \"0002_second\")])\n\n    # Create a mock migration loader\n    loader = mock.Mock()\n    loader.graph = graph\n\n    # Create a mock migration recorder\n    recorder = mock.Mock()\n\n    # Create a migration executor\n    executor = MigrationExecutor(connection, progress_callback=None)\n    executor.loader = loader\n    executor.recorder = recorder\n\n    # Get the migration plan\n    targets = [(\"app\", \"0003_third\")]\n    plan = executor.migration_plan(targets)\n\n    # Check that the replacement migration is in the plan\n    self.assertIn((graph.nodes[(\"app\", \"0004_replacement\")], False), plan)\n", "def test_migration_plan_with_replaced_migrations(self):\n    \"\"\"\n    Tests that replaced migrations are properly handled in the migration plan.\n    \"\"\"\n    # Create a mock migration graph with some replaced migrations\n    graph = MigrationGraph()\n    graph.add_node((\"app\", \"0001_initial\"), None)\n    graph.add_node((\"app\", \"0002_second\"), [(\"app\", \"0001_initial\")])\n    graph.add_node((\"app\", \"0003_third\"), [(\"app\", \"0002_second\")])\n    graph.add_replacement((\"app\", \"0004_merge\"), ((\"app\", \"0003_third\"),))\n\n    # Create a mock migration recorder with some applied migrations\n    recorder = MigrationRecorder(connection)\n    recorder.record_applied(\"app\", \"0001_initial\")\n    recorder.record_applied(\"app\", \"0002_second\")\n\n    # Create a migration executor with the mock graph and recorder\n    executor = MigrationExecutor(connection, progress_callback=None)\n    executor.loader.graph = graph\n    executor.recorder = recorder\n\n    # Get the migration plan for the given targets\n    targets = [(\"app\", \"0004_merge\")]\n    plan = executor.migration_plan(targets)\n\n    # Assert that the plan contains the correct migrations\n    expected_plan = [\n        (\"app\", \"0003_third\", False),\n        (\"app\", \"0004_merge\", False),\n    ]\n    self.assertEqual(plan, expected_plan)\n"], "sample_10": ["def test_lookup_contains_aggregate(self):\n    articles = Article.objects.annotate(max_pub_date=Max('pub_date'))\n    lookup = Contains(articles[0].headline, 'Article')\n    self.assertFalse(lookup.contains_aggregate)\n    lookup = Contains(articles[0].max_pub_date, datetime(2005, 7, 27))\n    self.assertTrue(lookup.contains_aggregate)\n", "def test_exact_lookup_with_query(self):\n    Article.objects.create(headline='Test Article 1')\n    subquery = Article.objects.filter(headline__exact='Test Article 1').values('pk')\n    self.assertTrue(Article.objects.filter(pk__exact=subquery).exists())\n    self.assertFalse(Article.objects.filter(pk__exact=subquery[:0]).exists())\n", "def test_exists_lookup(self):\n    # Create a few Players and Games.\n    p1 = Player.objects.create(name='Player 1')\n    p2 = Player.objects.create(name='Player 2')\n    g1 = Game.objects.create(player=p1, game_date=datetime(2020, 1, 1))\n    g2 = Game.objects.create(player=p2, game_date=datetime(2020, 1, 2))\n\n    # Use Exists to filter for players with games.\n    players_with_games = Player.objects.filter(Exists(Game.objects.filter(player=OuterRef('pk'))))\n    self.assertQuerysetEqual(players_with_games, [p1, p2])\n\n    # Use Exists to filter for players without games.\n    players_without_games = Player.objects.filter(~Exists(Game.objects.filter(player=OuterRef('pk'))))\n    self.assertQuerysetEqual(players_without_games, [])\n\n    # Use Exists with Subquery to filter for players with games on a specific date.\n    players_with_games_on_date = Player.objects.filter(\n        Exists(Game.objects.filter(player=OuterRef('pk'), game_date=datetime(2020, 1, 1)))\n    )\n    self.assertQuerysetEqual(players_with_games_on_date, [p1])\n", "def test_lookup_in_with_empty_list(self):\n    with self.assertRaises(EmptyResultSet):\n        Article.objects.filter(headline__in=[])\n\n    with self.assertRaises(EmptyResultSet):\n        Article.objects.exclude(headline__in=[])\n", "def test_exists_lookup_with_outerref(self):\n    subquery = Article.objects.filter(author=OuterRef('pk')).values('author')\n    authors = Author.objects.filter(Exists(subquery)).order_by('name')\n    self.assertQuerysetEqual(authors, ['Author 1', 'Author 2'], attrgetter('name'))\n"], "sample_61": ["def test_decimal_pos(self):\n    self.assertEqual(nformat(12345.6789, decimal_sep=\".\", decimal_pos=2), \"12345.68\")\n    self.assertEqual(nformat(12345.6789, decimal_sep=\",\", decimal_pos=3), \"12345,679\")\n    self.assertEqual(nformat(12345, decimal_sep=\".\", decimal_pos=2), \"12345.00\")\n    self.assertEqual(nformat(12345, decimal_sep=\",\", decimal_pos=0), \"12345\")\n", "def test_numberformat_scientific_notation(self):\n    num = Decimal(\"1.23456789e-100\")\n    formatted_num = nformat(num, decimal_sep=\".\", decimal_pos=5)\n    self.assertEqual(formatted_num, \"1.23457e-100\")\n\n    num = Decimal(\"1.23456789e100\")\n    formatted_num = nformat(num, decimal_sep=\".\", decimal_pos=5)\n    self.assertEqual(formatted_num, \"1.23457e+100\")\n", "def test_numberformat_force_grouping(self):\n    self.assertEqual(nformat(12345, decimal_sep='.', grouping=3, thousand_sep=',', force_grouping=True), '12,345')\n    self.assertEqual(nformat(12345, decimal_sep='.', grouping=3, thousand_sep=',', force_grouping=False), '12345')\n    self.assertEqual(nformat(12345, decimal_sep='.', grouping=0, thousand_sep=',', force_grouping=True), '12345')\n", "def test_decimal_pos_rounding(self):\n    self.assertEqual(nformat(Decimal('123.456'), '.', decimal_pos=2), '123.46')\n    self.assertEqual(nformat(Decimal('123.456'), '.', decimal_pos=0), '123')\n    self.assertEqual(nformat(Decimal('123.456'), '.', decimal_pos=4), '123.4560')\n", "def test_format_decimal_pos(self):\n    self.assertEqual(nformat(123.456, decimal_sep=\".\", decimal_pos=2), \"123.46\")\n    self.assertEqual(nformat(123.456, decimal_sep=\".\", decimal_pos=0), \"123\")\n    self.assertEqual(nformat(123.456, decimal_sep=\".\", decimal_pos=None), \"123.456\")\n    self.assertEqual(nformat(Decimal(\"123.456\"), decimal_sep=\".\", decimal_pos=2), \"123.46\")\n    self.assertEqual(nformat(Decimal(\"123.456\"), decimal_sep=\".\", decimal_pos=0), \"123\")\n    self.assertEqual(nformat(Decimal(\"123.456\"), decimal_sep=\".\", decimal_pos=None), \"123.456\")\n"], "sample_9": ["def test_iter_modules_and_files_zip_import(self):\n    # Create a zip file containing a module.\n    with tempfile.NamedTemporaryFile(suffix='.zip') as tmp_file:\n        with zipfile.ZipFile(tmp_file.name, 'w') as zip_file:\n            zip_file.writestr('mymodule/__init__.py', '')\n            zip_file.writestr('mymodule/myfile.py', 'x = 1')\n        self.addCleanup(lambda: sys.path_importer_cache.clear())\n\n        # Add the zip file to sys.path.\n        with extend_sys_path(tmp_file.name):\n            self.import_and_cleanup('mymodule.myfile')\n\n            # Check that iter_modules_and_files() yields the module file inside the zip.\n            modules_and_files = list(autoreload.iter_all_python_module_files())\n            self.assertEqual(len(modules_and_files), 2)\n            zip_file_path = Path(tmp_file.name).resolve()\n            self.assertIn(zip_file_path, modules_and_files)\n", "def test_iter_modules_and_files_with_zip_importer(self):\n    tmpdir = tempfile.mkdtemp()\n    self.addCleanup(shutil.rmtree, tmpdir)\n\n    # Create a zip archive with a Python module.\n    zip_filename = Path(tmpdir) / 'test.zip'\n    with zipfile.ZipFile(str(zip_filename), 'w') as zip_file:\n        zip_file.writestr('test.py', b'def test(): pass')\n\n    # Add the zip archive to sys.path and import the module.\n    extend_sys_path(str(tmpdir))\n    self.import_and_cleanup('test')\n\n    # The module should be found by iter_modules_and_files.\n    self.assertFileFound(zip_filename)\n", "    def test_common_roots(self):\n        paths = [\n            Path('/path/to/dir1/file1.py'),\n            Path('/path/to/dir1/file2.py'),\n            Path('/path/to/dir2/file3.py'),\n        ]\n        roots = autoreload.common_roots(paths)\n        self.assertEqual(roots, (Path('/path/to/dir1'), Path('/path/to/dir2')))\n", "def test_iter_modules_and_files_with_compiled_file(self):\n    with extend_sys_path(tempfile.mkdtemp()):\n        filename = self.temporary_file('test.py')\n        compiled_filename = py_compile.compile(str(filename))\n        self.import_and_cleanup('test')\n        self.assertFileFound(Path(compiled_filename))\n", "def test_iter_modules_and_files_zip_import(self):\n    with tempfile.NamedTemporaryFile(suffix='.zip', delete=False) as tmp_file:\n        filename = Path(tmp_file.name)\n        self.addCleanup(filename.unlink)\n        with zipfile.ZipFile(tmp_file, 'w') as zip_file:\n            zip_file.writestr('test.py', b'')\n        sys.path.insert(0, str(filename))\n        self.addCleanup(lambda: sys.path.pop(0))\n        import_module('test')\n        self.assertFileFound(filename)\n"], "sample_146": ["def test_print_MatPow():\n    A = MatrixSymbol(\"A\", 2, 2)\n    assert sstr(A**3) == \"A**3\"\n", "def test_print_Dimension():\n    assert sstr(Dimension(\"length\")) == \"length\"\n", "def test_print_Predicate():\n    assert sstr(Q.is_true(x > 0)) == \"Q.is_true(x > 0)\"\n", "def test_StrPrinter_print_Subs():\n    expr = Subs(x + y, x, 2)\n    assert sstr(expr) == \"Subs(x + y, x, 2)\"\n", "def test_print_Subs():\n    f = Function('f')\n    expr = Subs(f(x), x, 2)\n    assert sstr(expr) == \"Subs(f(x), x, 2)\"\n"], "sample_3": ["def test_separable_arithmetic_operator():\n    # Test that arithmetic operators always return a non-separable output\n    model1 = models.Shift(1)\n    model2 = models.Shift(2)\n\n    result = _arith_oper(model1, model2)\n    assert np.all(result == 1)\n\n    # Test with numpy arrays\n    array1 = np.array([[1, 0], [0, 1]])\n    array2 = np.array([[1, 0], [0, 1]])\n\n    result = _arith_oper(array1, array2)\n    assert np.all(result == 1)\n", "def test_arith_oper():\n    # Test that _arith_oper raises an error when the inputs have different numbers of inputs or outputs\n    with pytest.raises(ModelDefinitionError):\n        _arith_oper(models.Scale(1), models.Scale(2) & models.Scale(3))\n\n    # Test that _arith_oper returns an array of ones when the inputs have the same numbers of inputs and outputs\n    result = _arith_oper(models.Scale(1), models.Scale(2))\n    assert_allclose(result, np.ones((1, 1)))\n", "def test_arith_oper():\n    # Test that _arith_oper raises an error for incompatible models\n    with pytest.raises(ModelDefinitionError):\n        _arith_oper(sh1, rot)\n\n    # Test that _arith_oper returns the correct result for compatible models\n    result = _arith_oper(sh1, sh2)\n    assert_allclose(result, np.ones((1, 1)))\n", "def test_separability_matrix_single_input_model():\n    model = models.Polynomial1D(1)\n    expected_matrix = np.ones((model.n_outputs, model.n_inputs), dtype=np.bool_)\n    assert_allclose(separability_matrix(model), expected_matrix)\n", "def test_separable_arithmetic_operator():\n    # Test separability with arithmetic operators\n    model = sh1 + sh2\n    assert not is_separable(model).any()\n    assert np.all(separability_matrix(model))\n"], "sample_8": ["    def test_cleanse_setting(self):\n        self.assertEqual(cleanse_setting('foo', 'bar'), 'bar')\n        self.assertEqual(cleanse_setting('API_KEY', 'secret'), CLEANSED_SUBSTITUTE)\n        self.assertEqual(cleanse_setting('DATABASES', {'default': {'PASSWORD': 'secret'}}), {'default': {'PASSWORD': CLEANSED_SUBSTITUTE}})\n", "    def test_cleanse_setting(self):\n        # Test with sensitive setting\n        self.assertEqual(cleanse_setting('SECRET_KEY', 'secret_value'), CLEANSED_SUBSTITUTE)\n\n        # Test with non-sensitive setting\n        self.assertEqual(cleanse_setting('NON_SENSITIVE_SETTING', 'non_sensitive_value'), 'non_sensitive_value')\n\n        # Test with dictionary value\n        sensitive_dict = {'key1': 'value1', 'key2': 'value2'}\n        cleansed_dict = cleanse_setting('SETTING_NAME', sensitive_dict)\n        self.assertIsInstance(cleansed_dict, dict)\n        self.assertEqual(cleansed_dict['key1'], 'value1')\n        self.assertEqual(cleansed_dict['key2'], 'value2')\n\n        # Test with callable value\n            return 'callable_value'\n        cleansed_callable = cleanse_setting('SETTING_NAME', my_callable)\n        self.assertIsInstance(cleansed_callable, CallableSettingWrapper)\n", "    def test_cleanse_setting(self):\n        self.assertEqual(cleanse_setting('key', 'value'), 'value')\n        self.assertEqual(cleanse_setting('API_KEY', 'secret'), CLEANSED_SUBSTITUTE)\n        self.assertEqual(cleanse_setting('DATABASES', {'default': {'PASSWORD': 'secret'}}), {'default': {'PASSWORD': CLEANSED_SUBSTITUTE}})\n", "    def test_cleanse_setting(self):\n        self.assertEqual(cleanse_setting('TEST', 'test'), 'test')\n        self.assertEqual(cleanse_setting('SECRET_KEY', 'secret'), CLEANSED_SUBSTITUTE)\n        self.assertEqual(cleanse_setting('DATABASES', {'default': {'PASSWORD': 'password'}}), {'default': {'PASSWORD': CLEANSED_SUBSTITUTE}})\n        self.assertEqual(cleanse_setting('ALLOWED_HOSTS', ['host1', 'host2']), ['host1', 'host2'])\n", "    def test_cleanse_setting(self):\n        self.assertEqual(cleanse_setting('TEST_SETTING', 'test_value'), 'test_value')\n"], "sample_133": ["def test_matrix_symbols():\n    n = symbols('n', integer=True)\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    C = MatrixSymbol('C', n, n)\n\n    eq = Eq(C, A*B)\n    routine = make_routine('matmul', eq)\n    csrc = get_string(CCodeGen().dump_c, [routine])\n    fsrc = get_string(FCodeGen().dump_f95, [routine])\n\n    assert 'void matmul(double *A, double *B, int n, double *C)' in csrc\n    assert 'subroutine matmul(A, B, n, C)' in fsrc\n", "def test_MatrixOutput():\n    x, y = symbols('x,y')\n    M = Matrix([[x,y],[y,x]])\n    expr = Equality(M, M)\n    raises(CodeGenError, lambda: make_routine('test', expr))\n", "def test_code_gen_matrix():\n    x, y = symbols('x y')\n    A = Matrix([[x, y], [y, x]])\n    expr = Eq(A, A)\n    raises(CodeGenError, lambda: codegen(('f', expr), 'C'))\n    raises(CodeGenError, lambda: codegen(('f', expr), 'F95'))\n    raises(CodeGenError, lambda: codegen(('f', expr), 'Octave'))\n", "def test_CodeGenArgumentListError():\n    x, y = symbols('x y')\n    raises(CodeGenArgumentListError, lambda: make_routine(\"test\", Eq(x, y), argument_sequence=(y,)))\n", "def test_c_codegen_with_user_declarations():\n    x, y = symbols('x y')\n    user_declarations = \"\"\"\\"], "sample_105": ["def test_voting_regressor_transform():\n    # Test VotingRegressor's transform method\n    X, y = datasets.make_regression(n_samples=100, n_features=5)\n    estimator1 = LinearRegression()\n    estimator2 = RandomForestRegressor()\n    voting_regressor = VotingRegressor(estimators=[('lr', estimator1), ('rf', estimator2)])\n    voting_regressor.fit(X, y)\n    transformed_data = voting_regressor.transform(X)\n    assert_array_equal(transformed_data.shape, (100, 2))\n", "def test_voting_regressor_predict_shape():\n    # Test that VotingRegressor predict method returns the correct shape\n    X, y = datasets.make_regression(n_samples=10, n_features=5)\n    estimator1 = LinearRegression()\n    estimator2 = RandomForestRegressor()\n    voting_regressor = VotingRegressor(estimators=[('lr', estimator1), ('rf', estimator2)])\n    voting_regressor.fit(X, y)\n    y_pred = voting_regressor.predict(X)\n    assert_array_equal(y_pred.shape, (10,))\n", "def test_voting_classifier_set_params():\n    # Test setting estimator parameters after initialization\n    clf1 = LogisticRegression()\n    clf2 = RandomForestClassifier()\n    eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)])\n\n    # Set parameters for the ensemble and its individual estimators\n    eclf.set_params(lr__C=10, rf__n_estimators=100)\n\n    assert_equal(eclf.named_estimators.lr.C, 10)\n    assert_equal(eclf.named_estimators.rf.n_estimators, 100)\n", "def test_voting_classifier_predict_proba():\n    # Test predict_proba for VotingClassifier\n    clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=1)\n    clf2 = RandomForestClassifier(n_estimators=10, random_state=1)\n    clf3 = GaussianNB()\n\n    eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft')\n\n    eclf.fit(X, y)\n\n    assert eclf.predict_proba(X).shape == (len(X), len(np.unique(y)))\n\n    # Check that predict_proba works with dropouts\n    eclf_drop = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('drop', None)], voting='soft')\n    eclf_drop.fit(X, y)\n\n    assert eclf_drop.predict_proba(X).shape == (len(X), len(np.unique(y)))\n", "def test_voting_classifier_predict_proba():\n    clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=1)\n    clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n    clf3 = GaussianNB()\n    eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft')\n\n    eclf.fit(X, y)\n\n    # Check if predict_proba returns the same result with or without weights\n    y_proba = eclf.predict_proba(X)\n    eclf.weights = [1, 1, 1]\n    y_proba_weighted = eclf.predict_proba(X)\n\n    assert_array_almost_equal(y_proba, y_proba_weighted)\n\n    # Check if predict_proba raises an error when voting is 'hard'\n    eclf.voting = 'hard'\n    with pytest.raises(AttributeError):\n        eclf.predict_proba(X)\n"], "sample_59": ["def test_formset_factory_with_absolute_max(self):\n    # absolute_max is a hard limit on forms instantiated, to prevent\n    # memory-exhaustion attacks.\n    formset = formset_factory(\n        Choice, extra=1, max_num=10, validate_max=True, absolute_max=5\n    )\n    self.assertEqual(formset.absolute_max, 5)\n    self.assertRaises(ValueError, formset_factory, Choice, max_num=10, absolute_max=5)\n\n    # if absolute_max is not specified, it defaults to max_num + DEFAULT_MAX_NUM\n    formset = formset_factory(Choice, extra=1, max_num=10)\n    self.assertEqual(formset.absolute_max, 1010)\n", "def test_formset_with_custom_widget(self):\n    class CustomWidgetForm(Form):\n        name = CharField(widget=HiddenInput)\n\n    CustomWidgetFormSet = formset_factory(CustomWidgetForm)\n    formset = CustomWidgetFormSet(data={\n        'form-TOTAL_FORMS': '1',\n        'form-INITIAL_FORMS': '0',\n        'form-MAX_NUM_FORMS': '',\n        'form-MIN_NUM_FORMS': '',\n        'form-0-name': 'John Doe'\n    })\n    self.assertTrue(formset.is_valid())\n    self.assertEqual(formset.cleaned_data[0]['name'], 'John Doe')\n", "def test_formset_non_form_error(self):\n    formset = ChoiceFormsetWithNonFormError(\n        data={\n            \"choices-TOTAL_FORMS\": \"1\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MAX_NUM_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"test\",\n            \"choices-0-votes\": \"1\",\n        }\n    )\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(len(formset.non_form_errors()), 1)\n    self.assertEqual(formset.non_form_errors()[0], \"non-form error\")\n", "def test_formset_absolute_max(self):\n    \"\"\"\n    FormSet's absolute_max attribute is a hard limit on forms instantiated,\n    to prevent memory-exhaustion attacks.\n    \"\"\"\n    # Set absolute_max to 5 and max_num to 10\n    ChoiceFormSetAbsoluteMax = formset_factory(\n        Choice, max_num=10, absolute_max=5, validate_max=True\n    )\n    # Try to instantiate more than absolute_max forms\n    formset_data = [\n        (\"choice1\", 1),\n        (\"choice2\", 2),\n        (\"choice3\", 3),\n        (\"choice4\", 4),\n        (\"choice5\", 5),\n        (\"choice6\", 6),\n    ]\n    with self.assertRaisesMessage(ValidationError, \"Please submit at most 5 forms.\"):\n        self.make_choiceformset(formset_data, formset_class=ChoiceFormSetAbsoluteMax)\n", "def test_formset_management_form_validation(self):\n    # Test that the management form validates its fields correctly\n    data = {\n        'choices-TOTAL_FORMS': '1',\n        'choices-INITIAL_FORMS': '0',\n        'choices-MIN_NUM_FORMS': '-1',  # Invalid value\n        'choices-MAX_NUM_FORMS': '1001',  # Invalid value\n    }\n    formset = self.make_choiceformset(data)\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(len(formset.management_form.errors), 2)\n    self.assertIn('MIN_NUM_FORMS', formset.management_form.errors)\n    self.assertIn('MAX_NUM_FORMS', formset.management_form.errors)\n"], "sample_141": ["def test_convert_to_with_prefix():\n    assert convert_to(kilo*meter, centimeter) == 100000*centimeter\n    assert convert_to(meter, kilo*centimeter) == Rational(1, 1000)*kilo*centimeter\n", "def test_convert_to_Planck_units():\n    from sympy.physics.units import hbar, gravitational_constant, speed_of_light\n    from sympy.physics.units import atomic_mass_constant\n\n    assert convert_to(atomic_mass_constant, [gravitational_constant, speed_of_light, hbar]).n() == \\\n        7.62963085040767e-20*gravitational_constant**(-0.5)*hbar**0.5*speed_of_light**0.5\n", "def test_convert_to():\n    assert convert_to(speed_of_light, meter/second) == 299792458*meter/second\n    assert convert_to(day, second) == 86400*second\n    assert convert_to(3*newton, kilogram*meter/second**2) == 3*kilogram*meter/second**2\n    assert convert_to(atomic_mass_constant, gram).n() == 1.660539060e-24*gram\n\n    # Test conversion to multiple units\n    assert convert_to(speed_of_light, [meter, second]) == 299792458*meter/second\n    assert convert_to(3*newton, [centimeter, gram, second]) == 300000*centimeter*gram/second**2\n\n    # Test conversion to Planck units\n    assert convert_to(atomic_mass_constant, [gravitational_constant, speed_of_light, hbar]).n() == 7.62963085040767e-20*gravitational_constant**(-0.5)*hbar**0.5*speed_of_light**0.5\n", "def test_convert_to():\n    # Test conversion to multiple units\n    assert convert_to(speed_of_light, [meter, second]) == 299792458*meter/second\n    assert convert_to(3*newton, [centimeter, gram, second]) == 300000*centimeter*gram/second**2\n\n    # Test conversion to Planck units\n    planck_units = [gravitational_constant, speed_of_light, hbar]\n    assert convert_to(atomic_mass_constant, planck_units).n() == 7.62963085040767e-20*gravitational_constant**(-0.5)*hbar**0.5*speed_of_light**0.5\n\n    # Test conversion of Add instances\n    expr = 2*newton + 3*kilogram*meter/second**2\n    assert convert_to(expr, kilogram*meter/second**2) == 5*kilogram*meter/second**2\n", "def test_convert_to_multiple_units():\n    expr = speed_of_light\n    target_units = [meter, second]\n    result = convert_to(expr, target_units)\n    assert result == 299792458*meter/second\n\n    expr = 3*newton\n    target_units = [centimeter, gram, second]\n    result = convert_to(expr, target_units)\n    assert result == 300000*centimeter*gram/second**2\n\n    expr = atomic_mass_constant\n    target_units = [gravitational_constant, speed_of_light, hbar]\n    result = convert_to(expr, target_units).n()\n    assert result == 7.62963085040767e-20*gravitational_constant**(-0.5)*hbar**0.5*speed_of_light**0.5\n"], "sample_140": ["def test_point_v1pt_theory():\n    q, q2 = dynamicsymbols('q q2')\n    qd, q2d = dynamicsymbols('q q2', 1)\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    B.set_ang_vel(N, 5 * B.y)\n    O = Point('O')\n    P = O.locatenew('P', q * B.x)\n    P.set_vel(B, qd * B.x + q2d * B.y)\n    O.set_vel(N, 0)\n    assert P.v1pt_theory(O, N, B) == qd*B.x + q2d*B.y - 5*q*B.z\n", "def test_locatenew():\n    N = ReferenceFrame('N')\n    p1 = Point('p1')\n    p2 = p1.locatenew('p2', 10 * N.x)\n    assert p2.pos_from(p1) == 10 * N.x\n    assert p1.pos_from(p2) == -10 * N.x\n    raises(TypeError, lambda: p1.locatenew(1, 10 * N.x))\n    raises(TypeError, lambda: p1.locatenew('p3', 1))\n", "def test_point_partial_velocity():\n    u1, u2 = dynamicsymbols('u1 u2')\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    p = Point('p')\n    p.set_vel(N, u1 * N.x + u2 * A.y)\n    assert p.partial_velocity(N, u1) == N.x\n    assert p.partial_velocity(N, u1, u2) == (N.x, A.y)\n    raises(TypeError, lambda: p.partial_velocity(N, u1, 5))\n", "def test_point_v1pt_theory():\n    q, q2 = dynamicsymbols('q q2')\n    qd, q2d = dynamicsymbols('q q2', 1)\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    B.set_ang_vel(N, 5 * B.y)\n    O = Point('O')\n    P = O.locatenew('P', q * B.x)\n    P.set_vel(B, qd * B.x + q2d * B.y)\n    O.set_vel(N, 0)\n    assert P.v1pt_theory(O, N, B) == qd*B.x + q2d*B.y - 5*q*B.z\n", "def test_point_v1pt_theory():\n    q, q2, qd, q2d = dynamicsymbols('q q2 qd q2d')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    B.set_ang_vel(N, 5 * B.y)\n    O = Point('O')\n    P = O.locatenew('P', q * B.x)\n    P.set_vel(B, qd * B.x + q2d * B.y)\n    O.set_vel(N, 0)\n    assert P.v1pt_theory(O, N, B) == qd*B.x + q2d*B.y - 5*q*B.z\n"], "sample_28": ["def test_each_context_with_nav_sidebar_disabled(self):\n    request = self.request_factory.get(reverse('test_adminsite:index'))\n    request.user = self.u1\n    site.enable_nav_sidebar = False\n    ctx = site.each_context(request)\n    self.assertFalse(ctx['is_nav_sidebar_enabled'])\n", "def test_each_context_site_title(self):\n    self.assertEqual(self.ctx['site_title'], 'Django site admin')\n\n    # override the site title\n    site.site_title = 'My Site Admin'\n    request = self.request_factory.get(reverse('test_adminsite:index'))\n    request.user = self.u1\n    ctx = site.each_context(request)\n    self.assertEqual(ctx['site_title'], 'My Site Admin')\n", "def test_each_context_has_permission(self):\n    request = self.request_factory.get(reverse('test_adminsite:index'))\n    request.user = self.u1\n    ctx = site.each_context(request)\n    self.assertTrue(ctx['has_permission'])\n    request.user = User.objects.create_user(username='user', password='secret')\n    ctx = site.each_context(request)\n    self.assertFalse(ctx['has_permission'])\n", "def test_each_context_site_title(self):\n    self.assertEqual(self.ctx['site_title'], admin.site.site_title)\n", "def test_each_context_with_no_permission(self):\n    request = self.request_factory.get(reverse('test_adminsite:index'))\n    request.user = User.objects.create_user(username='no-perm', password='secret')\n    ctx = site.each_context(request)\n    self.assertFalse(ctx['has_permission'])\n    self.assertEqual(ctx['available_apps'], [])\n"], "sample_20": ["    def test_fields_cache_descriptor(self):\n        class Model(models.Model):\n            field = models.IntegerField()\n\n        instance = Model(field=1)\n        self.assertEqual(instance._state.fields_cache, {})\n        instance._state.fields_cache['field'] = 2\n        self.assertEqual(instance._state.fields_cache, {'field': 2})\n", "    def test_field_name_clashes_with_property(self):\n        class Model(models.Model):\n            field = models.CharField(max_length=10)\n\n            @property\n                return 'value'\n\n        errors = Model.check()\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, 'models.E025')\n", "    def test_field_name_clashes(self):\n        class Model(models.Model):\n            field = models.CharField(max_length=10)\n            field2 = models.CharField(max_length=10, db_column='field')\n\n        errors = Model.check()\n        self.assertEqual(len(errors), 1)\n        error = errors[0]\n        self.assertIsInstance(error, Error)\n        self.assertEqual(error.id, 'models.E007')\n        self.assertEqual(error.msg, \"Field 'field2' has column name 'field' that is used by another field.\")\n        self.assertEqual(error.hint, \"Specify a 'db_column' for the field.\")\n        self.assertEqual(error.obj, Model)\n", "    def test_field_name_clashes_with_property(self):\n        class Model(models.Model):\n            field = models.CharField(max_length=10)\n\n            @property\n                return 'clash'\n\n        errors = Model.check()\n        self.assertEqual(errors, [\n            Error(\n                \"The property 'field' clashes with a related field accessor.\",\n                obj=Model,\n                id='models.E025',\n            ),\n        ])\n", "    def test_unique_for_date_year_month(self):\n        class Model(models.Model):\n            title = models.CharField(max_length=255)\n            date_field = models.DateField(unique_for_date='title')\n            year_field = models.DateField(unique_for_year='title')\n            month_field = models.DateField(unique_for_month='title')\n\n        errors = Model.check()\n        self.assertEqual(len(errors), 3)\n        error_messages = [str(e) in ['\"unique_for_date\" must be either True or False.',\n                                    '\"unique_for_year\" must be either True or False.',\n                                    '\"unique_for_month\" must be either True or False.'] for e in errors]\n        self.assertTrue(all(error_messages))\n"], "sample_98": ["def test_check_is_fitted():\n    class Estimator:\n            self.fitted_ = False\n\n            self.fitted_ = True\n            return self\n\n    estimator = Estimator()\n    assert_raises(NotFittedError, check_is_fitted, estimator, \"fitted_\")\n\n    estimator.fit(None)\n    check_is_fitted(estimator, \"fitted_\")\n", "def test_check_is_fitted():\n    class Estimator:\n            self.estimator_ = None\n\n            self.estimator_ = 1\n\n    estimator = Estimator()\n    assert_raises(NotFittedError, check_is_fitted, estimator, \"estimator_\")\n    estimator.fit()\n    check_is_fitted(estimator, \"estimator_\")\n\n    # test multiple attributes\n    class MultiEstimator:\n            self.estimator1_ = None\n            self.estimator2_ = None\n\n            self.estimator1_ = 1\n            self.estimator2_ = 1\n\n    multi_estimator = MultiEstimator()\n    assert_raises(NotFittedError, check_is_fitted, multi_estimator,\n                  [\"estimator1_\", \"estimator2_\"])\n    multi_estimator.fit()\n    check_is_fitted(multi_estimator, [\"estimator1_\", \"estimator2_\"])\n\n    # test all_or_any parameter\n    class EitherEstimator:\n            self.estimator1_ = None\n            self.estimator2_ = None\n\n            self.estimator1_ = 1\n\n    either_estimator = EitherEstimator()\n    assert_raises(NotFittedError, check_is_fitted, either_estimator,\n                  [\"estimator1_\", \"estimator2_\"], all_or_any=all)\n    check_is_fitted(either_estimator, [\"estimator1_\", \"estimator2_\"],\n                    all_or_any=any)\n\n    either_estimator.fit()\n    check_is_fitted(either_estimator, [\"estimator1_\", \"estimator2_\"],\n                    all_or_any=any)\n", "def test_check_is_fitted():\n    class Estimator:\n            self.coef_ = None\n\n            self.coef_ = np.array([1.])\n\n    estimator = Estimator()\n    assert_raises(NotFittedError, check_is_fitted, estimator, \"coef_\")\n\n    estimator.fit(None)\n    check_is_fitted(estimator, \"coef_\")\n\n    # multiple attributes\n    assert_raises(NotFittedError, check_is_fitted, estimator, [\"coef_\", \"estimator_\"])\n\n    # attribute not exist\n    assert_raises(NotFittedError, check_is_fitted, estimator, \"estimator_\")\n\n    # custom message\n    msg = \"Estimator, %(name)s, must be fitted before sparsifying\"\n    assert_raise_message(NotFittedError, msg % {\"name\": \"Estimator\"},\n                         check_is_fitted, estimator, \"estimator_\", msg=msg)\n\n    # all or any\n    check_is_fitted(estimator, [\"coef_\", \"estimator_\"], all_or_any=any)\n", "def test_check_is_fitted():\n    class Estimator:\n            self.fitted_ = True\n\n    estimator = Estimator()\n    assert_raises(NotFittedError, check_is_fitted, estimator, \"fitted_\")\n\n    estimator.fit(None)\n    check_is_fitted(estimator, \"fitted_\")\n\n    # checking multiple attributes\n    class MultiEstimator:\n            self.fitted_ = True\n            self.fitted_second_ = True\n\n    multi_est = MultiEstimator()\n\n    assert_raises(NotFittedError, check_is_fitted, multi_est, [\"fitted_\", \"fitted_second_\"])\n\n    multi_est.fit(None)\n    check_is_fitted(multi_est, [\"fitted_\", \"fitted_second_\"])\n\n    # using all_or_any parameter\n    class HalfEstimator:\n            self.fitted_ = True\n\n    half_est = HalfEstimator()\n    half_est.fit(None)\n\n    assert_raises(NotFittedError, check_is_fitted, half_est, [\"fitted_\", \"fitted_second_\"])\n    check_is_fitted(half_est, [\"fitted_\", \"fitted_second_\"], all_or_any=any)\n", "def test_check_is_fitted():\n    class Estimator:\n            self.coef_ = np.array([1.])\n    \n    estimator = Estimator()\n    assert_raises_regex(NotFittedError, \"Estimator\", check_is_fitted, estimator, 'coef_')\n\n    estimator.fit(None)\n    check_is_fitted(estimator, 'coef_')\n    assert_true(hasattr(estimator, 'coef_'))\n\n    # test with multiple attributes\n    class MultiAttrEstimator:\n            self.coef_ = np.array([1.])\n            self.intercept_ = np.array([0.])\n\n    estimator = MultiAttrEstimator()\n    assert_raises_regex(NotFittedError, \"MultiAttrEstimator\", check_is_fitted, estimator, ['coef_', 'intercept_'])\n\n    estimator.fit(None)\n    check_is_fitted(estimator, ['coef_', 'intercept_'])\n    assert_true(hasattr(estimator, 'coef_'))\n    assert_true(hasattr(estimator, 'intercept_'))\n\n    # test with all_or_any parameter\n    estimator = MultiAttrEstimator()\n    estimator.coef_ = np.array([1.])\n    check_is_fitted(estimator, ['coef_', 'intercept_'], all_or_any=any)\n\n    assert_raises_regex(NotFittedError, \"MultiAttrEstimator\", check_is_fitted, estimator, ['coef_', 'intercept_'], all_or_any=all)\n\n    # test custom message\n    msg = \"Custom error message\"\n    assert_raises_regex(NotFittedError, msg, check_is_fitted, estimator, 'intercept_', msg=msg)\n"], "sample_45": ["def test_method_decorator(self):\n            return func(*args, **kwargs)\n        return wrapper\n\n    class MyClass:\n        @method_decorator(my_decorator)\n            return \"hello\"\n\n    obj = MyClass()\n    self.assertEqual(obj.my_method(), \"hello\")\n\n    # Test method decorator with a name.\n    class MyClass:\n            return \"hello\"\n\n    MyClass = method_decorator(my_decorator, name='my_method')(MyClass)\n    obj = MyClass()\n    self.assertEqual(obj.my_method(), \"hello\")\n", "def test_method_decorator(self):\n            return func(*args, **kwargs)\n        return wrapper\n\n    class MyClass:\n        @method_decorator(my_decorator)\n            return \"Hello, World!\"\n\n    obj = MyClass()\n    self.assertEqual(obj.my_method(), \"Hello, World!\")\n\n    # Test that method_decorator works with methods that have arguments.\n    class MyClass2:\n        @method_decorator(my_decorator)\n            return arg1 + arg2\n\n    obj2 = MyClass2()\n    self.assertEqual(obj2.my_method(1, 2), 3)\n\n    # Test that method_decorator preserves the original function's docstring and name.\n            return func(*args, **kwargs)\n        return wrapper\n\n    class MyClass3:\n        @method_decorator(my_decorator2)\n            \"\"\"This is a docstring.\"\"\"\n            return \"Hello, World!\"\n\n    obj3 = MyClass3()\n    self.assertEqual(obj3.my_method.__name__, \"my_method\")\n    self.assertEqual(obj3.my_method.__doc__, \"This is a docstring.\")\n", "def test_method_decorator(self):\n            return func(*args, **kwargs)\n        return wrapper\n\n    class MyClass:\n        @method_decorator(my_decorator)\n            return \"Hello, World!\"\n\n    obj = MyClass()\n    self.assertEqual(obj.my_method(), \"Hello, World!\")\n\n    # Test that the decorator is applied correctly when using the name argument.\n    class MyClass2:\n            return \"Hello, World!\"\n\n    my_decorator_with_name = method_decorator(my_decorator, name='my_method')\n    MyClass2 = my_decorator_with_name(MyClass2)\n    obj2 = MyClass2()\n    self.assertEqual(obj2.my_method(), \"Hello, World!\")\n", "def test_method_decorator(self):\n    class MyClass:\n            return \"hello\"\n\n    decorator = lambda x: x\n    decorated_class = method_decorator(decorator, name='my_method')(MyClass)\n    self.assertEqual(decorated_class().my_method(), \"hello\")\n\n    # Test that the decorator was applied correctly\n            return \"goodbye\"\n        return wrapper\n\n    decorated_class = method_decorator(my_decorator, name='my_method')(MyClass)\n    self.assertEqual(decorated_class().my_method(), \"goodbye\")\n", "def test_method_decorator(self):\n    class TestClass:\n        @method_decorator(login_required, name='dispatch')\n            return HttpResponse('Hello')\n\n    instance = TestClass()\n    self.assertTrue(hasattr(instance.dispatch, 'login_required'))\n    self.assertEqual(instance.dispatch.__name__, 'dispatch')\n    self.assertEqual(instance.dispatch.__doc__, None)\n"], "sample_11": ["    def test_serialize_float(self):\n        serializer = FloatSerializer(1.5)\n        self.assertEqual(serializer.serialize(), ('1.5', set()))\n", "    def test_serializer_factory_float(self):\n        value = 1.23\n        serializer = serializer_factory(value)\n        self.assertIsInstance(serializer, FloatSerializer)\n        string, imports = serializer.serialize()\n        self.assertEqual(string, repr(value))\n        self.assertEqual(imports, set())\n", "    def test_serializer_factory_float(self):\n        value = float('inf')\n        serializer = serializer_factory(value)\n        self.assertIsInstance(serializer, FloatSerializer)\n        string, imports = serializer.serialize()\n        self.assertEqual(string, 'float(\"inf\")')\n        self.assertEqual(imports, set())\n", "    def test_serialize_float(self):\n        serializer = FloatSerializer(1.5)\n        self.assertEqual(serializer.serialize(), ('1.5', set()))\n\n        serializer = FloatSerializer(float('inf'))\n        self.assertEqual(serializer.serialize(), (\"float('inf')\", set()))\n\n        serializer = FloatSerializer(float('-inf'))\n        self.assertEqual(serializer.serialize(), (\"float('-inf')\", set()))\n\n        serializer = FloatSerializer(float('nan'))\n        self.assertEqual(serializer.serialize(), (\"float('nan')\", set()))\n", "    def test_serialize_float(self):\n        value = float('inf')\n        serializer = BaseSerializer(value)\n        result, imports = serializer_factory(value).serialize()\n        self.assertEqual(result, 'float(\"inf\")')\n        self.assertEqual(imports, set())\n"], "sample_107": ["def test_logistic_regression_multinomial():\n    # Test multinomial logistic regression on a given dataset.\n    # 'multinomial' is the default for multi_class so just check 'auto'\n    X, y = make_classification(n_samples=50, n_features=20,\n                               n_informative=10, n_classes=3, random_state=0)\n\n    clf = LogisticRegression(multi_class='auto', solver='lbfgs')\n    check_predictions(clf, X, y)\n\n    clf = LogisticRegression(multi_class='auto', solver='newton-cg')\n    check_predictions(clf, X, y)\n", "def test_logistic_regression_saga_sparse():\n    # Test that saga solver works with sparse data\n    rng = np.random.RandomState(0)\n    X, y = make_classification(n_samples=50, n_features=20, random_state=rng)\n    X_sparse = sp.csr_matrix(X)\n\n    lr_dense = LogisticRegression(solver='saga', max_iter=1000)\n    lr_sparse = LogisticRegression(solver='saga', max_iter=1000)\n\n    lr_dense.fit(X, y)\n    lr_sparse.fit(X_sparse, y)\n\n    assert_array_almost_equal(lr_dense.coef_, lr_sparse.coef_)\n    assert_array_almost_equal(lr_dense.intercept_, lr_sparse.intercept_)\n", "def test_logistic_regression_saga_sparse():\n    # Make sure that saga works with sparse matrices\n    X, y = make_classification(n_samples=20, n_features=10, random_state=0)\n    X_sparse = sp.csr_matrix(X)\n\n    # Set max_iter high to ensure convergence for all solvers\n    lr_sparse = LogisticRegression(solver='saga', max_iter=1000, random_state=42)\n    lr_dense = LogisticRegression(solver='liblinear', random_state=42)\n\n    assert_array_almost_equal(lr_sparse.fit(X_sparse, y).coef_,\n                              lr_dense.fit(X, y).coef_)\n", "def test_logistic_regression_solvers():\n    \"\"\"Test logistic regression solvers on multi-class problems.\"\"\"\n    X, y = make_classification(n_samples=200, n_features=20,\n                               n_informative=10, n_redundant=0,\n                               n_classes=3, random_state=42)\n\n    for solver in ('newton-cg', 'lbfgs', 'sag', 'saga'):\n        check_predictions(LogisticRegression(solver=solver), X, y)\n", "def test_logistic_regression_solvers_multiclass():\n    # Test that the solvers give similar results for a multiclass problem\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=10,\n                               n_redundant=0, random_state=0, n_classes=3)\n\n    # Solvers can give slightly different results, so we use a tolerance here.\n    tol = 1e-2\n\n    # LBFGS is our reference solver here.\n    clf_ref = LogisticRegression(solver='lbfgs', multi_class='multinomial',\n                                 max_iter=1000)\n    clf_ref.fit(X, y)\n    coef_ref = clf_ref.coef_\n    intercept_ref = clf_ref.intercept_\n\n    for solver in ['newton-cg', 'sag', 'saga']:\n        clf = LogisticRegression(solver=solver, multi_class='multinomial',\n                                 max_iter=1000)\n        clf.fit(X, y)\n        assert_allclose(clf.coef_, coef_ref, atol=tol, rtol=tol)\n        assert_allclose(clf.intercept_, intercept_ref, atol=tol, rtol=tol)\n"], "sample_49": ["def test_reset_loaders_called_on_template_change(self, mock_reset_loaders):\n    template_dir = EXTRA_TEMPLATES_DIR\n    file_path = template_dir / 'template.txt'\n    with mock.patch('django.utils._os.to_path', return_value=str(template_dir)):\n        autoreload.template_changed(None, file_path)\n    mock_reset_loaders.assert_called_once()\n", "    def test_template_changed_not_python_file(self, mock_reset_loaders):\n        template_path = EXTRA_TEMPLATES_DIR / 'template.html'\n        with mock.patch('pathlib.Path.suffix', '.html'):\n            with mock.patch('pathlib.Path.parents', [EXTRA_TEMPLATES_DIR]):\n                autoreload.template_changed(None, template_path)\n                mock_reset_loaders.assert_called_once()\n", "    def test_reset_loaders_called_for_template_change(self, mock_get_template_directories):\n        mock_get_template_directories.return_value = [EXTRA_TEMPLATES_DIR]\n        file_path = EXTRA_TEMPLATES_DIR / 'test.txt'\n        with mock.patch('django.template.autoreload.reset_loaders') as mock_reset_loaders:\n            autoreload.template_changed(None, file_path)\n            self.assertTrue(mock_reset_loaders.called)\n", "    def test_get_template_directories(self):\n        template_dirs = autoreload.get_template_directories()\n        self.assertIn(EXTRA_TEMPLATES_DIR, template_dirs)\n        for dir in template_dirs:\n            self.assertIsInstance(dir, Path)\n", "    def test_template_changed_does_not_reset_loaders_for_python_files(self, mock_reset):\n        file_path = Path(__file__).parent / 'example.py'\n        autoreload.template_changed(None, file_path)\n        mock_reset.assert_not_called()\n"], "sample_5": ["def test_protect(self):\n    new_user = User.objects.create(username='newuser')\n    self.assertRaises(\n        ProtectedError,\n        Collector(using='default').collect, [new_user],\n        source=A, nullable=False, collect_related=True,\n    )\n", "def test_protect(self):\n    new_m = M.objects.create()\n    new_r = R.objects.create(m=new_m)\n    with self.assertRaises(ProtectedError) as cm:\n        new_m.delete()\n    self.assertEqual(cm.exception.protected_objects, [new_r])\n", "def test_sorting_of_models(self):\n    # Create objects\n    a = create_a()\n    r = R.objects.create(a=a)\n    m = M.objects.create(r=r)\n\n    # Collect objects for deletion\n    collector = Collector(using='default')\n    collector.collect([a])\n\n    # Check the order of models in the collector\n    self.assertEqual(list(collector.data.keys()), [A, R, M])\n", "def test_can_fast_delete(self):\n    # We can fast delete if there are no cascades, no parents and no signal listeners.\n    a = create_a()\n    self.assertTrue(Collector('default').can_fast_delete(a))\n\n    # But we cannot fast delete if there is a signal listener.\n        pass\n\n    models.signals.pre_delete.connect(listener, sender=A)\n    try:\n        self.assertFalse(Collector('default').can_fast_delete(a))\n    finally:\n        models.signals.pre_delete.disconnect(listener, sender=A)\n\n    # We also cannot fast delete if there are cascades.\n    child = Child.objects.create(parent=a)\n    self.assertFalse(Collector('default').can_fast_delete(a))\n\n    # We also cannot fast delete if there are parents.\n    parent = Parent.objects.create(child=child)\n    self.assertFalse(Collector('default').can_fast_delete(child))\n", "def test_protect(self):\n    collector = Collector(using='default')\n    a = create_a()\n    with self.assertRaises(ProtectedError) as cm:\n        PROTECT(collector, A.r, [a], 'default')\n    self.assertEqual(cm.exception.protected_objects, [a])\n"], "sample_158": ["def test_get_dimensional_expr():\n    x = symbols('x')\n    expr = 3*x**2 + 2*x - 4\n    assert SI.get_dimensional_expr(expr) == 1\n\n    expr = sin(x)\n    assert SI.get_dimensional_expr(expr) == 1\n\n    expr = exp(x)\n    assert SI.get_dimensional_expr(expr) == 1\n\n    expr = integrate(x**2, x)\n    assert SI.get_dimensional_expr(expr) == length**3\n\n    expr = diff(x**2, x)\n    assert SI.get_dimensional_expr(expr) == length\n\n    q = Quantity('q', length)\n    expr = q * x\n    assert SI.get_dimensional_expr(expr) == length**2\n", "def test_UnitSystem_get_dimensional_expr():\n    us = UnitSystem(base_units=(meter, second), name=\"SI\")\n    assert us.get_dimensional_expr(meter) == length.name\n    assert us.get_dimensional_expr(second) == time.name\n    assert us.get_dimensional_expr(meter/second) == length.name / time.name\n    assert us.get_dimensional_expr(meter**2) == length.name ** 2\n    assert us.get_dimensional_expr(sin(meter)) == sin(length.name)\n    assert us.get_dimensional_expr(diff(meter, second)) == length.name / time.name\n", "def test_UnitSystem_get_dimensional_expr():\n    u = UnitSystem((meter, second), name=\"test\")\n    q1 = Quantity(\"q1\", length)\n    q2 = Quantity(\"q2\", time)\n    assert u.get_dimensional_expr(q1) == length.name\n    assert u.get_dimensional_expr(q2) == time.name\n    assert u.get_dimensional_expr(q1 * q2) == length.name * time.name\n    assert u.get_dimensional_expr(q1 / q2) == length.name / time.name\n    assert u.get_dimensional_expr(q1 ** 2) == length.name ** 2\n    assert u.get_dimensional_expr(q1 + q2) == length.name\n", "def test_get_dimensional_expr():\n    # Test with Mul\n    expr = kilogram * meter / second\n    assert SI.get_dimensional_expr(expr) == mass * length / time\n\n    # Test with Pow\n    expr = kilogram ** 2\n    assert SI.get_dimensional_expr(expr) == mass ** 2\n\n    # Test with Add\n    expr = kilogram + gram\n    assert SI.get_dimensional_expr(expr) == mass\n\n    # Test with Derivative\n    x = symbols('x')\n    expr = diff(kilogram * x, x)\n    assert SI.get_dimensional_expr(expr) == mass\n\n    # Test with Function\n    expr = sin(kilogram)\n    assert SI.get_dimensional_expr(expr) == sin(mass)\n\n    # Test with Quantity\n    expr = kilogram\n    assert SI.get_dimensional_expr(expr) == mass\n", "def test_UnitSystem_get_dimensional_expr():\n    us = SI\n    q = Quantity(\"test\", length)\n    assert us.get_dimensional_expr(q) == length.name\n\n    expr = q**2\n    assert us.get_dimensional_expr(expr) == length.name**2\n\n    expr = q + q\n    assert us.get_dimensional_expr(expr) == length.name\n\n    expr = sin(q)\n    assert us.get_dimensional_expr(expr) == sin(length.name)\n\n    expr = diff(q, symbols(\"x\"))\n    assert us.get_dimensional_expr(expr) == length.name / Symbol(\"x\")\n"], "sample_55": ["def test_base_command_arguments(self):\n    class Command(BaseCommand):\n            pass\n\n    parser = Command().create_parser(\"manage.py\", \"command\")\n    options = parser.parse_args([\"--help\"])\n    self.assertTrue(options.help)\n\n    with captured_stderr():\n        options = parser.parse_args([\"-v\", \"1\"])\n        self.assertEqual(options.verbosity, 1)\n        options = parser.parse_args([\"--verbosity\", \"2\"])\n        self.assertEqual(options.verbosity, 2)\n        options = parser.parse_args([\"-v\", \"3\"])\n        self.assertEqual(options.verbosity, 3)\n\n        with self.assertRaises(CommandError):\n            parser.parse_args([\"-v\", \"4\"])\n\n    with captured_stderr():\n        options = parser.parse_args([\"--traceback\"])\n        self.assertTrue(options.traceback)\n", "    def test_base_command_arguments(self):\n        class Command(BaseCommand):\n                self.stdout.write(str(options))\n\n        out = StringIO()\n        command = Command(stdout=out)\n        parser = command.create_parser(\"manage.py\", \"command\")\n        opts = parser.parse_args([\"--verbosity\", \"2\", \"--no-color\"])\n        command.execute(**vars(opts))\n        self.assertEqual(out.getvalue().strip(), \"{'verbosity': 2, 'no_color': True}\")\n", "def test_base_command_style(self):\n    class TestCommand(BaseCommand):\n            self.stdout.write(self.style.SUCCESS(\"Success message\"))\n            self.stderr.write(self.style.ERROR(\"Error message\"))\n\n    command = TestCommand()\n    with captured_stderr() as stderr:\n        command.handle()\n    self.assertIn(\"\\033[92mSuccess message\\033[0m\", stderr.getvalue())\n    self.assertIn(\"\\033[91mError message\\033[0m\", stderr.getvalue())\n", "def test_base_command_arguments(self):\n    class TestCommand(BaseCommand):\n            pass\n\n    command = TestCommand()\n    parser = command.create_parser(\"test\", \"test\")\n    options = parser.parse_args([\"--help\"])\n\n    self.assertEqual(options.verbosity, 1)\n    self.assertEqual(options.settings, None)\n    self.assertEqual(options.pythonpath, None)\n    self.assertFalse(options.traceback)\n\n    with captured_stderr():\n        options = parser.parse_args([\"--version\"])\n\n    self.assertEqual(options.verbosity, 1)\n    self.assertEqual(options.settings, None)\n    self.assertEqual(options.pythonpath, None)\n    self.assertFalse(options.traceback)\n\n    options = parser.parse_args([\"-v\", \"2\"])\n    self.assertEqual(options.verbosity, 2)\n    self.assertEqual(options.settings, None)\n    self.assertEqual(options.pythonpath, None)\n    self.assertFalse(options.traceback)\n\n    options = parser.parse_args([\"--settings\", \"test_settings\"])\n    self.assertEqual(options.verbosity, 1)\n    self.assertEqual(options.settings, \"test_settings\")\n    self.assertEqual(options.pythonpath, None)\n    self.assertFalse(options.traceback)\n\n    options = parser.parse_args([\"--pythonpath\", \"/path/to/python\"])\n    self.assertEqual(options.verbosity, 1)\n    self.assertEqual(options.settings, None)\n    self.assertEqual(options.pythonpath, \"/path/to/python\")\n    self.assertFalse(options.traceback)\n\n    options = parser.parse_args([\"--traceback\"])\n    self.assertEqual(options.verbosity, 1)\n    self.assertEqual(options.settings, None)\n    self.assertEqual(options.pythonpath, None)\n    self.assertTrue(options.traceback)\n", "def test_base_command_style(self):\n    class TestCommand(BaseCommand):\n            self.stdout.write(self.style.SUCCESS(\"Test success message\"))\n            self.stderr.write(self.style.ERROR(\"Test error message\"))\n\n    cmd = TestCommand()\n    with captured_stderr() as stderr:\n        cmd.handle()\n\n    self.assertIn(\"\\033[92mTest success message\\033[0m\", stderr.getvalue())\n    self.assertIn(\"\\033[91mTest error message\\033[0m\", stderr.getvalue())\n"], "sample_95": ["def test_skip_mark_hook_call(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        textwrap.dedent(\n            \"\"\"\\\n            import pytest\n\n                pytest.skip(\"called from hook\")\n\n                pass\n            \"\"\"\n        )\n    )\n    item = pytester.getitem(\"test_foo\")\n    assert not evaluate_skip_marks(item, \"line\")\n    pytester.runpytest().assert_outcomes(skipped=1)\n", "def test_skip_reason_constructed_from_mark_and_module_msg(\n    pytester: Pytester, monkeypatch", "def test_multiple_parametrize_with_ids(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        textwrap.dedent(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"x\", [1, 2], ids=[\"one\", \"two\"])\n            @pytest.mark.parametrize(\"y\", [10, 20], ids=[\"ten\", \"twenty\"])\n                pass\n            \"\"\"\n        )\n    )\n    result = pytester.runpytest(\"--collect-only\")\n    result.stdout.fnmatch_lines([\"*test_foo[one-ten]*\", \"*test_foo[one-twenty]*\"])\n    result.stdout.fnmatch_lines([\"*test_foo[two-ten]*\", \"*test_foo[two-twenty]*\"])\n", "def test_skip_marks_with_parametrize_and_fixtures(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        textwrap.dedent(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n                return 1\n\n            @pytest.mark.parametrize(\"arg2\", [\"a\", \"b\"])\n            @pytest.mark.skip(reason=\"Skipped\")\n                assert False\n    \"\"\"\n        )\n    )\n    item = pytester.getitem(\"test_function\", nodeid=\"test_function[a]\")\n    assert item.keywords == {\"skip\": True}\n    skip_info = evaluate_skip_marks(item)\n    assert skip_info is not None\n    assert skip_info.reason == \"Skipped\"\n", "def test_parametrize_with_mark_xfail_run_test_setup(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"i\", range(5))\n        @pytest.mark.xfail\n            assert i == 0\n        \"\"\"\n    )\n    items, _ = pytester.inline_genitems()\n    assert len(items) == 5\n    for item in items:\n        pytest_runtest_setup(item)\n        evaluate_skip_marks(item, \"setup\")\n        excinfo = runtestprotocol(item, logreport=True)\n        assert excinfo is not None\n        assert excinfo.passed == (item.callspec.indices[\"i\"] == 0)\n        evaluate_xfail_marks(item, excinfo)\n"], "sample_106": ["def test_nca_init():\n    # Test the different initialization options for the transformation\n\n    n_samples, n_features = 10, 5\n    X = rng.rand(n_samples, n_features)\n    y = rng.randint(0, 2, size=n_samples)\n\n    # Test 'auto'\n    nca = NeighborhoodComponentsAnalysis(init='auto', random_state=0)\n    nca.fit(X, y)\n    assert_equal(nca.components_.shape[1], n_features)\n\n    # Test 'pca'\n    nca = NeighborhoodComponentsAnalysis(init='pca', random_state=0)\n    nca.fit(X, y)\n    assert_equal(nca.components_.shape[1], n_features)\n\n    # Test 'lda'\n    nca = NeighborhoodComponentsAnalysis(init='lda', random_state=0)\n    nca.fit(X, y)\n    assert_equal(nca.components_.shape[1], n_features)\n\n    # Test 'identity'\n    nca = NeighborhoodComponentsAnalysis(init='identity', random_state=0)\n    nca.fit(X, y)\n    assert_array_equal(nca.components_, np.eye(n_features))\n\n    # Test 'random'\n    nca = NeighborhoodComponentsAnalysis(init='random', random_state=0)\n    nca.fit(X, y)\n    assert_equal(nca.components_.shape[1], n_features)\n\n    # Test array-like init\n    init_custom = rng.rand(n_features, n_features)\n    nca = NeighborhoodComponentsAnalysis(init=init_custom, random_state=0)\n    nca.fit(X, y)\n    assert_array_almost_equal(nca.components_, init_custom)\n", "def test_nca_init():\n    # Test that the initialization of the transformation matrix is correct\n\n    # When n_components is not specified, it should be set to n_features\n    X, y = make_classification(n_samples=10, n_features=5)\n    nca = NeighborhoodComponentsAnalysis(init='identity')\n    nca.fit(X, y)\n    assert_array_equal(nca.components_.shape, (5, 5))\n\n    # When init is 'identity', the transformation matrix should be the identity\n    nca = NeighborhoodComponentsAnalysis(init='identity', n_components=3)\n    nca.fit(X, y)\n    assert_array_almost_equal(nca.components_, np.eye(3, 5))\n\n    # When init is 'random', the transformation matrix should be random\n    nca = NeighborhoodComponentsAnalysis(init='random', n_components=3,\n                                         random_state=0)\n    nca.fit(X, y)\n    assert nca.components_.shape == (3, 5)\n\n    # When init is a numpy array, it should be used as the transformation matrix\n    init = rng.rand(3, 5)\n    nca = NeighborhoodComponentsAnalysis(init=init)\n    nca.fit(X, y)\n    assert_array_equal(nca.components_, init)\n", "def test_nca_init():\n    # Test that the initialization of NCA leads to the correct initial\n    # transformation and that a ConvergenceWarning is raised if n_components\n    # is larger than the number of features\n    X, y = make_classification(n_samples=50, n_features=10, random_state=0)\n    nca = NeighborhoodComponentsAnalysis(init='random', random_state=0)\n\n    assert_raises(ConvergenceWarning, nca.fit, X, y)\n\n    nca = NeighborhoodComponentsAnalysis(n_components=5, init='pca',\n                                         random_state=0)\n    nca.fit(X, y)\n\n    pca = clone(nca._initialize(X, y, init='pca').T)\n    assert_array_almost_equal(nca.components_, pca.components_)\n", "def test_nca_init():\n    # Test that the initialization of NCA leads to the correct transformation\n    X, y = iris_data, iris_target\n\n    nca_pca = NeighborhoodComponentsAnalysis(init='pca', n_components=2)\n    nca_pca.fit(X, y)\n    assert_array_almost_equal(nca_pca.components_, PCA(n_components=2).fit(X).components_)\n\n    nca_lda = NeighborhoodComponentsAnalysis(init='lda', n_components=2)\n    nca_lda.fit(X, y)\n    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n    lda = LinearDiscriminantAnalysis(n_components=2)\n    lda.fit(X, y)\n    assert_array_almost_equal(nca_lda.components_, lda.scalings_.T[:2])\n\n    nca_identity = NeighborhoodComponentsAnalysis(init='identity')\n    nca_identity.fit(X, y)\n    assert_array_almost_equal(nca_identity.components_, np.eye(X.shape[1]))\n\n    nca_random = NeighborhoodComponentsAnalysis(init='random', random_state=0)\n    nca_random.fit(X, y)\n    assert_array_almost_equal(nca_random.components_, check_random_state(0).randn(X.shape[1], X.shape[1]))\n", "def test_nca_init():\n    # Test that the initialization of the transformation is correct\n    n_samples, n_features = 100, 5\n    X, y = make_classification(n_samples=n_samples, n_features=n_features,\n                               n_informative=3, n_redundant=0, random_state=0)\n    n_components = 3\n\n    # Test 'auto' init\n    nca = NeighborhoodComponentsAnalysis(n_components=n_components, init='auto',\n                                         random_state=0)\n    nca.fit(X, y)\n    assert_equal(nca.components_.shape, (n_components, n_features))\n\n    # Test 'pca' init\n    nca = NeighborhoodComponentsAnalysis(n_components=n_components, init='pca',\n                                         random_state=0)\n    nca.fit(X, y)\n    assert_equal(nca.components_.shape, (n_components, n_features))\n\n    # Test 'lda' init\n    nca = NeighborhoodComponentsAnalysis(n_components=n_components, init='lda')\n    nca.fit(X, y)\n    assert_equal(nca.components_.shape, (n_components, n_features))\n\n    # Test 'identity' init\n    nca = NeighborhoodComponentsAnalysis(n_components=n_components,\n                                         init='identity')\n    nca.fit(X, y)\n    assert_array_equal(nca.components_, np.eye(n_components, n_features))\n\n    # Test 'random' init\n    nca = NeighborhoodComponentsAnalysis(n_components=n_components, init='random',\n                                         random_state=0)\n    nca.fit(X, y)\n    assert_equal(nca.components_.shape, (n_components, n_features))\n\n    # Test init with a numpy array\n    init = rng.rand(n_components, n_features)\n    nca = NeighborhoodComponentsAnalysis(n_components=n_components, init=init)\n    nca.fit(X, y)\n    assert_array_equal(nca.components_, init)\n\n    # Test invalid init\n    assert_raises(ValueError, NeighborhoodComponentsAnalysis,\n                  n_components=n_components, init='invalid')\n"], "sample_90": ["def test_mark_evaluator_with_compiled_eval():\n    item = mock.Mock()\n    item.obj = mock.Mock(__globals__={\"foo\": \"bar\"})\n    item.config = mock.Mock()\n    evaluator = MarkEvaluator(item, \"my_mark\")\n\n    with mock.patch(\"_pytest._code.compile\") as compile_mock:\n        compiled_expr = compile_mock.return_value\n\n            evaluator.expr = expr\n            return evaluator._istrue()\n\n        evaluate(\"foo == 'bar'\")\n        compile_mock.assert_called_once_with(\"foo == 'bar'\", mode=\"eval\")\n        assert compiled_expr in [mock.call(evaluator._getglobals()), mock.call().__getitem__(0)]\n", "def test_MarkEvaluator_getglobals(item):\n    \"\"\"Test that _getglobals() returns the expected dictionary.\"\"\"\n    evaluator = MarkEvaluator(item, \"mark_name\")\n    result = evaluator._getglobals()\n    assert \"os\" in result\n    assert \"sys\" in result\n    assert \"platform\" in result\n    assert \"config\" in result\n    if hasattr(item, \"obj\"):\n        assert all(key in result for key in item.obj.__globals__)\n", "    def test_mark_evaluator_with_condition(self):\n        item = mock.Mock(spec=Node)\n        item.config = mock.Mock(spec=Collector)\n        item.obj = mock.Mock()\n        item.obj.__globals__ = {}\n        mark_name = \"my_mark\"\n        mark = Mark(mark_name, args=(\"foo == 'bar'\",), kwargs={\"reason\": \"some reason\"})\n        item.iter_markers.return_value = [mark]\n\n        evaluator = MarkEvaluator(item, mark_name)\n\n        assert evaluator.istrue() is False\n        assert evaluator.getexplanation() == \"condition: foo == 'bar'\"\n        assert evaluator.wasvalid() is True\n\n        item.obj.__globals__[\"foo\"] = \"bar\"\n        assert evaluator.istrue() is True\n        assert evaluator.getexplanation() == \"some reason\"\n        assert evaluator.wasvalid() is True\n", "def test_MarkEvaluator_istrue_condition_is_string(self, monkeypatch):\n    item = mock.Mock()\n    item.obj = mock.Mock(__globals__={})\n    mark = Mark(\"test_mark\", (\"condition_str\",), {\"reason\": \"some_reason\"})\n    item.iter_markers.return_value = [mark]\n\n        assert expr == \"condition_str\"\n        return True\n\n    monkeypatch.setattr(\"pytest.mark.compiled_eval\", compiled_eval_side_effect)\n\n    evaluator = MarkEvaluator(item, \"test_mark\")\n    assert evaluator.istrue()\n    assert evaluator.getexplanation() == \"some_reason\"\n", "    def test_mark_evaluator_compiled_eval(self):\n        item = mock.Mock(spec=Node)\n        item.obj = mock.Mock()\n        item.obj.__globals__ = {\"foo\": \"bar\"}\n        mark_name = \"my_mark\"\n        mark = Mark(mark_name, (\"condition\",), {\"reason\": \"some reason\"})\n        item.iter_markers.return_value = iter([mark])\n\n        evaluator = MarkEvaluator(item, mark_name)\n        assert evaluator.istrue()\n        assert evaluator.getexplanation() == \"some reason\"\n\n        # Test with syntax error in condition\n        mark.kwargs[\"condition\"] = \" invalid syntax\"\n        assert not evaluator.istrue()\n\n        # Test with boolean condition\n        mark.kwargs[\"condition\"] = True\n        assert evaluator.istrue()\n\n        # Test with missing reason\n        del mark.kwargs[\"reason\"]\n        mark.args = (True,)\n        with pytest.raises(AssertionError):\n            evaluator.istrue()\n"], "sample_74": ["def test_colorbar_orientation(fig_test, fig_ref):\n    x = np.linspace(0, 10, 100)\n    y = np.linspace(0, 10, 100)\n    X, Y = np.meshgrid(x, y)\n    Z = np.sin(X) + np.cos(Y)\n\n    fig_test.add_subplot(121).pcolormesh(Z, cmap=\"viridis\")\n    cbar = fig_test.colorbar(orientation=\"horizontal\")\n\n    fig_ref.add_subplot(121).pcolormesh(Z, cmap=\"viridis\")\n    cbar = fig_ref.colorbar(orientation=\"horizontal\", location=\"bottom\")\n\n    # Assert they are equivalent.\n    assert cbar.orientation == \"horizontal\"\n    assert cbar.location == \"bottom\"\n", "def test_colorbar_extension_length():\n    fig_uniform = _colorbar_extension_length('uniform')\n    fig_proportional = _colorbar_extension_length('proportional')\n    return [fig_uniform, fig_proportional]\n", "def test_colorbar_extension_length():\n    fig1 = _colorbar_extension_length('uniform')\n    fig2 = _colorbar_extension_length('proportional')\n    return fig1, fig2\n", "def test_colorbar_with_negative_alpha():\n    \"\"\"\n    Test that creating a colorbar with negative alpha raises an error.\n    \"\"\"\n    cmap = mpl.colormaps[\"RdBu\"]\n    norm = Normalize(vmin=0, vmax=1)\n    cax = plt.axes()\n    with pytest.raises(ValueError):\n        Colorbar(cax, cmap=cmap, norm=norm, alpha=-0.5)\n", "def test_colorbar_removed_from_figure():\n    # Create a figure and a colorbar\n    fig, ax = plt.subplots()\n    cax = fig.add_axes([0.1, 0.1, 0.8, 0.05])\n    cb = Colorbar(cax, cmap=mpl.colormaps['RdBu'])\n    \n    # Remove the colorbar from the figure\n    cb.remove()\n    \n    # Check that the colorbar is no longer in the figure\n    assert cb.ax not in fig.axes\n"], "sample_85": ["def test_get_option_ini(tmpdir, pytestconfig):\n    pytestconfig.cache.set(\"log_format\", \"ini_value\")\n    with pytest.raises(pytest.UsageError):\n        get_option_ini(pytestconfig, \"log_format\", \"non_existent_option\")\n\n    assert get_option_ini(pytestconfig, \"log_format\") == \"ini_value\"\n\n    pytestconfig.addoption(\"--custom-log-format\", dest=\"log_format\")\n    pytestconfig.option.log_format = \"command_line_value\"\n    assert get_option_ini(pytestconfig, \"log_format\") == \"command_line_value\"\n", "def test_get_option_ini(tmpdir, pytestconfig):\n    config = pytestconfig\n    tmpdir.join(\"pytest.ini\").write(\"[pytest]\\nlog_format = %%(levelname)s\")\n    assert get_option_ini(config, \"log_format\") == \"%(levelname)s\"\n    assert get_option_ini(config, \"log_date_format\") is None\n", "def test_get_option_ini(config):\n    \"\"\"Test that get_option_ini returns the correct value\"\"\"\n    config.option.log_print = None\n    config.ini_values[\"log_print\"] = \"True\"\n    assert get_option_ini(config, \"log_print\") == \"True\"\n\n    config.option.log_print = \"False\"\n    assert get_option_ini(config, \"log_print\") == \"False\"\n", "def test_get_option_ini(tmpdir, monkeypatch):\n    pytest.ini = tmpdir.join(\"pytest.ini\")\n    with open(str(pytest.ini), \"w\") as f:\n        f.write(\"[pytest]\\nlog_format = %(levelname)s\\n\")\n\n        if key == \"log_format\":\n            return \"%(levelname)s\"\n        return None\n\n    config = type(\"\", (), {\"getoption\": lambda x: None, \"getini\": getini})\n    assert get_option_ini(config, \"log_format\") == \"%(levelname)s\"\n", "def test_get_option_ini(tmpdir, pytestconfig):\n    tmpdir.join(\"pytest.ini\").write(\"[pytest]\\nlog_format = %s\\n\" % \"custom\")\n    assert get_option_ini(pytestconfig, \"log_format\") == \"custom\"\n    assert get_option_ini(pytestconfig, \"log_date_format\") == DEFAULT_LOG_DATE_FORMAT\n"], "sample_27": ["def test_make_token_with_timestamp(self):\n    user = User.objects.create_user('testuser', 'test@example.com', 'testpassword')\n    generator = PasswordResetTokenGenerator()\n    timestamp = generator._num_seconds(datetime(2022, 1, 1))\n    token = generator._make_token_with_timestamp(user, timestamp)\n    ts_b36, hash_string = token.split('-')\n    self.assertEqual(int_to_base36(timestamp), ts_b36)\n    self.assertEqual(len(hash_string), 20)  # Length of SHA-256 hash, truncated to 20 characters\n", "def test_token_generator_timeout(self):\n    # Create a user and a token generator with a mocked _now value.\n    user = User.objects.create_user('testuser', 'test@example.com', 'testpassword')\n    now = datetime.now()\n    token_generator = MockedPasswordResetTokenGenerator(now)\n    \n    # Generate a token.\n    token = token_generator.make_token(user)\n    \n    # Advance the mocked time beyond the PASSWORD_RESET_TIMEOUT.\n    future_now = now + timedelta(seconds=settings.PASSWORD_RESET_TIMEOUT + 1)\n    token_generator._now_val = future_now\n    \n    # The token should be invalid due to timeout.\n    self.assertFalse(token_generator.check_token(user, token))\n", "def test_make_token_with_timestamp_legacy(self):\n    user = User.objects.create_user('testuser', 'test@example.com', 'password')\n    generator = MockedPasswordResetTokenGenerator(datetime(2022, 1, 1))\n    token = generator._make_token_with_timestamp(user, self._num_seconds(datetime(2022, 1, 1)), legacy=True)\n    self.assertRegex(token, r'^[0-9a-z]{6}-[0-9a-f]{20}$')\n", "def test_token_generator_timeout(self):\n    user = User.objects.create_user('testuser', 'test@example.com', 'password')\n    token_generator = MockedPasswordResetTokenGenerator(datetime.now())\n    token = token_generator.make_token(user)\n    self.assertTrue(token_generator.check_token(user, token))\n\n    # Move forward in time beyond the timeout period\n    future_time = datetime.now() + timedelta(seconds=settings.PASSWORD_RESET_TIMEOUT + 1)\n    token_generator = MockedPasswordResetTokenGenerator(future_time)\n    self.assertFalse(token_generator.check_token(user, token))\n", "def test_token_generator_timeout(self):\n    # Create a user and a token generator with a mocked _now value.\n    user = User.objects.create_user('testuser', 'test@example.com', 'testpassword')\n    now = datetime.now()\n    token_generator = MockedPasswordResetTokenGenerator(now)\n    token = token_generator.make_token(user)\n\n    # Check that the token is valid.\n    self.assertTrue(token_generator.check_token(user, token))\n\n    # Advance the mocked _now value beyond the password reset timeout.\n    token_generator._now_val = now + timedelta(seconds=settings.PASSWORD_RESET_TIMEOUT + 1)\n\n    # Check that the token is no longer valid.\n    self.assertFalse(token_generator.check_token(user, token))\n"], "sample_39": ["    def test_no_url_patterns(self):\n        resolver = get_resolver()\n        with self.assertRaises(Resolver404):\n            resolver.resolve('/test/')\n", "    def test_no_url_patterns(self):\n        resolver = get_resolver(None)\n        with self.assertRaises(Resolver404):\n            resolver.resolve('/example/')\n", "    def test_no_url_patterns(self):\n        resolver = get_resolver()\n        with self.assertRaises(Resolver404):\n            resolver.resolve('/example/')\n", "def test_resolver_match_repr(self):\n    view_name = 'urlpatterns_reverse.views.empty_view'\n    resolver_match = ResolverMatch(empty_view, (), {}, url_name='test', route='/test/')\n    self.assertEqual(\n        repr(resolver_match),\n        f\"ResolverMatch(func={view_name}, args=(), kwargs={{}}, url_name='test', app_names=[], namespaces=[], route='/test/')\"\n    )\n", "    def test_resolvermatch_str(self):\n        resolver_match = ResolverMatch(None, (), {}, url_name='test', app_names=['app1'], namespaces=['ns1'])\n        self.assertEqual(str(resolver_match), (\n            \"ResolverMatch(func=None, args=(), kwargs={}, url_name='test', \"\n            \"app_names=['app1'], namespaces=['ns1'], route=None)\"\n        ))\n"], "sample_144": ["def test_refine_abs():\n    assert refine(Abs(x), Q.real(x)) == Abs(x)\n    assert refine(Abs(x), Q.positive(x)) == x\n    assert refine(Abs(x), Q.negative(x)) == -x\n    assert refine(Abs(x*y), Q.positive(x) & Q.real(y)) == x*Abs(y)\n    assert refine(Abs(x*y), Q.negative(x) & Q.real(y)) == -x*Abs(y)\n", "def test_refine_real_imaginary():\n    x = Symbol('x')\n    assert refine(re(x), Q.real(x)) == x\n    assert refine(im(x), Q.real(x)) == 0\n    assert refine(re(x), Q.imaginary(x)) == 0\n    assert refine(im(x), Q.imaginary(x)) == -I*x\n", "def test_refine_atan2():\n    assert refine(atan2(y, x), Q.real(y) & Q.positive(x)) == atan(y/x)\n    assert refine(atan2(y, x), Q.negative(y) & Q.negative(x)) == atan(y/x) - pi\n    assert refine(atan2(y, x), Q.positive(y) & Q.negative(x)) == atan(y/x) + pi\n    assert refine(atan2(y, x), Q.zero(y) & Q.negative(x)) == pi\n    assert refine(atan2(y, x), Q.positive(y) & Q.zero(x)) == pi/2\n    assert refine(atan2(y, x), Q.negative(y) & Q.zero(x)) == -pi/2\n    assert refine(atan2(y, x), Q.zero(y) & Q.zero(x)) == nan\n", "def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 2], Q.symmetric(X)) == X[1, 2]\n    assert refine(X[2, 1], Q.symmetric(X)) == X[1, 2]\n", "def test_refine_abs():\n    assert refine(Abs(x), Q.real(x)) == Abs(x)\n    assert refine(Abs(x), Q.positive(x)) == x\n    assert refine(Abs(x), Q.negative(x)) == -x\n    assert refine(Abs(x*y), Q.real(x) & Q.real(y)) == Abs(x)*Abs(y)\n"], "sample_31": ["def test_ipython_interface(self):\n    with mock.patch('IPython.start_ipython') as start_ipython:\n        call_command('shell', '--interface=ipython')\n        start_ipython.assert_called_once_with(argv=[])\n", "def test_handle_command(self):\n    with captured_stdout() as stdout:\n        call_command('shell', command='print(\"Hello, World!\")')\n    self.assertEqual(stdout.getvalue().strip(), 'Hello, World!')\n", "def test_handle_with_command(self):\n    with captured_stdout() as stdout:\n        call_command('shell', '--command', self.script_globals)\n    self.assertEqual(stdout.getvalue().strip(), 'True')\n", "def test_no_startup(self):\n    with captured_stdout() as stdout, captured_stdin() as stdin:\n        with mock.patch('os.environ', {'PYTHONSTARTUP': 'non_existent_file.py'}):\n            call_command('shell', '--no-startup')\n            self.assertEqual(stdout.getvalue(), '')\n            self.assertEqual(stdin.getvalue(), '')\n", "def test_no_startup(self):\n    with captured_stdout() as stdout:\n        with mock.patch('os.environ.get', return_value='nonexistent_file.py'):\n            with mock.patch('os.path.isfile', return_value=True):\n                call_command('shell', '--no-startup')\n    self.assertEqual(stdout.getvalue(), '')\n"], "sample_64": ["def test_prepopulated_fields_js(self):\n    # Set up an admin form and inline admin formsets\n    admin_form = ArticleAdmin(Article, site).get_form(None)\n    inline_admin_formset = ArticleAdmin(Article, site).get_inline_formsets(None)\n\n    # Create a context with the admin form and inline admin formsets\n    context = {\n        \"adminform\": admin_form,\n        \"inline_admin_formsets\": inline_admin_formset,\n    }\n\n    # Call the prepopulated_fields_js function\n    updated_context = prepopulated_fields_js(context)\n\n    # Check that the context has been updated with prepopulated fields\n    self.assertIn(\"prepopulated_fields\", updated_context)\n    self.assertIn(\"prepopulated_fields_json\", updated_context)\n\n    # Check that the prepopulated fields are correctly formatted\n    prepopulated_fields = updated_context[\"prepopulated_fields\"]\n    for field in prepopulated_fields:\n        self.assertIn(\"field\", field)\n        self.assertIn(\"dependencies\", field)\n        self.assertIsInstance(field[\"dependencies\"], list)\n", "def test_prepopulated_fields_js(self):\n    request = self.request_factory.get(reverse('admin:auth_user_add'))\n    request.user = self.superuser\n    admin = UserAdmin(User, site)\n    form = admin.get_form(request)(instance=None)\n    context = {\n        'adminform': form,\n        'add': True,\n        'change': False,\n        'is_popup': False,\n        'save_as': False,\n        'has_add_permission': True,\n        'has_change_permission': True,\n        'has_view_permission': True,\n        'has_editable_inline_admin_formsets': False,\n    }\n    context = prepopulated_fields_js(context)\n    self.assertEqual(context['prepopulated_fields'], [])\n    self.assertEqual(context['prepopulated_fields_json'], '[]')\n", "def test_prepopulated_fields_js(self):\n    # Setup admin and RF\n    model_admin = ArticleAdmin(Article, site)\n    request = self.request_factory.get(reverse('admin:admin_test_article_add'))\n    request.user = self.superuser\n    response = model_admin.add_view(request)\n\n    # Render the template tag with context\n    context = {\n        'adminform': model_admin.get_form(request),\n        'inline_admin_formsets': [],\n        'add': True,\n        'change': False,\n        'is_popup': False,\n        'save_as': False,\n        'has_add_permission': True,\n        'has_change_permission': True,\n        'has_view_permission': True,\n        'has_editable_inline_admin_formsets': False,\n    }\n    prepopulated_fields_js(context)\n\n    # Assert expected fields are present in context\n    self.assertIn('prepopulated_fields', context)\n    self.assertIn('prepopulated_fields_json', context)\n    self.assertIsInstance(context['prepopulated_fields'], list)\n    self.assertIsInstance(context['prepopulated_fields_json'], str)\n", "def test_prepopulated_fields_js(self):\n    request = self.request_factory.get(reverse('admin:auth_user_add'))\n    request.user = self.superuser\n    admin = UserAdmin(User, site)\n    adminform = admin.get_form(request)(instance=None)\n    context = {\n        'adminform': adminform,\n        'add': True,\n        'change': False,\n        'is_popup': False,\n        'save_as': False,\n        'has_add_permission': True,\n        'has_change_permission': True,\n        'has_view_permission': True,\n        'has_editable_inline_admin_formsets': False,\n    }\n    context = prepopulated_fields_js(context)\n    self.assertIn('prepopulated_fields', context)\n    self.assertIn('prepopulated_fields_json', context)\n", "def test_prepopulated_fields_js(self):\n    request = self.request_factory.get(reverse('admin:admin_test_article_add'))\n    admin = ArticleAdmin(Article, site)\n    form = admin.get_form(request)(instance=Article())\n    field = form.base_fields['title']\n    field.widget.attrs['id'] = 'id_title'\n    context = {\n        'adminform': admin.get_form(request)(instance=Article()),\n        'has_change_permission': True,\n        'add': True,\n        'change': False,\n        'is_popup': False,\n        'save_as': False,\n        'show_save': True,\n        'show_save_and_add_another': True,\n        'show_save_and_continue': True,\n        'has_add_permission': True,\n        'has_view_permission': True,\n        'has_editable_inline_admin_formsets': False,\n    }\n    prepopulated_fields_js(context)\n    self.assertIn('prepopulated_fields', context)\n    self.assertIn('prepopulated_fields_json', context)\n    self.assertEqual(len(context['prepopulated_fields']), 0)\n"], "sample_86": ["def test_add_global_property(testdir):\n    resultpath = testdir.tmpdir.join(\"junit.xml\")\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n            record_testsuite_property(\"ARCH\", \"PPC\")\n            record_testsuite_property(\"STORAGE_TYPE\", \"CEPH\")\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--junitxml=%s\" % resultpath)\n    xmldoc = minidom.parse(str(resultpath))\n    node = DomNode(xmldoc).find_first_by_tag(\"testsuite\").get_unique_child\n    assert node.tag == \"properties\"\n    props = node.children\n    assert len(props) == 2\n    props.sort(key=lambda x: x[\"name\"])\n    assert props[0].assert_attr(name=\"ARCH\", value=\"PPC\")\n    assert props[1].assert_attr(name=\"STORAGE_TYPE\", value=\"CEPH\")\n", "def test_junit_log_passing_tests(testdir):\n    testdir.makepyfile(\"\"\"\n            pass\n    \"\"\")\n    result, dom = runandparse(testdir, \"--junit-logging=no\", \"--junit-log-passing-tests=False\")\n    assert len(dom.find_by_tag(\"system-out\")) == 0\n\n    result, dom = runandparse(testdir, \"--junit-logging=system-out\", \"--junit-log-passing-tests=False\")\n    assert len(dom.find_by_tag(\"system-out\")) == 0\n\n    result, dom = runandparse(testdir, \"--junit-logging=system-out\", \"--junit-log-passing-tests=True\")\n    assert len(dom.find_by_tag(\"system-out\")) == 1\n\n    result, dom = runandparse(testdir, \"--junit-logging=system-out\")\n    assert len(dom.find_by_tag(\"system-out\")) == 1\n", "def test_add_stats(testdir):\n    resultpath = testdir.tmpdir.join(\"junit.xml\")\n    testdir.runpytest(\"--junitxml=%s\" % resultpath, \"tests/example/test_example.py\")\n    xml = minidom.parse(str(resultpath))\n    node = DomNode(xml)\n    assert_attr(node.find_first_by_tag(\"testsuite\"), errors=\"0\", failures=\"1\", skipped=\"0\", tests=\"1\")\n", "def test_junit_xml_property(testdir):\n    p1 = testdir.makepyfile(\n        \"\"\"\n            record_property(\"example_key\", 1)\n        \"\"\"\n    )\n    result, dom = runandparse(testdir, p1)\n    node = dom.find_first_by_tag(\"testcase\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    assert properties_node is not None\n    property_node = properties_node.find_first_by_tag(\"property\")\n    assert property_node is not None\n    assert property_node[\"name\"] == \"example_key\"\n    assert property_node[\"value\"] == \"1\"\n", "def test_junitxml_property(testdir):\n    p = testdir.makepyfile(\"\"\"\n            record_property(\"my_prop\", \"42\")\n    \"\"\")\n    result, dom = runandparse(testdir, p)\n    node = dom.find_first_by_tag(\"testcase\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    property_node = properties_node.find_first_by_tag(\"property\")\n    assert_attr(property_node, name=\"my_prop\", value=\"42\")\n"], "sample_76": ["def test_polyfit_empty(self, df):\n\n    # Create an empty dataframe\n    empty_df = pd.DataFrame(columns=[\"x\", \"y\"])\n\n    # Create a PolyFit object\n    poly_fit = PolyFit()\n\n    # Apply the PolyFit to the empty dataframe\n    result = poly_fit(empty_df, GroupBy(), \"x\", None)\n\n    # Check that the result is an empty dataframe\n    assert_frame_equal(result, pd.DataFrame(columns=[\"x\", \"y\"]))\n", "def test_polyfit_direct(self, df):\n\n    order = 2\n    gridsize = 100\n\n    x = df[\"x\"]\n    y = df[\"y\"]\n\n    stat = PolyFit(order=order, gridsize=gridsize)\n    result = stat._fit_predict(df)\n\n    p = np.polyfit(x, y, order)\n    xx = np.linspace(x.min(), x.max(), gridsize)\n    yy = np.polyval(p, xx)\n\n    expected = pd.DataFrame(dict(x=xx, y=yy))\n    assert_frame_equal(result, expected)\n", "def test_polyfit_gridsize(self, df):\n\n    n = 50\n    poly_fit = PolyFit(gridsize=n)\n\n    groupby = GroupBy(\"color\")\n    result = poly_fit(df, groupby, \"x\", None)\n\n    assert len(result) == len(df[\"color\"].unique()) * n\n", "def test_polyfit_empty(self, df):\n\n    df = df.drop(\"x\", axis=1)\n    groupby = GroupBy([\"group\"])\n    poly_fit = PolyFit()\n\n    result = poly_fit(df, groupby, \"x\", None)\n\n    assert_frame_equal(result, pd.DataFrame(columns=[\"x\", \"y\"], dtype=float))\n", "def test_polyfit_dropna(self, df):\n\n    df.loc[0, \"x\"] = np.nan\n    df.loc[1, \"y\"] = np.nan\n\n    stat = PolyFit()\n    result = stat(df, GroupBy(\"color\"), \"x\", None)\n\n    assert_frame_equal(result, stat(df.dropna(subset=[\"x\", \"y\"]), GroupBy(\"color\"), \"x\", None))\n"], "sample_19": ["    def test_cleansed_substitute(self):\n        filter = SafeExceptionReporterFilter()\n        self.assertEqual(filter.cleansed_substitute, '********************')\n", "    def test_get_safe_settings(self):\n        filter = SafeExceptionReporterFilter()\n        settings = {'SECRET_KEY': 'secret'}\n        with override_settings(**settings):\n            safe_settings = filter.get_safe_settings()\n            self.assertEqual(safe_settings['SECRET_KEY'], filter.cleansed_substitute)\n", "    def test_get_safe_settings(self):\n        filter = SafeExceptionReporterFilter()\n        settings = filter.get_safe_settings()\n        self.assertIsInstance(settings, dict)\n        for key, value in settings.items():\n            self.assertNotIn('API', key)\n            self.assertNotIn('TOKEN', key)\n            self.assertNotIn('KEY', key)\n            self.assertNotIn('SECRET', key)\n            self.assertNotIn('PASS', key)\n            self.assertNotIn('SIGNATURE', key)\n", "    def test_cleansed_multivaluedict(self):\n        filter = SafeExceptionReporterFilter()\n        request = RequestFactory().get('/test/')\n        request.sensitive_post_parameters = ['sensitive']\n        multivaluedict = {'normal': 'value', 'sensitive': 'secret'}\n        cleansed = filter.get_cleansed_multivaluedict(request, multivaluedict)\n        self.assertEqual(cleansed['normal'], 'value')\n        self.assertEqual(cleansed['sensitive'], '********************')\n", "    def test_cleansing_setting(self):\n        filter = SafeExceptionReporterFilter()\n        self.assertEqual(filter.cleanse_setting('SETTING', 'VALUE'), 'VALUE')\n        self.assertEqual(filter.cleanse_setting('API_KEY', 'SECRET_VALUE'), '********************')\n"], "sample_118": ["def test_ccode_reserved_words():\n    x, y = symbols('x, y')\n    reserved = ['auto', 'if', 'break', 'int', 'case', 'long', 'char', 'register',\n                'continue', 'return', 'default', 'short', 'do', 'sizeof',\n                'double', 'static', 'else', 'struct', 'entry', 'switch',\n                'extern', 'typedef', 'float', 'union', 'for', 'unsigned',\n                'goto', 'while', 'enum', 'void', 'const', 'signed', 'volatile']\n    for word in reserved:\n        expr = symbols(word)\n        assert ccode(expr) == word + \"_\"\n        assert ccode(expr, assign_to=expr) == word + \"_ = \" + word + \"_;\"\n        assert ccode(x+expr) == \"x + \" + word + \"_\"\n", "def test_ccode_sinc():\n    expr = implemented_function(\"sinc\", Lambda(x, sin(x)/x))\n    assert ccode(expr(x)) == '((sin(x) > 0) - (sin(x) < 0))'\n    assert ccode(expr(x), assign_to=\"s\") == 's = ((sin(x) > 0) - (sin(x) < 0));'\n", "def test_ccode_reserved_words():\n    x = symbols('x')\n    expr = sin(x)\n    assign_to = 'for'\n    with raises(ValueError):\n        ccode(expr, assign_to=assign_to)\n\n    printer = CCodePrinter({'error_on_reserved': False})\n    assert printer.doprint(expr, assign_to) == 'for_ = sin(x);'\n", "def test_ccode_sinc():\n    expr = implemented_function(\"sinc\", Lambda(x, sin(x)/x))\n    assert ccode(expr(x)) == '((sin(x) > 0) - (sin(x) < 0))*(sin(x)/x)'\n    assert ccode(expr(x), assign_to='y') == 'y = ((sin(x) > 0) - (sin(x) < 0))*(sin(x)/x);'\n", "def test_ccode_sinc():\n    x = symbols('x')\n    expr = sinc(x)\n    result = ccode(expr)\n    expected = '((sin(x)/x) > 0 ? (sin(x)/x) : 1)'\n    assert result != expected\n\n    from sympy.functions.elementary.trigonometric import sin\n    from sympy.core.relational import Ne\n    from sympy.functions import Piecewise\n    _piecewise = Piecewise(\n        (sin(x) / x, Ne(x, 0)), (1, True))\n    assert ccode(expr) == ccode(_piecewise)\n"], "sample_152": ["def test_NDimArray_diff():\n    # Test differentiation of NDimArray instances with respect to symbols.\n    array = ImmutableDenseNDimArray([[x**2, y**2], [x*y, x + y]])\n    assert simplify(array.diff(x)) == ImmutableDenseNDimArray([[2*x, 0], [y, 1]])\n    assert simplify(array.diff(y)) == ImmutableDenseNDimArray([[0, 2*y], [x, 1]])\n\n    # Test differentiation of NDimArray instances with respect to other NDimArray instances.\n    array1 = ImmutableDenseNDimArray([x, y])\n    array2 = ImmutableDenseNDimArray([sin(x), cos(y)])\n    assert simplify(array2.diff(array1)) == ImmutableDenseNDimArray([[cos(x), 0], [0, -sin(y)]])\n", "def test_NDimArray_diff():\n    # Test differentiation of N-dim array\n    M = ImmutableDenseNDimArray([[x, y], [1, x*y]])\n    assert M.diff(x) == ImmutableDenseNDimArray([[1, 0], [0, y]])\n    assert M.diff(y) == ImmutableDenseNDimArray([[0, 1], [0, x]])\n", "def test_NDimArray_diff():\n    # Test differentiation of NDimArray instances\n    M = ImmutableDenseNDimArray([[x, y], [1, x*y]])\n    assert M.diff(x) == ImmutableDenseNDimArray([[1, 0], [0, y]])\n    assert M.diff(y) == ImmutableDenseNDimArray([[0, 1], [0, x]])\n\n    # Test differentiation of NDimArray with nested expressions\n    M = ImmutableDenseNDimArray([[sin(x), cos(y)], [x**2, y**2]])\n    assert M.diff(x) == ImmutableDenseNDimArray([[cos(x), 0], [2*x, 0]])\n    assert M.diff(y) == ImmutableDenseNDimArray([[0, -sin(y)], [0, 2*y]])\n\n    # Test differentiation with multiple symbols\n    M = ImmutableDenseNDimArray([[x*y, x+y], [x-y, x/y]])\n    assert M.diff(x) == ImmutableDenseNDimArray([[y, 1], [1, 1/y]])\n    assert M.diff(y) == ImmutableDenseNDimArray([[x, 1], [-1, -x/y**2]])\n\n    # Test differentiation of a scalar array\n    M = ImmutableDenseNDimArray([x])\n    assert M.diff(x) == ImmutableDenseNDimArray([1])\n\n    # Test differentiation of an empty array\n    M = ImmutableDenseNDimArray([])\n    assert M.diff(x) == ImmutableDenseNDimArray([])\n", "def test_ndim_array_diff():\n    # Create an NDimArray with symbolic values\n    a = ImmutableDenseNDimArray([[x, y], [1, x*y]])\n\n    # Calculate the derivative of the array with respect to x\n    da_dx = a.diff(x)\n\n    # Check if the result is as expected\n    assert simplify(da_dx[0, 0]) == 1\n    assert simplify(da_dx[0, 1]) == 0\n    assert simplify(da_dx[1, 0]) == 0\n    assert simplify(da_dx[1, 1]) == y\n\n    # Calculate the derivative of the array with respect to y\n    da_dy = a.diff(y)\n\n    # Check if the result is as expected\n    assert simplify(da_dy[0, 0]) == 0\n    assert simplify(da_dy[0, 1]) == 1\n    assert simplify(da_dy[1, 0]) == 0\n    assert simplify(da_dy[1, 1]) == x\n", "def test_NDimArray_shape():\n    # Test that shape is correctly set for N-dim arrays\n    a = MutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    assert a.shape == (2, 2)\n    b = MutableDenseNDimArray([[1, 2], [3, 4]])\n    assert b.shape == (2, 2)\n    c = MutableDenseNDimArray([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n    assert c.shape == (2, 2, 2)\n"], "sample_154": ["def test_lambdify_piecewise():\n    f = Piecewise((x**2, x < 0), (x, x >= 0))\n    f_np = lambdify(x, f, 'numpy')\n    assert f_np(-2) == 4\n    assert f_np(3) == 3\n", "def test_lambdify_matrix_args():\n    x = symbols('x')\n    M = MatrixSymbol('M', 2, 2)\n    mat = Matrix([[x, x], [x, x]])\n    f = lambdify((M,), M, 'sympy')\n    assert f(mat) == mat\n    assert f(Matrix([[1, 2], [3, 4]])) == Matrix([[1, 2], [3, 4]])\n", "def test_lambdify_with_implemented_function():\n    f = implemented_function('f', lambda x: x+1)\n    func = lambdify(x, f(x), 'numpy')\n    assert func(2) == 3\n", "def test_lambdify_tensorflow():\n    if not tensorflow:\n        skip(\"TensorFlow not installed\")\n\n    f = lambdify(x, x + 1, 'tensorflow')\n    assert f(1) == 2\n\n    f = lambdify((x, y), x + y, 'tensorflow')\n    assert f(1, 2) == 3\n\n    f = lambdify(x, sin(x), 'tensorflow')\n    assert f(0) == 0\n\n    f = lambdify(x, exp(x), 'tensorflow')\n    assert f(0) == 1\n", "def test_lambdify_with_bessel_functions():\n    # Test lambdify with bessel functions\n    f = besseli(x, 1)\n    g = lambdify(x, f, 'scipy')\n    assert abs(g(3.5) - mpmath.besseli(3.5, 1)) < 1e-10\n\n    f = besselj(x, 2)\n    g = lambdify(x, f, 'scipy')\n    assert abs(g(2.5) - mpmath.besselj(2.5, 2)) < 1e-10\n\n    f = besselk(x, 3)\n    g = lambdify(x, f, 'scipy')\n    assert abs(g(4.0) - mpmath.besselk(4.0, 3)) < 1e-10\n\n    f = bessely(x, 1)\n    g = lambdify(x, f, 'scipy')\n    assert abs(g(3.5) - mpmath.bessely(3.5, 1)) < 1e-10\n"], "sample_51": ["def test_serve_file_with_directory_index(self):\n    \"\"\"Test serving a file with directory index\"\"\"\n    with self.settings(MEDIA_ROOT=media_dir):\n        response = self.client.get(f\"/{self.prefix}/directory/\")\n\n        self.assertEqual(response.status_code, 200)\n        self.assertTemplateUsed(response, \"static/directory_index.html\")\n        self.assertContains(response, \"Index of directory/\")\n        self.assertContains(response, \"file1.txt\")\n        self.assertContains(response, \"file2.txt\")\n        self.assertContains(response, \"subdirectory/\")\n", "def test_serve_directory_index(self):\n    \"\"\"Tests serving a directory index\"\"\"\n    with override_settings(TEMPLATE_DIRS=[path.join(path.dirname(urls.__file__), 'templates')]):\n        response = self.client.get('/site_media/')\n        self.assertContains(response, 'Index of /')\n        self.assertContains(response, '<li><a href=\"test/\">test/</a></li>')\n\n    # With show_indexes=False (default), it should raise 404\n    with override_settings(MEDIA_URL='/'):\n        response = self.client.get('/media/')\n        self.assertEqual(response.status_code, 404)\n", "def test_serve_directory_index(self):\n    \"\"\"\n    Test serving a directory index. The test case creates a file and a\n    directory inside the temporary media directory.\n    \"\"\"\n    # Create a temporary file and directory\n    tmp_file = path.join(media_dir, 'file.txt')\n    open(tmp_file, 'w').close()\n    tmp_dir = path.join(media_dir, 'subdir')\n    path.os.mkdir(tmp_dir)\n\n    response = self.client.get('/%s/' % self.prefix)\n    self.assertEqual(response.status_code, 200)\n    self.assertTemplateUsed(response, 'static/directory_index.html')\n\n    # Check that the links in the page are encoded correctly\n    self.assertContains(response, quote('file.txt'))\n    self.assertContains(response, quote('subdir/'))\n\n    # Check for the link to the parent directory (..) if we're not in the root\n    self.assertContains(response, quote('../'))\n\n    # Clean up after the test\n    path.os.remove(tmp_file)\n    path.os.rmdir(tmp_dir)\n", "def test_serve(self):\n    file_path = path.join(media_dir, 'file.txt')\n    with open(file_path, 'w') as f:\n        f.write('Hello, world!')\n    response = self.client.get(f'/{self.prefix}/file.txt')\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(response.content, b'Hello, world!')\n    self.assertEqual(response['Content-Type'], mimetypes.guess_type(file_path)[0])\n    self.assertGreaterEqual(len(response['Last-Modified']), 26)  # length of HTTP date format\n    with open(file_path, 'rb') as f:\n        expected_etag = f'\"{http_date(path.getmtime(file_path))}\"'\n        self.assertEqual(response['ETag'], expected_etag)\n", "def test_serve(self):\n    media_file = path.join(media_dir, 'mediafile.txt')\n    with open(media_file, 'w') as f:\n        f.write('some content')\n    response = self.client.get(f'/{self.prefix}/mediafile.txt')\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(response.content, b'some content')\n    self.assertEqual(response['Content-Type'], 'text/plain')\n    self.assertContains(response, 'some content')\n\n    # check Content-Encoding header\n    with open(media_file, 'wb') as f:\n        f.write(b'some binary content')\n    response = self.client.get(f'/{self.prefix}/mediafile.txt')\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(response['Content-Type'], 'application/octet-stream')\n\n    # check Last-Modified header\n    mtime = http_date(path.getmtime(media_file))\n    response = self.client.get(f'/{self.prefix}/mediafile.txt', HTTP_IF_MODIFIED_SINCE=mtime)\n    self.assertEqual(response.status_code, 304)\n\n    # check that If-Modified-Since is ignored if the file doesn't exist\n    response = self.client.get(f'/{self.prefix}/doesntexist.txt', HTTP_IF_MODIFIED_SINCE=mtime)\n    self.assertEqual(response.status_code, 404)\n"], "sample_17": ["def test_create_test_db(self):\n    test_connection = get_connection_copy()\n    creation = BaseDatabaseCreation(test_connection)\n\n    # Mock the _create_test_db method to avoid actual database creation.\n    with mock.patch.object(creation, '_create_test_db', return_value='test_database'):\n        with mock.patch.object(creation, 'log'):\n            test_database_name = creation.create_test_db(verbosity=0, autoclobber=False, serialize=True, keepdb=False)\n            self.assertEqual(test_database_name, 'test_database')\n            self.assertEqual(test_connection.settings_dict['NAME'], 'test_database')\n", "def test_get_test_db_name(self):\n    test_connection = get_connection_copy()\n    creation = BaseDatabaseCreation(test_connection)\n\n    # Test with TEST['NAME'] set\n    test_name = 'test_name'\n    test_connection.settings_dict['TEST']['NAME'] = test_name\n    self.assertEqual(creation._get_test_db_name(), test_name)\n\n    # Test without TEST['NAME'] set\n    del test_connection.settings_dict['TEST']['NAME']\n    expected_name = TEST_DATABASE_PREFIX + test_connection.settings_dict['NAME']\n    self.assertEqual(creation._get_test_db_name(), expected_name)\n", "def test_get_test_db_name(self):\n    test_connection = get_connection_copy()\n    creation = BaseDatabaseCreation(test_connection)\n\n    # If 'TEST'['NAME'] is specified, it should be used.\n    test_connection.settings_dict['TEST']['NAME'] = 'test_database'\n    self.assertEqual(creation._get_test_db_name(), 'test_database')\n\n    # If 'TEST'['NAME'] is not specified, the name should be constructed by\n    # prefixing the database name with 'test_'.\n    test_connection.settings_dict['TEST']['NAME'] = ''\n    self.assertEqual(\n        creation._get_test_db_name(),\n        TEST_DATABASE_PREFIX + test_connection.settings_dict['NAME']\n    )\n", "    def test_create_test_db_name(self):\n        test_connection = get_connection_copy()\n        creation = BaseDatabaseCreation(test_connection)\n        self.assertEqual(\n            creation._get_test_db_name(),\n            TEST_DATABASE_PREFIX + test_connection.settings_dict['NAME']\n        )\n", "    def test_get_test_db_name(self):\n        connection = get_connection_copy()\n        creation = BaseDatabaseCreation(connection)\n        self.assertEqual(creation._get_test_db_name(), TEST_DATABASE_PREFIX + connection.settings_dict['NAME'])\n"], "sample_149": ["def test_Monomial_div():\n    a, b = symbols('a b')\n    m1 = Monomial((3, 4), (a, b))\n    m2 = Monomial((1, 2), (a, b))\n\n    assert m1 / m2 == Monomial((2, 2), (a, b))\n\n    raises(ExactQuotientFailed, lambda: m2 / m1)\n", "def test_Monomial_ops():\n    a, b = symbols('a b')\n\n    m1 = Monomial((2, 3), (a, b))\n    m2 = Monomial((1, 4), (a, b))\n\n    assert m1 * m2 == Monomial((3, 7), (a, b))\n    assert m1 / m2 == Monomial((1, -1), (a, b))\n    raises(ExactQuotientFailed, lambda: m2 / m1)\n    assert m1 ** 3 == Monomial((6, 9), (a, b))\n    assert m1.gcd(m2) == Monomial((1, 3), (a, b))\n    assert m1.lcm(m2) == Monomial((2, 4), (a, b))\n", "def test_Monomial_rebuild():\n    M = Monomial((2, 3), (x, y))\n    assert M.rebuild(M.exponents) == M\n    assert M.rebuild(M.exponents, M.gens) == M\n    assert M.rebuild(M.exponents, (z, x)) != M\n", "def test_monomial_pow():\n    assert monomial_pow((1, 2, 3), 0) == (0, 0, 0)\n    assert monomial_pow((1, 2, 3), 1) == (1, 2, 3)\n    assert monomial_pow((1, 2, 3), 2) == (2, 4, 6)\n    raises(ValueError, lambda: monomial_pow((1, 2, 3), -1))\n", "def test_Monomial_pow():\n    x, y = symbols('x y')\n    m1 = Monomial((2, 3), (x, y))\n    assert m1**0 == Monomial((0, 0), (x, y))\n    assert m1**1 == m1\n    assert m1**2 == Monomial((4, 6), (x, y))\n    raises(ValueError, lambda: m1**-1)\n"], "sample_130": ["def test_lambdify_with_Tensorflow():\n    if not tensorflow:\n        skip(\"TensorFlow is not installed.\")\n\n    # Simple\n    f = lambdify(x, x**2, \"tensorflow\")\n    assert f(2) == 4\n\n    # Matrix\n    M = Matrix([[x, y], [y, x]])\n    f = lambdify((x, y), M, \"tensorflow\")\n    assert (f(1, 2) == [[1, 2], [2, 1]]).all()\n\n    # Vector\n    v = Matrix([x, y])\n    f = lambdify((x, y), v, \"tensorflow\")\n    assert (f(1, 2) == [1, 2]).all()\n\n    # Piecewise\n    f = lambdify(x, Piecewise((x, x < 1), (1/x, True)), \"tensorflow\")\n    assert f(0.5) == 0.5\n    assert f(2) == 0.5\n", "def test_lambdastr():\n    # Test lambdastr works for different types of args and expr\n    assert lambdastr(x, x**2) == 'lambda x: (x**2)'\n    assert lambdastr((x, y), x + y) == 'lambda x,y: (x + y)'\n    assert lambdastr((x, (y, z)), x + y) == (\n        'lambda _0,_1: (lambda x,y,z: (x + y))(_0,_1[0],_1[1])')\n    assert lambdastr(x, Piecewise((x, x < 1), (x**2, True))) == (\n        'lambda x: ((x) if (x < 1) else (x**2))')\n", "def test_lambdify_with_sum():\n    j = symbols('j')\n    a = IndexedBase('a')\n    L = lambdify((a, x), Sum(a[j]*x**j, (j, 0, 5)).doit(), 'numpy')\n    assert L([1, 2, 3, 4, 5, 6], 7) == sum(a_val*7**j for j, a_val in enumerate([1, 2, 3, 4, 5, 6]))\n", "def test_lambdify_piecewise():\n    f = Piecewise((x, x <= 1), (1/x, x > 1))\n    f_lambda = lambdify(x, f, 'numpy')\n    assert f_lambda(0.5) == 0.5\n    assert f_lambda(2) == 0.5\n", "def test_lambdify_with_integer_function():\n    f = implemented_function('f', lambda x: 2*x)\n    lam_f = lambdify(x, f(x), 'math')\n    assert lam_f(3) == 6\n"], "sample_113": ["def test_column_transformer_get_feature_names_out_pandas():\n    # Test that get_feature_names_out works with pandas\n    X = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\n    ct = ColumnTransformer([(\"trans\", Trans(), [\"A\", \"B\"])])\n    ct.fit(X)\n    feature_names = ct.get_feature_names_out()\n    assert_array_equal(feature_names, [\"trans__A\", \"trans__B\"])\n\n    # Test that get_feature_names_out works with verbose_feature_names_out=False\n    ct.verbose_feature_names_out = False\n    feature_names = ct.get_feature_names_out()\n    assert_array_equal(feature_names, [\"A\", \"B\"])\n", "def test_column_transformer_get_params():\n    # Test that we can get the parameters of a ColumnTransformer\n    trans = ColumnTransformer(\n        [(\"trans1\", Trans()), (\"trans2\", Trans())], remainder=\"passthrough\"\n    )\n    params = trans.get_params()\n    assert \"trans1\" in params\n    assert \"trans2\" in params\n    assert params[\"remainder\"] == \"passthrough\"\n\n    # Test that we can get the parameters of a nested ColumnTransformer\n    nested_trans = ColumnTransformer(\n        [(\"nested_trans1\", Trans()), (\"nested_trans2\", Trans())]\n    )\n    trans = ColumnTransformer([(\"trans1\", Trans()), (\"trans2\", nested_trans)])\n    params = trans.get_params()\n    assert \"trans1\" in params\n    assert \"trans2\" in params\n    assert \"trans2__nested_trans1\" in params\n    assert \"trans2__nested_trans2\" in params\n", "def test_column_transformer_get_feature_names_out_with_callable():\n    X = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\n\n    # Use make_column_selector to select columns based on dtype\n    ct = ColumnTransformer(\n        [\n            (\n                \"select_integers\",\n                FunctionTransformer(),\n                make_column_selector(dtype_include=\"int64\"),\n            )\n        ]\n    )\n\n    ct.fit(X)\n    feature_names = ct.get_feature_names_out()\n    assert_array_equal(feature_names, [\"select_integers__A\", \"select_integers__B\"])\n", "def test_column_transformer_feature_names_out():\n    X = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4], \"C\": [5, 6]})\n\n    # All transformers output pandas DataFrames\n    ct = ColumnTransformer(\n        [\n            (\"trans1\", Trans(), [\"A\", \"B\"]),\n            (\"trans2\", FunctionTransformer(), [\"C\"]),\n        ],\n    )\n    ct.fit(X)\n    assert_array_equal(ct.get_feature_names_out(), [\"trans1_A\", \"trans1_B\", \"trans2_C\"])\n\n    # Only some transformers output pandas DataFrames\n    ct = ColumnTransformer([(\"trans1\", Trans(), [\"A\"]), (\"trans2\", TransNo2D(), [\"B\"])])\n    ct.fit(X)\n    assert_array_equal(ct.get_feature_names_out(), [\"trans1_A\", \"trans2_B\"])\n\n    # None of the transformers output pandas DataFrames\n    ct = ColumnTransformer([(\"trans1\", TransNo2D(), [\"A\"]), (\"trans2\", TransNo2D(), [\"B\"])])\n    ct.fit(X)\n    with pytest.raises(AttributeError):\n        ct.get_feature_names_out()\n", "def test_column_transformer_feature_names_out():\n    X = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n\n    # Test with verbose_feature_names_out=True (default)\n    ct = ColumnTransformer(\n        [(\"trans1\", StandardScaler(), [\"A\"]), (\"trans2\", OneHotEncoder(), [\"B\"])],\n        verbose_feature_names_out=True,\n    )\n    ct.fit(X)\n    assert_array_equal(ct.get_feature_names_out(), [\"trans1__A\", \"trans2__B_4\", \"trans2__B_5\", \"trans2__B_6\"])\n\n    # Test with verbose_feature_names_out=False\n    ct = ColumnTransformer(\n        [(\"trans1\", StandardScaler(), [\"A\"]), (\"trans2\", OneHotEncoder(), [\"B\"])],\n        verbose_feature_names_out=False,\n    )\n    ct.fit(X)\n    assert_array_equal(ct.get_feature_names_out(), [\"A\", \"B_4\", \"B_5\", \"B_6\"])\n\n    # Test that an error is raised when feature names are not unique and verbose_feature_names_out=False\n    X = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [1, 2, 3]})\n    ct = ColumnTransformer(\n        [(\"trans1\", StandardScaler(), [\"A\"]), (\"trans2\", StandardScaler(), [\"B\"])],\n        verbose_feature_names_out=False,\n    )\n    ct.fit(X)\n    with pytest.raises(ValueError):\n        ct.get_feature_names_out()\n"], "sample_116": ["def test_create_index(builder, sphinx_env):\n    indexentries = IndexEntries(sphinx_env)\n    domain = sphinx_env.get_domain('index')\n    domain.entries['test'] = [('single', 'entry', 'tid', 'main', None)]\n    result = indexentries.create_index(builder, group_entries=True)\n    assert len(result) == 1\n    assert result[0][0] == 'E'  # first letter of \"entry\"\n    assert len(result[0][1]) == 1\n    assert result[0][1][0][0] == 'entry'\n    assert result[0][1][0][1] == [('main', f\"{builder.get_relative_uri('genindex', 'test')}#tid\")]\n", "def test_create_index(app, status, warning):\n    # create an instance of IndexEntries\n    env = app.builder.env\n    indexentries = IndexEntries(env)\n\n    # add some index entries\n    domain = env.get_domain('index')\n    domain.add_entry('single', 'entry1', 'tid1', 'main1', None)\n    domain.add_entry('pair', 'entry2;entry3', 'tid2', 'main2', None)\n    domain.add_entry('see', 'entry4;entry5', 'tid3', None, None)\n\n    # create the index\n    builder = app.builder\n    result = indexentries.create_index(builder)\n\n    # check the result\n    assert len(result) > 0\n    for key, entries in result:\n        if key == 'E':\n            assert len(entries) == 3\n            for entry in entries:\n                if entry[0] == 'entry1':\n                    assert len(entry[1]) == 1\n                elif entry[0] == 'entry2':\n                    assert len(entry[1]) == 2\n                elif entry[0] == 'entry4':\n                    assert len(entry[1]) == 1\n", "def test_create_index(app, status, warning):\n    # create an instance of IndexEntries\n    index = IndexEntries(app.env)\n\n    # simulate some index entries\n    domain = app.env.get_domain('index')\n    domain.entries['file1'] = [\n        ('single', 'entry1', 'tid1', 'main1', None),\n        ('pair', 'entry2; entry3', 'tid2', 'main2', None),\n    ]\n\n    # create the index\n    index_entries = index.create_index(app.builder)\n\n    # check if the index entries are correctly created\n    assert len(index_entries) == 2\n    assert index_entries[0][0] == _('Symbols')\n    assert len(index_entries[0][1]) == 2\n    assert index_entries[1][0] == 'E'\n    assert len(index_entries[1][1]) == 1\n", "def test_create_index(builder, env):\n    # Create an instance of IndexEntries\n    index_entries = IndexEntries(env)\n\n    # Add some index entries to the environment\n    domain = env.get_domain('index')\n    domain.add_entry('single', 'entry1', 'tid1', 'main1', None)\n    domain.add_entry('pair', 'entry2;entry3', 'tid2', 'main2', None)\n    domain.add_entry('triple', 'entry4;entry5;entry6', 'tid3', 'main3', None)\n\n    # Create the index\n    index = index_entries.create_index(builder)\n\n    # Check if the index is created correctly\n    assert len(index) == 3\n    assert index[0][0] == 'E'\n    assert len(index[0][1]) == 2\n    assert index[1][0] == 'E'\n    assert len(index[1][1]) == 1\n    assert index[2][0] == 'E'\n    assert len(index[2][1]) == 1\n\n    # Check if the sub-entries are sorted correctly\n    sub_entries = index[0][1]\n    assert len(sub_entries) == 2\n    assert sub_entries[0][0] == 'entry1'\n    assert sub_entries[1][0] == 'entry2'\n\n    # Check if the sub-sub-entries are sorted correctly\n    sub_sub_entries = sub_entries[1][1]\n    assert len(sub_sub_entries) == 1\n    assert sub_sub_entries[0][0] == 'entry3'\n", "def test_create_index(app):\n    # Create an instance of IndexEntries with a dummy BuildEnvironment\n    env = app.builder.env\n    indexentries = IndexEntries(env)\n\n    # Define some dummy index entries\n    domain = env.get_domain('index')\n    domain.entries['dummy'] = [\n        ('single', 'entry1', 'tid1', 'main1', None),\n        ('pair', 'entry2 subentry2', 'tid2', 'main2', None),\n        ('see', 'entry3 otherentry3', 'tid3', 'main3', None),\n    ]\n\n    # Create the index\n    index = indexentries.create_index(app.builder, group_entries=True)\n\n    # Assert that the index has the expected structure and content\n    assert len(index) == 1\n    key, entries = index[0]\n    assert key == 'E'\n    assert len(entries) == 3\n    assert entries[0][0] == 'entry1'\n    assert entries[1][0] == 'entry2'\n    assert entries[2][0] == 'entry3'\n"], "sample_109": ["def test_build_repr():\n    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n    repr = _build_repr(cv)\n    assert repr == \"KFold(n_splits=5, random_state=42, shuffle=True)\"\n", "def test_build_repr():\n    # Test that _build_repr builds a good repr with a mock object\n    class MockObject:\n            self.a = a\n            self.b = b\n\n    obj = MockObject(a=5)\n    repr = _build_repr(obj)\n    assert repr == \"MockObject(a=5)\"\n\n    obj = MockObject(b='something')\n    repr = _build_repr(obj)\n    assert repr == \"MockObject(b='something')\"\n", "def test_build_repr():\n    # Test that _build_repr builds the correct representation for an object\n    class MockClass:\n            self.a = a\n            self.b = b\n\n    mock_obj = MockClass(a=5, b='test')\n    expected_repr = \"MockClass(a=5, b='test')\"\n    assert _build_repr(mock_obj) == expected_repr\n", "def test_build_repr():\n    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n    repr = _build_repr(cv)\n    assert repr == \"KFold(n_splits=5, random_state=42, shuffle=True)\"\n\n    cv = StratifiedKFold(n_splits=3, shuffle=False, random_state=None)\n    repr = _build_repr(cv)\n    assert repr == \"StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\"\n", "def test_build_repr():\n    # Test that _build_repr builds the correct repr for an object\n    class DummyClass:\n            self.a = a\n            self.b = b\n\n    obj = DummyClass(a=5, b='test')\n    expected_repr = \"DummyClass(a=5, b='test')\"\n    assert _build_repr(obj) == expected_repr\n\n    obj2 = DummyClass()\n    expected_repr2 = \"DummyClass(a=0, b=None)\"\n    assert _build_repr(obj2) == expected_repr2\n"], "sample_40": ["def test_boundfield_auto_id(self):\n    # Test that auto_id is correctly passed to the widget.\n    form = Person()\n    field = form['first_name']\n    self.assertEqual(field.auto_id, 'id_first_name')\n    self.assertHTMLEqual(field.as_widget(), '<input id=\"id_first_name\" name=\"first_name\" type=\"text\">')\n\n    # Test that if the widget already has an id, auto_id does not override it.\n    form = PersonNew()\n    field = form['first_name']\n    self.assertEqual(field.auto_id, 'id_first_name')\n    self.assertHTMLEqual(field.as_widget(), '<input id=\"first_name_id\" name=\"first_name\" type=\"text\">')\n", "def test_boundfield_widget_type(self):\n    # Test that BoundField.widget_type returns the correct widget type.\n    class TestForm(Form):\n        field = CharField(widget=TextInput())\n\n    form = TestForm()\n    bound_field = form['field']\n    self.assertEqual(bound_field.widget_type, 'textinput')\n", "def test_boundfield_initial_value(self):\n    class MyForm(Form):\n        field1 = CharField(initial='initial value')\n\n    form = MyForm()\n    self.assertEqual(form['field1'].initial, 'initial value')\n    self.assertEqual(form['field1'].value(), 'initial value')\n\n    # If data is provided, it takes precedence over initial\n    form = MyForm({'field1': 'new value'})\n    self.assertEqual(form['field1'].initial, 'initial value')\n    self.assertEqual(form['field1'].value(), 'new value')\n", "def test_boundfield_errors(self):\n    class TestForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n\n    form = TestForm({'field1': 'value', 'field2': ''})\n    form.is_valid()\n    self.assertEqual(form['field1'].errors, [])\n    self.assertEqual(len(form['field2'].errors), 1)\n    self.assertIsInstance(form['field2'].errors, ErrorList)\n", "def test_bound_field_label_tag(self):\n    # Test label_tag() method of BoundField.\n    class MyForm(Form):\n        myfield = CharField(label='My Field', required=True)\n\n    form = MyForm()\n    expected = '<label for=\"id_myfield\">My Field:</label>'\n    self.assertHTMLEqual(form['myfield'].label_tag(), expected)\n\n    # Test the 'contents' parameter.\n    expected = '<label for=\"id_myfield\">My New Field:</label>'\n    self.assertHTMLEqual(form['myfield'].label_tag(contents='My New Field:'), expected)\n\n    # Test the 'attrs' parameter.\n    expected = '<label class=\"class1\" for=\"id_myfield\">My Field:</label>'\n    self.assertHTMLEqual(form['myfield'].label_tag(attrs={'class': 'class1'}), expected)\n\n    # Test with no 'for' attribute if id is not available.\n    class MyForm(Form):\n        myfield = CharField(label='My Field', widget=TextInput(attrs={'id': None}))\n\n    form = MyForm()\n    expected = 'My Field:'\n    self.assertHTMLEqual(form['myfield'].label_tag(), expected)\n"], "sample_128": ["def test_Domain_preprocess():\n    assert Domain.preprocess(ZZ) == ZZ\n    assert Domain.preprocess(QQ) == QQ\n    assert Domain.preprocess(EX) == EX\n    assert Domain.preprocess(RR) == RR\n    assert Domain.preprocess(CC) == CC\n    assert Domain.preprocess('ZZ') == ZZ\n    assert Domain.preprocess('QQ') == QQ\n    assert Domain.preprocess('EX') == EX\n    assert Domain.preprocess('RR') == RR\n    assert Domain.preprocess('CC') == CC\n    assert Domain.preprocess('FF(2)') == FF(2)\n    assert Domain.preprocess(GF(3)) == GF(3)\n    raises(OptionError, lambda: Domain.preprocess('Invalid'))\n", "def test_options():\n    raises(OptionError, lambda: Options({}, {'invalid': True}))\n\n    options = Options((x, y), {'domain': 'ZZ'})\n\n    assert options.gens == (x, y)\n    assert options.domain == ZZ\n    assert options.order == lex\n\n    raises(OptionError, lambda: Options((x, y), {'domain': 'Invalid'}))\n    raises(OptionError, lambda: Options((x, y), {'order': 'Invalid'}))\n\n    assert Options((x, y), {'domain': ZZ, 'order': 'lex'}).order == lex\n    assert Options((x, y), {'domain': ZZ, 'order': 'Invalid'}, strict=False).order == lex\n\n    raises(OptionError, lambda: Options((x, y), {'extension': 0}))\n    raises(OptionError, lambda: Options((x, y), {'extension': [1, 2, 3]}))\n\n    raises(OptionError, lambda: Options((x, y), {'modulus': 0}))\n    raises(OptionError, lambda: Options((x, y), {'modulus': 4.5}))\n\n    raises(OptionError, lambda: Options((x, y), {'gaussian': True, 'domain': 'ZZ'}))\n    raises(OptionError, lambda: Options((x, y), {'split': True, 'domain': 'ZZ'}))\n\n    raises(GeneratorsError, lambda: Options((x, x), {}))\n    raises(GeneratorsError, lambda: Options((x, Symbol('x', commutative=False)), {}))\n\n    raises(OptionError, lambda: Options((x, y), {'wrt': 'Invalid'}))\n    raises(OptionError, lambda: Options((x, y), {'sort': 'Invalid'}))\n", "def test_Options_clone():\n    options = Options((x, y), {'domain': 'ZZ', 'order': 'lex'})\n    cloned_options = options.clone({'order': 'ilex'})\n\n    assert options['domain'] == cloned_options['domain']\n    assert options['order'] != cloned_options['order']\n    assert cloned_options['order'] == sympy.polys.orderings.ilex\n", "def test_Options_clone():\n    opts = Options((x, y), {'domain': 'ZZ'})\n    assert opts.clone({'domain': 'QQ'}) == Options((x, y), {'domain': 'QQ'})\n    assert opts.clone() == opts\n    assert opts.clone({}) == opts\n", "def test_Options():\n    raises(OptionError, lambda: Options((x, y, z), {'gens': (x, y)}))\n    raises(OptionError, lambda: Options((x, y, z), {'domain': 'ZZ', 'field': True}))\n    raises(OptionError, lambda: Options((x, y, z), {'domain': 'ZZ', 'greedy': True}))\n    raises(OptionError, lambda: Options((x, y, z), {'domain': 'ZZ', 'split': True}))\n    raises(OptionError, lambda: Options((x, y, z), {'domain': 'ZZ', 'gaussian': True}))\n    raises(OptionError, lambda: Options((x, y, z), {'domain': 'ZZ', 'extension': I}))\n    raises(OptionError, lambda: Options((x, y, z), {'domain': 'ZZ', 'modulus': 2}))\n    raises(OptionError, lambda: Options((x, y, z), {'domain': 'ZZ', 'symmetric': True}))\n\n    opt = Options((x, y, z), {'domain': 'ZZ'})\n\n    assert opt.domain == ZZ\n    assert opt.gens == (x, y, z)\n    assert opt.args == {'domain': ZZ}\n    assert opt.options == {\n        'auto': False,\n        'domain': ZZ,\n        'expand': True,\n        'extension': None,\n        'field': False,\n        'formal': False,\n        'frac': False,\n        'gaussian': False,\n        'gens': (x, y, z),\n        'greedy': False,\n        'modulus': None,\n        'order': lex,\n        'polys': False,\n        'split': False,\n        'strict': True,\n        'symmetric': False,\n        'wrt': [],\n    }\n\n    assert opt.clone({'domain': 'QQ'}).domain == QQ\n"], "sample_73": ["def test_AnnotationBbox():\n    fig, ax = plt.subplots()\n    offsetbox = TextArea(\"Test\", minimumdescent=False)\n    ab = AnnotationBbox(offsetbox, (0.5, 0.5), xycoords='data',\n                        boxcoords=\"offset points\", arrowprops=dict(arrowstyle=\"->\"))\n    ax.add_artist(ab)\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    assert isinstance(ab.arrow_patch, mpatches.FancyArrowPatch)\n    assert ab.arrow_patch.get_mutation_scale() == ab.prop.get_size_in_points()\n    fig.canvas.draw()\n", "def test_offsetbox_children_visibility():\n    fig, ax = plt.subplots()\n    box = OffsetBox()\n    child1 = TextArea(\"Child 1\")\n    child2 = TextArea(\"Child 2\")\n    child2.set_visible(False)\n    box._children = [child1, child2]\n\n    visible_children = box.get_visible_children()\n    assert len(visible_children) == 1\n    assert visible_children[0] is child1\n", "def test_offsetbox_clip_children():\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100, clip=True)\n    ax.add_artist(da)\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n\n    # Add a child that extends beyond the parent box.\n    rect = mpatches.Rectangle((50, 50), 150, 50, fill=False)\n    da.add_artist(rect)\n\n    # Save the figure and compare it to the expected result.\n    @image_comparison(['offsetbox_clip_children'], remove_text=True)\n        return fig\n", "def test_AnnotationBbox_offsetbox():\n    fig, ax = plt.subplots()\n    offsetbox = TextArea(\"Test\", textprops=dict(color=\"r\"))\n    ab = AnnotationBbox(offsetbox, (0.5, 0.5), xycoords='data',\n                        boxcoords=\"offset points\",\n                        box_alignment=(0., 0.))\n    ax.add_artist(ab)\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n\n        fig.canvas.draw()\n        assert_allclose(ab.offsetbox.get_offset(), (72, 72))\n\n    do_test()\n\n    # Check that zooming changes the position of the box but not its content.\n    with pytest.raises(AssertionError):\n        ax.set_xlim(0, 2)\n        do_test()\n\n    offsetbox.set_text(\"Something else\")\n    do_test()\n", "def test_offsetbox_pick():\n    fig, ax = plt.subplots()\n    box = TextArea(\"Test\")\n    offsetbox = AnnotationBbox(box, (0.5, 0.5), xycoords='data',\n                               boxcoords=\"offset points\", pad=0.25)\n    ax.add_artist(offsetbox)\n\n        if event.artist == offsetbox:\n            assert event.mouseevent.button == MouseButton.LEFT\n\n    fig.canvas.mpl_connect('pick_event', onpick)\n\n    mouse_event = MouseEvent(\n        'button_press_event', fig.canvas, 0.5, 0.5, button=MouseButton.LEFT)\n    offsetbox.pick(mouse_event)\n"], "sample_111": ["def test_perfect_labelings():\n    # Perfect labelings are both homogeneous and complete, hence have score 1.0\n    for metric in NORMALIZED_METRICS:\n        assert SUPERVISED_METRICS[metric](y1, y1) == pytest.approx(1.0)\n", "def test_perfect_labeling_scores():\n    # A perfect labeling should return 1 for all the metrics\n    y_true = np.array([0, 0, 0, 1, 1, 1])\n    y_pred = np.array([0, 0, 0, 1, 1, 1])\n\n    for name, metric in SUPERVISED_METRICS.items():\n        assert_allclose(metric(y_true, y_pred), 1.0)\n", "def test_check_clusterings():\n    # test that invalid inputs raise the correct errors\n    with pytest.raises(ValueError):\n        check_clusterings(labels_true=np.array([[1, 2], [3, 4]]), labels_pred=[1, 2, 3, 4])\n    with pytest.raises(ValueError):\n        check_clusterings(labels_true=[1, 2, 3, 4], labels_pred=np.array([[1, 2], [3, 4]]))\n    with pytest.raises(ValueError):\n        check_clusterings(labels_true=[1, 2, 3, 4], labels_pred=[1, 2, 3])\n\n    # test that valid inputs are returned correctly\n    labels_true = np.array([1, 2, 3, 4])\n    labels_pred = np.array([1, 2, 3, 4])\n    checked_labels_true, checked_labels_pred = check_clusterings(labels_true, labels_pred)\n    assert_allclose(checked_labels_true, labels_true)\n    assert_allclose(checked_labels_pred, labels_pred)\n", "def test_check_clusterings():\n    # check that invalid input types raise the correct errors\n    invalid_inputs = [\n        (np.array([[1, 2], [3, 4]]), np.array([1, 2])),  # y_true is not 1D\n        (np.array([1, 2]), np.array([[1, 2], [3, 4]])),  # y_pred is not 1D\n        (np.array([1, 2]), np.array([1, 2, 3])),  # y_true and y_pred are not of same length\n    ]\n\n    for y_true, y_pred in invalid_inputs:\n        with pytest.raises(ValueError):\n            check_clusterings(y_true, y_pred)\n\n    # check that valid input types do not raise an error\n    valid_inputs = [\n        (np.array([1, 2]), np.array([1, 2])),\n        (np.array([1, 2]), np.array([2, 1])),\n    ]\n\n    for y_true, y_pred in valid_inputs:\n        check_clusterings(y_true, y_pred)\n", "def test_check_clusterings():\n    # test that we raise an error on non-1D arrays\n    y1 = np.array([[1, 2], [3, 4]])\n    y2 = np.array([1, 2, 3, 4])\n    with pytest.raises(ValueError):\n        check_clusterings(y1, y2)\n\n    # test that we raise an error when inputs are not of same length\n    y1 = np.array([1, 2, 3])\n    y2 = np.array([1, 2, 3, 4])\n    with pytest.raises(ValueError):\n        check_clusterings(y1, y2)\n\n    # check that arrays with non-integer dtypes get converted to integer\n    y1 = np.array([1.0, 2.0, 3.0])\n    y2 = np.array([1, 2, 3])\n    y1_checked, y2_checked = check_clusterings(y1, y2)\n    assert y1_checked.dtype.kind == 'i'\n    assert y2_checked.dtype.kind == 'i'\n\n    # check that arrays with object dtype (e.g., strings) get converted to integer\n    y1 = np.array(['a', 'b', 'c'])\n    y2 = np.array([1, 2, 3])\n    y1_checked, y2_checked = check_clusterings(y1, y2)\n    assert y1_checked.dtype.kind == 'i'\n    assert y2_checked.dtype.kind == 'i'\n"], "sample_151": ["def test_point_transform():\n    p = Point(1, 2)\n    assert p.transform(Matrix([[1, 0, 1], [0, 1, 1], [0, 0, 1]])) == Point(2, 3)\n\n    p3d = Point3D(1, 2, 3)\n    assert p3d.transform(Matrix([[1, 0, 0, 1], [0, 1, 0, 1], [0, 0, 1, 1], [0, 0, 0, 1]])) == Point3D(2, 3, 4)\n", "def test_point_transform():\n    p = Point(1, 1)\n    assert p.transform(Matrix([[1, 0, 1], [0, 1, 1], [0, 0, 1]])) == Point(2, 2)\n    p3d = Point3D(1, 1, 1)\n    assert p3d.transform(Matrix([[1, 0, 0, 1], [0, 1, 0, 1], [0, 0, 1, 1], [0, 0, 0, 1]])) == Point3D(2, 2, 2)\n", "def test_point_transform():\n    p = Point(1, 2)\n    assert p.transform(Matrix([[1, 0, 1], [0, 1, 1], [0, 0, 1]])) == Point(2, 3)\n    p3d = Point3D(1, 2, 3)\n    assert p3d.transform(Matrix([[1, 0, 0, 1], [0, 1, 0, 1], [0, 0, 1, 1], [0, 0, 0, 1]])) == Point3D(2, 3, 4)\n", "def test_point_orthogonal_direction():\n    p1 = Point(1, 2, 3)\n    p2 = p1.orthogonal_direction\n    assert p1.dot(p2) == 0\n    assert p2 != Point(0, 0, 0)\n\n    p1 = Point2D(1, 2)\n    p2 = p1.orthogonal_direction\n    assert p1.dot(p2) == 0\n    assert p2 != Point(0, 0)\n", "def test_point_transform():\n    p = Point(1, 1)\n    assert p.transform(Matrix([[1, 0, 1], [0, 1, 1], [0, 0, 1]])) == Point(2, 2)\n    p3d = Point3D(1, 1, 1)\n    assert p3d.transform(Matrix([[1, 0, 0, 1], [0, 1, 0, 1], [0, 0, 1, 1], [0, 0, 0, 1]])) == Point3D(2, 2, 2)\n"], "sample_54": ["def test_escapejs(self):\n    # Ensure escapejs() escapes characters correctly\n    self.check_output(escapejs, \"some\\njavascript\", 'some\\\\u003Cjavascript')\n    self.check_output(escapejs, \"some\\rjavascript\", 'some\\\\u003Cjavascript')\n    self.check_output(escapejs, \"some\\ujavascript\", 'some\\\\u005Cujavascript')\n    self.check_output(escapejs, \"<some>javascript\", '\\\\u003Csome\\\\u003Ejavascript')\n    self.check_output(escapejs, \"some'javascript\", \"some\\\\u0027javascript\")\n    self.check_output(escapejs, 'some\"javascript', 'some\\\\u0022javascript')\n    self.check_output(escapejs, \"some&javascript\", \"some\\\\u0026javascript\")\n", "def test_escapejs(self):\n    self.check_output(escapejs, \"hello world\")\n    self.check_output(escapejs, \"hello\\ world\")\n    self.check_output(escapejs, \"hello\\nworld\", r\"hello\\u000Aworld\")\n    self.check_output(escapejs, \"<script>alert('hello')</script>\", r\"\\u003Cscript\\u003Ealert\\(\\'hello\\'\\)\\u003C\\/script\\u003E\")\n\n    # Make sure that non-ASCII characters are handled properly.\n    self.check_output(escapejs, \"\\xc3\\xbcmlaut\", \"\\\\u00FCmlaut\")\n    self.check_output(escapejs, \"\\u2028\", \"\\\\u2028\")  # U+2028: line separator\n    self.check_output(escapejs, \"\\u2029\", \"\\\\u2029\")  # U+2029: paragraph separator\n", "def test_html_escape(self):\n    self.check_output(escape, \"<script>alert('XSS')</script>\", \"&lt;script&gt;alert(&#x27;XSS&#x27;)&lt;/script&gt;\")\n    self.check_output(escape, \"Hello, world!\", \"Hello, world!\")\n    self.check_output(escape, \"\", \"\")\n", "def test_escapejs(self):\n    # Make sure escapejs works correctly with non-ASCII characters and doesn't escape them.\n    value = \"h\u00ebll\u00f6\"\n    self.check_output(escapejs, value)\n    # Make sure escapejs works correctly with escaped characters.\n    value = \"<hello>\"\n    output = \"\\\\u003Chello\\\\u003E\"\n    self.check_output(escapejs, value, output)\n    # Make sure escapejs works correctly with newline and tab characters.\n    value = \"\\n\\t\"\n    output = \"\\\\u000A\\\\u0009\"\n    self.check_output(escapejs, value, output)\n    # Make sure escapejs works correctly with double quotes and backslashes.\n    value = '\"\\\\'\n    output = \"\\\\u0022\\\\\\\\\"\n    self.check_output(escapejs, value, output)\n", "def test_escapejs(self):\n    # Make sure escapejs works with a variety of inputs\n    self.check_output(escapejs, 'a\"b')\n    self.check_output(escapejs, \"a'b\")\n    self.check_output(escapejs, \"a\\\\b\")\n    self.check_output(escapejs, \"\\n\")\n    self.check_output(escapejs, \"\\t\")\n    self.check_output(escapejs, \"\\x07\")  # BEL\n    self.check_output(escapejs, \"\\u2028\")  # LINE SEPARATOR\n    self.check_output(escapejs, \"\\u2029\")  # PARAGRAPH SEPARATOR\n    self.check_output(escapejs, \"</script>\")\n"], "sample_148": ["def test_polar_lift():\n    p = Symbol('p', polar=True)\n    x = Symbol('x')\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(I + 2) == polar_lift(2 + I)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*p) == 4*p\n", "def test_polar_lift():\n    p = Symbol('p', polar=True)\n    x = Symbol('x')\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(I + 2) == polar_lift(2 + I)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*p) == 4*p\n", "def test_principal_branch():\n    x = Symbol('x')\n    assert principal_branch(x, oo) == x\n    assert principal_branch(exp_polar(2*pi*I)*3, 2*pi) == 3*exp_polar(0)\n    assert principal_branch(exp_polar(2*pi*I)*3*x, 2*pi) == 3*principal_branch(x, 2*pi)\n    assert N_equals(principal_branch(exp_polar(pi*I/4)*3, 2*pi).evalf(), 3*exp_polar(I*pi/4))\n", "def test_principal_branch_periodic_argument():\n    z = symbols('z', polar=True)\n    p = symbols('p', positive=True)\n\n    assert principal_branch(exp_polar(2*pi*I)*3, 2*pi) == 3*exp_polar(0)\n    assert principal_branch(exp_polar(5*I*pi), pi) == exp_polar(I*pi)\n    assert principal_branch(exp_polar(7*I*pi), 4*pi) == exp_polar(-I*pi)\n\n    assert periodic_argument(exp_polar(10*I*pi), 2*pi) == 0\n    assert periodic_argument(exp_polar(5*I*pi), 4*pi) == pi\n    assert periodic_argument(exp_polar(7*I*pi), pi) == -pi/2\n\n    assert principal_branch(z, oo) == z\n    assert principal_branch(z, p) != z\n", "def test_principal_branch_periodic_argument():\n    x = Symbol('x')\n    assert N_equals(periodic_argument(principal_branch(exp_polar(10*pi*I), 2*pi), 2*pi), 0)\n    assert N_equals(periodic_argument(principal_branch(exp_polar(5*pi*I), 4*pi), 4*pi), pi)\n    assert N_equals(periodic_argument(principal_branch(exp_polar(5*pi*I)*x, 2*pi), 2*pi), arg(x))\n"], "sample_155": ["def test_UnitSystem_get_dimensional_expr():\n    # Create a unit system\n    unit_system = UnitSystem((meter, second), name=\"SI\")\n\n    # Test get_dimensional_expr with different types of expressions\n    assert unit_system.get_dimensional_expr(meter) == length.name\n    assert unit_system.get_dimensional_expr(second) == time.name\n    assert unit_system.get_dimensional_expr(meter/second) == length.name / time.name\n    assert unit_system.get_dimensional_expr(meter**2) == length.name**2\n    assert unit_system.get_dimensional_expr(sin(meter)) == sin(length.name)\n    assert unit_system.get_dimensional_expr(diff(meter, second)) == length.name / time.name\n\n    # Test with an Add expression\n    expr = meter + second\n    assert unit_system.get_dimensional_expr(expr) == length.name\n\n    # Test with a Derivative expression\n    expr = diff(meter, second)\n    assert unit_system.get_dimensional_expr(expr) == length.name / time.name\n\n    # Test with a Function expression\n    expr = sin(meter)\n    assert unit_system.get_dimensional_expr(expr) == sin(length.name)\n\n    # Test with a Mul expression\n    expr = meter * second\n    assert unit_system.get_dimensional_expr(expr) == length.name * time.name\n", "def test_unit_system_get_dimensional_expr():\n    u = UnitSystem(base_units=(meter, kilogram, second), name=\"SI\")\n    q = Quantity(\"q\", length)\n    assert u.get_dimensional_expr(q) == length.name\n\n    expr = q * q\n    assert u.get_dimensional_expr(expr) == length.name**2\n\n    expr = q + q\n    assert u.get_dimensional_expr(expr) == length.name\n\n    expr = sin(q)\n    assert u.get_dimensional_expr(expr) == 1\n\n    expr = diff(q, symbols(\"x\"))\n    assert u.get_dimensional_expr(expr) == length.name / Dimension(1)\n", "def test_UnitSystem_get_dimensional_expr():\n    us = UnitSystem(base_units=(meter, kilogram, second), name=\"SI\")\n    q1 = Quantity(\"q1\", length)\n    q2 = Quantity(\"q2\", mass)\n    expr = q1 * q2 / second\n    assert us.get_dimensional_expr(expr) == length * mass / time\n\n    expr = q1 + q2  # Add is not supported for quantities with different dimensions\n    raises(ValueError, lambda: us.get_dimensional_expr(expr))\n\n    expr = diff(q1, symbols('t'))\n    assert us.get_dimensional_expr(expr) == length / time\n\n    expr = sin(q1)\n    assert us.get_dimensional_expr(expr) == S.One\n", "def test_unit_system_get_dimensional_expr():\n    u = UnitSystem(base_units=(meter, kilogram, second), name=\"SI\")\n    q1 = Quantity(\"q1\", length)\n    q2 = Quantity(\"q2\", time)\n    assert u.get_dimensional_expr(q1) == length.name\n    assert u.get_dimensional_expr(q2) == time.name\n    assert u.get_dimensional_expr(q1 * q2) == length.name * time.name\n    assert u.get_dimensional_expr(q1 / q2) == length.name / time.name\n    assert u.get_dimensional_expr(q1 ** 2) == length.name ** 2\n\n    f = Function(\"f\")\n    assert u.get_dimensional_expr(f(q1)) == f(length.name)\n    assert u.get_dimensional_expr(f(q1, q2)) == f(length.name, time.name)\n\n    d = diff(q1, q2)\n    assert u.get_dimensional_expr(d) == length.name / time.name\n", "def test_get_dimensional_expr():\n    u = UnitSystem((meter, second), name=\"MS\")\n    q1 = Quantity(\"q1\", length)\n    q2 = Quantity(\"q2\", time)\n    assert u.get_dimensional_expr(q1) == length.name\n    assert u.get_dimensional_expr(q2) == time.name\n    assert u.get_dimensional_expr(q1 + q2) == length.name  # should return the dimension of the first arg\n    assert u.get_dimensional_expr(q1 * q2) == length.name * time.name\n    assert u.get_dimensional_expr(q1 / q2) == length.name / time.name\n    assert u.get_dimensional_expr(diff(q1, q2)) == length.name / time.name\n"], "sample_83": ["def test_colorized_text_reporter_message_coloring(reporter, capsys):\n    class TestColorizedTextReporter(ColorizedTextReporter):\n        COLOR_MAPPING = {\n            \"I\": MessageStyle(\"green\"),\n            \"W\": MessageStyle(\"magenta\"),\n            \"E\": MessageStyle(\"red\", (\"bold\",)),\n        }\n\n    reporter = TestColorizedTextReporter()\n\n    message_warning = Message(\n        \"warning\",\n        \"test warning\",\n        \"W1234\",\n        \"test\",\n        \"module\",\n        \"\",\n        1,\n        1,\n        1,\n        1,\n        \"\",\n        HIGH,\n    )\n\n    message_error = Message(\n        \"error\",\n        \"test error\",\n        \"E1234\",\n        \"test\",\n        \"module\",\n        \"\",\n        1,\n        1,\n        1,\n        1,\n        \"\",\n        HIGH,\n    )\n\n    reporter.handle_message(message_warning)\n    reporter.handle_message(message_error)\n\n    captured = capsys.readouterr()\n    assert \"\\033[35m\" in captured.out  # magenta color for warning\n    assert \"\\033[31;1m\" in captured.out  # red and bold for error\n", "def test_colorize_ansi(msg_style, expected_output):\n    assert colorize_ansi(\"message\", msg_style) == expected_output\n", "def test_text_reporter_colorize_ansi_deprecation_warning(recwarn: WarningsRecorder) -> None:\n    \"\"\"Test that colorize_ansi raises a DeprecationWarning when called with deprecated parameters.\"\"\"\n    with recwarn:\n        TextReporter().colorize_ansi(\"message\", \"red\", style=\"bold\")\n        assert len(recwarn.list) == 1\n        assert recwarn.list[0].category == DeprecationWarning\n", "def test_text_reporter_handle_message(reporter, capsys):\n    \"\"\"Test TextReporter handle_message method\"\"\"\n    msg = Message(\n        \"test\",\n        \"test message\",\n        \"test\",\n        \"test\",\n        HIGH,\n        (1, 0),\n        None,\n        \"module\",\n        \"\",\n        \"\",\n        (\"\", \"\"),\n    )\n    rep = reporter()\n    rep.handle_message(msg)\n    captured = capsys.readouterr()\n    assert \"************* Module module\" in captured.out\n    assert \"test:1:0: test: test message (test)\" in captured.out\n\n", "def test_colorized_text_reporter_color_mapping(caplog):\n    reporter = ColorizedTextReporter()\n    msg = Message(\"msg\", \"msg_id\", \"C\", None, \"module\", \"obj\", HIGH)\n    reporter.handle_message(msg)\n    assert caplog.records[-1].msg == \"************* Module module\\n\"\n    # Test with custom color mapping\n    color_mapping = {\"C\": (\"red\", \"bold\")}\n    reporter = ColorizedTextReporter(color_mapping=color_mapping)\n    reporter.handle_message(msg)\n    assert caplog.records[-1].msg == f\"\\033[31;1m************* Module {msg.module}\\033[0m\\n\"\n\n    # Test deprecated color mapping\n    color_mapping_deprecated = {\"C\": (\"red\", \"bold italic\")}\n    with pytest.warns(DeprecationWarning):\n        reporter = ColorizedTextReporter(color_mapping=color_mapping_deprecated)\n    reporter.handle_message(msg)\n    assert caplog.records[-1].msg == f\"\\033[31;1;3m************* Module {msg.module}\\033[0m\\n\"\n"], "sample_43": ["def test_get_paginator(self):\n    request = self.factory.get(self.url, data=self.opts)\n    view = AutocompleteJsonView.as_view(**self.as_view_args)\n    response = view(request)\n    paginator = response.context_data['paginator']\n    self.assertEqual(paginator.count, Answer.objects.count())\n    self.assertEqual(paginator.num_pages, (Answer.objects.count() + PAGINATOR_SIZE - 1) // PAGINATOR_SIZE)\n", "def test_get_paginator(self):\n    request = self.factory.get(self.url, data=self.opts)\n    view = AutocompleteJsonView.as_view(**self.as_view_args)\n    response = view(request)\n    paginator = response.context_data['paginator']\n    self.assertEqual(paginator.count, Answer.objects.count())\n    self.assertEqual(paginator.num_pages, (Answer.objects.count() + PAGINATOR_SIZE - 1) // PAGINATOR_SIZE)\n", "def test_process_request_success(self):\n    request = self.factory.get(self.url, data=self.opts)\n    view = AutocompleteJsonView.as_view(**self.as_view_args)\n    response = view(request)\n    self.assertEqual(response.status_code, 200)\n\n    # Check that process_request sets the correct attributes on the view.\n    view_instance = AutocompleteJsonView(**self.as_view_args)\n    view_instance.request = request\n    term, model_admin, source_field, to_field_name = view_instance.process_request(request)\n    self.assertEqual(term, '')\n    self.assertIsInstance(model_admin, QuestionAdmin)\n    self.assertEqual(source_field.name, 'question')\n    self.assertEqual(to_field_name, 'id')\n", "def test_get_paginator(self):\n    request = self.factory.get(self.url, self.opts)\n    request.user = self.user\n    view = AutocompleteJsonView.as_view(**self.as_view_args)\n    response = view(request)\n    paginator = response.context_data['paginator']\n    self.assertIsInstance(paginator, type(AuthorAdmin.get_paginator(request, Answer.objects.all(), 20)))\n", "def test_process_request(self):\n    request = self.factory.get(self.url, self.opts)\n    view = AutocompleteJsonView.as_view(**self.as_view_args)\n    response = view(request)\n    self.assertEqual(response.status_code, 200)\n\n    # Test with missing parameters\n    for key in ['app_label', 'model_name', 'field_name']:\n        opts = self.opts.copy()\n        del opts[key]\n        request = self.factory.get(self.url, opts)\n        with self.assertRaises(PermissionDenied):\n            view(request)\n\n    # Test with invalid app_label\n    opts = self.opts.copy()\n    opts['app_label'] = 'invalid_app'\n    request = self.factory.get(self.url, opts)\n    with self.assertRaises(PermissionDenied):\n        view(request)\n\n    # Test with invalid model_name\n    opts = self.opts.copy()\n    opts['model_name'] = 'invalid_model'\n    request = self.factory.get(self.url, opts)\n    with self.assertRaises(PermissionDenied):\n        view(request)\n\n    # Test with invalid field_name\n    opts = self.opts.copy()\n    opts['field_name'] = 'invalid_field'\n    request = self.factory.get(self.url, opts)\n    with self.assertRaises(PermissionDenied):\n        view(request)\n"], "sample_137": ["def test_roundrobin():\n    from sympy.utilities.iterables import roundrobin\n    assert list(roundrobin('ABC', 'D', 'EF')) == ['A', 'D', 'E', 'B', 'F', 'C']\n    assert list(roundrobin([1, 2, 3], [4, 5], [6, 7, 8, 9])) == [1, 4, 6, 2, 5, 7, 3, 8, 9]\n", "def test_roundrobin():\n    from sympy.utilities.iterables import roundrobin\n    assert list(roundrobin('ABC', 'D', 'EF')) == ['A', 'D', 'E', 'B', 'F', 'C']\n    assert list(roundrobin([1, 2], [3, 4], [5, 6])) == [1, 3, 5, 2, 4, 6]\n    assert list(roundrobin([], [1, 2, 3], ['a', 'b'])) == [1, 'a', 2, 'b', 3]\n", "def test_postorder_traversal():\n    expr = w + (x + y)*z\n    expected = [z, y, x, x + y, z*(x + y), w, w + z*(x + y)]\n    assert list(postorder_traversal(expr)) == expected\n\n    # with keys\n    expected = [w, z, x, y, x + y, z*(x + y), w + z*(x + y)]\n    assert list(postorder_traversal(expr, keys=True)) == expected\n", "def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [\n        (0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((1, 1, 1))) == [\n        (1, 1, 1), (-1, 1, 1), (1, -1, 1), (-1, -1, 1),\n        (1, 1, -1), (-1, 1, -1), (1, -1, -1), (-1, -1, -1)]\n", "def test_rotations():\n    assert list(rotations([1, 2, 3])) == [[1, 2, 3], [2, 3, 1], [3, 1, 2]]\n    assert list(rotations([1, 2, 3], -1)) == [[1, 2, 3], [3, 1, 2], [2, 3, 1]]\n    assert list(rotations([1, 2, 3, 4])) == [[1, 2, 3, 4], [2, 3, 4, 1], [3, 4, 1, 2], [4, 1, 2, 3]]\n    assert list(rotations([1, 2, 3, 4], -1)) == [[1, 2, 3, 4], [4, 1, 2, 3], [3, 4, 1, 2], [2, 3, 4, 1]]\n    assert list(rotations([])) == []\n    assert list(rotations([1])) == [[1]]\n    assert list(rotations([1, 2])) == [[1, 2], [2, 1]]\n"], "sample_68": ["def test_bulk_create_conflict_update(self):\n    Country.objects.create(name=\"United States of America\", iso_two_letter=\"US\")\n    with self.assertRaises(IntegrityError):\n        Country.objects.bulk_create(\n            [Country(name=\"The Netherlands\", iso_two_letter=\"US\")],\n            update_conflicts=True,\n            update_fields=[\"name\"],\n            unique_fields=[\"iso_two_letter\"],\n        )\n", "def test_bulk_create_nullable_fields(self):\n    data = [\n        NullableFields(f1=\"foo\", f2=None),\n        NullableFields(f1=None, f2=\"bar\"),\n        NullableFields(f1=\"baz\", f2=\"qux\"),\n    ]\n    NullableFields.objects.bulk_create(data)\n    self.assertEqual(NullableFields.objects.count(), 3)\n", "def test_bulk_create_empty(self):\n    self.assertEqual(Country.objects.bulk_create([]), [])\n", "def test_bulk_create_with_conflict_update_fields(self):\n    Country.objects.create(name=\"United States of America\", iso_two_letter=\"US\")\n    new_country = Country(name=\"USA\", iso_two_letter=\"US\")\n    try:\n        Country.objects.bulk_create([new_country], update_conflicts=True, update_fields=[\"name\"])\n    except NotSupportedError:\n        self.skipTest(\"This database backend does not support updating conflicts.\")\n    country = Country.objects.get(iso_two_letter=\"US\")\n    self.assertEqual(country.name, \"USA\")\n", "def test_bulk_create_conflict_update_fields(self):\n    Country.objects.create(name=\"United States of America\", iso_two_letter=\"US\")\n    countries = [\n        Country(name=\"United States of America\", iso_two_letter=\"US\"),\n        Country(name=\"The Netherlands\", iso_two_letter=\"NL\"),\n    ]\n    with self.assertRaises(ValueError) as cm:\n        Country.objects.bulk_create(\n            countries,\n            update_conflicts=True,\n            update_fields=(\"name\",),\n            unique_fields=(\"iso_two_letter\",),\n        )\n    self.assertIn(\"bulk_create() cannot be used with primary key fields in update_fields.\", str(cm.exception))\n"], "sample_119": ["def test_print_Function():\n    assert mcode(f(x)) == \"f[x]\"\n    assert mcode(sin(x)) == \"Sin[x]\"\n    assert mcode(exp(x)) == \"Exp[x]\"\n", "def test_Pow():\n    assert mcode(x**2) == 'x^2'\n    assert mcode(x**(y**2)) == 'x^(y^2)'\n    assert mcode((x**y)**2) == '(x^y)^2'\n", "def test_mcode_user_functions():\n    x = symbols('x')\n    f = Function('f')\n    g = Function('g')\n\n    assert mcode(f(x)) == 'f[x]'\n\n    settings = {'user_functions': {'f': 'myFunc', 'g': 'yourFunc'}}\n    assert mcode(f(x), **settings) == 'myFunc[x]'\n    assert mcode(g(x), **settings) == 'yourFunc[x]'\n\n    # test multiple conditions for a user function\n    settings = {'user_functions': {'f': [(lambda x: x.is_integer, 'myFuncInt'), (lambda x: True, 'myFunc')]}}\n    assert mcode(f(1), **settings) == 'myFuncInt[1]'\n    assert mcode(f(x), **settings) == 'myFunc[x]'\n", "def test_print_Function():\n    assert mcode(f(x)) == \"f[x]\"\n    assert mcode(sin(x)) == \"Sin[x]\"\n    assert mcode(exp(x)) == \"Exp[x]\"\n    g = Function('g')\n    assert mcode(g(x, y)) == \"g[x, y]\"\n    assert mcode(sin(x).func) == \"Sin\"\n", "def test_infinity():\n    assert mcode(oo) == 'Infinity'\n    assert mcode(-oo) == '-Infinity'\n"], "sample_79": ["def test_concat_coords_data_vars_conflict():\n    # Test that concat fails when a variable is in coords for one dataset and\n    # data_vars for another.\n    ds1 = Dataset()\n    ds1[\"x\"] = (\"x\", [1])\n    ds2 = Dataset(coords={\"x\": (\"x\", [1])})\n    with raises_regex(ValueError, \"Variable x is a coordinate in some datasets but not others\"):\n        concat([ds1, ds2], dim=\"x\")\n", "def test_concat_dataset_coords():\n    # Test that concatenating datasets with coords works as expected\n    ds1 = Dataset()\n    ds1['x'] = ('x', [1, 2])\n    ds1.coords['y'] = ('y', [10, 20])\n\n    ds2 = Dataset()\n    ds2['x'] = ('x', [3, 4])\n    ds2.coords['y'] = ('y', [30, 40])\n\n    expected = Dataset()\n    expected['x'] = ('x', [1, 2, 3, 4])\n    expected.coords['y'] = ('y', [10, 20, 30, 40])\n\n    result = concat([ds1, ds2], dim='x')\n    assert_identical(result, expected)\n", "def test_concat_coords_data_vars_conflict():\n    # Test that concat fails when a variable is in coords for one dataset and\n    # data_vars for another.\n    ds1 = Dataset()\n    ds1[\"x\"] = (\"x\", [1])\n    ds2 = Dataset(coords={\"x\": (\"x\", [1])})\n    with raises_regex(ValueError, \"Variable x is a coordinate in some datasets but not others\"):\n        concat([ds1, ds2], dim=\"x\")\n", "def test_concat_dataset_with_dim_coords():\n    # Test concatenating datasets with dimension coordinates\n    ds1 = Dataset(\n        coords={\"x\": (\"x\", [1, 2, 3]), \"y\": (\"y\", [4, 5, 6])},\n        data_vars={\"z\": ((\"x\", \"y\"), np.random.rand(3, 3))},\n    )\n    ds2 = Dataset(\n        coords={\"x\": (\"x\", [7, 8, 9]), \"y\": (\"y\", [10, 11, 12])},\n        data_vars={\"z\": ((\"x\", \"y\"), np.random.rand(3, 3))},\n    )\n\n    result = concat([ds1, ds2], dim=\"new_dim\")\n    expected = Dataset(\n        coords={\n            \"new_dim\": (\"new_dim\", [0, 1]),\n            \"x\": (\"new_dim\", \"x\", [[1, 2, 3], [7, 8, 9]]),\n            \"y\": (\"new_dim\", \"y\", [[4, 5, 6], [10, 11, 12]]),\n        },\n        data_vars={\"z\": ((\"new_dim\", \"x\", \"y\"), np.vstack([ds1.z.values, ds2.z.values]))},\n    )\n    assert_identical(result, expected)\n", "def test_concat_coords_different_length():\n    # regression test for GH1625\n    ds1 = Dataset(coords={\"x\": [0, 1]})\n    ds2 = Dataset(coords={\"x\": [0, 1, 2]})\n\n    expected = Dataset(coords={\"x\": [0, 1, 2]})\n    actual = concat([ds1, ds2], dim=\"y\")\n    assert_identical(actual, expected)\n"], "sample_88": ["def test_saferepr_dispatches_to_pformat():\n    class PrettyObject:\n            return \"PrettyObject()\"\n\n    obj = [PrettyObject() for _ in range(10)]\n\n    # make sure that the normal repr is not the same as the pretty repr\n    assert repr(obj) != _pformat_dispatch(obj)\n\n    # check that saferepr dispatches to pformat\n    assert saferepr(obj) == _pformat_dispatch(obj)\n", "def test_saferepr_dispatching_pretty_printer():\n    class CustomClass:\n            return \"CustomClass()\"\n\n    obj = CustomClass()\n    expected = \"CustomClass()\"\n    assert saferepr(obj) == expected\n    assert _pformat_dispatch(obj) == expected\n", "def test_saferepr_recursive():\n    class RecursiveRepr:\n            return saferepr(self)\n\n    r = RecursiveRepr()\n    assert \"unpresentable exception\" in saferepr(r)\n", "def test_saferepr_with_recursive_object():\n    class RecursiveObject:\n            return \"RecursiveObject(\" + repr(self) + \")\"\n\n    obj = RecursiveObject()\n    result = saferepr(obj, maxsize=100)\n    assert len(result) <= 100\n    assert \"RecursiveObject\" in result\n    assert \"...\" in result  # ellipsis due to recursion limit\n", "def test_saferepr_with_recursive_object():\n    class RecursiveObject:\n            return repr(self)\n\n    obj = RecursiveObject()\n    result = saferepr(obj, maxsize=100)\n    assert \"RecursionError\" in result\n    assert \"raised in repr()\" in result\n"], "sample_21": ["def test_sort(self):\n    collector = Collector(using='default')\n    a = create_a()\n    collector.collect([a])\n    self.assertEqual(list(collector.data), [A])\n    b = B.objects.create(a=a)\n    collector.collect([b])\n    # A is listed before B because of the fk from B to A.\n    self.assertEqual(list(collector.data), [B, A])\n    collector.sort()\n    # The order doesn't change as B has a dependency on A.\n    self.assertEqual(list(collector.data), [B, A])\n", "def test_related_objects(self):\n    collector = Collector(using=\"default\")\n    r1 = R.objects.create()\n    r2 = R.objects.create()\n    m1 = M.objects.create(r=r1)\n    m2 = M.objects.create(r=r1)\n    m3 = M.objects.create(r=r2)\n\n    related_objects = collector.related_objects(R, [R._meta.get_field(\"m\")], [r1])\n    self.assertQuerysetEqual(related_objects, [m1, m2], ordered=False)\n\n    related_objects = collector.related_objects(R, [R._meta.get_field(\"m\")], [r2])\n    self.assertQuerysetEqual(related_objects, [m3], ordered=False)\n", "def test_cascade_deletion(self):\n    collector = Collector(using='default')\n    a = create_a()\n    collector.collect([a])\n    with self.assertNumQueries(4):\n        deleted, _ = collector.delete()\n    self.assertEqual(deleted, 3)\n    self.assertQuerysetEqual(A.objects.all(), [])\n    self.assertQuerysetEqual(B.objects.all(), [])\n    self.assertQuerysetEqual(C.objects.all(), [])\n", "def test_collector_sorts_models_in_correct_order(self):\n    collector = Collector(using='default')\n    a = create_a()\n    b = B.objects.create(a=a)\n    c = Child.objects.create(b=b)\n\n    collector.collect([a])\n    self.assertIn(A, collector.data)\n    self.assertIn(B, collector.data)\n    self.assertIn(Child, collector.data)\n\n    # Simulate the order of models as it would be returned by the database\n    collector.data = {Child: collector.data[Child], A: collector.data[A], B: collector.data[B]}\n    collector.sort()\n\n    # Verify that the models are in the correct order after sorting\n    self.assertEqual(list(collector.data.keys()), [A, B, Child])\n", "def test_sort(self):\n    collector = Collector(using='default')\n    a = create_a()\n    b = B.objects.create(a=a)\n    c = B.objects.create(a=a)\n\n    collector.add([a])\n    collector.add([b])\n    collector.add([c])\n\n    self.assertEqual(list(collector.data.keys()), [A, B, B])\n    collector.sort()\n    self.assertEqual(list(collector.data.keys()), [B, B, A])\n"], "sample_69": ["def test_artist_aliases():\n    line = mlines.Line2D([0, 1], [0, 1])\n    assert martist.getp(line, 'lw') == martist.getp(line, 'linewidth')\n    assert martist.getp(line, 'ls') == martist.getp(line, 'linestyle')\n    assert martist.getp(line, 'c') == martist.getp(line, 'color')\n    assert martist.getp(line, 'fc') == martist.getp(line, 'facecolor')\n    assert martist.getp(line, 'ec') == martist.getp(line, 'edgecolor')\n    assert martist.getp(line, 'mfc') == martist.getp(line, 'markerfacecolor')\n    assert martist.getp(line, 'mec') == martist.getp(line, 'markeredgecolor')\n    assert martist.getp(line, 'mew') == martist.getp(line, 'markeredgewidth')\n    assert martist.getp(line, 'ms') == martist.getp(line, 'markersize')\n", "def test_artist_inspector_get_aliases():\n    artist = mlines.Line2D([0, 1], [0, 1])\n    inspector = martist.ArtistInspector(artist)\n    aliases = inspector.get_aliases()\n    assert 'markerfacecolor' in aliases\n    assert 'mfc' in aliases['markerfacecolor']\n", "def test_artist_aliases():\n    line = mlines.Line2D([0, 1], [0, 1])\n    insp = martist.ArtistInspector(line)\n    assert 'lw' in insp.aliasd['linewidth']\n    assert 'ls' in insp.aliasd['linestyle']\n    assert 'c' in insp.aliasd['color']\n\n    # Check that the aliased names are included in the output.\n    s = io.StringIO()\n    martist.setp(line, file=s)\n    assert 'linewidth or lw' in s.getvalue()\n    assert 'linestyle or ls' in s.getvalue()\n    assert 'color or c' in s.getvalue()\n", "def test_artist_sticky_edges():\n    artist = martist.Artist()\n    assert artist.sticky_edges.x == []\n    assert artist.sticky_edges.y == []\n\n    artist.sticky_edges.x = [1, 2]\n    artist.sticky_edges.y = [3, 4]\n\n    assert artist.sticky_edges.x == [1, 2]\n    assert artist.sticky_edges.y == [3, 4]\n", "def test_artist_inspector():\n    fig, ax = plt.subplots()\n    line, = ax.plot([1, 2, 3])\n\n    # Test getting a property value.\n    insp = martist.ArtistInspector(line)\n    assert insp.get_setters() == [\n        'aa', 'agg_filter', 'alpha', 'animated', 'antialiased', 'axes',\n        'clip_box', 'clip_on', 'clip_path', 'color', 'contains', 'dash_capstyle',\n        'dash_joinstyle', 'data', 'drawstyle', 'figure', 'gid', 'in_layout',\n        'label', 'linestyle', 'linewidth', 'marker', 'markeredgecolor',\n        'markeredgewidth', 'markerfacecolor', 'markerfacecoloralt',\n        'markersize', 'markevery', 'mouseover', 'path_effects', 'picker',\n        'pickradius', 'rasterized', 'sketch_params', 'snap', 'solid_capstyle',\n        'solid_joinstyle', 'transform', 'url', 'visible', 'xdata', 'ydata',\n        'zorder']\n\n    # Test getting a property value.\n    assert insp.aliased_name('linestyle') == 'linestyle or ls'\n\n    # Test getting valid values.\n    assert (insp.get_valid_values('linestyle')\n            == ('-', '--', '-.', ':', '', (offset, onoffseq)))\n"], "sample_121": ["def test_from_inversion_vector():\n    p = Permutation([3, 2, 1, 0])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    p = Permutation([1, 2, 3, 0, 4])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    p = Permutation([4, 8, 0, 7, 1, 5, 3, 6, 2])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n", "def test_cycle_init():\n    # check that singletons are handled correctly\n    assert Cycle(1) == Cycle(1, 1)\n    raises(ValueError, lambda: Cycle(1, 2, 2))\n    raises(ValueError, lambda: Cycle(-1, 2))\n    # check that the elements are properly flattened\n    assert Cycle([[1, 2], [3, 4]]) == Cycle(1, 2)(3, 4)\n", "def test_Permutation():\n    # check that Permutations can be created from a list\n    assert Permutation(list(range(3))) == Permutation(2)\n    assert Permutation([0, 2, 1]) == Permutation(0, 2, 1)\n    raises(ValueError, lambda: Permutation([4, 5]))\n    assert Permutation([1, 0], size=2) == Permutation(0, 1)\n    assert Permutation([[0, 1]], size=2) == Permutation(0, 1)\n    raises(ValueError, lambda: Permutation([0, 1], size=1))\n    raises(ValueError, lambda: Permutation([[0, 1]], size=1))\n    raises(ValueError, lambda: Permutation([0, 1, 2, 3], size=3))\n    raises(ValueError, lambda: Permutation([[0, 1, 2, 3]], size=3))\n    assert Permutation(3)(0, 1) == Permutation(0, 1, 2, 3)\n    assert Permutation(3)([0, 1]) == Permutation(0, 1, 2, 3)\n    assert Permutation(3)((0, 1)) == Permutation(0, 1, 2, 3)\n    assert Permutation(3)(([0, 1],)) == Permutation(0, 1, 2, 3)\n    assert Permutation(3)(Permutation(0, 1)) == Permutation(0, 1, 2, 3)\n", "def test__af_new():\n    # Test that _af_new returns a Permutation instance\n    p = _af_new([0, 2, 1])\n    assert isinstance(p, Permutation)\n    assert p.array_form == [0, 2, 1]\n", "def test__af_parity():\n    assert _af_parity([0, 1, 2, 3]) == 0\n    assert _af_parity([3, 2, 0, 1]) == 1\n    assert _af_parity([0, 1, 2, 3, 4]) == 0\n    assert _af_parity([4, 3, 2, 1, 0]) == 1\n    assert _af_parity([]) == 0\n"], "sample_58": ["def test_settings_to_cmd_args_env_with_ssl_settings(self):\n    settings_dict = {\n        \"NAME\": \"mydb\",\n        \"USER\": \"myuser\",\n        \"PASSWORD\": \"mypassword\",\n        \"HOST\": \"localhost\",\n        \"PORT\": 5432,\n        \"OPTIONS\": {\n            \"sslmode\": \"require\",\n            \"sslrootcert\": \"/path/to/ssl/root/cert\",\n            \"sslcert\": \"/path/to/ssl/cert\",\n            \"sslkey\": \"/path/to/ssl/key\",\n        },\n    }\n    args, env = self.settings_to_cmd_args_env(settings_dict)\n    self.assertEqual(args, [\"psql\", \"-U\", \"myuser\", \"-h\", \"localhost\", \"-p\", \"5432\", \"mydb\"])\n    self.assertEqual(env, {\n        \"PGSSLMODE\": \"require\",\n        \"PGSSLROOTCERT\": \"/path/to/ssl/root/cert\",\n        \"PGSSLCERT\": \"/path/to/ssl/cert\",\n        \"PGSSLKEY\": \"/path/to/ssl/key\",\n        \"PGPASSWORD\": \"mypassword\",\n    })\n", "def test_settings_to_cmd_args_env_with_ssl_options(self):\n    settings_dict = {\n        \"HOST\": \"localhost\",\n        \"PORT\": 5432,\n        \"NAME\": \"mydb\",\n        \"USER\": \"myuser\",\n        \"PASSWORD\": \"mypassword\",\n        \"OPTIONS\": {\n            \"sslmode\": \"require\",\n            \"sslrootcert\": \"/path/to/root/cert\",\n            \"sslcert\": \"/path/to/cert\",\n            \"sslkey\": \"/path/to/key\",\n        },\n    }\n    cmd_args, env = self.settings_to_cmd_args_env(settings_dict)\n    self.assertEqual(cmd_args, [\"psql\", \"-h\", \"localhost\", \"-p\", \"5432\", \"-U\", \"myuser\", \"mydb\"])\n    self.assertEqual(env, {\n        \"PGPASSWORD\": \"mypassword\",\n        \"PGSSLMODE\": \"require\",\n        \"PGSSLROOTCERT\": \"/path/to/root/cert\",\n        \"PGSSLCERT\": \"/path/to/cert\",\n        \"PGSSLKEY\": \"/path/to/key\",\n    })\n", "def test_settings_to_cmd_args_env_with_ssl(self):\n    settings_dict = {\n        \"NAME\": \"mydatabase\",\n        \"USER\": \"myuser\",\n        \"PASSWORD\": \"mypassword\",\n        \"HOST\": \"localhost\",\n        \"PORT\": 5432,\n        \"OPTIONS\": {\n            \"sslmode\": \"require\",\n            \"sslrootcert\": \"/path/to/sslrootcert\",\n            \"sslcert\": \"/path/to/sslcert\",\n            \"sslkey\": \"/path/to/sslkey\",\n        },\n    }\n    args, env = self.settings_to_cmd_args_env(settings_dict)\n    self.assertEqual(args, [\"psql\", \"-U\", \"myuser\", \"-h\", \"localhost\", \"-p\", \"5432\", \"mydatabase\"])\n    self.assertEqual(env, {\n        \"PGSSLMODE\": \"require\",\n        \"PGSSLROOTCERT\": \"/path/to/sslrootcert\",\n        \"PGSSLCERT\": \"/path/to/sslcert\",\n        \"PGSSLKEY\": \"/path/to/sslkey\",\n        \"PGPASSWORD\": \"mypassword\",\n    })\n", "def test_settings_to_cmd_args_env_with_ssl_options(self):\n    settings_dict = {\n        \"NAME\": \"mydatabase\",\n        \"USER\": \"myuser\",\n        \"PASSWORD\": \"mypassword\",\n        \"HOST\": \"localhost\",\n        \"PORT\": 5432,\n        \"OPTIONS\": {\n            \"sslmode\": \"require\",\n            \"sslrootcert\": \"/path/to/ssl/root/cert\",\n            \"sslcert\": \"/path/to/ssl/cert\",\n            \"sslkey\": \"/path/to/ssl/key\",\n        },\n    }\n    args, env = self.settings_to_cmd_args_env(settings_dict)\n    self.assertEqual(args, [\"psql\", \"-U\", \"myuser\", \"-h\", \"localhost\", \"-p\", \"5432\", \"mydatabase\"])\n    self.assertEqual(\n        env,\n        {\n            \"PGPASSWORD\": \"mypassword\",\n            \"PGSSLMODE\": \"require\",\n            \"PGSSLROOTCERT\": \"/path/to/ssl/root/cert\",\n            \"PGSSLCERT\": \"/path/to/ssl/cert\",\n            \"PGSSLKEY\": \"/path/to/ssl/key\",\n        },\n    )\n", "def test_settings_to_cmd_args_env_with_ssl_options(self):\n    settings_dict = {\n        \"NAME\": \"mydb\",\n        \"USER\": \"myuser\",\n        \"PASSWORD\": \"mypassword\",\n        \"HOST\": \"localhost\",\n        \"PORT\": 5432,\n        \"OPTIONS\": {\n            \"sslmode\": \"require\",\n            \"sslrootcert\": \"/path/to/root/cert\",\n            \"sslcert\": \"/path/to/cert\",\n            \"sslkey\": \"/path/to/key\",\n        },\n    }\n    args, env = self.settings_to_cmd_args_env(settings_dict)\n    self.assertEqual(args, [\"psql\", \"-U\", \"myuser\", \"-h\", \"localhost\", \"-p\", \"5432\", \"mydb\"])\n    self.assertEqual(\n        env,\n        {\n            \"PGPASSWORD\": \"mypassword\",\n            \"PGSSLMODE\": \"require\",\n            \"PGSSLROOTCERT\": \"/path/to/root/cert\",\n            \"PGSSLCERT\": \"/path/to/cert\",\n            \"PGSSLKEY\": \"/path/to/key\",\n        },\n    )\n"], "sample_41": ["def test_formset_management_form_initial_data(self):\n    ChoiceFormSet = formset_factory(Choice)\n    formset = ChoiceFormSet(initial=[{'choice': 'Test', 'votes': 1}])\n    self.assertEqual(formset.management_form.initial, {\n        'TOTAL_FORMS': 1,\n        'INITIAL_FORMS': 1,\n        'MIN_NUM_FORMS': 0,\n        'MAX_NUM_FORMS': 1000,\n    })\n", "def test_formset_management_form_validates(self):\n    # Test that the management form validates the data\n    formset = self.make_choiceformset(\n        [('Choice 1', '10'), ('Choice 2', '20')],\n        total_forms=3,\n        initial_forms=2,\n        max_num_forms=4,\n        min_num_forms=1,\n    )\n\n    # Tamper with the management form data to make it invalid\n    formset.data['choices-TOTAL_FORMS'] = 'abc'\n\n    # Assert that the management form is not valid\n    self.assertFalse(formset.management_form.is_valid())\n    self.assertIn('TOTAL_FORMS', formset.management_form.errors)\n", "def test_formset_management_form_with_missing_fields(self):\n    formset = self.make_choiceformset(formset_data=[('Choice 1', '10'), ('Choice 2', '20')])\n    management_form = formset.management_form\n    management_form.cleaned_data.pop('TOTAL_FORMS')\n    with self.assertRaisesMessage(ValidationError, 'ManagementForm data is missing or has been tampered with'):\n        formset.is_valid()\n", "def test_formset_absolute_max(self):\n    ChoiceFormSet = formset_factory(Choice, max_num=10, absolute_max=15)\n    formset = self.make_choiceformset([('1', '1')] * 12, total_forms=12)\n    self.assertTrue(formset.is_valid())\n    formset = self.make_choiceformset([('1', '1')] * 16, total_forms=16)\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(len(formset.errors), 0)\n    self.assertEqual(len(formset.non_form_errors()), 1)\n", "def test_formset_factory_absolute_max(self):\n    # Test that formset_factory raises an error if absolute_max is less than max_num\n    with self.assertRaises(ValueError):\n        formset_factory(Choice, max_num=10, absolute_max=5)\n"], "sample_94": ["def test_getstatementrange_ast_with_empty_lines_at_end():\n    src = Source(\n        \"\"\"\n            pass\n\n        \n    \"\"\"\n    )\n    ast_node, start, end = getstatementrange_ast(1, src)\n    assert start == 0\n    assert end == 2\n", "def test_getstatementrange_ast_single_line():\n    source = Source(\"x = 1\")\n    astnode, start, end = getstatementrange_ast(0, source)\n    assert start == 0\n    assert end == 1\n", "def test_Source_getstatementrange_multiline_string(tmp_path: Path) -> None:\n    # Test that getstatementrange handles multiline strings correctly.\n    # See https://github.com/pytest-dev/pytest/issues/8550\n    p = tmp_path / \"example.py\"\n    p.write_text(\n        textwrap.dedent(\n            \"\"\"\n                bar = '''\n                    hello\n                '''\n            \"\"\"\n        )\n    )\n    source = Source(import_path(p))\n    _, start, end = getstatementrange_ast(1, source)\n    assert start == 0\n    assert end == 4\n", "def test_getstatementrange_ast_single_line() -> None:\n    src = Source(\"x = 1\\ny = 2\")\n    ast_tree, start, end = getstatementrange_ast(0, src)\n    assert start == 0\n    assert end == 1\n", "def test_source_getstatementrange_ast():\n    src = Source(\"\"\"\n            if x > 0:\n                return True\n            else:\n                return False\n\n            pass\n    \"\"\")\n    ast_node, start, end = getstatementrange_ast(2, src)\n    assert start == 1\n    assert end == 6\n"], "sample_65": ["    def test_stringformat(self):\n        output = self.engine.render_to_string(\"stringformat01\", {\"a\": 12345})\n        self.assertEqual(output, \"1.2345E+4\")\n", "    def test_stringfilter_capfirst(self):\n        output = self.engine.render_to_string(\"stringfilter01\", {\"a\": \"hello\"})\n        self.assertEqual(output, \"Hello\")\n", "    def test_addslashes(self):\n        output = self.engine.render_to_string(\"addslashes01\", {\"a\": \"Hello, World!\"})\n        self.assertEqual(output, \"Hello\\\\, World\\\\!\")\n", "    def test_addslashes(self):\n        output = self.engine.render_to_string(\"addslashes01\", {\"a\": \"a\\'b\"})\n        self.assertEqual(output, \"a\\\\'b\")\n", "    def test_addslashes(self):\n        output = self.engine.render_to_string(\"addslashes01\", {\"a\": \"Hello, World!\"})\n        self.assertEqual(output, \"Hello\\\\, World\\\\!\")\n"], "sample_72": ["def test_figure_repr():\n    fig = Figure()\n    assert re.match(r\"<Figure size \\d+\\.\\d+x\\d+\\.\\d+ with 0 Axes>\", repr(fig))\n    ax = fig.add_subplot(111)\n    assert re.match(r\"<Figure size \\d+\\.\\d+x\\d+\\.\\d+ with 1 Axes>\", repr(fig))\n", "def test_figure_repr():\n    fig = Figure()\n    expected_repr = f\"<{fig.__class__.__name__} size {fig.bbox.size[0]:g}x{fig.bbox.size[1]:g} with 0 Axes>\"\n    assert repr(fig) == expected_repr\n\n    ax = fig.add_subplot(111)\n    expected_repr = f\"<{fig.__class__.__name__} size {fig.bbox.size[0]:g}x{fig.bbox.size[1]:g} with 1 Axes>\"\n    assert repr(fig) == expected_repr\n", "def test_figure_get_constrained_layout(layout, expected):\n    fig = Figure(layout=layout)\n    assert fig.get_constrained_layout() == expected\n", "def test_figure_labeling():\n    fig, axs = plt.subplots(2, 2)\n    for i, ax in enumerate(axs.flat):\n        ax.set_title(f'Title {i}')\n        ax.set_xlabel(f'XLabel {i}')\n        ax.set_ylabel(f'YLabel {i}')\n\n    fig.tight_layout()\n\n    # Checking if labels are correctly aligned\n    for ax in axs.flat:\n        assert ax.title.get_visible()\n        assert ax.xaxis.label.get_visible()\n        assert ax.yaxis.label.get_visible()\n\n    plt.close('all')\n", "def test_figure_size(figsize, expected_size):\n    fig = Figure(figsize=figsize)\n    assert np.allclose(fig.get_size_inches(), expected_size)\n"], "sample_122": ["def test_sparse_matrix_row_join():\n    # Test row_join\n    A = SparseMatrix(((1, 0, 1), (0, 1, 0), (1, 1, 0)))\n    B = SparseMatrix(((1, 0, 0), (0, 1, 0), (0, 0, 1)))\n    assert A.row_join(B) == Matrix([\n        [1, 0, 1, 1, 0, 0],\n        [0, 1, 0, 0, 1, 0],\n        [1, 1, 0, 0, 0, 1]])\n\n    # Test row_join with zero matrix\n    C = SparseMatrix(3, 3, {})\n    assert A.row_join(C) == A\n\n    # Test row_join with non-sparse matrix\n    D = Matrix(((1, 0, 0), (0, 1, 0), (0, 0, 1)))\n    assert A.row_join(D) == Matrix([\n        [1, 0, 1, 1, 0, 0],\n        [0, 1, 0, 0, 1, 0],\n        [1, 1, 0, 0, 0, 1]])\n", "def test_sparse_matrix_row_join():\n    A = SparseMatrix(((1, 0, 1), (0, 1, 0), (1, 1, 0)))\n    B = SparseMatrix(((1, 0, 0), (0, 1, 0), (0, 0, 1)))\n    C = A.row_join(B)\n    assert C == A.row_join(Matrix(B))\n    assert C == Matrix([\n        [1, 0, 1, 1, 0, 0],\n        [0, 1, 0, 0, 1, 0],\n        [1, 1, 0, 0, 0, 1]])\n", "def test_sparse_applyfunc():\n    A = SparseMatrix(3, 3, {(1, 1): S(2), (0, 2): S(3)})\n    B = A.applyfunc(lambda x: x**2)\n    assert B == SparseMatrix(3, 3, {(1, 1): S(4), (0, 2): S(9)})\n", "def test_sparse_row_col_operations():\n    # Test row and column operations\n    M = SparseMatrix(3, 3, {(0, 1): 1, (1, 2): 2, (2, 0): 3})\n\n    # Row operations\n    M.row_op(1, lambda v, j: v + 2*M[0, j])\n    assert M == SparseMatrix(3, 3, {(0, 1): 1, (1, 1): 2, (1, 2): 2, (2, 0): 3})\n\n    M.row_swap(1, 0)\n    assert M == SparseMatrix(3, 3, {(0, 1): 2, (0, 2): 2, (1, 1): 1, (2, 0): 3})\n\n    M.row_del(0)\n    assert M == SparseMatrix(2, 3, {(0, 1): 1, (1, 0): 3})\n\n    # Column operations\n    M.col_op(1, lambda v, i: v + 2*M[i, 0])\n    assert M == SparseMatrix(2, 3, {(0, 1): 1, (1, 0): 3, (1, 1): 6})\n\n    M.col_swap(1, 0)\n    assert M == SparseMatrix(2, 3, {(0, 0): 1, (1, 0): 6, (1, 1): 3})\n\n    M.col_del(0)\n    assert M == SparseMatrix(2, 2, {(1, 0): 3})\n", "def test_sparse_matrix_row_op():\n    M = SparseMatrix.eye(3)*2\n    M[0, 1] = -1\n    M.row_op(1, lambda v, j: v + 2*M[0, j])\n    assert M == SparseMatrix([[2, -1, 0], [4, 0, 0], [0, 0, 2]])\n"], "sample_91": ["def test_evaluate_condition_unexpected_exception(monkeypatch):\n    item = pytest.Item(\"test_func\", None)\n    mark = pytest.Mark(\n        \"xfail\", (\"condition\",), kwargs={\"reason\": \"some_reason\"}, args=(\"arg\",)\n    )\n    monkeypatch.setattr(sys, \"platform\", \"win32\")\n\n        raise Exception(\"Something went wrong\")\n\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_condition(item, mark, condition)\n\n    assert \"Error evaluating 'xfail' condition\" in str(excinfo.value)\n    assert \"Exception: Something went wrong\" in str(excinfo.value)\n", "def test_evaluate_condition_string_reason(item):\n    mark = pytest.mark.skipif(\"True\", reason=\"something is wrong\")\n    result, reason = evaluate_condition(item, mark, \"True\")\n    assert result\n    assert reason == \"something is wrong\"\n", "def test_xfail_mark_strict_true(testdir):\n    item = testdir.getitem(\"xfail_mark_strict\")\n    xfailed = evaluate_xfail_marks(item)\n    assert xfailed.strict is True\n\n    class DummyConfig:\n        option = lambda self, x: False\n        getini = lambda self, x: True\n\n    item._config = DummyConfig()\n    rep = runtestprotocol(item, log=False)\n    assert rep.outcome == \"failed\"\n    assert \"[XPASS(strict)]\" in str(rep.longrepr)\n", "def test_evaluate_xfail_mark_strict(self, item):\n    item.config._inicache[\"xfail_strict\"] = True\n    mark = pytest.mark.xfail(reason=\"some reason\")\n    xfail = evaluate_xfail_marks(item)\n    assert xfail.strict is True\n", "def test_xfail_strict():\n    item = pytest.Item(\"test\", None)\n    item.config = pytest.Config()\n    item.config.option.runxfail = False\n    item.config.getini.return_value = True\n\n    xfail_mark = pytest.mark.xfail(reason=\"some reason\", strict=True)\n    item.add_marker(xfail_mark)\n\n    call = pytest.CallInfo(None, None, None)\n\n    report = pytest.TestReport(item.nodeid, \"passed\", None, None, None)\n    report.when = \"call\"\n\n    pytest_runtest_makereport(item, report, call)\n\n    assert report.outcome == \"failed\"\n    assert report.longrepr.startswith(\"[XPASS(strict)]\")\n"], "sample_115": ["def test__wrap_in_pandas_container_sparse():\n    sparse_data = csr_matrix(np.array([[0, 1], [2, 0]]))\n    with pytest.raises(ValueError):\n        _wrap_in_pandas_container(sparse_data, columns=[\"col1\", \"col2\"])\n", "def test_wrap_in_pandas_container():\n    # Test with numpy array and default columns\n    data = np.array([[1, 2], [3, 4]])\n    result = _wrap_in_pandas_container(data, columns=None)\n    assert result.shape == (2, 2)\n    assert_array_equal(result.columns, range(2))\n\n    # Test with numpy array and custom columns\n    data = np.array([[1, 2], [3, 4]])\n    result = _wrap_in_pandas_container(data, columns=[\"a\", \"b\"])\n    assert result.shape == (2, 2)\n    assert_array_equal(result.columns, [\"a\", \"b\"])\n\n    # Test with pandas dataframe and default columns\n    import pandas as pd\n    data = pd.DataFrame({\"a\": [1, 2], \"b\": [3, 4]})\n    result = _wrap_in_pandas_container(data, columns=None)\n    assert result.shape == (2, 2)\n    assert_array_equal(result.columns, [\"a\", \"b\"])\n\n    # Test with pandas dataframe and custom columns\n    data = pd.DataFrame({\"a\": [1, 2], \"b\": [3, 4]})\n    result = _wrap_in_pandas_container(data, columns=[\"c\", \"d\"])\n    assert result.shape == (2, 2)\n    assert_array_equal(result.columns, [\"c\", \"d\"])\n\n    # Test with sparse matrix\n    data = csr_matrix(np.array([[1, 2], [3, 4]]))\n    with pytest.raises(ValueError):\n        _wrap_in_pandas_container(data, columns=None)\n", "def test_wrap_in_pandas_container_sparse():\n    # Check that wrapping sparse data raises an error\n    data = csr_matrix(np.array([[1, 2], [3, 4]]))\n    with pytest.raises(ValueError):\n        _wrap_in_pandas_container(data, columns=[\"col1\", \"col2\"])\n", "def test_wrap_in_pandas_container_sparse():\n    sparse_data = csr_matrix(np.array([[1, 0], [0, 1]]))\n    with pytest.raises(ValueError):\n        _wrap_in_pandas_container(sparse_data, columns=[\"col1\", \"col2\"])\n", "def test_wrap_in_pandas_container_sparse():\n    # Test that wrapping sparse data raises an error\n    sparse_data = csr_matrix(np.array([[1, 0, 2], [0, 0, 3]]))\n    with pytest.raises(ValueError, match=\"Pandas output does not support sparse data.\"):\n        _wrap_in_pandas_container(sparse_data, columns=[1, 2, 3])\n"], "sample_15": ["def test_check_language_settings_consistent_valid(self):\n    errors = check_language_settings_consistent(None)\n    self.assertEqual(errors, [])\n", "def test_check_language_settings_consistent(self):\n    errors = check_language_settings_consistent(None)\n    self.assertEqual(errors, [])\n\n    with override_settings(LANGUAGE_CODE='non-existent'):\n        errors = check_language_settings_consistent(None)\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, 'translation.E004')\n", "def test_check_language_settings_consistent_valid(self):\n    errors = check_language_settings_consistent()\n    self.assertEqual(errors, [])\n", "def test_check_setting_language_code(self):\n    with override_settings(LANGUAGE_CODE='en'):\n        errors = check_setting_language_code(None)\n        self.assertEqual(errors, [])\n\n    with override_settings(LANGUAGE_CODE=None):\n        errors = check_setting_language_code(None)\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, 'translation.E001')\n\n    with override_settings(LANGUAGE_CODE=123):\n        errors = check_setting_language_code(None)\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, 'translation.E001')\n\n    for tag in self.invalid_tags:\n        with override_settings(LANGUAGE_CODE=tag):\n            errors = check_setting_language_code(None)\n            self.assertEqual(len(errors), 1)\n            self.assertIsInstance(errors[0], Error)\n            self.assertEqual(errors[0].id, 'translation.E001')\n", "def test_check_language_settings_consistent(self):\n    with override_settings(LANGUAGE_CODE='en', LANGUAGES=[('fr', 'French')]):\n        errors = check_language_settings_consistent()\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, 'translation.E004')\n\n    with override_settings(LANGUAGE_CODE='en', LANGUAGES=[('en', 'English')]):\n        errors = check_language_settings_consistent()\n        self.assertEqual(len(errors), 0)\n"], "sample_12": ["def test_generate_altered_constraints(self):\n    \"\"\"Tests that altered constraints are properly generated.\"\"\"\n    # Create initial model state\n    before = self.make_project_state([self.author_name])\n    after = self.make_project_state([self.author_name_check_constraint])\n\n    # Set up autodetector\n    autodetector = MigrationAutodetector(before, after)\n\n    # Detect changes\n    changes = autodetector._detect_changes()\n\n    # Assert correct number of migrations\n    self.assertNumberMigrations(changes, 'testapp', 1)\n\n    # Assert correct operations\n    self.assertOperationTypes(changes, 'testapp', 0, ['AddConstraint'])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name_contains_bob')\n", "def test_detect_changes_remove_constraints(self):\n    \"\"\"Tests autodetection of removed constraints.\"\"\"\n    # Create the initial model and state\n    before = self.make_project_state([self.author_name_check_constraint])\n    after = self.make_project_state([self.author_name])\n    autodetector = MigrationAutodetector(before, after)\n    changes = autodetector._detect_changes()\n    # Right number of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    # Right number of operations?\n    migration = changes['testapp'][0]\n    self.assertEqual(len(migration.operations), 1)\n    self.assertIsInstance(migration.operations[0], operations.RemoveConstraint)\n    self.assertEqual(migration.operations[0].name, 'name_contains_bob')\n", "def test_create_model_with_indexes(self):\n    changes = self.get_changes(\n        [self.author_empty],\n        [self.author_name, self.book_indexes]\n    )\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, ['CreateModel'])\n    self.assertOperationTypes(changes, 'otherapp', 0, ['CreateModel'])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='book')\n    self.assertOperationAttributes(changes, 'otherapp', 0, 1, model_name='book', name='author')\n    self.assertOperationAttributes(changes, 'otherapp', 0, 2, model_name='book', name='title')\n    self.assertOperationAttributes(changes, 'otherapp', 0, 3, model_name='book')\n    self.assertOperationAttributes(changes, 'otherapp', 0, 4, model_name='book')\n    self.assertOperationAttributes(changes, 'otherapp', 0, 5, model_name='book')\n", "def test_create_model_with_default_permissions(self):\n    changes = self.get_changes([self.author_empty], [self.author_with_options])\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, ['CreateModel'])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Author')\n    self.assertEqual(\n        changes['testapp'][0].operations[0].options,\n        {'permissions': [('can_hire', 'Can hire')], 'verbose_name': 'Authi'}\n    )\n", "def test_autodetector_add_check_constraint(self):\n    \"\"\"Tests autodetection of new CheckConstraints.\"\"\"\n    before = self.make_project_state([self.author_name])\n    after = self.make_project_state([self.author_name_check_constraint])\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, ['AddConstraint'])\n    self.assertOperationAttributes(\n        changes, 'testapp', 0, 0,\n        model_name='author',\n        constraint=models.CheckConstraint(\n            check=models.Q(name__contains='Bob'), name='name_contains_bob'\n        ),\n    )\n"], "sample_100": ["def test_ordinal_encoder_inverse_transform():\n    # Test inverse transform for OrdinalEncoder\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc = OrdinalEncoder()\n    X_tr = enc.fit_transform(X)\n\n    # Inverse transform should get back the original data\n    assert_array_equal(enc.inverse_transform(X_tr), X)\n", "def test_one_hot_encoder_handle_unknown():\n    # Test the 'handle_unknown' parameter of OneHotEncoder\n\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc = OneHotEncoder(handle_unknown='error')\n    enc.fit(X)\n\n    # Test that an error is raised when an unknown category is encountered\n    X_test = [['Unknown', 1]]\n    assert_raises(ValueError, enc.transform, X_test)\n\n    # Test that no error is raised when handle_unknown='ignore'\n    enc = OneHotEncoder(handle_unknown='ignore')\n    enc.fit(X)\n    X_test = [['Unknown', 1]]\n    X_trans = enc.transform(X_test)\n    assert_array_equal(toarray(X_trans), [[0., 0., 0., 0., 0.]])\n", "def test_ordinal_encoder_categories():\n    # Test that categories are correctly set\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc = OrdinalEncoder()\n    enc.fit(X)\n    assert_array_equal(enc.categories_, [np.array(['Female', 'Male']),\n                                         np.array([1, 2, 3])])\n", "def test_one_hot_encoder_inverse_transform():\n    # create an instance of OneHotEncoder\n    enc = OneHotEncoder(categories='auto')\n    \n    # fit the encoder with some data\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    \n    # transform some data\n    X_transformed = enc.transform([['Female', 3], ['Male', 1]])\n    \n    # inverse transform and check result\n    X_inverse = enc.inverse_transform(X_transformed)\n    assert_array_equal(X_inverse, np.array([['Female', 3], ['Male', 1]]))\n", "def test_ordinal_encoder_inverse_transform():\n    # Test inverse transform for OrdinalEncoder\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    transformed_X = enc.transform([['Female', 3], ['Male', 1]])\n    inverse_X = enc.inverse_transform(transformed_X)\n\n    assert_array_equal(inverse_X, [['Female', 3], ['Male', 1]])\n"], "sample_81": ["    def test_by_id_managed_messages(self):\n        linter = self.linter\n        linter._by_id_managed_msgs = [\n            (\"module\", \"msgid\", \"symbol\", 1, False),\n            (\"other_module\", \"msgid\", \"symbol\", 1, True),\n        ]\n        node = self.extract_node_from_file(\n            \"\"\"\n            # pylint: disable-msgid=msgid\n            # pylint: enable-msgid=msgid\n            \"\"\"\n        )\n        with set_config(node, linter):\n            self.checker.process_module(node)\n        self.assertAddsMessages(\n            MessageTest(msg_id=\"use-symbolic-message-instead\", line=1),\n            MessageTest(msg_id=\"use-symbolic-message-instead\", line=2),\n        )\n", "    def test_by_id_managed_messages(self):\n        config = set_config(\n            managed_messages=[\n                (\"miscellaneous\", \"fixme\", \"W0511\", 1, True),\n                (\"miscellaneous\", \"invalid-name\", \"C0103\", 2, False),\n            ]\n        )\n        node = self.checker.process_module(\n            self.ast_from_string(\"pass\\n# pylint: disable=W0511\\npass\")\n        )\n        with set_config(**config):\n            self.checker._check_by_id_managed_msgs(node)\n        self.assert_add_message(\n            \"use-symbolic-message-instead\",\n            line=1,\n            args=\"'W0511' is cryptic: use '# pylint: disable=fixme' instead\",\n        )\n        self.assert_no_messages()\n", "    def test_use_symbolic_message_instead(self):\n        config = self.linter.config\n        linter = self.linter\n        linter._by_id_managed_msgs = [(\"module\", \"msgid\", \"symbol\", 1, False)]\n        node = self.extract_node_from_file(\"module.py\", \"\")\n        with set_config(self.linter.config, notes=[]):\n            self.checker.process_module(node)\n            self.assert_message_output(\n                MessageTest(msg_id=\"use-symbolic-message-instead\", line=1, args=\"msgid\")\n            )\n", "    def test_add_message(self):\n        node = self.extract_node(\"\"\"\n            # pylint: disable=1234\n            pass\n        \"\"\")\n        self.checker.linter._by_id_managed_msgs.append((\"module\", \"1234\", \"symbol\", 1, True))\n        with self.assertAddsMessages(\n            MessageTest(misc.ByIdManagedMessagesChecker.use_symbolic_message_instead,\n                        line=1,\n                        args=\"'1234' is cryptic: use '# pylint: disable=symbol' instead\")\n        ):\n            self.checker.process_module(node)\n", "    def test_by_id_managed_messages(self):\n        config = self.linter.get_config()\n        # Set up some by_id managed messages\n        self.linter._by_id_managed_msgs = [\n            (\"module1\", \"msgid1\", \"symbol1\", 1, False),\n            (\"module2\", \"msgid2\", \"symbol2\", 2, True),\n        ]\n        node = self.extract_node_from_file(\"module1\")\n        with set_config(self.linter, config):\n            self.checker.process_module(node)\n        self.assertAddsMessages(\n            MessageTest(\n                msg_id=\"use-symbolic-message-instead\",\n                line=1,\n                args=\"'msgid1' is cryptic: use '# pylint: enable=symbol1' instead\",\n            ),\n        )\n"], "sample_1": ["def test_understand_err_col():\n    colnames = ['a', 'a_err', 'b', 'b_perr', 'b_nerr']\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [1])\n    assert np.allclose(terr, [2])\n\n    with pytest.raises(ValueError):\n        _understand_err_col(['a', 'a_nerr'])\n\n    with pytest.raises(ValueError):\n        _understand_err_col(['a', 'a_perr'])\n", "def test_get_lines_from_file_str():\n    # Test reading a QDP file from a string.\n    qdp_file = \"\"\"READ SERR 1\\n1.0 0.1\\nNO NO\"\"\"\n    lines = _get_lines_from_file(qdp_file)\n    assert lines == [\"READ SERR 1\", \"1.0 0.1\", \"NO NO\"]\n", "def test_read_table_qdp_with_err_specs():\n    # Create a test QDP file with error specs\n    qdp_file = \"\"\"\n    READ TERR 1\n    READ SERR 3\n    ! Table 0 comment\n    !a a(pos) a(neg) b be c d\n    53000.5   0.25  -0.5   1  1.5  3.5 2\n    54000.5   1.25  -1.5   2  2.5  4.5 3\n    NO NO NO NO NO\n    ! Table 1 comment\n    !a a(pos) a(neg) b be c d\n    54000.5   2.25  -2.5   NO  3.5  5.5 5\n    55000.5   3.25  -3.5   4  4.5  6.5 nan\n    \"\"\"\n\n    # Read the table with error specs\n    table = _read_table_qdp(qdp_file, names=['a', 'b', 'c', 'd'], table_id=0)\n\n    # Check that the error columns are correctly identified\n    assert table.colnames == ['a', 'a_perr', 'a_nerr', 'b', 'b_err', 'c', 'd']\n\n    # Check that the data is correctly read\n    assert np.allclose(table['a'], [53000.5, 54000.5])\n    assert np.allclose(table['a_perr'], [0.25, 1.25])\n    assert np.allclose(table['a_nerr'], [-0.5, -1.5])\n    assert np.allclose(table['b'], [1, 2])\n    assert np.allclose(table['b_err'], [1.5, 2.5])\n    assert np.allclose(table['c'], [3.5, 4.5])\n    assert np.allclose(table['d'], [2, 3])\n", "def test_read_table_qdp_with_err_specs(tmpdir):\n    # Create a QDP file with error specs\n    filename = str(tmpdir.join(\"test.qdp\"))\n    with open(filename, \"w\") as f:\n        f.write(\"! Initial comment\\n\")\n        f.write(\"READ TERR 1\\n\")\n        f.write(\"READ SERR 2\\n\")\n        f.write(\"! Column names\\n\")\n        f.write(\"a b c\\n\")\n        f.write(\"1 2 3 4 5 6\\n\")\n        f.write(\"7 8 9 10 11 12\\n\")\n\n    # Read the table with error specs\n    table = _read_table_qdp(filename, names=[\"a\", \"b\", \"c\"])\n\n    # Check the column names and data\n    assert table.colnames == [\"a\", \"a_perr\", \"a_nerr\", \"b\", \"b_err\", \"c\"]\n    assert np.all(table[\"a\"] == [1, 7])\n    assert np.all(table[\"a_perr\"] == [2, 8])\n    assert np.all(table[\"a_nerr\"] == [3, 9])\n    assert np.all(table[\"b\"] == [4, 10])\n    assert np.all(table[\"b_err\"] == [5, 11])\n    assert np.all(table[\"c\"] == [6, 12])\n\n    # Check the meta comments\n    assert table.meta[\"initial_comments\"] == [\"Initial comment\"]\n    assert table.meta[\"comments\"] == [\"Column names\"]\n", "def test_qdp_write_err_specs():\n    # Create a table with error columns\n    table = Table({\n        'a': [1, 2, 3],\n        'a_err': [0.1, 0.2, 0.3],\n        'b': [4, 5, 6],\n        'b_perr': [0.4, 0.5, 0.6],\n        'b_nerr': [0.7, 0.8, 0.9]\n    })\n\n    # Write the table to a QDP file with error specs\n    lines = _write_table_qdp(table, err_specs={'serr': [1], 'terr': [2]})\n\n    # Check that the error specs are written correctly\n    assert 'READ SERR 1' in lines\n    assert 'READ TERR 2' in lines\n\n    # Check that the error columns are written correctly\n    assert '1 0.1 4 0.4 0.7' in lines\n    assert '2 0.2 5 0.5 0.8' in lines\n    assert '3 0.3 6 0.6 0.9' in lines\n"], "sample_102": ["def test_iforest_average_path_length():\n    # Test the average path length computation in _average_path_length\n    n_samples_leaf = np.array([1, 2, 3, 4, 5])\n    avg_path_length = _average_path_length(n_samples_leaf)\n\n    # Check if the function returns the correct values for n_samples_leaf == 1\n    assert_array_almost_equal(avg_path_length[0], 0.)\n\n    # Check if the function returns the correct values for n_samples_leaf == 2\n    assert_array_almost_equal(avg_path_length[1], 1.)\n\n    # Check if the function returns the correct values for n_samples_leaf > 2\n    assert np.all(avg_path_length[2:] > 0)\n    assert np.all(avg_path_length[2:] < n_samples_leaf[2:])\n", "def test_iforest_average_path_length():\n    # Test the average path length computation in Isolation Forest\n\n    # A few test cases where the analytical formula is known\n    test_cases = [\n        (1, 0),  # 1 sample in a leaf\n        (2, 1),  # 2 samples in a leaf\n        (3, 2 * np.log(2) + np.euler_gamma - 4/3),\n        # 3 samples in a leaf\n        (5, 2 * np.log(4) + np.euler_gamma - 8/5)\n        # 5 samples in a leaf\n    ]\n\n    for n_samples_leaf, expected_score in test_cases:\n        # Compute the score using _average_path_length function\n        score = _average_path_length([n_samples_leaf])\n        assert_allclose(score, expected_score)\n\n    # An array-like with different values should return an array of scores\n    test_cases_array = [1, 2, 3, 5]\n    expected_scores_array = [0, 1,\n                             2 * np.log(2) + np.euler_gamma - 4/3,\n                             2 * np.log(4) + np.euler_gamma - 8/5]\n    scores_array = _average_path_length(test_cases_array)\n    assert_allclose(scores_array, expected_scores_array)\n\n    # Test with an array of shape (n_samples, )\n    scores_array_reshaped = _average_path_length(np.array([test_cases_array]))\n    assert_allclose(scores_array_reshaped, expected_scores_array)\n", "def test_iforest_sparse_input():\n    # Test IsolationForest on sparse input\n    X = csc_matrix(iris.data)\n    assert_raises(TypeError, IsolationForest().fit, X)\n\n    X = csr_matrix(iris.data)\n    IsolationForest().fit(X)\n\n    X = csr_matrix(boston.data)\n    IsolationForest().fit(X)\n", "def test_iforest_check_contamination():\n    # Check if the warn message is raised when the contamination parameter is\n    # not in (0, 0.5] for behaviour 'new'\n    with assert_warns_message(FutureWarning,\n                              \"default contamination parameter 0.1 will change \"\n                              \"in version 0.22 to \\\"auto\\\"\"):\n        IsolationForest(contamination=0.1, behaviour='new')\n\n    # check if contamination is in (0, 0.5]\n    assert_raises_regex(ValueError, \"contamination must be in \\(0, 0.5]\",\n                        IsolationForest, contamination=0.6, behaviour='new')\n    assert_raises_regex(ValueError, \"contamination must be in \\(0, 0.5]\",\n                        IsolationForest, contamination=0, behaviour='new')\n    assert_raises_regex(ValueError, \"contamination must be \\\"auto\\\" or a \"\n                                    \"float in \\(0, 0.5]\",\n                        IsolationForest, contamination=-0.1, behaviour='new')\n    assert_raises_regex(ValueError, \"contamination must be \\\"auto\\\" or a \"\n                                    \"float in \\(0, 0.5]\",\n                        IsolationForest, contamination=1, behaviour='new')\n    assert_raises_regex(ValueError, \"contamination must be \\\"auto\\\" or a \"\n                                    \"float in \\(0, 0.5]\",\n                        IsolationForest, contamination='abc', behaviour='new')\n", "def test_iforest_sparse():\n    # Check if IsolationForest works with sparse matrices\n    X = csc_matrix(iris.data)\n    assert_warns_message(FutureWarning, \"default contamination parameter\",\n                         IsolationForest().fit, X)\n    y_pred = IsolationForest(contamination=0.1, random_state=0).fit_predict(X)\n    assert_greater(roc_auc_score(iris.target != 0, -y_pred), 0.9)\n\n    X = csr_matrix(boston.data)\n    assert_warns_message(FutureWarning, \"default contamination parameter\",\n                         IsolationForest().fit, X)\n    y_pred = IsolationForest(contamination=0.1, random_state=0).fit_predict(X)\n    assert_greater(roc_auc_score(boston.target > 30, -y_pred), 0.7)\n"], "sample_139": ["def test_principal_branch():\n    x = Symbol('x')\n    assert principal_branch(exp_polar(2*pi*I)*3, 2*pi) == 3*exp_polar(0)\n    assert principal_branch(exp_polar(2*pi*I)*3*x, 2*pi) == 3*principal_branch(x, 2*pi)\n    assert principal_branch(exp_polar(pi*I)*x, 2*pi) == exp_polar(pi*I)*principal_branch(x, 2*pi)\n    assert principal_branch(exp_polar(3*pi*I)*x, 2*pi) == exp_polar(-pi*I)*principal_branch(x, 2*pi)\n    assert principal_branch(exp_polar(4*pi*I)*x, 2*pi) == principal_branch(x, 2*pi)\n", "def test_re_im_conjugate():\n    x, y = symbols('x y', real=True)\n    z = Symbol('z')\n    assert re(x) == x\n    assert im(x) == 0\n    assert conjugate(x) == x\n    assert re(1 + I) == 1\n    assert im(1 + I) == 1\n    assert conjugate(1 + I) == 1 - I\n    assert re(x + I*y) == x\n    assert im(x + I*y) == y\n    assert conjugate(x + I*y) == x - I*y\n    assert re(z).conjugate() == re(z)\n    assert im(z).conjugate() == im(z)\n    assert conjugate(re(z)) == re(z)\n    assert conjugate(im(z)) == im(z)\n", "def test_polarify():\n    x, y = symbols('x y')\n    expr = (-x)**y\n    pol_expr, r = polarify(expr)\n    assert pol_expr.expand() == r[x]**r[y]*exp_polar(r[y]*I*pi)\n    assert polarify(x*(1+y), lift=True) == polar_lift(x)*polar_lift(y + 1)\n    assert polarify(1 + sin((1 + I)*x)) == (sin(x*polar_lift(1 + I)) + 1, {x: x})\n", "def test_polar_lift():\n    x = Symbol('x')\n    p = Symbol('p', polar=True)\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(I + 2) == polar_lift(2 + I)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*p) == 4*p\n", "def test_polar_lift():\n    p = Symbol('p', polar=True)\n    x = Symbol('x')\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(I + 2) == polar_lift(2 + I)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*p) == 4*p\n"], "sample_131": ["def test_MCodePrinter_print_Pow():\n    assert mcode(x**2) == 'x^2'\n    assert mcode(x**(1/2)) == 'x^(1/2)'\n    assert mcode(x**-1) == 'x^(-1)'\n", "def test_mcode_print_pow():\n    assert mcode(x**2) == 'x^2'\n    assert mcode(1/(x**2)) == '1/x^2'\n    assert mcode(x**(1/2)) == 'x^(1/2)'\n", "def test_mcode_Pow():\n    assert mcode(x**2) == 'x^2'\n    assert mcode(x**(1/2)) == 'x^(1/2)'\n    assert mcode(x**-1) == 'x^(-1)'\n    assert mcode(1/x) == 'x^(-1)'\n", "def test_Pow():\n    assert mcode(x**3) == 'x^3'\n    assert mcode(2**x) == '2^x'\n    assert mcode(S.Half**x) == '(1/2)^x'\n", "def test_MCodePrinter_print_Pow():\n    assert mcode(x**2) == 'x^2'\n    assert mcode(x**(1/2)) == 'x^(1/2)'\n    assert mcode(x**3*y**4) == 'x^3*y^4'\n"], "sample_29": ["def test_ref_expression(self):\n    query = Company.objects.filter(\n        num_employees=OuterRef(\"num_employees\")\n    ).values(\"name\")\n    self.assertIsInstance(query.query.where.children[0].rhs, Ref)\n    self.assertEqual(\n        str(query.query.where.children[0].rhs),\n        \"(OuterRef:num_employees)\"\n    )\n", "def test_deferred_annotation_fields(self):\n    qs = Company.objects.defer('name').annotate(\n        employee_count=Count('employees'),\n        chair_count=F('num_chairs'),\n    )\n    self.assertIn('employee_count', qs.first().__dict__)\n    self.assertIn('chair_count', qs.first().__dict__)\n    with self.assertRaises(AttributeError):\n        qs.first().name\n", "def test_select_nested(self):\n    qs = Company.objects.annotate(\n        foo=Count('employees', filter=Q(employees__firstname='John')),\n        bar=Count('employees', filter=Q(employees__lastname='Doe'))\n    ).values('foo').annotate(baz=Sum('bar')).values('baz')\n    self.assertEqual(str(qs.query), 'SELECT SUM((SELECT COUNT(*) FROM ...)) AS \"baz\" FROM ...')\n", "def test_query_build_where(self):\n    q = Q(name='test')\n    query = Query(Company)\n    where_clause = query.build_where(q)\n    self.assertIsInstance(where_clause, WhereNode)\n    self.assertEqual(len(where_clause.children), 1)\n    lookup = where_clause.children[0]\n    self.assertIsInstance(lookup, Lookup)\n    self.assertEqual(lookup.lhs.output_field.name, 'name')\n    self.assertEqual(lookup.rhs, 'test')\n\n    q = ~Q(name='test')\n    query = Query(Company)\n    where_clause = query.build_where(q)\n    self.assertIsInstance(where_clause, WhereNode)\n    self.assertEqual(len(where_clause.children), 1)\n    lookup = where_clause.children[0]\n    self.assertIsInstance(lookup, Lookup)\n    self.assertEqual(lookup.lhs.output_field.name, 'name')\n    self.assertEqual(lookup.rhs, 'test')\n    self.assertTrue(where_clause.negated)\n", "def test_resolve_expression_with_subquery(self):\n    subquery = Company.objects.filter(num_employees__gt=OuterRef('num_employees'))\n    queryset = Company.objects.annotate(has_more_employees=Exists(subquery))\n    with CaptureQueriesContext(connection) as captured_queries:\n        list(queryset)\n    self.assertEqual(len(captured_queries.captured_queries), 2)\n"], "sample_32": ["def test_key_transform_in_lookup(self):\n    obj = JSONModel.objects.create(json={\n        'a': 1,\n        'b': 2,\n        'c': 3,\n    })\n    qs = JSONModel.objects.filter(json__keys__in=['a', 'b'])\n    self.assertEqual(qs.count(), 1)\n    self.assertIn(obj, qs)\n\n    qs = JSONModel.objects.filter(json__keys__in=['a', 'd'])\n    self.assertEqual(qs.count(), 1)\n    self.assertIn(obj, qs)\n\n    qs = JSONModel.objects.filter(json__keys__in=['d', 'e'])\n    self.assertEqual(qs.count(), 0)\n    self.assertNotIn(obj, qs)\n", "def test_key_transform_nested_lookup(self):\n    obj = JSONModel.objects.create(value={'a': {'b': 'c'}})\n    self.assertSequenceEqual(\n        JSONModel.objects.filter(value__a__b='c'),\n        [obj],\n    )\n    self.assertSequenceEqual(\n        JSONModel.objects.filter(value__a__b='d'),\n        [],\n    )\n", "def test_key_transform_text_lookup_mixin(self):\n    # Test that KeyTransformTextLookupMixin correctly uses the ->> operator\n    # on PostgreSQL.\n    with connection.cursor() as cursor:\n        cursor.execute('INSERT INTO jsonfield_tests_jsonmodel (field1) VALUES (%s)', ['{\"a\": \"b\"}'])\n\n    # Use a custom lookup to ensure we're using the correct operator.\n    class CustomContains(KeyTransformTextLookupMixin, lookups.Contains):\n        pass\n\n    JSONModel.objects.filter(field1__a__contains='b').delete()\n    self.assertEqual(JSONModel.objects.count(), 0)\n", "def test_key_transform_text_lookup_mixin(self):\n    mixin = KeyTransformTextLookupMixin()\n    key_transform = KeyTransform('key', 'value')\n    with self.assertRaises(TypeError):\n        mixin.__init__(key_transform, 'rhs')\n    with mock.patch.object(KeyTransformTextLookupMixin, '__init__') as mock_init:\n        mixin.__init__(key_transform, 'rhs')\n        mock_init.assert_called_once_with(key_transform, 'rhs')\n", "def test_key_transform_factory(self):\n    factory = KeyTransformFactory('key_name')\n    key_transform = factory(JSONModel.json_field)\n    self.assertIsInstance(key_transform, KeyTransform)\n    self.assertEqual(key_transform.key_name, 'key_name')\n    self.assertEqual(key_transform.lhs, JSONModel.json_field)\n"], "sample_62": ["    def setUp(self):\n        self.cache_dir = tempfile.mkdtemp()\n        self.cache = FileBasedCache(self.cache_dir, {})\n", "    def test_key_to_file(self):\n        cache = caches[\"default\"]\n        key = \"test-key\"\n        version = 1\n        file_path = cache._key_to_file(key, version)\n        self.assertTrue(file_path.startswith(cache._dir))\n        self.assertIn(md5((key + str(version)).encode(), usedforsecurity=False).hexdigest(), file_path)\n", "    def test_file_based_cache(self):\n        # Set a value in the cache\n        cache.set(\"key\", \"value\")\n        self.assertEqual(cache.get(\"key\"), \"value\")\n\n        # Check that the cache file exists\n        cache_dir = settings.CACHES[\"default\"][\"LOCATION\"]\n        cache_file = os.path.join(cache_dir, md5(\"key\".encode()).hexdigest() + \".djcache\")\n        self.assertTrue(os.path.exists(cache_file))\n\n        # Delete the cache file and check that the value is gone\n        os.remove(cache_file)\n        self.assertIsNone(cache.get(\"key\"))\n\n        # Try to set an expired value in the cache\n        with mock.patch(\"time.time\") as mock_time:\n            mock_time.return_value = 1000\n            cache.set(\"key\", \"value\", timeout=1)\n        self.assertIsNone(cache.get(\"key\"))\n", "    def test_filebasedcache_cull(self):\n        cache = caches[\"default\"]\n        cache.clear()\n\n        # Create 10 keys and add them to the cache\n        for i in range(10):\n            cache.set(f\"key{i}\", f\"value{i}\")\n\n        # Set the max entries and cull frequency to 5\n        cache._max_entries = 5\n        cache._cull_frequency = 2\n\n        # Call _cull to remove some cache entries\n        cache._cull()\n\n        # Check if the number of cache files is less than or equal to max entries\n        self.assertLessEqual(len(cache._list_cache_files()), cache._max_entries)\n\n        # Clean up\n        cache.clear()\n", "    def test_filebased_cache(self):\n        cache = caches[\"default\"]\n        key = \"test_key\"\n        value = \"test_value\"\n\n        # Test set and get\n        cache.set(key, value)\n        self.assertEqual(cache.get(key), value)\n\n        # Test add\n        self.assertFalse(cache.add(key, \"new_value\"))\n        cache.delete(key)\n        self.assertTrue(cache.add(key, \"new_value\"))\n        self.assertEqual(cache.get(key), \"new_value\")\n\n        # Test touch\n        cache.touch(key, 10)\n        self.assertGreater(cache.get(key), time.time() + 5)\n\n        # Test delete\n        cache.delete(key)\n        self.assertIsNone(cache.get(key))\n\n        # Test clear\n        cache.set(key, value)\n        cache.clear()\n        self.assertIsNone(cache.get(key))\n\n        # Test cull\n        cache._max_entries = 2\n        cache._cull_frequency = 1\n        cache.set(key, value)\n        cache.set(\"key2\", \"value2\")\n        cache.set(\"key3\", \"value3\")\n        self.assertIsNone(cache.get(key))\n\n        # Test _is_expired\n        cache._write_content(open(cache._key_to_file(key), \"wb\"), -1, value)\n        with open(cache._key_to_file(key), \"rb\") as f:\n            self.assertTrue(cache._is_expired(f))\n"], "sample_33": ["def test_connect_with_dispatch_uid(self):\n        pass\n\n    a_signal.connect(receiver, dispatch_uid='test_uid')\n    self.assertEqual(len(a_signal.receivers), 1)\n\n    # Connecting with the same dispatch_uid should not add a new receiver\n    a_signal.connect(receiver, dispatch_uid='test_uid')\n    self.assertEqual(len(a_signal.receivers), 1)\n\n    # Disconnecting with the dispatch_uid should remove the receiver\n    a_signal.disconnect(dispatch_uid='test_uid')\n    self.assertEqual(len(a_signal.receivers), 0)\n", "def test_connect_weak_ref_cleanup(self):\n    # Connect a weakref receiver and verify it's cleaned up properly\n    callable_obj = Callable()\n    ref = weakref.ref(callable_obj)\n    a_signal.connect(ref, weak=False)\n\n    del callable_obj\n    garbage_collect()\n\n    self.assertTestIsClean(a_signal)\n", "def test_connect_disconnect_use_caching(self):\n        pass\n\n    signal = Signal(use_caching=True)\n    signal.connect(receiver)\n    self.assertTrue(signal.has_listeners())\n\n    # Disconnect and verify that receiver is removed from cache.\n    signal.disconnect(receiver)\n    self.assertFalse(signal.has_listeners())\n    self.assertEqual(signal.sender_receivers_cache, {})\n", "def test_connect_invalid_receivers(self):\n    msg = \"Signal receivers must be callable.\"\n    with self.assertRaisesMessage(TypeError, msg):\n        a_signal.connect(\"non-callable\")\n\n    msg = \"Signal receivers must accept keyword arguments (**kwargs).\"\n    with self.assertRaisesMessage(ValueError, msg):\n        a_signal.connect(lambda x: x)\n", "def test_connect_invalid_receivers(self):\n    with self.assertRaisesMessage(ValueError, \"Signal receivers must accept keyword arguments (**kwargs).\"):\n        a_signal.connect(lambda x: x)\n"], "sample_93": ["def test_tmp_path_factory_basetemp(tmp_path_factory: TempPathFactory, monkeypatch: MonkeyPatch) -> None:\n    \"\"\"Test that tmp_path_factory returns the correct basetemp directory.\"\"\"\n    basetemp = tmp_path_factory.getbasetemp()\n    assert basetemp.exists()\n    assert basetemp.is_dir()\n\n    # Test that setting _given_basetemp changes the base directory.\n    new_basetemp = Path(\"new-basetemp\")\n    monkeypatch.setattr(tmp_path_factory, \"_given_basetemp\", new_basetemp)\n    assert tmp_path_factory.getbasetemp() == new_basetemp\n\n    # Test that _given_basetemp is absolute.\n    abs_basetemp = Path(os.path.abspath(str(new_basetemp)))\n    monkeypatch.setattr(tmp_path_factory, \"_given_basetemp\", new_basetemp)\n    assert tmp_path_factory._given_basetemp == abs_basetemp\n", "def test_tmp_path_factory_basetemp(tmp_path_factory: TempPathFactory, tmpdir: Path) -> None:\n    \"\"\"Test that the basetemp directory is correctly set and used by the TempPathFactory.\"\"\"\n    assert tmp_path_factory.getbasetemp().exists()\n    new_basetemp = tmpdir.joinpath(\"new-basetemp\")\n    tmp_path_factory._basetemp = new_basetemp\n    assert tmp_path_factory.getbasetemp() == new_basetemp\n    # Ensure that the new basetemp directory is created\n    tmp_path_factory.mktemp(\"test\", numbered=True)\n    assert new_basetemp.exists()\n", "def test_get_user(monkeypatch: MonkeyPatch) -> None:\n    import getpass\n\n        return \"mocked_user\"\n\n    monkeypatch.setattr(getpass, \"getuser\", mock_getuser)\n    assert get_user() == \"mocked_user\"\n\n        raise ImportError\n\n    monkeypatch.setattr(getpass, \"getuser\", mock_getuser_raise_import_error)\n    assert get_user() is None\n\n        raise KeyError\n\n    monkeypatch.setattr(getpass, \"getuser\", mock_getuser_raise_key_error)\n    assert get_user() is None\n", "def test_temp_path_factory_basetemp(tmp_path: Path, monkeypatch: MonkeyPatch) -> None:\n    \"\"\"Test that TempPathFactory correctly handles the basetemp option (#4427).\"\"\"\n    basetemp = tmp_path / \"basetemp\"\n    monkeypatch.setattr(sys, \"argv\", sys.argv + [\"-p\", \"no:pytest-shutil\", \"--basetemp\", str(basetemp)])\n    config = Config.from_prepared_config(\n        pytester._config_for_test(), [\"-vv\"], preparse=None  # type: ignore\n    )\n    temp_path_factory = TempPathFactory.from_config(config)\n    assert temp_path_factory.getbasetemp() == basetemp.resolve()\n", "def test_tmp_path_factory_basetemp(tmp_path_factory: TempPathFactory, monkeypatch: MonkeyPatch) -> None:\n    \"\"\"Test that tmp_path_factory correctly handles the basetemp parameter.\"\"\"\n    basetemp = Path(\"my_basetemp\")\n    monkeypatch.setattr(tmp_path_factory, \"_given_basetemp\", basetemp)\n    assert tmp_path_factory.getbasetemp() == basetemp.resolve()\n"], "sample_42": ["    def test_serializer_factory_float(self):\n        value = float('inf')\n        serializer = serializer_factory(value)\n        self.assertIsInstance(serializer, FloatSerializer)\n\n        serialized_value, imports = serializer.serialize()\n        self.assertEqual(serialized_value, 'float(\"inf\")')\n        self.assertEqual(imports, set())\n", "    def test_serializer_factory_float(self):\n        value = 1.23\n        serializer = serializer_factory(value)\n        self.assertIsInstance(serializer, FloatSerializer)\n", "    def test_serializer_factory_with_lazy_object(self):\n        lazy_object = SimpleLazyObject(lambda: 'hello')\n        serializer = serializer_factory(lazy_object)\n        self.assertIsInstance(serializer, BaseSimpleSerializer)\n        string, imports = serializer.serialize()\n        self.assertEqual(string, \"'hello'\")\n        self.assertEqual(imports, set())\n", "    def test_serialize_float(self):\n        serializer = FloatSerializer(1.0)\n        string, imports = serializer.serialize()\n        self.assertEqual(string, '1.0')\n        self.assertEqual(imports, set())\n\n        serializer = FloatSerializer(float('inf'))\n        string, imports = serializer.serialize()\n        self.assertEqual(string, 'float(\"inf\")')\n        self.assertEqual(imports, set())\n\n        serializer = FloatSerializer(float('nan'))\n        string, imports = serializer.serialize()\n        self.assertEqual(string, 'float(\"nan\")')\n        self.assertEqual(imports, set())\n", "    def test_serializer_factory(self):\n        # Test that the serializer factory can handle various types of values\n        self.assertIsInstance(serializer_factory(123), BaseSerializer)\n        self.assertIsInstance(serializer_factory('hello'), BaseSerializer)\n        self.assertIsInstance(serializer_factory([1, 2, 3]), BaseSerializer)\n        self.assertIsInstance(serializer_factory({'a': 1, 'b': 2}), BaseSerializer)\n        self.assertIsInstance(serializer_factory(datetime.datetime(2022, 1, 1)), BaseSerializer)\n        self.assertIsInstance(serializer_factory(decimal.Decimal('123.45')), BaseSerializer)\n        self.assertIsInstance(serializer_factory(uuid.UUID('12345678-1234-1234-1234-123456789012')), BaseSerializer)\n        self.assertIsInstance(serializer_factory(re.compile('pattern')), BaseSerializer)\n        self.assertIsInstance(serializer_factory(pathlib.PurePath('/path/to/file')), BaseSerializer)\n        self.assertIsInstance(serializer_factory(os.PathLike('/path/to/file')), BaseSerializer)\n        self.assertIsInstance(serializer_factory(models.Field()), ModelFieldSerializer)\n        self.assertIsInstance(serializer_factory(models.manager.BaseManager()), ModelManagerSerializer)\n        self.assertIsInstance(serializer_factory(Operation()), OperationSerializer)\n        self.assertIsInstance(serializer_factory(type), TypeSerializer)\n        self.assertIsInstance(serializer_factory(DeconstructibleInstances()), DeconstructableSerializer)\n        self.assertIsInstance(serializer_factory(Money('123.45')), DeconstructableSerializer)\n"], "sample_142": ["def test_roundrobin():\n    from sympy.utilities.iterables import roundrobin\n    assert list(roundrobin('ABC', 'D', 'EF')) == ['A', 'D', 'E', 'B', 'F', 'C']\n    assert list(roundrobin([1, 2], [3, 4, 5])) == [1, 3, 2, 4, 5]\n    assert list(roundrobin('AB', 'CD', 'EF')) == ['A', 'C', 'E', 'B', 'D', 'F']\n", "def test_minlex():\n    assert minlex((1, 2, 0)) == (0, 1, 2)\n    assert minlex((1, 0, 2)) == (0, 2, 1)\n    assert minlex((1, 0, 2), directed=False) == (0, 1, 2)\n    assert minlex('11010011000', directed=True) == '00011010011'\n    assert minlex('11010011000', directed=False) == '00011001011'\n", "def test_rotations():\n    assert list(rotations([1,2,3])) == [[1, 2, 3], [2, 3, 1], [3, 1, 2]]\n    assert list(rotations([1,2,3], -1)) == [[1, 2, 3], [3, 1, 2], [2, 3, 1]]\n    assert list(rotations('abc')) == [['a', 'b', 'c'], ['b', 'c', 'a'], ['c', 'a', 'b']]\n    assert list(rotations('abc', -1)) == [['a', 'b', 'c'], ['c', 'a', 'b'], ['b', 'c', 'a']]\n", "def test_generate_oriented_forest():\n    # number of oriented forests on n nodes is n^(n-2)\n    assert len(list(generate_oriented_forest(1))) == 1**(-1 + 1)\n    assert len(list(generate_oriented_forest(2))) == 2**(2 - 2)\n    assert len(list(generate_oriented_forest(3))) == 3**(3 - 2)\n    assert len(list(generate_oriented_forest(4))) == 4**(4 - 2)\n    assert len(list(generate_oriented_forest(5))) == 5**(5 - 2)\n", "def test_roundrobin():\n    from sympy.utilities.iterables import roundrobin\n\n    # Test with iterables of same length\n    a = [1, 2, 3]\n    b = ['a', 'b', 'c']\n    c = [True, False, True]\n    expected = [1, 'a', True, 2, 'b', False, 3, 'c', True]\n    assert list(roundrobin(a, b, c)) == expected\n\n    # Test with iterables of different lengths\n    a = [1, 2, 3]\n    b = ['a', 'b']\n    c = [True, False, True, False]\n    expected = [1, 'a', True, 2, 'b', False, 3, True, False]\n    assert list(roundrobin(a, b, c)) == expected\n\n    # Test with empty iterable\n    a = [1, 2, 3]\n    b = []\n    c = [True, False, True]\n    expected = [1, True, 2, False, 3, True]\n    assert list(roundrobin(a, b, c)) == expected\n\n    # Test with single iterable\n    a = [1, 2, 3]\n    expected = [1, 2, 3]\n    assert list(roundrobin(a)) == expected\n\n    # Test with no iterables\n    expected = []\n    assert list(roundrobin()) == expected\n"], "sample_120": ["def test_matrix_element():\n    i, j = symbols('i j', integer=True)\n    A_ij = MatrixElement(A, i, j)\n    assert A_ij.parent == A\n    assert A_ij.i == i\n    assert A_ij.j == j\n    assert A_ij.is_symbol\n    assert A_ij.diff(A) == KroneckerDelta(i, i)*KroneckerDelta(j, j)\n\n    # Check that MatrixElement can handle matrix base objects\n    X = ImmutableMatrix([[1, 2], [3, 4]])\n    X_ij = MatrixElement(X, i, j)\n    assert X_ij.doit() == X[i, j]\n", "def test_MatrixElement():\n    A = MatrixSymbol('A', 3, 3)\n    i, j = symbols('i j')\n    assert A[i, j] == MatrixElement(A, i, j)\n    assert MatrixElement(A, 1, 2).diff(A[1, 2]) == 1\n    assert MatrixElement(A, 1, 1).diff(A[2, 2]) == 0\n    assert MatrixElement(A, i, j).diff(A[i, j]) == 1\n", "def test_matrix_element():\n    i, j = symbols('i j', integer=True)\n    A = MatrixSymbol('A', n, m)\n    A_ij = MatrixElement(A, i, j)\n    assert A_ij.parent == A\n    assert A_ij.i == i\n    assert A_ij.j == j\n    assert A_ij.free_symbols == {A, i, j}\n    assert A_ij.diff(i) == S.Zero\n    assert A_ij.diff(A) == KroneckerDelta(i, j)\n", "def test_matrix_element():\n    # Test MatrixElement creation\n    A = MatrixSymbol('A', 3, 3)\n    assert isinstance(A[1, 2], MatrixElement)\n\n    # Test MatrixElement parent and indices\n    me = MatrixElement(A, 1, 2)\n    assert me.parent == A\n    assert me.i == 1\n    assert me.j == 2\n\n    # Test MatrixElement doit\n    assert me.doit() == A[1, 2]\n\n    # Test MatrixElement derivative\n    x = symbols('x')\n    B = MatrixSymbol('B', 3, 3)\n    assert diff(me, x) == S.Zero\n    assert diff(me, B) == S.Zero\n    assert diff(me, B[1, 2]) == KroneckerDelta(1, 1)*KroneckerDelta(2, 2)\n", "def test_MatrixElement():\n    i, j = symbols('i j', integer=True)\n    x = MatrixSymbol('x', n, m)\n    assert x[i, j] == MatrixElement(x, i, j)\n    assert MatrixElement(x, i, j).parent == x\n    assert MatrixElement(x, i, j).i == i\n    assert MatrixElement(x, i, j).j == j\n    assert MatrixElement(x, i, j).is_symbol\n    assert MatrixElement(x, i, j).is_commutative\n    assert MatrixElement(x, i, j).doit() == x[i, j]\n"], "sample_14": ["    def test_serialize_float(self):\n        serializer = FloatSerializer(1.5)\n        result, imports = serializer.serialize()\n        self.assertEqual(result, '1.5')\n        self.assertEqual(imports, set())\n\n        serializer = FloatSerializer(float('inf'))\n        result, imports = serializer.serialize()\n        self.assertEqual(result, \"float('inf')\")\n        self.assertEqual(imports, set())\n\n        serializer = FloatSerializer(float('nan'))\n        result, imports = serializer.serialize()\n        self.assertEqual(result, \"float('nan')\")\n        self.assertEqual(imports, set())\n", "    def test_serialize_float(self):\n        value = float('inf')\n        serializer = FloatSerializer(value)\n        serialized, imports = serializer.serialize()\n        self.assertEqual(serialized, 'float(\"inf\")')\n        self.assertEqual(imports, set())\n", "    def test_serialize_float_nan_and_infinity(self):\n        serializer = FloatSerializer(float('nan'))\n        self.assertEqual(serializer.serialize(), ('float(\"nan\")', set()))\n        serializer = FloatSerializer(float('inf'))\n        self.assertEqual(serializer.serialize(), ('float(\"inf\")', set()))\n        serializer = FloatSerializer(float('-inf'))\n        self.assertEqual(serializer.serialize(), ('float(\"-inf\")', set()))\n", "    def test_serialize_float(self):\n        serializer = FloatSerializer(float('inf'))\n        self.assertEqual(serializer.serialize(), ('float(\"inf\")', set()))\n        serializer = FloatSerializer(float('-inf'))\n        self.assertEqual(serializer.serialize(), ('float(\"-inf\")', set()))\n        serializer = FloatSerializer(float('nan'))\n        self.assertEqual(serializer.serialize(), ('float(\"nan\")', set()))\n", "    def test_serializer_factory(self):\n        value = decimal.Decimal('1.23')\n        serializer = serializer_factory(value)\n        self.assertIsInstance(serializer, DecimalSerializer)\n        self.assertEqual(serializer.serialize(), (repr(value), {\"from decimal import Decimal\"}))\n"], "sample_157": ["def test_tensor_product_simp_Mul():\n    e = TP(A, B) * TP(C, D)\n    assert tensor_product_simp(e) == (A*C)*(B*D)\n    e = TP(A, B) * TP(C, D) * x\n    assert tensor_product_simp(e) == x*(A*C)*(B*D)\n    e = x * TP(A, B) * TP(C, D)\n    assert tensor_product_simp(e) == x*(A*C)*(B*D)\n    e = TP(A, B) * x * TP(C, D)\n    assert tensor_product_simp(e) == x*(A*C)*(B*D)\n", "def test_tensor_product_simp_Mul():\n    assert tensor_product_simp(TP(A, B)*TP(C, D)) == (A*C)*(B*D)\n    assert tensor_product_simp(TP(A, B)*TP(C, D)*x) == x*(A*C)*(B*D)\n    assert tensor_product_simp(x*TP(A, B)*TP(C, D)) == x*(A*C)*(B*D)\n    assert tensor_product_simp(TP(A, B)**2) == TP(A**2, B**2)\n    assert tensor_product_simp((TP(A, B)*TP(C, D))**2) == ((A*C)*(B*D))**2\n", "def test_tensor_product_simp_Mul():\n    assert tensor_product_simp(TP(A, B)*TP(C, D)) == TP(A*C, B*D)\n    assert tensor_product_simp(TP(A, B)*TP(C, D)*x) == x*TP(A*C, B*D)\n    assert tensor_product_simp(x*TP(A, B)*TP(C, D)) == x*TP(A*C, B*D)\n    assert tensor_product_simp(TP(A, B)**2) == TP(A**2, B**2)\n", "def test_tensor_product_simp_Pow():\n    assert tensor_product_simp_Pow(A**2) == A**2\n    assert tensor_product_simp_Pow((TP(A, B))**2) == TP(A**2, B**2)\n    assert tensor_product_simp_Pow((TP(A, B))**x) == TP(A**x, B**x)\n", "def test_tensor_product_simp():\n    assert tensor_product_simp(TP(A, B)*TP(C, D)) == TP(A*C, B*D)\n    assert tensor_product_simp(TP(A, B)*TP(C, D)**2) == TP(A*C**2, B*D**2)\n    assert tensor_product_simp((TP(A, B)*TP(C, D))**2) == TP((A*C)**2, (B*D)**2)\n    assert tensor_product_simp(Comm(TP(A, B), TP(C, D))) == Comm(TP(A, B), TP(C, D))\n    assert tensor_product_simp(Comm(TP(A, B), TP(C, D)).doit()) == TP(A*C - C*A, B*D) + TP(A*D, -B*C + D*B)\n"], "sample_110": ["def test_affinity_propagation_precomputed():\n    # Test affinity propagation with precomputed affinity matrix\n    S = euclidean_distances(X)\n    model = AffinityPropagation(affinity='precomputed')\n    model.fit(S)\n\n    assert_array_equal(model.labels_, model.predict(X))\n    assert_array_equal(model.cluster_centers_indices_, np.unique(model.labels_))\n\n    # Check that fit_predict works as expected\n    labels = model.fit_predict(S)\n    assert_array_equal(labels, model.labels_)\n", "def test_affinity_propagation_precomputed_affinity():\n    # Test affinity propagation with precomputed affinity matrix\n    S = -euclidean_distances(X, squared=True)\n    cluster_centers_indices, labels = affinity_propagation(S, random_state=0)\n\n    af = AffinityPropagation(affinity='precomputed', random_state=0)\n    af.fit(S)\n\n    assert_array_equal(af.cluster_centers_indices_, cluster_centers_indices)\n    assert_array_equal(af.labels_, labels)\n", "def test_affinity_propagation_predict():\n    # Test predict method of AffinityPropagation\n    ap = AffinityPropagation(random_state=0)\n    with assert_no_warnings():\n        ap.fit(X)\n    labels = ap.labels_\n    predicted_labels = ap.predict(X)\n    assert_array_equal(labels, predicted_labels)\n\n    # Test when fit does not converge\n    ap = AffinityPropagation(max_iter=1, random_state=0)\n    with assert_warns(ConvergenceWarning):\n        ap.fit(X)\n    assert_array_equal(np.array([-1] * X.shape[0]), ap.predict(X))\n", "def test_affinity_propagation_equal_similarities_and_preferences():\n    # Test that affinity propagation behaves as expected when all similarities\n    # and preferences are equal.\n    S = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])\n    preference = np.array([1, 1, 1])\n\n    assert _equal_similarities_and_preferences(S, preference)\n\n    cluster_centers_indices, labels = affinity_propagation(S, preference)\n    assert_array_equal(cluster_centers_indices, np.arange(3))\n    assert_array_equal(labels, np.arange(3))\n", "def test_affinity_propagation_predict():\n    # Test that predict method works after fit\n    ap = AffinityPropagation()\n    ap.fit(X)\n    labels = ap.predict(X)\n    assert_array_equal(labels, ap.labels_)\n"], "sample_136": ["def test_blockcut():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (1, 3))\n    assert isinstance(B, BlockMatrix)\n    assert ImmutableMatrix(B.blocks[0, 1]) == Matrix([[1, 2, 3]])\n    assert B.shape == (4, 4)\n    assert B.blockshape == (2, 2)\n    assert B.rowblocksizes == [1, 3]\n    assert B.colblocksizes == [1, 3]\n", "def test_blockcut():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (1, 3))\n    assert isinstance(B, BlockMatrix)\n    assert B.blocks[0, 1] == Matrix([[1, 2, 3]])\n", "def test_block_collapse_blockdiag():\n    X = MatrixSymbol('X', n, n)\n    Y = MatrixSymbol('Y', m, m)\n    B = BlockDiagMatrix(X, Y)\n    assert block_collapse(B) == B\n    assert block_collapse(2*B) == BlockDiagMatrix(2*X, 2*Y)\n", "def test_bc_matadd():\n    X = MatrixSymbol('X', n, n)\n    Y = MatrixSymbol('Y', n, n)\n    Z = MatrixSymbol('Z', n, n)\n    expr = X + BlockMatrix([[Y, Z]])\n    result = bc_matadd(expr)\n    assert isinstance(result, MatAdd)\n    assert len(result.args) == 2\n    assert result.args[0] == X\n    assert result.args[1].structurally_equal(BlockMatrix([[Y, Z]]))\n", "def test_bc_block_plus_ident():\n    A = BlockMatrix([[MatrixSymbol('A', n, n)]])\n    B = BlockDiagMatrix(MatrixSymbol('B', n, n), MatrixSymbol('C', n, n))\n    expr = A + Identity(n) + B\n    result = bc_block_plus_ident(expr)\n    assert result == 2*Identity(n) + B\n"], "sample_80": ["def test_pretty_print():\n    assert formatting.pretty_print(\"foobar\", 10) == \"foobar   \"\n    assert formatting.pretty_print(\"foobar\", 5) == \"fo...\"\n    assert formatting.pretty_print(\"foobar\", 6) == \"foobar\"\n    assert formatting.pretty_print(1.23456789, 4) == \"1.23\"\n", "def test_pretty_print():\n    max_name_length = 10\n    col_width = formatting._calculate_col_width([\"short\", \"very_long_variable_name\"])\n    assert col_width == max_name_length + 6\n\n    short_col = formatting.pretty_print(\"short\", col_width)\n    long_col = formatting.pretty_print(\"very_long_variable_name\", col_width)\n\n    assert len(short_col) == col_width\n    assert len(long_col) == col_width\n    assert short_col.count(\" \") == col_width - len(\"short\")\n", "def test_inline_variable_array_repr():\n    var = xr.Variable([1, 2, 3], name=\"test\")\n    expected = \"[1 2 3]\"\n    assert formatting.inline_variable_array_repr(var, 100) == expected\n\n    # Test with limited width\n    expected = \"[1 2 ...]\"\n    assert formatting.inline_variable_array_repr(var, 5) == expected\n\n    # Test with non-numeric data\n    var = xr.Variable([\"a\", \"b\", \"c\"], name=\"test\")\n    expected = \"['a' 'b' 'c']\"\n    assert formatting.inline_variable_array_repr(var, 100) == expected\n", "def test_inline_variable_array_repr():\n    v = xr.Variable((\"x\",), np.array([1, 2, 3]))\n    assert formatting.inline_variable_array_repr(v, 10) == \"[1 2 3]\"\n    v = xr.Variable((\"x\", \"y\"), np.array([[1, 2], [3, 4]]))\n    assert formatting.inline_variable_array_repr(v, 10) == \"[[1 2]\\n [3 4]]\"\n    v = xr.Variable((\"x\", \"y\", \"z\"), np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]]))\n    assert formatting.inline_variable_array_repr(v, 20) == \"[[[1 2]\\n  [3 4]]\\n\\n [[5 6]\\n  [7 8]]]\"\n", "def test_pretty_print():\n    assert formatting.pretty_print(\"hello\", 10) == \"hello     \"\n    assert formatting.pretty_print(\"hello world\", 5) == \"hello...\"\n"], "sample_99": ["def test_neighbors_base_algorithm_metric_auto():\n    # Test that algorithm and metric are correctly set when using 'auto'\n    X = iris.data\n\n    # If n_neighbors is less than the number of samples, use 'ball_tree'\n    nn = neighbors.NearestNeighbors(n_neighbors=5, algorithm='auto')\n    nn.fit(X)\n    assert_equal(nn._fit_method, 'ball_tree')\n\n    # If n_neighbors is equal to the number of samples, use 'brute'\n    nn = neighbors.NearestNeighbors(n_neighbors=X.shape[0], algorithm='auto')\n    nn.fit(X)\n    assert_equal(nn._fit_method, 'brute')\n\n    # If metric is callable, use 'ball_tree'\n    nn = neighbors.NearestNeighbors(n_neighbors=5, algorithm='auto',\n                                   metric=lambda x, y: np.sum(x - y))\n    nn.fit(X)\n    assert_equal(nn._fit_method, 'ball_tree')\n\n    # If metric is 'precomputed', use 'brute'\n    nn = neighbors.NearestNeighbors(n_neighbors=5, algorithm='auto',\n                                   metric='precomputed')\n    nn.fit(X)\n    assert_equal(nn._fit_method, 'brute')\n", "def test_kneighbors_sparse():\n    # Test kneighbors with sparse input\n    X = csr_matrix(np.array([[0, 3], [1, 4], [2, 5]]))\n    y = np.array([0, 0, 1])\n\n    for algo in ALGORITHMS:\n        for metric in VALID_METRICS_SPARSE['brute']:\n            neigh = neighbors.KNeighborsClassifier(n_neighbors=2,\n                                                  algorithm=algo,\n                                                  metric=metric)\n            neigh.fit(X, y)\n\n            # check kneighbors returns the right indices and distances\n            dist, ind = neigh.kneighbors(X, return_distance=True)\n\n            assert_equal(dist.shape, (3, 2))\n            assert_equal(ind.shape, (3, 2))\n\n            # check the actual values returned by kneighbors\n            if metric == 'euclidean':\n                # Euclidean distance is easy to calculate manually\n                dist_manual = pairwise_distances(X, metric='euclidean')\n                dist_manual.sort(axis=1)\n                assert_array_almost_equal(dist, dist_manual[:, 1:3])\n", "def test_neighbors_base_algorithm():\n    # Test neighbors base algorithm\n    X = iris.data\n    n_neighbors = 5\n\n    # Test ball_tree algorithm\n    nbrs = neighbors.NeighborsBase(algorithm='ball_tree')\n    nbrs._fit(X)\n    assert_equal(nbrs._fit_method, 'ball_tree')\n\n    # Test kd_tree algorithm\n    nbrs = neighbors.NeighborsBase(algorithm='kd_tree')\n    nbrs._fit(X)\n    assert_equal(nbrs._fit_method, 'kd_tree')\n\n    # Test brute algorithm\n    nbrs = neighbors.NeighborsBase(algorithm='brute')\n    nbrs._fit(X)\n    assert_equal(nbrs._fit_method, 'brute')\n\n    # Test auto algorithm\n    nbrs = neighbors.NeighborsBase(algorithm='auto')\n    nbrs._fit(X)\n    assert_in(nbrs._fit_method, ['ball_tree', 'kd_tree', 'brute'])\n\n    # Test invalid algorithm\n    nbrs = neighbors.NeighborsBase(algorithm='invalid')\n    assert_raises(ValueError, nbrs._fit, X)\n", "def test_neighbors_base_algorithm():\n    # Test that algorithm auto-selection is working as expected\n    X = iris.data\n\n    # Ball tree is preferred for high-dimensional data (dim > 15)\n    nbrs = neighbors.NearestNeighbors(algorithm='auto')\n    nbrs.fit(X[:, :16])  # reduce dimension to 16\n    assert_equal(nbrs._fit_method, 'ball_tree')\n\n    # KD Tree is preferred for low-dimensional data\n    nbrs = neighbors.NearestNeighbors(algorithm='auto')\n    nbrs.fit(X[:, :3])  # reduce dimension to 3\n    assert_equal(nbrs._fit_method, 'kd_tree')\n\n    # For small datasets, brute force should be preferred\n    X_small = X[:10]\n    nbrs = neighbors.NearestNeighbors(algorithm='auto')\n    nbrs.fit(X_small)\n    assert_equal(nbrs._fit_method, 'brute')\n\n    # With sparse data, brute force is the only option\n    X_sparse = csr_matrix(X)\n    nbrs = neighbors.NearestNeighbors(algorithm='auto')\n    nbrs.fit(X_sparse)\n    assert_equal(nbrs._fit_method, 'brute')\n", "def test_neighbors_base_algorithm():\n    # Test algorithm auto-selection for NeighborsBase\n\n    # With dense data and default parameters, it should use 'brute'\n    X = np.random.rand(10, 5)\n    nb = neighbors.NeighborsBase(algorithm='auto')\n    nb.fit(X)\n    assert_equal(nb._fit_method, 'brute')\n\n    # With sparse data, it should always use 'brute'\n    X_sparse = csr_matrix(X)\n    nb = neighbors.NeighborsBase(algorithm='auto')\n    nb.fit(X_sparse)\n    assert_equal(nb._fit_method, 'brute')\n\n    # When n_neighbors is small, it should use a tree-based method\n    X = np.random.rand(1000, 5)\n    nb = neighbors.NeighborsBase(n_neighbors=5, algorithm='auto')\n    nb.fit(X)\n    assert_in(nb._fit_method, ['ball_tree', 'kd_tree'])\n\n    # When the metric is not supported by the trees, it should use 'brute'\n    X = np.random.rand(10, 5)\n    nb = neighbors.NeighborsBase(metric='cosine', algorithm='auto')\n    nb.fit(X)\n    assert_equal(nb._fit_method, 'brute')\n"], "sample_6": ["    def test_ascii_validator(self):\n        validator = ASCIIUsernameValidator()\n        self.assertIsNone(validator('test_user'))\n        self.assertIsNone(validator('test.user'))\n        self.assertIsNone(validator('test@user'))\n        with self.assertRaisesMessage(ValidationError, 'Enter a valid username. This value may contain only English letters, numbers, and @/./+/-/_ characters.'):\n            validator('test\u00fcser')\n", "    def test_ascii_validator(self):\n        validator = ASCIIUsernameValidator()\n        valid_usernames = ['test123', 'test.123', 'test_123', 'test-123']\n        for username in valid_usernames:\n            validator(username)\n\n        invalid_usernames = ['test@', 'test 123', 'test!123']\n        for username in invalid_usernames:\n            with self.assertRaises(ValidationError):\n                validator(username)\n", "    def test_ascii_validator(self):\n        validator = ASCIIUsernameValidator()\n        self.assertIsNone(validator('testuser'))\n        with self.assertRaisesMessage(ValidationError, 'Enter a valid username. This value may contain only English letters, numbers, and @/./+/-/_ characters.'):\n            validator('test user')\n", "    def test_ascii_validator(self):\n        validator = ASCIIUsernameValidator()\n        valid_usernames = ['hello', 'hello123', 'hello.123', 'hello_123']\n        for username in valid_usernames:\n            validator(username)  # Should not raise an exception\n\n        invalid_usernames = ['hello!', 'hello world', 'hello\u00e9']\n        for username in invalid_usernames:\n            with self.assertRaises(ValidationError):\n                validator(username)\n", "    def test_ascii_validator(self):\n        validator = ASCIIUsernameValidator()\n        self.assertTrue(validator('test123'))\n        self.assertTrue(validator('test.123'))\n        self.assertTrue(validator('test_123'))\n        self.assertFalse(validator('test 123'))\n        self.assertFalse(validator('test!123'))\n"], "sample_25": ["def test_create_model_with_foo_together(self):\n    \"\"\"\n    Tests that having a unique/index_together in an initial model doesn't\n    generate a spurious AlterUnique/IndexTogether operation (#22849)\n    \"\"\"\n    changes = self.get_changes([self.author_empty], [self.book_foo_together])\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, [\n        'CreateModel',\n    ])\n    create_model = changes['otherapp'][0].operations[0]\n    self.assertEqual(create_model.options['unique_together'], {('author', 'title')})\n    self.assertEqual(create_model.options['index_together'], {('author', 'title')})\n", "def test_rename_model_with_through(self):\n    \"\"\"\n    Renaming a model with a through model field should not result in an\n    additional AlterField operation being generated for the through model.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_with_m2m_through, self.contract],\n        [self.author_with_renamed_m2m_through, self.contract_renamed],\n    )\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, ['RenameModel'])\n", "def test_autodetector_add_field_with_partially_deconstructible_default(self):\n    \"\"\"\n    The autodetector can handle add field operations with partially\n    deconstructible defaults.\n    \"\"\"\n    before = self.make_project_state([self.author_empty])\n    after = self.make_project_state([\n        ModelState(\"testapp\", \"Author\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\n                \"name\",\n                models.CharField(max_length=200, default=functools.partial(DeconstructibleObject, 1)),\n            ),\n        ])\n    ])\n\n    changes = self.get_changes(before, after)\n\n    # Right number of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    # Right number of AddField operations?\n    migration = changes[\"testapp\"][0]\n    self.assertEqual(len(migration.operations), 1)\n    self.assertIsInstance(migration.operations[0], migrations.AddField)\n    self.assertEqual(\n        migration.operations[0].field.default,\n        functools.partial(DeconstructibleObject, 1),\n    )\n", "def test_alter_model_options(self):\n    \"\"\"\n    Options on a model are correctly added/removed/altered.\n    \"\"\"\n    project_state = self.make_project_state([self.author_empty])\n    after_state = self.make_project_state([ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True))], {\n        \"permissions\": [('can_hire', 'Can hire')],\n        \"verbose_name\": \"Authi\",\n    })])\n    changes = MigrationAutodetector(project_state, after_state)._detect_changes()\n    # Make sure only AlterModelOptions is created\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelOptions\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, options={\n        \"permissions\": [('can_hire', 'Can hire')],\n        \"verbose_name\": \"Authi\",\n    })\n    # Reversing the changes should create an AlterModelOptions to the other value\n    project_state = self.make_project_state([ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True))], {\n        \"permissions\": [('can_hire', 'Can hire')],\n        \"verbose_name\": \"Authi\",\n    })])\n    after_state = self.make_project_state([self.author_empty])\n    changes = MigrationAutodetector(project_state, after_state)._detect_changes()\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelOptions\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, options={})\n", "def test_altered_indexes(self):\n    # Make state\n    before = self.make_project_state([self.book])\n    after = self.make_project_state([self.book_indexes])\n    autodetector = MigrationAutodetector(before, after)\n    changes = autodetector._detect_changes()\n    # Right number of migrations?\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    # Right operations?\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AddIndex'])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='book_title_author_idx')\n"], "sample_63": ["    def test_read_only_password_hash_widget(self):\n        widget = ReadOnlyPasswordHashWidget()\n        html = widget.render(\"password\", \"testhash\")\n        self.assertHTMLEqual(\n            '<div class=\"readonly\">*************</div>', html, msg=None\n        )\n        self.assertEqual(widget.id_for_label(\"password\"), None)\n", "    def test_constructor(self):\n        field = ReadOnlyPasswordHashField()\n        self.assertTrue(field.disabled)\n        self.assertFalse(field.required)\n", "    def test_readonlypasswordhashfield_rendering(self):\n        # Test that the widget renders correctly with a password value\n        field = ReadOnlyPasswordHashField(label=\"Password\")\n        output = field.widget.render(\"password\", \"sha1$1234567890123456789012345678901234567890\")\n        self.assertHTMLEqual(\n            output,\n            \"\"\"<div>", "    def test_readonlypasswordhashfield_widget_attrs(self):\n        field = ReadOnlyPasswordHashField()\n        widget = field.widget\n        self.assertIsInstance(widget, ReadOnlyPasswordHashWidget)\n        self.assertTrue(field.disabled)\n        self.assertFalse(field.required)\n", "    def test_readonlypasswordhashfield_widget_attrs(self):\n        field = ReadOnlyPasswordHashField()\n        widget = field.widget\n        self.assertIsInstance(widget, ReadOnlyPasswordHashWidget)\n        self.assertTrue(widget.read_only)\n"], "sample_96": ["def test_ridge_cv_scorer():\n    # Test that RidgeCV can work with different scorers\n    X, y = make_regression(n_samples=10, n_features=5, random_state=42)\n    for scoring in ['neg_mean_squared_error', 'mean_absolute_error', 'r2']:\n        scorer = get_scorer(scoring)\n        ridge = RidgeCV(scoring=scorer)\n        ridge.fit(X, y)\n        assert hasattr(ridge, 'best_score_')\n", "def test_ridgecv_scorer():\n    # Test that RidgeCV can use a custom scorer\n    X, y = make_regression(n_samples=50, n_features=10, random_state=0)\n\n    # Define a scorer\n        return -mean_squared_error(y, estimator.predict(X))\n\n    # Use the scorer in RidgeCV\n    ridge = RidgeCV(scoring=make_scorer(scorer))\n    ridge.fit(X, y)\n    assert_almost_equal(ridge.score(X, y), scorer(ridge, X, y))\n\n    # Use the scorer in GridSearchCV\n    param_grid = {'alpha': [1, 2]}\n    grid = GridSearchCV(Ridge(), param_grid, scoring=make_scorer(scorer))\n    grid.fit(X, y)\n    assert_almost_equal(grid.score(X, y), scorer(grid.best_estimator_, X, y))\n", "def test_ridgecv_scorer():\n    # Test that RidgeCV can be used with any scorer and raises proper errors.\n    X, y = make_regression(n_samples=10, n_features=10, random_state=42)\n    scorer = make_scorer(mean_squared_error)\n\n    # Using mean squared error as the scoring function should give the same\n    # result as the default scorer for regression (i.e., R^2 score).\n    ridge_cv_1 = RidgeCV(scorer=scorer)\n    ridge_cv_1.fit(X, y)\n    ridge_cv_2 = RidgeCV()\n    ridge_cv_2.fit(X, y)\n    assert_almost_equal(ridge_cv_1.alpha_, ridge_cv_2.alpha_)\n\n    # Using a classifier scorer should raise an error.\n    scorer = get_scorer('accuracy')\n    ridge_cv = RidgeCV(scorer=scorer)\n    msg = \"Cannot use mean accuracy with RidgeCV when y is not label-encodable\"\n    assert_raise_message(ValueError, msg, ridge_cv.fit, X, y)\n\n    # Using a regression scorer for classification should also raise an error.\n    X_c, y_c = make_multilabel_classification(random_state=0)\n    scorer = make_scorer(mean_squared_error)\n    ridge_ccv = RidgeClassifierCV(scorer=scorer)\n    msg = \"Cannot use mean squared error with RidgeClassifierCV\"\n    assert_raise_message(ValueError, msg, ridge_ccv.fit, X_c, y_c)\n", "def test_ridgecv_normalize():\n    # Test that RidgeCV's normalize parameter works as expected.\n    X, y = make_regression(n_samples=10, n_features=5, random_state=0)\n\n    # Calculate the mean and standard deviation of the features\n    std = np.std(X, axis=0)\n    mean = np.mean(X, axis=0)\n\n    ridgecv = RidgeCV(normalize=True)\n    ridgecv.fit(X, y)\n\n    # Check that the coefficients are equal to those obtained with standardized\n    # data and no normalization\n    ridgecv_noreg = RidgeCV(normalize=False)\n    ridgecv_noreg.fit((X - mean) / std, y)\n    assert_array_almost_equal(ridgecv.coef_, ridgecv_noreg.coef_)\n    assert_almost_equal(ridgecv.intercept_, ridgecv_noreg.intercept_)\n", "def test_ridge_cv_store_cv_values():\n    # Test if cv_values_ are stored correctly\n    X, y = make_regression(n_samples=10, n_features=5)\n    ridge_cv = RidgeCV(alphas=[0.1, 1.0], store_cv_values=True)\n    ridge_cv.fit(X, y)\n\n    assert_equal(ridge_cv.cv_values_.shape, (10, 2))\n    assert_array_almost_equal(ridge_cv.cv_values_[:, 0],\n                              ridge_cv.scorer(ridge_cv, X, y))\n"], "sample_36": ["def test_combine_with_empty_q(self):\n    q1 = Q(x=1)\n    q2 = Q()\n    self.assertEqual((q1 & q2), q1)\n    self.assertEqual((q1 | q2), q1)\n    self.assertEqual((q2 & q1), q1)\n    self.assertEqual((q2 | q1), q1)\n", "def test_q_combine(self):\n    q1 = Q(a=1)\n    q2 = Q(b=2)\n    combined = q1 & q2\n    self.assertIsInstance(combined, Q)\n    self.assertEqual(combined.connector, Q.AND)\n    self.assertEqual(len(combined.children), 2)\n    self.assertEqual(combined.children[0], q1.children[0])\n    self.assertEqual(combined.children[1], q2.children[0])\n\n    q3 = Q(c=3)\n    combined &= q3\n    self.assertIsInstance(combined, Q)\n    self.assertEqual(combined.connector, Q.AND)\n    self.assertEqual(len(combined.children), 3)\n    self.assertEqual(combined.children[0], q1.children[0])\n    self.assertEqual(combined.children[1], q2.children[0])\n    self.assertEqual(combined.children[2], q3.children[0])\n", "def test_combine_Q_objects(self):\n    q1 = Q(x=1)\n    q2 = Q(y=2)\n    combined = q1 & q2\n    self.assertEqual(combined.connector, Q.AND)\n    self.assertEqual(len(combined.children), 2)\n\n    combined = q1 | q2\n    self.assertEqual(combined.connector, Q.OR)\n    self.assertEqual(len(combined.children), 2)\n\n    combined = q1 & ~q2\n    self.assertEqual(combined.connector, Q.AND)\n    self.assertEqual(len(combined.children), 2)\n    self.assertTrue(combined.children[1].negated)\n\n    combined = ~q1 & q2\n    self.assertEqual(combined.connector, Q.AND)\n    self.assertEqual(len(combined.children), 2)\n    self.assertTrue(combined.children[0].negated)\n", "def test_combine_Q_objects(self):\n    q1 = Q(a=1)\n    q2 = Q(b=2)\n    combined = q1 & q2\n    self.assertIsInstance(combined, Q)\n    self.assertEqual(combined.connector, Q.AND)\n    self.assertEqual(len(combined.children), 2)\n\n    combined = q1 | q2\n    self.assertIsInstance(combined, Q)\n    self.assertEqual(combined.connector, Q.OR)\n    self.assertEqual(len(combined.children), 2)\n\n    combined = q1 & ~q2\n    self.assertIsInstance(combined, Q)\n    self.assertEqual(combined.connector, Q.AND)\n    self.assertEqual(len(combined.children), 2)\n    self.assertTrue(combined.children[1].negated)\n", "def test_q_combine_with_empty_q(self):\n    q1 = Q(a=1)\n    q2 = Q()\n    combined = q1 & q2\n    self.assertEqual(combined.children, [q1])\n    self.assertEqual(combined.connector, Q.AND)\n\n    combined = q1 | q2\n    self.assertEqual(combined.children, [q1])\n    self.assertEqual(combined.connector, Q.OR)\n"], "sample_78": ["def test_cli_with_appcontext():\n    app = Flask(__name__)\n    cli = AppGroup(app)\n\n    @app.cli.command()\n    @with_appcontext\n        assert current_app._get_current_object() is app\n\n    result = CliRunner().invoke(cli, [\"hello\"])\n    assert result.exit_code == 0\n", "def test_find_best_app():\n    # Create a module with multiple Flask instances\n    app1 = Flask(\"app1\")\n    app2 = Flask(\"app2\")\n\n    module = types.ModuleType(\"module\")\n    module.app = app1\n    module.application = app2\n\n    assert find_best_app(module) == app1\n\n    del module.app\n    assert find_best_app(module) == app2\n\n    del module.application\n    with pytest.raises(NoAppException):\n        find_best_app(module)\n", "def test_find_best_app_module_file():\n    with pytest.raises(NoAppException) as e:\n        find_best_app(types.ModuleType(\"test\"))\n\n    assert \"Failed to find Flask application or factory in module 'test'.\" in str(e.value)\n", "def test_cli_run_command_loads_app_with_app_env(runner, monkeypatch):\n    app = Flask(__name__)\n\n    @app.route(\"/\")\n        return \"Hello World!\"\n\n        return app\n\n    monkeypatch.setattr(\"flask.cli.ScriptInfo.load_app\", load_app)\n\n    result = runner.invoke(run_command, [\"--port\", \"3000\"])\n\n    assert result.exit_code == 0\n    assert \"Running on\" in result.output\n", "def test_cli_with_app_context(runner):\n    app = Flask(__name__)\n\n    @app.cli.command()\n    @with_appcontext\n        click.echo(current_app.name)\n\n    result = runner.invoke(app.cli, [\"hello\"])\n    assert result.exit_code == 0\n    assert result.output.strip() == app.name\n"], "sample_2": ["def test_wcs_to_header(self):\n    # Test WCS.to_header() to ensure that it produces a header with\n    # the same WCS information as the original header.\n    for hdr_file in self._file_list:\n        if 'proj.hdr' in hdr_file or 'proj2.hdr' in hdr_file:\n            continue  # Skip headers with polynomial distortion\n        header = fits.Header.fromtextfile(hdr_file)\n        wcs_info = wcs.WCS(header)\n        new_header = wcs_info.to_header()\n        new_wcs_info = wcs.WCS(new_header)\n\n        assert wcs_info.wcs.naxis == new_wcs_info.wcs.naxis\n\n        # Check that the axis types match up\n        for axis_type, new_axis_type in zip(wcs_info.get_axis_types(),\n                                           new_wcs_info.get_axis_types()):\n            assert axis_type['coordinate_type'] == new_axis_type['coordinate_type']\n            assert axis_type['scale'] == new_axis_type['scale']\n            assert axis_type['group'] == new_axis_type['group']\n            assert axis_type['number'] == new_axis_type['number']\n\n        # Check that the CRVAL coordinates are equivalent\n        assert_array_almost_equal_nulp(wcs_info.wcs.crval, new_wcs_info.wcs.crval)\n\n        # Check that the CDELT and PC matrix are equivalent\n        if hasattr(wcs_info.wcs, 'cd'):\n            cdelt = wcs_info.wcs.cd\n        else:\n            cdelt = np.diag(wcs_info.wcs.cdelt)\n            pc = wcs_info.wcs.pc\n            if pc is not None:\n                cdelt = np.dot(cdelt, pc)\n        if hasattr(new_wcs_info.wcs, 'cd'):\n            new_cdelt = new_wcs_info.wcs.cd\n        else:\n            new_cdelt = np.diag(new_wcs_info.wcs.cdelt)\n            new_pc = new_wcs_info.wcs.pc\n            if new_pc is not None:\n                new_cdelt = np.dot(new_cdelt, new_pc)\n        assert_array_almost_equal_nulp(cdelt, new_cdelt)\n", "def test_wcs_header_corrupt(self):\n    # Test WCS header fixing when a header has invalid keywords\n    header = fits.Header.fromtextfile(get_pkg_data_filename('data/fix-wcs-header.hdr'))\n    with pytest.warns(wcs.FITSFixedWarning):\n        wcs.WCS(header)\n", "def test_wcs_init_errors(self):\n    # Test WCS initialization with invalid parameters\n    with pytest.raises(ValueError):\n        wcs.WCS(header=None, fobj=None)\n\n    with pytest.raises(TypeError):\n        wcs.WCS(header='string', fobj=None)\n\n    with pytest.raises(ValueError):\n        wcs.WCS(header=fits.Header(), fobj=None, key='invalid')\n", "def test_to_header(self):\n    # Test that to_header raises an exception if there are no WCS keys in the header\n    wcs = wcs.WCS(naxis=2)\n    with raises(wcs.NoWcsKeywordsFoundError):\n        wcs.to_header()\n\n    # Test that to_header produces a valid header with the correct WCS keys\n    hdr = fits.Header.fromtextfile(get_pkg_data_filename(\"data/3d_cd.hdr\"))\n    wcs = wcs.WCS(hdr)\n    header_string = wcs.to_header()\n    header = fits.Header.fromstring(header_string)\n\n    assert \"CTYPE1\" in header\n    assert \"CTYPE2\" in header\n    assert \"CRVAL1\" in header\n    assert \"CRVAL2\" in header\n    assert \"CDELT1\" in header\n    assert \"CDELT2\" in header\n    assert \"CRPIX1\" in header\n    assert \"CRPIX2\" in header\n    assert \"EQUINOX\" in header\n\n    # Test that to_header produces a valid header when relax is True\n    header_string = wcs.to_header(relax=True)\n    header = fits.Header.fromstring(header_string)\n\n    assert \"CTYPE1\" in header\n    assert \"CTYPE2\" in header\n    assert \"CRVAL1\" in header\n    assert \"CRVAL2\" in header\n    assert \"CDELT1\" in header\n    assert \"CDELT2\" in header\n    assert \"CRPIX1\" in header\n    assert \"CRPIX2\" in header\n    assert \"EQUINOX\" in header\n", "def test_wcs_invalid_input(self):\n    with pytest.raises(TypeError) as excinfo:\n        wcs.WCS(header=None, fobj=None)\n    assert \"header must be a string, an astropy.io.fits.Header object, or a dict-like object\" in str(excinfo.value)\n\n    with pytest.raises(ValueError) as excinfo:\n        wcs.WCS(header=\"invalid_file.fits\", fobj=None)\n    assert \"The file 'invalid_file.fits' does not exist.\" in str(excinfo.value)\n\n    with pytest.raises(TypeError) as excinfo:\n        wcs.WCS(header=fits.Header(), fobj=\"invalid_fobj\")\n    assert \"fobj must be an astropy.io.fits.HDUList object or None\" in str(excinfo.value)\n"], "sample_71": ["def test_style_use_list():\n    # Create a temporary style sheet with some settings.\n    with temp_style('temp1', {'image.cmap': 'pink'}):\n        with temp_style('temp2', {'lines.color': 'red'}):\n            # Use the two temporary styles together in a list.\n            style.use(['temp1', 'temp2'])\n            assert mpl.rcParams['image.cmap'] == 'pink'\n            assert mpl.rcParams['lines.color'] == 'red'\n", "def test_reload_library():\n    # Test that reload_library removes styles from previous user library paths.\n    original_library = style.library.copy()\n    with temp_style('test'):\n        assert 'test' in style.library\n    style.reload_library()\n    assert style.library == original_library\n", "def test_update_nested_dict():\n    main_dict = {'style1': {'param1': 'value1'}}\n    new_dict = {'style1': {'param2': 'value2'}, 'style2': {'param3': 'value3'}}\n    style.update_nested_dict(main_dict, new_dict)\n    assert main_dict == {\n        'style1': {'param1': 'value1', 'param2': 'value2'},\n        'style2': {'param3': 'value3'}\n    }\n", "def test_reload_library():\n    \"\"\"Test that reload_library() updates the style library.\"\"\"\n    original_lib = style.library.copy()\n    with temp_style('test_reload', DUMMY_SETTINGS):\n        assert 'test_reload' in style.library\n    style.reload_library()\n    assert style.library == original_lib\n", "def test_use_style_with_deprecated_seaborn_name():\n    # Test that using a deprecated seaborn style name raises a deprecation warning\n    with pytest.warns(mpl.MatplotlibDeprecationWarning):\n        style.use('seaborn')\n"], "sample_26": ["    def test_create_test_db(self):\n        test_connection = get_connection_copy()\n        db_creation = BaseDatabaseCreation(test_connection)\n        with mock.patch.object(db_creation, '_create_test_db') as mock_create_test_db:\n            db_name = db_creation.create_test_db(verbosity=0)\n            self.assertEqual(db_name, TEST_DATABASE_PREFIX + test_connection.settings_dict['NAME'])\n            mock_create_test_db.assert_called_once_with(verbosity=0, autoclobber=False, keepdb=False)\n", "    def test_create_test_db(self):\n        test_connection = get_connection_copy()\n        db_creation = BaseDatabaseCreation(test_connection)\n        with mock.patch.object(db_creation, '_create_test_db') as mocked_create:\n            mocked_create.return_value = 'test_database'\n            db_name = db_creation.create_test_db(verbosity=0)\n            self.assertEqual(db_name, 'test_database')\n            self.assertEqual(test_connection.settings_dict['NAME'], 'test_database')\n", "    def test_test_db_signature(self):\n        # Get the signature of the test database.\n        db_signature = connections[DEFAULT_DB_ALIAS].creation.test_db_signature()\n\n        # Expected signature elements.\n        host = connections[DEFAULT_DB_ALIAS].settings_dict['HOST']\n        port = connections[DEFAULT_DB_ALIAS].settings_dict['PORT']\n        engine = connections[DEFAULT_DB_ALIAS].settings_dict['ENGINE']\n        db_name = TEST_DATABASE_PREFIX + connections[DEFAULT_DB_ALIAS].settings_dict['NAME']\n\n        self.assertEqual(db_signature, (host, port, engine, db_name))\n", "    def test_test_db_signature(self):\n        db_creation = BaseDatabaseCreation(get_connection_copy())\n        signature = db_creation.test_db_signature()\n        self.assertEqual(len(signature), 4)\n        self.assertEqual(signature[2], 'django.db.backends.base.creation.BaseDatabaseCreation')\n        self.assertIn(TEST_DATABASE_PREFIX, signature[3])\n", "    def test_create_test_db(self):\n        test_connection = get_connection_copy()\n        creation = BaseDatabaseCreation(test_connection)\n        with mock.patch.object(creation, '_create_test_db') as _create_test_db:\n            _create_test_db.return_value = 'test_database'\n            with mock.patch.object(creation, 'log'):\n                db_name = creation.create_test_db(verbosity=0)\n                self.assertEqual(db_name, 'test_database')\n                self.assertEqual(test_connection.settings_dict['NAME'], 'test_database')\n"], "sample_23": ["def test_union(self):\n    qs1 = Number.objects.filter(num__lte=3)\n    qs2 = Number.objects.filter(num__gte=7)\n    qs3 = Number.objects.filter(num__in=[4, 5])\n    self.assertNumbersEqual(qs1.union(qs2), [0, 1, 2, 3, 7, 8, 9], ordered=False)\n    self.assertNumbersEqual(qs1.union(qs2).union(qs3), [0, 1, 2, 3, 4, 5, 7, 8, 9], ordered=False)\n    self.assertNumbersEqual(qs1.union(qs2, all=True), [0, 1, 2, 3, 7, 8, 9], ordered=False)\n    self.assertNumbersEqual(qs1.union(qs2).union(qs3, all=True), [0, 1, 2, 3, 4, 5, 7, 8, 9], ordered=False)\n", "def test_union(self):\n    qs1 = Number.objects.filter(num__lt=5)\n    qs2 = Number.objects.filter(num__gte=5)\n    union_qs = qs1.union(qs2)\n    self.assertNumbersEqual(union_qs, range(10))\n", "def test_union(self):\n    qs1 = Number.objects.filter(num__lte=5)\n    qs2 = Number.objects.filter(num__gte=5)\n    union_qs = qs1.union(qs2)\n    self.assertNumbersEqual(union_qs, list(range(10)))\n    self.assertEqual(len(list(union_qs)), 10)\n", "def test_union(self):\n    qs1 = Number.objects.filter(num__lte=5)\n    qs2 = Number.objects.filter(num__gt=5)\n\n    union_qs = qs1.union(qs2)\n    self.assertNumbersEqual(union_qs, list(range(10)))\n\n    union_qs = qs1.union(qs2.order_by('-num'))\n    self.assertNumbersEqual(union_qs, list(range(10)))\n", "def test_union(self):\n    qs1 = Number.objects.filter(num__lte=3)\n    qs2 = Number.objects.filter(num__gte=7)\n    self.assertNumbersEqual(qs1.union(qs2), [0, 1, 2, 3, 7, 8, 9])\n"], "sample_117": ["def test_restify_broken_type():\n    assert restify(BrokenType) == ':class:`BrokenType`'\n", "def test_restify_py37():\n    # test restify with Python 3.7+\n    if sys.version_info >= (3, 7):\n        assert restify(Union[int, str]) == ':obj:`Union`\\\\ [:class:`int`, :class:`str`]'\n        assert restify(Callable[[int], str]) == ':class:`Callable`\\\\ [[:class:`int`], :class:`str`]'\n        assert restify(MyList[int]) == ':class:`MyList`\\\\ [:class:`int`]'\n        assert restify(Generator[int, None, None]) == ':class:`Generator`\\\\ [:class:`int`, :obj:`None`, :obj:`None`]'\n        assert restify(Optional[int]) == ':obj:`Optional`\\\\ [:class:`int`]'\n        assert restify(Union[int, None]) == ':obj:`Optional`\\\\ [:class:`int`]'\n", "def test_restify_py36_broken_type():\n    with pytest.raises(AttributeError):\n        restify(BrokenType())\n", "def test_stringify_broken_type():\n    with pytest.raises(AttributeError):\n        stringify(BrokenType())\n", "def test_restify_py37():\n    assert restify(Union[int, str]) == ':obj:`Union`\\\\ [:class:`int`, :class:`str`]'\n    assert restify(Callable[[int], str]) == ':class:`Callable`\\\\ [[{:class:`int`}], :class:`str`]'\n    assert restify(List[int]) == ':class:`List`\\\\ [:class:`int`]'\n    assert restify(Optional[int]) == ':obj:`Optional`\\\\ [:class:`int`]'\n    assert restify(Tuple[int, str]) == ':class:`Tuple`\\\\ [:class:`int`, :class:`str`]'\n    assert restify(Generator[int, None, None]) == ':class:`Generator`\\\\ [:class:`int`, :obj:`None`, :obj:`None`]'\n    assert restify(MyClass1) == ':class:`test_util_typing.MyClass1`'\n    assert restify(MyClass2) == ':class:`test_util_typing.MyClass2`'\n"], "sample_87": ["def test_collect_ignore_moduleCollector_setup_fails(monkeypatch, tmpdir):\n    \"\"\"Verify that ModuleCollector setup failure does not prevent subsequent collection.\"\"\"\n    modcol = pytest.Module(tmpdir.join(\"test_foo.py\"), parent=Session())\n    monkeypatch.setattr(modcol.obj, \"collect\", lambda: [1])\n    rep = collect_one_node(modcol)\n    assert rep.failed\n    assert len(rep.result) == 0\n\n        return [2]\n\n    modcol = pytest.Module(tmpdir.join(\"test_bar.py\"), parent=Session())\n    monkeypatch.setattr(modcol.obj, \"collect\", collect)\n    rep = collect_one_node(modcol)\n    assert rep.passed\n    assert len(rep.result) == 1\n", "def test_collect_ignore_multipleCollectorIgnore_args(tmpdir, request):\n    tmpdir.mkdir(\"a\")\n    tmpdir.mkdir(\"b\")\n    tmpdir.mkdir(\"c\")\n\n    class TestCollector(Session):\n            assert arg == str(tmpdir)\n            return [tmpdir.join(\"a\"), tmpdir.join(\"b\")]\n\n    session = TestCollector(FakeConfig(request))\n    session._initialpaths = [tmpdir]\n    items = session.collect()\n    assert len(items) == 2\n\n    # Using the collect_ignore_glob argument should ignore the specified files\n    class TestCollector(Session):\n            assert arg == str(tmpdir)\n            return [\n                tmpdir.join(\"a\"),\n                tmpdir.join(\"b\"),\n                tmpdir.join(\"c\"),\n            ]\n\n    config = FakeConfig(request)\n    config.option.ignore_glob.append(\"b\")\n    session = TestCollector(config)\n    session._initialpaths = [tmpdir]\n    items = session.collect()\n    assert len(items) == 2\n", "def test_collect_ignore_with_absolute_path(tmp_path, monkeypatch):\n    \"\"\"Test collect_ignore with absolute path.\"\"\"\n    root = tmp_path / \"root\"\n    root.mkdir()\n    ignore_file = root / \"ignore_me.py\"\n    ignore_file.touch()\n\n    # Create a pytest.ini file with the absolute path in collect_ignore\n    pytest_ini = root / \"pytest.ini\"\n    pytest_ini.write_text(\n        textwrap.dedent(\n            \"\"\"\n            [pytest]\n            collect_ignore = {ignore_file}\n            \"\"\".format(ignore_file=ignore_file)\n        )\n    )\n\n        return str(root)\n\n    monkeypatch.setattr(os, \"getcwd\", getcwd)\n\n    session = Session(pytest.config.main([\"-vv\"]))\n    assert ignore_file not in [item.fspath for item in session.items]\n", "def test_collect_ignore_paths(tmpdir, monkeypatch):\n    \"\"\"Test that paths in collect_ignore are not collected.\"\"\"\n    tmpdir.join(\"ignore_me.py\").write(\"def test_ignore(): pass\")\n    tmpdir.join(\"conftest.py\").write(\n        textwrap.dedent(\n            \"\"\"\n                return [\"ignore_me.py\"]\n            \"\"\"\n        )\n    )\n    session = Session(pytest.config)\n    session._initialpaths = [tmpdir]\n    items = session.perform_collect()\n    assert len(items) == 0\n", "def test_collect_ignore_paths(config, tmpdir):\n    conf = tmpdir.join(\"conftest.py\")\n    conf.write(\"collect_ignore = ['ignore_dir', 'ignore_file.py']\")\n    ignore_dir = tmpdir.mkdir(\"ignore_dir\")\n    ignore_file = tmpdir.join(\"ignore_file.py\")\n    keep_file = tmpdir.join(\"keep_file.py\")\n\n    session = Session(config)\n    collector = session.genitems(tmpdir)\n\n    collected = list(collector)\n\n    assert ignore_dir not in collected\n    assert ignore_file not in collected\n    assert keep_file in collected\n"], "sample_153": ["def test_pretty_matrix():\n    from sympy import Matrix, Symbol\n    a = Symbol('a')\n    M = Matrix([[1, 2], [3*a, 4]])\n    assert pretty(M) == \"\"\"\\", "def test_pretty_print_TensorProduct():\n    from sympy.tensor.tensor import TensorProduct\n    from sympy.tensor.array import MutableDenseNDimArray\n\n    a1 = MutableDenseNDimArray([1, 2])\n    a2 = MutableDenseNDimArray([3, 4])\n\n    assert upretty(TensorProduct(a1, a2)) == \"1 \u2a02 3 + 1 \u2a02 4 + 2 \u2a02 3 + 2 \u2a02 4\"\n    assert pretty(TensorProduct(a1, a2)) == \"1 x 3 + 1 x 4 + 2 x 3 + 2 x 4\"\n\n    # test with non-array arguments\n    assert upretty(TensorProduct(1, 2)) == \"1 \u2a02 2\"\n    assert pretty(TensorProduct(1, 2)) == \"1 x 2\"\n\n    # test nested tensor product\n    assert upretty(TensorProduct(a1, TensorProduct(a2, a1))) == \\\n        \"(1 \u2a02 3) \u2a02 1 + (1 \u2a02 3) \u2a02 2 + (1 \u2a02 4) \u2a02 1 + (1 \u2a02 4) \u2a02 2 + (2 \u2a02 3) \u2a02 1 + (2 \u2a02 3) \u2a02 2 + (2 \u2a02 4) \u2a02 1 + (2 \u2a02 4) \u2a02 2\"\n    assert pretty(TensorProduct(a1, TensorProduct(a2, a1))) == \\\n        \"(1 x 3) x 1 + (1 x 3) x 2 + (1 x 4) x 1 + (1 x 4) x 2 + (2 x 3) x 1 + (2 x 3) x 2 + (2 x 4) x 1 + (2 x 4) x 2\"\n", "def test_printing_functions():\n    from sympy.functions import Chi, Ci, Ei, Shi, Si\n    assert upretty(Chi(a)) == 'Chi(a)'\n    assert pretty(Chi(a)) == 'Chi(a)'\n    assert upretty(Ci(a)) == 'Ci(a)'\n    assert pretty(Ci(a)) == 'Ci(a)'\n    assert upretty(Ei(a)) == 'Ei(a)'\n    assert pretty(Ei(a)) == 'Ei(a)'\n    assert upretty(Shi(a)) == 'Shi(a)'\n    assert pretty(Shi(a)) == 'Shi(a)'\n    assert upretty(Si(a)) == 'Si(a)'\n    assert pretty(Si(a)) == 'Si(a)'\n", "def test_pretty_print_AssignmentBase():\n    from sympy import symbols, Eq\n    x = symbols('x')\n    expr = Eq(x, 2)\n    assert pretty(expr) == 'Eq(x, 2)'\n    assert upretty(expr) == 'x = 2'\n", "def test_pretty_printing_dot_product():\n    # Initialize vectors for testing\n    v1 = N.i + 2*N.j - 3*N.k\n    v2 = 4*N.i - 5*N.j + 6*N.k\n\n    # Calculate dot product\n    dot_product = v1.dot(v2)\n\n    # Expected pretty forms\n    upretty_dot_product = \"\"\"\\"], "sample_82": ["def test_consolidate_slices():\n    slices = [slice(1, 3), slice(4, 5), slice(6, 7)]\n    expected = [slice(1, 3), slice(4, 5), slice(6, 7)]\n    assert _consolidate_slices(slices) == expected\n\n    slices = [slice(1, 2), slice(2, 3), slice(4, 5), slice(6, 7)]\n    expected = [slice(1, 3), slice(4, 5), slice(6, 7)]\n    assert _consolidate_slices(slices) == expected\n\n    slices = [slice(1, 3), slice(3, 5), slice(6, 7)]\n    expected = [slice(1, 5), slice(6, 7)]\n    assert _consolidate_slices(slices) == expected\n", "def test_groupby_consolidate_slices():\n    slices = [slice(0, 1), slice(1, 3), slice(3, 5)]\n    expected = [slice(0, 5)]\n    assert _consolidate_slices(slices) == expected\n\n    slices = [slice(0, 1), slice(2, 3), slice(3, 5)]\n    expected = [slice(0, 1), slice(2, 5)]\n    assert _consolidate_slices(slices) == expected\n\n    slices = [slice(0, 1), slice(1, 2), slice(3, 4)]\n    expected = [slice(0, 2), slice(3, 4)]\n    assert _consolidate_slices(slices) == expected\n", "def test_groupby_consolidate_slices():\n    slices = [slice(0, 1), slice(1, 2), slice(2, 3)]\n    expected = slices\n    assert _consolidate_slices(slices) == expected\n\n    slices = [slice(0, 1), slice(1, 2), slice(2, 4)]\n    expected = [slice(0, 2), slice(2, 4)]\n    assert _consolidate_slices(slices) == expected\n\n    slices = [slice(0, 2), slice(2, 3), slice(3, 4)]\n    expected = slices\n    assert _consolidate_slices(slices) == expected\n", "def test_groupby_reduce_dim_order(array):\n    # regression test for GH1426\n    array = array.transpose(\"y\", \"x\", \"z\")\n    expected = array.groupby(\"z\").mean(dim=[\"x\", \"y\"])\n    result = array.groupby(\"z\").mean()\n    assert_identical(result, expected)\n", "def test_groupby_reduce_dim_order(dataset):\n    # GH 3468: Test that reducing a groupby object preserves the original dimension order.\n    expected = dataset.mean(dim=\"y\")\n    result = dataset.groupby(\"x\").reduce(np.mean, dim=\"y\")\n    assert_identical(result, expected)\n"], "sample_70": ["def test_get_legend_handles():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], label='Line')\n    ax.scatter([1, 2, 3], [1, 2, 3], label='Scatter')\n    handles = list(mlegend._get_legend_handles([ax]))\n    assert len(handles) == 2\n    assert isinstance(handles[0], mlines.Line2D)\n    assert isinstance(handles[1], mcollections.PathCollection)\n", "def test_legend_get_texts():\n    fig, ax = plt.subplots()\n    line1, = ax.plot([1, 2], label='Line 1')\n    line2, = ax.plot([3, 4], label='Line 2')\n    legend = ax.legend(handles=[line1, line2])\n    texts = legend.get_texts()\n    assert len(texts) == 2\n    assert texts[0].get_text() == 'Line 1'\n    assert texts[1].get_text() == 'Line 2'\n", "def test_legend_with_scatter(fig_test, fig_ref):\n    x = np.linspace(0, 10, 100)\n    y = np.sin(x)\n\n    fig_test.subplots()\n    fig_ref.subplots()\n\n    fig_test.axes[0].scatter(x, y, label='sin')\n    fig_test.axes[0].legend(scatteryoffsets=[0.5])\n\n    fig_ref.axes[0].scatter(x, y, label='sin')\n    fig_ref.axes[0].legend(scatteryoffsets=[0.5])\n\n    # Check that user-specified scatteryoffsets are used\n    assert fig_test.axes[0].get_legend().legendHandles[0].get_offsets()[0, 1] == 0.5\n", "def test_legend_loc(loc):\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], label='test')\n    ax.legend(loc=loc)\n    legend = ax.get_legend()\n    assert legend._get_loc() == mlegend.Legend.codes[loc]\n", "def test_legend_draggable(fig_test, fig_ref):\n    fig_test.subplots()\n    draggable_legend = mlegend.Legend(fig_test.axes[0], [], [], draggable=True)\n    fig_test.axes[0].add_artist(draggable_legend)\n    fig_test.canvas.draw()\n    fig_ref.subplots()\n    draggable_legend = mlegend.Legend(fig_ref.axes[0], [], [], draggable=False)\n    fig_ref.axes[0].add_artist(draggable_legend)\n    fig_ref.canvas.draw()\n"], "sample_56": ["    def test_string_if_invalid_not_a_string(self):\n        errors = check_string_if_invalid_is_string(app_configs=None)\n        self.assertEqual(len(errors), 1)\n        error = errors[0]\n        self.assertEqual(error.id, E002.id)\n        self.assertIn(\"must be a string but got: 123 (int)\", error.msg)\n", "    def test_string_if_invalid_is_not_string(self):\n        errors = check_string_if_invalid_is_string(None)\n        self.assertEqual(len(errors), 1)\n        error = errors[0]\n        self.assertIsInstance(error, Error)\n        self.assertEqual(error.id, E002.id)\n        self.assertIn(\"must be a string but got: 123 (int)\", error.msg)\n", "    def test_string_if_invalid_is_not_a_string(self):\n        errors = check_string_if_invalid_is_string(None)\n        self.assertEqual(len(errors), 1)\n        error = errors[0]\n        self.assertIsInstance(error, Error)\n        self.assertEqual(error.id, E002.id)\n        self.assertIn(\"must be a string but got: 123 (int)\", error.msg)\n", "    def test_string_if_invalid_is_string(self):\n        errors = check_string_if_invalid_is_string(None)\n        self.assertEqual(errors, [])\n", "    def test_string_if_invalid_not_a_string(self):\n        errors = check_string_if_invalid_is_string(None)\n        self.assertEqual(len(errors), 1)\n        error = errors[0]\n        self.assertIsInstance(error, Error)\n        self.assertEqual(error.id, E002.id)\n        self.assertIn(\"must be a string but got: 123 (int)\", error.msg)\n"], "sample_18": ["def test_related_name_is_valid(self):\n    class Model(models.Model):\n        field = models.ForeignKey('self', on_delete=models.CASCADE, related_name='!@#$')\n\n    errors = Model.check()\n    self.assertEqual(len(errors), 1)\n    self.assertIsInstance(errors[0], Error)\n    self.assertEqual(errors[0].id, 'fields.E306')\n", "def test_related_field_type(self):\n    class Model(models.Model):\n        field = models.ForeignKey('self', on_delete=models.CASCADE)\n\n    errors = Model.check()\n    self.assertEqual(errors, [\n        Error(\n            'The field field clashes with the field field from model Model.',\n            hint='Rename field on Model. Add or change a related_name '\n                 'argument to the definition for field on Model.',\n            obj=Model._meta.get_field('field'),\n            id='fields.E302',\n        ),\n    ])\n", "def test_recursive_relationship_constant(self):\n    class Model(models.Model):\n        field = models.ForeignKey('self', on_delete=models.CASCADE)\n\n    model_field = Model._meta.get_field('field')\n    self.assertEqual(model_field.remote_field.model, Model)\n    self.assertEqual(model_field.remote_field.to, RECURSIVE_RELATIONSHIP_CONSTANT)\n", "def test_resolve_relation(self):\n    with isolate_apps('invalid_models_tests'):\n        class AbstractModel(models.Model):\n            pass\n\n        class ConcreteModel(models.Model):\n            pass\n\n        self.assertEqual(resolve_relation(ConcreteModel, 'AbstractModel'), 'invalid_models_tests.AbstractModel')\n        self.assertEqual(resolve_relation(ConcreteModel, 'ConcreteModel'), 'invalid_models_tests.ConcreteModel')\n        self.assertEqual(resolve_relation(ConcreteModel, 'self'), ConcreteModel)\n        self.assertEqual(resolve_relation(ConcreteModel, ConcreteModel), ConcreteModel)\n", "def test_resolve_relation(self):\n    model = models.Model()\n    self.assertEqual(resolve_relation(model, RECURSIVE_RELATIONSHIP_CONSTANT), model)\n    self.assertEqual(resolve_relation(model, 'self'), model)\n\n    rel_model_name = 'other_model'\n    self.assertEqual(resolve_relation(model, rel_model_name), f'{model._meta.app_label}.{rel_model_name}')\n\n    other_app_label = 'other_app'\n    rel_model_name_with_app = f'{other_app_label}.{rel_model_name}'\n    self.assertEqual(resolve_relation(model, rel_model_name_with_app), rel_model_name_with_app)\n"], "sample_75": ["def test_imagegrid_cbar_mode():\n    fig = plt.figure()\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode='each', cbar_location='right')\n    for i, ax in enumerate(grid):\n        im = ax.imshow(np.random.rand(10, 10))\n        grid.cbar_axes[i].colorbar(im)\n    plt.close(fig)\n\n    fig = plt.figure()\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode='single', cbar_location='right')\n    for ax in grid:\n        im = ax.imshow(np.random.rand(10, 10))\n    grid.cbar_axes[0].colorbar(im)\n    plt.close(fig)\n\n    fig = plt.figure()\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode='edge', cbar_location='right')\n    for i, ax in enumerate(grid):\n        im = ax.imshow(np.random.rand(10, 10))\n        if i % 2 == 1:  # only right edge\n            grid.cbar_axes[i // 2].colorbar(im)\n    plt.close(fig)\n\n    fig = plt.figure()\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode=None)\n    for ax in grid:\n        ax.imshow(np.random.rand(10, 10))\n    assert all(not cax.axison for cax in grid.cbar_axes)\n    plt.close(fig)\n", "def test_imagegrid_cbar_mode():\n    fig = plt.figure()\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode='each')\n    assert len(grid.cbar_axes) == 4\n    for ax in grid.cbar_axes:\n        assert ax.get_visible()\n\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode='single')\n    assert len(grid.cbar_axes) == 4\n    for ax in grid.cbar_axes[1:]:\n        assert not ax.get_visible()\n    assert grid.cbar_axes[0].get_visible()\n\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode='edge')\n    assert len(grid.cbar_axes) == 4\n    for ax in grid.cbar_axes[:2]:\n        assert ax.get_visible()\n    for ax in grid.cbar_axes[2:]:\n        assert not ax.get_visible()\n\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode=None)\n    assert len(grid.cbar_axes) == 4\n    for ax in grid.cbar_axes:\n        assert not ax.get_visible()\n", "def test_imagegrid_cbar_mode():\n    fig = plt.figure()\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode='each')\n    assert len(grid.cbar_axes) == 4\n\n    fig = plt.figure()\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode='single')\n    assert len(grid.cbar_axes) == 1\n\n    fig = plt.figure()\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode='edge')\n    assert len(grid.cbar_axes) == 2\n\n    fig = plt.figure()\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode=None)\n    assert len(grid.cbar_axes) == 4\n    for ax in grid.cbar_axes:\n        assert not ax.get_visible()\n", "def test_grid_set_axes_pad(nrows, ncols, direction):\n    fig = plt.figure()\n    grid = Grid(fig, rect=111, nrows_ncols=(nrows, ncols),\n                direction=direction, axes_pad=0.5)\n    grid.set_axes_pad((0.1, 0.2))\n    assert_array_almost_equal(grid.get_axes_pad(), (0.1, 0.2))\n", "def test_grid_set_axes_pad():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 2), axes_pad=0.5)\n    assert_array_almost_equal(grid.get_axes_pad(), (0.5, 0.5))\n    grid.set_axes_pad((0.2, 0.3))\n    assert_array_almost_equal(grid.get_axes_pad(), (0.2, 0.3))\n    plt.close(fig)\n"], "sample_114": ["def test_class_distribution():\n    # Test class_distribution function for correct output\n    y = np.array([[1, 2], [2, 3], [1, 3]])\n    classes, n_classes, class_prior = class_distribution(y)\n    \n    assert_array_equal(classes, [np.array([1, 2]), np.array([2, 3])])\n    assert_array_equal(n_classes, [2, 2])\n    assert_allclose(class_prior, [np.array([0.5, 0.5]), np.array([0.5, 0.5])])\n\n    # Test with sample weights\n    sample_weight = np.array([0.5, 0.5, 0.5])\n    classes, n_classes, class_prior = class_distribution(y, sample_weight)\n    \n    assert_array_equal(classes, [np.array([1, 2]), np.array([2, 3])])\n    assert_array_equal(n_classes, [2, 2])\n    assert_allclose(class_prior, [np.array([0.5, 0.5]), np.array([0.5, 0.5])])\n\n    # Test with sparse matrix\n    y_sparse = sp.csr_matrix(y)\n    classes, n_classes, class_prior = class_distribution(y_sparse)\n    \n    assert_array_equal(classes, [np.array([1, 2]), np.array([2, 3])])\n    assert_array_equal(n_classes, [2, 2])\n    assert_allclose(class_prior, [np.array([0.5, 0.5]), np.array([0.5, 0.5])])\n", "def test_type_of_target_implicit_zeroes():\n    # Test that type_of_target correctly handles indicator matrices with\n    # implicit zeroes (i.e., when a class is not explicitly listed for a sample)\n    y = csr_matrix(np.array([[1, 0], [0, 0]]))\n    assert type_of_target(y) == \"multilabel-indicator\"\n\n    y = np.array([[1, 0], [0, 0]])\n    assert type_of_target(y) == \"multilabel-indicator\"\n", "def test_unique_labels_with_mixed_dtypes():\n    # Test that unique_labels raises an error when input arrays have mixed dtypes\n    with pytest.raises(ValueError, match=\"Mix of label input types\"):\n        unique_labels([1, 2, 3], [\"a\", \"b\", \"c\"])\n", "def test_unique_labels_mixed_types():\n    # Test that unique_labels raises an error when encountering mixed types\n    ys = [[1, 2], [\"a\", \"b\"]]\n    with pytest.raises(ValueError):\n        unique_labels(*ys)\n", "def test_type_of_target_string_labels():\n    # Test that type_of_target correctly handles string labels\n    y = np.array([\"a\", \"b\", \"c\"])\n    assert type_of_target(y) == \"multiclass\"\n\n    y = np.array([[\"a\"], [\"b\"], [\"c\"]])\n    assert type_of_target(y) == \"multiclass\"\n\n    y = np.array([[\"a\", \"b\"], [\"b\", \"c\"]])\n    assert type_of_target(y) == \"multiclass-multioutput\"\n"], "sample_112": ["def test_isotonic_regression_sample_weight_dtype():\n    # Test that isotonic_regression preserves the dtype of sample_weight\n    y = np.array([1, 2, 3, 4, 5], dtype=np.float32)\n    sample_weight = np.array([1, 1, 1, 1, 1], dtype=np.float32)\n    result = isotonic_regression(y, sample_weight=sample_weight)\n    assert result.dtype == np.float32\n\n    y = np.array([1, 2, 3, 4, 5], dtype=np.float64)\n    sample_weight = np.array([1, 1, 1, 1, 1], dtype=np.float64)\n    result = isotonic_regression(y, sample_weight=sample_weight)\n    assert result.dtype == np.float64\n", "def test_isotonic_regression_pickle():\n    \"\"\"Test that IsotonicRegression can be pickled.\"\"\"\n    iso = IsotonicRegression()\n    X, y = make_regression(n_samples=10, n_features=1, random_state=42)\n    iso.fit(X, y)\n\n    # Test that the object can be pickled and unpickled without changing its\n    # attributes.\n    iso_pickled = pickle.loads(pickle.dumps(iso))\n\n    assert_array_equal(iso.X_thresholds_, iso_pickled.X_thresholds_)\n    assert_array_equal(iso.y_thresholds_, iso_pickled.y_thresholds_)\n\n    # Test that the unpickled object can still make predictions.\n    y_pred = iso.predict(X)\n    y_pred_pickled = iso_pickled.predict(X)\n    assert_allclose(y_pred, y_pred_pickled)\n", "def test_isotonic_regression_sample_weight():\n    # Test isotonic regression with sample weights\n    n_samples = 10\n    X, y = make_regression(n_samples=n_samples, n_features=1, random_state=42)\n\n    # Create sample weights\n    sample_weight = np.ones(n_samples)\n    sample_weight[::2] = 0.5\n\n    # Fit isotonic regression model with and without sample weights\n    ir_sw = IsotonicRegression()\n    ir_sw.fit(X, y, sample_weight=sample_weight)\n\n    ir_no_sw = IsotonicRegression()\n    ir_no_sw.fit(X, y)\n\n    # Check that the models are different\n    assert not np.array_equal(ir_sw.X_thresholds_, ir_no_sw.X_thresholds_)\n    assert not np.array_equal(ir_sw.y_thresholds_, ir_no_sw.y_thresholds_)\n", "def test_isotonic_regression_check_increasing():\n    # Test check_increasing function with different inputs\n    x = np.array([1, 2, 3, 4, 5])\n    y = np.array([1, 2, 3, 4, 5])\n\n    # Test with increasing sequence\n    assert check_increasing(x, y) is True\n\n    # Test with decreasing sequence\n    y = np.array([5, 4, 3, 2, 1])\n    assert check_increasing(x, y) is False\n\n    # Test with constant sequence\n    y = np.array([1, 1, 1, 1, 1])\n    assert check_increasing(x, y) is True\n\n    # Test with non-monotonic sequence\n    y = np.array([1, 3, 2, 4, 5])\n    assert check_increasing(x, y) is True\n\n    # Test with Spearman correlation coefficient spanning zero\n    x = np.array([1, 2, 3, 4, 5])\n    y = np.array([2, 1, 4, 3, 5])\n    with warnings.catch_warnings(record=True) as w:\n        assert check_increasing(x, y) is True\n        assert len(w) == 1\n", "def test_isotonic_regression_non_finite_values():\n    # Test that isotonic_regression handles non-finite values correctly\n    X = np.array([1, 2, 3, 4, 5])\n    y = np.array([1.0, np.nan, 3.0, np.inf, -np.inf])\n\n    with pytest.raises(ValueError):\n        isotonic_regression(y)\n\n    # Test that finite values are not affected by non-finite values\n    y[1] = 2.0\n    y_expected = isotonic_regression(y[:3])\n    y_result = isotonic_regression(y)[:3]\n    assert_array_equal(y_result, y_expected)\n"], "sample_138": ["def test_bc_block_plus_ident():\n    # Test that adding BlockMatrix with Identity works correctly\n    block = BlockDiagMatrix(A, B)\n    identity = Identity(n + n)\n    assert bc_block_plus_ident(block + identity) == \\\n        BlockDiagMatrix(A + Identity(n), B + Identity(n))\n", "def test_blockcut():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (1, 3))\n    assert isinstance(B, BlockMatrix)\n    assert B.blocks[0, 1] == Matrix([[1, 2, 3]])\n    assert B.blocks[1, 0] == Matrix([[4], [8], [12]])\n", "def test_blockcut():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (1, 3))\n    assert isinstance(B, BlockMatrix)\n    assert B.blocks[0, 1] == Matrix([[1, 2, 3]])\n    assert B.blocks[1, 0] == Matrix([[4], [8], [12]])\n", "def test_bc_dist():\n    A = BlockDiagMatrix(Identity(n), Identity(n))\n    B = block_collapse(2*A)\n    assert isinstance(B, BlockDiagMatrix)\n    assert B.diag[0] == 2*Identity(n)\n    assert B.diag[1] == 2*Identity(n)\n\n    C = BlockMatrix([[A, ZeroMatrix(n, n)]])\n    D = block_collapse(3*C)\n    assert isinstance(D, BlockMatrix)\n    assert D.blocks[0, 0] == 3*A\n    assert D.blocks[0, 1] == ZeroMatrix(n, n)\n", "def test_blockcut():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (1, 3))\n    assert isinstance(B, BlockMatrix)\n    assert B.blocks[0, 1] == Matrix([[1, 2, 3]])\n    assert B.blocks[1, 0] == Matrix([[4], [8], [12]])\n"], "sample_16": ["def test_lookup_field(self):\n    article = Article.objects.create(title='Test article')\n    field, attr, value = lookup_field('title', article)\n    self.assertEqual(field.name, 'title')\n    self.assertIsNone(attr)\n    self.assertEqual(value, 'Test article')\n\n    # Test callable\n        return obj.title.upper()\n    field, attr, value = lookup_field(callable_title, article)\n    self.assertIsNone(field)\n    self.assertEqual(attr.__name__, 'callable_title')\n    self.assertEqual(value, 'TEST ARTICLE')\n\n    # Test property\n    class ArticleForm(forms.ModelForm):\n        class Meta:\n            model = Article\n            fields = ('title',)\n\n        @property\n            return self.instance.title[:5]\n\n    form = ArticleForm(instance=article)\n    field, attr, value = lookup_field('short_title', article, model_admin=form)\n    self.assertIsNone(field)\n    self.assertEqual(attr.fget.__name__, 'short_title')\n    self.assertEqual(value, 'Test')\n", "def test_lookup_field(self):\n    article = Article.objects.create(title='Test Article')\n    field, attr, value = lookup_field('title', article)\n    self.assertEqual(field.name, 'title')\n    self.assertIsNone(attr)\n    self.assertEqual(value, 'Test Article')\n\n    field, attr, value = lookup_field('does_not_exist', article)\n    self.assertIsNone(field)\n    self.assertIsInstance(attr, AttributeError)\n    with self.assertRaises(AttributeError):\n        value\n\n    # Test callable attribute\n        return 'callable result'\n\n    article.callable_attribute = callable_attribute\n    field, attr, value = lookup_field('callable_attribute', article)\n    self.assertIsNone(field)\n    self.assertEqual(attr, callable_attribute)\n    self.assertEqual(value, 'callable result')\n", "def test_lookup_field_with_callable(self):\n    obj = Count.objects.create(num=5)\n        return \"Callable value\"\n    self.assertEqual(lookup_field(callable_func, obj)[2], \"Callable value\")\n", "def test_quote_unquote(self):\n    original_string = \"Hello, World! /_#?;@&=+$,\"\n    quoted_string = quote(original_string)\n    unquoted_string = unquote(quoted_string)\n    self.assertEqual(unquoted_string, original_string)\n\n    # Test quote/unquote with non-string input\n    original_value = 123\n    quoted_value = quote(original_value)\n    self.assertEqual(quoted_value, original_value)\n", "def test_lookup_field_callable(self):\n    model_admin = helpers.ModelAdmin(Count, None)\n    obj = Count.objects.create(num=1)\n\n        return 'Callable Value'\n\n    setattr(model_admin, 'callable_attr', callable_attr)\n    f, attr, value = lookup_field('callable_attr', obj, model_admin=model_admin)\n    self.assertIsNone(f)\n    self.assertEqual(attr.__name__, 'callable_attr')\n    self.assertEqual(value, 'Callable Value')\n"], "sample_89": ["def test_splitnode() -> None:\n    assert nodes._splitnode(\"\") == ()\n    assert nodes._splitnode(\"foo\") == (\"foo\",)\n    assert nodes._splitnode(\"foo/bar\") == (\"foo\", \"bar\")\n    assert nodes._splitnode(\"foo/bar::TestBaz\") == (\"foo\", \"bar\", \"TestBaz\")\n    assert nodes._splitnode(\"foo/bar/test_baz.py::TestBaz\") == (\n        \"foo\",\n        \"bar\",\n        \"test_baz.py\",\n        \"TestBaz\",\n    )\n", "def test_node_repr(tmpdir):\n    class MyNode(nodes.Node):\n            super().__init__(name, parent=parent)\n\n    node = MyNode(\"foo\")\n    assert repr(node) == \"<MyNode foo>\"\n    subnode = MyNode(\"bar\", parent=node)\n    assert repr(subnode) == \"<MyNode bar>\"\n", "def test_splitnode(nodeid, expected):\n    assert nodes._splitnode(nodeid) == tuple(expected)\n", "def test_splitnode(nodeid, expected):\n    assert nodes._splitnode(nodeid) == tuple(expected)\n", "def test_splitnode(nodeid, expected):\n    assert nodes._splitnode(nodeid) == tuple(expected)\n"], "sample_13": ["def test_urlencode_with_non_string_values(self):\n    with self.assertRaises(TypeError) as e:\n        urlencode({'a': None})\n    self.assertEqual(str(e.exception), self.cannot_encode_none_msg)\n\n    with self.assertRaises(TypeError) as e:\n        urlencode([('a', None)])\n    self.assertEqual(str(e.exception), self.cannot_encode_none_msg)\n\n    with self.assertRaises(TypeError) as e:\n        urlencode(MultiValueDict({'a': [None]}))\n    self.assertEqual(str(e.exception), self.cannot_encode_none_msg)\n", "def test_urlencode_with_non_string_values(self):\n    data = {'a': 1, 'b': None, 'c': [2, 3], 'd': (4, 5)}\n    with self.assertRaises(TypeError) as cm:\n        urlencode(data)\n    self.assertEqual(str(cm.exception), self.cannot_encode_none_msg)\n\n    data['b'] = ''\n    self.assertEqual(urlencode(data), 'a=1&c=2&c=3&d=4&d=5')\n", "    def test_round_trip(self):\n        bytestring = b'Hello, World!'\n        encoded = urlsafe_base64_encode(bytestring)\n        decoded = urlsafe_base64_decode(encoded)\n        self.assertEqual(decoded, bytestring)\n", "def test_urlencode_none_value(self):\n    with self.assertRaises(TypeError) as e:\n        urlencode({'a': None})\n    self.assertEqual(str(e.exception), self.cannot_encode_none_msg)\n", "def test_urlencode_none_value(self):\n    with self.assertRaises(TypeError) as context:\n        urlencode({'a': None})\n    self.assertEqual(str(context.exception), self.cannot_encode_none_msg)\n"], "sample_50": ["def test_message_encoder_decoder(self):\n    message = Message(constants.DEBUG, 'Test message', extra_tags='tag1 tag2')\n    encoder = MessageEncoder()\n    decoder = MessageDecoder()\n\n    encoded_message = encoder.default(message)\n    self.assertIsInstance(encoded_message, list)\n    self.assertEqual(len(encoded_message), 5)\n\n    decoded_message = decoder.process_messages(encoded_message)\n    self.assertIsInstance(decoded_message, Message)\n    self.assertEqual(decoded_message.message, 'Test message')\n    self.assertEqual(decoded_message.level, constants.DEBUG)\n    self.assertEqual(decoded_message.extra_tags, 'tag1 tag2')\n\n    # Test SafeData encoding and decoding\n    safe_message = Message(constants.DEBUG, mark_safe('Safe message'))\n    encoded_safe_message = encoder.default(safe_message)\n    self.assertEqual(encoded_safe_message[1], 1)  # 1 indicates SafeData\n\n    decoded_safe_message = decoder.process_messages(encoded_safe_message)\n    self.assertIsInstance(decoded_safe_message.message, SafeData)\n    self.assertEqual(decoded_safe_message.message, 'Safe message')\n", "def test_message_encoder(self):\n    message = Message(constants.DEBUG, 'message', extra_tags='tag')\n    encoder = MessageEncoder()\n    encoded = encoder.encode([message])\n    self.assertIn(MessageEncoder.message_key, encoded)\n    self.assertEqual(json.loads(encoded)[0], MessageEncoder.message_key)\n\n    # Test SafeData is encoded as 1\n    safe_message = Message(constants.DEBUG, mark_safe('message'))\n    encoded = encoder.encode([safe_message])\n    self.assertEqual(json.loads(encoded)[1], 1)\n\n    # Test non-SafeData is encoded as 0\n    unsafe_message = Message(constants.DEBUG, 'message')\n    encoded = encoder.encode([unsafe_message])\n    self.assertEqual(json.loads(encoded)[1], 0)\n", "def test_process_messages(self):\n    decoder = MessageDecoder()\n    message = Message(constants.DEBUG, 'message', 'extra_tags')\n\n    # Test with a single message\n    data = [MessageEncoder.message_key, 0, constants.DEBUG, 'message']\n    self.assertEqual(decoder.process_messages(data), message)\n\n    # Test with a list of messages\n    data = [\n        [MessageEncoder.message_key, 0, constants.DEBUG, 'message1'],\n        [MessageEncoder.message_key, 0, constants.INFO, 'message2']\n    ]\n    expected_messages = [\n        Message(constants.DEBUG, 'message1'),\n        Message(constants.INFO, 'message2')\n    ]\n    self.assertEqual(decoder.process_messages(data), expected_messages)\n\n    # Test with a message containing safe data\n    data = [MessageEncoder.message_key, 1, constants.DEBUG, mark_safe('safe_message')]\n    expected_message = Message(constants.DEBUG, mark_safe('safe_message'))\n    self.assertEqual(decoder.process_messages(data), expected_message)\n\n    # Test with an empty list\n    self.assertIsNone(decoder.process_messages([]))\n\n    # Test with a non-list input\n    self.assertIsNone(decoder.process_messages('not_a_list'))\n\n    # Test with a dictionary\n    data = {'key': [MessageEncoder.message_key, 0, constants.DEBUG, 'message']}\n    expected_messages = {'key': Message(constants.DEBUG, 'message')}\n    self.assertEqual(decoder.process_messages(data), expected_messages)\n", "def test_max_cookie_size(self):\n    storage = self.get_storage()\n    messages = [Message(constants.DEBUG, get_random_string(100)) for _ in range(20)]\n    response = self.get_response()\n    unstored_messages = storage._store(messages, response)\n    self.assertEqual(stored_cookie_messages_count(storage, response), 17)\n    self.assertEqual(len(unstored_messages), 3)\n", "def test_cookie_storage_max_cookie_size(self):\n    storage = self.get_storage()\n    messages = [Message(constants.DEBUG, get_random_string(50)) for _ in range(20)]\n    response = self.get_response()\n    unstored_messages = storage._store(messages, response)\n    self.assertLessEqual(len(storage._encode(messages)), storage.max_cookie_size)\n    self.assertEqual(len(unstored_messages), len(messages) - stored_cookie_messages_count(storage, response))\n"], "sample_92": ["def test_xfail_mark_with_condition(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.xfail(condition=True, reason=\"condition is true\")\n            assert 1 == 1\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.assert_outcomes(skipped=1)\n    assert \"XFAIL\" in result.stdout.str()\n    assert \"condition is true\" in result.stdout.str()\n", "def test_evaluate_xfail_marks_strict(self, pytestconfig):\n    item = pytestconfig.rootdir.join(\"test_evaluate_xfail_marks.py\")\n    item = pytestconfig.getitem(item)\n    mark = pytest.mark.xfail(strict=True)\n    item.add_marker(mark)\n    xfailed = evaluate_xfail_marks(item)\n    assert xfailed is not None\n    assert xfailed.strict is True\n", "def test_evaluate_xfail_marks_with_condition(item):\n    item.add_marker(pytest.mark.xfail(condition=\"sys.platform == 'win32'\"))\n    result = evaluate_xfail_marks(item)\n    assert result is not None\n    assert result.reason == \"condition: sys.platform == 'win32'\"\n    assert result.run is True\n    assert result.strict is False\n    assert result.raises is None\n", "def test_evaluate_skip_marks_item_with_skip_mark(testdir):\n    item = testdir.getitem(\"def test_skip(): pass\")\n    marks = [pytest.mark.skip(reason=\"skip reason\")]\n    item.add_marker(marks[0])\n    skip = evaluate_skip_marks(item)\n    assert skip is not None\n    assert skip.reason == \"skip reason\"\n", "def test_evaluate_skip_marks_unconditional_skip(item):\n    item.add_marker(pytest.mark.skip(reason=\"unconditional skip\"))\n    result = evaluate_skip_marks(item)\n    assert result is not None\n    assert result.reason == \"unconditional skip\"\n"], "sample_135": ["def test_free_symbols():\n    x, y = symbols('x y')\n    b1 = Basic(x)\n    b2 = Basic(b1, y)\n    assert b1.free_symbols == {x}\n    assert b2.free_symbols == {x, y}\n    f = Function('f')\n    b3 = Basic(f(x))\n    assert b3.free_symbols == {x}\n    b4 = Basic(f(x), y)\n    assert b4.free_symbols == {x, y}\n", "def test_doit():\n    f = Basic(sin, 1)\n    assert f.doit() == sin(1)\n    assert f.doit(deep=False) == f\n", "def test_Basic_copy():\n    v = Basic(1, 2, 3)\n    assert v.copy() == v\n    assert v.copy() is not v\n\n    class Mat(Basic):\n            return self.func(*self.args)\n\n    m = Mat([[1, 2], [3, 4]])\n    assert m.copy() == m\n    assert m.copy() is not m\n", "def test_doit():\n    f = Basic()\n    assert f.doit() == f\n    assert f.doit(deep=False) == f\n    assert f.doit(deep=True) == f\n    raises(TypeError, lambda: f.doit(something='else'))\n", "def test_doit():\n    f = Function('f')\n    assert Basic().doit() == Basic()\n    assert Basic(Basic()).doit() == Basic(Basic())\n    assert Basic(f(1)).doit() == Basic(f(1))\n    assert Basic(Integral(1, 1, 2)).doit() == Basic(1)\n    assert Basic(Sum(1, (Symbol('i'), 1, 3))).doit() == Basic(3)\n    assert Basic(f(Integral(1, 1, 2))).doit(deep=False) == Basic(f(Integral(1, 1, 2)))\n    assert Basic(f(Integral(1, 1, 2))).doit() == Basic(f(1))\n"], "sample_46": ["    def setUp(self):\n        self.reference = Columns('table', ['column1', 'column2'], lambda table: table.upper())\n", "    def setUp(self):\n        self.reference = TableColumns('table', ['column1', 'column2'])\n", "    def setUp(self):\n        self.reference = TableColumns('table', ['column1', 'column2'])\n", "    def setUp(self):\n        self.reference = Columns('table', ['column1', 'column2'], lambda column: column.upper())\n", "    def setUp(self):\n        self.reference = TableColumns('table', ['column1', 'column2'])\n"], "sample_159": ["def test_prefix_unit():\n    # Test prefix_unit function with different units and prefixes\n    u = Quantity(\"test_unit\", abbrev=\"tu\")\n    prefixed_units = prefix_unit(u, PREFIXES)\n    assert len(prefixed_units) == len(PREFIXES)\n\n    # Test with binary prefixes\n    prefixed_units = prefix_unit(u, BIN_PREFIXES)\n    assert len(prefixed_units) == len(BIN_PREFIXES)\n\n    # Test with a subset of prefixes\n    pref_subset = {\"k\": PREFIXES[\"k\"], \"m\": PREFIXES[\"m\"]}\n    prefixed_units = prefix_unit(u, pref_subset)\n    assert len(prefixed_units) == len(pref_subset)\n", "def test_prefix_operations():\n    # Test multiplication with number\n    assert kilo * 2 == 2000\n\n    # Test division with number\n    assert kilo / 2 == 500\n\n    # Test multiplication with another prefix\n    assert kilo * kibi == kilo.scale_factor * kibi.scale_factor\n\n    # Test division with another prefix\n    assert kilo / kibi == kilo.scale_factor / kibi.scale_factor\n\n    # Test rdivision with another prefix\n    assert 1 / kilo == 1 / kilo.scale_factor\n", "def test_prefix_unit():\n    u = Quantity(\"testunit\", abbrev=\"tu\")\n    prefixed_units = prefix_unit(u, PREFIXES)\n    assert len(prefixed_units) == 24\n    assert prefixed_units[0].name == \"yottatestunit\"\n    assert prefixed_units[0].abbrev == \"Ytu\"\n    assert prefixed_units[-1].name == \"yoctotestunit\"\n    assert prefixed_units[-1].abbrev == \"ytu\"\n", "def test_prefix_operations():\n    # Test prefix multiplication\n    assert kilo * 2 == 2000\n    assert kilo * kilo == 1000000\n    assert kilo * meter == 1000 * meter\n\n    # Test prefix division\n    assert kilo / 2 == 500\n    assert kilo / kilo == 1\n    assert kilo / meter == 1000 / meter\n\n    # Test prefix with binary base\n    assert kibi * kibi == 1048576\n", "def test_prefix_unit():\n    # Test that prefix_unit returns the correct units\n    u = Quantity(\"test unit\", abbrev=\"tu\")\n    prefixed_units = prefix_unit(u, PREFIXES)\n    assert len(prefixed_units) == len(PREFIXES)\n    for i, (prefix_abbr, prefix) in enumerate(PREFIXES.items()):\n        assert prefixed_units[i].name == f\"{prefix.name}{u.name}\"\n        assert prefixed_units[i].abbrev == f\"{prefix.abbrev}{u.abbrev}\"\n\n    # Test with a subset of prefixes\n    pref_subset = {\"k\": kilo, \"m\": PREFIXES[\"m\"]}\n    prefixed_units = prefix_unit(u, pref_subset)\n    assert len(prefixed_units) == len(pref_subset)\n    for i, (prefix_abbr, prefix) in enumerate(pref_subset.items()):\n        assert prefixed_units[i].name == f\"{prefix.name}{u.name}\"\n        assert prefixed_units[i].abbrev == f\"{prefix.abbrev}{u.abbrev}\"\n\n    # Test with binary prefixes\n    prefixed_units = prefix_unit(u, BIN_PREFIXES)\n    assert len(prefixed_units) == len(BIN_PREFIXES)\n    for i, (prefix_abbr, prefix) in enumerate(BIN_PREFIXES.items()):\n        assert prefixed_units[i].name == f\"{prefix.name}{u.name}\"\n        assert prefixed_units[i].abbrev == f\"{prefix.abbrev}{u.abbrev}\"\n"], "sample_24": ["def test_validation_error_hash(self):\n    # Test that ValidationError instances with the same parameters are hash equal\n    ve1 = ValidationError('Error message', code='error_code', params={'param': 'value'})\n    ve2 = ValidationError('Error message', code='error_code', params={'param': 'value'})\n    self.assertEqual(hash(ve1), hash(ve2))\n\n    # Test that ValidationError instances with different parameters are not hash equal\n    ve3 = ValidationError('Different error message', code='error_code', params={'param': 'value'})\n    self.assertNotEqual(hash(ve1), hash(ve3))\n\n    # Test that ValidationError instances with lists or dictionaries are hash equal\n    ve4 = ValidationError(['Error message 1', 'Error message 2'])\n    ve5 = ValidationError(['Error message 1', 'Error message 2'])\n    self.assertEqual(hash(ve4), hash(ve5))\n\n    ve6 = ValidationError({'field1': ['Error message 1'], 'field2': ['Error message 2']})\n    ve7 = ValidationError({'field1': ['Error message 1'], 'field2': ['Error message 2']})\n    self.assertEqual(hash(ve6), hash(ve7))\n", "def test_validation_error_with_message_dict(self):\n    error = ValidationError({'field1': ['error1'], 'field2': ['error2']})\n    self.assertEqual(error.message_dict, {'field1': ['error1'], 'field2': ['error2']})\n    self.assertEqual(error.messages, ['error1', 'error2'])\n    self.assertEqual(str(error), \"{'field1': ['error1'], 'field2': ['error2']}\")\n", "def test_validation_error_init_with_message(self):\n    message = \"Test error message\"\n    error = ValidationError(message)\n    self.assertEqual(error.message, message)\n    self.assertIsNone(error.code)\n    self.assertIsNone(error.params)\n    self.assertEqual(len(error.error_list), 1)\n    self.assertEqual(str(error.error_list[0]), message)\n", "def test_validation_error_hash(self):\n    error1 = ValidationError('Error message', code='invalid')\n    error2 = ValidationError('Error message', code='invalid')\n    self.assertEqual(hash(error1), hash(error2))\n\n    error3 = ValidationError('Error message', code='invalid', params={'foo': 'bar'})\n    self.assertNotEqual(hash(error1), hash(error3))\n", "def test_validation_error_hash(self):\n    error1 = ValidationError('Error message', code='code', params={'param': 'value'})\n    error2 = ValidationError('Error message', code='code', params={'param': 'value'})\n    error3 = ValidationError('Different error message', code='code', params={'param': 'value'})\n\n    self.assertEqual(hash(error1), hash(error2))\n    self.assertNotEqual(hash(error1), hash(error3))\n"], "sample_147": ["def test_derivative_with_noncommutative_symbol():\n    f = noncomm_x**3\n    assert isinstance(f.diff(noncomm_x), Derivative)\n", "def test_derivative_kind():\n    x = Symbol('x')\n    y = Symbol('y')\n\n    assert Derivative(x, x).kind == NumberKind\n    assert Derivative(y, x).kind == UndefinedKind\n    assert Derivative(x*y, x).kind == UndefinedKind\n    assert Derivative(Mul(x, y), x).kind == UndefinedKind\n    assert Derivative(Add(x, y), x).kind == UndefinedKind\n", "def test_derivative_with_noncommutative():\n    # Test that Derivative works with non-commutative symbols\n    f = noncomm_x**3\n    assert f.diff(noncomm_x) == 3*noncomm_x**2\n", "def test_derivative():\n    f = comm_x**3\n    assert isinstance(f.diff(comm_x), Add)\n    assert f.diff(comm_x, 2).is_Number\n    assert not f.diff(comm_x, 1.5).is_Number\n    assert (f.diff(comm_x) * f.diff(comm_x)).diff(comm_x) == 30*comm_x**4\n    assert (comm_x**2 + 2*comm_x + 1).diff(comm_x, 2) == 2\n    assert (comm_x**2 + 2*comm_x + 1).diff(comm_x, 2000000) == 0\n", "def test_Derivative_doit():\n    f = Function('f')\n    x = Symbol('x')\n    assert Derivative(f(x), x).doit() == f(x).diff(x)\n    assert Derivative(Derivative(f(x), x), x).doit() == f(x).diff(x, 2)\n    assert Derivative(x**2, x).doit() == 2*x\n    assert Derivative(x**2, (x, 2)).doit() == 2\n    assert Derivative(sin(x), x).doit() == cos(x)\n    assert Derivative(cos(x), x).doit() == -sin(x)\n"], "sample_57": ["def test_baseformset_add_fields(self):\n    # Test that add_fields is called for each form in the formset\n    class TestForm(Form):\n        pass\n\n    class BaseTestFormSet(BaseFormSet):\n            super().add_fields(form, index)\n            if index is not None:\n                form.fields[\"custom_field\"] = CharField()\n\n    TestFormSet = formset_factory(TestForm, formset=BaseTestFormSet, extra=2)\n\n    formset = TestFormSet()\n    for i, form in enumerate(formset):\n        if i == 0:\n            self.assertIn(\"custom_field\", form.fields)\n        else:\n            self.assertIn(\"custom_field\", form.fields)\n", "def test_formset_non_form_error(self):\n    formset = ChoiceFormsetWithNonFormError(\n        data={\n            \"choices-TOTAL_FORMS\": \"1\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-MAX_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Test\",\n            \"choices-0-votes\": \"1\",\n        }\n    )\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(len(formset.non_form_errors()), 1)\n    self.assertEqual(formset.non_form_errors()[0], \"non-form error\")\n", "def test_formset_management_form_validation_error(self):\n    # Ensure a validation error is raised when the management form is invalid.\n    data = {\n        \"choices-TOTAL_FORMS\": \"1\",\n        \"choices-0-choice\": \"Test\",\n        \"choices-0-votes\": \"1\",\n    }\n    formset = self.make_choiceformset(data)\n    with self.assertRaisesMessage(\n        ValidationError, \"ManagementForm data is missing or has been tampered with.\"\n    ):\n        formset.is_valid()\n", "def test_management_form_required_fields(self):\n    management_form = ManagementForm()\n    required_fields = [\"TOTAL_FORMS\", \"INITIAL_FORMS\"]\n    for field_name in required_fields:\n        self.assertTrue(management_form.fields[field_name].required)\n        self.assertEqual(management_form.fields[field_name].widget, HiddenInput)\n\n    not_required_fields = [\"MIN_NUM_FORMS\", \"MAX_NUM_FORMS\"]\n    for field_name in not_required_fields:\n        self.assertFalse(management_form.fields[field_name].required)\n        self.assertEqual(management_form.fields[field_name].widget, HiddenInput)\n", "def test_baseformset_management_form_validation_error(self):\n    data = {\n        \"choices-TOTAL_FORMS\": \"1\",\n        \"choices-INITIAL_FORMS\": \"\",\n        \"choices-MIN_NUM_FORMS\": \"\",\n        \"choices-MAX_NUM_FORMS\": \"\",\n    }\n    formset = self.make_choiceformset(data)\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(len(formset.management_form.errors), 1)\n    self.assertIn(\"initial_forms\", formset.management_form.errors)\n"], "sample_103": ["def test_mutual_info_classif_discrete_features():\n    # Test mutual information between discrete features and a target variable.\n    X = np.array([[0, 1, 0],\n                  [1, 0, 0],\n                  [0, 0, 1]])\n    y = np.array([0, 0, 1])\n    mi = mutual_info_classif(X, y, discrete_features=True)\n    assert_array_equal(mi, np.array([0., 0., 1.]))\n", "def test_mutual_info_regression_with_discrete_features():\n    # Test mutual_info_regression with discrete features.\n    X = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n    y = np.array([0.5, 0.5, 0.2, 0.8])\n\n    # All features are discrete.\n    discrete_features = [True, True]\n    mi = mutual_info_regression(X, y, discrete_features=discrete_features)\n    assert_array_equal(mi, mutual_info_classif(X, (y > 0.5).astype(int),\n                                               discrete_features=discrete_features))\n\n    # Only the first feature is discrete.\n    discrete_features = [True, False]\n    mi = mutual_info_regression(X, y, discrete_features=discrete_features)\n    expected_mi = np.array([mutual_info_classif(X[:, 0].reshape(-1, 1), (y > 0.5).astype(int))[0],\n                            _compute_mi(X[:, 1], y, False, False)])\n    assert_array_equal(mi, expected_mi)\n\n    # Only the second feature is discrete.\n    discrete_features = [False, True]\n    mi = mutual_info_regression(X, y, discrete_features=discrete_features)\n    expected_mi = np.array([_compute_mi(X[:, 0], y, False, False),\n                            mutual_info_classif(X[:, 1].reshape(-1, 1), (y > 0.5).astype(int))[0]])\n    assert_array_equal(mi, expected_mi)\n", "def test_mutual_info_classif_discrete_features():\n    # Test mutual information between discrete features and a target variable\n    X = np.array([[0, 1], [1, 0], [0, 1], [1, 0]])\n    y = np.array([0, 0, 1, 1])\n    mi = mutual_info_classif(X, y, discrete_features=True)\n    assert_array_equal(mi, np.array([0., 0.]))\n\n    # Test with sparse input\n    X_sparse = csr_matrix(X)\n    mi_sparse = mutual_info_classif(X_sparse, y, discrete_features=True)\n    assert_array_equal(mi_sparse, np.array([0., 0.]))\n", "def test_mutual_info_regression_with_discrete_features():\n    # Test mutual information regression with discrete features.\n    random_state = check_random_state(0)\n    X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    y = np.array([1, 2, 3])\n    discrete_features = [True, False, True]\n\n    mi = mutual_info_regression(X, y, discrete_features=discrete_features,\n                                random_state=random_state)\n\n    assert_array_equal(mi.shape, (X.shape[1],))\n    assert_greater(mi[0], 0)\n    assert_greater(mi[1], 0)\n    assert_greater(mi[2], 0)\n", "def test_mutual_info_classif_discrete_features():\n    # Test mutual information between discrete features and a target variable\n    X = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 1], [1, 0, 0]])\n    y = np.array([0, 0, 1, 1])\n    mi = mutual_info_classif(X, y, discrete_features='auto')\n    assert_array_equal(mi, np.array([0., 0., 0.69314718]))\n"], "sample_108": ["def test_libsvm_sparse_predict_proba():\n    # Test predict_proba with sparse data\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=10,\n                               random_state=0)\n    X_sparse = sparse.csr_matrix(X)\n\n    clf = svm.SVC(kernel='linear', probability=True, random_state=0)\n    clf.fit(X_sparse, y)\n\n    assert_array_almost_equal(clf.predict_proba(X_sparse).sum(axis=1), np.ones(100))\n", "def test_libsvm_sparse_predict_proba():\n    # Test that predict_proba works with sparse input\n    X, y = make_classification(n_samples=20, n_features=10)\n    clf = svm.SVC(probability=True)\n    clf.fit(X, y)\n\n    X_sparse = sparse.csr_matrix(X)\n    y_proba_sparse = clf.predict_proba(X_sparse)\n    y_proba_dense = clf.predict_proba(X)\n\n    assert_array_almost_equal(y_proba_sparse, y_proba_dense)\n", "def test_libsvm_predict_proba():\n    # Load the iris dataset\n    iris = datasets.load_iris()\n    X_train, X_test, y_train, y_test = train_test_split(\n        iris.data, iris.target, test_size=0.5, random_state=42)\n\n    # Train a SVM model with probability estimates\n    clf = svm.SVC(probability=True, random_state=42)\n    clf.fit(X_train, y_train)\n\n    # Predict probabilities\n    y_proba = clf.predict_proba(X_test)\n\n    # Check if probabilities sum up to 1\n    assert_array_almost_equal(y_proba.sum(axis=1), np.ones(y_proba.shape[0]))\n\n    # Check if predict_proba returns a numpy array\n    assert isinstance(y_proba, np.ndarray)\n\n    # Check if predict_proba works with sparse data\n    X_sparse = sparse.csr_matrix(X_test)\n    y_proba_sparse = clf.predict_proba(X_sparse)\n    assert_array_almost_equal(y_proba_sparse, y_proba)\n", "def test_libsvm_decision_function_shape():\n    # check that decision_function_shape is correctly handled\n    X, y = make_classification(n_samples=50, n_features=20, random_state=0)\n\n    # check ovo\n    clf = svm.SVC(decision_function_shape='ovo')\n    clf.fit(X, y)\n    dec = clf.decision_function(X)\n    assert_array_equal(dec.shape, (len(X), len(np.unique(y)) * (len(np.unique(y)) - 1) // 2))\n\n    # check ovr\n    clf = svm.SVC(decision_function_shape='ovr')\n    clf.fit(X, y)\n    dec = clf.decision_function(X)\n    assert_array_equal(dec.shape, (len(X), len(np.unique(y))))\n", "def test_libsvm_predict_proba_ties():\n    # Test that predict_proba returns the correct result when there are ties\n    X, y = make_classification(n_samples=100, n_features=20, random_state=42)\n    clf = svm.SVC(probability=True, decision_function_shape='ovr',\n                  break_ties=False, random_state=42)\n    clf.fit(X, y)\n\n    # Make sure there are ties\n    dec_func = clf.decision_function(X)\n    assert np.any(dec_func == dec_func.max(axis=1)[:, np.newaxis])\n\n    prob = clf.predict_proba(X)\n    assert_array_almost_equal(np.sum(prob, axis=1), np.ones(len(X)))\n"], "sample_22": ["def test_unescape_string_literal(self):\n    self.assertEqual(text.unescape_string_literal('\"abc\"'), 'abc')\n    self.assertEqual(text.unescape_string_literal(\"'abc'\"), 'abc')\n    self.assertEqual(text.unescape_string_literal('\"a \\\\\"bc\\\\\"\"'), 'a \"bc\"')\n    self.assertEqual(text.unescape_string_literal(\"'\\\\'ab\\\\' c'\"), \"'ab' c\")\n    with self.assertRaises(ValueError):\n        text.unescape_string_literal('abc')\n", "def test_truncator_words(self):\n    truncator = text.Truncator('Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.')\n    self.assertEqual(truncator.words(10), 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod')\n    self.assertEqual(truncator.words(5, truncate='...'), 'Lorem ipsum dolor sit amet...')\n    with override('fr'):\n        self.assertEqual(truncator.words(5, truncate='...'), 'Lorem ipsum dolor sit amet...')\n", "def test_wrap(self):\n    self.assertEqual(text.wrap('Hello World', 5), 'Hello\\nWorld')\n    self.assertEqual(text.wrap('Hello   World', 5), 'Hello\\n\\n\\nWorld')\n    self.assertEqual(text.wrap('Hello\\nWorld', 5), 'Hello\\nWorld')\n    self.assertEqual(text.wrap('This is a very long line that needs to be wrapped.', 10),\n                     'This is a\\nvery long\\nline that\\nneeds to be\\nwrapped.')\n", "def test_wrap(self):\n    self.assertEqual(text.wrap('Hello world!', 15), 'Hello world!\\n')\n    self.assertEqual(text.wrap('Hello world!', 7), 'Hello\\nworld!\\n')\n    self.assertEqual(text.wrap('This is a very long sentence, with many words.', 10),\n                     'This is a\\nvery long\\nsentence,\\nwith many\\nwords.\\n')\n", "def test_unescape_string_literal(self):\n    self.assertEqual(text.unescape_string_literal('\"abc\"'), 'abc')\n    self.assertEqual(text.unescape_string_literal(\"'abc'\"), 'abc')\n    self.assertEqual(text.unescape_string_literal('\"a \\\\\"bc\\\\\"\"'), 'a \"bc\"')\n    self.assertEqual(text.unescape_string_literal(\"'\\\\'ab\\\\' c'\"), \"'ab' c\")\n    with self.assertRaises(ValueError):\n        text.unescape_string_literal('abc')\n    with self.assertRaises(ValueError):\n        text.unescape_string_literal('\"abc')\n"], "sample_38": ["    def test_read_only_password_hash_widget(self):\n        widget = ReadOnlyPasswordHashWidget()\n        html = widget.render('password', 'sha1$12345$1234567890abcdef1234567890abcdef12345678')\n        self.assertHTMLEqual(html, \"\"\"<div>", "    def test_widget(self):\n        field = ReadOnlyPasswordHashField()\n        self.assertIsInstance(field.widget, ReadOnlyPasswordHashWidget)\n", "    def test_computed_attrs(self):\n        field = ReadOnlyPasswordHashField()\n        self.assertTrue(field.disabled)\n        self.assertFalse(field.required)\n", "    def test_user_creation_password_validation(self):\n        # Test that invalid passwords raise ValidationError.\n        invalid_passwords = [\n            '',  # Empty password\n            'short',  # Too short\n            'onlyletters',  # No digits\n            'onlydigits12345',  # No letters\n            'commonpassword12345',  # Too common\n        ]\n        form = UserCreationForm()\n        for password in invalid_passwords:\n            with self.assertRaises(ValidationError):\n                form.clean_password2()\n                form.instance.set_password(password)\n                form._post_clean()\n", "    def test_user_creation_form_with_valid_data(self):\n        # Test that a valid user is created when form data is valid\n        data = {\n            'username': 'newuser',\n            'password1': 'test123',\n            'password2': 'test123',\n        }\n        form = UserCreationForm(data)\n        self.assertTrue(form.is_valid())\n        form.save()\n        self.assertEqual(User.objects.filter(username='newuser').count(), 1)\n"], "sample_34": ["    def test_model_validation(self):\n        class Model(models.Model):\n            name = models.CharField(max_length=10)\n\n        model = Model(name='a' * 11)\n        with self.assertRaises(Warning):\n            model.full_clean()\n", "    def test_model_name_db_lookup_clashes(self):\n        class MyModel(models.Model):\n            pass\n\n        model = MyModel()\n        with self.assertRaisesMessage(\n            Error,\n            \"The model name 'My_Model' cannot contain double underscores as \"\n            \"it collides with the query lookup syntax.\",\n        ):\n            model._check_model_name_db_lookup_clashes()\n\n        class MyModel(models.Model):\n            class Meta:\n                db_table = 'my__model'\n\n        model = MyModel()\n        with self.assertRaisesMessage(\n            Error,\n            \"The model name 'My_Model' cannot contain double underscores as \"\n            \"it collides with the query lookup syntax.\",\n        ):\n            model._check_model_name_db_lookup_clashes()\n\n        class MyModel(models.Model):\n            class Meta:\n                db_table = 'my_model'\n\n        model = MyModel()\n        model._check_model_name_db_lookup_clashes()  # No error.\n", "    def test_swappable(self):\n        class SwappableModel(models.Model):\n            class Meta:\n                swappable = 'SWAPPABLE_MODEL'\n\n        with self.settings(SWAPPABLE_MODEL='check_framework.SomeModel'):\n            errors = checks.run_checks()\n            self.assertEqual(errors, [])\n\n        with self.settings():\n            errors = checks.run_checks()\n            expected_errors = [\n                Error(\n                    \"'SWAPPABLE_MODEL' setting not installed\",\n                    id='models.E001',\n                ),\n            ]\n            self.assertEqual(errors, expected_errors)\n\n        class NonExistentAppSwappableModel(models.Model):\n            class Meta:\n                swappable = 'nonexistentapp.SomeModel'\n\n        errors = checks.run_checks()\n        expected_errors = [\n            Error(\n                \"'nonexistentapp.SomeModel' is not of the form 'app_label.app_name'.\",\n                id='models.E001',\n            ),\n        ]\n        self.assertEqual(errors, expected_errors)\n", "    def test_model_base_checks(self):\n        class Model(models.Model):\n            pass\n\n        self.assertEqual(Model.check(), [])\n", "    def test_model_str(self):\n        class TestModel(models.Model):\n            pass\n\n        errors = checks.run_checks(app_configs=self.apps.get_app_configs())\n        self.assertEqual(errors, [])\n\n        class TestModel(models.Model):\n                return ''\n\n        errors = checks.run_checks(app_configs=self.apps.get_app_configs())\n        self.assertEqual(errors, [])\n"], "sample_35": ["    def test_model_form_options(self):\n        class MyModelForm(forms.ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = '__all__'\n\n        opts = MyModelForm._meta\n        self.assertEqual(opts.model, ChoiceModel)\n        self.assertEqual(opts.fields, '__all__')\n        self.assertIsNone(opts.exclude)\n        self.assertIsNone(opts.widgets)\n        self.assertIsNone(opts.localized_fields)\n        self.assertIsNone(opts.labels)\n        self.assertIsNone(opts.help_texts)\n        self.assertIsNone(opts.error_messages)\n        self.assertIsNone(opts.field_classes)\n", "    def test_model_choice_field(self):\n        class TestForm(Form):\n            field1 = ModelChoiceField(ChoiceModel.objects.all())\n\n        form = TestForm({'field1': 1})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['field1'].id, 1)\n", "    def test_model_choice_field(self):\n        class ChoiceModelForm(forms.Form):\n            choice = ModelChoiceField(queryset=ChoiceModel.objects.all())\n\n        form = ChoiceModelForm(data={'choice': '1'})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors['choice'], ['Select a valid choice. That choice is not one of the available choices.'])\n\n        ChoiceModel.objects.create(choice='choice1')\n        form = ChoiceModelForm(data={'choice': '1'})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['choice'].pk, 1)\n", "    def test_model_choice_field(self):\n        choices = ChoiceModel.objects.all()\n        field = ModelChoiceField(queryset=choices)\n        self.assertEqual(field.widget.choices, field.choices)\n\n        # Test validation with a valid choice.\n        form = Form(data={'choice': choices[0].pk})\n        form.fields['choice'] = field\n        self.assertTrue(form.is_valid())\n\n        # Test validation with an invalid choice.\n        form = Form(data={'choice': 'invalid'})\n        form.fields['choice'] = field\n        self.assertFormErrors(['Select a valid choice. That choice is not one of the available choices.'], form.full_clean)\n", "    def test_model_choice_field(self):\n        class ChoiceForm(Form):\n            choice = ModelChoiceField(ChoiceModel.objects.all())\n\n        form = ChoiceForm({'choice': 1})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['choice'].id, 1)\n"], "sample_77": ["def test_setup_ticks_at(self, x):\n    a = self.setup_ticks(x, at=[1, 3, 9])\n    assert_array_equal(a.major.locator(), [1, 3, 9])\n", "def test_continuous_label(self, x):\n\n    # Test that a pre-configured formatter is used\n    fmt = mpl.ticker.FuncFormatter(lambda x, pos: f\"{x}!\")\n    ax, locs = self.setup_labels(x, formatter=fmt)\n    labels = [t.get_text() for t in ax.major.formatter.format_ticks(locs)]\n    assert labels == [\"1.0!\", \"3.0!\", \"9.0!\"]\n\n    # Test \"like\" string pattern\n    ax, locs = self.setup_labels(x, like=\".0f\")\n    labels = [t.get_text() for t in ax.major.formatter.format_ticks(locs)]\n    assert labels == [\"1\", \"3\", \"9\"]\n\n    # Test \"like\" format string\n    ax, locs = self.setup_labels(x, like=\"${x:.0f}\")\n    labels = [t.get_text() for t in ax.major.formatter.format_ticks(locs)]\n    assert labels == [\"$1\", \"$3\", \"$9\"]\n\n    # Test \"like\" callable\n        return f\"[{x}]\"\n    ax, locs = self.setup_labels(x, like=fmt)\n    labels = [t.get_text() for t in ax.major.formatter.format_ticks(locs)]\n    assert labels == [\"[1.0]\", \"[3.0]\", \"[9.0]\"]\n", "def test_continuous_label_like(self, x):\n    s = Continuous().label(like=\".2f\")._setup(x, Coordinate())\n    a = PseudoAxis(s._matplotlib_scale)\n    locs = a.major.locator()\n    labels = a.major.formatter.format_ticks(locs)\n    assert all(re.match(r\"^\\d+\\.\\d{2}$\", label) for label in labels)\n", "compilation error", "def test_continuous_label_formatter(self, x):\n\n    a, locs = self.setup_labels(x, like=\".2f\")\n    labels = a.major.formatter.format_ticks(locs)\n    assert all(re.match(r\"^\\d+\\.\\d\\d$\", label) for label in labels)\n\n    a, locs = self.setup_labels(x, like=\"${x:.1f}\")\n    labels = a.major.formatter.format_ticks(locs)\n    assert all(re.match(r\"^\\$\\d+\\.\\d$\", label) for label in labels)\n\n        return f\"[{x}]\"\n    a, locs = self.setup_labels(x, like=fmt)\n    labels = a.major.formatter.format_ticks(locs)\n    assert all(re.match(r\"^\\[\\d+\\]$\", label) for label in labels)\n"], "sample_4": ["    def test_headers(self):\n        response = HttpResponse()\n        response['Content-Type'] = 'text/plain'\n        self.assertEqual(response['Content-Type'], 'text/plain')\n        self.assertIn('Content-Type', response)\n        del response['Content-Type']\n        self.assertNotIn('Content-Type', response)\n", "    def test_http_response_default_charset(self):\n        response = HttpResponse()\n        self.assertEqual(response.charset, 'utf-8')\n", "    def test_http_response_can_be_pickled(self):\n        response = HttpResponse('Hello, world!')\n        self.assertEqual(response.content, b'Hello, world!')\n\n        # Pickle the response.\n        pickled_response = pickle.dumps(response)\n\n        # Unpickle the response.\n        unpickled_response = pickle.loads(pickled_response)\n\n        # The unpickled response should match the original response.\n        self.assertEqual(unpickled_response.content, b'Hello, world!')\n", "    def test_http_response___getitem__(self):\n        response = HttpResponse()\n        response['Content-Type'] = 'text/plain'\n        self.assertEqual(response['Content-Type'], 'text/plain')\n", "    def test_serialize_headers(self):\n        response = HttpResponse()\n        response['Content-Type'] = 'text/plain'\n        response['X-Custom-Header'] = 'Custom value'\n        self.assertEqual(response.serialize_headers(), b'Content-Type: text/plain\\r\\nX-Custom-Header: Custom value\\r\\n')\n"], "sample_66": ["    def test_raw_id_fields_must_be_a_list_or_tuple(self):\n        class RawIdFieldModelAdmin(ModelAdmin):\n            raw_id_fields = \"field1\"\n\n        self.assertIsInvalid(\n            RawIdFieldModelAdmin,\n            ValidationTestModel,\n            \"The value of 'raw_id_fields' must be a list or tuple.\",\n            id=\"admin.E001\",\n        )\n", "    def test_readonly_fields_item(self):\n        class ModelAdmin(ModelAdmin):\n            readonly_fields = (\"test\",)\n\n                return obj\n\n        self.assertIsValid(ModelAdmin, ValidationTestModel)\n\n        class ModelAdmin(ModelAdmin):\n            readonly_fields = (\"__str__\",)\n\n        self.assertIsValid(ModelAdmin, ValidationTestModel)\n\n        class ModelAdmin(ModelAdmin):\n            readonly_fields = (\"__unicode__\",)\n\n        self.assertIsValid(ModelAdmin, ValidationTestModel)\n\n        class ModelAdmin(ModelAdmin):\n            readonly_fields = (\"non_field\",)\n\n        self.assertIsInvalid(\n            ModelAdmin,\n            ValidationTestModel,\n            'The value of \\'readonly_fields[0]\\' is not a callable, an attribute of '\n            '\\'ModelAdmin\\', or an attribute of \\'%(app_label)s.%(object_name)s\\'.',\n            id='admin.E035'\n        )\n", "    def test_field_spec_ok(self):\n        class ModelAdminTest(ModelAdmin):\n            fields = (\"name\", \"genre\")\n\n        self.assertIsValid(ModelAdminTest, Band)\n", "    def test_raw_id_fields_valid(self):\n        class MyModelAdmin(ModelAdmin):\n            raw_id_fields = (\"id\",)\n\n        self.assertIsValid(MyModelAdmin, Band)\n", "    def test_fieldset_field_valid(self):\n        class ModelAdminTest(admin.ModelAdmin):\n            fieldsets = (\n                (\"General\", {\"fields\": (\"name\",)}),\n            )\n\n        self.assertIsValid(ModelAdminTest, ValidationTestModel)\n"], "sample_101": ["def test_pipeline_predict_params():\n    # Test that predict_params are passed to the final estimator\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    pipe = Pipeline([('transf', Transf()), ('clf', DummyEstimatorParams())])\n    pipe.fit(X, y)\n    pipe.predict(X, got_attribute=True)\n    assert pipe.named_steps['clf'].got_attribute\n", "def test_pipeline_memory():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n\n    # With caching\n    cachedir = mkdtemp()\n    try:\n        memory = Memory(cachedir, verbose=10)\n        pipeline = Pipeline([('transf', DummyTransf()), ('clf', SVC())],\n                            memory=memory)\n        # First fit should cache the results of 'transf'\n        first_fit_time = time.time()\n        pipeline.fit(X, y)\n        first_fit_time = time.time() - first_fit_time\n        # Second fit should be faster as 'transf' does not need to be recomputed\n        second_fit_time = time.time()\n        pipeline.fit(X, y)\n        second_fit_time = time.time() - second_fit_time\n        assert second_fit_time < first_fit_time\n\n        # Pipeline with memory should behave the same as without memory\n        pipeline_no_cache = Pipeline([('transf', DummyTransf()), ('clf', SVC())])\n        pipeline_no_cache_named_steps = dict(pipeline_no_cache.named_steps)\n        pipeline_named_steps = dict(pipeline.named_steps)\n\n        assert_array_equal(pipeline_no_cache_named_steps['transf'].means_,\n                           pipeline_named_steps['transf'].means_)\n    finally:\n        shutil.rmtree(cachedir)\n", "def test_pipeline_fit_params():\n    # Test that pipeline passes fit_params to the final estimator\n    # only when fit is called.\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    n_components = 1\n\n    pca = PCA(n_components=n_components)\n    fit_param_estimator = FitParamT()\n    pipe = make_pipeline(pca, fit_param_estimator)\n\n    pipe.fit(X, y, should_succeed=True)\n\n    assert fit_param_estimator.successful\n", "def test_pipeline_methods_available():\n    # Test that the pipeline methods are available when the last estimator\n    # implements them\n    pipeline = make_pipeline(StandardScaler(), LogisticRegression())\n    assert hasattr(pipeline, 'predict_proba')\n    assert hasattr(pipeline, 'decision_function')\n    assert not hasattr(pipeline, 'transform')\n\n    pipeline = make_pipeline(StandardScaler(), StandardScaler())\n    assert not hasattr(pipeline, 'predict_proba')\n    assert not hasattr(pipeline, 'decision_function')\n    assert hasattr(pipeline, 'transform')\n\n    pipeline = make_pipeline(LogisticRegression(), StandardScaler())\n    assert not hasattr(pipeline, 'predict_proba')\n    assert not hasattr(pipeline, 'decision_function')\n    assert hasattr(pipeline, 'transform')\n", "def test_pipeline_sliced_getitem():\n    # Test that Pipeline can be sliced using getitem with an int, list or slice.\n    # Also tests that sub-pipelines created by slicing are also instances of\n    # Pipeline.\n\n    pipeline = make_pipeline(PCA(n_components=2), StandardScaler(), LogisticRegression())\n    X = np.random.rand(10, 5)\n    y = np.random.randint(0, 2, size=10)\n\n    pipeline.fit(X, y)\n\n    assert isinstance(pipeline[0], PCA)\n    assert isinstance(pipeline[1], StandardScaler)\n    assert isinstance(pipeline[-1], LogisticRegression)\n\n    assert isinstance(pipeline[:1], Pipeline)\n    assert isinstance(pipeline[:2], Pipeline)\n    assert isinstance(pipeline[1:], Pipeline)\n    assert isinstance(pipeline[:-1], Pipeline)\n\n    with pytest.raises(TypeError):\n        pipeline['invalid']\n\n    with pytest.raises(ValueError):\n        pipeline[::2]\n\n    with pytest.raises(ValueError):\n        pipeline[::-1]\n"], "sample_37": ["    def test_q_combine(self):\n        q1 = Q(x=1)\n        q2 = Q(y=2)\n        combined = q1 & q2\n        self.assertEqual(combined.children, [q1, q2])\n        self.assertEqual(combined.connector, Q.AND)\n\n        q3 = Q(z=3)\n        combined = combined | q3\n        self.assertEqual(combined.children, [Q(x=1) & Q(y=2), q3])\n        self.assertEqual(combined.connector, Q.OR)\n", "    def test_Q(self):\n        q1 = Q(a=1)\n        q2 = Q(b=2)\n        q3 = Q(c=3)\n\n        self.assertEqual((q1 & q2) & q3, Q(a=1, b=2, c=3))\n        self.assertEqual(q1 & (q2 & q3), Q(a=1, b=2, c=3))\n\n        self.assertEqual((q1 | q2) | q3, Q(a=1) | Q(b=2) | Q(c=3))\n        self.assertEqual(q1 | (q2 | q3), Q(a=1) | Q(b=2) | Q(c=3))\n\n        self.assertEqual(~Q(a=1), ~Q(a=1))\n\n        self.assertEqual(Q(), Q())\n        self.assertEqual(Q() & Q(), Q())\n        self.assertEqual(Q() | Q(), Q())\n\n        self.assertEqual(Q(a=1) & Q(), Q(a=1))\n        self.assertEqual(Q(a=1) | Q(), Q(a=1))\n\n        self.assertEqual(Q() & Q(a=1), Q(a=1))\n        self.assertEqual(Q() | Q(a=1), Q(a=1))\n", "def test_deferred_attribute(self):\n    # Test that DeferredAttribute correctly retrieves and caches values.\n    company = self.example_inc\n    deferred_attr = DeferredAttribute(Company._meta.get_field('name'))\n    self.assertEqual(deferred_attr.__get__(company), 'Example Inc.')\n    # Check that the attribute is cached.\n    company.refresh_from_db()\n    self.assertEqual(deferred_attr.__get__(company), 'Example Inc.')\n    # Check that the cache is updated after a save.\n    company.name = 'New Name'\n    company.save()\n    self.assertEqual(deferred_attr.__get__(company), 'New Name')\n", "def test_q_clone(self):\n    q = Q(name='test') & Q(num_employees=10)\n    cloned_q = deepcopy(q)\n    self.assertEqual(q.children, cloned_q.children)\n    self.assertEqual(q.connector, cloned_q.connector)\n    self.assertEqual(q.negated, cloned_q.negated)\n", "def test_deferred_attribute(self):\n    company = Company.objects.create(name='Test Company', num_employees=10)\n    company_deferred = Company.objects.defer('num_employees').get(id=company.id)\n\n    with self.assertNumQueries(1):\n        self.assertIsNone(company_deferred.__dict__.get('num_employees'))\n        self.assertEqual(company_deferred.num_employees, 10)\n        self.assertEqual(company_deferred.__dict__['num_employees'], 10)\n"], "sample_104": ["def test_repr_max_elements_to_show():\n    # Test that the repr of an estimator with many parameters is truncated\n    class Estimator(BaseEstimator):\n            self.set_params(**kwargs)\n\n    estimator = Estimator(**{f\"param_{i}\": i for i in range(100)})\n    set_config(print_changed_only=False)\n    repr_ = _EstimatorPrettyPrinter(n_max_elements_to_show=10).pformat(estimator)\n    assert \"...\" in repr_\n    assert len(repr_.split(\",\")) == 11\n", "def test_n_max_elements_to_show():\n    # Test that the n_max_elements_to_show parameter works as expected\n    data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n    printer = _EstimatorPrettyPrinter(n_max_elements_to_show=5)\n    output = printer.pformat(data)\n    assert re.match(r\"\\[1, 2, 3, 4, 5, \\.\\.\\.\\]\", output)\n\n    printer = _EstimatorPrettyPrinter(n_max_elements_to_show=None)\n    output = printer.pformat(data)\n    assert re.match(r\"\\[1, 2, 3, 4, 5, 6, 7, 8, 9, 10\\]\", output)\n\n    data = {\"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4, \"e\": 5, \"f\": 6}\n    printer = _EstimatorPrettyPrinter(n_max_elements_to_show=5)\n    output = printer.pformat(data)\n    assert re.match(r\"{.*?}\", output) and len(re.findall(r\"[\\w']+: \\d+\", output)) == 5\n\n    printer = _EstimatorPrettyPrinter(n_max_elements_to_show=None)\n    output = printer.pformat(data)\n    assert re.match(r\"{.*?}\", output) and len(re.findall(r\"[\\w']+: \\d+\", output)) == 6\n", "def test_pprint_n_max_elements_to_show():\n    # Test that the `n_max_elements_to_show` parameter works as expected\n    data = np.array([1, 2, 3, 4, 5])\n    estimator = LogisticRegression()\n\n    # Set n_max_elements_to_show to a small value\n    set_config(print_changed_only=True)\n    printer = _EstimatorPrettyPrinter(n_max_elements_to_show=2)\n\n    # Create a SelectKBest estimator with many features\n    selector = SelectKBest(chi2, k=5)\n    selector.fit(data.reshape(-1, 1), data)\n\n    # Assert the repr is short and has an ellipsis\n    repr_ = printer.pformat(selector)\n    assert len(repr_) < 200\n    assert '...' in repr_\n\n    # Reset print_changed_only to False\n    set_config(print_changed_only=False)\n", "def test_long_dict_repr():\n    data = {'key_{}'.format(i): i for i in range(1000)}\n    expected = r\"{.*?\\.\\.\\.}\"\n    repr_ = _EstimatorPrettyPrinter(n_max_elements_to_show=10).pformat(data)\n    assert re.match(expected, repr_)\n", "def test_pprint_estimator_with_n_max_elements_to_show():\n    # Test that the n_max_elements_to_show parameter works with estimators.\n    data = np.array([[1, 2], [3, 4]])\n    estimator = RFE(estimator=SVC(), n_features_to_select=1)\n    estimator.estimator.max_iter = 1000\n    estimator.estimator.class_weight = {0: 1, 1: 2}\n    pprinter = _EstimatorPrettyPrinter(n_max_elements_to_show=2)\n    output = pprinter.pformat(estimator)\n    assert \"max_iter=...\" in output\n    assert \"class_weight={...}\" in output\n"], "sample_156": ["def test_MathematicaParser_convert_function():\n    parser = MathematicaParser()\n    assert parser._convert_function('Sin[x]') == 'sin(x)'\n    assert parser._convert_function('2*Sin[x]') == '2*sin(x)'\n    assert parser._convert_function('x*Sin[x]') == 'x*sin(x)'\n    assert parser._convert_function('Sin[2*x]') == 'sin(2*x)'\n    assert parser._convert_function('Sin[x]*Cos[x]') == 'sin(x)*cos(x)'\n    raises(ValueError, lambda: parser._convert_function('InvalidFunction[x]'))\n", "def test_parse_mathematica_Function():\n    # Test that Function nodes are parsed correctly.\n    expr = \"f[x, y]\"\n    result = parse_mathematica(expr)\n    assert result == Function(\"f\")(x, y)\n\n    expr = \"f[x_, y_]\"\n    result = parse_mathematica(expr)\n    x_, y_ = symbols('x_ y_', cls=Dummy)\n    assert result == Lambda((x_, y_), Function(\"f\")(x_, y_))\n\n    expr = \"# + #2 &[x, y]\"\n    result = parse_mathematica(expr)\n    assert result == Lambda((x, y), x + y)(x, y)\n", "def test_function_with_variable_length_argument():\n    mparser = MathematicaParser()\n    assert mparser._from_fullformlist_to_sympy([\"f\", [\"x\", \"y\"]]) == Function(\"f\")(x, y)\n    expr = mparser.parse(\"f[x__]\")\n    assert expr == Function(\"f\")(*symbols(\"x:\"))\n    expr = mparser.parse(\"f[x___]\")\n    assert expr == Function(\"f\")(*symbols(\"x:\"))\n    expr = mparser.parse(\"f[x_, y__]\")\n    assert expr == Function(\"f\")(x, *symbols(\"y:\"))\n    expr = mparser.parse(\"f[x_, y___]\")\n    assert expr == Function(\"f\")(x, *symbols(\"y:\"))\n    expr = mparser.parse(\"f[x__, y_]\")\n    assert expr == Function(\"f\")(*symbols(\"x:\"), y)\n    expr = mparser.parse(\"f[x___, y_]\")\n    assert expr == Function(\"f\")(*symbols(\"x:\"), y)\n", "def test_mathematica_parser():\n    # Test that MathematicaParser can handle expressions with whitespace\n    assert parse_mathematica(\"Sin [ x ]\") == sin(x)\n    assert parse_mathematica(\"x + y\") == x + y\n\n    # Test that MathematicaParser can handle prefix and postfix operators\n    assert parse_mathematica(\"! x\") == Function('Not')(x)\n    assert parse_mathematica(\"x !\") == x * Function('Factorial')()\n\n    # Test that MathematicaParser can handle infix operators\n    assert parse_mathematica(\"x + y\") == x + y\n    assert parse_mathematica(\"x - y\") == x - y\n    assert parse_mathematica(\"x * y\") == x * y\n    assert parse_mathematica(\"x / y\") == x / y\n\n    # Test that MathematicaParser can handle functions\n    assert parse_mathematica(\"Sin[x]\") == sin(x)\n    assert parse_mathematica(\"f[x, y]\") == Function('f')(x, y)\n\n    # Test that MathematicaParser can handle nested expressions\n    assert parse_mathematica(\"Sin[Cos[x]]\") == sin(cos(x))\n    assert parse_mathematica(\"x + Sin[y] - Cos[z]\") == x + sin(y) - cos(z)\n\n    # Test that MathematicaParser can handle symbols\n    assert parse_mathematica(\"Pi\") == sympify('pi')\n    assert parse_mathematica(\"E\") == sympify('E')\n\n    # Test that MathematicaParser can handle user-defined symbols\n    assert parse_mathematica(\"mySymbol\") == symbols('mySymbol')\n\n    # Test that MathematicaParser can handle lambda functions\n    assert parse_mathematica(\"# &\") == Lambda(Dummy('x'), Dummy('x'))\n    assert parse_mathematica(\"#1 &\") == Lambda(Dummy('x'), Dummy('x'))\n    assert parse_mathematica(\"#1^2 &\") == Lambda(Dummy('x'), Dummy('x')**2)\n", "def test_mathematica_parser_Prefix():\n    # Test Prefix operators\n    assert parse_mathematica(\"!x\") == Function(\"Not\")(x)\n    assert parse_mathematica(\"+x\") == x\n    assert parse_mathematica(\"-x\") == -x\n    assert parse_mathematica(\"#\") == Function(\"Slot\")(\"1\")\n    assert parse_mathematica(\"##\") == Function(\"SlotSequence\")(\"1\")\n"], "sample_30": ["def test_get_inline_instances(self):\n    request = self.factory.get('/admin/holder/add/')\n    request.user = self.superuser\n    admin = ModelAdmin(Holder, admin_site)\n    admin.inlines = [InnerInline]\n    inline_instances = admin.get_inline_instances(request)\n    self.assertEqual(len(inline_instances), 1)\n    self.assertIsInstance(inline_instances[0], InnerInline)\n", "def test_inline_model_admin_get_queryset(self):\n    request = self.factory.get(reverse('admin:admin_inlines_holder_change', args=(self.holder.pk,)))\n    request.user = self.superuser\n    inline = InnerInline(self.model, admin_site)\n    queryset = inline.get_queryset(request)\n    self.assertQuerysetEqual(queryset, Inner.objects.all())\n    # Test that the queryset is empty when the user doesn't have view or change permission.\n    request.user.is_superuser = False\n    request.user.save()\n    queryset = inline.get_queryset(request)\n    self.assertQuerysetEqual(queryset, Inner.objects.none())\n", "def test_inline_get_queryset(self):\n    request = self.factory.get('/admin/holder/1/change/')\n    request.user = self.superuser\n    inline = InnerInline(self.model, admin_site)\n    queryset = inline.get_queryset(request)\n    self.assertEqual(queryset.count(), 1)\n    self.assertEqual(queryset[0].dummy, 42)\n", "def test_get_formset_kwargs(self):\n    request = self.factory.get('/admin/holder/add/')\n    request.user = self.superuser\n    inline = InnerInline(admin_site, Holder)\n    obj = Holder()\n    prefix = 'inner-set'\n    kwargs = inline.get_formset_kwargs(request, obj, inline, prefix)\n    self.assertEqual(kwargs['instance'], obj)\n    self.assertEqual(kwargs['prefix'], prefix)\n    self.assertEqual(kwargs['queryset'], Inner.objects.none())\n", "def test_inline_change_permission(self):\n    request = self.factory.get('/admin/holder/1/change')\n    request.user = self.superuser\n    inline = InnerInline(Holder, admin_site)\n    self.assertTrue(inline.has_change_permission(request))\n    self.superuser.is_superuser = False\n    self.superuser.save()\n    self.assertFalse(inline.has_change_permission(request))\n    content_type = ContentType.objects.get_for_model(Inner)\n    permission = Permission.objects.get(codename='change_inner', content_type=content_type)\n    self.superuser.user_permissions.add(permission)\n    self.assertTrue(inline.has_change_permission(request))\n"], "sample_132": ["def test_convex_hull():\n    p1 = Point2D(0, 0)\n    p2 = Point2D(1, 0)\n    p3 = Point2D(1, 1)\n    p4 = Point2D(0, 1)\n\n    # Test convex hull of a single point\n    assert convex_hull(p1) == p1\n\n    # Test convex hull of two points\n    assert convex_hull(p1, p2) == Segment(p1, p2)\n\n    # Test convex hull of multiple collinear points\n    assert convex_hull(p1, p2, Point2D(2, 0)) == Segment(p1, Point2D(2, 0))\n\n    # Test convex hull of four points forming a square\n    assert convex_hull(p1, p2, p3, p4) == Polygon(p1, p2, p3, p4)\n\n    # Test convex hull of multiple points in random order\n    points = [p1, p3, p2, p4]\n    assert convex_hull(*points) == Polygon(p1, p2, p3, p4)\n", "def test_idiff():\n    x = Symbol('x')\n    y = Symbol('y')\n    eq = x**2 + y**2 - 4\n    assert idiff(eq, y, x) == -x/y\n    assert idiff(eq, y, x, 2).simplify() == -(x**2 + y**2)/y**3\n    a = Symbol('a')\n    eq = x + a + y\n    assert idiff(eq, y, x) == -1\n    assert idiff(eq, [y, a], x) == -Derivative(a, x) - 1\n", "def test_convex_hull():\n    p1 = Point2D(0, 0)\n    p2 = Point2D(1, 1)\n    p3 = Point2D(1, 0)\n    p4 = Point2D(0, 1)\n    p5 = Point2D(-1, -1)\n    p6 = Point2D(-1, 0)\n    p7 = Point2D(0, -1)\n\n    assert convex_hull(p1, p2, p3, p4) == Polygon(p1, p3, p2, p4)\n    assert convex_hull(p1, p2, p3, p5) == Polygon(p1, p3, p2, p5)\n    assert convex_hull(p1, p2, p4, p5) == Polygon(p5, p1, p2, p4)\n    assert convex_hull(p1, p3, p5, p6) == Polygon(p5, p6, p1, p3)\n    assert convex_hull(p1, p4, p5, p7) == Polygon(p5, p7, p1, p4)\n", "def test_convex_hull():\n    p1 = Point(0, 0)\n    p2 = Point(1, 1)\n    p3 = Point(1, 0)\n    p4 = Point(0, 1)\n    p5 = Point(-1, 2)\n    p6 = Point(-2, 2)\n\n    assert convex_hull(p1, p2, p3, p4) == Polygon(p1, p3, p2, p4)\n    assert convex_hull(p1, p2, p3, p5) == Polygon(p1, p3, p2, p5)\n    assert convex_hull(p1, p2, p5, p6) == Polygon(p1, p2, p5, p6)\n    assert convex_hull(p1, p3, p5, p6) == Polygon(p1, p3, p5, p6)\n    assert convex_hull(p1, p1, p1) == p1\n    assert convex_hull(p1, p2) == Segment(p1, p2)\n", "def test_convex_hull():\n    p1 = Point2D(0, 0)\n    p2 = Point2D(1, 0)\n    p3 = Point2D(1, 1)\n    p4 = Point2D(0, 1)\n    p5 = Point2D(-1, -1)\n\n    assert convex_hull(p1, p2, p3, p4) == Polygon(p1, p2, p3, p4)\n    assert convex_hull(p1, p2, p3, p4, p5) == Polygon(p1, p2, p3, p4, p5)\n\n    s1 = Segment(p1, p2)\n    s2 = Segment(p2, p3)\n    s3 = Segment(p3, p4)\n    s4 = Segment(p4, p1)\n\n    assert convex_hull(s1, s2, s3, s4) == Polygon(p1, p2, p3, p4)\n"], "sample_48": ["    def test_create_model(self):\n        operation = migrations.CreateModel(\n            name=\"Pony\",\n            fields=[\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"pink\", models.IntegerField(default=1)),\n            ],\n        )\n        self.apply_operations([operation])\n        project_state = self.set_up_test_model(\"testapp\", \"Pony\")\n        self.assertModelExists(\"testapp\", \"Pony\")\n        model = project_state.apps.get_model(\"testapp\", \"Pony\")\n        self.assertEqual(model._meta.get_field(\"pink\").default, 1)\n", "    def test_create_model(self):\n        operation = migrations.CreateModel(\n            name='Pony',\n            fields=[\n                ('id', models.AutoField(primary_key=True)),\n                ('pink', models.IntegerField()),\n            ],\n        )\n        # Test the state alteration\n        project_state = ProjectState()\n        new_state = project_state.clone()\n        operation.state_forwards('tests', new_state)\n        self.assertEqual(len(new_state.models['tests', 'pony'].fields), 2)\n        # Test the database alteration\n        self.apply_operations('tests', project_state, [operation])\n        self.assertTableExists('tests_pony')\n        with connection.schema_editor() as schema_editor:\n            schema_editor.add_field(\n                ModelState('tests', 'Pony', [\n                    ('id', models.AutoField(primary_key=True)),\n                    ('pink', models.IntegerField()),\n                ]),\n                models.IntegerField(null=True),\n                ' tests_pony',\n            )\n        self.assertColumnExists('tests_pony', 'pink')\n        # And test reversal\n        self.unapply_operations('tests', project_state, [operation])\n        self.assertTableNotExists('tests_pony')\n", "    def test_create_model(self):\n        operation = migrations.CreateModel(\n            \"TestModel\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=255)),\n            ],\n        )\n        # Test state changing\n        project_state = ProjectState()\n        new_state = project_state.clone()\n        operation.state_forwards(\"testapp\", new_state)\n        self.assertEqual(len(new_state.models), 1)\n        model_state = list(new_state.models.values())[0]\n        self.assertEqual(model_state.name, \"TestModel\")\n        self.assertEqual(len(model_state.fields), 2)\n        # Test database creation\n        with connection.schema_editor() as schema_editor:\n            operation.database_forwards(\"testapp\", schema_editor, project_state, new_state)\n            table_description = connection.introspection.get_table_description(connection.cursor(), \"testapp_testmodel\")\n            self.assertEqual(len(table_description), 2)\n        # Test database revert\n        with connection.schema_editor() as schema_editor:\n            operation.database_backwards(\"testapp\", schema_editor, new_state, project_state)\n            self.assertFalse(connection.introspection.table_name_exists(\"testapp_testmodel\"))\n", "    def test_create_model(self):\n        operation = migrations.CreateModel(\n            name='TestModel',\n            fields=[\n                ('id', models.AutoField(primary_key=True)),\n                ('name', models.CharField(max_length=100)),\n            ],\n        )\n        self.apply_operations(operation)\n        model = self.apps.get_model('testapp', 'TestModel')\n        self.assertEqual(model._meta.db_table, 'testapp_testmodel')\n        self.assertEqual(model._meta.get_field('name').max_length, 100)\n\n        # Test database table creation\n        with connection.cursor() as cursor:\n            cursor.execute(\"SELECT * FROM testapp_testmodel\")\n            columns = [desc[0] for desc in cursor.description]\n            self.assertEqual(columns, ['id', 'name'])\n", "    def test_create_model(self):\n        operation = migrations.CreateModel(\n            name='TestModel',\n            fields=[\n                ('id', models.AutoField(primary_key=True)),\n                ('name', models.CharField(max_length=20)),\n            ],\n        )\n        # Test state changing\n        project_state = ProjectState()\n        new_state = project_state.clone()\n        operation.state_forwards('testapp', new_state)\n        self.assertEqual(len(new_state.models), 1)\n        model_state = new_state.models['testapp', 'testmodel']\n        self.assertEqual(model_state.name, 'TestModel')\n        self.assertEqual(len(model_state.fields), 2)\n        # Test database creation\n        with connection.schema_editor() as schema_editor:\n            operation.database_forwards('testapp', schema_editor, project_state, new_state)\n        # Test the table exists\n        with connection.cursor() as cursor:\n            cursor.execute(\"SELECT COUNT(*) FROM testapp_testmodel\")\n            self.assertEqual(cursor.fetchone()[0], 0)\n        # And test reversal\n        with connection.schema_editor() as schema_editor:\n            operation.database_backwards('testapp', schema_editor, new_state, project_state)\n        # Make sure the table is gone\n        with connection.cursor() as cursor:\n            with self.assertRaises(connection.DatabaseError):\n                cursor.execute(\"SELECT COUNT(*) FROM testapp_testmodel\")\n"], "sample_124": ["def test_hyperbolic_inverse():\n    x = symbols('x')\n    assert asinh(sinh(x)) == x\n    assert acosh(cosh(x)) == x\n    assert atanh(tanh(x)) == x\n    assert acoth(coth(x)) == x\n    assert asech(sech(x)) == x\n    assert acsch(csch(x)) == x\n", "def test_hyperbolic_rewrites():\n    x = Symbol('x')\n\n    assert sinh(x).rewrite(exp) == (exp(x) - exp(-x))/2\n    assert cosh(x).rewrite(exp) == (exp(x) + exp(-x))/2\n    assert tanh(x).rewrite(exp) == (exp(x) - exp(-x))/(exp(x) + exp(-x))\n    assert coth(x).rewrite(exp) == (exp(x) + exp(-x))/(exp(x) - exp(-x))\n\n    assert asinh(x).rewrite(log) == log(x + sqrt(x**2 + 1))\n    assert acosh(x).rewrite(log) == log(x + sqrt(x + 1)*sqrt(x - 1))\n    assert atanh(x).rewrite(log) == (log(1 + x) - log(1 - x))/2\n    assert acoth(x).rewrite(log) == (log(1 + 1/x) - log(1 - 1/x))/2\n\n    assert sech(x).rewrite(exp) == 2/(exp(x) + exp(-x))\n    assert csch(x).rewrite(exp) == 2/(exp(x) - exp(-x))\n    assert asech(x).rewrite(log) == log(1/x + sqrt(1/x - 1)*sqrt(1/x + 1))\n    assert acsch(x).rewrite(log) == log(1/x + sqrt(1/x**2 + 1))\n", "def test_hyperbolic_rewrite():\n    x = Symbol('x')\n\n    # Test rewrite of sinh/cosh in terms of exp\n    assert sinh(x).rewrite(exp) == (exp(x) - exp(-x))/2\n    assert cosh(x).rewrite(exp) == (exp(x) + exp(-x))/2\n\n    # Test rewrite of tanh/coth in terms of exp\n    assert tanh(x).rewrite(exp) == (exp(2*x) - 1)/(exp(2*x) + 1)\n    assert coth(x).rewrite(exp) == (exp(2*x) + 1)/(exp(2*x) - 1)\n\n    # Test rewrite of sech/csch in terms of exp\n    assert sech(x).rewrite(exp) == 2/(exp(x) + exp(-x))\n    assert csch(x).rewrite(exp) == 2/(exp(x) - exp(-x))\n\n    # Test rewrite of asinh/acosh in terms of log\n    assert asinh(x).rewrite(log) == log(x + sqrt(x**2 + 1))\n    assert acosh(x).rewrite(log) == log(x + sqrt(x**2 - 1))\n\n    # Test rewrite of atanh/acoth in terms of log\n    assert atanh(x).rewrite(log) == log((1 + x)/(1 - x))/2\n    assert acoth(x).rewrite(log) == log((x + 1)/(x - 1))/2\n\n    # Test rewrite of asech/acsch in terms of log\n    assert asech(x).rewrite(log) == log((1 + sqrt(1 - x**2))/x)\n    assert acsch(x).rewrite(log) == log((1 + sqrt(1 + x**2))/x)\n", "def test_hyperbolic_branching():\n    x = Symbol('x')\n    assert sinh(x).inverse() == asinh\n    assert cosh(x).inverse() is None\n    assert tanh(x).inverse() == atanh\n    assert coth(x).inverse() == acoth\n    assert sech(x).inverse() == asech\n    assert csch(x).inverse() == acsch\n", "def test_issue_13324():\n    x = Symbol('x')\n    assert sinh(x).as_real_imag(deep=True) == (sinh(x), 0)\n    assert cosh(x).as_real_imag(deep=True) == (cosh(x), 0)\n    assert tanh(x).as_real_imag(deep=True) == (tanh(x), 0)\n    assert coth(x).as_real_imag(deep=True) == (coth(x), 0)\n    assert sech(x).as_real_imag(deep=True) == (sech(x), 0)\n    assert csch(x).as_real_imag(deep=True) == (csch(x), 0)\n"], "sample_0": ["def test_autocomplete_select_widget_render(self):\n    form = AlbumForm()\n    band_field = form.fields['band']\n    widget = band_field.widget\n    html = widget.render('band', None)\n    self.assertHTMLEqual(\n        html,\n        '<select class=\"my-class\" name=\"band\"></select>',\n    )\n", "def test_multiwidget_render(self):\n    class TestForm(forms.Form):\n        field = forms.SplitDateTimeField(widget=SplitDateTimeWidget)\n\n    form = TestForm()\n    output = form.as_p()\n    self.assertHTMLEqual(output, '<p>Field:<input type=\"text\" name=\"field_0\" /><input type=\"text\" name=\"field_1\" /></p>')\n", "def test_autocomplete_select_widget_required(self):\n    form = RequiredBandForm()\n    self.assertHTMLEqual(\n        form.as_p(),\n        '<p>Band: <select class=\"my-class\" data-ajax--delay=\"250\" data-ajax--type=\"GET\" '\n        'data-ajax--cache=\"true\" data-ajax--url=\"/autocomplete/?q=%7B%7D\" '\n        'name=\"band\" required><option value=\"\" selected></option>\\n'\n        '<option value=\"1\">Album1</option>\\n<option value=\"2\">Album2</option>\\n'\n        '</select></p>',\n    )\n    form = NotRequiredBandForm()\n    self.assertHTMLEqual(\n        form.as_p(),\n        '<p>Band: <select class=\"my-class\" data-ajax--delay=\"250\" data-ajax--type=\"GET\" '\n        'data-ajax--cache=\"true\" data-ajax--url=\"/autocomplete/?q=%7B%7D\" '\n        'name=\"band\"><option value=\"\" selected></option>\\n'\n        '<option value=\"1\">Album1</option>\\n<option value=\"2\">Album2</option>\\n'\n        '</select></p>',\n    )\n", "def test_select_date_widget(self):\n    widget = forms.SelectDateWidget()\n    self.check_html(widget, 'date', '')\n    self.assertEqual(\n        widget.value_from_datadict({'date_year': '2017', 'date_month': '12', 'date_day': '25'}, {}, 'date'),\n        '2017-12-25',\n    )\n    self.assertEqual(\n        widget.value_from_datadict({'date_year': '', 'date_month': '', 'date_day': ''}, {}, 'date'),\n        None,\n    )\n    self.assertEqual(widget.format_value('2017-12-25'), {'year': 2017, 'month': 12, 'day': 25})\n    self.assertEqual(widget.format_value(None), {'year': None, 'month': None, 'day': None})\n", "    def test_split_datetime_widget_render(self):\n        widget = SplitDateTimeWidget()\n        self.check_html(widget, 'datetime', '2017-12-01 14:30:00', html=(\n            '<input type=\"text\" name=\"datetime_0\" value=\"2017-12-01\">'\n            '<input type=\"text\" name=\"datetime_1\" value=\"14:30:00\">'\n        ))\n"], "sample_129": ["def test_latex_trig():\n    x = symbols('x')\n    assert latex(sin(x)) == r\"\\sin{\\left(x \\right)}\"\n    assert latex(cos(x)) == r\"\\cos{\\left(x \\right)}\"\n    assert latex(tan(x)) == r\"\\tan{\\left(x \\right)}\"\n    assert latex(cot(x)) == r\"\\cot{\\left(x \\right)}\"\n    assert latex(atan(x)) == r\"\\operatorname{atan}{\\left(x \\right)}\"\n    assert latex(acot(x)) == r\"\\operatorname{acot}{\\left(x \\right)}\"\n    assert latex(asin(x)) == r\"\\operatorname{asin}{\\left(x \\right)}\"\n    assert latex(acos(x)) == r\"\\operatorname{acos}{\\left(x \\right)}\"\n    assert latex(asec(x)) == r\"\\operatorname{asec}{\\left(x \\right)}\"\n    assert latex(acsc(x)) == r\"\\operatorname{acsc}{\\left(x \\right)}\"\n    assert latex(sinh(x)) == r\"\\sinh{\\left(x \\right)}\"\n    assert latex(cosh(x)) == r\"\\cosh{\\left(x \\right)}\"\n    assert latex(tanh(x)) == r\"\\tanh{\\left(x \\right)}\"\n    assert latex(coth(x)) == r\"\\coth{\\left(x \\right)}\"\n    assert latex(sech(x)) == r\"\\operatorname{sech}{\\left(x \\right)}\"\n    assert latex(csch(x)) == r\"\\operatorname{csch}{\\left(x \\right)}\"\n", "def test_latex_setexpr():\n    A = SetExpr(Interval(0, 1))\n    assert latex(A) == r\"\\left[0, 1\\right]\"\n    B = SetExpr(S.Reals)\n    assert latex(B) == r\"\\mathbb{R}\"\n", "def test_LatexPrinter_settings():\n    # Test if latex() works properly when some global settings are changed.\n\n    # TODO: This test is not very comprehensive and needs to be improved.\n\n    # Save the default settings\n    default_settings = dict(LatexPrinter._default_settings)\n\n    # Change some settings\n    LatexPrinter._default_settings['order'] = 'none'\n    LatexPrinter._default_settings['mode'] = 'inline'\n\n    # Create an expression and make sure it's latex'd properly\n    expr = x**2\n    assert latex(expr) == '$x^{2}$'\n\n    # Restore the default settings\n    LatexPrinter._default_settings = default_settings\n\n    # Make sure the default settings are still working properly\n    assert latex(expr) == 'x^{2}'\n\n    # Change some other settings\n    LatexPrinter._default_settings['fold_func_brackets'] = True\n\n    # Test the latex output with those settings\n    assert latex(expr) == 'x^{2}'\n\n    LatexPrinter._default_settings['inv_trig_style'] = 'full'\n\n    assert latex(asin(x)) == r'\\arcsin{\\left (x \\right )}'\n\n    LatexPrinter._default_settings['inv_trig_style'] = 'power'\n\n    assert latex(asin(x)) == r'\\sin^{-1}{\\left (x \\right )}'\n\n    # Restore the default settings\n    LatexPrinter._default_settings = default_settings\n\n    # Make sure the default settings are still working properly\n    assert latex(expr) == 'x^{2}'\n", "def test_latex_matrix():\n    M = Matrix([[1, 2], [3, 4]])\n    assert latex(M) == r\"\\left[\\begin{matrix}1 & 2\\\\3 & 4\\end{matrix}\\right]\"\n    assert latex(M, mat_str=\"array\") == r\"\\left[\\begin{array}{cc}1 & 2\\\\3 & 4\\end{array}\\right]\"\n    assert latex(M, mat_str=\"bmatrix\") == r\"\\left[\\begin{bmatrix}1 & 2\\\\3 & 4\\end{bmatrix}\\right]\"\n    assert latex(M, mat_delim=\"(\") == r\"\\left(\\begin{matrix}1 & 2\\\\3 & 4\\end{matrix}\\right)\"\n    assert latex(M, mat_delim=\"\") == r\"\\left\\begin{matrix}1 & 2\\\\3 & 4\\end{matrix}\\right\"\n", "def test_lerchphi():\n    assert latex(lerchphi(x, y, z)) == r'\\left(x, y, z\\right)'\n    assert latex(lerchphi(x, y, z, 1)) == r'\\left(x, y, z\\right)'\n"], "sample_145": ["def test_LatexPrinter_settings():\n    # Issue #11722\n    p = LatexPrinter({'decimal_separator': 'comma'})\n    assert p._print(1.5) == '1{,}5'\n\n    p = LatexPrinter({'decimal_separator': 'period'})\n    assert p._print(1.5) == '1.5'\n\n    # issue #12886\n    p = LatexPrinter({'parenthesize_super': False})\n    assert p._print(Pow(Symbol('x'), 2)) == r'x^{2}'\n\n    p = LatexPrinter({'parenthesize_super': True})\n    assert p._print(Pow(Symbol('x'), 2)) == r'{\\left(x \\right)}^{2}'\n\n    p = LatexPrinter({'parenthesize_super': True})\n    assert p._print(Derivative(sqrt(sqrt(x)) / sqrt(x), x)) == \\\n        r'\\frac{d}{d x} \\left(\\frac{\\sqrt[4]{x}}{\\sqrt{x}}\\right)'\n", "def test_LatexPrinter_settings():\n    # issue 15274\n    lp = LatexPrinter({'full_prec': 'auto'})\n    assert lp._settings['full_prec'] == 'auto'\n", "def test_LatexPrinter_settings():\n    x = Symbol('x')\n    lp = LatexPrinter()\n    assert lp._print(x) == lp._print(x, None, 18)\n    lp_order = LatexPrinter({'order': 'lex'})\n    assert lp._print(x + x**2) == lp_order._print(x + x**2)\n    lp_long_frac_ratio = LatexPrinter({'long_frac_ratio': 3})\n    assert lp._print(1/x) == lp_long_frac_ratio._print(1/x)\n    lp_inv_trig_style = LatexPrinter({'inv_trig_style': 'full'})\n    assert lp._print(asin(x)) == lp_inv_trig_style._print(asin(x))\n    lp_mat_delim = LatexPrinter({'mat_delim': '('})\n    assert lp._print(Matrix([[1, 2], [3, 4]])) == lp_mat_delim._print(Matrix([[1, 2], [3, 4]]))\n    lp_mat_str = LatexPrinter({'mat_str': 'array'})\n    assert lp._print(Matrix([[1, 2], [3, 4]])) == lp_mat_str._print(Matrix([[1, 2], [3, 4]]))\n", "def test_LatexPrinter_settings():\n    # issue 11723\n    x = Symbol('x')\n    lp = LatexPrinter({'decimal_separator': 'period'})\n    assert lp.doprint(1.5) == \"1.5\"\n    lp = LatexPrinter({'decimal_separator': 'comma'})\n    assert lp.doprint(1.5) == \"1{,}5\"\n    lp = LatexPrinter({'decimal_separator': 'period'})\n    assert lp.doprint([1, 2, 3]) == r\"\\left[ 1, \\  2, \\  3\\right]\"\n    lp = LatexPrinter({'decimal_separator': 'comma'})\n    assert lp.doprint([1, 2, 3]) == r\"\\left[ 1; \\  2; \\  3\\right]\"\n", "def test_latex_tensor_indices():\n    a = ArraySymbol('a', shape=(3,))\n    i = Symbol('i')\n    assert latex(a[i]) == r\"{a}_{i}\"\n    assert latex(a[i].as_base_exp_dict()) == r\"{a}^{\\left({i}\\right)}\"\n    assert latex(a[i].as_exp_base_dict()) == r\"{a}_{i}\"\n\n    assert latex(a[a[i]]) == r\"{a}_{{{a}_{i}}}\"\n    assert latex(a[a[i]].as_base_exp_dict()) == r\"{a}^{\\left({{a}_{i}}\\right)}\"\n    assert latex(a[a[i]].as_exp_base_dict()) == r\"{a}_{{{a}_{i}}}\"\n\n    assert latex(a[a[a][i]]) == r\"{a}_{{{a}_{{a}^{i}}}}\"\n    assert latex(a[a[a][i]].as_base_exp_dict()) == r\"{a}^{\\left({{a}_{{a}^{i}}}\\right)}\"\n    assert latex(a[a[a][i]].as_exp_base_dict()) == r\"{a}_{{{a}_{{a}^{i}}}}\"\n\n    assert latex(a[x]) == r\"{a}_{x}\"\n    assert latex(a[x].as_base_exp_dict()) == r\"{a}^{\\left({x}\\right)}\"\n    assert latex(a[x].as_exp_base_dict()) == r\"{a}_{x}\"\n\n    assert latex(a[a[x]]) == r\"{a}_{{{a}_{x}}}\"\n    assert latex(a[a[x]].as_base_exp_dict()) == r\"{a}^{\\left({{a}_{x}}\\right)}\"\n    assert latex(a[a[x]].as_exp_base_dict()) == r\"{a}_{{{a}_{x}}}\"\n\n    assert latex(a[a[a][x]]) == r\"{a}_{{{a}_{{a}^{x}}}}\"\n    assert latex(a[a[a][x]].as_base_exp_dict()) == r\"{a}^{\\left({{a}_{{a}^{x}}}\\right)}\"\n    assert latex(a[a[a][x]].as_exp_base_dict()) == r\"{a}_{{{a}_{{a}^{x}}}}\"\n"], "sample_53": ["def test_autodetector_indexes(self):\n    \"\"\"\n    Test the autodetector correctly detects and orders indexes.\n    \"\"\"\n    changes = self.get_changes([self.book], [self.book_indexes])\n    # Right number of migrations\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    # Right number of AddIndex operations\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AddIndex\"])\n    # Options are correct\n    self.assertOperationAttributes(\n        changes, \"otherapp\", 0, 0, model_name=\"book\", name=\"book_title_author_idx\"\n    )\n    # Field names are correct\n    self.assertOperationAttributes(\n        changes, \"otherapp\", 0, 0, fields=[\"author\", \"title\"]\n    )\n", "def test_altered_foo_together_unique(self):\n    before = self.make_project_state(\n        [\n            self.author_name,\n            self.book_foo_together,\n        ]\n    )\n    after = self.make_project_state(\n        [\n            self.author_name,\n            self.book_foo_together_2,\n        ]\n    )\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\"])\n    self.assertOperationAttributes(\n        changes, \"otherapp\", 0, 0, unique_together={(\"title\", \"author\")}\n    )\n", "def test_operation_dependencies(self):\n    \"\"\"Tests that operations can correctly calculate their dependencies.\"\"\"\n    # Create an autodetector and get the changes\n    autodetector = MigrationAutodetector(\n        self.make_project_state([self.author_name, self.book]),\n        self.make_project_state([self.author_name, self.book_with_multiple_authors]),\n    )\n    changes = autodetector._detect_changes()\n    # Add a dependency on the latest migration\n    migration = changes[\"testapp\"][-1]\n    migration.dependencies.append((\"testapp\", \"0002\"))\n    # Now call _build_migration_list again\n    changes = autodetector.arrange_for_graph(\n        changes, MigrationGraph(), \"0001_squashed_0002\"\n    )\n    # Make sure the dependency is still there\n    self MigrationDependencies(changes, \"testapp\", 0, [(\"testapp\", \"0002\")])\n", "def test_create_table_inheritance_parent_before_child(self):\n    \"\"\"\n    Table inheritance order should be: parent created before child.\n    \"\"\"\n    model_state = ModelState(\n        \"testapp\",\n        \"Book\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n        ],\n        bases=(\"testapp.Author\",),\n    )\n    changes = self.get_changes([self.author_name], [self.author_name, model_state])\n    # There should be CreateModel first for Author and then CreateModel\n    # for Book.\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\", \"CreateModel\"])\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, name=\"Author\", options={}\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 1, name=\"Book\", options={}, bases=(\"testapp.Author\",)\n    )\n", "compilation error"], "sample_123": ["def test_rational_new():\n    r = Rational(1, 2)\n    assert r.p == 1\n    assert r.q == 2\n    assert r == Rational(1, 2)\n\n    r = Rational(2)\n    assert r.p == 2\n    assert r.q == 1\n\n    r = Rational(0, 10)\n    assert r.p == 0\n    assert r.q == 1\n\n    r = Rational(1, 0)\n    assert r.is_Infinity\n", "def test_Float_mpf_norm():\n    assert Float._new(mpf_norm((1, 3, 0, 4), 10), 10) == Float._new((1, 3, 0, 4), 10)\n    assert mpf_norm((1, 0, 0, 5), 10) == (0, 0, 0, 0)\n    assert mpf_norm((1, 0, 0, 0), 10) == (0, 0, 0, 0)\n    assert Float._new(mpf_norm((1, 1, 0, 2), 5), 5) == Float._new((1, 1, 0, 2), 5)\n    assert Float._new(mpf_norm((1, 1, 0, 1), 5), 5) == Float._new((1, 1, 0, 1), 5)\n", "def test_as_integer_ratio():\n    assert Float(0.0).as_integer_ratio() == (0, 1)\n    assert Float(1.0).as_integer_ratio() == (1, 1)\n    assert Float(-0.5).as_integer_ratio() == (-1, 2)\n    assert Float(1.2).as_integer_ratio() == (5404319552844595, 4503599627370496)\n    assert Float(0.3).as_integer_ratio() == (5404319552844595, 18014398509481984)\n", "def test_mpf_norm():\n    a = mpf_norm((1, 5, 0, 3), 30)\n    assert a == (1, 5, 0, 3)\n\n    b = mpf_norm((1, 0, 1, 5), 30)\n    assert b == (1, 0, 1, 5)\n\n    c = mpf_norm((0, 0, 1, 5), 30)\n    assert c == (0, 0, 0, 1)\n", "def test_mpf_norm():\n    assert mpf_norm((1, 1, 0, 1), 53) == (1, 1, 0, 1)\n"], "sample_143": ["def test_pretty_mmMmmKk():\n    x = Symbol('x')\n    expr = sin(x)\n    n_expr = sin(x/Million)\n\n    assert upretty(expr) == upretty(n_expr.subs(Million, 1))\n    assert pretty(expr) == pretty(n_expr.subs(Million, 1))\n", "def test_pretty_RandomDomain():\n    from sympy.stats.rv import RandomDomain\n    from sympy import symbols\n    x, y = symbols('x, y')\n    dom = RandomDomain(x, y, symbols('lambda'))\n    assert upretty(dom) == upretty(symbols('Domain: ') * symbols('lambda'))\n", "def test_mersenne_prime_sequence():\n    mersenne = {3: 7, 4: 15, 5: 31, 6: 63}\n    mersenne_sequence = SeqFormula(lambda n: 2**n - 1, (n, 3, oo))\n    assert upretty(mersenne_sequence.truncate(4)) == upretty(tuple([mersenne[i] for i in range(3, 7)]))\n", "def test_prettyprint_units():\n    assert upretty(joule) == '\\N{KELVIN}\\N{GREEK SMALL LETTER GAMMA}\\N{MULTIPLICATION SIGN}\\N{METRE}\\N{SUPERSCRIPT TWO}\\N{SOLIDUS}\\N{SECOND}'\n    assert pretty(joule) == 'kg*m**2/s'\n", "def test_pretty_mod():\n    assert pretty(Mod(x, y)) == \"x mod y\"\n    assert upretty(Mod(x, y)) == \"x mod y\"\n"], "sample_52": ["    def test_create_model(self):\n        operation = migrations.CreateModel(\n            name=\"Tag\",\n            fields=[\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=255)),\n            ],\n        )\n\n        self.assertEqual(operation.name, \"Tag\")\n        self.assertEqual(\n            operation.fields,\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=255)),\n            ],\n        )\n\n        # Test the state alteration\n        project_state = ProjectState()\n        new_state = project_state.clone()\n        operation.state_forwards(\"testapp\", new_state)\n        self.assertEqual(len(new_state.models), 1)\n        self.assertEqual(\n            new_state.models[\"testapp\", \"tag\"].fields,\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=255)),\n            ],\n        )\n\n        # Test the database alteration\n        self.assertEqual(self.get_table_description(\"testapp_tag\"), None)\n        with atomic():\n            operation.database_forwards(\"testapp\", editor, project_state, new_state)\n        self.assertEqual(\n            self.get_table_description(\"testapp_tag\"),\n            [\n                (0, \"id\", \"integer\", 1, 11, 0, 1),\n                (0, \"name\", \"varchar(255)\", 1, None, 0, 0),\n            ],\n        )\n\n        # And test reversal\n        with atomic():\n            operation.database_backwards(\"testapp\", editor, new_state, project_state)\n        self.assertEqual(self.get_table_description(\"testapp_tag\"), None)\n", "    def test_rename_model(self):\n        operation = migrations.RenameModel(\"UnicodeModel\", \"NewUnicodeModel\")\n\n        # Test state changing\n        project_state = self.set_up_test_model(\"UnicodeModel\")\n        new_state = project_state.clone()\n        operation.state_forwards(\"tests\", new_state)\n        self.assertEqual(new_state.models[\"tests\", \"newunicodemodel\"].name, \"NewUnicodeModel\")\n\n        # Test database\n        self.apply_operations(operation)\n        self.assertTableExists(\"tests_newunicodemodel\")\n        self.assertTableNotExists(\"tests_unicodemodel\")\n", "    def test_create_model(self):\n        operation = migrations.CreateModel(\n            \"Pony\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=15)),\n                (\"is_magical\", models.BooleanField()),\n            ],\n        )\n        project_state = ProjectState()\n        new_state = project_state.clone()\n        operation.state_forwards(\"testapp\", new_state)\n        model_state = new_state.models[\"testapp\", \"pony\"]\n        self.assertEqual(model_state.name, \"Pony\")\n        self.assertEqual(len(model_state.fields), 3)\n\n        self.assertTableExists(\"testapp_pony\")\n        self.assertColumnExists(\"testapp_pony\", \"id\")\n        self.assertColumnExists(\"testapp_pony\", \"name\")\n        self.assertColumnExists(\"testapp_pony\", \"is_magical\")\n\n        with atomic(new_state.apps, savepoint=False):\n            with self.connection.schema_editor() as schema_editor:\n                operation.database_backwards(\"testapp\", schema_editor, new_state, project_state)\n        self.assertTableNotExists(\"testapp_pony\")\n\n        # Test no database operation when model options change.\n        operation.options[\"verbose_name\"] = \"Magical Pony\"\n        new_state = project_state.clone()\n        operation.state_forwards(\"testapp\", new_state)\n        model_state = new_state.models[\"testapp\", \"pony\"]\n        self.assertEqual(model_state.name, \"Pony\")\n        self.assertEqual(len(model_state.fields), 3)\n\n        with atomic(new_state.apps, savepoint=False):\n            with self.connection.schema_editor() as schema_editor:\n                operation.database_forwards(\"testapp\", schema_editor, project_state, new_state)\n        self.assertTableExists(\"testapp_pony\")\n        self.assertColumnExists(\"testapp_pony\", \"id\")\n        self.assertColumnExists(\"testapp_pony\", \"name\")\n        self.assertColumnExists(\"testapp_pony\", \"is_magical\")\n", "    def test_create_model(self):\n        operation = migrations.CreateModel(\n            name=\"Pony\",\n            fields=[\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"pink\", models.IntegerField()),\n            ],\n        )\n        # Test the state alteration\n        project_state = self.set_up_test_model(\"test_pony\")\n        new_state = project_state.clone()\n        operation.state_forwards(\"testapp\", new_state)\n        self.assertEqual(len(new_state.models[\"testapp\", \"pony\"].fields), 2)\n        # Test the database alteration\n        self.apply_operations(\"testapp\", project_state, [operation])\n        self.assertTableExists(\"testapp_pony\")\n        self.assertColumnExists(\"testapp_pony\", \"pink\")\n        # And test reversal\n        self.unapply_operations(\"testapp\", new_state, [operation])\n        self.assertTableNotExists(\"testapp_pony\")\n", "    def test_create_model(self):\n        operation = migrations.CreateModel(\n            \"Pony\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=10)),\n            ],\n        )\n        self.apply_operations(operation)\n        project_state = self.set_up_test_model(\"test\", \"Pony\")\n        self.assertColumnExists(\"test_pony\", \"name\")\n\n        # Going backwards, the table should be dropped\n        new_state = project_state - operation\n        with connection.schema_editor() as schema_editor:\n            operation.database_backwards(\n                \"test\", schema_editor, new_state, project_state\n            )\n        self.assertTableNotExists(\"test_pony\")\n"], "sample_126": ["def test_mod_inverse():\n    assert mod_inverse(3, 11) == 4\n    assert mod_inverse(5, 7) == 3\n    assert mod_inverse(-3, 11) == -4\n    raises(ValueError, lambda: mod_inverse(2, 4))\n    raises(ValueError, lambda: mod_inverse(4, 2))\n", "def test_int_log():\n    assert integer_log(10**5, 10) == 5\n    assert integer_log(10**5, 10) == 5\n    assert integer_log(10**6, 10) == 6\n    assert integer_log(10**7, 10) == 7\n    assert integer_log(7, 2) == 2\n    assert integer_log(7, 3) == 1\n    assert integer_log(7, 5) == 1\n    assert integer_log(7, 7) == 1\n", "def test_mpf_norm():\n    assert mpf_norm((0, 1, 0, 0), 53) == (0, 1, 0, 0)\n    assert mpf_norm((0, 12345, 0, 3), 53) == (0, 12345, 0, 3)\n    assert mpf_norm((0, 123456789, -4, 9), 53) == (0, 123456789, -4, 9)\n", "def test_mod_inverse():\n    assert mod_inverse(3, 11) == 4\n    assert mod_inverse(3, 11) == -7\n    assert mod_inverse(4, -3) == -1\n    assert mod_inverse(7, 2) == 1\n    assert mod_inverse(Rational(1, 2), Rational(3, 4)) == 2\n    assert mod_inverse(S.Half, Rational(3, 4)) == 2\n    assert mod_inverse(S.One / 7, Rational(5, 2)) == Rational(7, 2)\n    raises(ValueError, lambda: mod_inverse(2, 4))\n    raises(ValueError, lambda: mod_inverse(S(2) / 3, S(4) / 3))\n    raises(TypeError, lambda: mod_inverse(1, a))\n    raises(TypeError, lambda: mod_inverse(t, 4))\n", "def test_Float_mpf_val():\n    assert Float._new(mpf_norm((1, 5, 0, 3), 20), 20)._mpf_ == (1, 5, 0, 3)\n    assert Float._new(mpf_norm((1, 5, 0, 3), 20), 20)._prec == 20\n    assert Float._new((1, 5, 0), 20)._mpf_ == (1, 5, 0, 3)\n    assert Float._new((1, 5, 0), 20)._prec == 20\n"], "sample_125": ["def test_sympify_mpf():\n    assert sympify(mpf(1)) == 1\n    assert sympify(mpf(1.5)) == Rational(3, 2)\n    assert sympify(mpf('10**20')) == 10**20\n    assert sympify(mpf(1.1, 50))._prec == 50\n", "def test_comp():\n    assert comp(0.5, 0.5) is True\n    assert comp(0.5, 0.6) is False\n    assert comp(0, 0) is True\n    assert comp(1e50, 1e50 + 1) is True\n    assert comp(1e-50, 1e-50 + 1) is False\n    assert comp(1e-50, 1e50) is False\n    assert comp(1e50, 1e-50) is False\n", "def test_Rational():\n    assert Rational(1, 2) == Rational(1, 2)\n    assert Rational(1, 2) == Rational(2, 4)\n    assert Rational(1, 2) == Rational(3, 6)\n    assert Rational(1, 2) == Rational(4, 8)\n    assert Rational(1, 2) != Rational(1, 1)\n    assert Rational(1, 2) != Rational(2, 3)\n\n    assert Rational(1, 2) + Rational(1, 3) == Rational(5, 6)\n    assert Rational(1, 2) - Rational(1, 3) == Rational(1, 6)\n    assert Rational(1, 2) * Rational(1, 3) == Rational(1, 6)\n    assert Rational(1, 2) / Rational(1, 3) == Rational(3, 2)\n\n    assert Rational(1, 2) + 1 == Rational(3, 2)\n    assert Rational(1, 2) - 1 == Rational(-1, 2)\n    assert Rational(1, 2) * 2 == 1\n    assert Rational(1, 2) / 2 == Rational(1, 4)\n", "def test_integer_nthroot():\n    assert integer_nthroot(16, 4) == (2, True)\n    assert integer_nthroot(81, 3) == (3, False)  # 4**3 is 64\n    assert integer_nthroot(24, 3) == (2, False)  # 2**3 is 8\n    assert integer_nthroot(100, 10) == (2, False)  # 2**10 is 1024\n    # check that it is not true when it shouldn't be\n    assert integer_nthroot(100, 10)[1] is False\n    # check nthroot of negative numbers\n    assert integer_nthroot(-16, 4) == (-2, True)\n    assert integer_nthroot(factorial(6), 6) == (-6, False)\n    assert integer_nthroot(-factorial(6), 6) == (6, False)\n    assert integer_nthroot(factorial(6) + 1, 6) == (2, False)\n    assert integer_nthroot(-factorial(6) - 1, 6) == (-2, False)\n", "def test_mpf_norm():\n    # Check that mpf_norm returns mpf tuples with the correct precision\n    mpf_tup = (1, 123456, 0, 6)\n    assert mpf_norm(mpf_tup, 20) == (1, 123456, 0, 6)\n    assert mpf_norm(mpf_tup, 4) == (1, 123456, 0, 4)\n"], "sample_127": ["def test_latex_UnevaluatedExpr():\n    e = UnevaluatedExpr(2*x)\n    assert latex(e) == \"2 x\"\n", "def test_LatexPrinter_settings():\n    lp = LatexPrinter()\n    assert lp._settings[\"order\"] is None\n    assert lp._settings[\"mode\"] == \"plain\"\n    assert not lp._settings[\"itex\"]\n    assert not lp._settings[\"fold_frac_powers\"]\n    assert not lp._settings[\"fold_func_brackets\"]\n    assert lp._settings[\"fold_short_frac\"] is None\n    assert lp._settings[\"long_frac_ratio\"] == 2\n    assert lp._settings[\"mul_symbol\"] is None\n    assert lp._settings[\"inv_trig_style\"] == \"abbreviated\"\n    assert lp._settings[\"mat_str\"] is None\n    assert lp._settings[\"mat_delim\"] == \"[\"\n    assert lp._settings[\"symbol_names\"] == {}\n    assert not lp._settings[\"ln_notation\"]\n\n    # Check constructor without arguments\n    lp = LatexPrinter()\n    assert lp._settings[\"order\"] is None\n    assert lp._settings[\"mode\"] == \"plain\"\n    assert not lp._settings[\"itex\"]\n    assert not lp._settings[\"fold_frac_powers\"]\n    assert not lp._settings[\"fold_func_brackets\"]\n    assert lp._settings[\"fold_short_frac\"] is None\n    assert lp._settings[\"long_frac_ratio\"] == 2\n    assert lp._settings[\"mul_symbol\"] is None\n    assert lp._settings[\"inv_trig_style\"] == \"abbreviated\"\n    assert lp._settings[\"mat_str\"] is None\n    assert lp._settings[\"mat_delim\"] == \"[\"\n    assert lp._settings[\"symbol_names\"] == {}\n    assert not lp._settings[\"ln_notation\"]\n\n    # Check constructor with some arguments\n    settings = {\n        \"order\": \"lex\",\n        \"mode\": \"inline\",\n        \"itex\": True,\n        \"fold_frac_powers\": True,\n        \"fold_func_brackets\": True,\n        \"fold_short_frac\": True,\n        \"long_frac_ratio\": 3,\n        \"mul_symbol\": \"times\",\n        \"inv_trig_style\": \"full\",\n        \"mat_str\": \"array\",\n        \"mat_delim\": \"(\",\n        \"symbol_names\": {\"x\": \"x_i\"},\n        \"ln_notation\": True\n    }\n    lp = LatexPrinter(settings)\n    for key, val in settings.items():\n        assert lp._settings[key] == val\n", "def test_PolynomialRing_latex():\n    R = ZZ.poly_ring(x, y, z)\n    assert latex(R) == r\"\\mathbb{Z}\\left[x, y, z\\right]\"\n    assert latex(ZZ.old_poly_ring(x, y, z)) == r\"\\mathbb{Z}\\left[x, y, z\\right]\"\n", "def test_LatexPrinter_settings():\n    # test if latex() is using default settings\n    assert latex(1 / x) == r\"\\frac{1}{x}\"\n    assert latex(1 / x, fold_short_frac=False) == r\"\\frac{1}{x}\"\n    assert latex(1 / y) == r\"\\frac{1}{y}\"\n\n    assert latex(x * y, mul_symbol='times') == r\"x \\times y\"\n    assert latex(x / y, fold_short_frac=True) == r\"x / y\"\n    assert latex((x + y) / z, fold_short_frac=True) == r\"\\frac{x + y}{z}\"\n\n    assert latex(S.GoldenRatio, symbol_names={S.GoldenRatio: r'\\phi'}) == r\"\\phi\"\n    assert latex(S.ImaginaryUnit, symbol_names={S.ImaginaryUnit: r'i'}) == r\"i\"\n", "def test_latex_matrix():\n    M = Matrix([[1, 2], [3, 4]])\n    assert latex(M) == r'\\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}'\n    M = MatrixSymbol('M', 2, 2)\n    assert latex(M) == r'M'\n    assert latex(M**-1) == r'M^{-1}'\n    assert latex(M.inv()) == r'M^{-1}'\n    assert latex(M.T) == r'M^{T}'\n"]}, "raw_scored_generations": {"sample_1": [false, true, false, false, true], "sample_2": [false, false, false, false, false], "sample_4": [true, true, true, true, false], "sample_0": [true, true, true, true, false], "sample_3": [true, true, true, true, false], "sample_6": [false, false, false, false, false], "sample_5": [true, true, true, false, true], "sample_7": [false, true, true, false, true], "sample_9": [true, true, false, true, true], "sample_8": [true, false, false, true, true], "sample_10": [true, true, true, true, true], "sample_11": [false, false, false, false, false], "sample_13": [true, true, true, true, true], "sample_14": [false, false, false, false, false], "sample_12": [true, true, true, true, true], "sample_15": [true, true, true, true, true], "sample_16": [false, true, false, true, false], "sample_17": [false, false, false, true, true], "sample_18": [false, false, false, false, false], "sample_19": [true, true, false, true, true], "sample_21": [true, true, true, true, true], "sample_20": [true, false, true, false, false], "sample_23": [true, true, true, true, true], "sample_22": [false, false, false, false, false], "sample_24": [false, false, false, false, false], "sample_25": [true, true, true, true, true], "sample_28": [true, true, true, true, true], "sample_26": [false, false, false, false, false], "sample_27": [false, false, false, false, false], "sample_29": [true, true, true, true, true], "sample_31": [true, true, true, true, true], "sample_30": [true, true, true, true, true], "sample_32": [false, false, false, false, false], "sample_33": [false, false, false, false, false], "sample_34": [false, false, false, true, false], "sample_35": [false, false, false, false, false], "sample_36": [false, false, false, false, false], "sample_37": [false, true, true, true, true], "sample_39": [false, false, false, false, false], "sample_38": [false, true, true, false, true], "sample_40": [false, false, false, false, false], "sample_42": [false, false, false, false, false], "sample_41": [true, true, true, true, true], "sample_43": [true, true, true, true, true], "sample_45": [false, false, false, false, false], "sample_44": [true, true, true, true, true], "sample_46": [false, false, false, false, false], "sample_48": [false, false, false, false, false], "sample_47": [false, false, false, false, false], "sample_50": [false, false, false, false, false], "sample_49": [false, true, true, false, true], "sample_51": [true, true, true, true, true], "sample_52": [false, false, false, true, false], "sample_53": [true, true, false, true, false], "sample_55": [false, false, false, false, false], "sample_54": [false, false, false, false, false], "sample_56": [false, false, false, true, false], "sample_58": [true, true, true, true, true], "sample_57": [true, true, true, true, true], "sample_60": [false, false, false, false, false], "sample_59": [true, true, true, true, true], "sample_61": [false, false, false, false, false], "sample_63": [false, true, false, true, true], "sample_62": [false, false, false, false, false], "sample_64": [true, true, true, true, true], "sample_66": [true, false, true, false, true], "sample_65": [false, false, false, false, false], "sample_68": [true, true, true, true, true], "sample_67": [false, false, false, false, false], "sample_69": [false, true, true, false, false], "sample_70": [true, true, false, false, false], "sample_71": [true, false, false, false, false], "sample_72": [false, true, false, true, false], "sample_73": [false, false, false, false, false], "sample_74": [false, false, false, false, false], "sample_75": [false, true, false, false, true], "sample_76": [false, false, false, false, false], "sample_77": [false, false, false, false, false], "sample_78": [false, true, true, false, false], "sample_79": [false, true, false, false, true], "sample_80": [false, false, false, false, false], "sample_82": [true, true, false, false, false], "sample_81": [false, false, false, false, false], "sample_83": [false, false, false, false, false], "sample_84": [false, false, false, false, false], "sample_85": [false, false, false, false, false], "sample_86": [false, false, false, false, false], "sample_87": [false, false, false, false, false], "sample_88": [false, false, false, false, false], "sample_89": [false, false, false, false, false], "sample_90": [false, false, false, false, false], "sample_91": [false, false, false, false, false], "sample_92": [false, false, false, false, false], "sample_93": [false, false, false, false, true], "sample_95": [false, false, false, false, false], "sample_94": [false, false, false, false, false], "sample_96": [false, false, false, false, false], "sample_97": [true, false, false, true, false], "sample_98": [false, false, false, false, false], "sample_99": [false, false, false, false, false], "sample_101": [true, false, false, false, false], "sample_100": [false, false, false, false, false], "sample_102": [true, false, false, false, false], "sample_103": [false, false, true, false, false], "sample_104": [false, false, false, false, false], "sample_105": [true, true, true, true, true], "sample_107": [false, false, false, false, true], "sample_106": [false, false, false, false, false], "sample_108": [true, false, false, false, false], "sample_109": [true, false, false, true, false], "sample_110": [false, false, false, true, true], "sample_111": [true, false, false, false, false], "sample_112": [true, true, false, false, false], "sample_113": [false, true, false, false, false], "sample_114": [false, true, true, true, true], "sample_115": [true, true, true, true, true], "sample_116": [false, false, false, false, false], "sample_117": [false, false, true, false, false], "sample_118": [false, false, false, false, false], "sample_119": [true, false, false, false, true], "sample_120": [false, true, false, false, true], "sample_121": [true, false, false, false, false], "sample_122": [false, true, true, true, true], "sample_123": [false, false, false, false, true], "sample_124": [false, false, false, false, false], "sample_125": [false, true, true, false, false], "sample_126": [true, false, false, false, false], "sample_127": [true, false, true, false, false], "sample_128": [true, false, false, false, false], "sample_129": [false, false, false, false, false], "sample_130": [true, false, false, false, true], "sample_131": [false, false, false, true, false], "sample_132": [true, false, false, true, false], "sample_133": [false, false, false, true, false], "sample_134": [false, false, true, false, true], "sample_135": [true, false, false, false, false], "sample_136": [true, false, true, false, false], "sample_137": [true, true, false, false, true], "sample_138": [false, false, false, false, false], "sample_139": [false, true, false, false, false], "sample_140": [true, true, false, true, true], "sample_142": [true, true, true, false, true], "sample_141": [false, false, false, false, false], "sample_143": [false, false, false, false, false], "sample_144": [true, true, true, true, false], "sample_145": [false, true, false, true, false], "sample_146": [true, false, false, true, true], "sample_147": [false, false, true, false, false], "sample_148": [false, false, false, false, false], "sample_149": [true, false, false, false, true], "sample_150": [false, false, false, false, false], "sample_151": [false, false, false, true, false], "sample_152": [true, true, false, true, true], "sample_153": [false, false, true, false, false], "sample_154": [false, true, false, true, false], "sample_155": [false, false, false, false, false], "sample_156": [true, false, false, false, false], "sample_157": [false, false, true, false, false], "sample_158": [false, false, false, false, false], "sample_159": [false, false, false, false, false]}}