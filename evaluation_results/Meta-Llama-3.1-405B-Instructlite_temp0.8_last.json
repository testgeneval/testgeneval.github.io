{"raw_generations": {"sample_67": ["def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return \"complex(%r)\" % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n    self.assertEqual(Serializer._registry[complex], ComplexSerializer)\n\n    Serializer.unregister(complex)\n    self.assertNotIn(complex, Serializer._registry)\n", "def test_register_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return \"complex(%r)\" % self.value, {}\n\n    class MyComplex:\n        pass\n\n    complex_value = MyComplex()\n    with self.assertRaises(ValueError):\n        MigrationWriter.serialize(complex_value)\n\n    Serializer.register(MyComplex, ComplexSerializer)\n    string, imports = MigrationWriter.serialize(complex_value)\n    self.assertEqual(string, \"complex(%r)\" % complex_value)\n\n    Serializer.unregister(MyComplex)\n    with self.assertRaises(ValueError):\n        MigrationWriter.serialize(complex_value)\n", "def test_serialize_zone_info(self):\n    self.assertSerializedEqual(zoneinfo.ZoneInfo(\"Europe/Paris\"))\n    tz = zoneinfo.ZoneInfo(\"Europe/Paris\")\n    dt = datetime.datetime(2022, 1, 1, tzinfo=tz)\n    string, imports = MigrationWriter.serialize(dt)\n    self.assertEqual(\n        string,\n        \"datetime.datetime(2022, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\",\n    )\n    self.assertEqual(imports, {\"import datetime\"})\n", "def test_serialize_regex_object(self):\n    regex = re.compile(r\"^\\w+$\")\n    self.assertSerializedResultEqual(\n        RegexObject(regex),\n        (\"re.compile('^\\\\\\\\w+$')\", {\"import re\"}),\n    )\n", "def test_register_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return \"complex(%r)\" % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n    self.assertEqual(\n        MigrationWriter.serialize(complex(1)),\n        (\"complex((1+0j))\", set()),\n    )\n\n    Serializer.unregister(complex)\n    with self.assertRaisesMessage(ValueError, \"Cannot serialize\"):\n        MigrationWriter.serialize(complex(1))\n"], "sample_97": ["def test_label_encoder_with_numpy_array():\n    # Test LabelEncoder's transform and inverse_transform methods with numpy array\n    le = LabelEncoder()\n    y = np.array([1, 1, 4, 5, -1, 0])\n    le.fit(y)\n    assert_array_equal(le.classes_, [-1, 0, 1, 4, 5])\n    assert_array_equal(le.transform(y), [2, 2, 3, 4, 0, 1])\n    assert_array_equal(le.inverse_transform([2, 2, 3, 4, 0, 1]), y)\n\n    # Test fit_transform with numpy array\n    le = LabelEncoder()\n    ret = le.fit_transform(y)\n    assert_array_equal(ret, [2, 2, 3, 4, 0, 1])\n\n    # Test fit_transform with 2D numpy array\n    le = LabelEncoder()\n    y_2d = np.array([[1], [1], [4], [5], [-1], [0]])\n    ret = le.fit_transform(y_2d)\n    assert_array_equal(ret, [2, 2, 3, 4, 0, 1])\n", "def test_label_binarize_invalid_input_type():\n    # Test that label_binarize raises an error for invalid input types\n    y = 'string'\n    classes = [0, 1]\n    assert_raises(ValueError, label_binarize, y, classes)\n\n    y = 123\n    classes = [0, 1]\n    assert_raises(ValueError, label_binarize, y, classes)\n\n    y = None\n    classes = [0, 1]\n    assert_raises(ValueError, label_binarize, y, classes)\n", "def test_label_binarizer_pos_label_zero():\n    # Test that LabelBinarizer handles pos_label=0 correctly\n    lb = LabelBinarizer(pos_label=0, neg_label=1)\n    y = [0, 1, 0, 1]\n    expected = np.array([[0], [1], [0], [1]])\n    got = lb.fit_transform(y)\n    assert_array_equal(expected, got)\n    assert_array_equal(lb.inverse_transform(got), y)\n", "def test_label_binarize_unsorted_classes():\n    y = [2, 1, 0]\n    classes = [2, 0, 1]\n    pos_label = 1\n    neg_label = 0\n    expected = np.array([[1, 0, 0], [0, 0, 1], [0, 1, 0]])\n\n    lb = LabelBinarizer(neg_label=neg_label, pos_label=pos_label)\n    binarized = lb.fit_transform(y)\n    assert_array_equal(binarized, expected)\n    assert_array_equal(lb.inverse_transform(binarized), y)\n", "def test_label_binarize_sparse_input():\n    # Test label_binarize with sparse input\n    y = csr_matrix(np.array([[0, 1, 0], [1, 1, 1], [0, 0, 0]]))\n    classes = [0, 1, 2]\n    pos_label = 2\n    neg_label = 0\n    expected = pos_label * y.toarray()\n\n    binarized = label_binarize(y, classes, neg_label=neg_label,\n                               pos_label=pos_label)\n    assert_array_equal(binarized, expected)\n\n    # Check inverse\n    y_type = type_of_target(y)\n    inversed = _inverse_binarize_thresholding(binarized, output_type=y_type,\n                                              classes=classes,\n                                              threshold=((neg_label +\n                                                          pos_label) /\n                                                         2.))\n    assert_array_equal(inversed, y.toarray())\n\n    # Check LabelBinarizer\n    lb = LabelBinarizer(neg_label=neg_label, pos_label=pos_label)\n    binarized = lb.fit_transform(y)\n    assert_array_equal(binarized, expected)\n    inverse_output = lb.inverse_transform(binarized)\n    assert_array_equal(inverse_output, y.toarray())\n"], "sample_7": ["def test_check_errors_catches_all_exceptions(self):\n    \"\"\"\n    Since Python may raise arbitrary exceptions when importing code,\n    check_errors() must catch Exception, not just some subclasses.\n    \"\"\"\n    class MyException(Exception):\n        pass\n\n    fake_method = mock.MagicMock(side_effect=MyException())\n    wrapped = autoreload.check_errors(fake_method)\n    with self.assertRaises(MyException):\n        wrapped()\n", "    def test_executable(self):\n        args = autoreload.get_child_arguments()\n        self.assertEqual(args[0], sys.executable)\n", "    def test_trigger_reload(self):\n        with mock.patch('django.utils.autoreload.sys.exit') as mocked_exit:\n            autoreload.trigger_reload('test.py')\n            self.assertEqual(mocked_exit.call_count, 1)\n            self.assertEqual(mocked_exit.call_args[0][0], 3)\n", "    def test_stop_closes_client(self):\n        reloader = autoreload.WatchmanReloader()\n        with mock.patch.object(reloader.client, 'close') as mocked_close:\n            reloader.stop()\n        self.assertEqual(mocked_close.call_count, 1)\n", "    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertEqual(mocked_termios.tcgetattr.call_count, 1)\n        self.assertEqual(mocked_termios.tcsetattr.call_count, 1)\n"], "sample_44": ["def test_limit_choices_to(self):\n    limit_choices_to = {'name__contains': 'test'}\n    f = forms.ModelChoiceField(Category.objects.all(), limit_choices_to=limit_choices_to)\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c2.pk, 'A test'),\n        (self.c3.pk, 'Third'),\n    ])\n\n        return {'name__contains': 'third'}\n\n    f = forms.ModelChoiceField(Category.objects.all(), limit_choices_to=limit_choices_to_callable)\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c3.pk, 'Third'),\n    ])\n", "def test_modelmultiplechoicefield_prepare_value(self):\n    field = forms.ModelMultipleChoiceField(Category.objects.all())\n    c4 = Category.objects.create(name='Fourth', slug='4th', url='4th')\n    self.assertEqual(\n        list(field.prepare_value([self.c1, self.c2, c4])),\n        [self.c1.pk, self.c2.pk, c4.pk],\n    )\n    self.assertEqual(field.prepare_value([]), [])\n    self.assertEqual(field.prepare_value(None), None)\n    self.assertEqual(field.prepare_value([None]), [None])\n    self.assertEqual(field.prepare_value([self.c1.pk]), [self.c1.pk])\n    self.assertEqual(field.prepare_value(['abc']), ['abc'])\n", "def test_choices_fetched_when_rendering(self):\n    with self.assertNumQueries(2):\n        field = forms.ModelChoiceField(Category.objects.order_by('-name'))\n        widget = field.widget\n        widget.render('name', self.c1.pk)\n", "def test_queryset_property(self):\n    f = forms.ModelChoiceField(Category.objects.all())\n    self.assertEqual(f.queryset, Category.objects.all())\n\n    # Changing the queryset property should update the choices.\n    new_queryset = Category.objects.filter(name='Entertainment')\n    f.queryset = new_queryset\n    self.assertEqual(f.queryset, new_queryset)\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c1.pk, 'Entertainment'),\n    ])\n", "def test_modelmultiplechoicefield_prepare_value(self):\n    f = forms.ModelMultipleChoiceField(Category.objects.all())\n    c4 = Category.objects.create(name='Fourth', slug='4th', url='4th')\n    value = [self.c1, self.c2, c4]\n    prepared_value = f.prepare_value(value)\n    self.assertEqual(prepared_value, [self.c1.pk, self.c2.pk, c4.pk])\n"], "sample_150": ["def test_solve_generic():\n    assert solve_generic([Poly(x - 1)], Options((x,), {'domain': 'ZZ'})) == [(1,)]\n    assert solve_generic([Poly(y - x), Poly(y - x - 1)], Options((x, y), {'domain': 'ZZ'})) is None\n    assert solve_generic([Poly(y - x**2), Poly(y + x**2)], Options((x, y), {'domain': 'ZZ'})) == [(0, 0)]\n\n    raises(NotImplementedError, lambda: solve_generic([Poly(x**3 - y**3)], Options((x, y), {'domain': 'ZZ'})))\n    raises(PolynomialError, lambda: solve_generic([Poly(1/x)], Options((x,), {'domain': 'ZZ'})))\n\n    raises(NotImplementedError, lambda: solve_generic(\n          [Poly(x-1)], Options((x, y), {'domain': 'ZZ'})))\n    raises(NotImplementedError, lambda: solve_generic(\n          [Poly(y-1)], Options((x, y), {'domain': 'ZZ'})))\n", "def test_solve_generic():\n    x0, y0, x1, y1, r = symbols('x0 y0 x1 y1 r')\n\n    f_1 = (x - 1)**2 + (y - 1)**2 - r**2\n    f_2 = (x - 2)**2 + (y - 2)**2 - r**2\n    s = sqrt(2*r**2 - 1)\n    a = (3 - s)/2\n    b = (3 + s)/2\n\n    assert solve_generic([f_1, f_2], Options((x, y), {'domain': 'ZZ'})) == [(a, b), (b, a)]\n\n    f_1 = (x - 1 )**2 + (y - 2)**2 - r**2\n    f_2 = (x - 1)**2 + (y - 1)**2 - r**2\n\n    assert solve_generic([f_1, f_2], Options((x, y), {'domain': 'ZZ'})) == \\\n        [(1 - sqrt((2*r - 1)*(2*r + 1))/2, Rational(3, 2)),\n         (1 + sqrt((2*r - 1)*(2*r + 1))/2, Rational(3, 2))]\n\n    query = lambda expr: expr.is_Pow and expr.exp is S.Half\n\n    f_1 = (x - 1 )**2 + (y - 2)**2 - r**2\n    f_2 = (x - x1)**2 + (y - 1)**2 - r**2\n\n    result = solve_generic([f_1, f_2], Options((x, y), {'domain': 'ZZ'}))\n\n    assert len(result) == 2 and all(len(r) == 2 for r in result)\n    assert all(r.count(query) == 1 for r in flatten(result))\n\n    raises(NotImplementedError, lambda: solve_generic([x*y - 2*y, 2*y**2 - x**2], Options((x, y), {'domain': 'ZZ'})))\n    raises(ComputationFailed, lambda: solve_generic([x**3 - y**3], Options((x, y), {'domain': 'ZZ'})))\n", "def test_solve_generic():\n    assert solve_generic([x - 1], Options((x,), {'domain': 'ZZ'})) == [(1,)]\n    assert solve_generic([x**2 + y, x + y*4], Options((x, y), {'domain': 'ZZ'})) == \\\n        [(0, 0), (1/4, -1/16)]\n    assert solve_generic([x - 2*y + 5, 2*x - y - 3], Options((x, y), {'domain': 'ZZ'})) == \\\n        [(11/3, 13/3)]\n    assert solve_generic([x**2 + 1, y - 1], Options((x, y), {'domain': 'ZZ'})) == []\n    raises(NotImplementedError, lambda: solve_generic([x**3 - y], Options((x, y), {'domain': 'ZZ'})))\n    raises(PolynomialError, lambda: solve_generic([1/x], Options((x,), {'domain': 'ZZ'})))\n", "def test_solve_generic():\n    # Test for issue 20762\n    f1 = x**2 + y**2 - 4\n    f2 = x*y - 2\n    assert solve_generic([f1, f2], dict=True) == [{x: -sqrt(2), y: -sqrt(2)}, {x: sqrt(2), y: sqrt(2)}]\n\n    # Test for issue 20762 with domain=QQ\n    assert solve_generic([f1, f2], domain='QQ', dict=True) == []\n\n    # Test for issue 20762 with domain=ZZ\n    assert solve_generic([f1, f2], domain='ZZ', dict=True) == []\n", "def test_solve_generic():\n    f_1 = x**2 + y - 2\n    f_2 = x + y**2 - 3\n\n    assert solve_generic([f_1, f_2], (x, y)) == [(1, 1)]\n\n    f_1 = x**2 + y**2 - 4\n    f_2 = x + y - 2\n\n    assert solve_generic([f_1, f_2], (x, y)) == [(0, 2), (2, 0)]\n\n    f_1 = x**2 + y**2 - 4\n    f_2 = x + y - 3\n\n    assert solve_generic([f_1, f_2], (x, y)) == []\n\n    f_1 = x**2 + y**2 - 1\n    f_2 = x**2 + y**2 - 2\n\n    assert solve_generic([f_1, f_2], (x, y)) is None\n"], "sample_84": ["def test_function_scoped_fixture_is_executed_once_per_function(testdir):\n    \"\"\"Test that a function-scoped fixture is executed once per function, even if the same fixture is used in multiple functions.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture(scope=\"function\")\n            return object()\n\n            assert isinstance(func_fixture, object)\n\n            assert isinstance(func_fixture, object)\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.assert_outcomes(passed=2)\n", "def test_fixture_scope_overrides_parametrize_session(self, testdir):\n    \"\"\"Test that the scope of a fixture can override the scope set by parametrize (#5585)\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture(scope=\"function\", params=[1, 2])\n            return request.param\n\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-v\")\n    result.stdout.fnmatch_lines([\"*test_foo[1]*PASSED*\", \"*test_foo[2]*PASSED*\"])\n", "def test_fixture_disallow_twice_with_different_scopes():\n    \"\"\"Test that applying @pytest.fixture twice with different scopes generates an error (#2334).\"\"\"\n    with pytest.raises(ValueError):\n\n        @pytest.fixture(scope=\"function\")\n        @pytest.fixture(scope=\"module\")\n            pass\n", "def test_fixture_reuse_with_parametrize(testdir):\n    \"\"\"Test that a fixture can be reused across tests when using parametrize (#3839)\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            return 1\n\n        @pytest.mark.parametrize(\"arg\", [1, 2])\n            assert fix == 1\n\n        @pytest.mark.parametrize(\"arg\", [3, 4])\n            assert fix == 1\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*4 passed*\"])\n", "def test_fixture_isinstancecheck():\n    class MyFixture:\n        pass\n\n    @pytest.fixture\n        return MyFixture()\n\n        assert isinstance(my_fixture, MyFixture)\n\n    with pytest.raises(pytest.fail.Exception):\n        assert my_fixture() == MyFixture()\n"], "sample_134": ["def test_codegen_array_elementwise_add_three_matrices():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    M = MatrixSymbol(\"M\", 2, 2)\n    N = MatrixSymbol(\"N\", 2, 2)\n    P = MatrixSymbol(\"P\", 2, 2)\n\n    ma = np.matrix([[1, 2], [3, 4]])\n    mb = np.matrix([[1,-2], [-1, 3]])\n    mc = np.matrix([[2, 0], [1, 2]])\n\n    cg = CodegenArrayElementwiseAdd(M, N, P)\n    f = lambdify((M, N, P), cg, 'numpy')\n    assert (f(ma, mb, mc) == ma+mb+mc).all()\n", "def test_codegen_array_contraction():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    M = MatrixSymbol(\"M\", 2, 2)\n    N = MatrixSymbol(\"N\", 2, 2)\n    P = MatrixSymbol(\"P\", 2, 2)\n\n    cg = CodegenArrayContraction(M*N*P)\n    f = lambdify((M, N, P), cg, 'numpy')\n\n    ma = np.matrix([[1, 2], [3, 4]])\n    mb = np.matrix([[1,-2], [-1, 3]])\n    mc = np.matrix([[2, 0], [1, 2]])\n    assert (f(ma, mb, mc) == ma*mb*mc).all()\n", "def test_codegen_array_elementwise_add():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    M = MatrixSymbol(\"M\", 2, 2)\n    N = MatrixSymbol(\"N\", 2, 2)\n    P = MatrixSymbol(\"P\", 2, 2)\n\n    cg = CodegenArrayElementwiseAdd(M, N)\n    f = lambdify((M, N), cg, 'numpy')\n\n    ma = np.matrix([[1, 2], [3, 4]])\n    mb = np.matrix([[5, 6], [7, 8]])\n    assert (f(ma, mb) == ma + mb).all()\n\n    cg = CodegenArrayElementwiseAdd(M, N, P)\n    f = lambdify((M, N, P), cg, 'numpy')\n\n    mc = np.matrix([[9, 10], [11, 12]])\n    assert (f(ma, mb, mc) == ma + mb + mc).all()\n", "def testcodegen_elementwise():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    M = MatrixSymbol(\"M\", 2, 2)\n    N = MatrixSymbol(\"N\", 2, 2)\n\n    ma = np.matrix([[1, 2], [3, 4]])\n    mb = np.matrix([[1,-2], [-1, 3]])\n\n    cg = CodegenArrayElementwiseAdd(M, N)\n    f = lambdify((M, N), cg, 'numpy')\n    assert (f(ma, mb) == ma+mb).all()\n\n    P = MatrixSymbol(\"P\", 2, 2)\n    mc = np.matrix([[2, 0], [1, 2]])\n\n    cg = CodegenArrayElementwiseAdd(M, N, P)\n    f = lambdify((M, N, P), cg, 'numpy')\n    assert (f(ma, mb, mc) == ma+mb+mc).all()\n", "def test_Identity():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    M = Identity(3)\n    f = lambdify((), M, \"numpy\")\n    assert np.array_equal(f(), np.eye(3))\n"], "sample_60": ["def test_serialize_type_with_module_name_conflict(self):\n    class Foo:\n        pass\n\n    self.assertSerializedResultEqual(\n        type(Foo()),\n        (\"type(migrations.test_writer.WriterTests.test_serialize_type_with_module_name_conflict.<locals>.Foo())\", set()),\n    )\n", "def test_serialize_type(self):\n    self.assertSerializedEqual(type)\n    self.assertSerializedResultEqual(\n        MigrationWriter.serialize(type),\n        (\"type\", set()),\n    )\n", "def test_serialize_type_with___module__(self):\n    class TestType:\n        pass\n\n    TestType.__module__ = \"test_module\"\n    self.assertSerializedResultEqual(\n        TestType,\n        (\"test_module.TestType\", {\"import test_module\"}),\n    )\n", "def test_register_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return \"complex(%r)\" % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n    value = complex(1, 2)\n    string, imports = MigrationWriter.serialize(value)\n    self.assertEqual(string, \"complex((1+2j))\")\n    self.assertEqual(imports, set())\n    Serializer.unregister(complex)\n\n    class InvalidSerializer:\n        pass\n\n    with self.assertRaisesMessage(\n        ValueError, \"'InvalidSerializer' must inherit from 'BaseSerializer'.\"\n    ):\n        Serializer.register(complex, InvalidSerializer)\n", "def test_serialize_enum_with_lazy_value(self):\n    class TextEnumWithLazyValue(enum.Enum):\n        A = _(\"a-value\")\n        B = _(\"value-b\")\n\n    self.assertSerializedResultEqual(\n        TextEnumWithLazyValue.A,\n        (\n            \"migrations.test_writer.TextEnumWithLazyValue['A']\",\n            {\"import migrations.test_writer\"},\n        ),\n    )\n    field = models.CharField(\n        default=TextEnumWithLazyValue.B, choices=[(m.value, m) for m in TextEnumWithLazyValue]\n    )\n    string = MigrationWriter.serialize(field)[0]\n    self.assertEqual(\n        string,\n        \"models.CharField(choices=[\"\n        \"(_, 'a-value'), (_, 'value-b')], \"\n        \"default=migrations.test_writer.TextEnumWithLazyValue['B'])\",\n    )\n"], "sample_47": ["def test_migration_plan_with_replacements(self):\n    \"\"\"\n    Tests migration plan with replacements.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Let's look at the plan first and make sure it's up to scratch\n    plan = executor.migration_plan([(\"migrations\", \"0002_second\")])\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n            (executor.loader.graph.nodes[\"migrations\", \"0002_second\"], False),\n        ],\n    )\n    # Check if replacement is applied\n    self.assertTrue(executor.loader.replace_migrations)\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Alright, let's undo what we did\n    plan = executor.migration_plan([(\"migrations\", None)])\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0002_second\"], True),\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], True),\n        ],\n    )\n    executor.migrate([(\"migrations\", None)])\n    # Are the tables gone?\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_book\")\n", "def test_migration_plan_with_clean_start(self):\n    \"\"\"\n    Tests migration plan with clean start.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Make the initial plan, check it\n    plan = executor.migration_plan([(\"migrations\", \"0002_second\")], clean_start=True)\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n            (executor.loader.graph.nodes[\"migrations\", \"0002_second\"], False),\n        ],\n    )\n    # Fake-apply all migrations\n    executor.migrate([\n        (\"migrations\", \"0002_second\"),\n    ], fake=True)\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Now plan a second time and make sure it's empty\n    plan = executor.migration_plan([(\"migrations\", \"0002_second\")], clean_start=True)\n    self.assertEqual(plan, [])\n", "def test_check_replacements(self):\n    \"\"\"\n    Mark replacement migrations applied if their replaced set all are.\n    \"\"\"\n    recorder = MigrationRecorder(connection)\n    # Place the database in a state where the replaced migrations are\n    # partially applied: 0001 is applied, 0002 is not.\n    recorder.record_applied(\"migrations\", \"0001_initial\")\n    executor = MigrationExecutor(connection)\n    executor.loader.build_graph()\n    executor.check_replacements()\n    # Because we've now applied 0001 but not 0002, the squashed replacement\n    # should not be marked as applied.\n    self.assertNotIn(\n        (\"migrations\", \"0001_squashed_0002\"),\n        recorder.applied_migrations(),\n    )\n    # Now apply the second migration and check again\n    recorder.record_applied(\"migrations\", \"0002_second\")\n    executor.loader.build_graph()\n    executor.check_replacements()\n    # Because we've now applied 0001 and 0002 both, their squashed replacement\n    # should be marked as applied.\n    self.assertIn(\n        (\"migrations\", \"0001_squashed_0002\"),\n        recorder.applied_migrations(),\n    )\n", "def test_migration_plan_with_replaced_migrations(self):\n    \"\"\"\n    Migration plans should include replaced migrations if they are not applied.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Fake-apply the first migration\n    executor.migrate([(\"migrations\", \"0001_initial\")], fake=True)\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # The next plan should include the replaced migration\n    plan = executor.migration_plan([(\"migrations\", \"0002_second\")])\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"].replaces[0], False),\n            (executor.loader.graph.nodes[\"migrations\", \"0002_second\"], False),\n        ],\n    )\n", "def test_migration_plan_with_replaced_migrations(self):\n    \"\"\"\n    Tests the migration plan when there are replaced migrations.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Make the initial plan, check it\n    plan = executor.migration_plan([(\"migrations\", \"0002_second\")])\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n            (executor.loader.graph.nodes[\"migrations\", \"0002_second\"], False),\n        ],\n    )\n    # Fake-apply all migrations\n    executor.migrate([\n        (\"migrations\", \"0002_second\"),\n    ], fake=True)\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Now replace the second migration with a new one\n    executor.loader.replace_migrations = {\n        (\"migrations\", \"0002_second\"): (\"migrations\", \"0003_third\")\n    }\n    # Make a new plan, check it\n    plan = executor.migration_plan([(\"migrations\", \"0003_third\")])\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0003_third\"], False),\n        ],\n    )\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Now unapply the new migration\n    plan = executor.migration_plan([(\"migrations\", None)])\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0003_third\"], True),\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], True),\n        ],\n    )\n"], "sample_10": ["def test_lookup_collision_with_custom_lookup(self):\n    \"\"\"Custom lookups do not collide with field names.\"\"\"\n    Season.objects.create(year=2012, gt=None)\n    self.assertFalse(Season.objects.filter(gt__isnull=True))\n    self.assertTrue(Season.objects.filter(gt__mycustomlookup='foo'))\n", "def test_lookup_collision_with_annotation(self):\n    # Genuine field names don't collide with built-in lookup types\n    # ('year', 'gt', 'range', 'in' etc.) when using annotations.\n    season_2009 = Season.objects.create(year=2009, gt=111)\n    season_2010 = Season.objects.create(year=2010, gt=222)\n    Article.objects.create(headline='Article 1', pub_date=datetime(2005, 7, 26), author=self.au1, slug='a1')\n    Article.objects.create(headline='Article 2', pub_date=datetime(2005, 7, 27), author=self.au1, slug='a2')\n\n    qs = Article.objects.annotate(\n        year=Max('author__seasons__year'),\n        gt=Max('author__seasons__gt'),\n    ).filter(year=2009)\n\n    self.assertCountEqual(qs, [])\n    season_2009.authors.add(self.au1)\n    self.assertCountEqual(qs, [Article.objects.get(slug='a1'), Article.objects.get(slug='a2')])\n", "def test_lookup_approximation_with_float_rhs(self):\n    \"\"\"\n    __exact, __iexact, __contains, and __icontains lookup types don't perform \n    any approximation when used with a float value as the rhs.\n    \"\"\"\n    Article.objects.create(headline='1.0', pub_date=datetime(2005, 7, 26))\n    self.assertQuerysetEqual(\n        Article.objects.filter(headline__exact=1.0),\n        ['<Article: 1.0>']\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(headline__iexact=1.0),\n        ['<Article: 1.0>']\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(headline__contains=1.0),\n        ['<Article: 1.0>']\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(headline__icontains=1.0),\n        ['<Article: 1.0>']\n    )\n", "def test_in_bulk_with_nullable_field(self):\n    # Create a few Seasons with and without a non-nullable field 'year' and a nullable field 'gt'.\n    season1 = Season.objects.create(year=2012, gt='foo')\n    season2 = Season.objects.create(year=2013, gt=None)\n    season3 = Season.objects.create(year=2014)\n\n    # in_bulk() should work correctly with both the primary key and the nullable field.\n    self.assertEqual(\n        Season.objects.in_bulk([season1.pk, season2.pk, season3.pk]),\n        {season1.pk: season1, season2.pk: season2, season3.pk: season3}\n    )\n    self.assertEqual(\n        Season.objects.in_bulk(['foo', None], field_name='gt'),\n        {'foo': season1, None: season2}\n    )\n", "def test_in_bulk_with_large_input(self):\n    # Create a large number of authors\n    Author.objects.bulk_create([Author() for _ in range(2000)])\n    \n    # Retrieve all authors using in_bulk()\n    authors = Author.objects.in_bulk(Author.objects.values_list('id', flat=True))\n    \n    # Check that the number of retrieved authors matches the total number of authors\n    self.assertEqual(len(authors), Author.objects.count())\n"], "sample_61": ["def test_decimal_subclass_formatting(self):\n    class EuroDecimal(Decimal):\n        \"\"\"\n        Wrapper for Decimal which prefixes each amount with the \u20ac symbol.\n        \"\"\"\n\n            amount = super().__format__(specifier, **kwargs)\n            return \"\u20ac {}\".format(amount)\n\n    euro_amount = EuroDecimal(\"1234.56\")\n    self.assertEqual(nformat(euro_amount, \".\"), \"\u20ac 1234.56\")\n    self.assertEqual(nformat(euro_amount, \".\", decimal_pos=2), \"\u20ac 1234.56\")\n    self.assertEqual(\n        nformat(euro_amount, \".\", grouping=3, thousand_sep=\",\"), \"\u20ac 1,234.56\"\n    )\n", "def test_decimal_subclass_formatting(self):\n    class EuroDecimal(Decimal):\n            amount = super().__format__(specifier, **kwargs)\n            return \"\u20ac {}\".format(amount)\n\n    euro = EuroDecimal(\"1234.56\")\n    self.assertEqual(nformat(euro, \".\"), \"\u20ac 1234.56\")\n    self.assertEqual(nformat(euro, \".\", decimal_pos=2), \"\u20ac 1234.56\")\n    self.assertEqual(\n        nformat(euro, \".\", grouping=3, thousand_sep=\",\"), \"\u20ac 1,234.56\"\n    )\n    self.assertEqual(\n        nformat(euro, \".\", grouping=3, thousand_sep=\",\", force_grouping=True),\n        \"\u20ac 1,234.56\",\n    )\n", "def test_decimal_subclass_formatting(self):\n    class EuroDecimal(Decimal):\n            amount = super().__format__(specifier, **kwargs)\n            return \"\u20ac {}\".format(amount)\n\n    euro_value = EuroDecimal(\"1234.56\")\n    self.assertEqual(nformat(euro_value, \".\"), \"\u20ac 1234.56\")\n    self.assertEqual(nformat(euro_value, \".\", decimal_pos=2), \"\u20ac 1234.56\")\n    self.assertEqual(\n        nformat(euro_value, \".\", grouping=3, thousand_sep=\",\"), \"\u20ac 1,234.56\"\n    )\n", "def test_none_and_empty_string(self):\n    self.assertEqual(nformat(None, \".\"), None)\n    self.assertEqual(nformat(\"\", \".\"), \"\")\n    self.assertEqual(nformat(None, \".\", decimal_pos=2), None)\n    self.assertEqual(nformat(\"\", \".\", decimal_pos=2), \"\")\n    self.assertEqual(\n        nformat(None, \".\", grouping=2, thousand_sep=\",\"), None\n    )\n    self.assertEqual(\n        nformat(\"\", \".\", grouping=2, thousand_sep=\",\"), \"\"\n    )\n    self.assertEqual(\n        nformat(None, \".\", grouping=2, thousand_sep=\",\", force_grouping=True),\n        None,\n    )\n    self.assertEqual(\n        nformat(\"\", \".\", grouping=2, thousand_sep=\",\", force_grouping=True),\n        \"\",\n    )\n", "def test_decimal_subclass_formatting(self):\n    class EuroDecimal(Decimal):\n            amount = super().__format__(specifier, **kwargs)\n            return \"\u20ac {}\".format(amount)\n\n    euro_decimal = EuroDecimal(\"1234.56\")\n    self.assertEqual(nformat(euro_decimal, \".\"), \"\u20ac 1234.56\")\n    self.assertEqual(nformat(euro_decimal, \".\", decimal_pos=2), \"\u20ac 1234.56\")\n    self.assertEqual(\n        nformat(euro_decimal, \".\", grouping=3, thousand_sep=\",\"), \"\u20ac 1,234.56\"\n    )\n"], "sample_9": ["def test_restart_with_reloader_sets_signal_handler(self):\n    with mock.patch('signal.signal') as mocked_signal:\n        autoreload.restart_with_reloader()\n    self.assertEqual(mocked_signal.call_count, 1)\n    self.assertSequenceEqual(\n        mocked_signal.call_args[0],\n        [signal.SIGTERM, mock.ANY]\n    )\n", "    def test_ensure_echo_on_calls_tcsetattr(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertEqual(mocked_termios.tcsetattr.call_count, 1)\n", "def test_trigger_reload(self):\n    with mock.patch('django.utils.autoreload.sys.exit') as mocked_exit:\n        autoreload.trigger_reload('path/to/file')\n        self.assertEqual(mocked_exit.call_count, 1)\n        self.assertSequenceEqual(mocked_exit.call_args[0], [3])\n", "    def test_ensure_echo_on_called(self, mocked_termios):\n        mocked_termios.tcgetattr.return_value = [0, 0, 0, 0]\n        autoreload.ensure_echo_on()\n        self.assertEqual(mocked_termios.tcsetattr.call_count, 1)\n", "    def test_trigger_reload(self):\n        with mock.patch('django.utils.autoreload.sys.exit') as exit_mock:\n            autoreload.trigger_reload('test_file.py')\n            self.assertEqual(exit_mock.call_count, 1)\n            self.assertSequenceEqual(exit_mock.call_args[0], [3])\n"], "sample_146": ["def test_Dimension():\n    assert str(Dimension(\"length\")) == \"Dimension(length)\"\n    assert sstrrepr(Dimension(\"length\")) == \"Dimension('length')\"\n", "def test_Dimension():\n    assert str(Dimension(\"length\")) == \"Dimension('length')\"\n    assert sstrrepr(Dimension(\"length\")) == \"Dimension('length')\"\n", "def test_ElementwiseApplyFunction():\n    from sympy.tensor.array.expressions.array_expressions import ElementwiseApplyFunction\n    x, y = symbols('x y')\n    A = MatrixSymbol(\"A\", 2, 2)\n    expr = ElementwiseApplyFunction(sin, A)\n    assert str(expr) == \"sin.(A)\"\n    expr = ElementwiseApplyFunction(lambda x: x**2, A)\n    assert str(expr) == \"<lambda>.(A)\"\n", "def test_ElementwiseApplyFunction():\n    from sympy.tensor.array.expressions.array_expressions import ArraySymbol, ElementwiseApplyFunction\n    A = ArraySymbol('A', (3,))\n    func = Lambda(x, x**2)\n    ewaf = ElementwiseApplyFunction(func, A)\n    assert str(ewaf) == \"Lambda(x, x**2).(A)\"\n", "def test_ElementwiseApplyFunction():\n    from sympy.functions.elementary.trigonometric import sin\n    from sympy.tensor.array.expressions.array_expressions import ArraySymbol, ElementwiseApplyFunction\n    A = ArraySymbol('A', (3, 3))\n    f = ElementwiseApplyFunction(sin, A)\n    assert str(f) == 'sin.(A)'\n"], "sample_3": ["def test_separable_single_input_multi_output():\n    # Test a model with a single input and multiple outputs\n    model = models.Shift(1) & models.Shift(2)\n    model.inputs = ('x',)\n    model.outputs = ('y1', 'y2')\n    assert_allclose(is_separable(model), np.array([False, False]))\n    assert_allclose(separability_matrix(model), np.array([[True], [True]]))\n", "def test_custom_model_separable():\n    @custom_model\n        return x\n\n    @custom_model(separable=False)\n        return x + y\n\n    assert_allclose(is_separable(model_a()), np.array([True]))\n    assert_allclose(separability_matrix(model_a()), np.array([[True]]))\n    assert_allclose(is_separable(model_b()), np.array([False, False]))\n    assert_allclose(separability_matrix(model_b()), np.array([[True, True], [True, True]]))\n", "def test_custom_model_separable():\n    @custom_model\n        return x\n\n    @custom_model(separable=True)\n        return x, y\n\n    assert_allclose(is_separable(model_a()), np.array([True]))\n    assert_allclose(is_separable(model_b()), np.array([True, True]))\n\n    @custom_model(separable=False)\n        return x + y, x - y\n\n    assert_allclose(is_separable(model_c()), np.array([False, False]))\n", "def test_custom_model_separable():\n    @custom_model\n        return x\n\n    @custom_model\n        return x + y\n\n    @custom_model(separable=False)\n        return x + y\n\n    assert_allclose(is_separable(model_a()), np.array([True]))\n    assert_allclose(is_separable(model_b()), np.array([False, False]))\n    assert_allclose(is_separable(model_c()), np.array([False, False]))\n", "def test_custom_model_separable():\n    @custom_model\n        return x\n\n    @custom_model\n        return x + y\n\n    model = model_a() & model_b()\n    assert_allclose(is_separable(model), np.array([True, False]))\n    assert_allclose(separability_matrix(model), np.array([[True, False], [True, True]]))\n\n    model = model_b() & model_a()\n    assert_allclose(is_separable(model), np.array([False, True]))\n    assert_allclose(separability_matrix(model), np.array([[True, True], [False, True]]))\n"], "sample_8": ["    def test_cleanse_setting_dictionary(self):\n        setting = {'foo': 'bar', 'password': 'super_secret'}\n        cleansed = cleanse_setting('SETTING', setting)\n        self.assertEqual(cleansed, {'foo': 'bar', 'password': CLEANSED_SUBSTITUTE})\n", "    def test_cleanse_setting_dictionary(self):\n        setting = {'foo': 'bar', 'password': 'super_secret'}\n        cleansed_setting = cleanse_setting('SETTING', setting)\n        self.assertEqual(cleansed_setting, {'foo': 'bar', 'password': CLEANSED_SUBSTITUTE})\n", "    def test_cleanse_setting_dictionary(self):\n        sensitive_settings = {\n            'SECRET_KEY': 'super_secret',\n            'PASSWORD': 'my_password',\n            'NON_SENSITIVE_SETTING': 'not_sensitive',\n            'DICT_SETTING': {'sensitive_key': 'sensitive_value', 'non_sensitive_key': 'not_sensitive'}\n        }\n        cleansed_settings = cleanse_setting('SETTING_NAME', sensitive_settings)\n        self.assertEqual(cleansed_settings['SECRET_KEY'], CLEANSED_SUBSTITUTE)\n        self.assertEqual(cleansed_settings['PASSWORD'], CLEANSED_SUBSTITUTE)\n        self.assertEqual(cleansed_settings['NON_SENSITIVE_SETTING'], 'not_sensitive')\n        self.assertEqual(cleansed_settings['DICT_SETTING']['sensitive_key'], CLEANSED_SUBSTITUTE)\n        self.assertEqual(cleansed_settings['DICT_SETTING']['non_sensitive_key'], 'not_sensitive')\n", "    def test_get_safe_settings(self):\n        with self.settings(FOO='bar', BAZ='qux', SECRET_KEY='hidden'):\n            settings_dict = get_safe_settings()\n            self.assertEqual(settings_dict['FOO'], 'bar')\n            self.assertEqual(settings_dict['BAZ'], 'qux')\n            self.assertEqual(settings_dict['SECRET_KEY'], CLEANSED_SUBSTITUTE)\n", "    def test_is_active(self):\n        filter = SafeExceptionReporterFilter()\n        request = RequestFactory().get('/test_view/')\n        with self.settings(DEBUG=True):\n            self.assertFalse(filter.is_active(request))\n        with self.settings(DEBUG=False):\n            self.assertTrue(filter.is_active(request))\n"], "sample_133": ["def test_c_with_printer():\n    #issue 13586\n    from sympy.printing.ccode import C99CodePrinter\n    class CustomPrinter(C99CodePrinter):\n            return \"fastpow({}, {})\".format(self._print(expr.base),\n                                            self._print(expr.exp))\n\n    printer = CustomPrinter()\n    x, y = symbols('x y')\n    expr = x**y\n\n    gen = C99CodeGen(printer=printer)\n\n    expected = (\n        '#include \"expr.h\"\\n'\n        '#include <math.h>\\n'\n        'double expr(double x, double y) {\\n'\n        '   double expr_result;\\n'\n        '   expr_result = fastpow(x, y);\\n'\n        '   return expr_result;\\n'\n        '}\\n'\n    )\n\n    result = codegen(('expr', expr), header=False, empty=False, code_gen=gen)\n    source = result[0][1]\n    assert source == expected\n", "def test_c_with_printer():\n    #issue 13586\n    from sympy.printing.ccode import C99CodePrinter\n    class CustomPrinter(C99CodePrinter):\n            return \"fastpow({}, {})\".format(self._print(expr.base),\n                                            self._print(expr.exp))\n\n    x = Symbol('x')\n    expr = x**2\n\n    gen = CCodeGen(printer=CustomPrinter())\n\n    expected = (\n        '#include \"expr.h\"\\n'\n        '#include <math.h>\\n'\n        'double expr(double x) {\\n'\n        '   double expr_result;\\n'\n        '   expr_result = fastpow(x, 2);\\n'\n        '   return expr_result;\\n'\n        '}\\n'\n    )\n\n    result = codegen(('expr', expr), header=False, empty=False, code_gen=gen)\n    source = result[0][1]\n    assert source == expected\n", "def test_c_with_printer():\n    from sympy.printing.ccode import C99CodePrinter\n    class CustomPrinter(C99CodePrinter):\n            return \"fastpow({}, {})\".format(self._print(expr.base),\n                                            self._print(expr.exp))\n\n    x = symbols('x')\n    expr = x**2\n\n    gen = C99CodeGen(printer=CustomPrinter())\n    result = codegen(('expr', expr), header=False, empty=False, code_gen=gen)\n    source = result[0][1]\n    expected = (\n        '#include \"expr.h\"\\n'\n        '#include <math.h>\\n'\n        'double expr(double x) {\\n'\n        '   double expr_result;\\n'\n        '   expr_result = fastpow(x, 2);\\n'\n        '   return expr_result;\\n'\n        '}\\n'\n    )\n    assert source == expected\n", "def test_c_with_printer():\n    #issue 13586\n    from sympy.printing.ccode import C99CodePrinter\n    class CustomPrinter(C99CodePrinter):\n            return \"fastpow({}, {})\".format(self._print(expr.base),\n                                            self._print(expr.exp))\n\n    x = Symbol('x')\n    gen = C99CodeGen(printer=CustomPrinter())\n\n    expected = (\n        '#include \"test.h\"\\n'\n        '#include <math.h>\\n'\n        'double test(double x) {\\n'\n        '   double test_result;\\n'\n        '   test_result = fastpow(x, 2);\\n'\n        '   return test_result;\\n'\n        '}\\n'\n    )\n\n    result = codegen(('test', x**2), header=False, empty=False, code_gen=gen)\n    source = result[0][1]\n    assert source == expected\n", "def test_julia_codegen():\n    x, y, z = symbols('x,y,z')\n    expr = (x + y)*z\n    routine = make_routine(\"test\", expr)\n    code_gen = JuliaCodeGen()\n    source = get_string(code_gen.dump_jl, [routine])\n    expected = (\n        'function test(x, y, z)\\n'\n        '   return z*(x + y)\\n'\n        'end\\n'\n    )\n    assert source == expected\n"], "sample_105": ["def test_voting_regressor_with_weights():\n    \"\"\"Check VotingRegressor with weights.\"\"\"\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([5, 6])\n\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(n_estimators=10, random_state=123)\n\n    ereg = VotingRegressor(estimators=[('lr', reg1), ('rf', reg2)],\n                           weights=[0.5, 0.5])\n    ereg.fit(X, y)\n\n    assert_array_almost_equal(ereg.predict(X),\n                              (reg1.fit(X, y).predict(X) +\n                               reg2.fit(X, y).predict(X)) / 2)\n", "def test_get_params():\n    \"\"\"Check that VotingClassifier and VotingRegressor get_params work\"\"\"\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    eclf = VotingClassifier(estimators=[\n                ('lr', clf1), ('rf', clf2)],\n                weights=[1, 2],\n                voting='soft')\n    params = eclf.get_params()\n    assert 'lr' in params\n    assert 'rf' in params\n    assert 'voting' in params\n    assert 'weights' in params\n\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor()\n    ereg = VotingRegressor(estimators=[\n                ('lr', reg1), ('rf', reg2)],\n                weights=[1, 2])\n    params = ereg.get_params()\n    assert 'lr' in params\n    assert 'rf' in params\n    assert 'weights' in params\n", "def test_voting_regressor_multivariate():\n    \"\"\"Check VotingRegressor on multivariate regression problem.\"\"\"\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([[1, 2], [3, 4], [5, 6]])\n\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(n_estimators=10, random_state=123)\n\n    ereg = VotingRegressor([('lr', reg1), ('rf', reg2)])\n    ereg.fit(X, y)\n    assert_array_equal(ereg.predict(X).shape, (3, 2))\n", "def test_voting_regressor_get_params():\n    \"\"\"Test VotingRegressor.get_params returns correct dict\"\"\"\n    reg1 = DummyRegressor(strategy='mean')\n    reg2 = DummyRegressor(strategy='median')\n    ereg = VotingRegressor([('mean', reg1), ('median', reg2)])\n\n    params = ereg.get_params()\n    assert 'estimators' in params\n    assert 'named_estimators' in params\n    assert 'weights' in params\n    assert 'n_jobs' in params\n\n    estimators = params['estimators']\n    assert len(estimators) == 2\n    assert estimators[0][0] == 'mean'\n    assert estimators[0][1] is reg1\n    assert estimators[1][0] == 'median'\n    assert estimators[1][1] is reg2\n\n    named_estimators = params['named_estimators']\n    assert len(named_estimators) == 2\n    assert named_estimators['mean'] is reg1\n    assert named_estimators['median'] is reg2\n", "def test_voting_regressor_transform():\n    \"\"\"Check transform method of VotingRegressor on toy dataset.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(random_state=123)\n    X = np.array([[-1.1, -1.5], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\n    y = np.array([1, 1, 2, 2])\n\n    ereg1 = VotingRegressor(estimators=[\n        ('lr', reg1), ('rf', reg2)]).fit(X, y)\n    ereg2 = VotingRegressor(estimators=[\n        ('lr', reg1), ('rf', reg2)],\n        n_jobs=2).fit(X, y)\n\n    assert_array_equal(ereg1.transform(X).shape, (4, 2))\n    assert_array_almost_equal(ereg1.transform(X),\n                              ereg2.transform(X))\n"], "sample_59": ["def test_add_fields_with_formset_kwargs(self):\n    \"\"\"The add_fields method receives the formset kwargs.\"\"\"\n\n    class BaseAddFieldFormSet(BaseFormSet):\n            super().add_fields(form, index)\n            form.fields[\"custom\"] = CharField(initial=self.formset_kwargs.get(\"custom\"))\n\n    AddFieldFormSet = formset_factory(Choice, formset=BaseAddFieldFormSet)\n    formset = AddFieldFormSet(formset_kwargs={\"custom\": \"value\"})\n    self.assertEqual(formset.forms[0].fields[\"custom\"].initial, \"value\")\n", "    def test_add_fields(self):\n        \"\"\"add_fields is called on each form in the formset.\"\"\"\n\n        class CustomBaseFormSet(BaseFormSet):\n                super().add_fields(form, index)\n                form.fields[\"custom\"] = CharField()\n\n        CustomChoiceFormSet = formset_factory(\n            Choice,\n            formset=CustomBaseFormSet,\n        )\n        formset = CustomChoiceFormSet()\n        for form in formset:\n            self.assertIn(\"custom\", form.fields)\n", "def test_add_fields_hook(self):\n    \"\"\"\n    FormSets have an add_fields() hook for adding extra fields on to each form.\n    \"\"\"\n    # Define a formset with a custom add_fields() hook.\n    class BaseDynamicFormSet(BaseFormSet):\n            super().add_fields(form, index)\n            form.fields[\"custom\"] = CharField()\n\n    DynamicFormSet = formset_factory(Choice, formset=BaseDynamicFormSet)\n    formset = DynamicFormSet()\n    # The custom field should be present in the form.\n    self.assertIn(\"custom\", formset.forms[0].fields)\n", "def test_add_fields_with_formset_kwargs(self):\n    class BaseDynamicFormSet(BaseFormSet):\n            super().add_fields(form, index)\n            form.fields[\"custom\"] = CharField()\n\n    DynamicFormSet = formset_factory(Choice, formset=BaseDynamicFormSet)\n    formset = DynamicFormSet()\n    for form in formset:\n        self.assertIn(\"custom\", form.fields)\n\n    # Make sure the fields are added with the correct prefix.\n    self.assertEqual(formset.forms[0].fields[\"custom\"].html_name, \"form-0-custom\")\n", "    def test_add_fields_with_can_delete(self):\n        ChoiceFormSet = formset_factory(Choice, can_delete=True)\n        formset = ChoiceFormSet()\n        for i, form in enumerate(formset.forms):\n            if i == 0:\n                self.assertIn(\"DELETE\", form.fields)\n            else:\n                self.assertNotIn(\"DELETE\", form.fields)\n"], "sample_141": ["def test_check_dimensions():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n    w = Quantity(\"w\")\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    w.set_global_relative_scale_factor(S(2), second)\n\n    assert check_dimensions(u + v) == u + v\n    raises(ValueError, lambda: check_dimensions(u + w))\n    raises(ValueError, lambda: check_dimensions(u - w))\n    raises(ValueError, lambda: check_dimensions(u + 1))\n    raises(ValueError, lambda: check_dimensions(u - 1))\n    raises(ValueError, lambda: check_dimensions(1 - exp(u / w)))\n", "def test_check_dimensions():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n    w = Quantity(\"w\")\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    w.set_global_relative_scale_factor(S(2), second)\n\n    assert check_dimensions(u + v) == u + v\n    assert check_dimensions(u - v) == u - v\n    raises(ValueError, lambda: check_dimensions(u + w))\n    raises(ValueError, lambda: check_dimensions(u - w))\n    raises(ValueError, lambda: check_dimensions(u + 1))\n    raises(ValueError, lambda: check_dimensions(u - 1))\n", "def test_check_dimensions():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n    w = Quantity(\"w\")\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    w.set_global_relative_scale_factor(S(2), second)\n\n    assert check_dimensions(u + v) == u + v\n    raises(ValueError, lambda: check_dimensions(u + w))\n    raises(ValueError, lambda: check_dimensions(u + 1))\n    raises(ValueError, lambda: check_dimensions(u - w))\n    raises(ValueError, lambda: check_dimensions(u - 1))\n    raises(ValueError, lambda: check_dimensions(1 - exp(u / w)))\n", "def test_quantity_simplify():\n    from sympy.physics.units import kilogram, meter, second\n    from sympy.physics.units.util import quantity_simplify\n\n    q = 10*kilogram*meter/second**2\n    assert quantity_simplify(q) == 10000*meter/second**2\n    assert quantity_simplify(kilogram + kilogram) == 2*kilogram\n    assert quantity_simplify(kilogram - kilogram) == 0\n    assert quantity_simplify(kilogram + 1) == kilogram + 1\n    assert quantity_simplify(foot + inch) == Rational(13, 12)*foot\n", "def test_check_dimensions():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n    w = Quantity(\"w\")\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    w.set_global_relative_scale_factor(S(2), second)\n\n    # test that no exception is raised for compatible dimensions\n    check_dimensions(u + v)\n    check_dimensions(u - v)\n    check_dimensions(u * w)\n\n    # test that an exception is raised for incompatible dimensions\n    raises(ValueError, lambda: check_dimensions(u + w))\n    raises(ValueError, lambda: check_dimensions(u - w))\n    raises(ValueError, lambda: check_dimensions(u / w + 1))\n"], "sample_140": ["def test_auto_point_vel_multiple_frame_path():\n    t = dynamicsymbols._t\n    q1, q2 = dynamicsymbols('q1 q2')\n    B = ReferenceFrame('B')\n    S = ReferenceFrame('S')\n    P = Point('P')\n    P.set_vel(B, q1 * B.x)\n    O = Point('O')\n    O.set_vel(S, q2 * S.y)\n    P1 = Point('P1')\n    P1.set_pos(P, q1 * B.y)\n    P1.set_pos(O, q2 * S.x)\n    assert P1.vel(B) == q1.diff(t) * B.y + q1 * B.x\n    assert P1.vel(S) == q2.diff(t) * S.x + q2 * S.y\n", "def test_point_vel_with_respect_to_multiple_frames():\n    q1, q2 = dynamicsymbols('q1 q2')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    O = Point('O')\n    P = Point('P')\n    P.set_pos(O, q1 * N.x)\n    O.set_vel(N, q2 * N.y)\n    P.set_vel(B, q1 * B.x)\n    assert P.vel(N) == q1.diff(dynamicsymbols._t) * N.x + q2 * N.y\n    assert P.vel(B) == q1 * B.x\n", "def test_point_vel_with_respect_to_itself():\n    N = ReferenceFrame('N')\n    P = Point('P')\n    assert P.vel(N) == 0\n    P.set_vel(N, 10 * N.x)\n    assert P.vel(N) == 10 * N.x\n    P2 = P.locatenew('P2', 0)\n    assert P2.vel(N) == 10 * N.x\n    P3 = Point('P3')\n    raises(ValueError, lambda: P3.vel(P3))\n", "def test_auto_point_vel_with_branching_tree():\n    t = dynamicsymbols._t\n    q1, q2, u1, u2 = dynamicsymbols('q1 q2 u1 u2')\n    B = ReferenceFrame('B')\n    P = Point('P')\n    P.set_vel(B, u1 * B.x)\n    P1 = Point('P1')\n    P1.set_pos(P, q2 * B.y)\n    P1.set_vel(B, q1 * B.z)\n    P2 = Point('P2')\n    P2.set_pos(P1, q1 * B.z)\n    P3 = Point('P3')\n    P3.set_pos(P2, 10 * q1 * B.y)\n    O = Point('O')\n    O.set_vel(B, u2 * B.y)\n    O1 = Point('O1')\n    O1.set_pos(O, q2 * B.z)\n    P3.set_pos(O1, q1 * B.x + q2 * B.z)\n    assert P3.vel(B) == q1.diff(t) * B.x + (u1 + u2) * B.y + 2 * q2.diff(t) * B.z\n", "def test_auto_point_vel_with_multiple_paths():\n    t = dynamicsymbols._t\n    q1, q2, u1, u2 = dynamicsymbols('q1 q2 u1 u2')\n    B = ReferenceFrame('B')\n    P = Point('P')\n    P.set_vel(B, u1 * B.x)\n    P1 = Point('P1')\n    P1.set_pos(P, q2 * B.y)\n    P1.set_vel(B, q1 * B.z)\n    P2 = Point('P2')\n    P2.set_pos(P1, q1 * B.z)\n    P3 = Point('P3')\n    P3.set_pos(P2, 10 * q1 * B.y)\n    P4 = Point('P4')\n    P4.set_pos(P3, q1 * B.x)\n    O = Point('O')\n    O.set_vel(B, u2 * B.y)\n    O1 = Point('O1')\n    O1.set_pos(O, q2 * B.z)\n    P4.set_pos(O1, q1 * B.x + q2 * B.z)\n    P5 = Point('P5')\n    P5.set_pos(O, q1 * B.x)\n    P5.set_vel(B, u2 * B.y)\n    assert P4.vel(B) == q1.diff(t) * B.x + u2 * B.y + 2 * q2.diff(t) * B.z\n    P4.set_pos(P5, q2 * B.y)\n    assert P4.vel(B) == q1.diff(t) * B.x + (u1 + u2) * B.y + q2.diff(t) * B.z\n"], "sample_28": ["    def setUpTestData(cls):\n        cls.u1 = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n", "    def setUpTestData(cls):\n        cls.u1 = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n", "    def setUp(self):\n        self.site = admin.AdminSite()\n", "    def setUpTestData(cls):\n        cls.u1 = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n", "    def setUpTestData(cls):\n        cls.u1 = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n"], "sample_20": ["    def test_model_name_clashes_with_lookup_syntax(self):\n        class _Model(models.Model):\n            pass\n\n        self.assertEqual(_Model.check(), [\n            Error(\n                \"The model name '_Model' cannot start or end with an underscore \"\n                \"as it collides with the query lookup syntax.\",\n                obj=_Model,\n                id='models.E023',\n            )\n        ])\n", "    def test_foreign_key_accessor_clash(self):\n        class Model(models.Model):\n            field = models.IntegerField()\n            fk = models.ForeignKey('self', models.CASCADE, related_name='field')\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"The field 'fk' clashes with the field 'field' from model \"\n                \"'invalid_models_tests.model'.\",\n                obj=Model._meta.get_field('fk'),\n                id='models.E006',\n            )\n        ])\n", "    def test_model_attribute(self):\n        class Model(models.Model):\n            pass\n\n        self.assertEqual(Model.check(), [])\n\n        # Add a model attribute that's not a field or manager.\n        Model.bad_attribute = 'foo'\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'Model' defines a model field or property 'bad_attribute' \"\n                \"which shadows a model attribute.\",\n                obj=Model,\n                id='models.E027',\n            ),\n        ])\n", "    def test_refresh_from_db_with_deferred_fields(self):\n        class Model(models.Model):\n            field1 = models.IntegerField()\n            field2 = models.IntegerField()\n\n        instance = Model(field1=1, field2=2)\n        instance.save()\n        instance.refresh_from_db(fields=['field1'])\n        self.assertEqual(instance.get_deferred_fields(), {'field2'})\n", "    def test_field_clashes_with_model_attribute(self):\n        class Model(models.Model):\n            clean = models.CharField(max_length=10)\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"The field 'clean' clashes with the model's attribute 'clean'.\",\n                obj=Model._meta.get_field('clean'),\n                id='models.E020',\n            )\n        ])\n"], "sample_98": ["def test_check_X_y():\n    X = np.random.rand(10, 2)\n    y = np.random.randint(0, 2, size=10)\n\n    # Test that check_X_y returns the original arrays if no conversion is needed\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(X, X_checked)\n    assert_array_equal(y, y_checked)\n\n    # Test that check_X_y raises an error if X and y have different lengths\n    X = np.random.rand(10, 2)\n    y = np.random.randint(0, 2, size=11)\n    assert_raises(ValueError, check_X_y, X, y)\n\n    # Test that check_X_y converts a list to a numpy array\n    X = [[1, 2], [3, 4]]\n    y = [0, 1]\n    X_checked, y_checked = check_X_y(X, y)\n    assert_true(isinstance(X_checked, np.ndarray))\n    assert_true(isinstance(y_checked, np.ndarray))\n\n    # Test that check_X_y handles multi-output correctly\n    X = np.random.rand(10, 2)\n    y = np.random.rand(10, 2)\n    X_checked, y_checked = check_X_y(X, y, multi_output=True)\n    assert_array_equal(X, X_checked)\n    assert_array_equal(y, y_checked)\n\n    # Test that check_X_y raises an error if y is not 1D when multi_output=False\n    X = np.random.rand(10, 2)\n    y = np.random.rand(10, 2)\n    assert_raises(ValueError, check_X_y, X, y)\n\n    # Test that check_X_y handles pandas DataFrames correctly\n    pd = importorskip('pandas')\n    X = pd.DataFrame(np.random.rand(10, 2))\n    y = pd.Series(np.random.randint(0, 2, size=10))\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(X.values, X_checked)\n    assert_array_equal(y.values, y_checked)\n", "def test_indexable():\n    check_consistent_length([1, 2, 3], np.array([4, 5, 6]), \"hello\")\n    assert_raises_regex(TypeError, r\"got <\\w+ 'int'>\",\n                        check_consistent_length, [1, 2], 3)\n    assert_raises_regex(ValueError, 'inconsistent numbers of samples',\n                        check_consistent_length, [1, 2], [1])\n\n    X = [[1, 2], [3, 4]]\n    y = [5, 6]\n    out_X, out_y = indexable(X, y)\n    assert_true(isinstance(out_X, np.ndarray))\n    assert_array_equal(out_X, X)\n    assert_true(isinstance(out_y, np.ndarray))\n    assert_array_equal(out_y, y)\n\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([5, 6])\n    out_X, out_y = indexable(X, y)\n    assert_true(out_X is X)\n    assert_true(out_y is y)\n\n    X = sp.csr_matrix(np.array([[1, 2], [3, 4]]))\n    y = np.array([5, 6])\n    out_X, out_y = indexable(X, y)\n    assert_true(sp.issparse(out_X))\n    assert_array_equal(out_X.toarray(), X.toarray())\n    assert_true(out_y is y)\n\n    X = MockDataFrame(np.array([[1, 2], [3, 4]]))\n    y = MockDataFrame(np.array([5, 6]))\n    out_X, out_y = indexable(X, y)\n    assert_true(isinstance(out_X, MockDataFrame))\n    assert_array_equal(out_X, X)\n    assert_true(isinstance(out_y, MockDataFrame))\n    assert_array_equal(out_y, y)\n", "def test_check_X_y_length_mismatch():\n    # Check that check_X_y raises a ValueError if X and y have different lengths\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([0, 0])\n    msg = \"Found input variables with inconsistent numbers of samples: [3, 2]\"\n    assert_raise_message(ValueError, msg, check_X_y, X, y)\n", "def test_check_array_with_nans():\n    X = np.array([[1, 2], [np.nan, 3]])\n    assert_raises_regex(ValueError, \"Input contains NaN\", check_array, X)\n\n    X = np.array([[1, 2], [np.nan, 3]])\n    X_checked = check_array(X, force_all_finite=False)\n    assert_array_equal(X_checked, X)\n\n    X = sp.csr_matrix(np.array([[1, 2], [np.nan, 3]]))\n    assert_raises_regex(ValueError, \"Input contains NaN\", check_array, X)\n\n    X = sp.csr_matrix(np.array([[1, 2], [np.nan, 3]]))\n    X_checked = check_array(X, force_all_finite=False, accept_sparse=True)\n    assert_array_equal(X_checked.toarray(), X.toarray())\n", "def test_check_X_y_length_error():\n    # Test that check_X_y raises a ValueError if X and y have different lengths.\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([0, 0])\n    msg = \"Found input variables with inconsistent numbers of samples: [3, 2]\"\n    assert_raise_message(ValueError, msg, check_X_y, X, y)\n"], "sample_45": ["    def test_sync_and_async_middleware(self):\n        @sync_and_async_middleware\n            return get_response\n\n        self.assertTrue(middleware.sync_capable)\n        self.assertTrue(middleware.async_capable)\n", "    def test_sync_and_async_middleware(self):\n        @sync_and_async_middleware\n            return get_response\n\n        self.assertTrue(my_middleware.sync_capable)\n        self.assertTrue(my_middleware.async_capable)\n", "    def test_sync_and_async_middleware_decorator(self):\n        @sync_and_async_middleware\n            return get_response\n\n        self.assertTrue(my_middleware.sync_capable)\n        self.assertTrue(my_middleware.async_capable)\n", "    def test_sync_and_async_middleware(self):\n        @sync_and_async_middleware\n            return get_response\n\n        self.assertTrue(my_middleware.sync_capable)\n        self.assertTrue(my_middleware.async_capable)\n", "    def test_sync_only_middleware(self):\n        \"\"\"Test method_decorator with sync-only middleware\"\"\"\n        @sync_only_middleware\n                return True\n            return _wrapper\n\n        @method_decorator(deco, name=\"method\")\n        class Test:\n                return False\n\n        self.assertTrue(Test().method())\n"], "sample_11": ["def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return 'complex(%r)' % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n    self.assertEqual(Serializer._registry[complex], ComplexSerializer)\n\n    Serializer.unregister(complex)\n    self.assertNotIn(complex, Serializer._registry)\n", "def test_unregister_serializer(self):\n    class TestSerializer(BaseSerializer):\n            return 'test(%r)' % self.value, {}\n\n    Serializer.register(complex, TestSerializer)\n    Serializer.unregister(complex)\n\n    with self.assertRaisesMessage(ValueError, \"Cannot serialize: (1+1j)\"):\n        MigrationWriter.serialize(1 + 1j)\n", "def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return 'complex(%r)' % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n    Serializer.unregister(complex)\n\n    with self.assertRaisesMessage(ValueError, \"Cannot serialize: (1+1j)\"):\n        MigrationWriter.serialize(1 + 1j)\n", "def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return 'complex(%r)' % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n    Serializer.unregister(complex)\n\n    with self.assertRaisesMessage(ValueError, \"Cannot serialize: (1+1j)\\n\"):\n        MigrationWriter.serialize(1 + 1j)\n", "def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return 'complex(%r)' % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n    try:\n        string = MigrationWriter.serialize(complex(1, 2))[0]\n        self.assertEqual(string, \"complex((1+2j))\")\n        Serializer.unregister(complex)\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize: (1+2j)'):\n            MigrationWriter.serialize(complex(1, 2))\n    finally:\n        Serializer.unregister(complex)\n"], "sample_107": ["def test_logistic_regression_path_multinomial_n_classes():\n    # Test that the shape of coefs returned by logistic_regression_path when\n    # multi_class='multinomial' is correct for different number of classes.\n    \n    X, y = make_classification(n_samples=200, n_classes=3, n_informative=2,\n                               n_redundant=0, n_clusters_per_class=1,\n                               random_state=0, n_features=2)\n    Cs = [.00001, 1, 10000]\n    \n    # Binary classification\n    y_bin = y == 0\n    coefs_bin, _, _ = _logistic_regression_path(X, y_bin, penalty='l1', Cs=Cs,\n                                                solver='saga', random_state=0,\n                                                multi_class='multinomial')\n    assert coefs_bin.shape == (1, len(Cs), X.shape[1] + 1)\n    \n    # Multiclass classification with 3 classes\n    coefs_multi, _, _ = _logistic_regression_path(X, y, penalty='l1', Cs=Cs,\n                                                  solver='saga', random_state=0,\n                                                  multi_class='multinomial')\n    assert coefs_multi.shape == (3, len(Cs), X.shape[1] + 1)\n", "def test_logistic_regression_path_multiclass_ill_conditioned():\n    # Test that logistic_regression_path converges on an ill-conditioned\n    # multiclass problem\n\n    # Create an ill-conditioned multiclass problem by duplicating features\n    X, y = make_classification(n_samples=200, n_classes=3, n_informative=2,\n                               n_redundant=0, n_clusters_per_class=1,\n                               random_state=0, n_features=2)\n    X = np.hstack((X, X))\n\n    Cs = [.00001, 1, 10000]\n    coefs, _, _ = _logistic_regression_path(X, y, penalty='l1', Cs=Cs,\n                                            solver='saga', random_state=0,\n                                            multi_class='multinomial')\n\n    assert not np.allclose(coefs[0], coefs[1], atol=1e-10)\n    assert not np.allclose(coefs[0], coefs[2], atol=1e-10)\n    assert not np.allclose(coefs[1], coefs[2], atol=1e-10)\n", "compilation error", "def test_logistic_regression_max_iter():\n    # Test that the maximum number of iteration is reached\n    X, y = iris.data, iris.target\n    clf = LogisticRegression(max_iter=1, multi_class='ovr', solver='lbfgs')\n    msg = \"Solver failed to converge. (Converged at iteration 1).\"\n    with pytest.warns_message(ConvergenceWarning, message=msg):\n        clf.fit(X, y)\n    assert clf.n_iter_[0] == 1\n", "def test_logistic_regressioncv_max_iter():\n    # Test that the maximum number of iteration is reached\n    X, y_bin = iris.data, iris.target.copy()\n    y_bin[y_bin == 2] = 0\n\n    solvers = ['newton-cg', 'liblinear', 'sag', 'saga', 'lbfgs']\n\n    for max_iter in range(1, 5):\n        for solver in solvers:\n            for multi_class in ['ovr', 'multinomial']:\n                if solver == 'liblinear' and multi_class == 'multinomial':\n                    continue\n                lr = LogisticRegressionCV(max_iter=max_iter, tol=1e-15,\n                                          multi_class=multi_class,\n                                          random_state=0, solver=solver)\n                assert_warns(ConvergenceWarning, lr.fit, X, y_bin)\n                assert_equal(lr.n_iter_[0], max_iter)\n"], "sample_49": ["def test_reset_loaders_with_locmem_loader(self):\n    with mock.patch('django.template.loaders.base.Loader.reset') as mock_reset:\n        autoreload.reset_loaders()\n        self.assertEqual(mock_reset.call_count, 2)\n", "    def test_reset_locmem_loader(self, mock_reset):\n        autoreload.reset_loaders()\n        mock_reset.assert_called_once()\n", "def test_get_template_directories_with_locmem_loader(self):\n    self.assertSetEqual(\n        autoreload.get_template_directories(),\n        {\n            EXTRA_TEMPLATES_DIR,\n            ROOT / 'templates',\n        }\n    )\n", "def test_get_template_directories_with_loader_without_get_dirs(self):\n    self.assertSetEqual(\n        autoreload.get_template_directories(),\n        {\n            EXTRA_TEMPLATES_DIR,\n            ROOT / 'templates',\n        }\n    )\n", "def test_template_changed_with_non_template_file(self, mock_reset):\n    template_path = Path(__file__).parent / 'templates' / 'non_template.txt'\n    self.assertTrue(autoreload.template_changed(None, template_path))\n    mock_reset.assert_called_once()\n"], "sample_5": ["def test_delete_with_inheritance_and_related(self):\n    rchild = RChild.objects.create()\n    s = S.objects.create(r=rchild.r_ptr)\n    t1 = T.objects.create(s=s)\n    t2 = T.objects.create(s=s)\n    self.assertEqual(R.objects.count(), 1)\n    self.assertEqual(RChild.objects.count(), 1)\n    self.assertEqual(S.objects.count(), 1)\n    self.assertEqual(T.objects.count(), 2)\n\n    rchild.delete()\n\n    self.assertEqual(R.objects.count(), 0)\n    self.assertEqual(RChild.objects.count(), 0)\n    self.assertEqual(S.objects.count(), 0)\n    self.assertEqual(T.objects.count(), 0)\n", "def test_deleteCollector_sort(self):\n    # Test Collector.sort() method to ensure proper ordering of models for deletion.\n    r = R.objects.create()\n    a1 = A.objects.create(setnull=r)\n    a2 = A.objects.create(cascade=r)\n\n    collector = Collector(using='default')\n    collector.add([a1, a2])\n    collector.collect([r])\n\n    collector.sort()\n\n    self.assertEqual(collector.data, {A: {a1, a2}, R: {r}})\n", "def test_can_fast_delete_with_m2m_through_model(self):\n    m = M.objects.create()\n    r = R.objects.create()\n    MR.objects.create(m=m, r=r)\n    collector = Collector(using='default')\n    self.assertFalse(collector.can_fast_delete(m))\n    self.assertFalse(collector.can_fast_delete(r))\n    m.delete()\n    self.assertFalse(MR.objects.exists())\n    self.assertFalse(M.objects.exists())\n", "def test_can_fast_delete_with_reverse_dependency(self):\n    # Testing that can_fast_delete returns False when there's a reverse dependency.\n    collector = Collector(using='default')\n    u = User.objects.create()\n    self.assertTrue(collector.can_fast_delete(u))\n    a = Avatar.objects.create(user=u)\n    self.assertFalse(collector.can_fast_delete(u))\n", "def test_collector_sort(self):\n    collector = Collector(using='default')\n    models = [M, R, A]\n    collector.data = {model: [] for model in models}\n    collector.dependencies = {\n        M._meta.concrete_model: {R._meta.concrete_model},\n        R._meta.concrete_model: {A._meta.concrete_model},\n    }\n    collector.sort()\n    self.assertEqual(list(collector.data.keys()), [A, R, M])\n"], "sample_158": ["def test_unit_system_get_default():\n    assert UnitSystem.get_default_unit_system() == UnitSystem._unit_systems[\"SI\"]\n", "def test_get_units_non_prefixed():\n    assert set(SI.get_units_non_prefixed()) == {\n        meter, second, joule, day, volt, ohm, elementary_charge, vacuum_permittivity,\n        molar_gas_constant, kilogram  # Note: kilogram is not prefixed in SI system\n    }\n    cgs = SI.extend(base=(centimeter,), name='cgs')\n    assert set(cgs.get_units_non_prefixed()) == {\n        centimeter, second, joule, day, volt, ohm, elementary_charge, vacuum_permittivity,\n        molar_gas_constant\n    }\n", "def test_unit_system_get_default():\n    default_unit_system = UnitSystem.get_default_unit_system()\n    assert default_unit_system == SI\n    assert default_unit_system.name == \"SI\"\n", "def test_get_units_non_prefixed():\n    assert set(SI.get_units_non_prefixed()) == {\n        meter, second, kilogram, ampere, kelvin, mole, candela,\n        # angles\n        radian, steradian,\n        # EM\n        coulomb, volt, ohm, siemens, farad, henry, weber, tesla,\n        # Other\n        newton, joule, watt, pascal, hertz, lux, becquerel, gray, sievert, katal\n    }\n", "def test_unit_system_get_dimensional_expr():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n    w = Quantity(\"w\")\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    w.set_global_relative_scale_factor(S(2), second)\n\n    assert SI.get_dimensional_expr(u) == length.name\n    assert SI.get_dimensional_expr(v) == length.name\n    assert SI.get_dimensional_expr(w) == time.name\n\n    expr = u + v\n    assert SI.get_dimensional_expr(expr) == length.name\n\n    expr = u * w\n    assert SI.get_dimensional_expr(expr) == (length * time).name\n"], "sample_55": ["def test_suppressed_base_arguments(self):\n    class Command(BaseCommand):\n        suppressed_base_arguments = {\"--version\", \"--help\"}\n\n    parser = Command().create_parser(\"prog_name\", \"subcommand\")\n    actions = [action for action in parser._actions if action.dest == \"version\"]\n    self.assertEqual(len(actions), 1)\n    self.assertEqual(actions[0].help, argparse.SUPPRESS)\n", "def test_suppressed_base_arguments(self):\n    parser = BaseCommand()\n    parser.suppressed_base_arguments = {\"--version\"}\n    parser.create_parser(\"prog_name\", \"subcommand\")\n    help_text = parser.create_parser(\"prog_name\", \"subcommand\").format_help()\n    self.assertNotIn(\"--version\", help_text)\n", "def test_command_parser_called_from_command_line(self):\n    parser = BaseCommand().create_parser(\"prog_name\", \"subcommand\")\n    self.assertIs(parser.called_from_command_line, None)\n    parser = BaseCommand(_called_from_command_line=True).create_parser(\n        \"prog_name\", \"subcommand\"\n    )\n    self.assertIs(parser.called_from_command_line, True)\n", "def test_find_commands(self):\n    \"\"\"\n    find_commands should return a list of valid commands in the given path.\n    \"\"\"\n    commands_dir = os.path.join(os.path.dirname(__file__), \"management\", \"commands\")\n    commands = find_commands(commands_dir)\n    self.assertIn(\"dance\", commands)\n    self.assertNotIn(\"__init__.py\", commands)\n    self.assertNotIn(\"__pycache__\", commands)\n", "def test_base_command_add_arguments(self):\n    class TestCommand(BaseCommand):\n            parser.add_argument(\"--foo\", action=\"store_true\")\n\n    cmd = TestCommand()\n    parser = cmd.create_parser(\"prog_name\", \"subcommand\")\n    options = parser.parse_args([\"--foo\"])\n    self.assertTrue(options.foo)\n"], "sample_95": ["def test_xfail_strict_from_ini(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        xfail_strict = True\n        \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail\n            pass\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n", "def test_xfail_strict_from_ini(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        xfail_strict = True\n    \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.xfail\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n", "def test_importorskip_with_minversion() -> None:\n    with pytest.raises(pytest.skip.Exception, match=\"^need 'sys' >= 100.0, have 3.*\"):\n        pytest.importorskip(\"sys\", minversion=\"100.0\")\n", "def test_importorskip_with_minversion() -> None:\n    with pytest.raises(\n        pytest.skip.Exception,\n        match=\"^could not import 'sys' with minversion 999: module version 3.* is too old\",\n    ):\n        pytest.importorskip(\"sys\", minversion=\"999\")\n", "def test_importorskip_with_reason() -> None:\n    with pytest.raises(\n        pytest.skip.Exception,\n        match=\"^could not import 'doesnotexist': No module named .*\",\n    ):\n        pytest.importorskip(\"doesnotexist\", reason=\"Custom reason\")\n"], "sample_106": ["def test_components_shape():\n    \"\"\"Test that the components have the expected shape.\"\"\"\n    X = iris_data\n    y = iris_target\n\n    nca = NeighborhoodComponentsAnalysis(n_components=2)\n    nca.fit(X, y)\n    assert_equal(nca.components_.shape, (2, X.shape[1]))\n", "def test_labels_validation():\n    # Test that invalid labels raise value error\n    X = np.arange(12).reshape(4, 3)\n    y = [1, 1, 2, 3]\n    NCA = NeighborhoodComponentsAnalysis\n\n    # non-integer labels\n    y = [1.5, 1, 2, 2]\n    assert_raises(ValueError, NCA().fit, X, y)\n\n    # non-numeric labels\n    y = ['a', 'b', 'c', 'd']\n    assert_raises(ValueError, NCA().fit, X, y)\n\n    # non-unique labels\n    y = [1, 1, 1, 1]\n    assert_raises(ValueError, NCA().fit, X, y)\n\n    # labels with negative values\n    y = [-1, 0, 1, 2]\n    assert_raises(ValueError, NCA().fit, X, y)\n\n    # valid labels\n    y = [1, 1, 2, 2]\n    NCA().fit(X, y)\n", "def test_components_shape():\n    \"\"\"Test that the learned components have the correct shape.\"\"\"\n    X = iris_data\n    y = iris_target\n\n    nca = NeighborhoodComponentsAnalysis(n_components=None)\n    nca.fit(X, y)\n    assert_array_equal(nca.components_.shape, (X.shape[1], X.shape[1]))\n\n    nca = NeighborhoodComponentsAnalysis(n_components=2)\n    nca.fit(X, y)\n    assert_array_equal(nca.components_.shape, (2, X.shape[1]))\n", "def test_check_grad():\n    # Test gradient of loss function\n\n    rng = np.random.RandomState(42)\n    X, y = make_classification()\n    M = rng.randn(rng.randint(1, X.shape[1] + 1),\n                  X.shape[1])\n    nca = NeighborhoodComponentsAnalysis()\n    nca.n_iter_ = 0\n    mask = y[:, np.newaxis] == y[np.newaxis, :]\n\n        return nca._loss_grad_lbfgs(M, X, mask)[0]\n\n        return nca._loss_grad_lbfgs(M, X, mask)[1]\n\n    # compute relative error\n    rel_diff = check_grad(fun, grad, M.ravel()) / np.linalg.norm(grad(M))\n    np.testing.assert_almost_equal(rel_diff, 0., decimal=5)\n", "def test_components_shape():\n    \"\"\"Test that the components_ attribute has the correct shape.\"\"\"\n    X = iris_data\n    y = iris_target\n    n_components = 2\n    nca = NeighborhoodComponentsAnalysis(n_components=n_components)\n    nca.fit(X, y)\n    assert_equal(nca.components_.shape, (n_components, X.shape[1]))\n"], "sample_90": ["def test_mark_evaluator_get_closest_mark_with_reason():\n    class DummyItem:\n        keywords = [\"mark1\", \"mark2\"]\n        _keywords = {\"mark1\": Mark(\"mark1\", (), {\"reason\": \"Some reason\"})}\n\n    item = DummyItem()\n    evaluator = MarkEvaluator(item, \"mark1\")\n\n    mark = evaluator.get_closest_marker(\"mark1\")\n    assert mark.kwargs[\"reason\"] == \"Some reason\"\n", "def test_mark_evaluator_getexplanation():\n    item = mock.Mock()\n    item.keywords = [\"foo\", \"bar\"]\n    item.nodeid = \"test_node\"\n    evaluator = MarkEvaluator(item, \"foo\")\n    assert evaluator.getexplanation() == \"\"\n    evaluator.reason = \"some reason\"\n    assert evaluator.getexplanation() == \"some reason\"\n    evaluator.expr = \"some expr\"\n    assert evaluator.getexplanation() == \"condition: some expr\"\n", "def test_MarkEvaluator_getexplanation():\n    item = mock.Mock(spec=Item, nodeid=\"test_item\")\n    item.keywords = []\n    evaluator = MarkEvaluator(item, \"test_mark\")\n    mark = Mark(name=\"test_mark\", args=(), kwargs={\"reason\": \"some reason\"})\n    item.iter_markers.return_value = [mark]\n    assert evaluator.getexplanation() == \"some reason\"\n    del mark.kwargs[\"reason\"]\n    assert evaluator.getexplanation() == \"\"\n    mark.args = (\"condition\",)\n    assert evaluator.getexplanation() == \"condition: condition\"\n", "def test_mark_evaluator_with_bool_expr(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.skipif(True or False)\n            assert True\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.assert_outcomes(skipped=1)\n", "def test_mark_evaluator_istrue():\n    class DummyItem:\n            self.name = name\n\n            if name == \"mark_name\":\n                return [Mark(name=\"mark_name\", args=(\"condition\",))]\n            else:\n                return []\n\n    item = DummyItem(\"test_item\")\n    evaluator = MarkEvaluator(item, \"mark_name\")\n\n    assert evaluator.istrue() is True\n\n    # test with condition\n    item = DummyItem(\"test_item\")\n    evaluator = MarkEvaluator(item, \"mark_name\")\n    evaluator._marks = [Mark(name=\"mark_name\", args=(\"condition\",), kwargs={\"condition\": \"True\"})]\n    assert evaluator.istrue() is True\n\n    # test with false condition\n    item = DummyItem(\"test_item\")\n    evaluator = MarkEvaluator(item, \"mark_name\")\n    evaluator._marks = [Mark(name=\"mark_name\", args=(\"condition\",), kwargs={\"condition\": \"False\"})]\n    assert evaluator.istrue() is False\n\n    # test with exception in condition\n    item = DummyItem(\"test_item\")\n    evaluator = MarkEvaluator(item, \"mark_name\")\n    evaluator._marks = [Mark(name=\"mark_name\", args=(\"condition\",), kwargs={\"condition\": \" invalid syntax\"})]\n    assert evaluator.istrue() is False\n"], "sample_74": ["def test_colorbar_set_label():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cb = fig.colorbar(im)\n    cb.set_label('Test Label')\n    assert cb.ax.get_ylabel() == 'Test Label'\n    cb.set_label(None)\n    assert cb.ax.get_ylabel() == ''\n    cb.set_label('Test Label 2', loc='top')\n    assert cb.ax.get_ylabel() == 'Test Label 2'\n    assert cb.ax.yaxis.get_label_position() == 'top'\n", "def test_colorbar_no_ticks():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    fig.colorbar(im, ticks=[])\n", "def test_colorbar_orientation_location():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    for loc in ['left', 'right', 'top', 'bottom']:\n        cbar = fig.colorbar(im, location=loc)\n        assert cbar.orientation == _get_orientation_from_location(loc)\n", "def test_colorbar_log_norm():\n    fig, ax = plt.subplots()\n    data = np.logspace(-3, 3, 100)\n    im = ax.imshow(data[:, None], norm=LogNorm(), cmap='viridis')\n    cb = fig.colorbar(im)\n    assert isinstance(cb.locator, ticker.LogLocator)\n    assert isinstance(cb.formatter, ticker.LogFormatter)\n", "def test_colorbar_label_rotation():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cb = fig.colorbar(im)\n    cb.set_label('Label', rotation=45)\n"], "sample_85": ["def test_log_file_path_traversal(testdir):\n    log_file = \"../log_file.log\"\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = INFO\n        \"\"\".format(\n            log_file\n        )\n    )\n\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logging.getLogger().info(\"Normal message\")\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n    assert result.ret == 0\n    log_file_path = testdir.tmpdir.join(log_file).strpath\n    assert os.path.isfile(log_file_path)\n    with open(log_file_path, encoding=\"utf-8\") as rfh:\n        contents = rfh.read()\n        assert \"Normal message\" in contents\n", "def test_log_cli_format(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_handler.formatter._fmt == '%(levelname)s %(message)s'\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n        log_cli_format=%(levelname)s %(message)s\n    \"\"\"\n    )\n\n    result = testdir.runpytest(\"-s\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_log_cli_format.py* This log message will be shown\",\n            \"PASSED\",  # 'PASSED' on its own line because the log message prints a new line\n        ]\n    )\n    assert result.ret == 0\n", "def test_set_log_path(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            plugin.set_log_path('%s')\n            assert plugin.log_file_handler.baseFilename == '%s'\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\" % (log_file, log_file)\n    )\n\n    result = testdir.runpytest(\"-s\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines([\"test_set_log_path.py PASSED\"])\n\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert \"This log message will be shown\" in contents\n", "def test_log_format_with_color(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logging.warning(\"Warning message\")\n            logging.info(\"Info message\")\n            logging.debug(\"Debug message\")\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--log-cli-level=DEBUG\", \"--color=yes\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*-- live log call --*\",\n            \"*WARNING*Warning message*\",\n            \"*INFO*Info message*\",\n            \"*DEBUG*Debug message*\",\n            \"PASSED*\",\n        ]\n    )\n", "def test_log_in_runtest_teardown(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = INFO\n        log_cli=true\n        \"\"\".format(\n            log_file\n        )\n    )\n    testdir.makeconftest(\n        \"\"\"\n        import logging\n        logger = logging.getLogger(__name__)\n\n            logger.info(\"teardown\")\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n                assert True\n        \"\"\"\n    )\n    testdir.runpytest()\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert \"teardown\" in contents\n"], "sample_27": ["def test_token_with_legacy_hashing_algorithm(self):\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    generator = PasswordResetTokenGenerator()\n    generator.algorithm = 'sha256'\n    token = generator.make_token(user)\n    # Check that the legacy hashing algorithm is used when checking the token.\n    with self.settings(DEFAULT_HASHING_ALGORITHM='sha1'):\n        self.assertIs(generator.check_token(user, token), True)\n", "def test_token_with_legacy_hashing_algorithm(self):\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    generator = PasswordResetTokenGenerator()\n    generator.algorithm = 'sha256'\n    token = generator.make_token(user)\n    # Simulate a legacy token by changing the algorithm to sha1\n    legacy_generator = PasswordResetTokenGenerator()\n    legacy_generator.algorithm = 'sha1'\n    legacy_token = legacy_generator._make_token_with_timestamp(user, self._num_seconds(datetime.now()), legacy=True)\n    self.assertIs(generator.check_token(user, legacy_token), True)\n    self.assertIs(legacy_generator.check_token(user, token), False)\n", "def test_token_with_different_algorithm(self):\n    \"\"\"\n    A valid token can be created with a different algorithm by\n    using the PasswordResetTokenGenerator.algorithm attribute.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    new_algorithm = 'md5'\n    # Create and check a token with a different algorithm.\n    p0 = PasswordResetTokenGenerator()\n    p0.algorithm = new_algorithm\n    tk0 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk0), True)\n    # Create and check a token with the default algorithm.\n    p1 = PasswordResetTokenGenerator()\n    self.assertEqual(p1.algorithm, settings.DEFAULT_HASHING_ALGORITHM)\n    self.assertNotEqual(p1.algorithm, new_algorithm)\n    tk1 = p1.make_token(user)\n    # Tokens created with a different algorithm don't validate.\n    self.assertIs(p0.check_token(user, tk1), False)\n    self.assertIs(p1.check_token(user, tk0), False)\n", "def test_token_with_legacy_hashing_algorithm(self):\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    generator = PasswordResetTokenGenerator()\n    generator.algorithm = 'sha256'\n    token = generator.make_token(user)\n    # Simulate a legacy token created with the old hashing algorithm (sha1).\n    legacy_generator = PasswordResetTokenGenerator()\n    legacy_generator.algorithm = 'sha1'\n    legacy_token = legacy_generator.make_token(user)\n    self.assertNotEqual(token, legacy_token)\n    # The check_token method should still validate the legacy token.\n    self.assertIs(generator.check_token(user, legacy_token), True)\n", "def test_make_token_with_timestamp_legacy(self):\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    ts = self._num_seconds(datetime.now())\n    tk1 = p0._make_token_with_timestamp(user, ts)\n    tk2 = p0._make_token_with_timestamp(user, ts, legacy=True)\n    self.assertNotEqual(tk1, tk2)\n    self.assertIs(p0.check_token(user, tk2), True)\n"], "sample_39": ["    def test_check_pattern_name(self):\n        msg = \"URL route 'view-name:with-colon' is invalid. ':' is not allowed in names.\"\n        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n            URLPattern(RegexPattern(r'^test/$'), views.empty_view, name='view-name:with-colon').check()\n", "    def test_resolver404_repr(self):\n        exception = Resolver404({'tried': [], 'path': '/test/'})\n        self.assertEqual(repr(exception), \"Resolver404({'tried': [], 'path': '/test/'}\")\n", "    def test_pattern_name_without_colon(self):\n        msg = \"URL pattern name 'view-name:arg' may not contain a colon.\"\n        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n            path('pattern/', views.empty_view, name='view-name:arg')\n", "    def test_lazy_compilation(self):\n        resolver = get_resolver()\n        pattern = RegexPattern(r'^test/')\n        self.assertIsInstance(pattern.regex, LocaleRegexDescriptor)\n        self.assertEqual(pattern.regex.__get__(pattern), re.compile(r'^test/'))\n", "    def test_warning_for_pattern_name_with_colon(self):\n        msg = (\n            \"URL route name 'view-name:with-colon' may cause conflicts if \"\n            \"used as a named route. Use only characters that are valid in \"\n            \"Python identifiers.\"\n        )\n        with self.assertWarnsMessage(Warning, msg):\n            check_resolver(get_resolver())\n"], "sample_144": ["def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[0, 0], Q.symmetric(X)) == X[0, 0]\n", "def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 1], Q.symmetric(X)) == X[1, 1]\n    Y = MatrixSymbol('Y', 2, 3)\n    assert refine(Y[0, 1], Q.symmetric(Y)) == Y[0, 1]\n", "def test_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[0, 0], Q.symmetric(X)) == X[0, 0]\n", "def test_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n", "def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n"], "sample_31": ["def test_shell_with_all_interfaces_not_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import python interface.\"):\n        call_command('shell')\n", "def test_shell_with_bpython_not_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import bpython interface.\"):\n        call_command('shell', interface='bpython')\n", "def test_shell_with_no_backend_available(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import python interface.\"):\n        call_command('shell')\n", "def test_shell_with_bpython_not_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import bpython interface.\"):\n        call_command('shell', interface='bpython')\n", "def test_no_startup_option(self, select):\n    with captured_stdout() as stdout:\n        call_command('shell', no_startup=True, command='print(\"Hello World\")')\n    self.assertEqual(stdout.getvalue().strip(), 'Hello World')\n    # Check that no startup file was executed\n    with mock.patch('os.path.isfile') as isfile:\n        isfile.return_value = True\n        with mock.patch('builtins.open') as open_mock:\n            call_command('shell', no_startup=True)\n            open_mock.assert_not_called()\n"], "sample_64": ["def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should generate JavaScript code for\n    prepopulated fields in the admin form and inlines.\n    \"\"\"\n    request = self.request_factory.get(\n        reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n    )\n    request.user = self.superuser\n    admin = UserAdmin(User, site)\n    response = admin.change_view(request, str(self.superuser.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIn(\"prepopulated_fields_json\", template_context)\n    self.assertIsInstance(template_context[\"prepopulated_fields_json\"], str)\n    self.assertJSONEqual(template_context[\"prepopulated_fields_json\"], [])\n", "def test_cell_count(self):\n    modeladmin = ModelAdmin(Article, site)\n    inline_admin_form = modeladmin.get_inline_formsets()[0](self.request, Article())\n    self.assertEqual(cell_count(inline_admin_form), 3)\n\n    # Add a field to the inline formset\n    modeladmin.inlines[0].fields = ('field1', 'field2')\n    inline_admin_form = modeladmin.get_inline_formsets()[0](self.request, Article())\n    self.assertEqual(cell_count(inline_admin_form), 4)\n\n    # Make one of the fields hidden\n    modeladmin.inlines[0].fields = ('field1', 'field2')\n    modeladmin.inlines[0].fields['field1'].widget.is_hidden = True\n    inline_admin_form = modeladmin.get_inline_formsets()[0](self.request, Article())\n    self.assertEqual(cell_count(inline_admin_form), 3)\n\n    # Test can_delete\n    modeladmin.inlines[0].can_delete = True\n    inline_admin_form = modeladmin.get_inline_formsets()[0](self.request, Article())\n    self.assertEqual(cell_count(inline_admin_form), 4)\n", "def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should create a list of\n    prepopulated fields for the admin form and inlines.\n    \"\"\"\n    request = self.request_factory.get(\n        reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n    )\n    request.user = self.superuser\n    admin = UserAdmin(User, site)\n    response = admin.change_view(request, str(self.superuser.pk))\n    context = prepopulated_fields_js(response.context_data)\n    self.assertIn(\"prepopulated_fields\", context)\n    self.assertIn(\"prepopulated_fields_json\", context)\n    self.assertIsInstance(context[\"prepopulated_fields\"], list)\n    self.assertIsInstance(context[\"prepopulated_fields_json\"], str)\n", "def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should create a JSON object with\n    the prepopulated fields' details.\n    \"\"\"\n    admin = UserAdmin(User, site)\n    request = self.request_factory.get(\n        reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n    )\n    request.user = self.superuser\n    response = admin.change_view(request, str(self.superuser.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIn(\"prepopulated_fields_json\", template_context)\n    self.assertIsInstance(template_context[\"prepopulated_fields_json\"], str)\n    try:\n        json.loads(template_context[\"prepopulated_fields_json\"])\n    except ValueError:\n        self.fail(\"prepopulated_fields_json is not valid JSON\")\n", "def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should return a context with \n    prepopulated fields and their dependencies.\n    \"\"\"\n    request = self.request_factory.get(\n        reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n    )\n    request.user = self.superuser\n    admin = UserAdmin(User, site)\n    response = admin.change_view(request, str(self.superuser.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIn(\"prepopulated_fields\", template_context)\n    self.assertIn(\"prepopulated_fields_json\", template_context)\n    self.assertIsInstance(template_context[\"prepopulated_fields\"], list)\n    self.assertIsInstance(template_context[\"prepopulated_fields_json\"], str)\n"], "sample_86": ["def test_log_passing_tests(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        junit_log_passing_tests = False\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n            print('Hello, world!')\n            pass\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    node = dom.find_first_by_tag(\"testcase\")\n    assert len(node.find_by_tag(\"system-out\")) == 0\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        junit_log_passing_tests = True\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    node = dom.find_first_by_tag(\"testcase\")\n    assert len(node.find_by_tag(\"system-out\")) == 1\n", "def test_log_passing_tests(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logging.info('Some log message')\n            assert True\n    \"\"\"\n    )\n    result, dom = runandparse(testdir, \"-o\", \"junit_log_passing_tests=True\")\n    node = dom.find_first_by_tag(\"testcase\")\n    systemout = node.find_first_by_tag(\"system-out\")\n    assert \"Some log message\" in systemout.toxml()\n\n    result, dom = runandparse(testdir, \"-o\", \"junit_log_passing_tests=False\")\n    node = dom.find_first_by_tag(\"testcase\")\n    systemout = node.find_first_by_tag(\"system-out\")\n    assert systemout is None or \"Some log message\" not in systemout.toxml()\n", "def test_junit_logging_no(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        import sys\n\n            print(\"hello-stdout\")\n            sys.stderr.write(\"hello-stderr\\\\n\")\n            logging.info('info msg')\n            logging.warning('warning msg')\n            raise ValueError(42)\n    \"\"\"\n    )\n\n    result, dom = runandparse(testdir, \"-o\", \"junit_logging=no\")\n    assert result.ret\n    node = dom.find_first_by_tag(\"testsuite\")\n    node.assert_attr(failures=1, tests=1)\n    tnode = node.find_first_by_tag(\"testcase\")\n    tnode.assert_attr(classname=\"test_junit_logging_no\", name=\"test_fail\")\n    fnode = tnode.find_first_by_tag(\"failure\")\n    fnode.assert_attr(message=\"ValueError: 42\")\n    assert \"ValueError\" in fnode.toxml()\n    systemout = tnode.find_first_by_tag(\"system-out\")\n    assert systemout is None\n    systemerr = tnode.find_first_by_tag(\"system-err\")\n    assert systemerr is None\n", "def test_add_stats(testdir):\n    log = LogXML(\"tests.xml\", None)\n    log.add_stats(\"passed\")\n    assert log.stats[\"passed\"] == 1\n    log.add_stats(\"failed\")\n    assert log.stats[\"failed\"] == 1\n    log.add_stats(\"skipped\")\n    assert log.stats[\"skipped\"] == 1\n    log.add_stats(\"error\")\n    assert log.stats[\"error\"] == 1\n", "def test_testsuite_property_node_with_no_properties(testdir):\n    path = testdir.tmpdir.join(\"test_global_properties.xml\")\n    log = LogXML(str(path), None)\n\n    class Report(BaseReport):\n        sections = []\n        nodeid = \"test_node_id\"\n\n    log.pytest_sessionstart()\n    log.pytest_sessionfinish()\n\n    dom = minidom.parse(str(path))\n\n    properties = dom.getElementsByTagName(\"properties\")\n\n    assert properties.length == 0, \"There must be no <properties> node\"\n"], "sample_76": ["def test_insufficient_data(self, df):\n\n    groupby = GroupBy([\"group\"])\n    df = df.head(2).copy()  # Not enough unique x values\n    res = PolyFit(order=2)(df, groupby, \"x\", {})\n\n    assert_frame_equal(res, pd.DataFrame(columns=[\"x\", \"y\"]))\n", "def test_insufficient_unique_x(self, df):\n\n    groupby = GroupBy([\"group\"])\n    res = PolyFit(order=3)(df[df[\"x\"] > 0.5], groupby, \"x\", {})\n\n    assert_frame_equal(res, pd.DataFrame(columns=[\"x\", \"y\"]))\n", "def test_insufficient_unique_x(self, df):\n\n    groupby = GroupBy([\"group\"])\n    df[\"x\"] = 1\n    res = PolyFit(order=2)(df, groupby, \"x\", {})\n\n    assert_frame_equal(res, pd.DataFrame(columns=[\"x\", \"y\"]))\n", "def test_insufficient_unique_x(self, df):\n\n    groupby = GroupBy([\"group\"])\n    df[\"x\"] = 1  # set all x values to be the same\n\n    res = PolyFit(order=2, gridsize=100)(df, groupby, \"x\", {})\n\n    assert res.columns.to_list() == [\"x\", \"y\", \"group\"]\n    assert res.empty  # verify that result is empty when there are not enough unique x values\n", "def test_insufficient_unique_x(self, df):\n\n    groupby = GroupBy([\"group\"])\n    df[\"x\"] = 1  # Not enough unique x values to fit a polynomial of order 2\n    res = PolyFit(order=2)(df, groupby, \"x\", {})\n\n    assert_frame_equal(res, pd.DataFrame(columns=[\"x\", \"y\", \"group\"], index=pd.RangeIndex(0)))\n"], "sample_19": ["    def test_technical_404(self):\n        exception = Http404('Non-existent URL')\n        request = RequestFactory().get('/non-existent-url')\n        response = technical_404_response(request, exception)\n        self.assertEqual(response.status_code, 404)\n        self.assertContains(response, 'Non-existent URL', status_code=404)\n        self.assertContains(response, 'Page not found <span>(404)</span>', status_code=404)\n", "    def test_get_cleansed_multivaluedict(self):\n        filter = SafeExceptionReporterFilter()\n        request = RequestFactory().post('/some_url/', {'password': 'secret', 'other': 'not secret'})\n        request.sensitive_post_parameters = ['password']\n        multivaluedict = request.POST.copy()\n        cleansed_dict = filter.get_cleansed_multivaluedict(request, multivaluedict)\n        self.assertEqual(cleansed_dict['password'], SafeExceptionReporterFilter.cleansed_substitute)\n        self.assertEqual(cleansed_dict['other'], 'not secret')\n", "    def test_get_traceback_data_no_request(self):\n        reporter = ExceptionReporter(None, None, None, None)\n        data = reporter.get_traceback_data()\n        self.assertIsNone(data['request'])\n        self.assertEqual(data['request_meta'], {})\n        self.assertEqual(data['filtered_POST_items'], [])\n        self.assertEqual(data['settings'], reporter.filter.get_safe_settings())\n        self.assertIsNone(data['user_str'])\n", "    def test_empty_traceback(self):\n        exc_type, exc_value, tb = None, None, None\n        reporter = ExceptionReporter(None, exc_type, exc_value, tb)\n        frames = reporter.get_traceback_frames()\n        self.assertEqual(frames, [])\n", "    def test_request_uri(self):\n        request = self.rf.get('/test_view/')\n        reporter = ExceptionReporter(request, None, None, None)\n        data = reporter.get_traceback_data()\n        self.assertEqual(data['request_path'], '/test_view/')\n"], "sample_118": ["def test_ccode_For():\n    from sympy.codegen import For, aug_assign\n    from sympy.tensor import IndexedBase, Idx\n\n    n = symbols('n', integer=True)\n    i = Idx('i', n)\n    x = IndexedBase('x')\n    y = IndexedBase('y')\n\n    body = aug_assign(x[i], '+', y[i])\n\n    f = For(i, Range(n), body)\n\n    assert ccode(f) == (\n        'for (int i=0; i<n; i++){\\n'\n        '   x[i] += y[i];\\n'\n        '}'\n    )\n", "def test_ccode_For():\n    from sympy import For\n    i = symbols('i', integer=True)\n    f = For(i, Range(0, 10), [aug_assign(x, '+', i)])\n    assert ccode(f) == (\n        'for (int i=0; i<10; i++){\\n'\n        '   x += i;\\n'\n        '}'\n    )\n    assert ccode(f, assign_to='result') == (\n        'for (int i=0; i<10; i++){\\n'\n        '   x += i;\\n'\n        '}'\n    )\n", "def test_ccode_For():\n    f = For(x, Range(0, 10), [AugAssign(y, Add, cos(x))])\n    assert ccode(f) == (\n        'for (x = 0; x < 10; x += 1) {\\n'\n        '   y += cos(x);\\n'\n        '}'\n    )\n", "def test_ccode_For():\n    from sympy import For\n    f = For(x, Range(0, 10), [aug_assign(y, '+', x)])\n    assert ccode(f) == (\n        'for (int x=0; x<10; x++){\\n'\n        '   y += x;\\n'\n        '}'\n    )\n", "def test_ccode_For():\n    from sympy import For, symbols\n    i, n = symbols('i n', integer=True)\n    f = For(i, Range(n), [x])\n    assert ccode(f) == (\n        'for (int i=0; i<n; i++){\\n'\n        '   x;\\n'\n        '}'\n    )\n    assert ccode(f, assign_to='y') == (\n        'for (int i=0; i<n; i++){\\n'\n        '   y = x;\\n'\n        '}'\n    )\n"], "sample_152": ["def test_array_equality():\n    for ArrayType in array_types:\n        a = ArrayType([[1, 2], [3, 4]])\n        b = ArrayType([[1, 2], [3, 4]])\n        c = ArrayType([[1, 2], [3, 5]])\n\n        assert a == b\n        assert a != c\n        assert a != Matrix([[1, 2], [3, 4]])\n\n        raises(TypeError, lambda: a == \"string\")\n", "def test_array_diff():\n    for ArrayType in array_types:\n        x, y = sympy.symbols('x y')\n        A = ArrayType([x**2, y**3])\n        B = ArrayType([[x**2, y**3], [x*y, x+y]])\n        assert A.diff(x) == ArrayType([2*x, 0])\n        assert A.diff(y) == ArrayType([0, 3*y**2])\n        assert B.diff(x) == ArrayType([[2*x, 0], [y, 1]])\n        assert B.diff(y) == ArrayType([[0, 3*y**2], [x, 1]])\n", "def test_array_equality():\n    for ArrayType in array_types:\n        array1 = ArrayType([[1, 2], [3, 4]])\n        array2 = ArrayType([[1, 2], [3, 4]])\n        array3 = ArrayType([[1, 2], [3, 5]])\n\n        assert array1 == array2\n        assert array1 != array3\n\n        # Test equality with different shapes\n        array4 = ArrayType([1, 2, 3, 4])\n        assert array1 != array4\n\n        # Test equality with non-array objects\n        assert array1 != [[1, 2], [3, 4]]\n        assert array1 != \"array\"\n", "def test_array_rank():\n    for ArrayType in array_types:\n        test_array = ArrayType([1, 2, 3, 4, 5, 6], (2, 3))\n        assert test_array.rank() == 2\n\n        test_array = ArrayType([1, 2, 3, 4, 5, 6, 7, 8], (2, 2, 2))\n        assert test_array.rank() == 3\n\n        test_array = ArrayType([1])\n        assert test_array.rank() == 0\n\n        test_array = ArrayType([])\n        assert test_array.rank() == 1\n", "def test_ndim_array_len():\n    for ArrayType in array_types:\n        test_array = ArrayType([[1, 2, 3], [4, 5, 6]])\n        assert len(test_array) == 6\n\n        test_array = ArrayType([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n        assert len(test_array) == 8\n\n        test_array = ArrayType([])\n        assert len(test_array) == 0\n\n        test_array = ArrayType([1, 2, 3, 4, 5, 6])\n        assert len(test_array) == 6\n"], "sample_154": ["def test_lambdify_cse_disabled():\n    f = lambdify(x, 2*x + 3*x)\n    assert f(1) == 5\n\n        return (), exprs\n\n    f_cse_disabled = lambdify(x, 2*x + 3*x, cse=False)\n    assert f_cse_disabled(1) == 5\n", "def test_lambdify_issue_23224():\n    f = lambdify([], (1,))\n    assert f() == (1,)\n", "def test_lambdify_with_user_functions():\n    # Test that lambdify handles user-defined functions correctly\n\n    # Define a simple user function\n        return x**2\n\n    # Create a SymPy expression using the user function\n    expr = user_func(x)\n\n    # Lambdify the expression with the user function\n    f = lambdify(x, expr, {\"user_func\": user_func})\n\n    # Test that the lambdified function works correctly\n    assert f(2) == 4\n", "def test_lambdify_minmax_numpy():\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    f = lambdify(x, Min(x, x**2))\n    assert f(-1) == -1\n\n    g = lambdify(x, Max(x, x**2))\n    assert g(-1) == 1\n", "def test_lambdify_use_imps():\n    f = implemented_function('f', lambda x: x + 1)\n    g = implemented_function('f', lambda x: x - 1)\n\n    # By default, lambdify should use the implementations\n    assert lambdify(x, f(x))(2) == 3\n    assert lambdify(x, g(x))(2) == 1\n\n    # If use_imps is False, it should not use them\n    raises(NameError, lambda: lambdify(x, f(x), use_imps=False)(2))\n"], "sample_51": ["def test_was_modified_since_header_with_length(self):\n    \"\"\"\n    Test was_modified_since with a header that includes a length value.\n    \"\"\"\n    mtime = 1343416141\n    size = 100\n    header = f\"Thu, 26 Jul 2012 14:42:21 GMT; length={size}\"\n    self.assertFalse(was_modified_since(header, mtime, size))\n    self.assertTrue(was_modified_since(header, mtime + 1, size))\n    self.assertTrue(was_modified_since(header, mtime, size + 1))\n", "def test_was_modified_since_with_encoding(self):\n    \"\"\"\n    Test that was_modified_since works correctly when the If-Modified-Since \n    header includes an encoding.\n    \"\"\"\n    mtime = 1343416141\n    size = 100\n    header = http_date(mtime) + '; length=' + str(size)\n    self.assertFalse(was_modified_since(header, mtime, size))\n    self.assertTrue(was_modified_since(header, mtime + 1, size))\n    self.assertTrue(was_modified_since(header, mtime, size + 1))\n", "def test_was_modified_since_no_header(self):\n    \"\"\"\n    If the If-Modified-Since header is not provided, was_modified_since returns True.\n    \"\"\"\n    self.assertTrue(was_modified_since(None, 0))\n", "def test_was_modified_since_with_size(self):\n    \"\"\"\n    Test was_modified_since with a size parameter.\n    \"\"\"\n    mtime = 1343416141.107817\n    header = http_date(mtime) + '; length=100'\n    self.assertFalse(was_modified_since(header, mtime, size=100))\n    self.assertTrue(was_modified_since(header, mtime, size=101))\n", "def test_was_modified_since_overflow(self):\n    \"\"\"\n    An overflow in the If-Modified-Since timestamp does not disturb was_modified_since.\n    \"\"\"\n    mtime = 2**32 - 1\n    header = http_date(mtime)\n    self.assertFalse(was_modified_since(header, mtime))\n"], "sample_17": ["    def test_clone_test_db(self, mocked_migrate, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        with mock.patch.object(creation, '_clone_test_db') as mocked_clone:\n            creation.clone_test_db(suffix='test_clone', verbosity=0, autoclobber=True)\n            mocked_clone.assert_called_once_with('test_clone', 0, False)\n", "    def test_keepdb_false(self, mocked_migrate, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db') as mocked_create:\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=False, keepdb=False)\n            mocked_create.assert_called_once()\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n", "    def test_get_test_db_clone_settings(self, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        suffix = '_test_clone'\n        clone_settings = creation.get_test_db_clone_settings(suffix)\n        self.assertEqual(clone_settings['NAME'], test_connection.settings_dict['NAME'] + suffix)\n", "def test_create_test_db_with_keepdb(self, mocked_migrate, mocked_ensure_connection):\n    test_connection = get_connection_copy()\n    creation = test_connection.creation_class(test_connection)\n    old_database_name = test_connection.settings_dict['NAME']\n    try:\n        with mock.patch.object(creation, '_create_test_db') as mocked_create_test_db:\n            creation.create_test_db(verbosity=0, autoclobber=True, serialize=False, keepdb=True)\n            mocked_create_test_db.assert_called_once_with(0, True, keepdb=True)\n        with mock.patch.object(creation, '_destroy_test_db') as mocked_destroy_test_db:\n            creation.destroy_test_db(old_database_name, verbosity=0, keepdb=True)\n            mocked_destroy_test_db.assert_not_called()\n    finally:\n        with mock.patch.object(creation, '_destroy_test_db'):\n            creation.destroy_test_db(old_database_name, verbosity=0)\n", "def test_create_test_db_with_keepdb(self, mocked_migrate, mocked_ensure_connection):\n    test_connection = get_connection_copy()\n    creation = test_connection.creation_class(test_connection)\n    old_database_name = test_connection.settings_dict['NAME']\n    try:\n        with mock.patch.object(creation, '_create_test_db'):\n            creation.create_test_db(verbosity=0, autoclobber=True, serialize=False, keepdb=True)\n        self.assertEqual(test_connection.settings_dict['NAME'], creation._get_test_db_name())\n    finally:\n        with mock.patch.object(creation, '_destroy_test_db'):\n            creation.destroy_test_db(old_database_name, verbosity=0, keepdb=True)\n"], "sample_149": ["def test_Monomial():\n    m = Monomial((1, 2, 3))\n    assert m.exponents == (1, 2, 3)\n    assert m.gens is None\n\n    x, y, z = symbols('x y z')\n    m = Monomial((1, 2, 3), (x, y, z))\n    assert m.exponents == (1, 2, 3)\n    assert m.gens == (x, y, z)\n\n    assert m.as_expr() == x*y**2*z**3\n    assert m.as_expr(x, y, z) == x*y**2*z**3\n\n    raises(ValueError, lambda: Monomial(x*y + z))\n    raises(ValueError, lambda: Monomial(x*y + z, (x, y)))\n", "def test_monomial_division_error():\n    raises(ExactQuotientFailed, lambda: monomial_div((1, 2), (3, 4)))\n", "def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n", "def test_Monomial():\n    x, y = symbols('x y')\n    m = Monomial((2, 3), (x, y))\n\n    assert m.exponents == (2, 3)\n    assert m.gens == (x, y)\n\n    assert m.as_expr() == x**2*y**3\n\n    assert m.__eq__((2, 3)) is True\n    assert m.__eq__((1, 2)) is False\n\n    assert m.__mul__(Monomial((1, 1), (x, y))) == Monomial((3, 4), (x, y))\n    assert m.__truediv__(Monomial((1, 1), (x, y))) == Monomial((1, 2), (x, y))\n\n    raises(ExactQuotientFailed, lambda: m.__truediv__(Monomial((3, 3), (x, y))))\n\n    assert m.__pow__(2) == Monomial((4, 6), (x, y))\n\n    assert m.gcd(Monomial((1, 2), (x, y))) == Monomial((1, 2), (x, y))\n    assert m.lcm(Monomial((1, 2), (x, y))) == Monomial((2, 3), (x, y))\n", "def test_monomial_ops():\n    ops = MonomialOps(3)\n\n    assert ops.mul()( (1, 2, 3), (4, 5, 6) ) == (5, 7, 9)\n    assert ops.pow()( (1, 2, 3), 2 ) == (2, 4, 6)\n    assert ops.mulpow()( (1, 2, 3), (4, 5, 6), 2 ) == (9, 12, 15)\n    assert ops.ldiv()( (1, 2, 3), (4, 5, 6) ) == (-3, -3, -3)\n    assert ops.div()( (1, 2, 3), (1, 1, 1) ) == (0, 1, 2)\n    assert ops.lcm()( (1, 2, 3), (4, 5, 6) ) == (4, 5, 6)\n    assert ops.gcd()( (1, 2, 3), (4, 5, 6) ) == (1, 2, 3)\n"], "sample_130": ["def test_lambdify_with_nested_functions():\n    # Test that lambdify works correctly with nested functions\n    f = lambdify(x, sin(cos(x)))\n    assert f(0) == sin(cos(0))\n", "def test_lambdify_kwargs():\n    f = lambdify((x, y), x + y)\n    assert f(x=1, y=2) == 3\n    assert f(1, y=2) == 3\n    assert f(x=1, y=2) == f(y=2, x=1)\n", "def test_lambdify_with_sum():\n    # Test that lambdify works with Sum objects\n    s = Sum(x, (x, 1, 10))\n    f = lambdify(x, s, 'sympy')\n    assert f(1) == 55\n", "def test_lambdify_with_Sum():\n    # Test that lambdify handles Sum correctly\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    i = symbols('i')\n    f = lambdify(x, Sum(x**i, (i, 1, 3)), 'numpy')\n    assert numpy.allclose(f(2), 2 + 2**2 + 2**3)\n", "def test_lambdify_lambda():\n    # Test that lambdify can handle lambda functions as input\n    func = lambda x: x**2\n    f = lambdify(x, func(x))\n    assert f(2) == 4\n"], "sample_113": ["def test_column_transformer_with_feature_names_in():\n    pd = pytest.importorskip(\"pandas\")\n    X_df = pd.DataFrame({\n        \"pet\": pd.Series([\"dog\", \"cat\", \"snake\"], dtype=\"category\"),\n        \"age\": [1.4, 2.1, 4.4],\n        \"height\": [20, 40, 10],\n    })\n\n    ct = ColumnTransformer(\n        [\n            (\n                \"pet_encode\",\n                OneHotEncoder(sparse_output=False, dtype=\"int8\"),\n                [\"pet\"],\n            ),\n            (\"age\", StandardScaler(), [\"age\"]),\n        ],\n        remainder=\"passthrough\",\n    )\n\n    feature_names_in = [\"new_pet\", \"new_age\", \"new_height\"]\n    ct.fit(X_df, feature_names_in=feature_names_in)\n\n    assert_array_equal(ct.feature_names_in_, feature_names_in)\n", "def test_column_transformer_set_output_numpy():\n    \"\"\"Check column transformer behavior with set_output to numpy.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame([[1, 2, 3, 4]], columns=[\"a\", \"b\", \"c\", \"d\"], index=[10])\n    ct = ColumnTransformer(\n        [(\"first\", TransWithNames(), [\"a\", \"c\"]), (\"second\", TransWithNames(), [\"d\"])],\n        remainder=\"passthrough\",\n    ).set_output(transform=\"numpy\")\n\n    X_trans = ct.fit_transform(df)\n    assert isinstance(X_trans, np.ndarray)\n\n    feature_names_out = ct.get_feature_names_out()\n    assert_array_equal(feature_names_out, X_trans.dtype.names)\n\n    # check numpy structured array shape\n    assert X_trans.shape == (1,)\n    assert len(X_trans.dtype) == len(feature_names_out)\n", "def test_column_transformer_feature_names_out_numpy():\n    \"\"\"Check feature names out when input is numpy array.\"\"\"\n    X = np.array([[1, 2], [3, 4]])\n    ct = ColumnTransformer(\n        [\n            (\"scale\", StandardScaler(), [0]),\n            (\"passthrough\", \"passthrough\", [1]),\n        ]\n    )\n    ct.fit(X)\n    feature_names_out = ct.get_feature_names_out()\n    assert_array_equal(feature_names_out, [\"scale__x0\", \"passthrough__x1\"])\n", "def test_column_transformer_feature_names_out_with_callable():\n    \"\"\"Check feature names out when using callable to specify columns.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame(\n        {\n            \"col_int\": np.array([0, 1, 2], dtype=int),\n            \"col_float\": np.array([0.0, 1.0, 2.0], dtype=float),\n            \"col_str\": [\"one\", \"two\", \"three\"],\n        },\n        columns=[\"col_int\", \"col_float\", \"col_str\"],\n    )\n\n        return [X.columns[0]]\n\n    ohe = OneHotEncoder()\n    ct = ColumnTransformer([(\"ohe\", ohe, select_columns)], remainder=\"passthrough\")\n\n    ct.fit(df)\n    assert_array_equal(ct.get_feature_names_out(), [\"ohe__col_int_0\", \"ohe__col_int_1\", \"ohe__col_int_2\", \"col_float\", \"col_str\"])\n", "def test_column_transformer_get_feature_names_out_mismatch_length():\n    \"\"\"Check error raised when transformer output length does not match feature names.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    df = pd.DataFrame([[1, 2, 3, 4]], columns=[\"a\", \"b\", \"c\", \"d\"])\n    ct = ColumnTransformer(\n        [\n            (\"bycol1\", TransWithNames([\"f1\", \"f2\"]), [\"a\"]),\n            (\"bycol2\", TransWithNames([\"f3\"]), [\"b\"]),\n        ],\n        remainder=\"drop\",\n    )\n    ct.fit(df)\n\n    msg = re.escape(\n        \"For estimator 'bycol1', the number of output features (2) does \"\n        \"not match the number of provided feature names (1).\"\n    )\n    with pytest.raises(ValueError, match=msg):\n        ct.get_feature_names_out(input_features=[\"a\", \"b\", \"c\", \"d\"])\n"], "sample_116": ["def test_create_index_with_non_alphanumeric_symbols(app):\n    text = (\".. index:: !@#$%^&*()_+~`|\\n\"\n            \".. index:: -_=+[]{}|;:,.<>/?\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n\n    # check index is created correctly\n    assert len(index) == 1\n    assert index[0][0] == _('Symbols')\n    assert len(index[0][1]) == 2\n", "def test_create_index_with_group_entries(app):\n    text = (\".. index:: docutils\\n\"\n            \".. index:: Python\\n\"\n            \".. index:: pip; install\\n\"\n            \".. index:: pip; upgrade\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder, group_entries=False)\n\n    # check index is created correctly without grouping\n    assert len(index) == 4\n    assert index[0] == ('D', [('docutils', [[('', '#index-0')], [], None])])\n    assert index[1] == ('P',\n                        [('pip', [[], [('install', [('', '#index-2')]),\n                                      ('upgrade', [('', '#index-3')])], None]),\n                         ('Python', [[('', '#index-1')], [], None])])\n\n    # check index is created correctly with grouping\n    index = IndexEntries(app.env).create_index(app.builder, group_entries=True)\n    assert len(index) == 4\n    assert index[0] == ('D', [('docutils', [[('', '#index-0')], [], None])])\n    assert index[1] == ('P',\n                        [('pip', [[],\n                                     [('install', [('', '#index-2')]),\n                                      ('upgrade', [('', '#index-3')])],\n                                     None]),\n                         ('Python', [[('', '#index-1')], [], None])])\n", "def test_create_index_with_group_entries(app):\n    text = (\".. index:: single: docutils\\n\"\n            \".. index:: single: Python\\n\"\n            \".. index:: single: Python (in module foo)\\n\"\n            \".. index:: single: Python (in module bar)\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder, group_entries=True)\n\n    assert len(index) == 2\n    assert index[0] == ('D', [('docutils', [[('', '#index-0')], [], None])])\n    assert index[1] == ('P', [('Python', [[('', '#index-1')],\n                                           [('in module bar', [('', '#index-3')]),\n                                            ('in module foo', [('', '#index-2')])],\n                                           None])])\n", "def test_create_index_with_group_entries(app):\n    text = (\".. index:: docutils\\n\"\n            \".. index:: Python\\n\"\n            \".. index:: pip; install\\n\"\n            \".. index:: pip; upgrade\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder, group_entries=False)\n\n    # check index is created correctly without grouping\n    assert len(index) == 4\n    assert index[0] == ('D', [('docutils', [[('', '#index-0')], [], None])])\n    assert index[1] == ('P', [('pip', [[], [('install', [('', '#index-2')])], None]),\n                              ('pip', [[], [('upgrade', [('', '#index-3')])], None]),\n                              ('Python', [[('', '#index-1')], [], None])])\n\n    index = IndexEntries(app.env).create_index(app.builder, group_entries=True)\n\n    # check index is created correctly with grouping\n    assert len(index) == 3\n    assert index[0] == ('D', [('docutils', [[('', '#index-0')], [], None])])\n    assert index[1] == ('P', [('pip', [[], [('install', [('', '#index-2')]),\n                                            ('upgrade', [('', '#index-3')])], None]),\n                              ('Python', [[('', '#index-1')], [], None])])\n", "def test_create_index_with_group_entries(app):\n    text = (\".. index:: single: docutils\\n\"\n            \".. index:: single: Python\\n\"\n            \".. index:: single: docutils()\\n\"\n            \".. index:: single: docutils (module)\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder, group_entries=True)\n\n    assert len(index) == 2\n    assert index[0] == ('D',\n                        [('docutils', [[], [('(module)', [('', '#index-3')])], None]),\n                         ('docutils()', [[('', '#index-2')], [], None])])\n    assert index[1] == ('P', [('Python', [[('', '#index-1')], [], None])])\n\n    # Test without grouping\n    index = IndexEntries(app.env).create_index(app.builder, group_entries=False)\n    assert len(index) == 4\n    assert index[0] == ('D', [('docutils', [[('', '#index-0')], [], None])])\n    assert index[1] == ('D', [('docutils ()', [[('', '#index-2')], [], None])])\n    assert index[2] == ('D', [('docutils (module)', [[('', '#index-3')], [], None])])\n    assert index[3] == ('P', [('Python', [[('', '#index-1')], [], None])])\n"], "sample_109": ["def test_validate_shuffle_split():\n    n_samples = 10\n    train_size = 0.8\n    test_size = 0.2\n\n    # Check if the computed train and test sizes are as expected\n    n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size)\n    assert n_train == int(train_size * n_samples)\n    assert n_test == int(test_size * n_samples)\n\n    # Check if the computed train size is correct when test size is None\n    n_train, n_test = _validate_shuffle_split(n_samples, None, train_size)\n    assert n_train == int(train_size * n_samples)\n    assert n_test == n_samples - n_train\n\n    # Check if the computed test size is correct when train size is None\n    n_train, n_test = _validate_shuffle_split(n_samples, test_size, None)\n    assert n_test == int(test_size * n_samples)\n    assert n_train == n_samples - n_test\n\n    # Check if an error is raised when both train and test sizes are None\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, None, None)\n\n    # Check if an error is raised when train size is greater than n_samples\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, None, 1.1)\n\n    # Check if an error is raised when test size is greater than n_samples\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, 1.1, None)\n", "def test_validate_shuffle_split():\n    # Check that _validate_shuffle_split raises errors for invalid inputs\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(10, test_size=0.6, train_size=0.6)\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(10, test_size=\"wrong_type\")\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(10, test_size=11)\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(10, test_size=-1)\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(10, test_size=0.0)\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(10, train_size=\"wrong_type\")\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(10, train_size=11)\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(10, train_size=-1)\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(10, train_size=0.0)\n    with pytest.raises(TypeError):\n        _validate_shuffle_split(10, test_size=None, train_size='string')\n", "def test_validate_shuffle_split():\n    # Test _validate_shuffle_split function\n    n_samples = 10\n    test_size, train_size = _validate_shuffle_split(n_samples, test_size=0.2,\n                                                    train_size=None,\n                                                    default_test_size=0.25)\n    assert test_size == 2\n    assert train_size == 8\n\n    test_size, train_size = _validate_shuffle_split(n_samples, test_size=2,\n                                                    train_size=None,\n                                                    default_test_size=0.25)\n    assert test_size == 2\n    assert train_size == 8\n\n    test_size, train_size = _validate_shuffle_split(n_samples, test_size=None,\n                                                    train_size=0.8,\n                                                    default_test_size=0.25)\n    assert test_size == 2\n    assert train_size == 8\n\n    test_size, train_size = _validate_shuffle_split(n_samples, test_size=None,\n                                                    train_size=8,\n                                                    default_test_size=0.25)\n    assert test_size == 2\n    assert train_size == 8\n\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size=0.5, train_size=0.6)\n\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size=6, train_size=5)\n\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size=0.5, train_size=1.1)\n\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size=11, train_size=None)\n\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size=None, train_size=11)\n", "def test_validate_shuffle_split():\n    # Test that _validate_shuffle_split returns the correct train and test sizes\n    n_samples = 10\n    test_size = 0.2\n    train_size = None\n    n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size)\n    assert n_train == 8\n    assert n_test == 2\n\n    # Test that an error is raised when test_size and train_size are both None\n    test_size = None\n    train_size = None\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size, train_size)\n\n    # Test that an error is raised when test_size + train_size > 1\n    test_size = 0.6\n    train_size = 0.6\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size, train_size)\n", "def test_validate_shuffle_split():\n    n_samples = 10\n    test_size = 0.2\n    train_size = 0.8\n    default_test_size = 0.25\n\n    # Test with valid test_size and train_size\n    n_train, n_test = _validate_shuffle_split(\n        n_samples, test_size, train_size, default_test_size)\n    assert n_train == int(train_size * n_samples)\n    assert n_test == int(test_size * n_samples)\n\n    # Test with valid test_size and no train_size\n    n_train, n_test = _validate_shuffle_split(\n        n_samples, test_size, None, default_test_size)\n    assert n_train == n_samples - int(test_size * n_samples)\n    assert n_test == int(test_size * n_samples)\n\n    # Test with valid train_size and no test_size\n    n_train, n_test = _validate_shuffle_split(\n        n_samples, None, train_size, default_test_size)\n    assert n_train == int(train_size * n_samples)\n    assert n_test == n_samples - int(train_size * n_samples)\n\n    # Test with neither test_size nor train_size\n    n_train, n_test = _validate_shuffle_split(\n        n_samples, None, None, default_test_size)\n    assert n_train == int((1 - default_test_size) * n_samples)\n    assert n_test == int(default_test_size * n_samples)\n\n    # Test with invalid test_size\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, -0.5, None, default_test_size)\n\n    # Test with invalid train_size\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, None, 1.5, default_test_size)\n\n    # Test with both test_size and train_size being None\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, None, None, None)\n"], "sample_40": ["def test_add_prefix(self):\n    class Person(Form):\n        first_name = CharField()\n        last_name = CharField()\n\n    p = Person(prefix='person')\n    self.assertEqual(p.add_prefix('first_name'), 'person-first_name')\n    self.assertEqual(p.add_initial_prefix('first_name'), 'initial-person-first_name')\n\n    p = Person(prefix='person')\n    self.assertEqual(p.add_prefix('first_name'), 'person-first_name')\n    self.assertEqual(p.add_initial_prefix('first_name'), 'initial-person-first_name')\n\n    p = Person()\n    self.assertEqual(p.add_prefix('first_name'), 'first_name')\n    self.assertEqual(p.add_initial_prefix('first_name'), 'initial-first_name')\n", "def test_boundfield_build_widget_attrs(self):\n    class MyForm(Form):\n        field = CharField(disabled=True, required=False)\n\n    form = MyForm()\n    bf = form['field']\n    attrs = {'class': 'myclass'}\n    self.assertEqual(bf.build_widget_attrs(attrs), {\n        'class': 'myclass',\n        'disabled': True,\n    })\n\n    class MyForm(Form):\n        field = CharField(disabled=False, required=True)\n\n    form = MyForm()\n    bf = form['field']\n    attrs = {'class': 'myclass'}\n    self.assertEqual(bf.build_widget_attrs(attrs), {\n        'class': 'myclass',\n        'required': True,\n    })\n\n    class MyForm(Form):\n        field = CharField(disabled=True, required=True)\n\n    form = MyForm()\n    bf = form['field']\n    attrs = {'class': 'myclass'}\n    self.assertEqual(bf.build_widget_attrs(attrs), {\n        'class': 'myclass',\n        'disabled': True,\n    })\n", "def test_is_hidden(self):\n    class MyForm(Form):\n        field1 = CharField()\n        field2 = CharField(widget=HiddenInput)\n\n    form = MyForm()\n    self.assertFalse(form['field1'].is_hidden)\n    self.assertTrue(form['field2'].is_hidden)\n", "def test_renderer_overridden_in_subclass(self):\n    class CustomForm(Form):\n        default_renderer = CustomRenderer()\n\n    class SubclassForm(CustomForm):\n        default_renderer = DjangoTemplates()\n\n    form = SubclassForm()\n    self.assertEqual(form.renderer, SubclassForm.default_renderer)\n", "def test_boundfield_label_tag_contents_escaping(self):\n    class SomeForm(Form):\n        field = CharField(label='Field & \"Name\"')\n\n    boundfield = SomeForm()['field']\n    self.assertHTMLEqual(boundfield.label_tag(), '<label for=\"id_field\">Field &amp; &quot;Name&quot;:</label>')\n    self.assertHTMLEqual(\n        boundfield.label_tag(contents='Custom & \"contents\"'),\n        '<label for=\"id_field\">Custom &amp; &quot;contents&quot;</label>'\n    )\n    self.assertHTMLEqual(\n        boundfield.label_tag(contents=mark_safe('Custom & \"contents\"')),\n        '<label for=\"id_field\">Custom & \"contents\"</label>'\n    )\n"], "sample_128": ["def test_Method_postprocess():\n    opt = {'method': 'foo'}\n    Method.postprocess(opt)\n\n    assert opt == {'method': 'foo'}\n", "def test_Method_postprocess():\n    opt = {'method': 'test'}\n    Method.postprocess(opt)\n\n    assert opt == {'method': 'test'}\n", "def test_Method_postprocess():\n    opt = {'method': 'foo'}\n    Method.postprocess(opt)\n\n    assert opt == {'method': 'foo'}\n", "def test_Method_postprocess():\n    opt = {'method': 'separate'}\n    Method.postprocess(opt)\n\n    assert opt == {'method': 'separate'}\n", "def test_Method_postprocess():\n    opt = {'method': 'some_method'}\n    Method.postprocess(opt)\n\n    assert opt == {'method': 'some_method'}\n"], "sample_73": ["def test_offsetbox_set_figure():\n    # Test if set_figure() method correctly sets the figure for the OffsetBox\n    # and all its children.\n\n    fig, ax = plt.subplots()\n    ob = OffsetBox()\n    child1 = OffsetBox()\n    child2 = OffsetBox()\n    ob._children = [child1, child2]\n\n    ob.set_figure(fig)\n\n    assert ob.get_figure() == fig\n    assert child1.get_figure() == fig\n    assert child2.get_figure() == fig\n", "def test_offsetbox_repr():\n    # Test that OffsetBox and its subclasses have a sensible repr.\n    offsetbox = OffsetBox()\n    assert isinstance(repr(offsetbox), str)\n\n    paddedbox = PaddedBox(offsetbox, pad=5)\n    assert isinstance(repr(paddedbox), str)\n\n    drawingarea = DrawingArea(20, 20, 0, 0, clip=True)\n    assert isinstance(repr(drawingarea), str)\n\n    textarea = TextArea(\"foo\")\n    assert isinstance(repr(textarea), str)\n\n    anchoredoffsetbox = AnchoredOffsetbox(\"upper left\", child=offsetbox)\n    assert isinstance(repr(anchoredoffsetbox), str)\n\n    anchoredtext = AnchoredText(\"bar\", \"upper right\")\n    assert isinstance(repr(anchoredtext), str)\n\n    annotationbbox = AnnotationBbox(offsetbox, (0.5, 0.5), xycoords='data')\n    assert isinstance(repr(annotationbbox), str)\n", "def test_offsetbox_get_bbox_and_child_offsets():\n    # Test that get_bbox_and_child_offsets returns the correct bbox and offsets\n    # for a simple OffsetBox with two children.\n    fig, ax = plt.subplots()\n    renderer = fig.canvas.get_renderer()\n\n    child1 = TextArea('Child 1')\n    child2 = TextArea('Child 2')\n\n    offsetbox = OffsetBox()\n    offsetbox._children = [child1, child2]\n\n    with pytest.raises(NotImplementedError):\n        offsetbox._get_bbox_and_child_offsets(renderer)\n\n    class CustomOffsetBox(OffsetBox):\n            bboxes = [c.get_bbox(renderer) for c in self.get_visible_children()]\n            maxh = max(bbox.height for bbox in bboxes)\n            total_width = sum(bbox.width for bbox in bboxes)\n            return Bbox.from_bounds(0, 0, total_width, maxh), [(0, 0)] * len(bboxes)\n\n    custom_offsetbox = CustomOffsetBox()\n    custom_offsetbox._children = [child1, child2]\n\n    bbox, offsets = custom_offsetbox._get_bbox_and_child_offsets(renderer)\n    assert isinstance(bbox, BboxBase)\n    assert len(offsets) == 2\n", "def test_auxtransformbox_properties():\n    atb = AuxTransformBox(mtransforms.Affine2D())\n    assert atb.aux_transform.is_affine\n    assert isinstance(atb.ref_offset_transform, mtransforms.Affine2D)\n    assert isinstance(atb.offset_transform, mtransforms.Affine2D)\n", "def test_annotationbbox_set_offset(fig_test, fig_ref):\n    ax_ref = fig_ref.add_subplot()\n    ab_ref = AnnotationBbox(DrawingArea(20, 20, 0, 0, clip=True), (0.5, 0.5),\n                            xycoords='data')\n    ax_ref.add_artist(ab_ref)\n\n    ax_test = fig_test.add_subplot()\n    ab_test = AnnotationBbox(DrawingArea(20, 20, 0, 0, clip=True), (0.5, 0.5),\n                             xycoords='data')\n    ab_test.set_offset((10, 10))\n    ax_test.add_artist(ab_test)\n"], "sample_111": ["def test_empty_input(metric_name):\n    # All supervised clustering metrics should be able to handle empty inputs\n    metric = SUPERVISED_METRICS[metric_name]\n    assert metric([], []) == 1.0\n    assert metric([1, 2, 3], []) == 1.0\n    assert metric([], [1, 2, 3]) == 1.0\n", "def test_empty_input(metric_name):\n    # Test that all supervised metrics can handle empty input arrays\n    metric = SUPERVISED_METRICS[metric_name]\n    assert metric([], []) == 1.0\n    if metric_name in SYMMETRIC_METRICS:\n        assert metric([1, 2, 3], []) == 1.0\n        assert metric([], [1, 2, 3]) == 1.0\n", "def test_empty_input(metric_name):\n    # All clustering metrics should be able to handle empty inputs\n    metric = SUPERVISED_METRICS[metric_name]\n    assert metric([], []) == 1.0\n", "def test_empty_input(metric_name):\n    # All supervised clustering metrics should be able to handle empty input\n    metric = SUPERVISED_METRICS[metric_name]\n    assert metric([], []) == 1.0\n", "def test_empty_input(metric_name):\n    # All clustering metrics should be able to handle empty inputs\n    metric = SUPERVISED_METRICS[metric_name]\n    assert metric([], []) == 1.0\n    with pytest.raises(ValueError):\n        metric([1, 2, 3], [])\n    with pytest.raises(ValueError):\n        metric([], [1, 2, 3])\n"], "sample_151": ["def test_affine_rank():\n    assert Point.affine_rank() == -1\n    assert Point.affine_rank(Point(0, 0)) == 0\n    assert Point.affine_rank(Point(0, 0), Point(1, 1)) == 1\n    assert Point.affine_rank(Point(0, 0), Point(1, 1), Point(2, 2)) == 1\n    assert Point.affine_rank(Point(0, 0), Point(1, 0), Point(0, 1)) == 2\n    assert Point.affine_rank(Point(0, 0, 0), Point(1, 1, 1), Point(2, 2, 2)) == 1\n    assert Point.affine_rank(Point(0, 0, 0), Point(1, 0, 0), Point(0, 1, 0), Point(0, 0, 1)) == 3\n", "def test_are_coplanar():\n    p1 = Point(0, 0)\n    p2 = Point(1, 0)\n    p3 = Point(0, 1)\n    p4 = Point(1, 1)\n    assert Point.are_coplanar(p1, p2, p3, p4) is True\n    p5 = Point(0, 0, 1)\n    assert Point.are_coplanar(p1, p2, p3, p5) is False\n\n    # All points are collinear, hence coplanar\n    p6 = Point(2, 2)\n    assert Point.are_coplanar(p1, p2, p4, p6) is True\n\n    # Four points in 3D space\n    p7 = Point(0, 0, 0)\n    p8 = Point(1, 0, 0)\n    p9 = Point(0, 1, 0)\n    p10 = Point(1, 1, 0)\n    assert Point.are_coplanar(p7, p8, p9, p10) is True\n\n    # Three points in 3D space are always coplanar\n    assert Point.are_coplanar(p7, p8, p9) is True\n", "def test_direction_cosine():\n    p1 = Point3D(1, 2, 3)\n    p2 = Point3D(4, 5, 6)\n    direction_cosine = p1.direction_cosine(p2)\n    assert len(direction_cosine) == 3\n    for i in direction_cosine:\n        assert abs(i) <= 1\n", "def test_project():\n    p1 = Point(0, 1)\n    p2 = Point(1, 0)\n    assert Point.project(p1, p2) == Point(0, 0)\n    p1 = Point(1, 1)\n    p2 = Point(1, 0)\n    assert Point.project(p1, p2) == Point(1, 0)\n    raises(ValueError, lambda: Point.project(p1, Point(0, 0)))\n", "def test_direction_cosine():\n    p1 = Point3D(1, 2, 3)\n    p2 = Point3D(4, 5, 6)\n    direction_cosine = p1.direction_cosine(p2)\n    assert len(direction_cosine) == 3\n    assert all(isinstance(i, Basic) for i in direction_cosine)\n    assert all(i.is_real for i in direction_cosine)\n"], "sample_54": ["def test_urlize_with_no_follow(self):\n    tests = (\n        (\n            \"Search for google.com/?q=! and see.\",\n            'Search for <a href=\"http://google.com/?q=\" rel=\"nofollow\">'\n            \"google.com/?q=</a>! and see.\",\n        ),\n        (\n            lazystr(\"Search for google.com/?q=!\"),\n            'Search for <a href=\"http://google.com/?q=\" rel=\"nofollow\">'\n            \"google.com/?q=</a>!\",\n        ),\n        (\n            \"foo@example.com\",\n            '<a href=\"mailto:foo@example.com\" rel=\"nofollow\">'\n            \"foo@example.com</a>\",\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value, nofollow=True), output)\n", "def test_urlize_no_follow(self):\n    tests = (\n        (\n            \"Search for google.com/?q=! and see.\",\n            'Search for <a href=\"http://google.com/?q=\" rel=\"nofollow\">google.com/?q=</a>! and see.',\n        ),\n        (\n            lazystr(\"Search for google.com/?q=!\"),\n            'Search for <a href=\"http://google.com/?q=\" rel=\"nofollow\">google.com/?q=</a>!',\n        ),\n        (\n            \"foo@example.com\",\n            '<a href=\"mailto:foo@example.com\">foo@example.com</a>',\n        ),  # mailto links don't get nofollow\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value, nofollow=True), output)\n", "def test_urlize_no_follow(self):\n    tests = (\n        (\n            \"Search for google.com/?q=! and see.\",\n            'Search for <a href=\"http://google.com/?q=\" rel=\"nofollow\">google.com/?q=</a>! and '\n            \"see.\",\n        ),\n        (\n            lazystr(\"Search for google.com/?q=!\"),\n            'Search for <a href=\"http://google.com/?q=\" rel=\"nofollow\">google.com/?q=</a>!',\n        ),\n        (\n            \"foo@example.com\",\n            '<a href=\"mailto:foo@example.com\">foo@example.com</a>',\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value, nofollow=True), output)\n", "def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\"Check out www.google.com.\", 'Check out <a href=\"http://www.google.com\">www.google.com</a>.'),\n        (\"Visit https://www.example.com!\", 'Visit <a href=\"https://www.example.com\">https://www.example.com</a>!'),\n        (\"Email me at foo@example.com?\", '<a href=\"mailto:foo@example.com\">foo@example.com</a>?'),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n", "def test_format_html_join(self):\n    items = (\n        (\n            \"<li>{} {}</li>\",\n            ((1, 2), (3, 4)),\n            \"<li>1 2</li><li>3 4</li>\",\n        ),\n        (\n            \"<p>{} {}</p>\",\n            ((\"hello\", \"world\"), (\"foo\", \"bar\")),\n            \"<p>hello world</p><p>foo bar</p>\",\n        ),\n    )\n    for format_string, args, output in items:\n        with self.subTest(format_string=format_string, args=args):\n            self.assertEqual(format_html_join(\"\", format_string, args), output)\n"], "sample_148": ["def test_polar_lift():\n    from sympy import polar_lift, exp_polar\n    x = Symbol('x')\n    assert polar_lift(0) == 0\n    assert polar_lift(1) == 1\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(I) == I\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(x) == x\n    assert polar_lift(exp_polar(I*pi)) == exp_polar(I*pi)\n    assert polar_lift(exp_polar(-I*pi)) == exp_polar(-I*pi)\n    assert polar_lift(exp_polar(3*I*pi/2)) == exp_polar(3*I*pi/2)\n", "def test_issue_18273():\n    from sympy import sqrt, I, principal_branch, exp_polar\n    z = Symbol('z')\n    assert sqrt((1 + I)**4) == 2*I\n    assert principal_branch((1 + I)**2, pi) == 2*I\n    assert principal_branch(exp_polar(I*pi/4)**4, pi) == exp_polar(I*pi)\n    assert principal_branch(exp_polar(7*I*pi/4)**4, pi) == exp_polar(-I*pi)\n    assert principal_branch(z**4, pi).subs(z, 1 + I) == 2*I\n    assert principal_branch(z**4, pi).subs(z, exp_polar(I*pi/4)) == exp_polar(I*pi)\n    assert principal_branch(z**4, pi).subs(z, exp_polar(7*I*pi/4)) == exp_polar(-I*pi)\n", "def test_issue_20758():\n    from sympy import MatrixSymbol, adjoint, transpose, conjugate\n    A = MatrixSymbol('A', 2, 2)\n    assert adjoint(adjoint(A)) == A\n    assert transpose(transpose(A)) == A\n    assert conjugate(conjugate(A)) == A\n    assert adjoint(transpose(A)) == conjugate(A)\n    assert transpose(adjoint(A)) == conjugate(A)\n    assert conjugate(adjoint(A)) == transpose(A)\n    assert conjugate(transpose(A)) == adjoint(A)\n", "def test_issue_20414():\n    x = Symbol('x')\n    assert unpolarify(sqrt(x)**2) == x\n    assert unpolarify((1/sqrt(x))**2) == 1/x\n    assert unpolarify(exp(sqrt(x))) == exp(sqrt(x))\n    assert unpolarify(log(sqrt(x))) == log(sqrt(x))\n", "def test_polar_lift():\n    from sympy import polar_lift, exp_polar, pi, I\n    x = Symbol('x')\n\n    assert polar_lift(2 + 3*I) == 2*exp_polar(I*atan2(3, 2)) + 3*I*exp_polar(I*atan2(3, 2))\n    assert polar_lift(x).diff(x) == exp_polar(I*atan2(im(x), re(x)))\n\n    # issue 14215\n    assert polar_lift(exp_polar(I*pi/4)) == exp_polar(I*pi/4)\n\n    assert polar_lift(0) == 0\n    assert polar_lift(1) == 1\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(I*pi/2)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n\n    assert polar_lift(oo) == oo\n    assert polar_lift(-oo) == -oo\n\n    assert polar_lift(nan) == nan\n    assert polar_lift(zoo) == zoo\n"], "sample_155": ["def test_get_units_non_prefixed():\n    assert set(SI.get_units_non_prefixed()) == {\n        meter, second, kilogram, ampere, kelvin, mole, candela,\n        gram, joule, newton, pascal, watt, volt, ohm, coulomb, farad,\n        henry, siemens, weber, tesla, henry, lux, becquerel, gray, sievert,\n        radian, steradian, katal, day, hour, minute, bit, byte\n    }\n", "def test_get_units_non_prefixed():\n    assert SI.get_units_non_prefixed() == {\n        meter, second, joule, kilogram, coulomb, molar_gas_constant,\n        vacuum_permittivity, elementary_charge, volt, ohm, day, hour, minute,\n        bit, byte, gravitational_constant\n    }\n", "def test_UnitSystem_get_unit_system():\n    assert UnitSystem.get_unit_system(\"SI\") == SI\n    with raises(ValueError):\n        UnitSystem.get_unit_system(\"nonexistent\")\n", "def test_get_units_non_prefixed():\n    assert meter in SI.get_units_non_prefixed()\n    assert joule in SI.get_units_non_prefixed()\n    assert day in SI.get_units_non_prefixed()\n    assert second in SI.get_units_non_prefixed()\n    assert volt in SI.get_units_non_prefixed()\n    assert ohm in SI.get_units_non_prefixed()\n    assert centimeter not in SI.get_units_non_prefixed()\n    assert kilometer not in SI.get_units_non_prefixed()\n    assert kilogram not in SI.get_units_non_prefixed()\n    assert pebibyte not in SI.get_units_non_prefixed()\n", "def test_get_units_non_prefixed():\n    assert set(SI.get_units_non_prefixed()) == {\n        meter, second, kilogram, ampere, kelvin, mole, candela,\n        gram, joule, newton, pascal, watt, volt, ohm, siemens,\n        coulomb, farad, henry, tesla, weber, lux, becquerel, gray,\n        sievert, katal\n    }\n"], "sample_83": ["def test_colorized_text_reporter_message_style() -> None:\n    reporter = ColorizedTextReporter()\n    msg_style = reporter._get_decoration(\"I\")\n    assert msg_style.color == \"green\"\n    assert not msg_style.style\n\n    msg_style = reporter._get_decoration(\"C\")\n    assert msg_style.color is None\n    assert msg_style.style == (\"bold\",)\n\n    msg_style = reporter._get_decoration(\"R\")\n    assert msg_style.color == \"magenta\"\n    assert msg_style.style == (\"bold\", \"italic\")\n\n    msg_style = reporter._get_decoration(\"W\")\n    assert msg_style.color == \"magenta\"\n    assert not msg_style.style\n\n    msg_style = reporter._get_decoration(\"E\")\n    assert msg_style.color == \"red\"\n    assert msg_style.style == (\"bold\",)\n\n    msg_style = reporter._get_decoration(\"F\")\n    assert msg_style.color == \"red\"\n    assert msg_style.style == (\"bold\", \"underline\")\n\n    msg_style = reporter._get_decoration(\"S\")\n    assert msg_style.color == \"yellow\"\n    assert msg_style.style == (\"inverse\",)\n", "def test_colorized_output_deprecation() -> None:\n    \"\"\"Test that using a deprecated color parameter raises a deprecation warning.\"\"\"\n    with warnings.catch_warnings(record=True) as cm:\n        warnings.simplefilter(\"always\")\n        colorize_ansi(\"message\", \"red\")\n\n    assert len(cm) == 1\n    assert isinstance(cm[0].message, DeprecationWarning)\n", "def test_colorized_text_reporter_color_mapping_deprecation() -> None:\n    \"\"\"TODO remove in 3.0.\"\"\"\n    color_mapping = {\"I\": (\"green\", \"bold\")}\n    with warnings.catch_warnings(record=True) as cm:\n        warnings.simplefilter(\"always\")\n        ColorizedTextReporter(color_mapping=color_mapping)\n\n    assert len(cm) == 1\n    assert isinstance(cm[0].message, DeprecationWarning)\n", "def test_colorized_output() -> None:\n    \"\"\"Test the ColorizedTextReporter.\"\"\"\n    output = StringIO()\n    reporter = ColorizedTextReporter(output)\n    message = Message(\n        symbol=\"missing-docstring\",\n        msg_id=\"C0123\",\n        location=MessageLocationTuple(\"abspath\", \"path\", \"module\", \"obj\", 1, 2, 1, 3),\n        msg=\"Not modified\",\n        confidence=HIGH,\n    )\n\n    reporter.handle_message(message)\n\n    assert output.getvalue().startswith(\"\\033[\")\n    assert \"Not modified\" in output.getvalue()\n    assert output.getvalue().endswith(\"\\n\")\n", "def test_colorized_output() -> None:\n    \"\"\"Test colorized output.\"\"\"\n    output = StringIO()\n    reporter = ColorizedTextReporter(output)\n    message = Message(\n        symbol=\"missing-docstring\",\n        msg_id=\"C0123\",\n        location=MessageLocationTuple(\"abspath\", \"path\", \"module\", \"obj\", 1, 2, 1, 3),\n        msg=\"Not modified\",\n        confidence=HIGH,\n    )\n    reporter.handle_message(message)\n    assert \"\\033[\" in output.getvalue()\n"], "sample_43": ["def test_serialize_result_with_missing_to_field_name(self):\n    class AutocompleteJsonSerializeResultView(AutocompleteJsonView):\n            return {\n                **super().serialize_result(obj, to_field_name),\n                'posted': str(obj.posted),\n            }\n\n    Question.objects.create(question='Question 1', posted=datetime.date(2021, 8, 9))\n    request = self.factory.get(self.url, {'term': 'question', **self.opts})\n    request.user = self.superuser\n    with mock.patch.object(AutocompleteJsonSerializeResultView, 'get_queryset') as get_queryset:\n        get_queryset.return_value = Question.objects.all()\n        response = AutocompleteJsonSerializeResultView.as_view(**self.as_view_args)(request)\n    self.assertEqual(response.status_code, 200)\n    data = json.loads(response.content.decode('utf-8'))\n    self.assertEqual(data, {\n        'results': [\n            {'id': str(q.pk), 'text': q.question, 'posted': str(q.posted)}\n            for q in Question.objects.order_by('-posted')\n        ],\n        'pagination': {'more': False},\n    })\n", "def test_process_request_bad_request(self):\n    # Test that process_request raises PermissionDenied on a bad request.\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': 'nonexistent'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n", "def test_process_request_invalid_params(self):\n    request = self.factory.get(self.url, {'term': 'is', **self.opts})\n    del request.GET['app_label']\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n\n    request = self.factory.get(self.url, {'term': 'is', **self.opts})\n    del request.GET['model_name']\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n\n    request = self.factory.get(self.url, {'term': 'is', **self.opts})\n    del request.GET['field_name']\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n", "def test_process_request_invalid_parameters(self):\n    request = self.factory.get(self.url, {'term': 'is', **self.opts, 'field_name': None})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n\n    request = self.factory.get(self.url, {'term': 'is', **self.opts, 'app_label': None})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n\n    request = self.factory.get(self.url, {'term': 'is', **self.opts, 'model_name': None})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n", "def test_process_request_app_label_error(self):\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': 'nonexistent', 'model_name': Answer._meta.model_name, 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n"], "sample_137": ["def test_roundrobin():\n    assert list(roundrobin('ABC', 'D', 'EF')) == ['A', 'D', 'E', 'B', 'F', 'C']\n    assert list(roundrobin([1, 2], [3, 4, 5], [6])) == [1, 3, 6, 2, 4, 5]\n    assert list(roundrobin([1], [2], [3])) == [1, 2, 3]\n    assert list(roundrobin([1, 2, 3], [], [4, 5, 6])) == [1, 4, 2, 5, 3, 6]\n", "def test_roundrobin():\n    assert list(roundrobin('ABC', 'D', 'EF')) == ['A', 'D', 'E', 'B', 'F', 'C']\n", "def test_roundrobin():\n    gen = roundrobin('ABC', 'D', 'EF')\n    assert next(gen) == 'A'\n    assert next(gen) == 'D'\n    assert next(gen) == 'E'\n    assert next(gen) == 'B'\n    assert next(gen) == 'F'\n    assert next(gen) == 'C'\n    raises(StopIteration, lambda: next(gen))\n", "def test_roundrobin():\n    gen = roundrobin('ABC', 'D', 'EF')\n    assert next(gen) == 'A'\n    assert next(gen) == 'D'\n    assert next(gen) == 'E'\n    assert next(gen) == 'B'\n    assert next(gen) == 'F'\n    assert next(gen) == 'C'\n    raises(StopIteration, lambda: next(gen))\n", "def test_roundrobin():\n    gen = roundrobin('ABC', 'D', 'EF')\n    assert next(gen) == 'A'\n    assert next(gen) == 'D'\n    assert next(gen) == 'E'\n    assert next(gen) == 'B'\n    assert next(gen) == 'F'\n    assert next(gen) == 'C'\n    raises(StopIteration, lambda: next(gen))\n"], "sample_68": ["def test_fields_with_db_columns(self):\n    FieldsWithDbColumns.objects.bulk_create(\n        [\n            FieldsWithDbColumns(char_field=\"abc\", integer_field=123),\n            FieldsWithDbColumns(char_field=\"def\", integer_field=456),\n        ]\n    )\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n    self.assertCountEqual(\n        FieldsWithDbColumns.objects.values(\"char_field\", \"integer_field\"),\n        [\n            {\"char_field\": \"abc\", \"integer_field\": 123},\n            {\"char_field\": \"def\", \"integer_field\": 456},\n        ],\n    )\n", "def test_update_conflicts_fields(self):\n    Country.objects.bulk_create(self.data)\n    self.assertEqual(Country.objects.count(), 4)\n\n    new_data = [\n        # Conflicting countries.\n        Country(\n            name=\"Germany\",\n            iso_two_letter=\"DE\",\n            description=(\"Germany is a country in Central Europe.\"),\n            last_modified=Now(),\n        ),\n        Country(\n            name=\"Czech Republic\",\n            iso_two_letter=\"CZ\",\n            description=(\n                \"The Czech Republic is a landlocked country in Central Europe.\"\n            ),\n            last_modified=Now(),\n        ),\n        # New countries.\n        Country(name=\"Australia\", iso_two_letter=\"AU\"),\n        Country(\n            name=\"Japan\",\n            iso_two_letter=\"JP\",\n            description=(\"Japan is an island country in East Asia.\"),\n            last_modified=Now(),\n        ),\n    ]\n    fields = [\"description\", \"last_modified\"]\n    results = Country.objects.bulk_create(\n        new_data,\n        update_conflicts=True,\n        update_fields=fields,\n    )\n    self.assertEqual(len(results), len(new_data))\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(Country.objects.count(), 6)\n    self.assertCountEqual(\n        Country.objects.values(\"iso_two_letter\", \"description\", \"last_modified\"),\n        [\n            {\"iso_two_letter\": \"US\", \"description\": \"\", \"last_modified\": None},\n            {\"iso_two_letter\": \"NL\", \"description\": \"\", \"last_modified\": None},\n            {\n                \"iso_two_letter\": \"DE\",\n                \"description\": (\"Germany is a country in Central Europe.\"),\n                \"last_modified__isnull\": False,\n            },\n            {\n                \"iso_two_letter\": \"CZ\",\n                \"description\": (\n                    \"The Czech Republic is a landlocked country in Central Europe.\"\n                ),\n                \"last_modified__isnull\": False,\n            },\n            {\"iso_two_letter\": \"AU\", \"description\": \"\", \"last_modified\": None},\n            {\n                \"iso_two_letter\": \"JP\",\n                \"description\": (\"Japan is an island country in East Asia.\"),\n                \"last_modified__isnull\": False,\n            },\n        ],\n    )\n", "def test_update_conflicts_nonexistent_field(self):\n    unique_fields = None\n    if connection.features.supports_update_conflicts_with_target:\n        unique_fields = [\"pk\"]\n    msg = \"bulk_create() can only be used with concrete fields in update_fields.\"\n    with self.assertRaisesMessage(ValueError, msg):\n        FieldsWithDbColumns.objects.bulk_create(\n            [FieldsWithDbColumns(x=\"foo\")],\n            update_conflicts=True,\n            update_fields=[\"nonexistent\"],\n            unique_fields=unique_fields,\n        )\n", "def test_update_conflicts_with_fields_db_column(self):\n    FieldsWithDbColumns.objects.bulk_create(\n        [\n            FieldsWithDbColumns(field1=\"foo\", field2=\"bar\"),\n            FieldsWithDbColumns(field1=\"baz\", field2=\"qux\"),\n        ]\n    )\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n\n    conflicting_objects = [\n        FieldsWithDbColumns(field1=\"foo\", field2=\"quux\"),\n        FieldsWithDbColumns(field1=\"baz\", field2=\"corge\"),\n    ]\n    results = FieldsWithDbColumns.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        update_fields=[\"field2\"],\n        unique_fields=[\"field1\"],\n    )\n    self.assertEqual(len(results), len(conflicting_objects))\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n    self.assertCountEqual(\n        FieldsWithDbColumns.objects.values(\"field1\", \"field2\"),\n        [\n            {\"field1\": \"foo\", \"field2\": \"quux\"},\n            {\"field1\": \"baz\", \"field2\": \"corge\"},\n        ],\n    )\n", "def test_bulk_create_with_fields_clash(self):\n    FieldsWithDbColumns.objects.bulk_create(\n        [\n            FieldsWithDbColumns(f1=\"f1_value\", f2=\"f2_value\"),\n        ]\n    )\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 1)\n    obj = FieldsWithDbColumns.objects.get()\n    self.assertEqual(obj.f1, \"f1_value\")\n    self.assertEqual(obj.f2, \"f2_value\")\n"], "sample_119": ["def test_Sum():\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]]\"\n    assert mcode(Sum(x**2 + y**2, (x, 1, 10), (y, 1, 5))) == \\\n        \"Hold[Sum[x^2 + y^2, {x, 1, 10}, {y, 1, 5}]]\"\n    assert mcode(Sum(sin(x)*y**4, (x, 1, 10), (y, 1, 5))) == \\\n        \"Hold[Sum[y^4*Sin[x], {x, 1, 10}, {y, 1, 5}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]]\"\n    assert mcode(Sum(x**2 + y**2, (x, 1, 10), (y, 1, 10))) == \\\n        \"Hold[Sum[x^2 + y^2, {x, 1, 10}, {y, 1, 10}]]\"\n", "def test_Sum():\n    assert mcode(Sum(1/x, (x, 1, 10))) == \"Hold[Sum[1/x, {x, 1, 10}]]\"\n    assert mcode(Sum(x*y, (x, 1, 10), (y, 1, 10))) == \\\n        \"Hold[Sum[x*y, {x, 1, 10}, {y, 1, 10}]]\"\n    assert mcode(Sum(sin(x), (x, 0, oo))) == \"Hold[Sum[Sin[x], {x, 0, Infinity}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]]\"\n    assert mcode(Sum(x**2 + y**2, (x, 1, 10), (y, 1, 10))) == \\\n        \"Hold[Sum[x^2 + y^2, {x, 1, 10}, {y, 1, 10}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]]\"\n    assert mcode(Sum(x*y, (x, 1, 5), (y, 1, 3))) == \"Hold[Sum[x*y, {x, 1, 5}, {y, 1, 3}]]\"\n    assert mcode(Sum(sin(x), (x, -oo, oo))) == \"Hold[Sum[Sin[x], {x, -Infinity, Infinity}]]\"\n"], "sample_79": ["def test_concat_positions(self):\n    ds1 = Dataset(\n        {\n            \"has_x_y\": ((\"y\", \"x\"), [[1, 2]]),\n            \"has_x\": (\"x\", [1, 2]),\n            \"no_x_y\": (\"z\", [1, 2]),\n        },\n        coords={\"x\": [0, 1], \"y\": [0], \"z\": [-1, -2]},\n    )\n    ds2 = Dataset(\n        {\n            \"has_x_y\": ((\"y\", \"x\"), [[3, 4]]),\n            \"has_x\": (\"x\", [1, 2]),\n            \"no_x_y\": ((\"q\", \"z\"), [[1, 2]]),\n        },\n        coords={\"x\": [0, 1], \"y\": [1], \"z\": [-1, -2], \"q\": [0]},\n    )\n\n    positions = [0, 1]\n    result = concat([ds1, ds2], dim=\"y\", data_vars=\"minimal\", positions=positions)\n    assert_equal(result.coords[\"y\"].values, [0, 1])\n\n    with raises_regex(ValueError, \"positions has different length\"):\n        concat([ds1, ds2, ds1], dim=\"y\", positions=[0, 1])\n", "def test_concat_positions(self):\n    data = Dataset(\n        {\n            \"foo\": ([\"x\", \"y\"], np.random.random((2, 3))),\n            \"bar\": ([\"x\", \"y\"], np.random.random((2, 3))),\n        },\n        {\"x\": [0, 1]},\n    )\n    foo = data[\"foo\"]\n    bar = data[\"bar\"]\n\n    # specify positions\n    actual = concat([foo, bar], \"w\", positions=[0, 1])\n    expected = DataArray(\n        np.array([foo.values, bar.values]),\n        dims=[\"w\", \"x\", \"y\"],\n        coords={\"x\": [0, 1]},\n    )\n    assert_equal(expected, actual)\n\n    # specify positions with coordinate\n    actual = concat([foo, bar], \"w\", positions=[10, 20])\n    expected = DataArray(\n        np.array([foo.values, bar.values]),\n        dims=[\"w\", \"x\", \"y\"],\n        coords={\"w\": [10, 20], \"x\": [0, 1]},\n    )\n    assert_equal(expected, actual)\n", "def test_concat_with_new_dim(self):\n    ds1 = Dataset({\"foo\": (\"x\", [1, 2])}, {\"x\": [0, 1]})\n    ds2 = Dataset({\"foo\": (\"x\", [3, 4])}, {\"x\": [2, 3]})\n\n    expected = Dataset(\n        {\"foo\": ((\"y\", \"x\"), [[1, 2], [3, 4]])},\n        {\"x\": [0, 1, 2, 3], \"y\": [0, 1]},\n    )\n\n    actual = concat([ds1, ds2], dim=\"y\")\n    assert_identical(actual, expected)\n", "def test_concat_positions(self):\n    # Test that the `positions` argument works as expected\n    data = create_test_data()\n    split_data = [data.isel(dim1=slice(3)), data.isel(dim1=slice(3, None))]\n    positions = [[0, 1, 2], [4, 5, 6]]\n    actual = concat(split_data, dim=\"dim1\", positions=positions)\n    expected = data.copy()\n    expected[\"dim1\"] = [0, 1, 2, 4, 5, 6]\n    assert_identical(actual, expected)\n\n    # Test that the `positions` argument raises an error when its length does not match the number of datasets\n    with pytest.raises(ValueError):\n        concat(split_data, dim=\"dim1\", positions=[[0, 1, 2]])\n\n    # Test that the `positions` argument raises an error when the lengths of the sublists do not match the dimensions of the datasets\n    with pytest.raises(ValueError):\n        concat(split_data, dim=\"dim1\", positions=[[0, 1, 2], [4, 5]])\n", "def test_concat_positions(self):\n    # Test that the positions argument works as expected\n    ds1 = Dataset({\"a\": (\"x\", [1, 2])}, {\"x\": [0, 1]})\n    ds2 = Dataset({\"a\": (\"x\", [3, 4])}, {\"x\": [0, 1]})\n\n    # Specify positions manually\n    actual = concat([ds1, ds2], dim=\"y\", positions=[[0], [1]])\n    expected = Dataset(\n        {\"a\": ((\"y\", \"x\"), [[1, 2], [3, 4]])},\n        {\"x\": [0, 1], \"y\": [0, 1]},\n    )\n    assert_identical(actual, expected)\n\n    # Omit positions to use default behavior\n    actual = concat([ds1, ds2], dim=\"y\")\n    assert_identical(actual, expected)\n"], "sample_88": ["def test_saferepr_recursive():\n    \"\"\"Test saferepr() with recursive objects.\"\"\"\n    class Recursive:\n            self.name = name\n            self.children = []\n\n            return f\"Recursive({self.name})\"\n\n            self.children.append(child)\n\n    parent = Recursive(\"parent\")\n    child = Recursive(\"child\")\n    parent.add_child(child)\n    child.add_child(parent)  # Create a cycle\n\n    repr_str = saferepr(parent)\n    assert \"Recursive('parent')\" in repr_str\n    assert \"Recursive('child')\" in repr_str\n    assert \"...\" in repr_str  # Check for ellipsis indicating recursion\n", "def test_saferepr_recursive():\n    \"\"\"Test saferepr() with recursive objects.\"\"\"\n\n    class Recursive:\n            self.attr = None\n\n            return \"Recursive({})\".format(saferepr(self.attr))\n\n    r1 = Recursive()\n    r2 = Recursive()\n    r1.attr = r2\n    r2.attr = r1\n\n    assert saferepr(r1) == \"Recursive(Recursive(...))\"\n", "def test_saferepr_recursive():\n    \"\"\"Test saferepr() with recursive objects.\"\"\"\n\n    class Recursive:\n            self.attr = None\n\n            return \"Recursive({})\".format(saferepr(self.attr))\n\n    obj1 = Recursive()\n    obj2 = Recursive()\n    obj1.attr = obj2\n    obj2.attr = obj1\n\n    assert saferepr(obj1).startswith(\"Recursive(\")\n    assert \"...\" in saferepr(obj1)\n    assert \"...\" in saferepr(obj2)\n", "def test_saferepr_recursive():\n    \"\"\"Test saferepr() with recursive structures.\"\"\"\n\n    class Node:\n            self.value = value\n            self.children = []\n\n            return f\"Node({self.value})\"\n\n    node1 = Node(1)\n    node2 = Node(2)\n    node3 = Node(3)\n\n    node1.children.append(node2)\n    node2.children.append(node3)\n    node3.children.append(node1)  # Create a cycle\n\n    repr_node1 = saferepr(node1)\n    assert \"Node(1)\" in repr_node1\n    assert \"...\" in repr_node1  # Check for ellipsis\n", "def test_saferepr_with_recursive_object():\n    \"\"\"Test saferepr() with recursive objects.\"\"\"\n\n    class RecursiveObject:\n            self.name = name\n            self.children = []\n\n            return f\"<{self.name}>\"\n\n    obj1 = RecursiveObject(\"obj1\")\n    obj2 = RecursiveObject(\"obj2\")\n    obj1.children.append(obj2)\n    obj2.children.append(obj1)\n\n    assert \"RecursionError\" not in saferepr(obj1)\n    assert \"...\" in saferepr(obj1, maxsize=20)\n"], "sample_21": ["def test_delete_with_m2m_through_model(self):\n    m = M.objects.create()\n    r = R.objects.create()\n    mr = MR.objects.create(m=m, r=r)\n    m.delete()\n    self.assertFalse(MR.objects.filter(id=mr.id).exists())\n    self.assertFalse(R.objects.filter(id=r.id).exists())\n\n    m = M.objects.create()\n    r = R.objects.create()\n    mr = MR.objects.create(m=m, r=r)\n    r.delete()\n    self.assertFalse(MR.objects.filter(id=mr.id).exists())\n    self.assertFalse(M.objects.filter(id=m.id).exists())\n", "def test_collector_dependency_resolution(self):\n    # Create objects with complex dependencies\n    parent = Parent.objects.create()\n    child1 = Child.objects.create(parent=parent)\n    child2 = Child.objects.create(parent=parent)\n    grandchild11 = Child.objects.create(parent=child1)\n    grandchild12 = Child.objects.create(parent=child1)\n    grandchild21 = Child.objects.create(parent=child2)\n\n    collector = Collector(using='default')\n    collector.collect([parent], keep_parents=False)\n\n    self.assertEqual(len(collector.data), 3)  # Parent, Child, Grandchildren\n\n    self.assertEqual(\n        len(collector.dependencies),\n        3  # Parent -> Child -> Grandchildren\n    )\n\n    self.assertIn(Child._meta.concrete_model, collector.dependencies[Parent._meta.concrete_model])\n    self.assertIn(\n        Child._meta.concrete_model,\n        collector.dependencies[Child._meta.concrete_model]\n    )\n    self.assertNotIn(\n        Parent._meta.concrete_model,\n        collector.dependencies[Child._meta.concrete_model]\n    )\n", "def test_delete_with_inheritance_and_related_objects(self):\n    child = RChild.objects.create()\n    related_obj = S.objects.create(r=child.r_ptr)\n    parent_id = child.r_ptr_id\n\n    collector = Collector(using='default')\n    collector.collect([child], keep_parents=True)\n\n    # Check that the collector has collected all related objects.\n    self.assertIn(related_obj, collector.data[S])\n\n    # Delete the child object, keeping parents.\n    child.delete(keep_parents=True)\n\n    # Check that the child object is deleted.\n    self.assertFalse(RChild.objects.filter(id=child.id).exists())\n\n    # Check that the parent object still exists.\n    self.assertTrue(R.objects.filter(id=parent_id).exists())\n\n    # Check that the related object is deleted.\n    self.assertFalse(S.objects.filter(id=related_obj.id).exists())\n", "def test_collector_clear_restricted_objects_from_set(self):\n    collector = Collector(using='default')\n    model = A\n    objs = [A.objects.create() for _ in range(3)]\n    field = A._meta.get_field('restrict')\n    collector.restricted_objects[model][field].update(objs)\n    collector.clear_restricted_objects_from_set(model, set(objs[:2]))\n    self.assertEqual(len(collector.restricted_objects[model][field]), 1)\n    self.assertIn(objs[2], collector.restricted_objects[model][field])\n", "def test_collector_instances_with_model(self):\n    collector = Collector(using='default')\n    r = R.objects.create()\n    s1 = S.objects.create(r=r)\n    s2 = S.objects.create(r=r)\n    T.objects.create(s=s1)\n    T.objects.create(s=s2)\n    collector.collect([r])\n    instances = list(collector.instances_with_model())\n    self.assertEqual(len(instances), 5)\n    self.assertEqual(instances[0][0], T)\n    self.assertEqual(instances[1][0], T)\n    self.assertEqual(instances[2][0], S)\n    self.assertEqual(instances[3][0], S)\n    self.assertEqual(instances[4][0], R)\n"], "sample_69": ["def test_set_mouseover():\n    fig, ax = plt.subplots()\n    art = martist.Artist()\n    ax.add_artist(art)\n    assert not art.get_mouseover()\n    art.set_mouseover(True)\n    assert art.get_mouseover()\n    assert art in ax._mouseover_set\n    art.set_mouseover(False)\n    assert not art.get_mouseover()\n    assert art not in ax._mouseover_set\n", "def test_artist_inspector_get_setters():\n    # test the correct format and type of get_setters method\n    ai = martist.ArtistInspector(mlines.Line2D)\n    setters = ai.get_setters()\n    assert 'linewidth' in setters\n    assert isinstance(setters, list)\n", "def test_artist_stale():\n    art = martist.Artist()\n    assert art.stale\n\n    art.stale = False\n    assert not art.stale\n\n    # Setting a property should set stale to True.\n    art.set_alpha(0.5)\n    assert art.stale\n", "def test_artist_findobj():\n    fig, ax = plt.subplots()\n    ln, = ax.plot([1, 2, 3])\n    assert ln in ax.findobj(mlines.Line2D)\n    assert ln not in ax.findobj(mpatches.Rectangle)\n    assert ax in fig.findobj(plt.Axes)\n    assert ln in fig.findobj(mlines.Line2D)\n\n    class Match:\n            return isinstance(artist, mlines.Line2D)\n\n    assert ln in ax.findobj(Match())\n    assert ln in fig.findobj(Match())\n\n    assert ax.findobj(id(ln)) == [ln]\n    assert fig.findobj(id(ln)) == [ln]\n", "def test_artist_findobj():\n    fig, ax = plt.subplots()\n    ln, = ax.plot([1, 2, 3])\n    txt = ax.text(0.5, 0.5, \"text\")\n\n    # Test findobj with match=None.\n    artists = ln.findobj(match=None)\n    assert len(artists) == 1\n    assert artists[0] is ln\n\n    # Test findobj with match being a function.\n        return isinstance(artist, mlines.Line2D)\n\n    artists = fig.findobj(match=match)\n    assert len(artists) == 1\n    assert artists[0] is ln\n\n    # Test findobj with match being an Artist subclass.\n    artists = fig.findobj(match=mlines.Line2D)\n    assert len(artists) == 1\n    assert artists[0] is ln\n\n    # Test findobj with match being a class instance.\n    artists = fig.findobj(match=txt)\n    assert len(artists) == 0\n\n    # Test include_self parameter.\n    artists = fig.findobj(include_self=False)\n    assert fig not in artists\n\n    # Test recursive search.\n    artists = ax.findobj(match=match)\n    assert len(artists) == 1\n    assert artists[0] is ln\n"], "sample_121": ["def test_printing_array():\n    Permutation.print_cyclic = False\n    p1 = Permutation([0, 2, 1])\n    assert repr(p1) == 'Permutation([0, 2, 1])'\n    assert str(p1) == '[0, 2, 1]'\n    p2 = Permutation()\n    assert repr(p2) == 'Permutation([])'\n    assert str(p2) == '[]'\n    p3 = Permutation([1, 2, 0, 3], size=5)\n    assert repr(p3) == 'Permutation([1, 2, 0, 3], size=5)'\n    assert str(p3) == '[1, 2, 0, 3]'\n", "def test_from_inversion_vector():\n    p = Permutation([0, 2, 1])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n\n    q = Permutation([4, 1, 3, 0, 2])\n    assert Permutation.from_inversion_vector(q.inversion_vector()) == q\n\n    r = Permutation([5, 1, 4, 3, 2, 0])\n    assert Permutation.from_inversion_vector(r.inversion_vector()) == r\n\n    raises(ValueError, lambda: Permutation.from_inversion_vector([1, 2, 3, -1]))\n    raises(ValueError, lambda: Permutation.from_inversion_vector([1, 2, 3, 4, 6]))\n", "def test_cycle_structure():\n    p = Permutation([0, 2, 1])\n    assert p.cycle_structure == {2: 1, 1: 1}\n    q = Permutation([3, 2, 1, 0])\n    assert q.cycle_structure == {4: 1}\n    r = Permutation([1, 0, 3, 2])\n    assert r.cycle_structure == {2: 2}\n", "def test_cycle_structure():\n    p = Permutation([1, 2, 0, 4, 3])\n    assert p.cycle_structure == {2: 1, 1: 1}\n    q = Permutation([0, 1, 2])\n    assert q.cycle_structure == {1: 3}\n    r = Permutation([2, 0, 1, 3, 4])\n    assert r.cycle_structure == {3: 1, 1: 2}\n", "def test_cycle_structure():\n    p = Permutation([1, 0, 2, 3])\n    assert p.cycle_structure == {2: 1}\n    p = Permutation([0, 1, 3, 2])\n    assert p.cycle_structure == {2: 1}\n    p = Permutation([0, 2, 1])\n    assert p.cycle_structure == {2: 1, 1: 1}\n    p = Permutation([0, 1, 2])\n    assert p.cycle_structure == {1: 3}\n"], "sample_58": ["def test_runshell(self):\n    with mock.patch.object(DatabaseClient, 'runshell') as mock_runshell:\n        db_client = DatabaseClient(connection)\n        original_sigint_handler = signal.getsignal(signal.SIGINT)\n        try:\n            db_client.runshell()\n            self.assertEqual(signal.getsignal(signal.SIGINT), original_sigint_handler)\n        finally:\n            signal.signal(signal.SIGINT, original_sigint_handler)\n\n        try:\n            db_client.runshell()\n            mock_runshell.assert_called_once()\n        except Exception:\n            signal.signal(signal.SIGINT, original_sigint_handler)\n            raise\n", "def test_runshell_restores_sigint_handler(self):\n    \"\"\"SIGINT handler is restored after runshell.\"\"\"\n    sigint_handler = signal.getsignal(signal.SIGINT)\n    with mock.patch.object(DatabaseClient, \"runshell\") as mocked_runshell:\n        client = DatabaseClient()\n        client.runshell([])\n    self.assertEqual(signal.getsignal(signal.SIGINT), sigint_handler)\n", "def test_no_dbname_or_service(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env({}),\n        ([\"psql\", \"postgres\"], None),\n    )\n", "def test_runshell_parameters(self):\n    with mock.patch(\"subprocess.run\") as mock_run:\n        client = DatabaseClient(connection)\n        client.runshell([\"--help\"])\n        mock_run.assert_called_once_with(\n            [\"psql\", \"--help\", connection.settings_dict[\"NAME\"]],\n            stdout=sys.stdout,\n            stderr=subprocess.STDOUT,\n            env=None,\n            check=True,\n        )\n", "def test_runshell(self):\n    with mock.patch(\"django.db.backends.postgresql.client.DatabaseClient.runshell\") as runshell:\n        database_client = DatabaseClient(connection)\n        database_client.runshell()\n        self.assertEqual(signal.getsignal(signal.SIGINT), signal.SIG_IGN)\n        signal.signal(signal.SIGINT, signal.SIG_DFL)  # Restore default handler\n        runshell.assert_called_once()\n"], "sample_41": ["def test_formset_media(self):\n    \"\"\"Media is available on formsets.\"\"\"\n    class MediaForm(Form):\n        class Media:\n            js = ('some-file.js',)\n    self.assertIn('some-file.js', str(formset_factory(MediaForm)().media))\n", "def test_all_valid_short_circuit(self):\n    class InvalidFormSet(BaseFormSet):\n            raise Exception(\"Shouldn't be called\")\n\n    data = {\n        'choices-TOTAL_FORMS': '2',\n        'choices-INITIAL_FORMS': '0',\n        'choices-MIN_NUM_FORMS': '0',\n        'choices-0-choice': 'Zero',\n        'choices-0-votes': '0',\n        'choices-1-choice': 'One',\n        'choices-1-votes': '1',\n    }\n    ChoiceFormSet = formset_factory(Choice)\n    InvalidChoiceFormSet = formset_factory(Choice, formset=InvalidFormSet)\n\n    formset1 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n    formset1.is_valid()  # Make sure formset1 is bound and validated.\n    formset2 = InvalidChoiceFormSet(data, auto_id=False, prefix='choices')\n\n    self.assertIs(all_valid((formset1, formset2)), False)\n", "def test_formset_media(self):\n    \"\"\"A Formset's media is the collection of all its forms' media.\"\"\"\n    class MediaForm(Form):\n        class Media:\n            js = ('some-file.js',)\n    self.assertIn('some-file.js', str(formset_factory(MediaForm)().media))\n    self.assertIn('some-file.js', str(formset_factory(MediaForm, extra=2)().media))\n    class AnotherMediaForm(Form):\n        class Media:\n            js = ('another-file.js',)\n    self.assertIn('some-file.js', str(formset_factory(MediaForm)().media))\n    self.assertIn('another-file.js', str(formset_factory(AnotherMediaForm)().media))\n    self.assertNotIn('another-file.js', str(formset_factory(MediaForm)().media))\n", "def test_formset_non_form_error(self):\n    \"\"\"Test that non-form errors are correctly rendered.\"\"\"\n    class NonFormErrorFormSet(BaseFormSet):\n            raise ValidationError('This is a non-form error')\n\n    NonFormErrorFormset = formset_factory(FavoriteDrinkForm, formset=NonFormErrorFormSet)\n    data = {\n        'form-TOTAL_FORMS': '1',\n        'form-INITIAL_FORMS': '0',\n        'form-0-name': 'Gin and Tonic',\n    }\n    formset = NonFormErrorFormset(data, prefix='form')\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(formset.non_form_errors(), ['This is a non-form error'])\n    self.assertHTMLEqual(\n        str(formset),\n        '<tr><td colspan=\"2\"><ul class=\"errorlist nonform\">'\n        '<li>This is a non-form error</li></ul></td></tr>\\n'\n        '<input type=\"hidden\" name=\"form-TOTAL_FORMS\" value=\"1\">'\n        '<input type=\"hidden\" name=\"form-INITIAL_FORMS\" value=\"0\">'\n        '<input type=\"hidden\" name=\"form-MIN_NUM_FORMS\" value=\"0\">'\n        '<input type=\"hidden\" name=\"form-MAX_NUM_FORMS\" value=\"1000\">'\n        '<tr><th><label for=\"id_form-0-name\">Name:</label></th>'\n        '<td><input type=\"text\" name=\"form-0-name\" value=\"Gin and Tonic\" id=\"id_form-0-name\"></td></tr>'\n    )\n", "def test_formset_clean_method_called(self):\n    \"\"\"Formset's clean method is called during full_clean.\"\"\"\n    class CleanMethodFormSet(BaseFormSet):\n            self.clean_called = True\n\n    FormSet = formset_factory(Choice, formset=CleanMethodFormSet)\n    formset = FormSet()\n    formset.full_clean()\n    self.assertTrue(formset.clean_called)\n"], "sample_94": ["def test_getstatement_with_empty_lines() -> None:\n    source = Source(\n        \"\"\"\\", "def test_getstatementrange_ast_with_empty_lines() -> None:\n    source = Source(\n        \"\"\"\\", "def test_getstatementrange_with_empty_lines() -> None:\n    source = Source(\n        \"\"\"\\\n            pass\n\n\n            pass\n    \"\"\"\n    )\n    assert len(source) == 6\n    assert source.getstatementrange(0) == (0, 2)\n    assert source.getstatementrange(3) == (4, 6)\n", "def test_getstatementrange_with_nested_try_except() -> None:\n    source = Source(\n        \"\"\"\\\n        try:\n            try:\n                raise ValueError\n            except ValueError:\n                raise IndexError(1)\n        except IndexError:\n            pass\n        \"\"\"\n    )\n    assert len(source) == 7\n    assert source.getstatementrange(2) == (2, 3)\n    assert source.getstatementrange(4) == (4, 5)\n    assert source.getstatementrange(6) == (6, 7)\n", "def test_source_indent() -> None:\n    source = Source(\n        \"\"\"\\\n            pass\n            pass\n    \"\"\"\n    )\n    indented_source = source.indent(\" \" * 2)\n    assert str(indented_source) == (\n        \"  def f(x):\\n\"\n        \"      pass\\n\"\n        \"  def g(x):\\n\"\n        \"      pass\"\n    )\n"], "sample_65": ["    def test_pluralize01(self):\n        output = self.engine.render_to_string(\"pluralize01\", {\"a\": 1})\n        self.assertEqual(output, \"\")\n", "    def test_floatformat01(self):\n        output = self.engine.render_to_string(\"floatformat01\", {\"num\": 34.23234})\n        self.assertEqual(output, \"34.2\")\n", "    def test_default_if_none01(self):\n        output = self.engine.render_to_string(\"default_if_none01\", {\"a\": None})\n        self.assertEqual(output, \"was None\")\n", "    def test_add01(self):\n        output = self.engine.render_to_string(\"add01\", {\"num1\": 5, \"num2\": 3})\n        self.assertEqual(output, \"8\")\n", "    def test_add01(self):\n        output = self.engine.render_to_string(\"add01\", {\"num1\": 5, \"num2\": 3})\n        self.assertEqual(output, \"8\")\n"], "sample_72": ["def test_subplots_adjust():\n    fig, ax = plt.subplots()\n    orig_size_inches = fig.get_size_inches()\n    orig_dpi = fig.dpi\n\n    # Set a new size in inches\n    fig.set_size_inches(4, 3)\n    assert fig.get_size_inches() == (4, 3)\n\n    # Reset to original size\n    fig.set_size_inches(orig_size_inches)\n    assert fig.get_size_inches() == orig_size_inches\n\n    # Set a new dpi\n    fig.dpi = 120\n    assert fig.dpi == 120\n\n    # Reset to original dpi\n    fig.dpi = orig_dpi\n    assert fig.dpi == orig_dpi\n\n    # Test setting bad values\n    with pytest.raises(ValueError):\n        fig.set_size_inches(-1, 2)\n    with pytest.raises(ValueError):\n        fig.set_size_inches(1, -2)\n    with pytest.raises(ValueError):\n        fig.set_size_inches(1, 2, forward=False)\n    with pytest.raises(ValueError):\n        fig.dpi = -100\n", "def test_subfigure_add_subplot():\n    fig = plt.figure()\n    subfig = fig.subfigures(1, 2)[0]\n    ax = subfig.add_subplot(111)\n    assert ax.get_subplotspec().get_gridspec() is not None\n", "def test_subfigure_add_artist():\n    fig = plt.figure()\n    subfig = fig.subfigures(1, 2)[0]\n    artist = plt.Line2D([0.5], [0.5])\n    added_artist = subfig.add_artist(artist)\n    assert added_artist is artist\n    assert artist.get_transform() == subfig.transSubfigure\n    assert artist in subfig.artists\n", "def test_figure_add_subplot_with_subplotspec():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    ss = gs[0, 1:]\n    ax = fig.add_subplot(ss)\n    assert ax.get_geometry() == (1, 2, 1)\n    assert ax.get_subplotspec().get_geometry() == (1, 2, 1)\n", "def test_subfigure_add_remove():\n    fig = plt.figure()\n    subfigs = fig.subfigures(2, 1)\n    ax1 = subfigs[0].subplots()\n    ax2 = subfigs[1].subplots()\n    assert len(fig.get_axes()) == 2\n    assert len(subfigs[0].get_axes()) == 1\n    assert len(subfigs[1].get_axes()) == 1\n\n    subfigs[0].delaxes(ax1)\n    assert len(fig.get_axes()) == 1\n    assert len(subfigs[0].get_axes()) == 0\n    assert len(subfigs[1].get_axes()) == 1\n\n    subfigs[0].add_subplot(111)\n    assert len(fig.get_axes()) == 2\n    assert len(subfigs[0].get_axes()) == 1\n    assert len(subfigs[1].get_axes()) == 1\n"], "sample_122": ["def test_row_structure_symbolic_cholesky():\n    S = SparseMatrix([\n        [1, 0, 3, 2],\n        [0, 0, 1, 0],\n        [4, 0, 0, 5],\n        [0, 6, 7, 0]])\n    assert S.row_structure_symbolic_cholesky() == [[0], [], [0], [1, 2]]\n", "def test_sparse_matrix_row_structure_symbolic_cholesky():\n    S = SparseMatrix([\n        [1, 0, 3, 2],\n        [0, 0, 1, 0],\n        [4, 0, 0, 5],\n        [0, 6, 7, 0]])\n    assert S.row_structure_symbolic_cholesky() == [[0], [], [0], [1, 2]]\n\n    # test with a symmetric matrix\n    S = SparseMatrix([\n        [1, 2, 3, 4],\n        [2, 5, 6, 7],\n        [3, 6, 8, 9],\n        [4, 7, 9, 10]])\n    assert S.row_structure_symbolic_cholesky() == [[0], [0], [0, 1], [0, 1, 2]]\n", "def test_liupc():\n    S = SparseMatrix([\n        [1, 0, 3, 2],\n        [0, 0, 1, 0],\n        [4, 0, 0, 5],\n        [0, 6, 7, 0]])\n    assert S.liupc() == ([[0], [], [0], [1, 2]], [4, 3, 4, 4])\n", "def test_mutable_sparse_matrix():\n    A = MutableSparseMatrix(3, 3, {})\n    A[0, 1] = 2\n    A[2, 2] = 5\n    assert A == SparseMatrix(((0, 2, 0), (0, 0, 0), (0, 0, 5)))\n    A.row_del(0)\n    assert A == SparseMatrix(((0, 0, 0), (0, 0, 5)))\n    A.col_del(2)\n    assert A == SparseMatrix(((0, 0), (0, 0)))\n    A.fill(1)\n    assert A == SparseMatrix(((1, 1), (1, 1)))\n    A[0, 0] = 0\n    assert A == SparseMatrix(((0, 1), (1, 1)))\n", "def test_sparse_matrix_row_col_operations():\n    # test row and column operations\n    A = SparseMatrix([\n        [1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]\n    ])\n\n    # test row swap\n    A.row_swap(0, 1)\n    assert A == SparseMatrix([\n        [4, 5, 6],\n        [1, 2, 3],\n        [7, 8, 9]\n    ])\n\n    # test col swap\n    A.col_swap(0, 1)\n    assert A == SparseMatrix([\n        [5, 4, 6],\n        [2, 1, 3],\n        [8, 7, 9]\n    ])\n\n    # test row delete\n    A.row_del(1)\n    assert A == SparseMatrix([\n        [5, 4, 6],\n        [8, 7, 9]\n    ])\n\n    # test col delete\n    A.col_del(1)\n    assert A == SparseMatrix([\n        [5, 6],\n        [8, 9]\n    ])\n\n    # test row insert\n    A.row_insert(1, SparseMatrix([1, 2]))\n    assert A == SparseMatrix([\n        [5, 6],\n        [1, 2],\n        [8, 9]\n    ])\n\n    # test col insert\n    A.col_insert(1, SparseMatrix([1, 2, 3]))\n    assert A == SparseMatrix([\n        [5, 1, 6],\n        [1, 2, 2],\n        [8, 3, 9]\n    ])\n"], "sample_91": ["def test_mark_xfail_with_invalid_raises(testdir):\n    \"\"\"\n    Verify that using pytest.mark.xfail with invalid raises parameter raises an error\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(raises=\"Invalid\")\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*TypeError:*\"])\n", "def test_xfail_strict_ini(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        xfail_strict = True\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n", "def test_xfail_mark_evaluation_condition(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n            assert 1\n\n            assert 0\n    \"\"\"\n    )\n    item = testdir.getitem(\"test_func\")\n    mark = pytest.mark.xfail(condition=\"True\", reason=\"expected failure\")\n    item.add_marker(mark)\n    result = evaluate_xfail_marks(item)\n    assert result.reason == \"expected failure\"\n\n    item = testdir.getitem(\"test_func2\")\n    mark = pytest.mark.xfail(condition=\"False\", reason=\"unexpected pass\")\n    item.add_marker(mark)\n    result = evaluate_xfail_marks(item)\n    assert result is None\n", "def test_xfail_strict_ini(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        xfail_strict = True\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail\n            assert 1\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n    assert result.ret == 1\n", "def test_xfail_strict_with_invalid_bool(self, testdir):\n    \"\"\"\n    Verify that using xfail(strict=...) with invalid boolean raises an error\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        class InvalidBool:\n                raise TypeError(\"INVALID\")\n\n        @pytest.mark.xfail(strict=InvalidBool())\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*TypeError:*INVALID*\"])\n"], "sample_115": ["def test__wrap_data_with_container():\n    \"\"\"Check _wrap_data_with_container works as expected.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    est = EstimatorWithSetOutput().fit(X)\n\n    # With output config set to \"default\", the data is not wrapped\n    output_config = _get_output_config(\"transform\", est)\n    assert output_config[\"dense\"] == \"default\"\n    data_to_wrap = est.transform(X)\n    wrapped_data = _wrap_data_with_container(\"transform\", data_to_wrap, X, est)\n    assert isinstance(wrapped_data, np.ndarray)\n\n    # With output config set to \"pandas\", the data is wrapped\n    est.set_output(transform=\"pandas\")\n    output_config = _get_output_config(\"transform\", est)\n    assert output_config[\"dense\"] == \"pandas\"\n    data_to_wrap = est.transform(X)\n    wrapped_data = _wrap_data_with_container(\"transform\", data_to_wrap, X, est)\n    assert isinstance(wrapped_data, pd.DataFrame)\n", "def test__wrap_in_pandas_container_column_callable():\n    \"\"\"Check that a callable `columns` can return the column names.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n        return [\"feat1\", \"feat2\"]\n\n    X_np = np.asarray([[1, 3], [2, 4], [3, 5]])\n    X_wrapped = _wrap_in_pandas_container(X_np, columns=get_columns)\n    assert_array_equal(X_wrapped.columns, [\"feat1\", \"feat2\"])\n", "def test__wrap_data_with_container_default_output():\n    \"\"\"Check _wrap_data_with_container with default output config.\"\"\"\n    est = EstimatorWithSetOutput().fit(np.asarray([[1, 2, 3]]))\n    X_trans = np.asarray([[4, 5, 6]])\n    wrapped_X = _wrap_data_with_container(\"transform\", X_trans, X_trans, est)\n    assert isinstance(wrapped_X, np.ndarray)\n", "def test__wrap_data_with_container_auto_wrap_false():\n    \"\"\"Check that _wrap_data_with_container does not wrap when auto_wrap is False.\"\"\"\n    est = EstimatorWithSetOutputNoAutoWrap()\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    assert X is _wrap_data_with_container(\"transform\", X, X, est)\n", "def test__wrap_data_with_container_error():\n    \"\"\"Check that _wrap_data_with_container raises an error if the output config is invalid.\"\"\"\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    est = EstimatorWithSetOutput().fit(X)\n\n    # Set the output config to an invalid value\n    est._sklearn_output_config = {\"transform\": \"invalid\"}\n\n    msg = \"output config must be 'default'\"\n    with pytest.raises(ValueError, match=msg):\n        _wrap_data_with_container(\"transform\", X, X, est)\n"], "sample_15": ["def test_language_settings_consistent_with_supported_language_variant(self):\n    msg = (\n        'You have provided a value for the LANGUAGE_CODE setting that is '\n        'not in the LANGUAGES setting.'\n    )\n    with self.settings(LANGUAGE_CODE='en', LANGUAGES=[('en-GB', 'English')]):\n        self.assertEqual(check_language_settings_consistent(None), [\n            Error(msg, id='translation.E004'),\n        ])\n    with self.settings(LANGUAGE_CODE='en-GB', LANGUAGES=[('en', 'English')]):\n        self.assertEqual(check_language_settings_consistent(None), [])\n", "def test_consistent_language_settings(self):\n    self.assertEqual(check_language_settings_consistent(None), [])\n", "def test_consistent_language_settings(self):\n    self.assertEqual(check_language_settings_consistent(None), [])\n", "def test_consistent_language_settings(self):\n    for tag in ['en', 'fr']:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [])\n", "def test_consistent_language_settings(self):\n    self.assertEqual(check_language_settings_consistent(None), [])\n"], "sample_12": ["def test_alter_field_to_fk_dependency_same_app(self):\n    changes = self.get_changes(\n        [self.author_empty, self.publisher_with_book],\n        [self.author_empty, self.publisher_with_author],\n    )\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, ['AlterField'])\n    self.assertMigrationDependencies(changes, 'testapp', 0, [])\n", "def test_alter_field_with_choices(self):\n    \"\"\"Tests autodetection of altered fields with choices.\"\"\"\n    changes = self.get_changes(\n        [ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True)), (\"name\", models.CharField(max_length=200, choices=[('A', 'A'), ('B', 'B')]))])],\n        [ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True)), (\"name\", models.CharField(max_length=200, choices=[('A', 'A'), ('C', 'C')]))])]\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True)\n", "def test_deep_deconstruct(self):\n    \"\"\"\n    Deep deconstruction descends into values of dictionaries and lists,\n    but not into the values' own attributes.\n    \"\"\"\n    # A model with a field that has a default value which is a list of objects.\n    author = ModelState(\n        \"testapp\",\n        \"Author\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=200, default=[DeconstructibleObject(), 123])),\n        ],\n    )\n    changes = self.get_changes([], [author])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\"])\n    # Check that the default value was correctly deconstructed.\n    field_default = changes['testapp'][0].operations[0].fields[1][1].default\n    self.assertEqual(field_default, [DeconstructibleObject(), 123])\n", "def test_alter_model_options_with_app_label_change(self):\n    \"\"\"Changing a model's app_label should create AlterModelOptions.\"\"\"\n    changes = self.get_changes([self.author_empty], [ModelState(\"otherapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n    ], options={\"verbose_name\": \"Authi\"})])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterModelTable\", \"AlterModelOptions\"])\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 0, name=\"author\", table=\"otherapp_author\")\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 1, name=\"author\", options={\"verbose_name\": \"Authi\"})\n", "def test_alter_model_table_on_model_rename(self):\n    \"\"\"\n    #28592 - AlterModelTable is correctly generated when a model is renamed and\n    its db_table is set to a value different from 'appname_modelname'.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_with_db_table_options],\n        [self.author_renamed_with_new_db_table_options],\n        MigrationQuestioner({\"ask_rename_model\": True}),\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"RenameModel\", \"AlterModelTable\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, old_name=\"Author\", new_name=\"NewAuthor\")\n    self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"newauthor\", table=\"author_three\")\n"], "sample_100": ["def test_encoder_get_feature_names_unfitted():\n    # Test get_feature_names before fitting\n    enc = OneHotEncoder()\n    msg = (\"This OneHotEncoder instance is not fitted yet. \"\n           \"Call 'fit' with appropriate arguments before using this method.\")\n    with pytest.raises(NotFittedError, match=msg):\n        enc.get_feature_names()\n", "def test_ordinal_encoder_not_fitted():\n    X = np.array([['a'], ['b']])\n    enc = OrdinalEncoder()\n    msg = (\"This OrdinalEncoder instance is not fitted yet. \"\n           \"Call 'fit' with appropriate arguments before using this method.\")\n    with pytest.raises(NotFittedError, match=msg):\n        enc.transform(X)\n", "def test_ordinal_encoder_dtype():\n    X = np.array([['a'], ['b']], dtype=object)\n    enc = OrdinalEncoder(dtype='int64')\n    X_tr = enc.fit_transform(X)\n    assert X_tr.dtype == 'int64'\n    assert_array_equal(enc.inverse_transform(X_tr), X)\n\n    X = np.array([[1], [2]], dtype='int64')\n    enc = OrdinalEncoder(dtype='float64')\n    X_tr = enc.fit_transform(X)\n    assert X_tr.dtype == 'float64'\n    assert_array_equal(enc.inverse_transform(X_tr), X.astype('object'))\n", "def test_ordinal_encoder_not_fitted():\n    X = np.array([['a'], ['b']])\n    enc = OrdinalEncoder()\n    msg = (\"This OrdinalEncoder instance is not fitted yet. \"\n           \"Call 'fit' with appropriate arguments before using this method.\")\n    with pytest.raises(NotFittedError, match=msg):\n        enc.transform(X)\n", "def test_ordinal_encoder_dtype():\n    # check that specified dtype is respected\n    X = np.array([['a'], ['b']])\n    enc = OrdinalEncoder(dtype=np.int32)\n    exp = np.array([[0], [1]], dtype=np.int32)\n    assert_array_equal(enc.fit_transform(X), exp)\n\n    # check for float dtypes\n    X = np.array([['a'], ['b']])\n    enc = OrdinalEncoder(dtype=np.float64)\n    exp = np.array([[0.], [1.]], dtype=np.float64)\n    assert_array_equal(enc.fit_transform(X), exp)\n\n    # check that specifying an integer dtype still gives correct results\n    # even if categories are string\n    X = np.array([['a'], ['b']])\n    enc = OrdinalEncoder(dtype=np.int32)\n    exp = np.array([[0], [1]], dtype=np.int32)\n    assert_array_equal(enc.fit_transform(X), exp)\n"], "sample_81": ["def test_fixme_with_disable_option(self) -> None:\n    code = \"\"\"a = 1\n            # FIXME message  # pylint: disable=fixme\n            \"\"\"\n    with self.assertNoMessages():\n        self.checker.process_tokens(_tokenize_str(code))\n", "def test_issue_regex_pattern(self) -> None:\n    code = \"# NOTE this should trigger a fixme\"\n    set_config(notes_rgx=\"NOTE\")\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"fixme\", line=1, args=\"NOTE this should trigger a fixme\", col_offset=1)\n    ):\n        self.checker.process_tokens(_tokenize_str(code))\n", "def test_fixme_pattern_with_notes_rgx(self) -> None:\n    code = \"\"\"a = 1\n            # NOTE\n            \"\"\"\n    set_config(self.checker, notes=[], notes_rgx=\"NOTE\")\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"fixme\", line=2, args=\"NOTE\", col_offset=17)\n    ):\n        self.checker.open()\n        self.checker.process_tokens(_tokenize_str(code))\n", "def test_disable_option(self) -> None:\n    code = \"\"\"# pylint: disable=fixme\n                # FIXME\n                \"\"\"\n    with self.assertNoMessages():\n        self.checker.process_tokens(_tokenize_str(code))\n", "def test_fixme_pattern_with_notes_rgx(self) -> None:\n    set_config(self.checker.config, notes_rgx=\"MYNOTE\")\n    code = \"\"\"a = 1\n            # MYNOTE message\n            \"\"\"\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"fixme\", line=2, args=\"MYNOTE message\", col_offset=17)\n    ):\n        self.checker.open()\n        self.checker.process_tokens(_tokenize_str(code))\n"], "sample_1": ["def test_get_lines_from_file(tmp_path):\n    example_qdp = \"\"\"\n        ! Initial comment line 1\n        ! Initial comment line 2\n        READ TERR 1\n        READ SERR 3\n        ! Table 0 comment\n        !a a(pos) a(neg) b c ce d\n        53000.5   0.25  -0.5   1  1.5  3.5 2\n        54000.5   1.25  -1.5   2  2.5  4.5 3\n        NO NO NO NO NO\n        ! Table 1 comment\n        !a a(pos) a(neg) b c ce d\n        54000.5   2.25  -2.5   NO  3.5  5.5 5\n        55000.5   3.25  -3.5   4  4.5  6.5 nan\n        \"\"\"\n\n    path = tmp_path / \"test.qdp\"\n    with open(path, \"w\") as fp:\n        print(example_qdp, file=fp)\n\n    lines1 = _get_lines_from_file(str(path))\n    lines2 = _get_lines_from_file(path)\n    lines3 = _get_lines_from_file(example_qdp.split(\"\\n\"))\n\n    assert lines1 == lines2\n    assert lines1 == lines3\n\n    with pytest.raises(ValueError):\n        _get_lines_from_file(123)\n", "def test_get_lines_from_file():\n    qdp_file = \"\"\"\n        ! Initial comment line 1\n        ! Initial comment line 2\n        READ TERR 1\n        READ SERR 3\n        ! Table 0 comment\n        !a a(pos) a(neg) b c ce d\n        53000.5   0.25  -0.5   1  1.5  3.5 2\n        54000.5   1.25  -1.5   2  2.5  4.5 3\n        NO NO NO NO NO\n        \"\"\"\n\n    lines = _get_lines_from_file(qdp_file)\n\n    assert lines[0] == \"! Initial comment line 1\"\n    assert lines[1] == \"! Initial comment line 2\"\n    assert lines[2] == \"READ TERR 1\"\n\n    with pytest.raises(ValueError):\n        _get_lines_from_file(123)\n", "def test_get_lines_from_file(tmp_path):\n    example_qdp = \"\"\"\n        ! Initial comment line 1\n        ! Initial comment line 2\n        READ TERR 1\n        READ SERR 3\n        ! Table 0 comment\n        !a a(pos) a(neg) b c ce d\n        53000.5   0.25  -0.5   1  1.5  3.5 2\n        54000.5   1.25  -1.5   2  2.5  4.5 3\n        NO NO NO NO NO\n        \"\"\"\n    path = tmp_path / \"test.qdp\"\n\n    with open(path, \"w\") as fp:\n        print(example_qdp, file=fp)\n\n    lines1 = _get_lines_from_file(fp.name)\n    with open(fp.name) as fobj:\n        lines2 = [line.strip() for line in fobj.readlines()]\n\n    assert lines1 == lines2\n\n    lines3 = _get_lines_from_file(example_qdp)\n    assert lines1 == lines3\n\n    with pytest.raises(ValueError):\n        _get_lines_from_file(12345)\n", "def test_get_lines_from_file():\n    # Test reading from a string\n    qdp_file = \"\"\"\n    ! Comment\n    READ TERR 1\n    53000.5   0.25  -0.5   1  1.5  3.5 2\n    NO NO NO NO NO\n    \"\"\"\n    lines = _get_lines_from_file(qdp_file)\n    assert lines[0] == \"! Comment\"\n\n    # Test reading from a file\n    with open(\"test.qdp\", \"w\") as fp:\n        print(qdp_file, file=fp)\n\n    lines = _get_lines_from_file(\"test.qdp\")\n    assert lines[0] == \"! Comment\"\n\n    # Test reading from an iterable\n    lines = _get_lines_from_file(qdp_file.splitlines())\n    assert lines[0] == \"! Comment\"\n\n    # Test invalid input\n    with pytest.raises(ValueError):\n        _get_lines_from_file(123)\n", "def test_get_lines_from_file(tmp_path):\n    example_qdp = \"\"\"\n    ! Swift/XRT hardness ratio of trigger: XXXX, name: BUBU X-2\n    ! Columns are as labelled\n    READ TERR 1\n    READ SERR 2\n    ! WT -- hard data\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   -0.212439       0.212439\n    \"\"\"\n\n    path = tmp_path / \"test.qdp\"\n\n    with open(path, \"w\") as fp:\n        print(example_qdp, file=fp)\n\n    lines = _get_lines_from_file(fp.name)\n    lines_str = _get_lines_from_file(example_qdp)\n    lines_list = _get_lines_from_file(lines)\n\n    for line1, line2, line3 in zip(lines, lines_str, lines_list):\n        assert line1 == line2 == line3\n\n    with pytest.raises(ValueError):\n        _get_lines_from_file(12345)\n"], "sample_102": ["def test_iforest_fit_time():\n    \"\"\"Test Isolation Forest fitting time with different numbers of threads\"\"\"\n    import timeit\n    X = np.random.rand(1000, 4)\n    clf = IsolationForest(n_estimators=100, random_state=42)\n\n    # measure fit time for single thread\n    start_time = timeit.default_timer()\n    clf.fit(X)\n    single_thread_time = timeit.default_timer() - start_time\n\n    # measure fit time for multiple threads\n    clf.n_jobs = -1\n    start_time = timeit.default_timer()\n    clf.fit(X)\n    multi_thread_time = timeit.default_timer() - start_time\n\n    assert multi_thread_time < single_thread_time\n", "def test_iforest_n_features_deprecation():\n    X = [[0.0, 1.0], [1.0, 2.0]]\n    clf = IsolationForest(n_features=2)\n\n    assert_warns_message(DeprecationWarning,\n                         \"The parameter 'n_features' is deprecated since \"\n                         \"version 0.24 and will be removed in 1.0.\",\n                         clf.fit, X)\n", "def test_iforest_fit_time_increases_with_n_estimators():\n    \"\"\"Test that fitting time increases with n_estimators\"\"\"\n    rng = check_random_state(0)\n    X_train = rng.randn(100, 2)\n\n    n_estimators_list = [1, 5, 10]\n    fit_times = []\n    for n_estimators in n_estimators_list:\n        clf = IsolationForest(n_estimators=n_estimators).fit(X_train)\n        fit_times.append(clf.fit_time_)\n\n    # Check if fit time is strictly increasing\n    assert all(fit_times[i] < fit_times[i+1] for i in range(len(fit_times)-1))\n", "def test_iforest_n_features_in():\n    X = iris.data\n    clf = IsolationForest().fit(X)\n    assert hasattr(clf, 'n_features_in_')\n    assert clf.n_features_in_ == X.shape[1]\n", "def test_iforest_fit_predict_sparse():\n    \"\"\"Test fit and predict methods with sparse data\"\"\"\n    rng = check_random_state(0)\n    X_train, X_test, y_train, y_test = train_test_split(boston.data[:50],\n                                                        boston.target[:50],\n                                                        random_state=rng)\n    clf = IsolationForest().fit(csr_matrix(X_train))\n    assert_array_equal(clf.predict(csr_matrix(X_test)),\n                       clf.predict(X_test))\n"], "sample_139": ["def test_polar_lift():\n    from sympy import exp_polar, polar_lift, I, pi\n    x = Symbol('x')\n\n    assert polar_lift(0) == 0\n    assert polar_lift(1) == exp_polar(0)\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(I*pi/2)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n\n    assert polar_lift(x) == exp_polar(I*arg(x))*Abs(x)\n    assert polar_lift(exp_polar(I*pi/4)) == exp_polar(I*pi/4)\n    assert polar_lift(polar_lift(x)) == polar_lift(x)\n\n    assert polar_lift(2 + 3*I) == polar_lift(2 + 3*I)\n    assert polar_lift((2 + 3*I)*exp_polar(I*pi)) == polar_lift(-(2 + 3*I))\n\n    assert polar_lift(1 + I).as_real_imag() == (polar_lift(1 + I), 0)\n    assert polar_lift(1 + I).is_comparable is False\n\n    p = Symbol('p', positive=True)\n    assert polar_lift(p) == p*exp_polar(0)\n    assert polar_lift(p*x) == p*polar_lift(x)\n", "def test_issue_20923():\n    x = Symbol('x')\n    assert unpolarify(sign(x)) == sign(unpolarify(x))\n    assert unpolarify(sign(conjugate(x))) == sign(unpolarify(conjugate(x)))\n    assert unpolarify(sign(exp_polar(I*pi/2)*x)) == sign(unpolarify(exp_polar(I*pi/2)*x))\n", "def test_polar_lift():\n    from sympy import polar_lift, exp_polar\n    x = Symbol('x')\n    p = Symbol('p', positive=True)\n    i = Symbol('i', imaginary=True)\n\n    assert polar_lift(0) == 0\n    assert polar_lift(1) == exp_polar(0)\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(p) == p*exp_polar(0)\n    assert polar_lift(x) == x*exp_polar(0)\n    assert polar_lift(i) == i*exp_polar(-I*pi/2)\n    assert polar_lift(2 + I) == (2 + I)*exp_polar(arg(2 + I))\n    assert polar_lift((2 + I)*x) == (2 + I)*polar_lift(x)\n    assert polar_lift((2 + I)*p) == (2 + I)*p\n    assert polar_lift((2 + I)*i) == (2 + I)*i*exp_polar(-I*pi/2)\n\n    # Test argument sanitization\n    assert polar_lift(nan).func is polar_lift\n    assert polar_lift(oo).func is polar_lift\n    assert polar_lift(zoo).func is polar_lift\n\n    # Test _eval_evalf\n    assert polar_lift(1)._eval_evalf() == 1\n    assert polar_lift(i)._eval_evalf() == I\n    assert polar_lift(i)._eval_evalf(2) == I\n    assert polar_lift(2 + I)._eval_evalf(2) == 2 + I\n", "def test_polar_lift():\n    from sympy import polar_lift, exp_polar, pi, I\n    x = Symbol('x')\n    assert polar_lift(2) == 2*exp_polar(0)\n    assert polar_lift(x) == x*exp_polar(0)\n    assert polar_lift(-2) == 2*exp_polar(I*pi)\n    assert polar_lift(-x) == x*exp_polar(I*pi)\n    assert polar_lift(exp_polar(I*pi/2)) == exp_polar(I*pi/2)\n    assert polar_lift(3*exp_polar(I*pi/2)) == 3*exp_polar(I*pi/2)\n    assert polar_lift(I) == exp_polar(I*pi/2)\n    assert polar_lift(1 + I) == polar_lift(1 + I)\n", "def test_issue_20382():\n    from sympy import MatrixSymbol, re, im\n    A = MatrixSymbol(\"A\", 2, 2)\n    assert re(A).is_real is True\n    assert im(A).is_real is True\n"], "sample_131": ["def test_Sum():\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]]\"\n    assert mcode(Sum(x**2, (x, 1, oo))) == \"Hold[Sum[x^2, {x, 1, Infinity}]]\"\n    assert mcode(Sum(x**2*y**3, (x, 1, 10), (y, 1, 5))) == \\\n        \"Hold[Sum[x^2*y^3, {x, 1, 10}, {y, 1, 5}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]]\"\n    assert mcode(Sum(x**2 + y**2, (x, 1, 10), (y, 1, 10))) == \\\n        \"Hold[Sum[x^2 + y^2, {x, 1, 10}, {y, 1, 10}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]]\"\n    assert mcode(Sum(x*y, (x, 1, 10), (y, 1, 10))) == \"Hold[Sum[x*y, {x, 1, 10}, {y, 1, 10}]]\"\n    assert mcode(Sum(sin(x), (x, 0, pi/4))) == \"Hold[Sum[Sin[x], {x, 0, Pi/4}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]]\"\n    assert mcode(Sum(x**2 + y**2, (x, 1, 10), (y, 1, 5))) == \\\n        \"Hold[Sum[x^2 + y^2, {x, 1, 10}, {y, 1, 5}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]]\"\n    assert mcode(Sum(x**2 + y**2, (x, 1, 10), (y, 1, 10))) == \\\n        \"Hold[Sum[x^2 + y^2, {x, 1, 10}, {y, 1, 10}]]\"\n"], "sample_29": ["    def test_votes(self):\n        promoter = JoinPromoter('AND', 3, False)\n        self.assertEqual(promoter.votes, Counter())\n        promoter.add_votes(['a', 'b'])\n        self.assertEqual(promoter.votes, Counter({'a': 1, 'b': 1}))\n", "    def setUpTestData(cls):\n        cls.n = Number.objects.create(integer=1)\n", "    def test_params_as_list(self):\n        RawSQL('SELECT * FROM table WHERE col = %s', ['value'])\n", "    def test_join_promotion(self):\n        query = Query(Model)\n        join_promoter = JoinPromoter(AND, 2, False)\n        join_promoter.add_votes(['table1', 'table2'])\n        self.assertEqual(join_promoter.update_join_types(query), {'table1', 'table2'})\n", "    def test_clone_with_args_mutation(self):\n        # Ensure cloning doesn't modify the original expression.\n        expr = Func('published', function='TO_CHAR')\n        clone = expr.clone()\n        clone.arg = 'updated'\n        self.assertEqual(expr.arg, 'published')\n"], "sample_32": ["def test_key_transform_with_expression_wrapper(self):\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.annotate(\n            expr=ExpressionWrapper(\n                KeyTransform('c', 'value'),\n                output_field=IntegerField(),\n            ),\n        ).filter(expr__isnull=False),\n        self.objs[3:5],\n    )\n", "    def setUpTestData(cls):\n        cls.objs = [\n            NullableJSONModel.objects.create(value={'a': 'b'}),\n            NullableJSONModel.objects.create(value={'c': 'd', 'e': {'f': 'g'}}),\n        ]\n", "    def test_nested_expression(self):\n        obj = JSONModel.objects.create(value={'a': {'b': {'c': 'd'}}})\n        qs = JSONModel.objects.filter(\n            value__a=KeyTransform('b', RawSQL(\"JSON_BUILD_OBJECT('c', 'd')\", ())),\n        )\n        self.assertSequenceEqual(qs, [obj])\n", "    def test_foreign_key(self):\n        related_obj = RelatedJSONModel.objects.create(data={'key': 'value'})\n        obj = JSONModel.objects.create(value={'key': 'value'}, related=related_obj)\n        self.assertEqual(obj.related.data, {'key': 'value'})\n", "    def setUpTestData(cls):\n        cls.related_obj = RelatedJSONModel.objects.create(value={'foo': 'bar'})\n"], "sample_62": ["    def test_cull(self):\n        cache = caches[\"default\"]\n        for i in range(1100):\n            cache.set(f\"key{i}\", f\"value{i}\")\n        # Ensure the cache has been culled to MAX_ENTRIES\n        self.assertLessEqual(len(cache._list_cache_files()), 1000)\n", "    def test_file_based_cache_with_multiple_threads(self):\n        # Create a file based cache with multiple threads\n        cache = caches[\"default\"]\n\n            cache.set(key, value)\n\n            return cache.get(key)\n\n        key = \"test_key\"\n        value = \"test_value\"\n\n        # Set the cache in one thread\n        t1 = threading.Thread(target=set_cache, args=(key, value))\n        t1.start()\n        t1.join()\n\n        # Get the cache in another thread\n        t2 = threading.Thread(target=get_cache, args=(key,))\n        t2.start()\n        t2.join()\n\n        # Check if the cache is set correctly\n        self.assertEqual(cache.get(key), value)\n\n        # Clean up\n        cache.delete(key)\n", "    def test_cache_create_directory_if_non_existent(self):\n        cache = caches[\"default\"]\n        self.assertFalse(os.path.exists(cache._dir))\n        cache.set(\"key\", \"value\")\n        self.assertTrue(os.path.exists(cache._dir))\n        shutil.rmtree(cache._dir)\n", "    def setUp(self):\n        self.cache_dir = tempfile.mkdtemp()\n        with override_settings(\n            CACHES={\n                \"default\": {\n                    \"BACKEND\": \"django.core.cache.backends.filebased.FileBasedCache\",\n                    \"LOCATION\": self.cache_dir,\n                },\n            }\n        ):\n            self.cache = caches[\"default\"]\n", "    def test_set_with_pickling_error(self):\n        class UnpicklableObject:\n                raise pickle.PickleError\n\n        with self.assertRaises(pickle.PickleError):\n            cache.set(\"key\", UnpicklableObject())\n"], "sample_33": ["def test_receiver_disconnect(self):\n    @receiver(a_signal)\n        self.state = val\n\n    self.state = False\n    a_signal.send(sender=self, val=True)\n    self.assertTrue(self.state)\n\n    a_signal.disconnect(f)\n    self.state = False\n    a_signal.send(sender=self, val=True)\n    self.assertFalse(self.state)\n", "def test_receiver_decorator_weakref(self):\n    @receiver(a_signal)\n        self.state = val\n\n    weak_f = weakref.ref(f)\n    del f\n    garbage_collect()\n\n    # Since the receiver decorator uses a weak reference to the function,\n    # after deleting the original function and running the garbage collector,\n    # the signal should not have any receivers.\n    result = a_signal.send(sender=self, val=True)\n    self.assertEqual(result, [])\n    self.assertTestIsClean(a_signal)\n\n    # Also check that the weak reference is no longer valid.\n    self.assertIsNone(weak_f())\n", "def test_receiver_disconnect(self):\n    @receiver(a_signal)\n        self.state = val\n\n    self.state = False\n    a_signal.send(sender=self, val=True)\n    self.assertTrue(self.state)\n\n    a_signal.disconnect(f)\n    self.state = False\n    a_signal.send(sender=self, val=True)\n    self.assertFalse(self.state)\n", "def test_receiver_single_signal_with_sender(self):\n    @receiver(a_signal, sender=self.__class__)\n        self.state = val\n    self.state = False\n    a_signal.send(sender=self, val=True)\n    self.assertTrue(self.state)\n    a_signal.send(sender=object(), val=False)\n    self.assertTrue(self.state)\n", "def test_receiver_weakref(self):\n    class Receiver:\n            self.state = val\n\n    receiver = Receiver()\n    weak_receiver = weakref.ref(receiver)\n\n    a_signal.connect(weak_receiver)\n    del receiver\n    garbage_collect()\n\n    result = a_signal.send(sender=self, val=\"test\")\n    self.assertEqual(result, [])\n    self.assertTestIsClean(a_signal)\n"], "sample_93": ["def test_temp_path_factory_basetemp_is_absolute(tmp_path_factory, monkeypatch):\n    \"\"\"Test that TempPathFactory.getbasetemp() returns an absolute path.\"\"\"\n    monkeypatch.chdir(tmp_path_factory.getbasetemp().parent)\n    assert tmp_path_factory.getbasetemp().is_absolute()\n", "def test_lock_cleanup_on_lockfile_removal(tmp_path: Path) -> None:\n    lock = create_cleanup_lock(tmp_path)\n\n    registry: List[Callable[..., None]] = []\n    register_cleanup_lock_removal(lock, register=registry.append)\n\n    (cleanup_func,) = registry\n\n    # simulate the lock file being removed by another process\n    lock.unlink()\n\n    # ensure we don't crash when the cleanup function is called\n    cleanup_func()\n", "def test_get_user_with_monkeypatched_getpass(pytester: Pytester, monkeypatch) -> None:\n    \"\"\"Test that get_user() function works with a monkeypatched getpass module.\"\"\"\n        return \"mocked_user\"\n\n    monkeypatch.setattr(\"getpass.getuser\", mock_getuser)\n    assert get_user() == \"mocked_user\"\n", "def test_tmp_path_factory_getbasetemp_with_given_basetemp(tmp_path):\n    config = cast(Config, FakeConfig(tmp_path))\n    t = TempPathFactory.from_config(config, _ispytest=True)\n    assert t.getbasetemp() == tmp_path.resolve()\n", "def test_temp_path_factory_getbasetemp_custom_basetemp(tmp_path):\n    config = cast(Config, FakeConfig(tmp_path))\n    t = TempPathFactory.from_config(config, _ispytest=True)\n    assert t.getbasetemp() == tmp_path\n"], "sample_42": ["def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return 'complex(%r)' % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n    self.assertIn(complex, Serializer._registry)\n\n    Serializer.unregister(complex)\n    self.assertNotIn(complex, Serializer._registry)\n", "def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return 'complex(%r)' % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n    try:\n        self.assertEqual(MigrationWriter.serialize(complex(1))[0], \"complex(1)\")\n        Serializer.unregister(complex)\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize: (1+1j)\\n'):\n            MigrationWriter.serialize(complex(1))\n    finally:\n        Serializer.unregister(complex)\n", "def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return 'complex(%r)' % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n    try:\n        Serializer.unregister(complex)\n    except KeyError:\n        self.fail('unregister() raised KeyError unexpectedly')\n    with self.assertRaises(KeyError):\n        Serializer.unregister(complex)\n", "def test_unregister_serializer(self):\n    class CustomSerializer(BaseSerializer):\n        pass\n\n    Serializer.register(complex, CustomSerializer)\n    Serializer.unregister(complex)\n\n    with self.assertRaisesMessage(ValueError, \"Cannot serialize: (1+1j)\\n\"):\n        MigrationWriter.serialize(1 + 1j)\n", "def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return 'complex(%r)' % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n    Serializer.unregister(complex)\n\n    with self.assertRaisesMessage(ValueError, \"Cannot serialize: (1+1j)\\nThere are some values Django cannot serialize into migration files.\"):\n        MigrationWriter.serialize(1 + 1j)\n"], "sample_142": ["def test_roundrobin():\n    assert list(roundrobin('ABC', 'D', 'EF')) == [\n        'A', 'D', 'E', 'B', 'F', 'C']\n    assert list(roundrobin([1, 2, 3], [4, 5], [6])) == [\n        1, 4, 6, 2, 5, 3]\n    assert list(roundrobin([1, 2, 3], [], [6])) == [1, 6, 2, 3]\n", "def test_roundrobin():\n    assert list(roundrobin('ABC', 'D', 'EF')) == ['A', 'D', 'E', 'B', 'F', 'C']\n    assert list(roundrobin([1, 2], [3, 4, 5])) == [1, 3, 2, 4]\n    assert list(roundrobin([1, 2, 3], [4, 5], [6, 7, 8, 9])) == [\n        1, 4, 6, 2, 5, 7, 3, 8, 9]\n", "def test_roundrobin():\n    gen = roundrobin('ABC', 'D', 'EF')\n    assert list(gen) == ['A', 'D', 'E', 'B', 'F', 'C']\n", "def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [\n        (0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((1, 1, 1))) == [\n        (1, 1, 1), (-1, 1, 1), (1, -1, 1), (1, 1, -1),\n        (-1, -1, 1), (-1, 1, -1), (1, -1, -1), (-1, -1, -1)]\n    assert list(permute_signs((0, 0, 0))) == [(0, 0, 0)]\n", "def test_roundrobin():\n    assert list(roundrobin('ABC', 'D', 'EF')) == [\n        'A', 'D', 'E', 'B', 'F', 'C'\n    ]\n    assert list(roundrobin('AB', 'CD', 'EF')) == [\n        'A', 'C', 'E', 'B', 'D', 'F'\n    ]\n    assert list(roundrobin([1, 2], [3, 4], [5, 6])) == [\n        1, 3, 5, 2, 4, 6\n    ]\n"], "sample_120": ["def test_MatrixExpr_canonicalize():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    assert (A*B).canonicalize() == A*B\n    assert (2*A*B).canonicalize() == 2*A*B\n    assert ((A*B).T).canonicalize() == B.T*A.T\n    assert ((2*A*B).T).canonicalize() == 2*B.T*A.T\n    assert (A + A).canonicalize() == 2*A\n", "def test_MatrixElement_subs():\n    i, j = symbols('i j')\n    A = MatrixSymbol('A', n, m)\n    assert A[i, j].subs(A, ZeroMatrix(n, m)) == 0\n    assert A[i, j].subs(i, 1).subs(j, 2) == A[1, 2]\n", "def test_MatrixElement_as_real_imag():\n    A = MatrixSymbol('A', 2, 2)\n    assert A[0, 0].as_real_imag() == ((A[0, 0] + A[0, 0].conjugate())/2, (A[0, 0] - A[0, 0].conjugate())/(2*S.I))\n", "def test_matrixelement_subs():\n    i, j = symbols('i j')\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', n, m)\n    assert A[i, j].subs(A, B) == B[i, j]\n    assert A[i, j].subs(i, 0) == A[0, j]\n    assert A[i, j].subs({i: 0, j: 1}) == A[0, 1]\n    assert A[i, j].subs({A: B, i: 0, j: 1}) == B[0, 1]\n", "def test_MatrixElement_as_real_imag():\n    A = MatrixSymbol('A', 2, 2)\n    x = symbols('x')\n    expr = A[0, 0] * x\n    real, imag = expr.as_real_imag()\n    assert real == expr\n    assert imag == 0\n\n    expr = A[0, 0] * I * x\n    real, imag = expr.as_real_imag()\n    assert real == 0\n    assert imag == A[0, 0] * x\n"], "sample_14": ["def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return 'complex(%r)' % self.value, {}\n    Serializer.register(complex, ComplexSerializer)\n    Serializer.unregister(complex)\n    with self.assertRaisesMessage(ValueError, \"Cannot serialize: (1+1j)\\nThere are some values Django cannot serialize into migration files.\"):\n        MigrationWriter.serialize(1 + 1j)\n", "def test_serialize_lazy_objects_with_unpickleable_lambda(self):\n        return 'test'\n\n    lazy_object = SimpleLazyObject(unpickleable_lambda)\n    with self.assertRaisesMessage(ValueError, 'Cannot serialize'):\n        MigrationWriter.serialize(lazy_object)\n", "def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return 'complex(%r)' % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n    self.assertEqual(Serializer._registry[complex], ComplexSerializer)\n    Serializer.unregister(complex)\n    self.assertNotIn(complex, Serializer._registry)\n", "def test_register_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return 'complex(%r)' % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n\n    value = complex(1, 2)\n    string, imports = MigrationWriter.serialize(value)\n    self.assertEqual(string, \"complex((1+2j))\")\n\n    Serializer.unregister(complex)\n\n    with self.assertRaisesMessage(ValueError, 'Cannot serialize'):\n        MigrationWriter.serialize(value)\n", "def test_unregister_serializer(self):\n    class TestSerializer(BaseSerializer):\n            return 'test', {}\n\n    Serializer.register(str, TestSerializer)\n    self.assertEqual(Serializer._registry[str], TestSerializer)\n\n    Serializer.unregister(str)\n    self.assertNotIn(str, Serializer._registry)\n"], "sample_157": ["def test_tensor_product_trace():\n    assert Tr(TP(A, B)) == Tr(A)*Tr(B)\n    assert Tr(TP(A, B), indices=[0]) == A*Tr(B)\n    assert Tr(TP(A, B), indices=[1]) == Tr(A)*B\n    assert Tr(TP(A, B)*TP(C, D)) == Tr(A*C)*Tr(B*D)\n    assert Tr(TP(A, B)*TP(C, D), indices=[0]) == A*C*Tr(B*D)\n    assert Tr(TP(A, B)*TP(C, D), indices=[1]) == Tr(A*C)*B*D\n", "def test_tensor_product_trace():\n    assert Tr(TP(A, B)) == Tr(A)*Tr(B)\n    assert Tr(TP(A, B), indices=[0]) == A*Tr(B)\n    assert Tr(TP(A, B), indices=[1]) == Tr(A)*B\n", "def test_tensor_product_simp_dagger():\n    assert tensor_product_simp(Dagger(TP(A, B))*TP(B, C)) == TP(Dagger(A)*B, Dagger(B)*C)\n", "def test_tensor_product_trace():\n    # Test trace of a tensor product\n    assert Tr(TP(A, B)) == Tr(A)*Tr(B)\n    assert Tr(TP(mat1, mat2)) == Tr(mat1)*Tr(mat2)\n\n    # Test partial trace of a tensor product\n    assert Tr(TP(A, B), indices=[0]) == Tr(A)*B\n    assert Tr(TP(A, B), indices=[1]) == A*Tr(B)\n", "def test_tensor_product_trace():\n    assert Tr(TP(A, B)) == Tr(A)*Tr(B)\n    assert Tr(TP(mat1, mat2)) == Tr(mat1)*Tr(mat2)\n    assert Tr(TP(A, B), indices=[0]) == Tr(A)*B\n    assert Tr(TP(A, B), indices=[1]) == A*Tr(B)\n"], "sample_110": ["def test_affinity_propagation_sparse_input():\n    # Test AffinityPropagation with sparse input\n    from sklearn.utils import sparsefuncs\n\n    af = AffinityPropagation(affinity=\"euclidean\")\n    X_sparse = sparsefuncs.csr_matrix(X)\n    labels_sparse = af.fit_predict(X_sparse)\n\n    af_dense = AffinityPropagation(affinity=\"euclidean\")\n    labels_dense = af_dense.fit_predict(X)\n\n    assert_array_equal(labels_sparse, labels_dense)\n", "def test_affinity_propagation_sparse_input():\n    # Test AffinityPropagation with sparse input\n    X_sparse = csr_matrix(X)\n    af = AffinityPropagation()\n    labels_sparse = af.fit_predict(X_sparse)\n    af_dense = AffinityPropagation()\n    labels_dense = af_dense.fit_predict(X)\n    assert_array_equal(labels_sparse, labels_dense)\n", "def test_affinity_propagation_sparse_input():\n    # Test that AffinityPropagation works with sparse input\n    from scipy.sparse import csr_matrix\n\n    X_sparse = csr_matrix(X)\n\n    af = AffinityPropagation()\n    labels_sparse = af.fit_predict(X_sparse)\n\n    af = AffinityPropagation()\n    labels_dense = af.fit_predict(X)\n\n    assert_array_equal(labels_sparse, labels_dense)\n", "def test_affinity_propagation_sparse_input():\n    # Test that AffinityPropagation can handle sparse input\n    X_sparse = csr_matrix(X)\n    af_sparse = AffinityPropagation()\n    af_dense = AffinityPropagation()\n\n    labels_sparse = af_sparse.fit_predict(X_sparse)\n    labels_dense = af_dense.fit_predict(X)\n\n    assert_array_equal(labels_sparse, labels_dense)\n", "def test_affinity_propagation_sparse_input():\n    # Test AffinityPropagation with sparse input\n    X_sparse = csr_matrix(X)\n    af = AffinityPropagation(affinity=\"euclidean\")\n    labels_sparse = af.fit_predict(X_sparse)\n\n    af_dense = AffinityPropagation(affinity=\"euclidean\")\n    labels_dense = af_dense.fit_predict(X)\n\n    assert_array_equal(labels_sparse, labels_dense)\n"], "sample_136": ["def test_BlockMatrix_equals():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', n, m)\n    X = BlockMatrix([[A]])\n    Y = BlockMatrix([[B]])\n\n    assert X.equals(Y) == False\n    assert X.equals(X) == True\n\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', m, m)\n    Z = BlockDiagMatrix(C, D)\n    W = BlockDiagMatrix(C, D)\n\n    assert Z.equals(W) == True\n    assert Z.equals(X) == False\n", "def test_blockcut_non_symbolic_matrix():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (2, 2))\n    assert isinstance(B, BlockMatrix)\n    assert len(B.blocks) == 2\n    assert len(B.blocks[0]) == 2\n    assert B.blocks[0, 0].shape == (1, 2)\n    assert B.blocks[0, 1].shape == (1, 2)\n    assert B.blocks[1, 0].shape == (3, 2)\n    assert B.blocks[1, 1].shape == (3, 2)\n", "def test_blockcollapse_type():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, k)\n    C = MatrixSymbol('C', l, m)\n    D = MatrixSymbol('D', l, k)\n    X = BlockMatrix([[A, B], [C, D]])\n\n    assert isinstance(block_collapse(X), BlockMatrix)\n    assert isinstance(block_collapse(Transpose(X)), BlockMatrix)\n    assert isinstance(block_collapse(Inverse(X)), Inverse)\n", "def test_blockcut_uneven_blocks():\n    A = MatrixSymbol('A', n, m)\n    B = blockcut(A, (n/3, n/3, n/3), (m/2, m/2))\n    assert A[i, j] == B[i, j]\n    assert B == BlockMatrix([[A[:n/3, :m/2], A[:n/3, m/2:]],\n                             [A[n/3:2*n/3, :m/2], A[n/3:2*n/3, m/2:]],\n                             [A[2*n/3:, :m/2], A[2*n/3:, m/2:]]])\n\n    M = ImmutableMatrix(6, 4, range(24))\n    B = blockcut(M, (2, 2, 2), (2, 2))\n    assert M == ImmutableMatrix(B)\n", "def test_deblock_nested():\n    B = BlockMatrix([[MatrixSymbol('A_%d%d'%(i,j), n, n)\n                    for j in range(4)]\n                    for i in range(4)])\n    BB = BlockMatrix([[B, B], [B, B]])\n    assert deblock(BB).blocks.shape == (8, 8)\n"], "sample_80": ["def test_wrap_indent(self):\n    text = \"foo\\nbar\\nbaz\"\n    expected = \"    foo\\n    bar\\n    baz\"\n    actual = formatting.wrap_indent(text, start=\"    \")\n    assert actual == expected\n\n    text = \"foo\\nbar\\nbaz\"\n    expected = \"foo\\n  bar\\n  baz\"\n    actual = formatting.wrap_indent(text, start=\"\", length=2)\n    assert actual == expected\n", "def test_short_data_repr(self):\n    data = np.arange(1000)\n    actual = formatting.short_data_repr(data)\n    expected = \"[0 1 2 ... 997 998 999]\"\n    assert actual == expected\n\n    data = xr.DataArray(np.arange(1000), dims=\"x\")\n    actual = formatting.short_data_repr(data)\n    expected = \"[0 1 2 ... 997 998 999]\"\n    assert actual == expected\n\n    data = dask.array.from_array(np.arange(1000), chunks=100)\n    actual = formatting.short_data_repr(data)\n    expected = \"dask.array<x_100: 1000, dtype='int64'>\"\n    assert actual == expected\n", "def test_short_data_repr(self):\n    array = xr.DataArray(np.arange(100).reshape(10, 10), dims=(\"x\", \"y\"))\n    expected = \"array([[ 0,  1,  2, ...,  7,  8,  9],\\n       [10, 11, 12, ..., 17, 18, 19],\\n       [20, 21, 22, ..., 27, 28, 29],\\n       ...,\\n       [70, 71, 72, ..., 77, 78, 79],\\n       [80, 81, 82, ..., 87, 88, 89],\\n       [90, 91, 92, ..., 97, 98, 99]])\"\n    actual = formatting.short_data_repr(array)\n    assert expected in actual\n\n    array = xr.DataArray(np.arange(10000), dims=\"x\")\n    expected = \"[10000 values with dtype='int64']\"\n    actual = formatting.short_data_repr(array)\n    assert expected == actual\n", "def test_unindexed_dims_repr(self):\n    dims = (\"x\", \"y\")\n    coords = {\"x\": [1, 2, 3]}\n    expected = \"Dimensions without coordinates: y\"\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert expected == actual\n\n    dims = (\"x\", \"y\")\n    coords = {\"x\": [1, 2, 3], \"y\": [4, 5, 6]}\n    expected = None\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert expected == actual\n\n    dims = ()\n    coords = {}\n    expected = None\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert expected == actual\n", "def test_limit_lines():\n    long_string = \"\\n\".join(str(i) for i in range(100))\n    limited_string = formatting.limit_lines(long_string, limit=10)\n    assert len(limited_string.splitlines()) == 10\n    assert \"...\" in limited_string\n\n    short_string = \"hello world\"\n    limited_string = formatting.limit_lines(short_string, limit=10)\n    assert limited_string == short_string\n"], "sample_99": ["def test_neighbors_n_jobs():\n    # Test that the n_jobs parameter is correctly passed to the underlying\n    # Parallel function.\n    X, y = datasets.make_classification(n_samples=30, n_features=5,\n                                        n_redundant=0, random_state=0)\n    X_train, X_test, y_train, y_test = train_test_split(X, y)\n\n        clf = neighbors.KNeighborsClassifier(n_neighbors=3,\n                                             algorithm=algorithm,\n                                             n_jobs=n_jobs)\n        clf.fit(X_train, y_train)\n        assert hasattr(clf, '_tree') == (n_jobs == 1 or algorithm == 'brute')\n        if algorithm != 'brute':\n            # Check that the correct number of threads is used\n            from sklearn.neighbors._ball_tree import BallTree\n            if isinstance(clf._tree, BallTree):\n                tree = clf._tree\n            else:\n                # KDTree does not have a public attribute for this\n                tree = clf._tree.tree_\n            if n_jobs == -1:\n                n_jobs = min(tree.n_samples, multiprocessing.cpu_count())\n            assert tree.threads == n_jobs\n\n    for algorithm in ALGORITHMS:\n        yield check_n_jobs, algorithm, 1\n        yield check_n_jobs, algorithm, -1\n        if algorithm != 'brute':\n            yield check_n_jobs, algorithm, 2\n", "def test_sparse_metric_callable_with_dense_input():\n        assert_true(issparse(x) and issparse(y))\n        return x.dot(y.T).A.item()\n\n    X = csr_matrix(np.array([[1, 0], [0, 1]]))\n    y = csr_matrix(np.array([[1, 0], [0, 1]]))\n\n    nn = neighbors.NearestNeighbors(metric=sparse_metric)\n    nn.fit(X)\n\n    # This should not raise an error\n    nn.kneighbors(y)\n", "def test_kneighbors_n_neighbors_dynamic():\n    # Test kneighbors with n_neighbors changing dynamically\n    X = np.array([[0, 1], [1.01, 1.], [2, 0]])\n\n    for algorithm in ALGORITHMS:\n        nbrs = neighbors.NearestNeighbors(algorithm=algorithm)\n        nbrs.fit(X)\n\n        # Test with n_neighbors > number of samples\n        dist, ind = nbrs.kneighbors(n_neighbors=5)\n        assert_array_equal(dist.shape, (3, 5))\n        assert_array_equal(ind.shape, (3, 5))\n\n        # Test with n_neighbors < number of samples\n        dist, ind = nbrs.kneighbors(n_neighbors=2)\n        assert_array_equal(dist.shape, (3, 2))\n        assert_array_equal(ind.shape, (3, 2))\n\n        # Test with n_neighbors == number of samples\n        dist, ind = nbrs.kneighbors(n_neighbors=3)\n        assert_array_equal(dist.shape, (3, 3))\n        assert_array_equal(ind.shape, (3, 3))\n", "def test_kneighbors_graph_with_self_loop():\n    # Test kneighbors_graph to build the k-Nearest Neighbor graph with self loop.\n    X = np.array([[0, 1], [1.01, 1.], [2, 0]])\n\n    A = neighbors.kneighbors_graph(X, 2, mode='connectivity',\n                                   include_self=True)\n    assert_array_equal(A.toarray(), np.array([[1., 1., 0.],\n                                              [1., 1., 0.],\n                                              [0., 1., 1.]]))\n\n    A = neighbors.kneighbors_graph(X, 2, mode='distance', include_self=True)\n    assert_array_almost_equal(A.toarray(), np.array([[0., 1.01, 0.],\n                                                     [1.01, 0., 1.40716026],\n                                                     [0., 1.40716026, 0.]]))\n", "def test_neighbors_transformer():\n    # Test that neighbors transformer methods work as expected\n\n    X = iris.data\n    y = iris.target\n\n    for algorithm in ALGORITHMS:\n        for Est in (neighbors.KNeighborsTransformer,\n                    neighbors.RadiusNeighborsTransformer):\n            if Est is neighbors.KNeighborsTransformer:\n                est = Est(n_neighbors=5, algorithm=algorithm)\n            else:\n                est = Est(radius=1.0, algorithm=algorithm)\n\n            Xt = est.fit_transform(X)\n            assert_equal(Xt.shape[0], X.shape[0])\n\n            Xc = est.transform(X[:10])\n            assert_equal(Xc.shape[0], 10)\n"], "sample_6": ["    def test_ascii_validator(self):\n        valid_usernames = ['joe', 'joe@example.com', 'joe+example@example.com']\n        invalid_usernames = [\n            \"Ren\u00e9\", \"\u0623\u062d\u0645\u062f\", \"o'connell\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A',\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n", "    def test_validator(self):\n        valid_usernames = ['joe', 'username123', 'username@domain.com']\n        invalid_usernames = [\n            \"Ren\u00e9\", \"\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30\", \"\u0623\u062d\u0645\u062f\",\n            \"o'connell\", \"\u0639\u0628\u062f \u0627\u0644\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A',\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n", "    def test_ascii_validator(self):\n        valid_usernames = ['joe', 'jane_doe', 'joe@example.com']\n        invalid_usernames = [\n            \"Ren\u00e9\", \"\u0623\u062d\u0645\u062f\", \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A',\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n", "    def test_validator(self):\n        valid_usernames = ['joe', 'joe@example.com']\n        invalid_usernames = [\n            \"o'connell\", \"\u0639\u0628\u062f \u0627\u0644\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A',\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n", "    def test_validator(self):\n        valid_usernames = ['joe', 'joe2', 'joe_user']\n        invalid_usernames = ['Ren\u00e9', '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f']\n\n        v = ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n"], "sample_25": ["def test_generate_altered_unique_together_with_multiple_constraints(self):\n    \"\"\"\n    Tests index/unique_together detection when there are multiple constraints.\n    \"\"\"\n    model_state = ModelState(\"otherapp\", \"Book\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n        (\"title\", models.CharField(max_length=200)),\n        (\"newfield\", models.IntegerField()),\n    ], {\n        \"index_together\": {(\"author\", \"title\"), (\"newfield\",)},\n        \"unique_together\": {(\"title\", \"newfield\")},\n    })\n    changes = self.get_changes([self.author_empty, self.book], [self.author_empty, model_state])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AddField\", \"AlterIndexTogether\", \"AlterUniqueTogether\"])\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 1, name=\"book\", index_together={(\"author\", \"title\"), (\"newfield\",)})\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 2, name=\"book\", unique_together={(\"title\", \"newfield\")})\n", "def test_add_field_with_choices(self):\n    \"\"\"Tests autodetection of new fields with choices.\"\"\"\n    changes = self.get_changes([self.author_empty], [\n        ModelState(\"testapp\", \"Author\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=200, choices=[(\"A\", \"A\"), (\"B\", \"B\")])),\n        ])\n    ])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n    self.assertEqual(changes['testapp'][0].operations[0].field.choices, [(\"A\", \"A\"), (\"B\", \"B\")])\n", "def test_alter_model_options_with_custom_manager(self):\n    \"\"\"Changing a model's options with custom manager should make a change.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_with_options_and_manager])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, options={\n        \"permissions\": [('can_hire', 'Can hire')],\n        \"verbose_name\": \"Authi\",\n        \"managers\": [('objects', models.Manager())],\n    })\n", "def test_generate_added_constraints_with_condition(self):\n    before = [\n        ModelState('app', 'Foo', [\n            ('id', models.AutoField(primary_key=True)),\n            ('field', models.IntegerField()),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'Foo', [\n            ('id', models.AutoField(primary_key=True)),\n            ('field', models.IntegerField()),\n        ], options={\n            'constraints': [\n                models.CheckConstraint(\n                    check=models.Q(field__gt=10),\n                    name='field_gt_10',\n                ),\n            ],\n        }),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['AddConstraint'])\n    self.assertOperationAttributes(\n        changes, 'app', 0, 0, model_name='foo',\n        constraint=models.CheckConstraint(check=models.Q(field__gt=10), name='field_gt_10'),\n    )\n", "def test_mti_inheritance_model_removal_with_child(self):\n    Animal = ModelState('app', 'Animal', [\n        (\"id\", models.AutoField(primary_key=True)),\n    ])\n    Dog = ModelState('app', 'Dog', [], bases=('app.Animal',))\n    Puppy = ModelState('app', 'Puppy', [], bases=('app.Dog',))\n    changes = self.get_changes([Animal, Dog, Puppy], [Animal])\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['DeleteModel', 'DeleteModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='Puppy')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='Dog')\n"], "sample_63": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = \"unusable\"\n        html = widget.render(name=\"password\", value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n", "    def test_custom_username_field(self):\n        class CustomUser(User):\n            USERNAME_FIELD = 'email'\n            email = models.EmailField(unique=True)\n\n        class CustomUserCreationForm(UserCreationForm):\n            class Meta(UserCreationForm.Meta):\n                model = CustomUser\n                fields = ('email',)\n\n        data = {\n            \"email\": \"test@example.com\",\n            \"password1\": \"test123\",\n            \"password2\": \"test123\",\n        }\n        form = CustomUserCreationForm(data)\n        self.assertTrue(form.is_valid())\n        user = form.save()\n        self.assertEqual(user.email, \"test@example.com\")\n        self.assertEqual(user.username, \"\")\n", "    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = \"unusable\"\n        html = widget.render(name=\"password\", value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n", "    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = UNUSABLE_PASSWORD_PREFIX + \"unusable\"\n        html = widget.render(name=\"password\", value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n", "    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = \"unusable\"\n        html = widget.render(name=\"password\", value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_96": ["def test_ridgecv_alphas():\n    # Test that RidgeCV works with different types of alphas\n\n    X, y = make_regression(n_samples=10, n_features=5, random_state=0)\n\n    # Test with a single alpha value\n    ridgecv = RidgeCV(alphas=1.0)\n    ridgecv.fit(X, y)\n    assert isinstance(ridgecv.alpha_, float)\n\n    # Test with an array of alpha values\n    alphas = [1.0, 2.0, 3.0]\n    ridgecv = RidgeCV(alphas=alphas)\n    ridgecv.fit(X, y)\n    assert ridgecv.alpha_ in alphas\n\n    # Test with a numpy array of alpha values\n    alphas = np.array([1.0, 2.0, 3.0])\n    ridgecv = RidgeCV(alphas=alphas)\n    ridgecv.fit(X, y)\n    assert ridgecv.alpha_ in alphas\n\n    # Test with an invalid type of alphas\n    assert_raises(ValueError, RidgeCV, alphas='invalid')\n", "def test_ridgecv_warns_when_solver_not_supported():\n    # Test that RidgeCV warns when using a solver not supported by Ridge\n    X, y = make_regression(n_samples=100, n_features=2, random_state=0)\n\n    ridgecv = RidgeCV(solver='auto', alphas=[1e-3], cv=None)\n    assert_warns(UserWarning, ridgecv.fit, X, y)\n", "def test_ridge_random_state():\n    # Test that Ridge is deterministic, i.e. the output does not depend on\n    # the state of the random number generator.\n\n    X = np.array([[-1.0, -1.0], [-1.0, 0], [-.8, -1.0],\n                  [1.0, 1.0], [1.0, 0.0]])\n    y = np.array([1, 1, 1, -1, -1])\n\n    ridge = Ridge(solver='sag', max_iter=1000, random_state=42)\n    ridge.fit(X, y)\n\n    ridge2 = Ridge(solver='sag', max_iter=1000, random_state=42)\n    ridge2.fit(X, y)\n\n    assert_array_almost_equal(ridge.coef_, ridge2.coef_)\n    assert_almost_equal(ridge.intercept_, ridge2.intercept_)\n\n    ridge3 = Ridge(solver='sag', max_iter=1000)\n    ridge3.fit(X, y)\n\n    assert_raises(AssertionError, assert_array_almost_equal, ridge.coef_, ridge3.coef_)\n    assert_raises(AssertionError, assert_almost_equal, ridge.intercept_, ridge3.intercept_)\n", "def test_ridgecv_warns_when_solver_not_supported():\n    X, y = make_regression(n_samples=10, n_features=2, random_state=42)\n    ridgecv = RidgeCV(solver='foo')\n    with ignore_warnings(category=UserWarning):\n        assert_warns(UserWarning, ridgecv.fit, X, y)\n", "def test_ridge_regression_sparse_target():\n    # Test that ridge regression can handle sparse targets\n\n    X = np.random.randn(10, 5)\n    y = sp.csr_matrix(np.random.randn(10))\n\n    ridge = Ridge(solver='lsqr')\n    ridge.fit(X, y)\n\n    assert_array_almost_equal(ridge.coef_.shape, (1, X.shape[1]))\n    assert_array_almost_equal(ridge.intercept_.shape, (1,))\n"], "sample_36": ["def test_register_lookup(self):\n    class MyLookup:\n        lookup_name = 'mylookup'\n\n    Q.register_lookup(MyLookup)\n    self.assertEqual(Q.get_lookups()['mylookup'], MyLookup)\n\n    # Check that lookups are inherited.\n    class MyQ(Q):\n        pass\n\n    self.assertEqual(MyQ.get_lookups()['mylookup'], MyLookup)\n\n    # Check that unregistering a lookup works.\n    Q._unregister_lookup(MyLookup)\n    self.assertIsNone(Q.get_lookups().get('mylookup'))\n", "def test_register_lookup(self):\n    class MyLookup:\n        lookup_name = 'mylookup'\n\n    Q.register_lookup(MyLookup)\n    self.assertIn('mylookup', Q.get_lookups())\n\n    # Test unregistering a lookup\n    Q._unregister_lookup(MyLookup)\n    self.assertNotIn('mylookup', Q.get_lookups())\n", "def test_register_lookup(self):\n    class MyQ(Q):\n        pass\n\n    lookup = object()\n    MyQ.register_lookup(lookup, 'my_lookup')\n    self.assertIn('my_lookup', MyQ.get_lookups())\n    self.assertEqual(MyQ.get_lookups()['my_lookup'], lookup)\n", "def test_register_lookup(self):\n    class MyLookup:\n        lookup_name = 'mylookup'\n\n    Q.register_lookup(MyLookup)\n    self.assertIn('mylookup', Q.get_lookups())\n\n    # Try to unregister the lookup.\n    Q._unregister_lookup(MyLookup)\n    self.assertNotIn('mylookup', Q.get_lookups())\n", "def test_register_lookup(self):\n    class TestLookup:\n        lookup_name = 'test'\n\n    class TestClass(RegisterLookupMixin):\n        pass\n\n    TestClass.register_lookup(TestLookup)\n    self.assertEqual(TestClass._get_lookup('test'), TestLookup)\n\n    # Check that unregistering works.\n    TestClass._unregister_lookup(TestLookup)\n    self.assertIsNone(TestClass._get_lookup('test'))\n\n    # Check that the lookup is also removed from subclasses.\n    class Subclass(TestClass):\n        pass\n\n    TestClass.register_lookup(TestLookup)\n    self.assertEqual(Subclass._get_lookup('test'), TestLookup)\n    TestClass._unregister_lookup(TestLookup)\n    self.assertIsNone(Subclass._get_lookup('test'))\n"], "sample_78": ["def test_cli_groups(app, runner):\n    \"\"\"Test commands and groups registered with Blueprint.group()\"\"\"\n    bp = Blueprint(\"grouped\", __name__, cli_group=\"grouped\")\n\n    @click.group(\"nested\")\n        pass\n\n    @nested.command(\"command\")\n        click.echo(\"nested_result\")\n\n    bp.cli.add_command(nested)\n\n    @bp.cli.group(\"merged\")\n        pass\n\n    @merged.command(\"command\")\n        click.echo(\"merged_result\")\n\n    cli = FlaskGroup(create_app=lambda: app)\n    result = runner.invoke(cli, [\"grouped\", \"nested\", \"command\"])\n    assert result.exit_code == 0\n    assert result.output == \"nested_result\\n\"\n\n    result = runner.invoke(cli, [\"grouped\", \"merged\", \"command\"])\n    assert result.exit_code == 0\n    assert result.output == \"merged_result\\n\"\n", "def test_cli_blueprint_groups(app, runner):\n    \"\"\"Test blueprint groups register correctly to the application\"\"\"\n    custom = Blueprint(\"custom\", __name__, cli_group=\"customized\")\n    no_group = Blueprint(\"no_group\", __name__, cli_group=None)\n\n    @custom.cli.command(\"custom\")\n        click.echo(\"custom_result\")\n\n    @no_group.cli.command(\"no_group\")\n        click.echo(\"no_group_result\")\n\n    app.register_blueprint(custom)\n    app.register_blueprint(no_group)\n\n    cli = FlaskGroup(create_app=lambda: app)\n    result = runner.invoke(cli, [\"custom\", \"custom\"])\n    assert result.exit_code == 0\n    assert result.output.strip() == \"custom_result\"\n\n    result = runner.invoke(cli, [\"no_group\"])\n    assert result.exit_code == 0\n    assert result.output.strip() == \"no_group_result\"\n", "def test_cli_custom_group_name(app, runner):\n    \"\"\"Test blueprint commands register correctly to the application with custom group name\"\"\"\n    custom = Blueprint(\"custom\", __name__, cli_group=\"customized\")\n    @custom.cli.command(\"custom\")\n        click.echo(\"custom_result\")\n\n    app.register_blueprint(custom)\n    result = runner.invoke(app.cli, [\"customized\", \"custom\"])\n    assert result.exit_code == 0\n    assert result.output.strip() == \"custom_result\"\n", "def test_cli_blueprints_register(app, runner):\n    \"\"\"Test blueprint commands register correctly to the application\"\"\"\n    custom = Blueprint(\"custom\", __name__, cli_group=\"customized\")\n    nested = Blueprint(\"nested\", __name__)\n    merged = Blueprint(\"merged\", __name__, cli_group=None)\n    late = Blueprint(\"late\", __name__)\n\n    @custom.cli.command(\"custom\")\n        click.echo(\"custom_result\")\n\n    @nested.cli.command(\"nested\")\n        click.echo(\"nested_result\")\n\n    @merged.cli.command(\"merged\")\n        click.echo(\"merged_result\")\n\n    @late.cli.command(\"late\")\n        click.echo(\"late_result\")\n\n    app.register_blueprint(custom)\n    app.register_blueprint(nested)\n    app.register_blueprint(merged)\n\n    # register after app is created\n    app.register_blueprint(late)\n\n    cli = FlaskGroup(create_app=lambda: app)\n\n    result = runner.invoke(cli, [\"custom\", \"custom\"])\n    assert result.exit_code == 0\n    assert result.output.strip() == \"custom_result\"\n\n    result = runner.invoke(cli, [\"nested\", \"nested\"])\n    assert result.exit_code == 0\n    assert result.output.strip() == \"nested_result\"\n\n    result = runner.invoke(cli, [\"merged\", \"merged\"])\n    assert result.exit_code == 0\n    assert result.output.strip() == \"merged_result\"\n\n    result = runner.invoke(cli, [\"late\", \"late\"])\n    assert result.exit_code == 0\n    assert result.output.strip() == \"late_result\"\n", "def test_cli_group_short_help():\n    \"\"\"Test that the short help for a CLI group is used.\"\"\"\n    group = AppGroup(\"group\", short_help=\"Short help\")\n    assert group.get_short_help_str() == \"Short help\"\n"], "sample_2": ["def test_wcs_print():\n    \"\"\"\n    Test WCS print function.\n    \"\"\"\n    w = wcs.WCS(naxis=2)\n    w.wcs.crval = [1, 1]\n    w.wcs.cdelt = [0.1, 0.1]\n    w.wcs.crpix = [1, 1]\n    w.wcs.ctype = ['RA---TAN', 'DEC--TAN']\n    print(w)\n    assert repr(w) == \"\"\"WCS Keywords", "def test_axis_type_names():\n    w = wcs.WCS(naxis=2)\n    w.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\"]\n    w.wcs.cname = [\"Longitude\", \"\"]\n    assert w.axis_type_names == [\"Longitude\", \"DEC--TAN\"]\n", "def test_axis_type_names():\n    w = wcs.WCS(naxis=2)\n    w.wcs.ctype = ['RA---TAN', 'DEC--TAN']\n    w.wcs.cname = ['', 'DEC--TAN']\n    assert w.axis_type_names == ['RA', 'DEC']\n", "def test_wcs_get_naxis():\n    \"\"\"\n    Test the WCS.get_naxis method.\n    \"\"\"\n    w = wcs.WCS(naxis=2)\n    assert w._get_naxis(header={'NAXIS1': 100, 'NAXIS2': 200}) is None\n    assert w.naxis == 2\n    assert w._naxis == [100, 200]\n", "def test_to_fits_2():\n    \"\"\"\n    Test to_fits() with SIP distortion.\n    \"\"\"\n    fits_name = get_pkg_data_filename('data/sip.fits')\n    w = wcs.WCS(fits_name)\n    wfits = w.to_fits()\n    assert isinstance(wfits, fits.HDUList)\n    assert isinstance(wfits[0], fits.PrimaryHDU)\n    assert len(wfits) == 1\n"], "sample_71": ["def test_reload_library():\n    original_library = style.library.copy()\n    with temp_style('test', DUMMY_SETTINGS):\n        assert 'test' in style.available\n    style.reload_library()\n    assert style.library == original_library\n", "def test_reload_library():\n    original_styles = style.available[:]\n    with temp_style('test', DUMMY_SETTINGS):\n        assert 'test' in style.available\n        style.reload_library()\n        assert style.available == original_styles\n", "def test_reload_library_multiple_times():\n    original_library = style.library.copy()\n    style.reload_library()\n    assert style.library == original_library\n    with temp_style('test', DUMMY_SETTINGS):\n        style.reload_library()\n        assert 'test' in style.library\n    style.reload_library()\n    assert style.library == original_library\n", "def test_reload_library_with_user_defined_styles():\n    original_value = 'gray'\n    mpl.rcParams[PARAM] = original_value\n    with temp_style('test', DUMMY_SETTINGS):\n        assert 'test' in style.available\n        style.reload_library()\n        assert 'test' in style.available\n        # Test that reloading the library does not affect current style.\n        assert mpl.rcParams[PARAM] == original_value\n", "def test_reload_library_with_added_user_style():\n    with temp_style('new_style', DUMMY_SETTINGS):\n        style.reload_library()\n        assert 'new_style' in style.available\n"], "sample_26": ["    def test_clone_test_db(self):\n        # Create a test database.\n        creation = connection.creation\n        old_database_name = connection.settings_dict['NAME']\n        test_database_name = creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n        \n        # Clone the test database.\n        clone_suffix = 'clone'\n        clone_settings = creation.get_test_db_clone_settings(clone_suffix)\n        with mock.patch.object(creation, '_clone_test_db'):\n            creation.clone_test_db(clone_suffix, verbosity=0)\n        \n        # Check that the clone settings are correct.\n        self.assertEqual(clone_settings['NAME'], '{}_{}'.format(test_database_name, clone_suffix))\n        \n        # Destroy the clone and the test database.\n        with mock.patch.object(creation, '_destroy_test_db'):\n            creation.destroy_test_db(old_database_name, verbosity=0, suffix=clone_suffix)\n            creation.destroy_test_db(old_database_name, verbosity=0)\n", "    def test_keepdb(self):\n        # A test database is created and not destroyed when keepdb=True.\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        with mock.patch.object(creation, '_create_test_db') as mocked_create:\n            creation.create_test_db(verbosity=0, autoclobber=True, keepdb=True, serialize=False)\n            creation.destroy_test_db(old_database_name, verbosity=0, keepdb=True)\n            mocked_create.assert_called_once()\n            self.assertEqual(test_connection.settings_dict['NAME'], creation._get_test_db_name())\n", "    def test_get_test_db_clone_settings(self):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        suffix = 'suffix'\n        try:\n            with mock.patch.object(creation, '_create_test_db'):\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n            clone_settings = creation.get_test_db_clone_settings(suffix)\n            self.assertEqual(clone_settings['NAME'], '{}_{}'.format(old_database_name, suffix))\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n", "    def test_create_test_db_with_database_error(self):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        with mock.patch.object(creation, '_execute_create_test_db') as mocked_execute:\n            mocked_execute.side_effect = Exception('Mocked database error')\n            with self.assertRaises(Exception) as context:\n                creation._create_test_db(verbosity=0, autoclobber=False, keepdb=False)\n            self.assertEqual(str(context.exception), 'Mocked database error')\n", "    def test_clone_test_db(self):\n        # Create the test database.\n        creation = connection.creation\n        old_database_name = connection.settings_dict['NAME']\n        test_database_name = creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n        \n        # Clone the test database.\n        suffix = '_clone'\n        cloned_settings_dict = creation.get_test_db_clone_settings(suffix)\n        with mock.patch.object(creation, '_clone_test_db'):\n            creation.clone_test_db(suffix, verbosity=0, autoclobber=True)\n        \n        # Ensure the cloned database settings are correct.\n        self.assertEqual(cloned_settings_dict['NAME'], test_database_name + suffix)\n\n        # Clean up.\n        with mock.patch.object(creation, '_destroy_test_db'):\n            creation.destroy_test_db(old_database_name, verbosity=0)\n"], "sample_23": ["def test_union_with_empty_queryset_values_list(self):\n    qs1 = Number.objects.filter(num=1).values_list('num', flat=True)\n    qs2 = Number.objects.none().values_list('num', flat=True)\n    self.assertEqual(list(qs1.union(qs2)), [1])\n", "def test_prefetch_related_objects(self):\n    # Create some sample data\n    Number.objects.bulk_create(Number(num=i, other_num=10 - i) for i in range(10))\n    ReservedName.objects.create(name='99 little bugs', order=99)\n\n    # Test prefetching related objects\n    qs = Number.objects.all()\n    prefetched_qs = qs.prefetch_related('reservedname_set')\n    self.assertEqual(len(prefetched_qs), 10)\n    for obj in prefetched_qs:\n        self.assertTrue(hasattr(obj, 'reservedname_set'))\n        self.assertIsInstance(obj.reservedname_set, list)\n\n    # Test prefetching with to_attr\n    qs = Number.objects.all()\n    prefetched_qs = qs.prefetch_related(Prefetch('reservedname_set', to_attr='custom_attr'))\n    self.assertEqual(len(prefetched_qs), 10)\n    for obj in prefetched_qs:\n        self.assertTrue(hasattr(obj, 'custom_attr'))\n        self.assertIsInstance(obj.custom_attr, list)\n\n    # Test prefetching with queryset\n    qs = Number.objects.all()\n    reserved_qs = ReservedName.objects.filter(order__gt=5)\n    prefetched_qs = qs.prefetch_related(Prefetch('reservedname_set', queryset=reserved_qs))\n    self.assertEqual(len(prefetched_qs), 10)\n    for obj in prefetched_qs:\n        self.assertTrue(hasattr(obj, 'reservedname_set'))\n        self.assertIsInstance(obj.reservedname_set, list)\n        self.assertLessEqual(len(obj.reservedname_set), len(reserved_qs))\n", "def test_union_with_order_by_in_subqueries(self):\n    qs1 = Number.objects.filter(num__lte=1).order_by('-num')\n    qs2 = Number.objects.filter(num__gte=8).order_by('num')\n    self.assertNumbersEqual(qs1.union(qs2), [1, 0, 8, 9], ordered=False)\n", "def test_union_with_none_queryset(self):\n    qs1 = Number.objects.all()\n    qs2 = Number.objects.none()\n    self.assertEqual(len(list(qs1.union(qs2))), 10)\n    self.assertEqual(len(list(qs2.union(qs1))), 10)\n    self.assertEqual(len(list(qs2.union(qs2))), 0)\n", "def test_union_with_values_and_limit(self):\n    ReservedName.objects.create(name='a', order=2)\n    qs1 = ReservedName.objects.all()\n    reserved_names = list(qs1.union(qs1).values('name', 'order', 'id')[:1])\n    self.assertEqual(len(reserved_names), 1)\n    self.assertEqual(reserved_names[0]['name'], 'a')\n    self.assertEqual(reserved_names[0]['order'], 2)\n"], "sample_117": ["def test_stringify_type_hints_ForwardRef():\n    if sys.version_info >= (3, 7):\n        from typing import ForwardRef  # type: ignore\n        assert stringify(ForwardRef(\"myint\")) == \"myint\"\n    else:\n        from sphinx.util.typing import ForwardRef\n        assert stringify(ForwardRef(\"myint\", is_argument=True)) == \"myint\"\n", "def test_stringify_type_hints_Ellipsis():\n    assert stringify(Ellipsis) == \"...\"\n", "def test_stringify_type_hints_ForwardRef():\n    from typing import ForwardRef  # type: ignore\n    assert stringify(ForwardRef(\"myint\")) == \"myint\"\n", "def test_restify_type_hints_Ellipsis():\n    assert restify(Ellipsis) == '...'\n    assert restify(List[...]) == \":class:`List`\\\\ [...]\"\n", "def test_stringify_type_hints_broken():\n    class BrokenType:\n        __args__ = None\n        __origin__ = None\n\n    assert stringify(BrokenType) == \"tests.test_util_typing.BrokenType\"\n"], "sample_87": ["def test_collect_ignore_with_pattern(testdir):\n    testdir.makeconftest(\n        \"\"\"\n        collect_ignore_glob = ['*_ignore.py']\n    \"\"\"\n    )\n    testdir.makepyfile(\n        test_file=\"\"\"\n            pass\n    \"\"\"\n    )\n    testdir.makepyfile(\n        test_ignore=\"\"\"\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"*1 passed in*\"])\n    result.stdout.no_fnmatch_line(\"*test_ignore*\")\n", "def test_collect_file_symlink_loop(testdir):\n    \"\"\"Test that collecting a file symlink which points to its parent directory does not cause infinite recursion.\"\"\"\n    sub = testdir.mkdir(\"sub\")\n    sub.ensure(\"__init__.py\")\n    sub.ensure(\"test_file.py\").write(\"def test_file(): pass\")\n    link = sub.join(\"link.py\")\n    link.mksymlinkto(sub)\n\n    result = testdir.runpytest(\"-v\", str(sub))\n    result.stdout.fnmatch_lines([\"sub/test_file.py::test_file PASSED*\", \"*1 passed in*\"])\n", "def test_collect_ignore_symlink_loop(testdir):\n    \"\"\"Test that collecting a symlink that points to its parent directory does not cause infinite recursion.\"\"\"\n    sub = testdir.mkdir(\"sub\")\n    sub.ensure(\"test_file.py\").write(\"def test_file(): pass\")\n\n    # Create a symlink that points to its parent directory.\n    sub.join(\"symlink_to_parent\").mksymlinkto(sub)\n\n    result = testdir.runpytest(\"-v\", str(sub))\n    result.stdout.fnmatch_lines([\"sub/test_file.py::test_file PASSED*\"])\n    assert result.ret == 0\n", "def test_collectreport_attr(testdir):\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n        class CustomFile(pytest.File):\n                return [CustomItem(\"hello\", parent=self)]\n\n                return \"Custom failure\"\n\n        class CustomItem(pytest.Item):\n                raise Exception(\"Custom error\")\n\n                return \"Custom item failure\"\n\n            if path.basename == \"custom.py\":\n                return CustomFile(path, parent)\n    \"\"\"\n    )\n    p = testdir.makefile(\".py\", \"custom\")\n    result = testdir.runpytest(p)\n    result.stdout.fnmatch_lines([\"*Custom failure*\", \"*Custom item failure*\"])\n", "def test_collect_error_propagation(testdir):\n    \"\"\"Verify that errors during collection propagate to the pytest_collectreport hook\"\"\"\n    testdir.makeconftest(\n        \"\"\"\n            raise Exception(\"Mock collection error\")\n    \"\"\"\n    )\n    testdir.makepyfile(\"def test_func(): pass\")\n    result = testdir.runpytest()\n    assert result.ret == 2\n    result.stdout.fnmatch_lines([\"*ERROR collecting*test_func.py*\", \"*Mock collection error*\"])\n"], "sample_153": ["def test_pretty_printing_matrix():\n    from sympy import Matrix, Symbol\n    A = Matrix([[1, 2], [3, 4]])\n    assert upretty(A) == \"\"\"\\", "def test_pretty_printing_assoc():\n    from sympy import sqrt\n    expr = 1/sqrt(2) + 3*sqrt(3)/sqrt(4)\n    assert pretty(expr) == '  ___   ___\\n/ 2  + 3*\\/ 3 \\n-----  -----\\n\\/ 2     2 '\n    assert upretty(expr) == '  \u221a2   \u221a3\\n\u2500\u2500\u2500\u2500\u2500 + \u2500\u2500\u2500\u2500\\n \u221a2    2'\n", "def test_pretty_printing_TensorProduct():\n    from sympy import TensorProduct\n    A = TensorProduct(a, b)\n    assert upretty(A) == \"a \\u2297 b\"\n    assert pretty(A) == \"a .* b\"\n", "def test_pretty_printing_of_hadamard_product():\n    from sympy.matrices.expressions.hadamard import HadamardProduct\n\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n\n    # Test pretty printing of Hadamard product\n    hadamard_product = HadamardProduct(A, B)\n    assert upretty(hadamard_product) == 'A .* B'\n\n    # Test pretty printing of Hadamard product with more than two matrices\n    C = MatrixSymbol('C', 2, 2)\n    hadamard_product = HadamardProduct(A, B, C)\n    assert upretty(hadamard_product) == 'A .* B .* C'\n", "def test_pretty_printing_pretty_repr():\n    from sympy import Rational, sqrt\n\n    assert pretty(Rational(3, 2)) == '3/2'\n    assert pretty(sqrt(2)) == 'sqrt(2)'\n    assert pretty([1, 2, 3]) == '[1, 2, 3]'\n    assert pretty((1, 2, 3)) == '(1, 2, 3)'\n    assert pretty({1: 2, 3: 4}) == '{1: 2, 3: 4}'\n    assert pretty({1, 2, 3}) == '{1, 2, 3}'\n    assert pretty(frozenset([1, 2, 3])) == 'frozenset({1, 2, 3})'\n"], "sample_82": ["def test_groupby_fillna():\n    # GH 2147\n    da = xr.DataArray(\n        [np.nan, 2, np.nan, 4],\n        dims=\"x\",\n        coords={\"group\": (\"x\", [\"A\", \"A\", \"B\", \"B\"])},\n    )\n    filled = da.groupby(\"group\").fillna(0)\n    expected = xr.DataArray([0, 2, 0, 4], dims=\"x\", coords=da.coords)\n    assert_identical(filled, expected)\n\n    ds = filled.to_dataset(name=\"foo\")\n    filled = ds.groupby(\"group\").fillna(0)\n    expected = xr.Dataset({\"foo\": expected})\n    assert_identical(filled, expected)\n", "def test_groupby_bins_label():\n    # GH: 4280\n    da = xr.DataArray([1, 2, 3], dims=[\"x\"], coords={\"x\": [1, 2, 3]})\n    bins = [0, 2, 4]\n    labels = [\"bin1\", \"bin2\"]\n    actual = da.groupby_bins(\"x\", bins=bins, labels=labels).sum()\n    expected = xr.DataArray(\n        [3, 3],\n        dims=[\"x_bins\"],\n        coords={\"x_bins\": pd.cut([1, 2, 3], bins=bins, labels=labels, include_lowest=True)},\n    )\n    assert_identical(actual, expected)\n", "def test_groupby_assign_coords():\n    # GH 5549\n    da = xr.DataArray([1, 2, 3], dims=[\"x\"], coords={\"x\": [10, 20, 30]})\n    da_grouped = da.groupby(\"x\")\n    new_coords = {\"y\": (\"x\", [100, 200, 300])}\n    result = da_grouped.assign_coords(**new_coords)\n    expected = da.assign_coords(**new_coords)\n    assert_identical(result, expected)\n", "def test_groupby_fillna():\n    # Test filling NaN values in grouped DataArray\n    da = xr.DataArray(\n        [[1, 2, np.nan], [3, 4, np.nan], [np.nan, 6, np.nan]],\n        dims=[\"x\", \"y\"],\n        coords={\"x\": [1, 1, 2]},\n    )\n    filled_da = da.groupby(\"x\").fillna(0)\n    expected_da = xr.DataArray(\n        [[1, 2, 0], [3, 4, 0], [0, 6, 0]], dims=[\"x\", \"y\"], coords={\"x\": [1, 1, 2]}\n    )\n    assert_identical(filled_da, expected_da)\n\n    # Test filling NaN values in grouped Dataset\n    ds = da.to_dataset(name=\"foo\")\n    filled_ds = ds.groupby(\"x\").fillna(0)\n    expected_ds = expected_da.to_dataset(name=\"foo\")\n    assert_identical(filled_ds, expected_ds)\n", "def test_groupby_apply_args_kwargs(array):\n        return (x + y) * z\n\n    expected = array.groupby(\"y\").apply(func, 1)\n    actual = array.groupby(\"y\").apply(func, y=1)\n    assert_identical(expected, actual)\n\n    expected = array.groupby(\"y\").apply(func, 2, z=2)\n    actual = array.groupby(\"y\").apply(func, y=2, z=2)\n    assert_identical(expected, actual)\n"], "sample_70": ["def test_legend_with_empty_label():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [3, 4], label='')\n    leg = ax.legend()\n    assert len(leg.get_texts()) == 0\n    assert len(leg.legendHandles) == 0\n", "def test_legend_remove_added_artist():\n    fig, ax = plt.subplots()\n    line1, = ax.plot([0, 1], label='line1')\n    line2, = ax.plot([0, 2], label='line2')\n\n    leg = ax.legend()\n    assert len(leg.legendHandles) == 2\n\n    line3, = ax.plot([0, 3], label='line3')\n    ax.add_artist(line3)\n    leg = ax.legend()\n    assert len(leg.legendHandles) == 3\n\n    ax.remove()\n    fig.add_axes(ax)\n    leg = ax.legend()\n    assert len(leg.legendHandles) == 3\n", "def test_legend_handles_length_mismatch():\n    # Test that legend raises an error when handles and labels have different lengths\n    fig, ax = plt.subplots()\n    lines = [ax.plot(range(10), label='hello world')[0]]\n    labels = ['label1', 'label2']\n    with pytest.raises(ValueError):\n        ax.legend(lines, labels)\n", "def test_legend_propagation_of_transform_to_handle():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], label='test')\n    leg = ax.legend()\n    assert leg.legendHandles[0].get_transform() is not None\n", "def test_legend_remove_all_handles():\n    fig, ax = plt.subplots()\n    lines = ax.plot(range(10), label='hello world')\n    leg = ax.legend()\n    leg.remove()\n    assert ax.get_legend() is None\n    assert fig.legends == []\n"], "sample_56": ["    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n", "    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n", "    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'custom_module.templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n", "    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n", "    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_3.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n"], "sample_18": ["    def test_table_name_collision_with_managed_model(self):\n        class Fan(models.Model):\n            pass\n\n        class Event(models.Model):\n            invitees = models.ManyToManyField(Fan)\n\n        class CollidingModel(models.Model):\n            pass\n\n        field = Event._meta.get_field('invitees')\n        with mock.patch.object(Event._meta.get_field('invitees').remote_field.through._meta, 'db_table', CollidingModel._meta.db_table):\n            self.assertEqual(field.check(from_model=Event), [\n                Error(\n                    \"The field's intermediary table 'invalid_models_tests_collidingmodel' clashes with the table name of 'CollidingModel'.\",\n                    obj=field,\n                    hint=(\n                        \"You have configured settings.DATABASE_ROUTERS. Verify \"\n                        \"that the table of 'CollidingModel' is correctly routed \"\n                        \"to a separate database.\"\n                    ),\n                    id='fields.W344',\n                ),\n            ])\n", "    def test_primary_key_on_through_model(self):\n        class Person(models.Model):\n            name = models.CharField(max_length=5)\n\n        class Group(models.Model):\n            members = models.ManyToManyField(Person, through='Membership')\n\n        class Membership(models.Model):\n            person = models.ForeignKey(Person, models.CASCADE)\n            group = models.ForeignKey(Group, models.CASCADE)\n            extra_info = models.CharField(max_length=10)\n            # The following line should not cause any errors\n            id = models.AutoField(primary_key=True)\n\n        self.assertEqual(Group.check(), [])\n", "    def test_unique_together_with_foreign_object(self):\n        class Parent(models.Model):\n            a = models.PositiveIntegerField()\n            b = models.PositiveIntegerField()\n\n            class Meta:\n                unique_together = (('a', 'b'),)\n\n        class Child(models.Model):\n            a = models.PositiveIntegerField()\n            b = models.PositiveIntegerField()\n            value = models.CharField(max_length=255)\n            parent = models.ForeignObject(\n                Parent,\n                on_delete=models.SET_NULL,\n                from_fields=('a', 'b'),\n                to_fields=('a', 'b'),\n                related_name='children',\n            )\n\n            class Meta:\n                unique_together = (('a', 'b'),)\n\n        field = Child._meta.get_field('parent')\n        self.assertEqual(field.check(from_model=Child), [])\n", "    def test_foreign_key_to_swapped_model(self):\n        class SwappableModel(models.Model):\n            class Meta:\n                swappable = 'TEST_SWAPPABLE_MODEL'\n\n        class Model(models.Model):\n            fk = models.ForeignKey(SwappableModel, models.CASCADE)\n\n        with override_settings(TEST_SWAPPABLE_MODEL='invalid_models_tests.Replacement'):\n            self.assertEqual(Model.check(), [\n                Error(\n                    \"Field defines a relation with model \"\n                    \"'invalid_models_tests.SwappableModel', which has been swapped out.\",\n                    hint=\"Update the relation to point at 'settings.TEST_SWAPPABLE_MODEL'.\",\n                    obj=Model._meta.get_field('fk'),\n                    id='fields.E301',\n                ),\n            ])\n", "    def test_m2m_through_model_delete(self):\n        class Target(models.Model):\n            pass\n\n        class Model(models.Model):\n            m2m = models.ManyToManyField(Target, through='Through')\n\n        class Through(models.Model):\n            target = models.ForeignKey(Target, models.CASCADE)\n            model = models.ForeignKey(Model, models.CASCADE)\n\n        field = Model._meta.get_field('m2m')\n        self.assertEqual(field.check(from_model=Model), [])\n\n        # Delete the 'through' model.\n        del apps.app_configs['invalid_models_tests'].models['through']\n\n        # Check that the field now correctly reports an error.\n        self.assertEqual(field.check(from_model=Model), [\n            Error(\n                \"Field specifies a many-to-many relation through model \"\n                \"'Through', which has not been installed.\",\n                obj=field,\n                id='fields.E331',\n            ),\n        ])\n"], "sample_75": ["def test_grid_set_aspect():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 2))\n    assert grid.get_aspect() is False\n    grid.set_aspect(True)\n    assert grid.get_aspect() is True\n    grid.set_aspect(False)\n    assert grid.get_aspect() is False\n\n    grid = ImageGrid(fig, 111, (2, 2))\n    assert grid.get_aspect() is True\n    grid.set_aspect(False)\n    assert grid.get_aspect() is False\n    grid.set_aspect(True)\n    assert grid.get_aspect() is True\n", "def test_grid_set_axes_locator():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 3))\n    locator = grid.get_axes_locator()\n    new_locator = grid._divider.new_locator(nx=1, ny=1)\n    grid.set_axes_locator(new_locator)\n    assert grid.get_axes_locator() != locator\n    assert grid.get_axes_locator() == new_locator\n", "def test_grid_set_aspect():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 3))\n    assert grid.get_aspect() is False\n    grid.set_aspect(True)\n    assert grid.get_aspect() is True\n    grid.set_aspect(False)\n    assert grid.get_aspect() is False\n", "def test_grid_label_mode():\n    fig = plt.figure(figsize=(6, 6))\n    grid = Grid(fig, 111, (2, 2), share_all=True)\n    for ax in grid:\n        ax.plot([0, 1], [0, 1])\n    grid.set_label_mode('L')\n    assert all(ax.get_xticklabels()[0].get_visible()\n               for ax in grid.axes_row[-1])\n    assert not any(ax.get_xticklabels()[0].get_visible()\n                   for ax in grid.axes_row[:-1])\n    assert all(ax.get_yticklabels()[0].get_visible()\n               for ax in grid.axes_column[0])\n    assert not any(ax.get_yticklabels()[0].get_visible()\n                   for ax in grid.axes_column[1:])\n", "def test_grid_set_axes_locator():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 3))\n    locator = grid.get_axes_locator()\n    new_locator = Divider(fig, [0, 0, 1, 1], [Size.Fixed(1)], [Size.Fixed(1)])\n    grid.set_axes_locator(new_locator)\n    assert grid.get_axes_locator() is not locator\n    assert grid.get_axes_locator() is new_locator\n"], "sample_114": ["def test_ovr_decision_function():\n    predictions = np.array([[0, 1, 0], [1, 0, 1]])\n    confidences = np.array([[0.3, 0.7, 0.2], [0.6, 0.4, 0.8]])\n\n    decision = _ovr_decision_function(predictions, confidences, 3)\n    assert decision.shape == (2, 3)\n    assert_array_almost_equal(decision[0], np.array([0.15, 0.65, 0.2]))\n    assert_array_almost_equal(decision[1], np.array([0.55, 0.35, 0.9]))\n\n    # Test ties\n    predictions = np.array([[0, 1, 0], [1, 0, 1]])\n    confidences = np.array([[0.5, 0.5, 0.2], [0.5, 0.5, 0.8]])\n\n    decision = _ovr_decision_function(predictions, confidences, 3)\n    assert decision.shape == (2, 3)\n    assert_array_almost_equal(decision[0], np.array([-0.05, 0.45, 0.2]))\n    assert_array_almost_equal(decision[1], np.array([0.45, -0.05, 0.8]))\n", "def test_ovr_decision_function():\n    # Test _ovr_decision_function with a simple example\n    predictions = np.array([[0, 1, 0], [1, 0, 1]])\n    confidences = np.array([[0.1, 0.9, 0.2], [0.8, 0.2, 0.7]])\n    n_classes = 3\n\n    decision_function = _ovr_decision_function(predictions, confidences, n_classes)\n    assert decision_function.shape == (2, 3)\n\n    # Test that the decision function is correct for a simple case\n    predictions = np.array([[0, 1]])\n    confidences = np.array([[0.4, 0.6]])\n    n_classes = 2\n\n    decision_function = _ovr_decision_function(predictions, confidences, n_classes)\n    assert decision_function.shape == (1, 2)\n    assert_array_almost_equal(decision_function[0], [-0.2, 0.2])\n", "def test_ovr_decision_function():\n    predictions = np.array([[0, 1, 0], [1, 0, 1]])\n    confidences = np.array([[0.5, 0.6, 0.7], [0.8, 0.9, 0.4]])\n    n_classes = 3\n\n    decision = _ovr_decision_function(predictions, confidences, n_classes)\n\n    assert decision.shape == (2, n_classes)\n    assert np.all(decision >= -1/3) and np.all(decision <= 1/3)\n", "def test_ovr_decision_function():\n    # Test _ovr_decision_function with a variety of inputs\n\n    # Binary classification\n    predictions = np.array([[0, 1], [1, 0]])\n    confidences = np.array([[0.2, 0.8], [0.7, 0.3]])\n    n_classes = 2\n    decision = _ovr_decision_function(predictions, confidences, n_classes)\n    assert_array_almost_equal(decision, np.array([[0.6, -0.6], [-0.4, 0.4]]))\n\n    # Multiclass classification\n    predictions = np.array([[0, 1, 2], [1, 2, 0]])\n    confidences = np.array([[0.2, 0.5, 0.3], [0.4, 0.4, 0.2]])\n    n_classes = 3\n    decision = _ovr_decision_function(predictions, confidences, n_classes)\n    assert_array_almost_equal(\n        decision, np.array([[0.16666667, 0.33333333, -0.5], [0.13333333, -0.06666667, -0.06666667]])\n    )\n\n    # Edge case: all confidences are zero\n    predictions = np.array([[0, 1, 2], [1, 2, 0]])\n    confidences = np.array([[0, 0, 0], [0, 0, 0]])\n    n_classes = 3\n    decision = _ovr_decision_function(predictions, confidences, n_classes)\n    assert_array_almost_equal(decision, np.zeros((2, 3)))\n", "def test_ovr_decision_function():\n    predictions = np.array([[0, 1, 1], [1, 0, 1]])\n    confidences = np.array([[0.3, 0.7, 0.9], [0.8, 0.2, 0.6]])\n    n_classes = 3\n\n    decision = _ovr_decision_function(predictions, confidences, n_classes)\n\n    # Check shape\n    assert decision.shape == (2, 3)\n\n    # Check columns sum to zero\n    assert_array_almost_equal(decision.sum(axis=1), np.zeros(2))\n\n    # Check predicted class has highest value\n    assert np.argmax(decision, axis=1).tolist() == [2, 0]\n"], "sample_112": ["def test_isotonic_regression_with_zero_weights():\n    \"\"\"Check that isotonic regression works correctly when some sample weights are zero.\"\"\"\n    X = np.arange(10)\n    y = np.arange(10)\n    sample_weight = np.ones_like(y)\n    sample_weight[3] = 0\n    sample_weight[7] = 0\n\n    iso_reg = IsotonicRegression().fit(X, y, sample_weight=sample_weight)\n\n    # Check that the zero-weight samples do not affect the result\n    y_pred = iso_reg.predict(X)\n    assert_array_equal(y_pred, np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n\n    # Check that the X_thresholds_ and y_thresholds_ attributes are correct\n    assert_array_equal(iso_reg.X_thresholds_, np.array([0, 1, 2, 4, 5, 6, 8, 9]))\n    assert_array_equal(iso_reg.y_thresholds_, np.array([0, 1, 2, 4, 5, 6, 8, 9]))\n", "def test_isotonic_regression_non_finite_values():\n    \"\"\"Check that isotonic regression can handle non-finite values.\"\"\"\n    X = np.arange(10)\n    y = np.array([np.nan, 2, 3, 4, 5, 6, 7, 8, 9, np.inf])\n    sample_weight = np.ones_like(y)\n\n    # Check that isotonic regression can handle NaN values\n    iso = IsotonicRegression()\n    with pytest.warns(UserWarning, match=\"Non-finite values were encountered\"):\n        iso.fit(X, y, sample_weight=sample_weight)\n\n    # Check that isotonic regression can handle inf values\n    y = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, np.inf])\n    iso = IsotonicRegression()\n    with pytest.warns(UserWarning, match=\"Non-finite values were encountered\"):\n        iso.fit(X, y, sample_weight=sample_weight)\n", "def test_isotonic_regression_feature_names_out():\n    \"\"\"Check `get_feature_names_out` for `IsotonicRegression` when the input is not fitted.\"\"\"\n    iso = IsotonicRegression()\n    with pytest.raises(AttributeError, match=\"object has no attribute 'f_'\"):\n        iso.get_feature_names_out()\n", "def test_isotonic_regression_single_y_value():\n    \"\"\"Check that isotonic regression works with a single y value.\"\"\"\n    X = np.arange(10)\n    y = np.repeat(5, 10)\n\n    iso = IsotonicRegression()\n    iso.fit(X, y)\n\n    assert_array_equal(iso.predict(X), y)\n    assert_array_equal(iso.X_thresholds_, [X[0]])\n    assert_array_equal(iso.y_thresholds_, [y[0]])\n", "def test_isotonic_regression_feature_names_out_error():\n    \"\"\"Check `get_feature_names_out` raises an error when `IsotonicRegression`\n    instance is not fitted.\"\"\"\n    iso = IsotonicRegression()\n    with pytest.raises(AttributeError, match=\"object has no attribute 'f_'\"):\n        iso.get_feature_names_out()\n"], "sample_138": ["def test_BlockMatrix_is_Identity():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', m, m)\n    X = BlockMatrix([[A, ZeroMatrix(n, m)], [ZeroMatrix(m, n), B]])\n    assert X.is_Identity == False\n\n    I_n = Identity(n)\n    I_m = Identity(m)\n    X = BlockMatrix([[I_n, ZeroMatrix(n, m)], [ZeroMatrix(m, n), I_m]])\n    assert X.is_Identity == True\n\n    Y = BlockDiagMatrix(I_n, I_m)\n    assert Y.is_Identity == True\n", "def test_blockcut_errors():\n    A = MatrixSymbol('A', n, m)\n    with raises(ValueError):\n        blockcut(A, (n/2,), (m/2, m/2))\n    with raises(ValueError):\n        blockcut(A, (n/2, n/2), (m/2,))\n    with raises(ValueError):\n        blockcut(A, (n/3, n/3, n/3), (m/2, m/2))\n    with raises(ValueError):\n        blockcut(A, (n/2, n/2), (m/3, m/3, m/3))\n", "def test_blockinverse_2x2():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n    inv_X = block_collapse(Inverse(X))\n\n    assert isinstance(inv_X, BlockMatrix)\n    assert inv_X.blocks[0, 0] == (-B*D.I*C + A).I\n    assert inv_X.blocks[0, 1] == -A.I*B*(D - C*A.I*B).I\n    assert inv_X.blocks[1, 0] == -(D - C*A.I*B).I*C*A.I\n    assert inv_X.blocks[1, 1] == (D - C*A.I*B).I\n", "def test_blockmatrix_equality():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    X = BlockMatrix([[A, ZeroMatrix(n, n)], [ZeroMatrix(n, n), B]])\n    Y = BlockMatrix([[A, ZeroMatrix(n, n)], [ZeroMatrix(n, n), B]])\n\n    assert X.equals(Y)\n    assert X == Y\n\n    C = MatrixSymbol('C', n, n)\n    Z = BlockMatrix([[A, ZeroMatrix(n, n)], [ZeroMatrix(n, n), C]])\n    assert not X.equals(Z)\n    assert X != Z\n", "def test_blockcollapse_trace():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', m, m)\n    X = BlockDiagMatrix(A, B)\n    assert block_collapse(trace(X)) == trace(A) + trace(B)\n"], "sample_16": ["def test_help_text_for_field(self):\n    \"\"\"\n    Tests for help_text_for_field\n    \"\"\"\n    self.assertEqual(\n        help_text_for_field(\"title\", Article),\n        \"\"\n    )\n    self.assertEqual(\n        help_text_for_field(\"hist\", Article),\n        \"This is a history field\"\n    )\n    with self.assertRaisesMessage(AttributeError, \"Unable to lookup 'unknown' on Article\"):\n        help_text_for_field(\"unknown\", Article)\n", "def test_quote_unquote(self):\n    value = \"example.com/path/to/resource?query=value#fragment\"\n    self.assertEqual(unquote(quote(value)), value)\n    value = \"/path/to/resource?query=value#fragment\"\n    self.assertEqual(unquote(quote(value)), value)\n    value = \"_example_com_path_to_resource_query_value_fragment\"\n    self.assertEqual(quote(unquote(value)), value)\n\n    # test special characters\n    value = 'example.com:8000/path/to/resource?query=\"value\"#fragment'\n    self.assertEqual(unquote(quote(value)), value)\n    value = \"/path/to/resource?query='value'#fragment\"\n    self.assertEqual(unquote(quote(value)), value)\n\n    # test already quoted string\n    value = \"example_com_path_to_resource_query_value_fragment\"\n    self.assertEqual(quote(value), value)\n    self.assertEqual(unquote(value), value)\n", "def test_quote(self):\n    self.assertEqual(quote('hello/world'), 'hello_2Fworld')\n    self.assertEqual(unquote('hello_2Fworld'), 'hello/world')\n    self.assertEqual(quote(123), 123)  # Non-string input is left unchanged\n    self.assertEqual(unquote(123), 123)  # Non-string input is left unchanged\n\n    # Test all special characters\n    special_chars = ':/\"_#?;@&=+$,[]<>%\\n\\\\'\n    quoted_special_chars = ''.join(QUOTE_MAP[ord(c)] for c in special_chars)\n    self.assertEqual(quote(special_chars), quoted_special_chars)\n    self.assertEqual(unquote(quoted_special_chars), special_chars)\n", "def test_quote(self):\n    \"\"\"\n    Regression test for quote()\n    \"\"\"\n    tests = (\n        (\"test\", \"test\"),\n        (\"test/test\", \"test_test\"),\n        (\"test_test\", \"test__test\"),\n        (\"test:test\", \"test:test\"),\n        (123, 123),\n    )\n    for value, expected in tests:\n        self.assertEqual(quote(value), expected)\n", "def test_reverse_field_path(self):\n    model, path = reverse_field_path(Event, \"location__address\")\n    self.assertEqual(model, Location)\n    self.assertEqual(path, \"event__location\")\n    \n    model, path = reverse_field_path(Location, \"event__guest\")\n    self.assertEqual(model, EventGuide)\n    self.assertEqual(path, \"event__location\")\n"], "sample_89": ["def test_node_repr():\n    node = nodes.Node.from_parent(None, name=\"test_node\")\n    assert repr(node) == \"<Node test_node>\"\n", "def test_node_repr():\n    node = nodes.Node.from_parent(None, name=\"test_node\")\n    assert repr(node) == \"<Node test_node>\"\n", "def test_node_keywords():\n    node = nodes.Node.from_parent(None, name=\"test_node\")\n    assert isinstance(node.keywords, nodes.NodeKeywords)\n    assert node.keywords == set()\n\n    node.keywords[\"test_keyword\"] = \"test_value\"\n    assert \"test_keyword\" in node.keywords\n    assert len(node.keywords) == 1\n\n    node.keywords[\"test_keyword2\"] = \"test_value2\"\n    assert len(node.keywords) == 2\n\n    assert node.listextrakeywords() == set()\n", "def test_get_fslocation_from_item():\n    class FakeItem:\n        fspath = py.path.local(\"/path/to/file\")\n\n    assert nodes.get_fslocation_from_item(FakeItem()) == (FakeItem.fspath, None)\n\n    class FakeItem:\n        location = (\"path\", 10)\n\n    assert nodes.get_fslocation_from_item(FakeItem()) == FakeItem.location\n\n    class FakeItem:\n        obj = object()\n\n    assert nodes.get_fslocation_from_item(FakeItem()) == (py.path.local(), -1)\n", "def test_node_repr():\n    node = nodes.Node.from_parent(None, name=\"test_node\")\n    assert repr(node) == \"<Node test_node>\"\n"], "sample_13": ["    def test_escape_leading_slashes(self):\n        self.assertEqual(escape_leading_slashes('//example.com'), '/%2F/example.com')\n        self.assertEqual(escape_leading_slashes('/example.com'), '/example.com')\n        self.assertEqual(escape_leading_slashes('http://example.com'), 'http://example.com')\n", "    def test_escape_leading_slashes(self):\n        self.assertEqual(escape_leading_slashes('//example.com'), '/%2F/example.com')\n        self.assertEqual(escape_leading_slashes('/example.com'), '/example.com')\n        self.assertEqual(escape_leading_slashes('http://example.com'), 'http://example.com')\n        self.assertEqual(escape_leading_slashes('https://example.com'), 'https://example.com')\n", "    def test_escape_leading_slashes(self):\n        self.assertEqual(escape_leading_slashes('//example.com'), '/%2F/example.com')\n        self.assertEqual(escape_leading_slashes('http://example.com'), 'http://example.com')\n        self.assertEqual(escape_leading_slashes('/example.com'), '/example.com')\n", "    def test_escape_leading_slashes(self):\n        self.assertEqual(escape_leading_slashes('//example.com'), '/%2F/example.com')\n        self.assertEqual(escape_leading_slashes('/example.com'), '/example.com')\n        self.assertEqual(escape_leading_slashes('http://example.com'), 'http://example.com')\n", "    def test_escape_leading_slashes(self):\n        self.assertEqual(escape_leading_slashes('//example.com'), '/%2Fexample.com')\n"], "sample_50": ["def test_update_cookie(self):\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # Test setting the cookie with data\n    messages = [Message(constants.INFO, 'Test message')]\n    encoded_data = storage._encode(messages)\n    storage._update_cookie(encoded_data, response)\n    self.assertEqual(response.cookies['messages'].value, encoded_data)\n\n    # Test deleting the cookie when there's no data\n    storage._update_cookie(None, response)\n    self.assertEqual(response.cookies['messages']['max-age'], 0)\n", "def test_not_finished_sentinel(self):\n    \"\"\"\n    The not_finished sentinel value is properly removed and restored.\n    \"\"\"\n    storage = self.get_storage()\n    messages = [Message(constants.INFO, 'message 1'), Message(constants.INFO, 'message 2')]\n    encoded_data = storage._encode(messages + [CookieStorage.not_finished])\n    decoded_messages = storage._decode(encoded_data)\n    self.assertEqual(decoded_messages[:-1], messages)\n    self.assertEqual(decoded_messages[-1], CookieStorage.not_finished)\n\n    # Test that the sentinel is removed when there are more messages to store.\n    additional_message = Message(constants.INFO, 'message 3')\n    messages.append(additional_message)\n    encoded_data = storage._encode(messages + [CookieStorage.not_finished])\n    decoded_messages = storage._decode(encoded_data)\n    self.assertEqual(decoded_messages[:-1], messages)\n    self.assertEqual(decoded_messages[-1], CookieStorage.not_finished)\n\n    # Test that the sentinel is removed when storing with remove_oldest=True.\n    storage = self.get_storage()\n    response = self.get_response()\n    messages = [Message(constants.INFO, 'message 1'), Message(constants.INFO, 'message 2')]\n    unstored_messages = storage._store(messages + [CookieStorage.not_finished], response, remove_oldest=True)\n    self.assertEqual(unstored_messages, [])\n    decoded_messages = storage._decode(response.cookies[CookieStorage.cookie_name].value)\n    self.assertEqual(decoded_messages, messages)\n", "def test_update_cookie(self):\n    \"\"\"\n    Test that the _update_cookie method correctly sets or deletes the cookie.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # Test setting the cookie with data\n    encoded_data = storage._encode(['test message'])\n    storage._update_cookie(encoded_data, response)\n    self.assertIn(storage.cookie_name, response.cookies)\n    self.assertEqual(response.cookies[storage.cookie_name].value, encoded_data)\n\n    # Test deleting the cookie when there is no data\n    storage._update_cookie(None, response)\n    self.assertIn(storage.cookie_name, response.cookies)\n    self.assertEqual(response.cookies[storage.cookie_name]['max-age'], 0)\n", "def test_not_finished(self):\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # Add messages to fill up the cookie, plus one extra\n    msg_size = int((CookieStorage.max_cookie_size - 54) / 4.5 - 37)\n    for i in range(5):\n        msg = get_random_string(msg_size)\n        storage.add(constants.INFO, msg)\n\n    unstored_messages = storage.update(response)\n\n    # Check that the 'not finished' sentinel value is stored\n    data = storage._decode(response.cookies['messages'].value)\n    self.assertEqual(data[-1], CookieStorage.not_finished)\n\n    # Check that the 'not finished' sentinel value is removed when retrieved\n    request = self.get_request()\n    request.COOKIES = response.cookies\n    storage = self.storage_class(request)\n    messages = list(storage)\n    self.assertNotIn(CookieStorage.not_finished, messages)\n", "def test_not_finished(self):\n    \"\"\"\n    When the data exceeds what is allowed in a cookie, and messages are removed,\n    a sentinel value is stored to indicate that not all messages were retrieved.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    msg_size = int((CookieStorage.max_cookie_size - 54) / 4.5 - 37)\n    for i in range(5):\n        msg = get_random_string(msg_size)\n        storage.add(constants.INFO, msg)\n\n    storage.update(response)\n\n    cookie_storing = self.stored_messages_count(storage, response)\n    self.assertEqual(cookie_storing, 4)\n\n    # Simulate retrieving the messages from the cookie\n    request = self.get_request()\n    request.COOKIES = response.cookies\n    storage = self.storage_class(request)\n\n    messages, all_retrieved = storage._get()\n    self.assertFalse(all_retrieved)\n    self.assertEqual(len(messages), 4)\n"], "sample_92": ["def test_xfail_strict_with_raises(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(strict=True, raises=TypeError)\n            raise ValueError(\"hello\")\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n", "def test_xfail_strict_module_level(testdir):\n    \"\"\"\n    Verify that using pytest.mark.xfail(strict=True) at module level causes a collection error\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        pytestmark = pytest.mark.xfail(strict=True, reason=\"Expected failure\")\n\n            assert True\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*Using pytest.mark.xfail(strict=True) outside of a test is not allowed*\"])\n", "def test_xfail_strict_with_multiple_conditions(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(\"True or False\", reason=\"multiple conditions\", strict=True)\n            assert 1\n    \"\"\"\n    )\n    result = testdir.runpytest(p, \"-rxX\")\n    result.stdout.fnmatch_lines([\"*XPASS(strict)*multiple conditions*\"])\n    assert result.ret == 1\n", "def test_xfail_strict_ini(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        xfail_strict = true\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n", "def test_xfail_strict_from_ini(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        xfail_strict = True\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n    assert result.ret == 1\n"], "sample_135": ["def test_compare_pretty():\n    x, y = symbols('x y')\n    assert Basic._compare_pretty(2*x, 3*y) == -1\n    assert Basic._compare_pretty(3*x, 2*y) == 1\n    assert Basic._compare_pretty(x**2, y**2) == -1\n    assert Basic._compare_pretty(y**2, x**2) == 1\n    assert Basic._compare_pretty(x**2 + 1, x**2) == 1\n    assert Basic._compare_pretty(x**2, x**2 + 1) == -1\n", "def test__constructor_postprocessor_mapping():\n    from sympy.core.function import UndefinedFunction\n\n    class MyType(Basic):\n        _constructor_postprocessor_mapping = {\n            'MyFunc': [_my_func_postprocessor]\n        }\n\n    class MyFunc(UndefinedFunction):\n        pass\n\n        if isinstance(expr, MyFunc):\n            return expr.args[0] + 1\n        return expr\n\n    assert MyFunc(1).args == (1,)\n    assert MyType(MyFunc(1)).args == (2,)\n", "def test_fromiter():\n    assert Basic.fromiter([1, 2, 3]) == Basic(1, 2, 3)\n    assert Basic.fromiter((1, 2, 3)) == Basic(1, 2, 3)\n    raises(TypeError, lambda: Basic.fromiter(\"123\"))\n", "def test_class_key():\n    x = symbols('x')\n    assert Basic.class_key() == (5, 0, 'Basic')\n    assert Atom.class_key() == (2, 0, 'Atom')\n    assert x.class_key() == (1, 0, 'Symbol')\n", "def test_compare_pretty():\n    from sympy.core.function import UndefinedFunction\n    f = UndefinedFunction('f')\n    x, y = symbols('x y')\n    assert Basic._compare_pretty(f(x), f(y)) == -1\n    assert Basic._compare_pretty(x**2, y**3) == -1\n    assert Basic._compare_pretty(x**11, x**2) == 1\n"], "sample_46": ["    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(),\n            opclasses=['varchar_ops', 'int4_ops']\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(),\n            col_suffixes=('ASC', 'DESC'), opclasses=('int4_ops', 'text_ops')\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(),\n            col_suffixes=('ASC', 'DESC'), opclasses=('integer_ops', 'text_ops')\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(),\n            col_suffixes=('ASC', 'DESC'), opclasses=('text_ops', 'varchar_ops')\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(),\n            opclasses=['varchar_ops', 'int4_ops']\n        )\n"], "sample_159": ["def test_prefix_repr():\n    m = PREFIXES['m']\n    k = PREFIXES['k']\n    M = PREFIXES['M']\n    kibi = Prefix('kibi', 'Ki', 10, 2)\n\n    assert repr(m) == \"Prefix('milli', 'm', -3)\"\n    assert repr(k) == \"Prefix('kilo', 'k', 3)\"\n    assert repr(M) == \"Prefix('mega', 'M', 6)\"\n    assert repr(kibi) == \"Prefix('kibi', 'Ki', 10, 2)\"\n", "def test_prefix_repr_latex():\n    assert repr(kilo) == \"Prefix('kilo', 'k', 3)\"\n    assert kilo._latex(None) == r'\\text{k}'\n    micro = PREFIXES['mu']\n    assert micro._latex(None) == r'\\mu'\n", "def test_prefix_repr():\n    yotta = PREFIXES['Y']\n    kibi = BIN_PREFIXES['Ki']\n\n    assert repr(yotta) == \"Prefix('yotta', 'Y', 24)\"\n    assert repr(kibi) == \"Prefix('kibi', 'Y', 10, 2)\"\n", "def test_prefix_properties():\n    k = PREFIXES['k']\n    m = PREFIXES['m']\n\n    assert k.name == 'kilo'\n    assert k.abbrev == 'k'\n    assert k.scale_factor == 1000\n    assert k.base == 10\n\n    assert m.name == 'milli'\n    assert m.abbrev == 'm'\n    assert m.scale_factor == Rational(1, 1000)\n    assert m.base == 10\n\n    assert str(k) == 'k'\n    assert repr(k) == \"Prefix('kilo', 'k', 3)\"\n    assert str(m) == 'm'\n    assert repr(m) == \"Prefix('milli', 'm', -3)\"\n\n    micro = PREFIXES['mu']\n    assert micro._latex() == r'\\mu'\n    assert k._latex() == r'\\text{k}'\n", "def test_prefix_repr():\n    m = PREFIXES['m']\n    k = PREFIXES['k']\n    M = PREFIXES['M']\n    kibi = Prefix('kibi', 'Ki', 10, 2)\n\n    assert repr(m) == \"Prefix('milli', 'm', -3)\"\n    assert repr(k) == \"Prefix('kilo', 'k', 3)\"\n    assert repr(M) == \"Prefix('mega', 'M', 6)\"\n    assert repr(kibi) == \"Prefix('kibi', 'Ki', 10, 2)\"\n"], "sample_24": ["def test_update_error_dict(self):\n    error_dict = {}\n    exception = ValidationError('message')\n    updated_dict = exception.update_error_dict(error_dict)\n    self.assertEqual(updated_dict, {'__all__': ['message']})\n\n    error_dict = {'field1': ['error1']}\n    exception = ValidationError('message')\n    updated_dict = exception.update_error_dict(error_dict)\n    self.assertEqual(updated_dict, {'field1': ['error1'], '__all__': ['message']})\n\n    error_dict = {}\n    exception = ValidationError({'field1': 'message'})\n    updated_dict = exception.update_error_dict(error_dict)\n    self.assertEqual(updated_dict, {'field1': ['message']})\n\n    error_dict = {'field1': ['error1']}\n    exception = ValidationError({'field1': 'message', 'field2': 'error2'})\n    updated_dict = exception.update_error_dict(error_dict)\n    self.assertEqual(updated_dict, {'field1': ['error1', 'message'], 'field2': ['error2']})\n", "def test_update_error_dict(self):\n    error_dict = {}\n    exception = ValidationError('message')\n    updated_dict = exception.update_error_dict(error_dict)\n    self.assertEqual(updated_dict, {'__all__': ['message']})\n\n    error_dict = {'field1': ['error1']}\n    exception = ValidationError({'field2': 'error2'})\n    updated_dict = exception.update_error_dict(error_dict)\n    self.assertEqual(updated_dict, {'field1': ['error1'], 'field2': ['error2']})\n\n    error_dict = {}\n    exception = ValidationError(['error1', 'error2'])\n    updated_dict = exception.update_error_dict(error_dict)\n    self.assertEqual(updated_dict, {'__all__': ['error1', 'error2']})\n", "def test_repr(self):\n    error1 = ValidationError('message')\n    error2 = ValidationError('message', code='my_code')\n    error3 = ValidationError({'field1': 'message', 'field2': 'other'})\n    error4 = ValidationError([\n        ValidationError({'field1': 'field error', 'field2': 'other'}),\n        'message',\n    ])\n\n    self.assertEqual(repr(error1), \"ValidationError(['message'])\")\n    self.assertEqual(repr(error2), \"ValidationError(['message'])\")  # code is not included in repr\n    self.assertEqual(repr(error3), \"ValidationError({'field1': ['message'], 'field2': ['other']})\")\n    self.assertEqual(\n        repr(error4),\n        \"ValidationError([ValidationError({'field1': ['field error'], 'field2': ['other']}), 'message'])\"\n    )\n", "def test_update_error_dict(self):\n    error_dict = {}\n    error1 = ValidationError('message')\n    error2 = ValidationError({'field1': 'message', 'field2': 'other'})\n\n    error1.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {NON_FIELD_ERRORS: ['message']})\n\n    error2.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {\n        NON_FIELD_ERRORS: ['message'],\n        'field1': ['message'],\n        'field2': ['other'],\n    })\n\n    error3 = ValidationError(['message1', 'message2'])\n    error3.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {\n        NON_FIELD_ERRORS: ['message', 'message1', 'message2'],\n        'field1': ['message'],\n        'field2': ['other'],\n    })\n", "def test_update_error_dict(self):\n    error1 = ValidationError('message')\n    error2 = ValidationError({'field1': 'message', 'field2': 'other'})\n    error3 = ValidationError([\n        ValidationError({'field1': 'field error', 'field2': 'other'}),\n        'message',\n    ])\n\n    error_dict = {}\n    error1.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {NON_FIELD_ERRORS: ['message']})\n\n    error_dict = {}\n    error2.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['message'], 'field2': ['other']})\n\n    error_dict = {}\n    error3.update_error_dict(error_dict)\n    self.assertEqual(\n        error_dict,\n        {\n            'field1': ['field error'],\n            'field2': ['other'],\n            NON_FIELD_ERRORS: ['message'],\n        },\n    )\n\n    error_dict = {'field1': ['existing error']}\n    error2.update_error_dict(error_dict)\n    self.assertEqual(\n        error_dict,\n        {'field1': ['existing error', 'message'], 'field2': ['other']},\n    )\n"], "sample_147": ["def test_MatMul_kind():\n    A = MatrixSymbol('A', 2,2)\n    B = MatrixSymbol('B', 2,2)\n    assert MatMul(A, B).kind is MatrixKind(NumberKind)\n    assert MatMul(A, comm_x).kind is MatrixKind(NumberKind)\n    assert MatMul(noncomm_x, A).kind is UndefinedKind\n", "def test_MatMul_kind():\n    A = MatrixSymbol('A', 2,2)\n    B = MatrixSymbol('B', 2,2)\n    assert MatMul(A, B).kind is MatrixKind(NumberKind)\n    assert MatMul(2, A).kind is MatrixKind(NumberKind)\n    assert MatMul(A, comm_x).kind is MatrixKind(NumberKind)\n    assert MatMul(noncomm_x, A).kind is UndefinedKind\n", "def test_MatMul_kind():\n    A = MatrixSymbol('A', 2,2)\n    B = MatrixSymbol('B', 2,2, commutative=False)\n    assert MatMul(A, A).kind is MatrixKind(NumberKind)\n    assert MatMul(B, B).kind is UndefinedKind\n    assert MatMul(A, B).kind is UndefinedKind\n", "def test_MatMul_kind():\n    A = MatrixSymbol('A', 2,2)\n    B = MatrixSymbol('B', 2,2)\n    assert MatMul(A, B).kind is MatrixKind(NumberKind)\n    assert MatMul(A, comm_x).kind is MatrixKind(NumberKind)\n    assert MatMul(comm_x, A).kind is MatrixKind(NumberKind)\n    assert MatMul(noncomm_x, A).kind is UndefinedKind\n", "def test_MatMul_kind():\n    A = MatrixSymbol('A', 2,2)\n    B = MatrixSymbol('B', 2,2)\n    assert MatMul(A, B).kind is MatrixKind(NumberKind)\n    assert MatMul(A, comm_x).kind is MatrixKind(NumberKind)\n    assert MatMul(comm_x, A).kind is MatrixKind(NumberKind)\n    assert MatMul(noncomm_x, A).kind is UndefinedKind\n    assert MatMul(A, noncomm_x).kind is UndefinedKind\n"], "sample_57": ["def test_all_valid_with_non_form_errors(self):\n    \"\"\"all_valid() validates all forms, even when some have non-form errors.\"\"\"\n    data = {\n        \"choices-TOTAL_FORMS\": \"2\",\n        \"choices-INITIAL_FORMS\": \"0\",\n        \"choices-MIN_NUM_FORMS\": \"0\",\n        \"choices-0-choice\": \"Zero\",\n        \"choices-0-votes\": \"0\",\n        \"choices-1-choice\": \"One\",\n        \"choices-1-votes\": \"1\",\n    }\n    ChoiceFormSet = formset_factory(Choice)\n    formset1 = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n    formset2 = ChoiceFormSet(\n        data,\n        auto_id=False,\n        prefix=\"choices\",\n        error_messages={\"too_many_forms\": \"Custom too many forms error\"},\n    )\n    formset2._non_form_errors = ErrorList([\"Custom non-form error\"])\n    self.assertIs(all_valid((formset1, formset2)), False)\n    expected_errors = [{}, {}]\n    self.assertEqual(formset1._errors, expected_errors)\n    self.assertEqual(formset2._errors, expected_errors)\n    self.assertEqual(formset2.non_form_errors(), [\"Custom non-form error\"])\n", "    def test_default_prefix(self):\n        ChoiceFormSet = formset_factory(Choice)\n        formset = ChoiceFormSet()\n        self.assertEqual(formset.prefix, \"form\")\n", "    def test_get_form_kwargs(self):\n        \"\"\"\n        The get_form_kwargs() method is used to pass kwargs to each form in the\n        formset. This can be overridden to pass different kwargs to each form.\n        \"\"\"\n\n        class BaseDynamicFormSet(BaseFormSet):\n                return {\"custom_kwarg\": index}\n\n        DynamicFormSet = formset_factory(\n            CustomKwargForm, formset=BaseDynamicFormSet, extra=2\n        )\n        formset = DynamicFormSet()\n        for i, form in enumerate(formset.forms):\n            self.assertEqual(form.custom_kwarg, i)\n", "def test_formset_absolute_max_overrides_default_max(self):\n    \"\"\"absolute_max overrides DEFAULT_MAX_NUM if it's provided.\"\"\"\n    LimitedFavoriteDrinkFormSet = formset_factory(\n        FavoriteDrinkForm,\n        max_num=1000,\n        absolute_max=500,\n    )\n    formset = LimitedFavoriteDrinkFormSet()\n    self.assertEqual(formset.absolute_max, 500)\n", "    def test_default_prefix(self):\n        ChoiceFormSet = formset_factory(Choice)\n        formset = ChoiceFormSet()\n        self.assertEqual(formset.prefix, 'form')\n"], "sample_103": ["def test_mutual_info_regression_sparse():\n    # Test that mutual_info_regression works with sparse matrices.\n    X = csr_matrix(np.array([[1, 2], [3, 4]]))\n    y = np.array([0, 1])\n    mi = mutual_info_regression(X, y)\n    assert_array_equal(mi.shape, (X.shape[1],))\n", "def test_mutual_info_classif_sparse():\n    # Test that mutual_info_classif works with sparse matrices\n    rng = check_random_state(0)\n    X = csr_matrix(rng.rand(100, 5))\n    y = rng.randint(0, 2, size=100)\n\n    mi = mutual_info_classif(X, y, discrete_features='auto')\n    assert_array_equal(mi.shape, (X.shape[1],))\n\n    # Check that the MI is non-negative\n    assert_greater(mi, -1e-10)\n", "def test_mutual_info_regression_sparse():\n    # We generate sample from multivariate normal distribution, using\n    # transformation from initially uncorrelated variables. The zero\n    # variables after transformation is selected as the target vector,\n    # it has the strongest correlation with the variable 2, and\n    # the weakest correlation with the variable 1.\n    T = np.array([\n        [1, 0.5, 2, 1],\n        [0, 1, 0.1, 0.0],\n        [0, 0.1, 1, 0.1],\n        [0, 0.1, 0.1, 1]\n    ])\n    cov = T.dot(T.T)\n    mean = np.zeros(4)\n\n    rng = check_random_state(0)\n    Z = rng.multivariate_normal(mean, cov, size=1000)\n    X = csr_matrix(Z[:, 1:])\n    y = Z[:, 0]\n\n    mi = mutual_info_regression(X, y, random_state=0)\n    assert_array_equal(np.argsort(-mi), np.array([1, 2, 0]))\n", "def test_mutual_info_regression_sparse():\n    # Test that mutual_info_regression works with sparse matrices.\n    rng = check_random_state(0)\n    X = rng.rand(100, 5)\n    y = rng.rand(100)\n\n    # Create a sparse matrix with the same data as X\n    X_sparse = csr_matrix(X)\n\n    mi_dense = mutual_info_regression(X, y, random_state=0)\n    mi_sparse = mutual_info_regression(X_sparse, y, random_state=0)\n\n    assert_array_equal(mi_dense, mi_sparse)\n", "def test_mutual_info_classif_sparse():\n    # Test that mutual_info_classif works with sparse matrices.\n    rng = check_random_state(0)\n    X = csr_matrix(rng.rand(100, 5))\n    y = rng.randint(0, 2, size=100)\n\n    mi = mutual_info_classif(X, y, discrete_features='auto', random_state=0)\n    assert_array_equal(mi.shape, (X.shape[1],))\n\n    # Check that mutual_info_classif works with sparse matrices and a mix of\n    # discrete and continuous features.\n    X = csr_matrix(rng.rand(100, 5))\n    X[:, 0] = X[:, 0] > 0.5\n    y = rng.randint(0, 2, size=100)\n\n    mi = mutual_info_classif(X, y, discrete_features=[0], random_state=0)\n    assert_array_equal(mi.shape, (X.shape[1],))\n"], "sample_108": ["def test_liblinear_sample_weight():\n    # Test that liblinear handles sample weights correctly.\n\n    # Create a toy dataset where one sample has more weight than the others.\n    X = [[1, 2], [3, 4], [5, 6]]\n    y = [0, 0, 1]\n    sample_weight = [1, 1, 100]\n\n    # Fit a LinearSVC model with and without sample weights.\n    clf_no_weights = svm.LinearSVC(random_state=0).fit(X, y)\n    clf_with_weights = svm.LinearSVC(random_state=0).fit(X, y, sample_weight)\n\n    # Check that the coefficients are different when using sample weights.\n    assert not np.allclose(clf_no_weights.coef_, clf_with_weights.coef_)\n", "def test_liblinear_decision_function_shape():\n    # Test that the decision function shape of LinearSVC is correct\n    X, y = make_classification(n_samples=200, n_features=20,\n                               n_informative=10, n_redundant=0,\n                               n_repeated=0, n_classes=3, random_state=0)\n    clf = svm.LinearSVC().fit(X, y)\n\n    assert clf.decision_function(X).shape == (len(X), len(clf.classes_))\n\n    # check shape with decision_function_shape='ovr'\n    clf = svm.LinearSVC(multi_class='ovr').fit(X, y)\n    assert clf.decision_function(X).shape == (len(X), len(clf.classes_))\n\n    # check shape with decision_function_shape='crammer_singer'\n    clf = svm.LinearSVC(multi_class='crammer_singer').fit(X, y)\n    assert clf.decision_function(X).shape == (len(X), len(clf.classes_))\n", "def test_base_libsvm_sparse_input():\n    # Test BaseLibSVM with sparse input.\n    X_sparse = sparse.csr_matrix(X)\n    clf = svm.SVC(kernel='linear').fit(X_sparse, Y)\n    assert_array_equal(clf.dual_coef_, [[-0.25, .25]])\n    assert_array_equal(clf.support_, [1, 3])\n    assert_array_equal(clf.intercept_, [0])\n    assert_array_equal(clf.predict(T), true_result)\n", "def test_libsvm_sparse_input():\n    # Test libsvm with sparse input\n    X_sparse = sparse.csr_matrix(X)\n    clf = svm.SVC(kernel='linear').fit(X_sparse, Y)\n    assert_array_equal(clf.predict(T), true_result)\n    assert_array_almost_equal(clf.intercept_, [0], decimal=3)\n\n    # test also the low-level API\n    model = svm.libsvm.fit(X_sparse, Y.astype(np.float64))\n    pred = svm.libsvm.predict(T, *model)\n    assert np.mean(pred == Y) > .95\n\n    # Gram matrix for test data but compute KT[i,j]\n    # for support vectors j only.\n    KT = np.zeros_like(KT)\n    for i in range(len(T)):\n        for j in clf.support_:\n            KT[i, j] = np.dot(T[i], X[j])\n\n    pred = clf.predict(KT)\n    assert_array_equal(pred, true_result)\n", "def test_oneclasssvm_unsupervised():\n    # Test OneClassSVM in unsupervised mode (novelty detection)\n    X_train = [[-1, -1], [-2, -1], [1, 1], [2, 1]]\n    clf = svm.OneClassSVM(kernel='rbf', gamma=1, nu=0.1)\n    clf.fit(X_train)\n\n    assert_array_equal(clf.predict(X_train), [1, 1, 1, 1])\n\n    X_test = [[-3, -3], [3, 3]]\n    assert_array_equal(clf.predict(X_test), [-1, -1])\n"], "sample_22": ["def test_camel_case_to_spaces(self):\n    items = [\n        ('camelCase', 'camel case'),\n        (' CamelCase', ' camel case'),\n        ('CamelCase ', 'camel case '),\n        (' camel Case', ' camel case'),\n        ('getHTTPResponseCode', 'get http response code'),\n        ('  helloWorld  ', '  hello world  '),\n    ]\n    for value, output in items:\n        self.assertEqual(text.camel_case_to_spaces(value), output)\n        self.assertEqual(text.camel_case_to_spaces(lazystr(value)), output)\n", "def test_format_lazy(self):\n    self.assertEqual(format_lazy('The answer is {}.', 42), 'The answer is 42.')\n    self.assertEqual(format_lazy('The answer is {}.', lazystr(42)), 'The answer is 42.')\n    self.assertEqual(format_lazy(lazystr('The answer is {}.'), 42), 'The answer is 42.')\n    self.assertEqual(format_lazy(lazystr('The answer is {}.'), lazystr(42)), 'The answer is 42.')\n", "def test_camel_case_to_spaces(self):\n    items = [\n        ('camelCase', 'camel case'),\n        ('CamelCase', 'camel case'),\n        ('CAMELCase', 'camel case'),\n        ('_camelCase', '_camel case'),\n        ('Camel_Case', 'camel case'),\n        ('__Camel_Case', ' camel case'),\n    ]\n    for value, output in items:\n        self.assertEqual(text.camel_case_to_spaces(value), output)\n    # lazy strings are handled correctly\n    self.assertEqual(text.camel_case_to_spaces(lazystr('camelCase')), 'camel case')\n", "def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces(\"camelCase\"), \"camel case\")\n    self.assertEqual(text.camel_case_to_spaces(\"anotherCamelCase\"), \"another camel case\")\n    self.assertEqual(text.camel_case_to_spaces(\"not_camel_case\"), \"not_camel_case\")\n    self.assertEqual(text.camel_case_to_spaces(lazystr(\"camelCase\")), \"camel case\")\n", "def test_camel_case_to_spaces(self):\n    items = [\n        ('camelCase', 'camel case'),\n        ('CamelCase', 'camel case'),\n        ('CAMELCase', 'camel case'),\n        ('_camelCase', '_camel case'),\n        ('_CamelCase', '_camel case'),\n        ('multipleWordsInCamelCase', 'multiple words in camel case'),\n    ]\n    for value, output in items:\n        self.assertEqual(text.camel_case_to_spaces(value), output)\n        self.assertEqual(text.camel_case_to_spaces(lazystr(value)), output)\n"], "sample_38": ["    def test_changed_data_contains_password(self):\n        user = User.objects.get(username='testclient')\n        data = {\n            'password1': 'test123',\n            'password2': 'test123',\n        }\n        form = AdminPasswordChangeForm(user, data)\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.changed_data, ['password'])\n", "    def test_email_normalization(self):\n        user = User.objects.create_user('testuser', 'test@example.com', 'test')\n        form = PasswordResetForm({'email': 'TeSt@ExAmPlE.cOm'})\n        self.assertTrue(form.is_valid())\n        form.save()\n        self.assertEqual(len(mail.outbox), 1)\n        self.assertEqual(mail.outbox[0].to, ['test@example.com'])\n", "    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = '!'\n        html = widget.render(name='password', value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n", "    def test_custom_form(self):\n        class CustomUserSetPasswordForm(SetPasswordForm):\n            class Meta(SetPasswordForm.Meta):\n                model = ExtensionUser\n                fields = ('new_password1', 'new_password2', 'date_of_birth')\n\n        user = User.objects.get(username='testclient')\n        data = {\n            'new_password1': 'test123',\n            'new_password2': 'test123',\n            'date_of_birth': '1988-02-24',\n        }\n        form = CustomUserSetPasswordForm(user, data)\n        self.assertTrue(form.is_valid())\n        form.save()\n        self.assertEqual(form.cleaned_data['new_password1'], 'test123')\n        self.assertEqual(form.cleaned_data['date_of_birth'], datetime.date(1988, 2, 24))\n", "    def test_get_users(self):\n        \"\"\"\n        Test that get_users returns the correct list of users for a given email.\n        \"\"\"\n        user1 = User.objects.create_user('testuser1', 'test@example.com', 'test')\n        user2 = User.objects.create_user('testuser2', 'test@example.com', 'test')\n        user3 = User.objects.create_user('testuser3', 'other@example.com', 'test')\n\n        form = PasswordResetForm({'email': 'test@example.com'})\n        self.assertTrue(form.is_valid())\n        users = form.get_users(form.cleaned_data['email'])\n        self.assertEqual(list(users), [user1, user2])\n"], "sample_34": ["    def test_field_name_clash(self):\n        class Model(models.Model):\n            field = models.CharField(max_length=10)\n            field_id = models.IntegerField()\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"Field 'field' clashes with the field 'field_id' from model \"\n                \"'check_framework.Model'.\",\n                obj=Model,\n                id='models.E005',\n            ),\n        ])\n", "    def test_default_auto_field_app_config(self):\n        class Model(models.Model):\n            pass\n\n        self.apps.get_app_config('check_framework').default_auto_field = 'django.db.models.BigAutoField'\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n", "    def test_property_related_field_accessor_clash(self):\n        class Model(models.Model):\n            related = models.ForeignKey('self', models.CASCADE)\n\n            @property\n                return self.related.id\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"The property 'related_id' clashes with a related field \"\n                \"accessor.\",\n                obj=Model,\n                id='models.E025',\n            )\n        ])\n", "    def test_id_field(self):\n        class Model(models.Model):\n            id = models.IntegerField()\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"'id' can only be used as a field name if the field also sets 'primary_key=True'.\",\n                obj=Model,\n                id='models.E004',\n            )\n        ])\n", "    def test_invalid_order_with_respect_to(self):\n        class Model(models.Model):\n            class Meta:\n                order_with_respect_to = 'nonexistent_field'\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"check_framework.Model: 'order_with_respect_to' refers to the \"\n                \"nonexistent field 'nonexistent_field'.\",\n                obj=Model,\n                id='models.E015',\n            ),\n        ])\n"], "sample_35": ["    def test_unique_fields_error_message(self):\n        # Create a model with unique fields.\n        from .models import UniqueFieldsModel\n        UniqueFieldsModel.objects.create(name='a', email='a@example.com')\n\n        # Create a form that should raise an error when trying to create a duplicate instance.\n        class DuplicateForm(ModelForm):\n            class Meta:\n                model = UniqueFieldsModel\n                fields = ('name', 'email')\n\n        f = DuplicateForm({'name': 'a', 'email': 'a@example.com'})\n\n        self.assertFalse(f.is_valid())\n\n        # Check that the correct error message is displayed for each field.\n        self.assertEqual(\n            f.errors['__all__'],\n            ['UniqueFieldsModel with this Name and Email already exists.']\n        )\n", "    def test_modelformfield_callback(self):\n        # Create choices for the model choice field tests below.\n        ChoiceModel.objects.create(pk=1, name='a')\n        ChoiceModel.objects.create(pk=2, name='b')\n        ChoiceModel.objects.create(pk=3, name='c')\n\n        class TestForm(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = ('name',)\n\n                    if db_field.name == 'name':\n                        kwargs['error_messages'] = {\n                            'required': 'CUSTOM REQUIRED',\n                            'invalid_choice': 'CUSTOM INVALID CHOICE',\n                        }\n                    return db_field.formfield(**kwargs)\n\n        f = TestForm()\n        self.assertEqual(f.fields['name'].error_messages, {\n            'required': 'CUSTOM REQUIRED',\n            'invalid_choice': 'CUSTOM INVALID CHOICE',\n        })\n", "    def test_modelform_unique_error_messages(self):\n        # Create a model form for the ChoiceModel with unique error messages.\n        from django.forms import ModelForm\n\n        class ChoiceModelForm(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = '__all__'\n                error_messages = {\n                    'name': {'unique': 'CUSTOM UNIQUE ERROR MESSAGE'},\n                }\n\n        # Create an existing choice.\n        ChoiceModel.objects.create(name='a')\n\n        # Try to create another choice with the same name.\n        f = ChoiceModelForm({'name': 'a'})\n        self.assertFormErrors(['CUSTOM UNIQUE ERROR MESSAGE'], f.clean)\n", "    def test_modelchoicefield_choices(self):\n        # Create choices for the model choice field tests below.\n        ChoiceModel.objects.create(pk=1, name='a')\n        ChoiceModel.objects.create(pk=2, name='b')\n        ChoiceModel.objects.create(pk=3, name='c')\n\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all())\n        self.assertEqual(list(f.choices), [\n            ('', '---------'),\n            (1, 'a'),\n            (2, 'b'),\n            (3, 'c'),\n        ])\n", "    def test_modelform_unique_error_messages(self):\n        class TestModel(models.Model):\n            name = models.CharField(max_length=10, unique=True)\n\n        class TestForm(forms.ModelForm):\n            class Meta:\n                model = TestModel\n                fields = '__all__'\n                error_messages = {\n                    'name': {'unique': 'CUSTOM UNIQUE ERROR MESSAGE'}\n                }\n\n        # Create a model instance to trigger the unique validation error\n        TestModel.objects.create(name='existing')\n\n        form = TestForm(data={'name': 'existing'})\n        self.assertFormErrors(['CUSTOM UNIQUE ERROR MESSAGE'], form.clean)\n"], "sample_77": ["    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n", "    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n", "def test_label_concise(self, t):\n\n    s = Temporal().label(concise=True)\n    a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n    a.set_view_interval(0, 365)\n    labels = a.major.formatter.format_ticks(a.major.locator())\n    for text in labels:\n        assert \"\\n\" not in text\n", "def test_label_concise(self, t):\n\n    s = Temporal().label(concise=True)\n    a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n    a.set_view_interval(10, 1000)\n    label, = a.major.formatter.format_ticks([100])\n    assert re.match(r\"^\\d{4}$\", label)\n", "    def test_scale_order(self):\n\n        assert Continuous._priority < Temporal._priority < Nominal._priority\n"], "sample_4": ["    def test_file_response(self):\n        with open(__file__, 'rb') as f:\n            response = FileResponse(f)\n            self.assertEqual(response.status_code, 200)\n            self.assertEqual(response['Content-Type'], 'text/x-python; charset=utf-8')\n", "    def test_utf8(self):\n        response = JsonResponse({'key': '\u0142\u00f3\u017cko'})\n        self.assertEqual(response.charset, 'utf-8')\n        self.assertEqual(response['Content-Type'], 'application/json')\n", "    def test_close(self):\n        # Make sure close() is called when HttpResponse is used as a context manager\n        class TestResponse(HttpResponse):\n            closed = False\n\n                self.closed = True\n\n        with TestResponse() as r:\n            pass\n\n        self.assertTrue(r.closed)\n", "    def test_file_response(self):\n        filename = os.path.join(os.path.dirname(__file__), 'abc.txt')\n        response = FileResponse(open(filename, 'rb'))\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response['Content-Type'], 'text/plain')\n        self.assertEqual(response['Content-Length'], str(os.path.getsize(filename)))\n", "    def test_close_called(self):\n        close_called = False\n\n        class TestHandler:\n                nonlocal close_called\n                close_called = True\n\n        response = HttpResponseBase()\n        response._handler_class = TestHandler\n        response.close()\n\n        self.assertTrue(close_called)\n"], "sample_66": ["    def test_not_callable_or_boolean(self):\n        class TestModelAdmin(ModelAdmin):\n            view_on_site = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'view_on_site' must be a callable or a boolean value.\",\n            \"admin.E025\",\n        )\n", "    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n", "    def test_actions_unique_with_inheritance(self):\n        @admin.action\n            pass\n\n        class BaseAdmin(ModelAdmin):\n            actions = (action1,)\n\n        @admin.action\n            pass\n\n        class BandAdmin(BaseAdmin):\n            actions = (action2, action1)\n\n        self.assertIsInvalid(\n            BandAdmin,\n            Band,\n            \"__name__ attributes of actions defined in BandAdmin must be \"\n            \"unique. Name 'action1' is not unique.\",\n            id=\"admin.E130\",\n        )\n", "    def test_not_boolean_or_callable(self):\n        class TestModelAdmin(ModelAdmin):\n            view_on_site = \"hello\"\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'view_on_site' must be a callable or a boolean value.\",\n            \"admin.E025\",\n        )\n", "    def test_not_callable_or_boolean(self):\n        class TestModelAdmin(ModelAdmin):\n            view_on_site = \"hello\"\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'view_on_site' must be a callable or a boolean value.\",\n            \"admin.E025\",\n        )\n"], "sample_101": ["def test_pipeline_get_params():\n    # Test that get_params returns all parameters of the estimators\n    transf = Transf()\n    mult2 = Mult(mult=2)\n    mult3 = Mult(mult=3)\n    pipeline = Pipeline([('transf', transf), ('mult2', mult2), ('mult3', mult3)])\n\n    params = pipeline.get_params(deep=True)\n    assert 'steps' in params\n    assert 'transf' in params\n    assert 'mult2' in params\n    assert 'mult3' in params\n    assert 'mult2__mult' in params\n    assert 'mult3__mult' in params\n", "def test_pipeline_get_params():\n    # Test that get_params returns all the parameters of the estimators\n    # in the pipeline.\n    mult2 = Mult(mult=2)\n    mult3 = Mult(mult=3)\n    pipeline = Pipeline([('m1', mult2), ('m2', mult3)])\n    params = pipeline.get_params()\n    assert 'm1__mult' in params\n    assert 'm2__mult' in params\n    assert params['m1__mult'] == 2\n    assert params['m2__mult'] == 3\n", "def test_pipeline_memory_none():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    clf = SVC(gamma='scale', probability=True, random_state=0)\n    transf = DummyTransf()\n    pipe = Pipeline([('transf', clone(transf)), ('svc', clf)])\n    cached_pipe = Pipeline([('transf', transf), ('svc', clf)], memory=None)\n\n    # Check that cached_pipe and pipe yield identical results\n    pipe.fit(X, y)\n    cached_pipe.fit(X, y)\n    assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n    assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n    assert_array_equal(pipe.predict_log_proba(X),\n                       cached_pipe.predict_log_proba(X))\n    assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n    assert_array_equal(pipe.named_steps['transf'].means_,\n                       cached_pipe.named_steps['transf'].means_)\n", "def test_pipeline_memory_clear():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        if LooseVersion(joblib_version) < LooseVersion('0.12'):\n            # Deal with change of API in joblib\n            memory = Memory(cachedir=cachedir, verbose=10)\n        else:\n            memory = Memory(location=cachedir, verbose=10)\n        clf = SVC(gamma='scale', probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', transf), ('svc', clf)], memory=memory)\n\n        # Memoize the transformer at the first fit\n        pipe.fit(X, y)\n        # Clear the cache\n        memory.clear(warn=False)\n        # Check that we are re-computing at the second fit\n        ts1 = pipe.named_steps['transf'].timestamp_\n        pipe.fit(X, y)\n        ts2 = pipe.named_steps['transf'].timestamp_\n        assert ts1 != ts2\n    finally:\n        shutil.rmtree(cachedir)\n", "def test_pipeline_with_none_step():\n    # Test that a pipeline with a None step raises an error when trying to fit\n    X = np.array([[1]])\n    y = np.array([1])\n    pipe = Pipeline([('step1', Mult()), ('step2', None), ('step3', FitParamT())])\n\n    assert_raises_regex(TypeError,\n                        \"All intermediate steps should be transformers \"\n                        \"and implement fit and transform or be the string \"\n                        \"'passthrough' 'NoneType' (type <class 'NoneType'>) \"\n                        \"doesn't\",\n                        pipe.fit, X, y)\n"], "sample_37": ["    def test_subquery_with_values_list(self):\n        names = Company.objects.filter(num_employees__gt=100).values_list('name', flat=True)\n        qs = Employee.objects.filter(firstname__in=Subquery(names))\n        self.assertEqual(qs.count(), 0)\n", "    def test_deconstruct(self):\n        q = Q(a=1)\n        path, args, kwargs = q.deconstruct()\n        self.assertEqual(path, 'django.db.models.Q')\n        self.assertEqual(args, (q.children,))\n        self.assertEqual(kwargs, {})\n", "    def test_combine(self):\n        q1 = Q(x=1)\n        q2 = Q(y=2)\n        combined = q1 | q2\n        self.assertEqual(combined.children, [q1, q2])\n        self.assertEqual(combined.connector, Q.OR)\n\n        combined = q1 & q2\n        self.assertEqual(combined.children, [q1, q2])\n        self.assertEqual(combined.connector, Q.AND)\n", "    def setUpTestData(cls):\n        cls.c1 = Company.objects.create(name='Example Inc.', num_employees=2300, num_chairs=5)\n        cls.c2 = Company.objects.create(name='Foobar Ltd.', num_employees=3, num_chairs=4, based_in_eu=True)\n", "    def test_repr(self):\n        q = Q(a=1) & Q(b=2)\n        self.assertEqual(repr(q), \"(AND: ('a', 1), ('b', 2))\")\n"], "sample_104": ["def test_repr_with_nan():\n    # Test that repr works correctly with NaN values\n    estimator = LogisticRegression(tol=float('nan'))\n    expected = \"LogisticRegression(tol=nan)\"\n    assert estimator.__repr__() == expected\n\n    estimator = LogisticRegression(tol=np.nan)\n    expected = \"LogisticRegression(tol=nan)\"\n    assert estimator.__repr__() == expected\n", "def test_params_dict_with_max_elements():\n    # Render a params dictionary with max elements constraint\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=5\n    )\n    vocabulary = {i: i for i in range(10)}\n    vectorizer = CountVectorizer(vocabulary=vocabulary)\n    expected = r\"\"\"", "def test_unsupported_type():\n    # Test that an unsupported type raises a TypeError\n    pp = _EstimatorPrettyPrinter(compact=True, indent=1, indent_at_name=True)\n\n    class UnsupportedType:\n        pass\n\n    unsupported = UnsupportedType()\n    with pytest.raises(TypeError):\n        pp.pformat(unsupported)\n", "def test_changed_only_with_nan():\n    # Make sure the changed_only param is correctly used with nan\n    set_config(print_changed_only=True)\n    imputer = SimpleImputer(missing_values=np.nan)\n    expected = \"\"\"SimpleImputer()\"\"\"\n    assert imputer.__repr__() == expected\n\n    imputer = SimpleImputer(missing_values=float('nan'))\n    expected = \"\"\"SimpleImputer()\"\"\"\n    assert imputer.__repr__() == expected\n\n    imputer = SimpleImputer(missing_values=0)\n    expected = \"\"\"SimpleImputer(missing_values=0)\"\"\"\n    assert imputer.__repr__() == expected\n\n    set_config(print_changed_only=False)\n", "def test_n_max_elements_to_show_zero():\n    # Test that setting n_max_elements_to_show to zero still works\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=0\n    )\n\n    vocabulary = {i: i for i in range(10)}\n    vectorizer = CountVectorizer(vocabulary=vocabulary)\n\n    expected = r\"\"\""], "sample_156": ["def test_parser_mathematica_newlines_inside_enclosures():\n    parser = MathematicaParser()\n\n    chain = lambda expr: parser._from_tokens_to_fullformlist(parser._from_mathematica_to_tokens(expr))\n\n    assert chain(\"(a \\nb)\") == [\"Times\", \"a\", \"b\"]\n    assert chain(\"{a, \\nb, c}\") == [\"List\", \"a\", \"b\", \"c\"]\n    assert chain(\"[a, \\nb, c]\") == [\"List\", \"a\", \"b\", \"c\"]\n    assert chain(\"a[b, \\nc]\") == [\"a\", \"b\", \"c\"]\n    assert chain(\"a[[b, \\nc]]\") == [\"Part\", \"a\", \"b\", \"c\"]\n", "def test_parser_mathematica_fullformsympy():\n    parser = MathematicaParser()\n\n    chain = lambda expr: parser._from_fullform_to_fullformsympy(parser._from_tokens_to_fullformlist(parser._from_mathematica_to_tokens(expr)))\n\n    # Basic patterns\n    assert chain(\"x\") == symbols(\"x\")\n    assert chain(\"42\") == 42\n    assert chain(\".2\") == 0.2\n\n    # Functions with no arguments\n    assert chain(\"Sin[]\") == Function(\"Sin\")()\n    assert chain(\"Cos[]\") == Function(\"Cos\")()\n\n    # Functions with one argument\n    assert chain(\"Sin[x]\") == sin(symbols(\"x\"))\n    assert chain(\"Cos[y]\") == cos(symbols(\"y\"))\n\n    # Functions with two arguments\n    assert chain(\"Mod[5,3]\") == Mod(5,3)\n    assert chain(\"Max[1,-2,3,-4]\") == Max(1,-2,3,-4)\n\n    # Functions with variable number of arguments\n    assert chain(\"Plus[a,b,c]\") == symbols(\"a\") + symbols(\"b\") + symbols(\"c\")\n    assert chain(\"Times[a,b,c,d]\") == symbols(\"a\") * symbols(\"b\") * symbols(\"c\") * symbols(\"d\")\n\n    # FullForm expressions\n    assert chain(\"Power[a, b]\") == symbols(\"a\") ** symbols(\"b\")\n    assert chain(\"List[a, b, c]\") == (symbols(\"a\"), symbols(\"b\"), symbols(\"c\"))\n    assert chain(\"Lambda[{x, y}, x^2 + y^2]\") == Lambda((symbols(\"x\"), symbols(\"y\")), symbols(\"x\")**2 + symbols(\"y\")**2)\n", "def test_parser_mathematica_from_fullformlist_to_sympy():\n    parser = MathematicaParser()\n    converter = parser._from_fullformlist_to_sympy\n\n    # Basic atoms\n    assert converter(\"x\") == symbols(\"x\")\n    assert converter(42) == 42\n    assert converter(3.14) == 3.14\n\n    # Basic operations\n    assert converter([\"Plus\", \"a\", \"b\"]) == symbols(\"a\") + symbols(\"b\")\n    assert converter([\"Times\", \"a\", \"b\"]) == symbols(\"a\") * symbols(\"b\")\n    assert converter([\"Power\", \"a\", \"b\"]) == symbols(\"a\") ** symbols(\"b\")\n\n    # FullForm expressions\n    assert converter([\"Sin\", \"x\"]) == sin(symbols(\"x\"))\n    assert converter([\"Cos\", \"x\"]) == cos(symbols(\"x\"))\n\n    # Nested expressions\n    assert converter([\"Plus\", [\"Sin\", \"x\"], [\"Cos\", \"y\"]]) == sin(symbols(\"x\")) + cos(symbols(\"y\"))\n    assert converter([\"Times\", [\"Power\", \"a\", \"b\"], [\"Sin\", \"x\"]]) == (symbols(\"a\") ** symbols(\"b\")) * sin(symbols(\"x\"))\n\n    # Complex expressions\n    assert converter([\"Plus\", [\"Times\", \"a\", [\"Power\", \"b\", \"c\"]], [\"Sin\", [\"Times\", \"d\", \"e\"]]]) == symbols(\"a\") * (symbols(\"b\") ** symbols(\"c\")) + sin(symbols(\"d\") * symbols(\"e\"))\n", "def test_parser_mathematica_from_fullformlist_to_sympy():\n    parser = MathematicaParser()\n\n    # Test cases for _from_fullformlist_to_sympy function\n    assert parser._from_fullformlist_to_sympy(\"x\") == symbols(\"x\")\n    assert parser._from_fullformlist_to_sympy([\"Plus\", \"a\", \"b\"]) == symbols(\"a\") + symbols(\"b\")\n    assert parser._from_fullformlist_to_sympy([\"Times\", \"a\", \"b\"]) == symbols(\"a\") * symbols(\"b\")\n    assert parser._from_fullformlist_to_sympy([\"Power\", \"a\", \"b\"]) == symbols(\"a\") ** symbols(\"b\")\n    assert parser._from_fullformlist_to_sympy([\"List\", \"a\", \"b\", \"c\"]) == (symbols(\"a\"), symbols(\"b\"), symbols(\"c\"))\n\n    # Test cases for more complex expressions\n    assert parser._from_fullformlist_to_sympy([\"Plus\", [\"Times\", \"a\", \"b\"], \"c\"]) == symbols(\"a\") * symbols(\"b\") + symbols(\"c\")\n    assert parser._from_fullformlist_to_sympy([\"Times\", [\"Power\", \"a\", \"b\"], \"c\"]) == (symbols(\"a\") ** symbols(\"b\")) * symbols(\"c\")\n    assert parser._from_fullformlist_to_sympy([\"List\", [\"Plus\", \"a\", \"b\"], [\"Times\", \"c\", \"d\"]]) == ((symbols(\"a\") + symbols(\"b\")), (symbols(\"c\") * symbols(\"d\")))\n", "def test_mathematica_parser_atan2():\n    assert parse_mathematica(\"ArcTan[x, y]\") == atan2(y, x)\n    assert parse_mathematica(\"ArcTan[3, 4]\") == atan2(4, 3)\n    assert parse_mathematica(\"ArcTan[-1, 1]\") == atan2(1, -1)\n"], "sample_30": ["    def test_get_extra(self):\n        class MyInline(TabularInline):\n            model = Inner\n\n                return 2\n\n        modeladmin = ModelAdmin(Holder, admin_site)\n        modeladmin.inlines = [MyInline]\n        request = self.factory.get(reverse('admin:admin_inlines_holder_add'))\n        request.user = self.superuser\n        response = modeladmin.changeform_view(request)\n        total_forms = (\n            '<input id=\"id_inner_set-TOTAL_FORMS\" '\n            'name=\"inner_set-TOTAL_FORMS\" type=\"hidden\" value=\"2\">'\n        )\n        self.assertInHTML(total_forms, response.rendered_content)\n", "    def setUp(self):\n        self.user = User.objects.create_user('testing', password='password', is_staff=True)\n        self.user.user_permissions.add(\n            Permission.objects.get(codename='change_holder5', content_type=ContentType.objects.get_for_model(Holder5))\n        )\n        self.holder5 = Holder5.objects.create(dummy=1)\n", "    def setUp(self):\n        self.client.force_login(self.superuser)\n", "    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', email='super@example.com', password='secret')\n", "def test_get_inline_formsets_with_no_model_permissions(self):\n    modeladmin = ModelAdmin(BinaryTree, admin_site)\n    obj = BinaryTree.objects.create(name=\"Tree Head\")\n    request = self.factory.get(reverse('admin:admin_inlines_binarytree_change', args=(obj.id,)))\n    request.user = User(username='super', is_superuser=False)\n    inline_instances = [\n        InlineModelAdmin(modeladmin.model, admin_site),\n        InlineModelAdmin(modeladmin.model, admin_site),\n    ]\n    formsets, inlines = modeladmin._get_formsets_and_inlines(request, obj, inline_instances=inline_instances)\n    self.assertEqual(formsets, [])\n    self.assertEqual(inlines, [])\n"], "sample_132": ["def test_closest_points():\n    points = [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5)]\n    assert closest_points(*points) == {(Point2D(1, 1), Point2D(2, 2))}\n    points = [(0, 0), (1, 1), (3, 3), (4, 4), (5, 5)]\n    assert closest_points(*points) == {(Point2D(0, 0), Point2D(1, 1))}\n    points = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4)]\n    assert closest_points(*points) == {(Point2D(1, 1), Point2D(1, 2))}\n", "def test_closest_points():\n    p1, p2, p3 = Point(0, 0), Point(1, 1), Point(3, 4)\n    assert closest_points(p1, p2, p3) == {(p1, p2)}\n    p4, p5 = Point(1, 0), Point(0, 1)\n    assert closest_points(p1, p2, p4, p5) == {(p1, p4), (p1, p5)}\n    assert closest_points(p1, p2, p3, p4, p5) == {(p1, p4), (p1, p5)}\n", "def test_closest_points():\n    p1, p2, p3 = Point(0, 0), Point(1, 1), Point(-1, -1)\n    assert closest_points(p1, p2, p3) == {(p1, p2), (p1, p3)}\n    p4, p5 = Point(1, 0), Point(0, 1)\n    assert closest_points(p1, p2, p4, p5) == {(p1, p4), (p1, p5)}\n", "def test_closest_points():\n    points = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4)]\n    assert closest_points(*points) == {(Point2D(1, 1), Point2D(1, 2))}\n    assert closest_points(Point(0, 0), Point(1, 1)) == {(Point2D(0, 0), Point2D(1, 1))}\n    raises(ValueError, lambda: closest_points(Point(0, 0)))\n", "def test_closest_points():\n    p1, p2, p3 = Point2D(0, 0), Point2D(1, 1), Point2D(3, 3)\n    assert closest_points(p1, p2, p3) == {(p1, p2)}\n    p4 = Point2D(1, 0)\n    assert closest_points(p1, p2, p3, p4) == {(p1, p4)}\n"], "sample_48": ["def test_reduce_references_model(self):\n    operation = FieldOperation('Model', 'field', models.ForeignKey('Other', models.CASCADE))\n    # Model name match.\n    self.assertIs(operation.reduce(FieldOperation('mOdEl', 'field', models.BooleanField(default=False)), None), False)\n    # Referenced field.\n    self.assertIs(operation.reduce(FieldOperation('Other', 'field', models.BooleanField(default=False)), None), False)\n    # Doesn't reference.\n    self.assertIs(operation.reduce(FieldOperation('Whatever', 'field', models.BooleanField(default=False)), None), True)\n", "def test_reduce_create_model_add_field(self):\n    project_state = self.set_up_test_model(\"test_crmo\")\n    operation = migrations.CreateModel(\n        \"Pony\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"pink\", models.IntegerField(default=1)),\n        ],\n    )\n    add_operation = migrations.AddField(\n        \"Pony\",\n        \"height\",\n        models.FloatField(null=True, default=5),\n    )\n    reduced_operation = operation.reduce(add_operation, 'test_crmo')\n    self.assertEqual(len(reduced_operation), 1)\n    self.assertIsInstance(reduced_operation[0], migrations.CreateModel)\n    self.assertEqual(\n        reduced_operation[0].fields,\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"pink\", models.IntegerField(default=1)),\n            (\"height\", models.FloatField(null=True, default=5)),\n        ],\n    )\n", "def test_reduce_create_model_with_indexes(self):\n    operation = migrations.CreateModel(\n        name='model',\n        fields=[\n            ('id', models.AutoField(primary_key=True)),\n            ('field', models.IntegerField()),\n        ],\n        options={\n            'indexes': [\n                models.Index(fields=['field'], name='my_name_idx'),\n                models.Index(fields=['-field'], name='my_name2_idx'),\n            ]\n        },\n    )\n    new_operation = operation.reduce(operation, app_label=None)\n    self.assertEqual(new_operation[0].__class__.__name__, 'CreateModel')\n    self.assertEqual(len(new_operation), 3)\n    self.assertEqual(new_operation[1].__class__.__name__, 'AddIndex')\n    self.assertEqual(new_operation[2].__class__.__name__, 'AddIndex')\n", "def test_alter_field_check_constraint(self):\n    \"\"\"\n    AlterField adds a new check constraint when changing the field type.\n    \"\"\"\n    app_label = 'test_alterfield_checkconstraint'\n    project_state = self.set_up_test_model(app_label)\n    operation = migrations.AlterField('Pony', 'pink', models.IntegerField(null=True))\n    new_state = project_state.clone()\n    operation.state_forwards(app_label, new_state)\n    with connection.schema_editor() as editor:\n        operation.database_forwards(app_label, editor, project_state, new_state)\n    Pony = new_state.apps.get_model(app_label, 'Pony')\n    Pony.objects.create(pink=1)\n    Pony.objects.create(pink=None).delete()\n    if connection.features.supports_table_check_constraints:\n        with self.assertRaises(IntegrityError), transaction.atomic():\n            Pony.objects.create(pink='hello')\n    else:\n        Pony.objects.create(pink='hello').delete()\n    # Reversal.\n    with connection.schema_editor() as editor:\n        operation.database_backwards(app_label, editor, new_state, project_state)\n    Pony.objects.create(pink='hello').delete()\n", "def test_rename_field_with_index(self):\n    project_state = self.set_up_test_model(\"test_rnflwi\", index=True)\n    self.assertIndexExists(\"test_rnflwi_pony\", [\"pink\"])\n    operation = migrations.RenameField(\"Pony\", \"pink\", \"blue\")\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_rnflwi\", new_state)\n    with connection.schema_editor() as editor:\n        operation.database_forwards(\"test_rnflwi\", editor, project_state, new_state)\n    self.assertIndexNotExists(\"test_rnflwi_pony\", [\"pink\"])\n    self.assertIndexExists(\"test_rnflwi_pony\", [\"blue\"])\n    with connection.schema_editor() as editor:\n        operation.database_backwards(\"test_rnflwi\", editor, new_state, project_state)\n    self.assertIndexNotExists(\"test_rnflwi_pony\", [\"blue\"])\n    self.assertIndexExists(\"test_rnflwi_pony\", [\"pink\"])\n"], "sample_124": ["def test_real_imag():\n    x = Symbol('x')\n    assert sinh(x).as_real_imag() == (sinh(x), 0)\n    assert cosh(x).as_real_imag() == (cosh(x), 0)\n    assert tanh(x).as_real_imag() == (tanh(x), 0)\n    assert coth(x).as_real_imag() == (coth(x), 0)\n    assert sech(x).as_real_imag() == (sech(x), 0)\n    assert csch(x).as_real_imag() == (csch(x), 0)\n\n    y = Symbol('y')\n    assert sinh(x + I*y).as_real_imag() == (sinh(x)*cos(y), cosh(x)*sin(y))\n    assert cosh(x + I*y).as_real_imag() == (cosh(x)*cos(y), sinh(x)*sin(y))\n    assert tanh(x + I*y).as_real_imag() == \\\n        (sinh(2*x)/(cosh(2*x) + cos(2*y)), sin(2*y)/(cosh(2*x) + cos(2*y)))\n    assert coth(x + I*y).as_real_imag() == \\\n        (sinh(2*x)/(cosh(2*x) - cos(2*y)), -sin(2*y)/(cosh(2*x) - cos(2*y)))\n    assert sech(x + I*y).as_real_imag() == \\\n        (cosh(x)*cos(y)/(cosh(2*x) + cos(2*y)/2 + 1),\n         -sinh(x)*sin(y)/(cosh(2*x) + cos(2*y)/2 + 1))\n    assert csch(x + I*y).as_real_imag() == \\\n        (sinh(x)*cos(y)/(cosh(2*x) - cos(2*y)/2 - 1),\n         cosh(x)*sin(y)/(cosh(2*x) - cos(2*y)/2 - 1))\n", "def test_is_real():\n    x = Symbol('x')\n    assert sinh(x).is_real == None\n    assert cosh(x).is_real == None\n    assert tanh(x).is_real == None\n    assert coth(x).is_real == None\n    assert sech(x).is_real == None\n    assert csch(x).is_real == None\n\n    assert asinh(x).is_real == None\n    assert acosh(x).is_real == None\n    assert atanh(x).is_real == None\n    assert acoth(x).is_real == None\n    assert asech(x).is_real == None\n    assert acsch(x).is_real == None\n\n    assert sinh(1).is_real == True\n    assert cosh(1).is_real == True\n    assert tanh(1).is_real == True\n    assert coth(1).is_real == True\n    assert sech(1).is_real == True\n    assert csch(1).is_real == True\n\n    assert asinh(1).is_real == True\n    assert acosh(2).is_real == True\n    assert atanh(0.5).is_real == True\n    assert acoth(2).is_real == True\n    assert asech(0.5).is_real == True\n    assert acsch(1).is_real == True\n", "def test_csch_is_real():\n    x = Symbol('x')\n    assert csch(x).is_real is None\n    assert csch(1).is_real is True\n    assert csch(I).is_real is False\n    assert csch(0).is_real is False\n", "def test_asech_is_real():\n    x = Symbol('x')\n    assert asech(x).is_real == None\n    assert asech(1.5).is_real == True\n    assert asech(-1.5).is_real == False\n", "def test_is_real():\n    x = Symbol('x')\n    assert sinh(x).is_real is None\n    assert cosh(x).is_real is None\n    assert tanh(x).is_real is None\n    assert coth(x).is_real is None\n    assert sech(x).is_real is None\n    assert csch(x).is_real is None\n\n    assert asinh(x).is_real is None\n    assert acosh(x).is_real is None\n    assert atanh(x).is_real is None\n    assert acoth(x).is_real is None\n    assert asech(x).is_real is None\n    assert acsch(x).is_real is None\n\n    x = Symbol('x', real=True)\n    assert sinh(x).is_real is True\n    assert cosh(x).is_real is True\n    assert tanh(x).is_real is True\n    assert coth(x).is_real is True\n    assert sech(x).is_real is True\n    assert csch(x).is_real is True\n\n    assert asinh(x).is_real is True\n    assert acosh(x).is_real is None\n    assert atanh(x).is_real is None\n    assert acoth(x).is_real is None\n    assert asech(x).is_real is None\n    assert acsch(x).is_real is None\n\n    x = Symbol('x', imaginary=True)\n    assert sinh(x).is_real is True\n    assert cosh(x).is_real is True\n    assert tanh(x).is_real is True\n    assert coth(x).is_real is True\n    assert sech(x).is_real is True\n    assert csch(x).is_real is True\n\n    assert asinh(x).is_real is False\n    assert acosh(x).is_real is False\n    assert atanh(x).is_real is False\n    assert acoth(x).is_real is False\n    assert asech(x).is_real is False\n    assert acsch(x).is_real is False\n"], "sample_0": ["def test_format_value(self):\n    beatles = Band.objects.create(name='The Beatles', style='rock')\n    form = AlbumForm(initial={'band': beatles.pk})\n    value = form['band'].field.widget.format_value(beatles.pk)\n    self.assertEqual(value, str(beatles.pk))\n", "def test_localization(self):\n    translation.activate('de')\n    form = AlbumForm()\n    output = form.as_table()\n    self.assertIn('data-placeholder', output)\n    translation.deactivate()\n", "def test_format_value(self):\n    beatles = Band.objects.create(name='The Beatles', style='rock')\n    who = Band.objects.create(name='The Who', style='rock')\n    form = AlbumForm(initial={'band': beatles.pk, 'featuring': [beatles.pk, who.pk]})\n    self.assertEqual(form['band'].value(), beatles.pk)\n    self.assertEqual(form['featuring'].value(), [beatles.pk, who.pk])\n", "def test_build_attrs_with_custom_placeholder(self):\n    form = AlbumForm()\n    attrs = form['band'].field.widget.get_context(name='my_field', value=None, attrs={'data-placeholder': 'Custom placeholder'})['widget']['attrs']\n    self.assertEqual(attrs['data-placeholder'], 'Custom placeholder')\n", "def test_value_from_datadict(self):\n    beatles = Band.objects.create(name='The Beatles', style='rock')\n    who = Band.objects.create(name='The Who', style='rock')\n    form = AlbumForm()\n    data = {'band': str(beatles.pk), 'featuring': [str(beatles.pk), str(who.pk)]}\n    self.assertEqual(form['band'].value_from_datadict(data, {}, 'band'), str(beatles.pk))\n    self.assertEqual(form['featuring'].value_from_datadict(data, {}, 'featuring'), [str(beatles.pk), str(who.pk)])\n"], "sample_129": ["def test_latex_PolyElement_fold_short_frac():\n    Ruv, u,v = ring(\"u,v\", ZZ)\n    Rxyz, x,y,z = ring(\"x,y,z\", Ruv)\n\n    assert latex((u**2 + 3*u*v + 1)*x**2*y + u + 1, fold_short_frac=True) == r\"\\left({u}^{2} + 3 u v + 1\\right) {x}^{2} y + u + 1\"\n    assert latex((u**2 + 3*u*v + 1)*x**2*y + (u + 1)*x, fold_short_frac=True) == r\"\\left({u}^{2} + 3 u v + 1\\right) {x}^{2} y + \\left(u + 1\\right) x\"\n    assert latex((u**2 + 3*u*v + 1)*x**2*y + (u + 1)*x + 1, fold_short_frac=True) == r\"\\left({u}^{2} + 3 u v + 1\\right) {x}^{2} y + \\left(u + 1\\right) x + 1\"\n    assert latex((-u**2 + 3*u*v - 1)*x**2*y - (u + 1)*x - 1, fold_short_frac=True) == r\"-\\left({u}^{2} - 3 u v + 1\\right) {x}^{2} y - \\left(u + 1\\right) x - 1\"\n", "def test_issue_15344():\n    from sympy import Abs, ComplexRootOf, DiracComb, EulerGamma, Heaviside, IdentityFunction, Integers, KroneckerDelta, Limit, Poly, Product, Rationals, Reals, UnevaluatedExpr\n    assert latex(Abs) == r\"\\left|{\\,}\\right|\"\n    assert latex(ComplexRootOf) == r\"CRootOf\"\n    assert latex(DiracComb) == r\"\\operatorname{DiracComb}\"\n    assert latex(EulerGamma) == r\"\\gamma\"\n    assert latex(Heaviside) == r\"H\"\n    assert latex(IdentityFunction) == r\"I\"\n    assert latex(Integers) == r\"\\mathbb{Z}\"\n    assert latex(KroneckerDelta) == r\"\\delta\"\n    assert latex(Limit) == r\"\\lim\"\n    assert latex(Poly) == r\"\\operatorname{Poly}\"\n    assert latex(Product) == r\"\\operatorname{prod}\"\n    assert latex(Rationals) == r\"\\mathbb{Q}\"\n    assert latex(Reals) == r\"\\mathbb{R}\"\n    assert latex(UnevaluatedExpr) == r\"\\operatorname{UnevaluatedExpr}\"\n", "def test_issue_17174():\n    from sympy import Quaternion\n    q = Quaternion(x, y, z, t)\n    assert latex(q.conjugate()) == \"x - y i - z j - t k\"\n    assert latex(q.norm()) == r\"\\sqrt{x^{2} + y^{2} + z^{2} + t^{2}}\"\n", "def test_LieDerivative():\n    from sympy.diffgeom import LieDerivative\n    from sympy.diffgeom.rn import R2_p, R2_r, x, y\n    from sympy.diffgeom import TensorProduct as TP\n    T = TP(R2_p.dx, R2_p.dx)\n    v1 = R2_r.e_x\n    v2 = R2_r.e_y\n    assert latex(LieDerivative(v1, v2)) == r\"\\left[v_{x},  v_{y}\\right]\"\n    assert latex(LieDerivative(v1, T)) == \\\n        r\"\\mathcal{L}_{v_{x}} dx \\otimes dx\"\n", "def test_latex_PolyElement_modified():\n    Ruv, u,v = ring(\"u,v\", ZZ)\n    Rxyz, x,y,z = ring(\"x,y,z\", Ruv)\n    \n    # Create a poly with a different variable ordering\n    poly = PolyElement([1, 2, 3], x*y, x*z, domain=Ruv)\n    assert latex(poly) == r\"\\left({u}^{2} + 3 u v + 1\\right) {x}^{2} y + u + 1\"\n"], "sample_145": ["def test_latex_transfer_function():\n    s = symbols('s')\n    G = TransferFunction(s, s**2 + 3*s + 2, s)\n    assert latex(G) == r\"\\frac{s}{s^{2} + 3 s + 2}\"\n    assert latex(G.simplify()) == r\"\\frac{s}{\\left(s + 1\\right) \\left(s + 2\\right)}\"\n", "compilation error", "def test_partialderivative():\n    assert latex(PartialDerivative(x**3, x)) == r\"\\frac{\\partial}{\\partial x} x^{3}\"\n    assert latex(PartialDerivative(x**3, x, 2)) == r\"\\frac{\\partial^{2}}{\\partial x^{2}} x^{3}\"\n    assert latex(PartialDerivative(sin(x*y), x, 2, y)) == \\\n        r\"\\frac{\\partial^{3}}{\\partial x^{2} \\partial y} \\sin{\\left(x y \\right)}\"\n    assert latex(PartialDerivative(sin(x*y), x, 2, y, 2)) == \\\n        r\"\\frac{\\partial^{4}}{\\partial x^{2} \\partial y^{2}} \\sin{\\left(x y \\right)}\"\n    assert latex(PartialDerivative(sin(x*y), x, y, 2)) == \\\n        r\"\\frac{\\partial^{3}}{\\partial x \\partial y^{2}} \\sin{\\left(x y \\right)}\"\n    assert latex(PartialDerivative(sin(x*y), x, y, 2, x)) == \\\n        r\"\\frac{\\partial^{4}}{\\partial x^{2} \\partial y^{2}} \\sin{\\left(x y \\right)}\"\n    assert latex(PartialDerivative(x, x, y)) == \\\n        r\"{{\\left(0\\right)}}_{,x y}\"\n    assert latex(PartialDerivative(x, x, 2, y, 2)) == \\\n        r\"{{\\left(0\\right)}}_{,x x y y}\"\n", "def test_decimal_separator_in_Tuple():\n    assert latex(Tuple(1.1, 2.2, 3.3), decimal_separator='comma') == r'\\left( 1{,}1; \\  2{,}2; \\  3{,}3\\right)'\n", "def test_LatexPrinter_defaults():\n    printer = LatexPrinter()\n    assert printer._settings['order'] is None\n"], "sample_53": ["def test_add_many_to_many_with_through_model(self):\n    \"\"\"\n    Adding a ManyToManyField with a through model should not prompt for a default.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_empty, self.publisher],\n        [self.author_with_m2m_through, self.publisher, self.contract],\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(\n        changes,\n        \"testapp\",\n        0,\n        [\"CreateModel\", \"CreateModel\", \"AddField\"],\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 2, name=\"publishers\", model_name=\"author\"\n    )\n", "def test_alter_model_options_with_custom_permissions(self):\n    author = ModelState(\n        \"testapp\",\n        \"Author\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n        ],\n        {\n            \"permissions\": [\n                (\"can_view_author\", \"Can view author\"),\n            ],\n        },\n    )\n    changes = self.get_changes(\n        [self.author_empty], [author]\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n    self.assertOperationAttributes(\n        changes,\n        \"testapp\",\n        0,\n        0,\n        options={\n            \"permissions\": [\n                (\"can_view_author\", \"Can view author\"),\n            ],\n        },\n    )\n", "def test_add_custom_m2m_with_hardcoded_through(self):\n    class HardcodedManyToManyField(models.ManyToManyField):\n            kwargs[\"through\"] = \"testapp.Membership\"\n            super().__init__(*args, **kwargs)\n\n            name, path, args, kwargs = super().deconstruct()\n            del kwargs[\"through\"]\n            return name, path, args, kwargs\n\n    person_hardcoded_through = ModelState(\n        \"testapp\",\n        \"Person\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\n                \"groups\",\n                HardcodedManyToManyField(\"testapp.Group\"),\n            ),\n        ],\n    )\n    group = ModelState(\n        \"testapp\",\n        \"Group\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n        ],\n    )\n    membership = ModelState(\n        \"testapp\",\n        \"Membership\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"person\", models.ForeignKey(\"testapp.Person\", models.CASCADE)),\n            (\"group\", models.ForeignKey(\"testapp.Group\", models.CASCADE)),\n        ],\n    )\n    changes = self.get_changes(\n        [],\n        [person_hardcoded_through, group, membership],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(\n        changes,\n        \"testapp\",\n        0,\n        [\"CreateModel\", \"CreateModel\", \"CreateModel\", \"AddField\"],\n    )\n    self.assertOperationAttributes(changes, \"testapp\", 0, 3, name=\"groups\")\n", "def test_alter_model_table_on_subclass(self):\n    \"\"\"\n    Altering model table on a subclass without specifying the parent link fields\n    should not result in an error.\n    \"\"\"\n    before = [\n        ModelState(\n            \"app\",\n            \"Base\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n            ],\n        ),\n        ModelState(\n            \"app\",\n            \"Subclass\",\n            [],\n            bases=(\"app.Base\",),\n        ),\n    ]\n    after = [\n        ModelState(\n            \"app\",\n            \"Base\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n            ],\n        ),\n        ModelState(\n            \"app\",\n            \"Subclass\",\n            [],\n            bases=(\"app.Base\",),\n            options={\"db_table\": \"new_table_name\"},\n        ),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, \"app\", 1)\n    self.assertOperationTypes(changes, \"app\", 0, [\"AlterModelTable\"])\n    self.assertOperationAttributes(\n        changes, \"app\", 0, 0, name=\"subclass\", table=\"new_table_name\"\n    )\n", "def test_check_dependency(self):\n    operation = migrations.CreateModel(\"Person\", fields=[])\n    self.assertTrue(\n        MigrationAutodetector.check_dependency(\n            operation, (\"testapp\", \"Person\", None, True)\n        )\n    )\n    self.assertFalse(\n        MigrationAutodetector.check_dependency(\n            operation, (\"testapp\", \"Animal\", None, True)\n        )\n    )\n    self.assertFalse(\n        MigrationAutodetector.check_dependency(\n            operation, (\"testapp\", \"Person\", None, False)\n        )\n    )\n    operation = migrations.DeleteModel(\"Person\")\n    self.assertTrue(\n        MigrationAutodetector.check_dependency(\n            operation, (\"testapp\", \"Person\", None, False)\n        )\n    )\n    self.assertFalse(\n        MigrationAutodetector.check_dependency(\n            operation, (\"testapp\", \"Animal\", None, False)\n        )\n    )\n    self.assertFalse(\n        MigrationAutodetector.check_dependency(\n            operation, (\"testapp\", \"Person\", None, True)\n        )\n    )\n"], "sample_123": ["def test_rational_as_coeff_Mul():\n    # a -> c*t\n    assert Rational(3, 4).as_coeff_Mul()[0] == Rational(3, 4)\n    assert Rational(3, 4).as_coeff_Mul()[1] == S.One\n\n    # coverage of the \"_nonzero\" condition in Rational.as_coeff_Mul\n    assert Rational(0).as_coeff_Mul()[0] == S.One\n    assert Rational(0).as_coeff_Mul()[1] == S.Zero\n", "def test_divmod_with_nonzero_finite_Floats():\n    a, b = Float(11.0), Float(4.0)\n    assert divmod(a, b) == (2, 3.0)\n    assert divmod(-a, b) == (-3, 1.0)\n    assert divmod(a, -b) == (-3, -1.0)\n    assert divmod(-a, -b) == (2, -3.0)\n    assert divmod(a, b**2) == (0, 11.0)\n    assert divmod(-a, b**2) == (-1, 5.0)\n    assert divmod(a, -(b**2)) == (-1, -5.0)\n    assert divmod(-a, -(b**2)) == (0, -11.0)\n", "def test_issue_12345():\n    assert Float('.nan', 15).is_nan is True\n    assert Float('nan', 15).is_nan is True\n    assert Float(0.0, 15).is_nan is False\n    assert Float(1.0, 15).is_nan is False\n    assert Float('inf', 15).is_nan is False\n    assert Float('-inf', 15).is_nan is False\n", "def test_Float_eq_precision():\n    # Float('1.0', 3) == Float('1.0', 4) is False.\n    # However, Float('1.0', 3) == 1 and 1 == Float('1.0', 3) is True.\n    assert Float('1.0', 3) != Float('1.0', 4)\n    assert Float('1.0', 3) == 1\n    assert 1 == Float('1.0', 3)\n    assert Float('1.0', 3) != 1.0\n    assert 1.0 != Float('1.0', 3)\n", "def test_Float_rounding():\n    # all values here are chosen to avoid any potential rounding differences\n    # between systems\n    assert Float('1.0', 3) == 1.0\n    assert Float('1.1', 3) == 1.1\n    assert Float('1.12', 3) == 1.12\n    assert Float('1.13', 3) == 1.13\n    assert Float('1.125', 3) == 1.12\n    assert Float('1.1251', 3) == 1.13\n    assert Float('1.124', 3) == 1.12\n    assert Float('1.3', 3) == 1.3\n    assert Float('1.34', 3) == 1.34\n"], "sample_143": ["def test_pretty_complex_conjugate():\n    from sympy import conjugate\n    assert pretty(conjugate(x)) == '_\\nx'\n    assert upretty(conjugate(x)) == '_\\nx'\n    assert pretty(conjugate(x + I)) == '  _     _\\n1 + x - I'\n    assert upretty(conjugate(x + I)) == '  _     _\\n1 + x - \u2148'\n", "def test_pretty_mod_inverse():\n    x = symbols('x')\n    mod = symbols('mod', positive=True)\n    assert pretty(ModularInverse(x, mod)) == 'modular_inverse(x, mod)'\n    assert upretty(ModularInverse(x, mod)) == 'x\u207b\u00b9 mod mod'\n    assert pretty(ModularInverse(x, 5)) == 'modular_inverse(x, 5)'\n    assert upretty(ModularInverse(x, 5)) == 'x\u207b\u00b9 mod 5'\n", "def test_pretty_GeometryEntity():\n    from sympy.geometry import (Point, Ellipse, Polygon, RegularPolygon,\n        Triangle, Point3D, Line3D, Plane, Ray3D)\n    p = Point(0, 0)\n    assert pretty(p) == 'Point2D(0, 0)'\n    assert pretty(Point(1, 2)) == 'Point2D(1, 2)'\n    assert upretty(p) == 'Point2D(0, 0)'\n    assert upretty(Point(1, 2)) == 'Point2D(1, 2)'\n    e = Ellipse(p, 3, 2)\n    assert pretty(e) == 'Ellipse(Point2D(0, 0), 3, 2)'\n    assert upretty(e) == 'Ellipse(Point2D(0, 0), 3, 2)'\n    poly = Polygon((0,0), (1,2), (5,0))\n    assert pretty(poly) == 'Polygon(Point2D(0, 0), Point2D(1, 2), Point2D(5, 0))'\n    assert upretty(poly) == 'Polygon(Point2D(0, 0), Point2D(1, 2), Point2D(5, 0))'\n    poly = RegularPolygon(p, 3, 4)\n    assert pretty(poly) == 'RegularPolygon(Point2D(0, 0), 4, 3)'\n    assert upretty(poly) == 'RegularPolygon(Point2D(0, 0), 4, 3)'\n    t = Triangle(p, Point(2,1), Point(3,1))\n    assert pretty(t) == 'Triangle(Point2D(0, 0), Point2D(2, 1), Point2D(3, 1))'\n    assert upretty(t) == 'Triangle(Point2D(0, 0), Point2D(2, 1), Point2D(3, 1))'\n    p = Point3D(0, 0, 0)\n    assert pretty(p) == 'Point3D(0, 0, 0)'\n    assert pretty(Point3D(1, 2, 3)) == 'Point3D(1, 2, 3)'\n    assert upretty(p) == 'Point3D(", "def test_pretty_units_temperature():\n    from sympy.physics.units import degree_Celsius, kelvin, degree_Rankine, degree_Fahrenheit\n\n    assert pretty(25 * degree_Celsius) == '25\u00b0C'\n    assert pretty(25 * degree_Fahrenheit) == '25\u00b0F'\n    assert pretty(25 * degree_Rankine) == '25\u00b0R'\n    assert pretty(25 * kelvin) == '25 K'\n\n    assert upretty(25 * degree_Celsius) == '25\u00b0C'\n    assert upretty(25 * degree_Fahrenheit) == '25\u00b0F'\n    assert upretty(25 * degree_Rankine) == '25\u00b0R'\n    assert upretty(25 * kelvin) == '25 K'\n", "def test_pretty_LatticeOp():\n    from sympy import LatticeOp, meet, join\n    from sympy.abc import x, y\n    meet_op = LatticeOp(LatticeOp.MEET, \"meet\")\n    join_op = LatticeOp(LatticeOp.JOIN, \"join\")\n    meet_xy = meet(x, y, evaluate=False)\n    join_xy = join(x, y, evaluate=False)\n    assert pretty(meet_xy) == \"meet(x, y)\"\n    assert upretty(meet_xy) == \"x.meet(y)\"\n    assert pretty(join_xy) == \"join(x, y)\"\n    assert upretty(join_xy) == \"x.join(y)\"\n    assert pretty(meet_op(x, y)) == \"meet(x, y)\"\n    assert upretty(meet_op(x, y)) == \"x.meet(y)\"\n    assert pretty(join_op(x, y)) == \"join(x, y)\"\n    assert upretty(join_op(x, y)) == \"x.join(y)\"\n"], "sample_52": ["def test_references_field_by_db_constraint(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.ForeignKey(\"Other\", models.CASCADE, db_constraint=False),\n    )\n    self.assertIs(\n        operation.references_field(\"Other\", \"whatever\", \"migrations\"), False\n    )\n", "def test_references_field_by_expression(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.CheckConstraint(check=models.Q(field=models.F(\"other_field\"))),\n    )\n    self.assertIs(operation.references_field(\"Model\", \"other_field\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Model\", \"field\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Model\", \"whatever\", \"migrations\"), False)\n    self.assertIs(operation.references_field(\"Other\", \"whatever\", \"migrations\"), False)\n", "def test_reduce_references_model(self):\n    operation = FieldOperation(\n        \"Model\", \"field\", models.ForeignKey(\"Other\", models.CASCADE)\n    )\n    other_operation = FieldOperation(\n        \"Other\", \"field\", models.BooleanField(default=False)\n    )\n    self.assertIs(operation.reduce(other_operation, \"migrations\"), True)\n    self.assertIs(other_operation.reduce(operation, \"migrations\"), False)\n", "def test_rename_table_references(self):\n    app_label = \"test_rmtr\"\n    project_state = self.set_up_test_model(\n        app_label,\n        second_model=True,\n        db_table=\"something_else\",\n        related_model=True,\n    )\n    self.assertTableExists(\"something_else\")\n    self.assertTableExists(\"%s_rider\" % app_label)\n    self.assertFKExists(\n        \"%s_rider\" % app_label,\n        [\"pony_id\"],\n        (\"something_else\", \"id\"),\n    )\n    # Rename the table we're referencing.\n    operation = migrations.AlterModelTable(name=\"Pony\", table=\"new_pony\")\n    new_state = project_state.clone()\n    operation.state_forwards(app_label, new_state)\n    # Rename the table in state and database.\n    with connection.schema_editor(atomic=True) as editor:\n        operation.database_forwards(\n            app_label,\n            editor,\n            project_state,\n            new_state,\n        )\n    self.assertTableNotExists(\"something_else\")\n    self.assertTableExists(\"new_pony\")\n    self.assertFKExists(\n        \"%s_rider\" % app_label,\n        [\"pony_id\"],\n        (\"new_pony\", \"id\"),\n    )\n    # Reversal.\n    with connection.schema_editor(atomic=True) as editor:\n        operation.database_backwards(\n            app_label,\n            editor,\n            new_state,\n            project_state,\n        )\n    self.assertTableExists(\"something_else\")\n    self.assertTableNotExists(\"new_pony\")\n    self.assertFKExists(\n        \"%s_rider\" % app_label,\n        [\"pony_id\"],\n        (\"something_else\", \"id\"),\n    )\n", "def test_reduce_references_model(self):\n    operation = FieldOperation(\"Model\", \"field\", models.BooleanField(default=False))\n    other_operation = FieldOperation(\"OtherModel\", \"other_field\", models.BooleanField())\n    self.assertIs(\n        operation.reduce(other_operation, \"migrations\"), [other_operation, operation]\n    )\n    other_operation = FieldOperation(\"Model\", \"field\", models.BooleanField())\n    self.assertIs(operation.reduce(other_operation, \"migrations\"), [operation])\n"], "sample_126": ["def test_mod_inverse_domain_error():\n    x = Symbol('x')\n    raises(TypeError, lambda: mod_inverse(cos(x), 5))\n", "def test_float_approximation():\n    assert Float('1.23456789').as_real_imag()[0].evalf(6) == Float('1.23457', 6)\n    assert Float('1.23456789').as_real_imag()[0].evalf(4) == Float('1.235', 4)\n    assert Float('1.23456789').as_real_imag()[0].evalf(3) == Float('1.23', 3)\n    assert Float('1.23456789').as_real_imag()[0].evalf(2) == Float('1.2', 2)\n    assert Float('1.23456789').as_real_imag()[0].evalf(1) == Float('1', 1)\n", "def test_Float__as_mpf_val():\n    assert Float._new(Float(1)._as_mpf_val(10), 10) == Float(1)\n    assert Float._new(Float(1.0)._as_mpf_val(10), 10) == Float(1.0)\n    assert Float._new(Float(3.14)._as_mpf_val(10), 10) == Float(3.14)\n    assert Float._new(Float('1.618033988749895')._as_mpf_val(10), 10) == Float('1.618033988749895')\n", "compilation error", "def test_mod_inverse_TypeError_when_symbolic_expr():\n    n = Symbol('n', positive=True)\n    raises(TypeError, lambda: mod_inverse(2, n))\n"], "sample_125": ["def test_issue_17466():\n    assert Integer(0).factors() == {}\n    assert Integer(1).factors() == {}\n    assert Integer(2).factors() == {2: 1}\n    assert Integer(4).factors() == {2: 2}\n    assert Integer(5).factors() == {5: 1}\n    assert Integer(6).factors() == {2: 1, 3: 1}\n    assert Integer(10).factors() == {2: 1, 5: 1}\n    assert Integer(12).factors() == {2: 2, 3: 1}\n    assert Integer(16).factors() == {2: 4}\n    assert Integer(17).factors() == {17: 1}\n    assert Integer(25).factors() == {5: 2}\n    assert Integer(37).factors() == {37: 1}\n    assert Integer(41).factors() == {41: 1}\n", "def test_Boolean_comparisons():\n    assert (S(1) < S(2)).is_Boolean\n    assert (S(1) > S(2)).is_Boolean\n    assert (S(1) <= S(2)).is_Boolean\n    assert (S(1) >= S(2)).is_Boolean\n    assert (S(1) == S(2)).is_Boolean\n    assert (S(1) != S(2)).is_Boolean\n", "def test_mod_inverse_issue():\n    p = 701\n    assert mod_inverse(3, p) == 467\n    assert 3 * 467 % p == 1\n", "def test_mpf_normlize():\n    assert mpf_norm((0, 4503599627370497, -52, 53), 53) == (0, long(2251799813685249), -51, 53)\n    assert mpf_norm((1, 1125899906842625, -50, 53), 53) == (1, long(1125899906842624), -50, 53)\n    assert mpf_norm((0, 1234567890101112, 50, 53), 53) == (0, long(1234567890101112), 50, 53)\n    assert mpf_norm((1, 0, 0, 0), 53) == (1, 0, 0, 0)\n", "def test_integer_nthroot_newton_rounding():\n    # Issue 16573\n    assert integer_nthroot(25**5 + 1, 5).root == 25\n    assert integer_nthroot(25**5 + 1, 5).root**5 >= 25**5\n"], "sample_127": ["def test_quaternion_norm():\n    q = Quaternion(x, y, z, t)\n    norm_q = (q.norm())\n    assert latex(norm_q) == r'\\left\\|{x + y i + z j + t k}\\right\\|'\n", "def test_latex_emptyimits():\n    from sympy.calculus.util import AccumBounds\n    assert latex(Integral(x, (x, AccumBounds(-oo, -oo)))) == r\"\\int_{-\\infty}^{-\\infty} x\\, dx\"\n    assert latex(Integral(x, (x, AccumBounds(2, -oo)))) == r\"\\int_{2}^{-\\infty} x\\, dx\"\n    assert latex(Integral(x, (x, AccumBounds(-oo, 1)))) == r\"\\int_{-\\infty}^{1} x\\, dx\"\n    assert latex(Integral(x, (x, AccumBounds(3, 3)))) == r\"\\int_{3}^{3} x\\, dx\"\n    assert latex(Integral(x, (x, AccumBounds(-oo, oo)))) == r\"\\int_{-\\infty}^{\\infty} x\\, dx\"\n", "def test_latex_FreeModuleElement():\n    from sympy.polys import QQ\n    from sympy.polys.agca import free_module\n    F, (e1, e2, e3) = free_module(QQ, 3)\n    f1 = e1 - 2*e2\n    f2 = e3\n    assert latex(f1) == r'-2 \\mathbf{e}_{2} + \\mathbf{e}_{1}'\n    assert latex(f2) == r'\\mathbf{e}_{3}'\n    assert latex(f1 + f2) == r'-2 \\mathbf{e}_{2} + \\mathbf{e}_{1} + \\mathbf{e}_{3}'\n    assert latex(f1 - f2) == r'-2 \\mathbf{e}_{2} + \\mathbf{e}_{1} - \\mathbf{e}_{3}'\n", "def test_latex_degree():\n    assert latex(degree) == r\"^\\circ\"\n", "def test_latex_UnitSystems():\n    from sympy.physics.units import UnitSystem\n    assert latex(UnitSystem()) == r'\\mathbb{US}'\n"]}, "raw_scored_generations": {"sample_1": [false, false, false, false, false], "sample_2": [false, false, false, true, true], "sample_4": [false, true, false, false, false], "sample_0": [true, true, true, true, true], "sample_3": [false, false, false, false, false], "sample_6": [true, true, true, true, false], "sample_5": [true, true, true, true, true], "sample_7": [true, true, true, true, false], "sample_9": [true, false, true, false, true], "sample_8": [true, true, false, false, false], "sample_10": [true, true, true, true, true], "sample_11": [false, false, false, false, false], "sample_13": [false, false, false, false, true], "sample_14": [false, false, false, false, false], "sample_12": [true, true, true, true, true], "sample_15": [true, true, true, true, true], "sample_16": [true, true, true, true, true], "sample_17": [true, true, false, true, true], "sample_18": [false, true, true, false, false], "sample_19": [true, true, true, true, false], "sample_21": [true, true, true, true, true], "sample_20": [true, false, false, false, false], "sample_23": [true, true, true, true, true], "sample_22": [true, true, true, true, true], "sample_24": [true, true, true, true, true], "sample_25": [true, true, true, true, true], "sample_28": [false, false, false, false, false], "sample_26": [false, true, false, false, false], "sample_27": [true, true, true, true, true], "sample_29": [false, false, false, false, false], "sample_31": [true, true, true, true, true], "sample_30": [false, false, false, false, true], "sample_32": [true, false, false, false, false], "sample_33": [false, false, false, false, true], "sample_34": [false, false, false, false, false], "sample_35": [false, false, false, false, false], "sample_36": [true, true, true, true, true], "sample_37": [false, false, false, false, false], "sample_39": [false, false, false, false, false], "sample_38": [true, false, true, false, true], "sample_40": [true, true, true, true, true], "sample_42": [false, false, false, true, false], "sample_41": [true, true, true, true, true], "sample_43": [false, true, true, true, true], "sample_45": [false, false, false, false, false], "sample_44": [false, true, true, true, true], "sample_46": [false, false, false, false, false], "sample_48": [true, true, true, true, true], "sample_47": [true, true, true, true, true], "sample_50": [true, true, true, true, true], "sample_49": [true, false, true, true, true], "sample_51": [true, true, true, true, true], "sample_52": [true, true, true, true, true], "sample_53": [true, true, false, true, true], "sample_55": [true, true, true, true, true], "sample_54": [true, true, true, true, true], "sample_56": [false, false, false, false, false], "sample_58": [true, true, true, true, true], "sample_57": [true, true, false, true, true], "sample_60": [true, true, true, false, true], "sample_59": [true, false, true, true, true], "sample_61": [false, false, false, true, false], "sample_63": [false, false, false, false, false], "sample_62": [false, false, false, false, false], "sample_64": [true, true, true, true, true], "sample_66": [true, true, false, true, true], "sample_65": [false, false, false, false, false], "sample_68": [true, true, true, true, true], "sample_67": [false, false, true, true, false], "sample_69": [true, true, true, false, false], "sample_70": [true, false, false, true, true], "sample_71": [true, true, true, true, true], "sample_72": [false, true, true, false, true], "sample_73": [true, true, false, false, false], "sample_74": [false, false, false, false, false], "sample_75": [true, true, true, false, true], "sample_76": [false, false, false, false, false], "sample_77": [false, false, false, false, true], "sample_78": [false, false, false, false, true], "sample_79": [false, false, false, false, false], "sample_80": [false, false, false, false, false], "sample_82": [true, false, false, true, false], "sample_81": [false, false, false, false, false], "sample_83": [false, false, false, false, false], "sample_84": [false, false, false, false, false], "sample_85": [false, false, false, false, false], "sample_86": [false, false, false, false, true], "sample_87": [false, false, true, false, false], "sample_88": [false, false, false, false, false], "sample_89": [false, false, false, false, false], "sample_90": [false, false, false, false, false], "sample_91": [false, false, false, false, false], "sample_92": [false, false, false, false, false], "sample_93": [true, false, false, true, true], "sample_95": [false, false, false, false, false], "sample_94": [false, false, false, true, false], "sample_96": [false, false, true, false, false], "sample_97": [true, false, false, false, false], "sample_98": [true, false, true, false, true], "sample_99": [false, false, false, false, false], "sample_101": [true, true, true, true, false], "sample_100": [true, false, true, false, true], "sample_102": [false, false, false, false, true], "sample_103": [false, false, false, false, false], "sample_104": [false, false, false, true, false], "sample_105": [true, true, false, false, true], "sample_107": [false, true, false, false, false], "sample_106": [true, false, true, false, true], "sample_108": [false, true, false, false, false], "sample_109": [false, false, false, false, false], "sample_110": [false, true, true, true, true], "sample_111": [false, false, false, false, false], "sample_112": [true, false, false, false, false], "sample_113": [false, false, true, false, false], "sample_114": [false, false, false, false, false], "sample_115": [false, false, false, false, false], "sample_116": [false, false, false, false, false], "sample_117": [true, true, true, false, false], "sample_118": [false, false, false, false, false], "sample_119": [true, true, false, true, true], "sample_120": [true, false, false, true, false], "sample_121": [false, true, false, false, false], "sample_122": [true, false, true, false, false], "sample_123": [true, false, false, false, false], "sample_124": [false, true, true, false, false], "sample_125": [false, false, false, false, false], "sample_126": [true, false, false, false, true], "sample_127": [false, false, false, true, false], "sample_128": [true, true, true, true, true], "sample_129": [true, false, false, false, false], "sample_130": [false, true, true, true, true], "sample_131": [true, true, false, true, true], "sample_132": [false, false, false, true, false], "sample_133": [false, false, false, false, false], "sample_134": [true, true, true, true, true], "sample_135": [false, false, false, false, true], "sample_136": [false, false, false, true, true], "sample_137": [false, false, false, false, false], "sample_138": [true, false, true, false, true], "sample_139": [false, false, false, false, false], "sample_140": [true, true, false, false, false], "sample_142": [false, false, false, false, false], "sample_141": [false, false, false, false, false], "sample_143": [false, false, false, false, false], "sample_144": [true, true, true, true, true], "sample_145": [false, false, false, true, true], "sample_146": [false, false, false, false, false], "sample_147": [false, false, false, false, false], "sample_148": [false, false, true, false, false], "sample_149": [true, false, false, true, false], "sample_150": [false, false, false, false, false], "sample_151": [true, true, true, true, true], "sample_152": [false, false, true, false, true], "sample_153": [false, false, false, false, false], "sample_154": [false, true, false, true, true], "sample_155": [false, false, false, false, false], "sample_156": [false, false, true, true, false], "sample_157": [false, false, true, false, false], "sample_158": [false, false, false, false, false], "sample_159": [true, true, false, false, true]}}