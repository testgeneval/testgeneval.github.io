{"raw_generations": {"sample_67": ["    def test_serialize_deconstructable(self):\n        @deconstructible\n        class CustomClass:\n                self.arg1 = arg1\n                self.arg2 = arg2\n\n                return (\n                    \"migrations.test_writer.CustomClass\",\n                    [self.arg1, self.arg2],\n                    {},\n                )\n\n        instance = CustomClass(\"value1\", 42)\n        self.assertSerializedResultEqual(\n            instance,\n            (\n                \"migrations.test_writer.CustomClass('value1', 42)\",\n                {\"import migrations.test_writer\"},\n            ),\n        )\n        self.assertSerializedEqual(instance)\n"], "sample_97": ["def test_label_encoder_non_numeric():\n    # Test LabelEncoder with non-numeric labels\n    le = LabelEncoder()\n    le.fit([\"cat\", \"dog\", \"fish\"])\n    assert_array_equal(le.classes_, [\"cat\", \"dog\", \"fish\"])\n    assert_array_equal(le.transform([\"cat\", \"dog\", \"fish\", \"cat\"]),\n                       [0, 1, 2, 0])\n    assert_array_equal(le.inverse_transform([0, 1, 2, 0]),\n                       [\"cat\", \"dog\", \"fish\", \"cat\"])\n    assert_raises(ValueError, le.transform, [\"cat\", \"bird\"])\n    assert_raises(ValueError, le.inverse_transform, [0, 3])\n"], "sample_37": ["    def test_filtered_relation_initialization(self):\n        relation_name = 'test_relation'\n        condition = Q(num_employees__gt=10)\n        filtered_relation = FilteredRelation(relation_name, condition=condition)\n        self.assertEqual(filtered_relation.relation_name, relation_name)\n        self.assertEqual(filtered_relation.condition, condition)\n        self.assertEqual(filtered_relation.alias, None)\n        self.assertEqual(filtered_relation.path, [])\n"], "sample_7": ["    def test_ensure_echo_on_enabled(self, mocked_isatty, mocked_termios):\n        attrs = [0, 0, 0, 0]\n        mocked_termios.tcgetattr.return_value = attrs\n        autoreload.ensure_echo_on()\n        self.assertFalse(mocked_termios.tcsetattr.called)\n"], "sample_129": ["def test_latex_undefined_function():\n    f = UndefinedFunction('f')\n    assert latex(f(x)) == r'f{\\left (x \\right )}'\n    assert latex(f(x, y)) == r'f{\\left (x,y \\right )}'\n    assert latex(f(x, y, z)) == r'f{\\left (x,y,z \\right )}'\n    assert latex(f) == r'f'\n    assert latex(f**2) == r'f^{2}'\n    assert latex(f(x)**2) == r'f^{2}{\\left (x \\right )}'\n"], "sample_44": ["    def test_model_to_dict(self):\n        # Create an instance of the Category model\n        category = Category.objects.create(name='Test Category', slug='test-category', url='test-category')\n\n        # Convert the model instance to a dictionary\n        data = model_to_dict(category)\n\n        # Check that the dictionary contains the correct data\n        self.assertEqual(data['name'], 'Test Category')\n        self.assertEqual(data['slug'], 'test-category')\n        self.assertEqual(data['url'], 'test-category')\n\n        # Check that the dictionary does not contain non-editable fields\n        self.assertNotIn('id', data)\n"], "sample_150": ["def test_solve_generic():\n    from sympy.polys import Options\n\n    NewOption = Options((x, y), {'domain': 'ZZ'})\n\n    a = Poly(x - y + 5, x, y, domain='ZZ')\n    b = Poly(x + y - 3, x, y, domain='ZZ')\n    assert solve_generic([a, b], NewOption) == [(-1, 4)]\n\n    a = Poly(x - 2*y + 5, x, y, domain='ZZ')\n    b = Poly(2*x - y - 3, x, y, domain='ZZ')\n    assert solve_generic([a, b], NewOption) == [(11/3, 13/3)]\n\n    a = Poly(x**2 + y, x, y, domain='ZZ')\n    b = Poly(x + y*4, x, y, domain='ZZ')\n    assert solve_generic([a, b], NewOption) == [(0, 0), (1/4, -1/16)]\n\n    a = Poly(x**2 + y**2 - 1, x, y, domain='ZZ')\n    b = Poly(x**2 - y**2, x, y, domain='ZZ')\n    assert solve_generic([a, b], NewOption) == [(-1, 0), (1, 0)]\n\n    a = Poly(x**3 - y**3, x, y, domain='ZZ')\n    b = Poly(x - y, x, y, domain='ZZ')\n    raises(NotImplementedError, lambda: solve_generic([a, b], NewOption))\n\n    a = Poly(x**2 + y**2 - 1, x, y, domain='ZZ')\n    b = Poly(x**2 - y**2 + 1, x, y, domain='ZZ')\n    raises(NotImplementedError, lambda: solve_generic([a, b], NewOption))\n"], "sample_84": ["def test_pyobj_property():\n    class MockNode:\n            self.obj = obj\n\n            return self\n\n    class MockClass:\n        obj = \"mock_object\"\n\n    node = MockNode(MockClass)\n    prop = pyobj_property(\"MockClass\")\n    assert prop.__doc__ == \"python mockclass object this node was collected from (can be None).\"\n    assert prop.fget(node) == \"mock_object\"\n"], "sample_134": ["def test_codegen_array_diagonal():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    M = MatrixSymbol(\"M\", 3, 3)\n    N = MatrixSymbol(\"N\", 3, 3)\n    cg = CodegenArrayDiagonal(CodegenArrayTensorProduct(M, N), (1, 2))\n    f = lambdify((M, N), cg, 'numpy')\n\n    ma = np.matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    mb = np.matrix([[9, 8, 7], [6, 5, 4], [3, 2, 1]])\n    expected_result = np.diagonal(np.einsum('ij,kl->ikjl', ma, mb), axis1=1, axis2=2)\n    assert np.array_equal(f(ma, mb), expected_result)\n"], "sample_60": ["    def test_serialize_functools_partial_with_nested_partial(self):\n        value = functools.partial(\n            functools.partial(datetime.timedelta, 1), seconds=2\n        )\n        result = self.serialize_round_trip(value)\n        self.assertIsInstance(result, functools.partial)\n        self.assertIsInstance(result.func, functools.partial)\n        self.assertEqual(result.func.func, datetime.timedelta)\n        self.assertEqual(result.func.args, (1,))\n        self.assertEqual(result.keywords, {\"seconds\": 2})\n"], "sample_47": ["    def test_mixed_migration_plan(self):\n        \"\"\"\n        Test that a mixed migration plan (with both forwards and backwards migrations)\n        raises an InvalidMigrationPlan exception.\n        \"\"\"\n        executor = MigrationExecutor(connection)\n        # Apply initial migrations\n        executor.migrate([(\"migrations\", \"0001_initial\")])\n        executor.loader.build_graph()\n        # Generate mixed plan\n        plan = executor.migration_plan([\n            (\"migrations\", \"0002_second\"),\n            (\"migrations\", \"0001_initial\"),\n        ])\n        msg = (\n            'Migration plans with both forwards and backwards migrations are '\n            'not supported. Please split your migration process into separate '\n            'plans of only forwards OR backwards migrations.'\n        )\n        with self.assertRaisesMessage(InvalidMigrationPlan, msg) as cm:\n            executor.migrate(None, plan)\n        self.assertEqual(\n            cm.exception.args[1],\n            [\n                (executor.loader.graph.nodes[\"migrations\", \"0002_second\"], False),\n                (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], True),\n            ],\n        )\n        # Cleanup\n        executor.migrate([(\"migrations\", None)])\n        self.assertTableNotExists(\"migrations_author\")\n        self.assertTableNotExists(\"migrations_book\")\n"], "sample_145": ["def test_latex_IndexedBase():\n    # Test for IndexedBase with various indices\n    A = IndexedBase('A')\n    i, j, k = symbols('i j k')\n    assert latex(A[i]) == r'{A}_{i}'\n    assert latex(A[i, j]) == r'{A}_{i, j}'\n    assert latex(A[i, j, k]) == r'{A}_{i, j, k}'\n    assert latex(A[i]**2) == r'{A}_{i}^{2}'\n    assert latex(A[i, j] + A[j, k]) == r'{A}_{i, j} + {A}_{j, k}'\n    assert latex(A[i, j] * A[j, k]) == r'{A}_{i, j} {A}_{j, k}'\n    assert latex(A[i, j] / A[j, k]) == r'\\frac{{A}_{i, j}}{{A}_{j, k}}'\n    assert latex(A[i, j] - A[j, k]) == r'{A}_{i, j} - {A}_{j, k}'\n    assert latex(A[i, j] + A[j, k] + A[k, i]) == r'{A}_{i, j} + {A}_{j, k} + {A}_{k, i}'\n    assert latex(A[i, j] * A[j, k] * A[k, i]) == r'{A}_{i, j} {A}_{j, k} {A}_{k, i}'\n    assert latex(A[i, j] / (A[j, k] + A[k, i])) == r'\\frac{{A}_{i, j}}{{A}_{j, k} + {A}_{k, i}}'\n"], "sample_10": ["    def test_year_lookups(self):\n        # Create some articles with specific publication years for testing year lookups.\n        Article.objects.create(headline='Article 2000', pub_date=datetime(2000, 1, 1), author=self.au1, slug='a2000')\n        Article.objects.create(headline='Article 2001', pub_date=datetime(2001, 1, 1), author=self.au1, slug='a2001')\n        Article.objects.create(headline='Article 2002', pub_date=datetime(2002, 1, 1), author=self.au1, slug='a2002')\n        Article.objects.create(headline='Article 2003', pub_date=datetime(2003, 1, 1), author=self.au1, slug='a2003')\n\n        # Test YearExact lookup\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year=2001),\n            ['<Article: Article 2001>'],\n            ordered=False\n        )\n\n        # Test YearGt lookup\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__gt=2001),\n            ['<Article: Article 2002>', '<Article: Article 2003>'],\n            ordered=False\n        )\n\n        # Test YearGte lookup\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__gte=2001),\n            ['<Article: Article 2001>', '<Article: Article 2002>', '<Article: Article 2003>'],\n            ordered=False\n        )\n\n        # Test YearLt lookup\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__lt=2002),\n            ['<Article: Article 2000>', '<Article: Article 2001>'],\n            ordered=False\n        )\n\n        # Test YearLte lookup\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__lte=2002),\n            ['<Article: Article 2000>', '<Article: Article 2001>', '<Article: Article 2002>'],\n            ordered=False\n        )\n"], "sample_61": ["    def test_none_and_empty_string(self):\n        self.assertEqual(nformat(None, \".\"), None)\n        self.assertEqual(nformat(\"\", \".\"), \"\")\n"], "sample_9": ["    def test_ensure_echo_on(self, mock_stdin, mock_termios):\n        # Mocking sys.stdin.isatty to return True\n        mock_stdin.isatty.return_value = True\n\n        # Mocking termios.tcgetattr to return a list with ECHO off\n        attrs = [0, 0, 0, 0]\n        attrs[3] = 0  # ECHO off\n        mock_termios.tcgetattr.return_value = attrs\n\n        # Call the function\n        autoreload.ensure_echo_on()\n\n        # Check that tcsetattr was called to turn ECHO on\n        attrs[3] |= mock_termios.ECHO\n        mock_termios.tcsetattr.assert_called_once_with(mock_stdin, mock_termios.TCSANOW, attrs)\n"], "sample_53": ["    def test_alter_field_with_custom_deconstruct(self):\n        \"\"\"\n        Tests autodetection of altered fields with custom deconstruct methods.\n        \"\"\"\n        class CustomField(models.CharField):\n                name, path, args, kwargs = super().deconstruct()\n                kwargs[\"custom\"] = \"value\"\n                return name, path, args, kwargs\n\n        before = [\n            ModelState(\n                \"testapp\",\n                \"Author\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\"name\", CustomField(max_length=200)),\n                ],\n            )\n        ]\n        after = [\n            ModelState(\n                \"testapp\",\n                \"Author\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\"name\", CustomField(max_length=400)),\n                ],\n            )\n        ]\n        changes = self.get_changes(before, after)\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, \"testapp\", 1)\n        self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, max_length=400)\n"], "sample_146": ["def test_Complexes():\n    assert str(S.Complexes) == 'Complexes'\n    assert str(S.Complexes - S.Reals) == 'Complexes \\ Reals'\n    assert str(S.Complexes & S.Reals) == 'Reals'\n    assert str(S.Complexes | S.Reals) == 'Complexes'\n"], "sample_3": ["def test_separability_matrix():\n    # Test separability_matrix function with various models\n    result = separability_matrix(sh1 & sh2 | scl1 & scl2)\n    assert_allclose(result, np.array([[True, False], [False, True]]))\n\n    result = separability_matrix(sh1 & sh2 | rot)\n    assert_allclose(result, np.array([[True, True], [True, True]]))\n\n    result = separability_matrix(sh1 & sh2 | map1)\n    assert_allclose(result, np.array([[True, False], [False, True], [True, False], [False, True]]))\n\n    result = separability_matrix(sh1 & sh2 | map2)\n    assert_allclose(result, np.array([[True, False], [True, False], [False, True]]))\n\n    result = separability_matrix(sh1 & sh2 | map3)\n    assert_allclose(result, np.array([[True], [True]]))\n"], "sample_8": ["    def setUp(self):\n        self.filter = SafeExceptionReporterFilter()\n        self.rf = RequestFactory()\n"], "sample_133": ["def test_rust_codegen():\n    x, y, z = symbols('x,y,z')\n    expr = (x + y)*z\n    routine = make_routine(\"test\", expr)\n    code_gen = RustCodeGen()\n    source = get_string(code_gen.dump_rs, [routine])\n    expected = (\n        \"fn test(x: f64, y: f64, z: f64) -> f64 {\\n\"\n        \"    let test_result = z*(x + y);\\n\"\n        \"    test_result\\n\"\n        \"}\\n\"\n    )\n    assert source == expected\n"], "sample_105": ["def test_voting_regressor():\n    \"\"\"Test VotingRegressor on a simple regression problem.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(n_estimators=10, random_state=1)\n    X = np.array([[1, 1], [2, 4], [3, 9], [4, 16], [5, 25], [6, 36]])\n    y = np.array([2, 6, 12, 20, 30, 42])\n\n    ereg = VotingRegressor(estimators=[('lr', reg1), ('rf', reg2)])\n    ereg.fit(X, y)\n    pred = ereg.predict(X)\n    \n    # Check if the predictions are close to the expected values\n    expected_pred = np.array([3.3, 5.7, 11.8, 19.7, 28.0, 40.3])\n    assert_array_almost_equal(pred, expected_pred, decimal=1)\n\n    # Check if the individual regressors are fitted\n    assert hasattr(ereg.named_estimators_, 'lr')\n    assert hasattr(ereg.named_estimators_, 'rf')\n\n    # Check if the transform method returns correct shape\n    transformed = ereg.transform(X)\n    assert transformed.shape == (6, 2)\n"], "sample_59": ["def test_management_form_clean(self):\n    \"\"\"\n    Test that the ManagementForm's clean method correctly sets default values\n    for TOTAL_FORMS and INITIAL_FORMS when they are missing or tampered with.\n    \"\"\"\n    # Case 1: ManagementForm with valid data\n    data = {\n        \"choices-TOTAL_FORMS\": \"2\",\n        \"choices-INITIAL_FORMS\": \"1\",\n        \"choices-MIN_NUM_FORMS\": \"0\",\n        \"choices-MAX_NUM_FORMS\": \"2\",\n    }\n    formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n    self.assertTrue(formset.management_form.is_valid())\n    self.assertEqual(formset.management_form.cleaned_data[TOTAL_FORM_COUNT], 2)\n    self.assertEqual(formset.management_form.cleaned_data[INITIAL_FORM_COUNT], 1)\n\n    # Case 2: ManagementForm with missing TOTAL_FORMS and INITIAL_FORMS\n    data = {\n        \"choices-MIN_NUM_FORMS\": \"0\",\n        \"choices-MAX_NUM_FORMS\": \"2\",\n    }\n    formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n    self.assertFalse(formset.management_form.is_valid())\n    self.assertEqual(\n        formset.management_form.errors,\n        {\n            TOTAL_FORM_COUNT: [\"This field is required.\"],\n            INITIAL_FORM_COUNT: [\"This field is required.\"],\n        },\n    )\n\n    # Case 3: ManagementForm with tampered TOTAL_FORMS and INITIAL_FORMS\n    data = {\n        \"choices-TOTAL_FORMS\": \"invalid\",\n        \"choices-INITIAL_FORMS\": \"invalid\",\n        \"choices-MIN_NUM_FORMS\": \"0\",\n        \"choices-MAX_NUM_FORMS\": \"2\",\n    }\n    formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n    self.assertFalse(formset.management_form.is_valid())\n    self.assertEqual(\n        formset.management_form.errors,\n        {\n            TOTAL_FORM_COUNT: [\"Enter a whole number.\"],\n            INITIAL_FORM_COUNT: [\"Enter a whole number.\"],\n        },\n    )\n"], "sample_123": ["def test_mpf_norm():\n    # Test the mpf_norm function with various inputs\n    assert mpf_norm((0, 0, 0, 0), 10) == (0, 0, 0, 0)\n    assert mpf_norm((1, 1, 1, 1), 10) == (1, 1, 1, 1)\n    assert mpf_norm((1, 0, 1, 0), 10) == (0, 0, 0, 0)  # edge case where mantissa is zero\n    assert mpf_norm((1, 123456789, 10, 30), 10) == (1, 123456789, 10, 30)\n    assert mpf_norm((0, 123456789, -10, 30), 10) == (0, 123456789, -10, 30)\n    assert mpf_norm((1, 0, 1, 1), 10) == (0, 0, 0, 0)  # another edge case where mantissa is zero\n"], "sample_141": ["def test_quantity_simplify():\n    from sympy.physics.units import foot, inch, kilo\n    from sympy.physics.units.util import quantity_simplify\n\n    expr = kilo * foot * inch\n    simplified_expr = quantity_simplify(expr)\n    assert simplified_expr == 250 * foot**2 / 3\n\n    expr = foot - 6 * inch\n    simplified_expr = quantity_simplify(expr)\n    assert simplified_expr == foot / 2\n\n    expr = kilo * (foot + inch)\n    simplified_expr = quantity_simplify(expr)\n    assert simplified_expr == 1000 * foot + 1000 * inch\n\n    expr = kilo * foot * inch + foot\n    simplified_expr = quantity_simplify(expr)\n    assert simplified_expr == 250 * foot**2 / 3 + foot\n"], "sample_140": ["def test_point_set_pos():\n    q = dynamicsymbols('q')\n    N = ReferenceFrame('N')\n    O = Point('O')\n    P = Point('P')\n    P.set_pos(O, q * N.x)\n    assert P.pos_from(O) == q * N.x\n    raises(TypeError, lambda: P.set_pos(O, 10))  # Invalid type for position vector\n    raises(TypeError, lambda: P.set_pos(\"O\", q * N.x))  # Invalid type for other point\n    Q = Point('Q')\n    Q.set_pos(P, 5 * N.y)\n    assert Q.pos_from(O) == q * N.x + 5 * N.y\n    assert O.pos_from(Q) == -q * N.x - 5 * N.y\n"], "sample_38": ["    def test_unicode_ci_compare_equal(self):\n        self.assertTrue(_unicode_ci_compare('test', 'TEST'))\n        self.assertTrue(_unicode_ci_compare('Stra\u00dfe', 'strasse'))\n        self.assertTrue(_unicode_ci_compare('caf\u00e9', 'CAFE'))\n"], "sample_28": ["    def setUp(self):\n        self.site = admin.AdminSite()\n"], "sample_20": ["    def test_modelbase_new_non_model_subclass(self):\n        class NonModelBase:\n            pass\n\n        with self.assertRaises(RuntimeError):\n            class TestModel(NonModelBase, metaclass=ModelBase):\n                pass\n"], "sample_98": ["def test_check_non_negative():\n    # Test for check_non_negative function\n    X = np.array([[1, 2], [3, 4]])\n    check_non_negative(X, \"test_check_non_negative\")\n\n    X_neg = np.array([[1, -2], [3, 4]])\n    assert_raises(ValueError, check_non_negative, X_neg, \"test_check_non_negative\")\n\n    X_sparse = sp.csr_matrix([[1, 2], [3, 4]])\n    check_non_negative(X_sparse, \"test_check_non_negative\")\n\n    X_sparse_neg = sp.csr_matrix([[1, -2], [3, 4]])\n    assert_raises(ValueError, check_non_negative, X_sparse_neg, \"test_check_non_negative\")\n"], "sample_45": ["    def test_decorator_from_middleware(self):\n        \"\"\"\n        Ensure decorator_from_middleware properly applies middleware to a view.\n        \"\"\"\n        class TestMiddleware:\n                self.get_response = get_response\n\n                response = self.get_response(request)\n                response['X-Test'] = 'TestMiddleware'\n                return response\n\n        @decorator_from_middleware(TestMiddleware)\n            return HttpResponse()\n\n        request = HttpRequest()\n        response = a_view(request)\n        self.assertEqual(response['X-Test'], 'TestMiddleware')\n"], "sample_11": ["    def test_serialize_function_type(self):\n            return \"sample\"\n\n        self.assertSerializedResultEqual(\n            sample_function,\n            (\"migrations.test_writer.sample_function\", {\"import migrations.test_writer\"})\n        )\n\n        with self.assertRaisesMessage(ValueError, \"Cannot serialize function: lambda\"):\n            self.assertSerializedEqual(lambda x: x)\n\n        class SampleClass:\n            @staticmethod\n                return \"static\"\n\n            @classmethod\n                return \"class\"\n\n        self.assertSerializedResultEqual(\n            SampleClass.static_method,\n            (\"migrations.test_writer.SampleClass.static_method\", {\"import migrations.test_writer\"})\n        )\n\n        self.assertSerializedResultEqual(\n            SampleClass.class_method,\n            (\"migrations.test_writer.SampleClass.class_method\", {\"import migrations.test_writer\"})\n        )\n"], "sample_104": ["def test_custom_key_val_tuple():\n    # Test the custom KeyValTuple and KeyValTupleParam classes\n    kv_tuple = KeyValTuple(('key', 'value'))\n    kv_param = KeyValTupleParam(('param', 'value'))\n\n    # Ensure the custom __repr__ methods are correctly used\n    assert repr(kv_tuple) == \"('key', 'value')\"\n    assert repr(kv_param) == \"('param', 'value')\"\n\n    # Test pretty printing with these custom classes\n    pp = _EstimatorPrettyPrinter(compact=True, indent=1, indent_at_name=True)\n    expected_kv_tuple = \"('key', 'value')\"\n    expected_kv_param = \"('param', 'value')\"\n    \n    assert pp.pformat(kv_tuple) == expected_kv_tuple\n    assert pp.pformat(kv_param) == expected_kv_param\n"], "sample_107": ["def test_logistic_regression_path():\n    # Test logistic_regression_path function directly\n    X, y = make_classification(n_samples=100, n_features=5, random_state=0)\n    Cs = [0.1, 1, 10]\n    coefs, Cs, n_iter = logistic_regression_path(X, y, Cs=Cs, solver='lbfgs', max_iter=100, tol=1e-4)\n    \n    assert len(coefs) == len(Cs)\n    assert len(n_iter) == len(Cs)\n    assert all(isinstance(c, np.ndarray) for c in coefs)\n    assert all(isinstance(n, int) for n in n_iter)\n    assert all(c.shape[1] == X.shape[1] + 1 for c in coefs)  # Check if intercept is included\n"], "sample_49": ["    def test_template_dirs_exclude_django_paths(self, mock_is_django_path):\n        self.assertSetEqual(\n            autoreload.get_template_directories(),\n            set()\n        )\n        mock_is_django_path.assert_called()\n"], "sample_5": ["    def test_protect_error_message(self):\n        \"\"\"\n        Test that the ProtectedError exception contains the correct message and protected objects.\n        \"\"\"\n        a = create_a('protect')\n        try:\n            a.protect.delete()\n        except ProtectedError as e:\n            self.assertEqual(\n                str(e),\n                \"Cannot delete some instances of model 'R' because they are referenced through a protected foreign key: 'A.protect'\"\n            )\n            self.assertIn(a.protect, e.protected_objects)\n"], "sample_156": ["def test_parser_mathematica_edge_cases():\n    # Test for empty input\n    assert parse_mathematica(\"\") == sympify(\"\")\n\n    # Test for single character input\n    assert parse_mathematica(\"a\") == sympify(\"a\")\n    assert parse_mathematica(\"1\") == sympify(\"1\")\n\n    # Test for invalid input\n    raises(SyntaxError, lambda: parse_mathematica(\"a[\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a]\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c,\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c,d\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c,d,\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c,d,e\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c,d,e,\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c,d,e,f\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c,d,e,f,\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c,d,e,f,g\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c,d,e,f,g,\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c,d,e,f,g,h\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c,d,e,f,g,h,\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c,d,e,f,g,h,i\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c,d,e,f,g,h,i,\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c,d,e,f,g,h,i,j\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c,d,e,f,g,h,i,j,\"))\n    raises(SyntaxError, lambda: parse_mathematica(\"a[b,c,d,e,f,g,h,i,j,k\"))\n    raises(SyntaxError, lambda"], "sample_158": ["def test_unit_system_extend():\n    base_units = (meter, second)\n    units = (joule, volt)\n    name = \"ExtendedSystem\"\n    descr = \"An extended unit system\"\n    dimension_system = SI.get_dimension_system()\n    derived_units = {energy: joule}\n\n    extended_system = SI.extend(base_units, units, name, descr, dimension_system, derived_units)\n\n    assert extended_system.name == name\n    assert extended_system.descr == descr\n    assert set(extended_system._base_units) == set(SI._base_units + base_units)\n    assert set(extended_system._units) == set(SI._units + units)\n    assert extended_system._dimension_system == dimension_system\n    assert extended_system._derived_units == {**SI._derived_units, **derived_units}\n    assert extended_system.get_dimension_system() == dimension_system\n    assert extended_system.get_quantity_dimension(joule) == energy\n    assert extended_system.get_quantity_scale_factor(joule) == 1\n    assert extended_system.get_quantity_dimension(volt) == SI.get_quantity_dimension(volt)\n    assert extended_system.get_quantity_scale_factor(volt) == SI.get_quantity_scale_factor(volt)\n"], "sample_55": ["    def test_command_error_returncode(self):\n        \"\"\"Test that CommandError sets the correct returncode.\"\"\"\n        with self.assertRaises(CommandError) as cm:\n            raise CommandError(\"Test error\", returncode=5)\n        self.assertEqual(cm.exception.returncode, 5)\n"], "sample_95": ["def test_pytest_addoption(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n            parser.addoption(\"--custom\", action=\"store_true\", help=\"custom option\")\n        \"\"\"\n    )\n    result = pytester.runpytest(\"--custom\")\n    assert result.ret == 0\n"], "sample_30": ["    def test_formfield_for_dbfield_with_choices(self):\n        \"\"\"\n        Test that formfield_for_dbfield returns the correct form field for a\n        database field with choices.\n        \"\"\"\n        class TestModel(models.Model):\n            CHOICES = (\n                ('A', 'Choice A'),\n                ('B', 'Choice B'),\n            )\n            choice_field = models.CharField(max_length=1, choices=CHOICES)\n\n        class TestModelAdmin(ModelAdmin):\n            model = TestModel\n\n        model_admin = TestModelAdmin(TestModel, admin_site)\n        request = self.factory.get(reverse('admin:index'))\n        form_field = model_admin.formfield_for_dbfield(TestModel._meta.get_field('choice_field'), request)\n        self.assertIsInstance(form_field.widget, widgets.AdminRadioSelect)\n        self.assertEqual(form_field.choices, [('A', 'Choice A'), ('B', 'Choice B')])\n"], "sample_34": ["    def test_field_name_clash_with_parent(self):\n        class Parent(models.Model):\n            name = models.CharField(max_length=20)\n\n        class Child(Parent):\n            name = models.IntegerField()\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"The field 'name' from parent model 'check_framework.Parent' clashes with the field 'name' from model 'check_framework.Child'.\",\n                obj=Child,\n                id='models.E005',\n            ),\n        ])\n"], "sample_106": ["def test_transform_before_fit():\n    \"\"\"Test that calling transform before fit raises a NotFittedError.\"\"\"\n    X = iris_data\n    nca = NeighborhoodComponentsAnalysis()\n    with pytest.raises(Exception) as excinfo:\n        nca.transform(X)\n    assert 'This NeighborhoodComponentsAnalysis instance is not fitted yet' in str(excinfo.value)\n"], "sample_90": ["def test_mark_evaluator_istrue():\n    from _pytest.nodes import Item\n    from _pytest.mark.structures import Mark\n\n    class MockItem(Item):\n            super().__init__(name, config)\n            self._markers = []\n\n            if name is None:\n                return iter(self._markers)\n            return (m for m in self._markers if m.name == name)\n\n    item = MockItem(name=\"test_item\", config=None)\n    item._markers.append(Mark(name=\"skipif\", args=(\"sys.version_info < (3,8)\",), kwargs={\"reason\": \"Python version too low\"}))\n\n    evaluator = MarkEvaluator(item=item, name=\"skipif\")\n    assert evaluator.istrue() == (sys.version_info < (3, 8))\n    assert evaluator.getexplanation() == \"Python version too low\"\n"], "sample_74": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cbar = fig.colorbar(im)\n    \n    # Test setting alpha to a scalar value\n    cbar.set_alpha(0.5)\n    assert cbar.alpha == 0.5\n    \n    # Test setting alpha to an array\n    alpha_array = np.array([[0.1, 0.2], [0.3, 0.4]])\n    cbar.set_alpha(alpha_array)\n    assert cbar.alpha is None  # Should reset to None when array is provided\n    \n    # Test setting alpha back to a scalar value\n    cbar.set_alpha(0.8)\n    assert cbar.alpha == 0.8\n"], "sample_85": ["def test_log_capture_handler_reset(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        from _pytest.logging import LogCaptureHandler\n\n            handler = LogCaptureHandler()\n            logger = logging.getLogger(__name__)\n            logger.addHandler(handler)\n            logger.warning(\"First log message\")\n            assert len(handler.records) == 1\n            assert handler.records[0].getMessage() == \"First log message\"\n            handler.reset()\n            assert len(handler.records) == 0\n            logger.warning(\"Second log message\")\n            assert len(handler.records) == 1\n            assert handler.records[0].getMessage() == \"Second log message\"\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"* 1 passed in *\"])\n"], "sample_132": ["def test_are_coplanar():\n    from sympy.geometry import Point3D, Line3D, Plane\n    a = Line3D(Point3D(5, 0, 0), Point3D(1, -1, 1))\n    b = Line3D(Point3D(0, -2, 0), Point3D(3, 1, 1))\n    c = Line3D(Point3D(0, -1, 0), Point3D(5, -1, 9))\n    d = Plane(Point3D(0, 0, 0), Point3D(1, 0, 0), Point3D(0, 1, 0))\n    assert not are_coplanar(a, b, c)\n    assert are_coplanar(a, b, d)\n    assert are_coplanar(Point3D(1, 2, 3), Point3D(4, 5, 6), Point3D(7, 8, 9))\n    assert not are_coplanar(Point3D(1, 2, 3), Point3D(4, 5, 6), Point3D(7, 8, 10))\n"], "sample_27": ["    def test_token_with_changed_password(self):\n        \"\"\"Changing the user's password invalidates the token.\"\"\"\n        user = User.objects.create_user('changepassworduser', 'test5@example.com', 'testpw')\n        p0 = PasswordResetTokenGenerator()\n        tk1 = p0.make_token(user)\n        self.assertIs(p0.check_token(user, tk1), True)\n        user.set_password('newtestpw')\n        user.save()\n        self.assertIs(p0.check_token(user, tk1), False)\n"], "sample_39": ["    def test_regex_pattern_match(self):\n        pattern = RegexPattern(r'^test/(?P<id>\\d+)/$')\n        match = pattern.match('test/123/')\n        self.assertIsNotNone(match)\n        self.assertEqual(match[1], ())\n        self.assertEqual(match[2], {'id': '123'})\n"], "sample_35": ["    def test_modelform_factory(self):\n        from django.db import models\n\n        class TestModel(models.Model):\n            name = models.CharField(max_length=100)\n            age = models.IntegerField()\n\n        TestModelForm = modelform_factory(TestModel, fields=['name', 'age'])\n\n        form_data = {'name': 'John Doe', 'age': 30}\n        form = TestModelForm(data=form_data)\n        self.assertTrue(form.is_valid())\n        instance = form.save()\n        self.assertEqual(instance.name, 'John Doe')\n        self.assertEqual(instance.age, 30)\n"], "sample_144": ["def test_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 1], Q.symmetric(X)) == X[1, 1]\n    assert refine(X[2, 1], Q.symmetric(X)) == X[1, 2]\n"], "sample_31": ["    def test_shell_with_bpython_not_installed(self, select):\n        select.return_value = ([], [], [])\n        with self.assertRaisesMessage(CommandError, \"Couldn't import bpython interface.\"):\n            call_command('shell', interface='bpython')\n"], "sample_64": ["    def test_prepopulated_fields_js(self):\n        \"\"\"\n        prepopulated_fields_js should correctly serialize prepopulated fields to JSON.\n        \"\"\"\n        class MockField:\n                self.auto_id = auto_id\n                self.name = name\n                self.field = self\n                self.max_length = max_length\n                self.allow_unicode = allow_unicode\n\n        class MockAdminForm:\n                self.prepopulated_fields = prepopulated_fields\n\n        context = {\n            \"adminform\": MockAdminForm(\n                prepopulated_fields=[\n                    {\n                        \"field\": MockField(\"id_title\", \"title\"),\n                        \"dependencies\": [MockField(\"id_slug\", \"slug\")],\n                    }\n                ]\n            ),\n            \"inline_admin_formsets\": [],\n        }\n        updated_context = prepopulated_fields_js(context)\n        expected_json = json.dumps(\n            [\n                {\n                    \"id\": \"#id_title\",\n                    \"name\": \"title\",\n                    \"dependency_ids\": [\"#id_slug\"],\n                    \"dependency_list\": [\"slug\"],\n                    \"maxLength\": 50,\n                    \"allowUnicode\": False,\n                }\n            ]\n        )\n        self.assertEqual(updated_context[\"prepopulated_fields_json\"], expected_json)\n"], "sample_86": ["def test_bin_xml_escape():\n    from _pytest.junitxml import bin_xml_escape\n\n    # Test escaping of invalid XML characters\n    invalid_chars = \"\\x00\\x01\\x0B\\x0C\\x0E\\x19\\xD800\\xDFFF\\xFFFE\\xFFFF\"\n    escaped = bin_xml_escape(invalid_chars).uniobj\n    assert \"#x00\" in escaped\n    assert \"#x01\" in escaped\n    assert \"#x0B\" in escaped\n    assert \"#x0C\" in escaped\n    assert \"#x0E\" in escaped\n    assert \"#x19\" in escaped\n    assert \"#xD800\" in escaped\n    assert \"#xDFFF\" in escaped\n    assert \"#xFFFE\" in escaped\n    assert \"#xFFFF\" in escaped\n\n    # Test escaping of valid XML characters\n    valid_chars = \"\\x09\\x0A\\x20\\x7E\\x80\\xD7FF\\xE000\\xFFFD\\x10000\\x10FFFF\"\n    escaped = bin_xml_escape(valid_chars).uniobj\n    assert \"\\x09\" in escaped\n    assert \"\\x0A\" in escaped\n    assert \"\\x20\" in escaped\n    assert \"\\x7E\" in escaped\n    assert \"\\x80\" in escaped\n    assert \"\\uD7FF\" in escaped\n    assert \"\\uE000\" in escaped\n    assert \"\\uFFFD\" in escaped\n    assert \"\\U00010000\" in escaped\n    assert \"\\U0010FFFF\" in escaped\n"], "sample_76": ["    def test_different_orders(self, df):\n\n        groupby = GroupBy([\"group\"])\n        \n        for order in range(1, 4):\n            res = PolyFit(order=order, gridsize=100)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n            assert_array_equal(res.columns, [\"x\", \"y\"])\n\n            grid = np.linspace(df[\"x\"].min(), df[\"x\"].max(), 100)\n            assert_array_equal(res[\"x\"], grid)\n            if order == 1:\n                assert_array_almost_equal(\n                    res[\"y\"].diff().diff().dropna(), np.zeros(grid.size - 2)\n                )\n            else:\n                assert res[\"y\"].diff().diff().dropna().abs().gt(0).all()\n"], "sample_19": ["    def setUp(self):\n        self.filter = SafeExceptionReporterFilter()\n"], "sample_118": ["def test_ccode_AugmentedAssignment():\n    assert ccode(aug_assign(x, '+', y)) == 'x += y;'\n    assert ccode(aug_assign(x, '-', y)) == 'x -= y;'\n    assert ccode(aug_assign(x, '*', y)) == 'x *= y;'\n    assert ccode(aug_assign(x, '/', y)) == 'x /= y;'\n    assert ccode(aug_assign(x, '%', y)) == 'x %= y;'\n    assert ccode(aug_assign(x, '<<', y)) == 'x <<= y;'\n    assert ccode(aug_assign(x, '>>', y)) == 'x >>= y;'\n    assert ccode(aug_assign(x, '&', y)) == 'x &= y;'\n    assert ccode(aug_assign(x, '^', y)) == 'x ^= y;'\n    assert ccode(aug_assign(x, '|', y)) == 'x |= y;'\n"], "sample_152": ["def test_array_arithmetic_operations():\n    for ArrayType in array_types:\n        a = ArrayType([1, 2, 3, 4], (2, 2))\n        b = ArrayType([5, 6, 7, 8], (2, 2))\n\n        # Test addition\n        c = a + b\n        assert c.tolist() == [[6, 8], [10, 12]]\n\n        # Test subtraction\n        d = b - a\n        assert d.tolist() == [[4, 4], [4, 4]]\n\n        # Test scalar multiplication\n        e = a * 2\n        assert e.tolist() == [[2, 4], [6, 8]]\n\n        # Test scalar division\n        f = b / 2\n        assert f.tolist() == [[2.5, 3], [3.5, 4]]\n\n        # Test negation\n        g = -a\n        assert g.tolist() == [[-1, -2], [-3, -4]]\n\n        # Test equality\n        assert a == ArrayType([1, 2, 3, 4], (2, 2))\n        assert a != b\n"], "sample_143": ["def test_pretty_ImaginaryUnit():\n    expr = I\n    ascii_str = \"I\"\n    ucode_str = \"\u2148\"\n    assert pretty(expr) == ascii_str\n    assert upretty(expr) == ucode_str\n\n    expr = I**2\n    ascii_str = \"-1\"\n    ucode_str = \"-1\"\n    assert pretty(expr) == ascii_str\n    assert upretty(expr) == ucode_str\n\n    expr = I**3\n    ascii_str = \"-I\"\n    ucode_str = \"-\u2148\"\n    assert pretty(expr) == ascii_str\n    assert upretty(expr) == ucode_str\n\n    expr = I**4\n    ascii_str = \"1\"\n    ucode_str = \"1\"\n    assert pretty(expr) == ascii_str\n    assert upretty(expr) == ucode_str\n\n    expr = I**5\n    ascii_str = \"I\"\n    ucode_str = \"\u2148\"\n    assert pretty(expr) == ascii_str\n    assert upretty(expr) == ucode_str\n\n    expr = I**6\n    ascii_str = \"-1\"\n    ucode_str = \"-1\"\n    assert pretty(expr) == ascii_str\n    assert upretty(expr) == ucode_str\n\n    expr = I**7\n    ascii_str = \"-I\"\n    ucode_str = \"-\u2148\"\n    assert pretty(expr) == ascii_str\n    assert upretty(expr) == ucode_str\n\n    expr = I**8\n    ascii_str = \"1\"\n    ucode_str = \"1\"\n    assert pretty(expr) == ascii_str\n    assert upretty(expr) == ucode_str\n\n    expr = 1 + I\n    ascii_str = \"1 + I\"\n    ucode_str = \"1 + \u2148\"\n    assert pretty(expr) == ascii_str\n    assert upretty(expr) == ucode_str\n\n    expr = 1 - I\n    ascii_str = \"1 - I\"\n    ucode_str = \"1 - \u2148\"\n    assert pretty(expr) == ascii_str\n    assert upretty(expr) == ucode_str\n\n    expr = I + 1\n    ascii_str = \"I + 1\"\n    ucode_str = \"\u2148 + 1\"\n    assert pretty(expr) == ascii_str\n    assert upretty(expr) == ucode_str\n\n    expr ="], "sample_154": ["def test_lambdify_with_custom_printer():\n    class CustomPrinter(LambdaPrinter):\n            return f\"custom_{expr.name}\"\n\n    x, y = symbols('x y')\n    expr = x + y\n    f = lambdify((x, y), expr, printer=CustomPrinter)\n    assert f(1, 2) == 3\n    assert f(3, 4) == 7\n"], "sample_51": ["    def test_directory_index_template_does_not_exist(self):\n        \"\"\"Test directory index when custom template does not exist.\"\"\"\n        with override_settings(\n            TEMPLATES=[\n                {\n                    \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n                    \"OPTIONS\": {\n                        \"loaders\": [\n                            (\n                                \"django.template.loaders.locmem.Loader\",\n                                {},\n                            ),\n                        ],\n                    },\n                }\n            ]\n        ):\n            response = self.client.get(\"/%s/\" % self.prefix)\n            self.assertContains(response, \"Index of ./\")\n            self.assertIn(\"subdir/\", response.context[\"file_list\"])\n"], "sample_17": ["    def test_serialize_db_to_string(self, mocked_migrate, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        with mock.patch('django.core.serializers.serialize') as mock_serialize:\n            mock_serialize.return_value = '[]'\n            serialized_data = creation.serialize_db_to_string()\n            self.assertEqual(serialized_data, '[]')\n            mock_serialize.assert_called_once()\n"], "sample_48": ["    def test_create_model_with_bases(self):\n        \"\"\"\n        Tests the CreateModel operation with different bases.\n        \"\"\"\n        project_state = ProjectState()\n        operation = migrations.CreateModel(\n            \"FlyingPony\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"wingspan\", models.FloatField(default=2.5)),\n            ],\n            bases=(\"test_crmo.Pony\", Mixin),\n        )\n        self.assertEqual(operation.describe(), \"Create model FlyingPony\")\n        self.assertEqual(operation.migration_name_fragment, 'flyingpony')\n        # Test the state alteration\n        new_state = project_state.clone()\n        operation.state_forwards(\"test_crmo\", new_state)\n        self.assertEqual(new_state.models[\"test_crmo\", \"flyingpony\"].name, \"FlyingPony\")\n        self.assertEqual(len(new_state.models[\"test_crmo\", \"flyingpony\"].fields), 2)\n        # Test the database alteration\n        self.assertTableNotExists(\"test_crmo_flyingpony\")\n        with connection.schema_editor() as editor:\n            operation.database_forwards(\"test_crmo\", editor, project_state, new_state)\n        self.assertTableExists(\"test_crmo_flyingpony\")\n        # And test reversal\n        with connection.schema_editor() as editor:\n            operation.database_backwards(\"test_crmo\", editor, new_state, project_state)\n        self.assertTableNotExists(\"test_crmo_flyingpony\")\n        # And deconstruction\n        definition = operation.deconstruct()\n        self.assertEqual(definition[0], \"CreateModel\")\n        self.assertEqual(definition[1], [])\n        self.assertEqual(sorted(definition[2]), [\"bases\", \"fields\", \"name\"])\n"], "sample_124": ["def test_csch_rewrite_as_cosh():\n    x = Symbol('x')\n    assert csch(x).rewrite(cosh) == I / cosh(x + I * pi / 2)\n"], "sample_149": ["def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n"], "sample_130": ["def test_lambdastr():\n    from sympy.abc import a, b, c\n    expr = a + b + c\n    lambdastr_expr = lambdastr((a, b, c), expr)\n    assert lambdastr_expr == 'lambda a,b,c: (a + b + c)'\n    \n    expr_nested = a + b * c\n    lambdastr_expr_nested = lambdastr((a, (b, c)), expr_nested)\n    assert lambdastr_expr_nested == 'lambda _0,_1: (lambda a,b,c: (a + b*c))(_0,_1[0],_1[1])'\n    \n    expr_with_func = sin(a) + cos(b)\n    lambdastr_expr_with_func = lambdastr((a, b), expr_with_func)\n    assert lambdastr_expr_with_func == 'lambda a,b: (sin(a) + cos(b))'\n    \n    expr_with_dummy = a + b + c\n    lambdastr_expr_with_dummy = lambdastr((a, b, c), expr_with_dummy, dummify=True)\n    assert 'Dummy' in lambdastr_expr_with_dummy\n"], "sample_113": ["def test_column_transformer_with_callable_remainder():\n    # Test ColumnTransformer with a callable remainder\n    X_array = np.array([[0, 1, 2], [2, 4, 6], [8, 6, 4]]).T\n\n        return X * 2\n\n    ct = ColumnTransformer([(\"trans1\", Trans(), [0])], remainder=custom_remainder)\n\n    X_res_both = np.array([[0, 2, 4], [1, 8, 12], [2, 12, 8]]).T\n\n    assert_array_equal(ct.fit_transform(X_array), X_res_both)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_both)\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == \"remainder\"\n    assert callable(ct.transformers_[-1][1])\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n"], "sample_116": ["def test_create_index_with_symbols_and_unicode(app):\n    text = (\".. index:: single: @decorator\\n\"\n            \".. index:: single: #hashtag\\n\"\n            \".. index:: single: C++\\n\"\n            \".. index:: single: na\u00efve\\n\"\n            \".. index:: single: r\u00e9sum\u00e9\\n\"\n            \".. index:: single: caf\u00e9\\n\"\n            \".. index:: single: 123number\\n\"\n            \".. index:: single: *asterisk\\n\"\n            \".. index:: single: !exclamation\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 4\n    assert index[0] == ('Symbols', [('!exclamation', [[('', '#index-8')], [], None]),\n                                    ('#hashtag', [[('', '#index-1')], [], None]),\n                                    ('*asterisk', [[('', '#index-7')], [], None]),\n                                    ('@decorator', [[('', '#index-0')], [], None])])\n    assert index[1] == ('C', [('C++', [[('', '#index-2')], [], None]),\n                              ('caf\u00e9', [[('', '#index-5')], [], None])])\n    assert index[2] == ('N', [('na\u00efve', [[('', '#index-3')], [], None])])\n    assert index[3] == ('R', [('r\u00e9sum\u00e9', [[('', '#index-4')], [], None])])\n"], "sample_109": ["def test_leave_p_out():\n    # Test LeavePOut with p=2\n    X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n    y = np.array([1, 2, 3, 4])\n    lpo = LeavePOut(p=2)\n    \n    # Expected splits\n    expected_splits = [\n        (np.array([2, 3]), np.array([0, 1])),\n        (np.array([1, 3]), np.array([0, 2])),\n        (np.array([1, 2]), np.array([0, 3])),\n        (np.array([0, 3]), np.array([1, 2])),\n        (np.array([0, 2]), np.array([1, 3])),\n        (np.array([0, 1]), np.array([2, 3]))\n    ]\n    \n    splits = list(lpo.split(X, y))\n    assert len(splits) == len(expected_splits)\n    \n    for split, expected in zip(splits, expected_splits):\n        train, test = split\n        expected_train, expected_test = expected\n        assert_array_equal(train, expected_train)\n        assert_array_equal(test, expected_test)\n    \n    # Test get_n_splits\n    assert lpo.get_n_splits(X, y) == 6\n    \n    # Test with insufficient samples\n    X_small = np.array([[1, 2]])\n    with pytest.raises(ValueError, match=\"p=2 must be strictly less than the number of samples=1\"):\n        lpo.split(X_small, y)\n"], "sample_40": ["    def test_boundfield_as_widget(self):\n        class TestForm(Form):\n            name = CharField()\n            description = CharField(widget=Textarea)\n            hidden_field = CharField(widget=HiddenInput)\n\n        form = TestForm()\n        self.assertHTMLEqual(\n            form['name'].as_widget(),\n            '<input type=\"text\" name=\"name\" id=\"id_name\" required>'\n        )\n        self.assertHTMLEqual(\n            form['description'].as_widget(),\n            '<textarea name=\"description\" cols=\"40\" rows=\"10\" id=\"id_description\" required></textarea>'\n        )\n        self.assertHTMLEqual(\n            form['hidden_field'].as_widget(),\n            '<input type=\"hidden\" name=\"hidden_field\" id=\"id_hidden_field\">'\n        )\n        self.assertHTMLEqual(\n            form['name'].as_widget(attrs={'class': 'custom-class'}),\n            '<input type=\"text\" name=\"name\" class=\"custom-class\" id=\"id_name\" required>'\n        )\n        self.assertHTMLEqual(\n            form['description'].as_widget(attrs={'rows': 20}),\n            '<textarea name=\"description\" cols=\"40\" rows=\"20\" id=\"id_description\" required></textarea>'\n        )\n        self.assertHTMLEqual(\n            form['hidden_field'].as_widget(attrs={'data-test': 'hidden'}),\n            '<input type=\"hidden\" name=\"hidden_field\" data-test=\"hidden\" id=\"id_hidden_field\">'\n        )\n"], "sample_128": ["def test_Method_postprocess():\n    opt = {'method': 'some_method'}\n    Method.postprocess(opt)\n\n    assert opt == {'method': 'some_method'}\n"], "sample_73": ["def test_offsetbox_set_offset_callable():\n    # Test OffsetBox set_offset with a callable function\n    fig, ax = plt.subplots()\n    size = 100\n    da = DrawingArea(size, size, clip=True)\n    bg = mpatches.Rectangle((0, 0), size, size,\n                            facecolor='#CCCCCC',\n                            edgecolor='None',\n                            linewidth=0)\n    line = mlines.Line2D([-size*.5, size*1.5], [size/2, size/2],\n                         color='black',\n                         linewidth=10)\n    anchored_box = AnchoredOffsetbox(\n        loc='center',\n        child=da,\n        pad=0.,\n        frameon=False,\n        bbox_to_anchor=(.5, .5),\n        bbox_transform=ax.transAxes,\n        borderpad=0.)\n\n    da.add_artist(bg)\n    da.add_artist(line)\n    ax.add_artist(anchored_box)\n\n        return (width / 2, height / 2)\n\n    da.set_offset(offset_func)\n    fig.canvas.draw()\n\n    renderer = fig.canvas.get_renderer()\n    bbox = da.get_bbox(renderer)\n    offset = da.get_offset(bbox, renderer)\n    assert offset == (size / 2, size / 2)\n"], "sample_111": ["def test_empty_labels(metric):\n    # Test that all supervised metrics handle empty labels correctly\n    assert metric([], []) == 1.0\n"], "sample_151": ["def test_point3D_direction_cosine_ratio():\n    p1 = Point3D(1, 2, 3)\n    p2 = Point3D(4, 5, 6)\n    \n    # Test direction cosine\n    cosines = p1.direction_cosine(p2)\n    assert cosines == [sqrt(3)/3, sqrt(3)/3, sqrt(3)/3]\n    \n    # Test direction ratio\n    ratios = p1.direction_ratio(p2)\n    assert ratios == [3, 3, 3]\n"], "sample_54": ["    def test_avoid_wrapping(self):\n        items = (\n            (\"Hello world\", \"Hello\\xa0world\"),\n            (\"This is a test\", \"This\\xa0is\\xa0a\\xa0test\"),\n            (\"Avoid wrapping\", \"Avoid\\xa0wrapping\"),\n            (\"No spaces\", \"No\\xa0spaces\"),\n            (\"Multiple   spaces\", \"Multiple\\xa0\\xa0\\xa0spaces\"),\n        )\n        for value, output in items:\n            with self.subTest(value=value, output=output):\n                self.check_output(avoid_wrapping, value, output)\n                self.check_output(avoid_wrapping, lazystr(value), output)\n"], "sample_148": ["def test_polar_lift():\n    from sympy import polar_lift, exp_polar, pi\n\n    x = Symbol('x')\n    p = Symbol('p', positive=True)\n    n = Symbol('n', negative=True)\n\n    assert polar_lift(1) == 1 * exp_polar(0)\n    assert polar_lift(-1) == 1 * exp_polar(I * pi)\n    assert polar_lift(I) == exp_polar(I * pi / 2)\n    assert polar_lift(-I) == exp_polar(-I * pi / 2)\n    assert polar_lift(2 * I) == 2 * exp_polar(I * pi / 2)\n    assert polar_lift(-2 * I) == 2 * exp_polar(-I * pi / 2)\n    assert polar_lift(x) == x * exp_polar(0)\n    assert polar_lift(p) == p\n    assert polar_lift(n) == -n * exp_polar(I * pi)\n    assert polar_lift(2 * x) == 2 * polar_lift(x)\n    assert polar_lift(2 * p) == 2 * p\n    assert polar_lift(2 * n) == 2 * polar_lift(n)\n    assert polar_lift(2 * I * x) == 2 * polar_lift(I * x)\n    assert polar_lift(2 * I * p) == 2 * I * p\n    assert polar_lift(2 * I * n) == 2 * polar_lift(I * n)\n    assert polar_lift(2 * x * I) == 2 * polar_lift(x * I)\n    assert polar_lift(2 * p * I) == 2 * p * I\n    assert polar_lift(2 * n * I) == 2 * polar_lift(n * I)\n    assert polar_lift(2 * x * n) == 2 * polar_lift(x * n)\n    assert polar_lift(2 * p * n) == 2 * polar_lift(p * n)\n    assert polar_lift(2 * n * n) == 2 * polar_lift(n * n)\n"], "sample_155": ["def test_get_units_non_prefixed():\n    # Create some quantities with and without prefixes\n    meter = Quantity(\"meter\")\n    kilometer = Quantity(\"kilometer\")\n    kilometer.set_global_relative_scale_factor(kilo, meter)\n    second = Quantity(\"second\")\n    millisecond = Quantity(\"millisecond\")\n    millisecond.set_global_relative_scale_factor(S.One/1000, second)\n    joule = Quantity(\"joule\")\n    kilojoule = Quantity(\"kilojoule\")\n    kilojoule.set_global_relative_scale_factor(kilo, joule)\n\n    # Create a UnitSystem with these quantities\n    us = UnitSystem(base_units=(meter, second), units=(kilometer, millisecond, joule, kilojoule))\n\n    # Get non-prefixed units\n    non_prefixed_units = us.get_units_non_prefixed()\n\n    # Check that only non-prefixed units are returned\n    assert meter in non_prefixed_units\n    assert second in non_prefixed_units\n    assert joule in non_prefixed_units\n    assert kilometer not in non_prefixed_units\n    assert millisecond not in non_prefixed_units\n    assert kilojoule not in non_prefixed_units\n"], "sample_83": ["def test_colorize_ansi():\n    \"\"\"Test the colorize_ansi function with various styles and colors.\"\"\"\n    msg = \"Test message\"\n    style = MessageStyle(\"red\", (\"bold\", \"underline\"))\n    colored_msg = colorize_ansi(msg, style)\n    assert colored_msg == \"\\033[1;4;31mTest message\\033[0m\"\n\n    style = MessageStyle(None, (\"italic\",))\n    colored_msg = colorize_ansi(msg, style)\n    assert colored_msg == \"\\033[3mTest message\\033[0m\"\n\n    style = MessageStyle(\"blue\", ())\n    colored_msg = colorize_ansi(msg, style)\n    assert colored_msg == \"\\033[34mTest message\\033[0m\"\n\n    style = MessageStyle(None, ())\n    colored_msg = colorize_ansi(msg, style)\n    assert colored_msg == \"Test message\"\n\n    # Test deprecated usage\n    with warnings.catch_warnings(record=True) as w:\n        warnings.simplefilter(\"always\")\n        colored_msg = colorize_ansi(msg, \"green\", \"bold\")\n        assert colored_msg == \"\\033[1;32mTest message\\033[0m\"\n        assert len(w) == 1\n        assert issubclass(w[-1].category, DeprecationWarning)\n"], "sample_43": ["    def test_invalid_app_label(self):\n        request = self.factory.get(self.url, {'term': 'is', 'app_label': 'invalid_app', 'model_name': 'Answer', 'field_name': 'question'})\n        request.user = self.superuser\n        with self.assertRaises(PermissionDenied):\n            AutocompleteJsonView.as_view(**self.as_view_args)(request)\n"], "sample_137": ["def test_ibin():\n    assert ibin(2) == [1, 0]\n    assert ibin(2, 4) == [0, 0, 1, 0]\n    assert ibin(2, 4)[::-1] == [0, 1, 0, 0]\n    assert list(ibin(2, 'all')) == [(0, 0), (0, 1), (1, 0), (1, 1)]\n    assert ibin(123, 10, str=True) == '0001111011'\n    assert ibin(123, 10, str=True)[::-1] == '1101111000'\n    assert list(ibin(3, 'all', str=True)) == ['000', '001', '010', '011', '100', '101', '110', '111']\n"], "sample_68": ["    def setUp(self):\n        self.country1 = Country.objects.create(name=\"Country1\", iso_two_letter=\"C1\")\n        self.country2 = Country.objects.create(name=\"Country2\", iso_two_letter=\"C2\")\n        self.country3 = Country.objects.create(name=\"Country3\", iso_two_letter=\"C3\")\n"], "sample_119": ["def test_Sum():\n    assert mcode(Sum(x, (x, 1, 10))) == \"Hold[Sum[x, {x, 1, 10}]]\"\n    assert mcode(Sum(x**2, (x, 0, 5))) == \"Hold[Sum[x^2, {x, 0, 5}]]\"\n    assert mcode(Sum(x*y, (x, 1, 5), (y, 1, 5))) == \"Hold[Sum[x*y, {x, 1, 5}, {y, 1, 5}]]\"\n"], "sample_79": ["def test_concat_with_positions():\n    ds1 = Dataset({\"a\": (\"x\", [1, 2, 3])})\n    ds2 = Dataset({\"a\": (\"x\", [4, 5, 6])})\n    ds3 = Dataset({\"a\": (\"x\", [7, 8, 9])})\n\n    # Concatenate with specified positions\n    actual = concat([ds1, ds2, ds3], dim=\"x\", positions=[[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n    expected = Dataset({\"a\": (\"x\", [1, 2, 3, 4, 5, 6, 7, 8, 9])})\n    assert_identical(actual, expected)\n\n    # Concatenate with overlapping positions\n    actual = concat([ds1, ds2, ds3], dim=\"x\", positions=[[0, 1, 2], [2, 3, 4], [4, 5, 6]])\n    expected = Dataset({\"a\": (\"x\", [1, 2, 3, 4, 5, 6, 7, 8, 9])})\n    assert_identical(actual, expected)\n\n    # Concatenate with gaps in positions\n    actual = concat([ds1, ds2, ds3], dim=\"x\", positions=[[0, 1, 2], [4, 5, 6], [8, 9, 10]])\n    expected = Dataset({\"a\": (\"x\", [1, 2, 3, np.nan, 4, 5, 6, np.nan, 7, 8, 9])})\n    assert_identical(actual, expected)\n"], "sample_77": ["    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n"], "sample_88": ["def test_safeformat():\n    class BrokenRepr:\n            raise ValueError(\"broken repr\")\n\n    class ComplexObject:\n            self.attr1 = \"value1\"\n            self.attr2 = BrokenRepr()\n\n    obj = ComplexObject()\n    formatted = safeformat(obj)\n    assert \"ComplexObject\" in formatted\n    assert \"broken repr\" in formatted\n"], "sample_21": ["    def test_set_callable(self):\n            return self.DEFAULT\n\n        a = create_a('set_callable')\n        a.set_callable = dynamic_value\n        a.save()\n        a.set_callable.delete()\n        a = A.objects.get(pk=a.pk)\n        self.assertEqual(self.DEFAULT, a.set_callable)\n"], "sample_52": ["    def test_create_model_with_duplicate_constraint_name(self):\n        \"\"\"\n        Tests the CreateModel operation with duplicate constraint names.\n        \"\"\"\n        constraint = models.CheckConstraint(check=models.Q(pink__gt=2), name=\"test_constraint\")\n        with self.assertRaisesMessage(\n            ValueError, \"Found duplicate value test_constraint in CreateModel options argument.\"\n        ):\n            migrations.CreateModel(\n                \"Pony\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\"pink\", models.IntegerField(default=3)),\n                ],\n                options={\"constraints\": [constraint, constraint]},\n            )\n"], "sample_69": ["def test_set_clip_path():\n    fig, ax = plt.subplots()\n    rect = mpatches.Rectangle((0, 0), 1, 1)\n    ax.add_patch(rect)\n\n    # Test setting clip path with a Rectangle\n    clip_rect = mpatches.Rectangle((0.5, 0.5), 0.5, 0.5)\n    rect.set_clip_path(clip_rect)\n    assert isinstance(rect.get_clip_path(), mtransforms.TransformedPatchPath)\n\n    # Test setting clip path with a Path\n    clip_path = mpath.Path.unit_circle()\n    rect.set_clip_path(clip_path, ax.transData)\n    assert isinstance(rect.get_clip_path(), mtransforms.TransformedPath)\n\n    # Test setting clip path with a TransformedPath\n    transformed_clip_path = mtransforms.TransformedPath(clip_path, ax.transData)\n    rect.set_clip_path(transformed_clip_path)\n    assert rect.get_clip_path() is transformed_clip_path\n\n    # Test setting clip path to None\n    rect.set_clip_path(None)\n    assert rect.get_clip_path() is None\n\n    # Test invalid clip path type\n    with pytest.raises(TypeError, match=\"Invalid arguments to set_clip_path\"):\n        rect.set_clip_path(\"invalid_clip_path\")\n"], "sample_121": ["def test_af_invert():\n    assert _af_invert([1, 0, 2]) == [1, 0, 2]\n    assert _af_invert([2, 0, 1]) == [1, 2, 0]\n    assert _af_invert([3, 2, 1, 0]) == [3, 2, 1, 0]\n    assert _af_invert([0, 1, 2, 3]) == [0, 1, 2, 3]\n    assert _af_invert([4, 3, 2, 1, 0]) == [4, 3, 2, 1, 0]\n"], "sample_58": ["    def test_no_dbname_no_service(self):\n        self.assertEqual(\n            self.settings_to_cmd_args_env(\n                {\n                    \"USER\": \"someuser\",\n                    \"PASSWORD\": \"somepassword\",\n                    \"HOST\": \"somehost\",\n                    \"PORT\": \"444\",\n                }\n            ),\n            (\n                [\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"postgres\"],\n                {\"PGPASSWORD\": \"somepassword\"},\n            ),\n        )\n"], "sample_126": ["def test_mpf_norm_special_cases():\n    # Test special cases for mpf_norm function\n    assert mpf_norm((0, 0, 0, 0), 10) == (0, 0, 0, 0)  # zero\n    assert mpf_norm((0, 1, 0, 1), 10) == (0, 1, 0, 1)  # one\n    assert mpf_norm((0, 1, 1, 1), 10) == (0, 1, 1, 1)  # two\n    assert mpf_norm((1, 1, 1, 1), 10) == (1, 1, 1, 1)  # negative two\n    assert mpf_norm((0, 1, -1, 1), 10) == (0, 1, -1, 1)  # half\n    assert mpf_norm((1, 1, -1, 1), 10) == (1, 1, -1, 1)  # negative half\n    assert mpf_norm((0, 0, 1, 0), 10) == (0, 0, 0, 0)  # zero with exponent\n    assert mpf_norm((0, 1, 0, 0), 10) == (0, 1, 0, 1)  # one with zero bits\n    assert mpf_norm((0, 1, 1, 0), 10) == (0, 1, 1, 1)  # two with zero bits\n    assert mpf_norm((1, 1, 1, 0), 10) == (1, 1, 1, 1)  # negative two with zero bits\n"], "sample_41": ["    def test_management_form_cleaned_data_defaults(self):\n        \"\"\"\n        Test that the management form sets default values for TOTAL_FORM_COUNT\n        and INITIAL_FORM_COUNT when they are missing or invalid.\n        \"\"\"\n        data = {\n            'choices-TOTAL_FORMS': '',  # empty value\n            'choices-INITIAL_FORMS': '',  # empty value\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-MAX_NUM_FORMS': '0',\n        }\n        formset = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(formset.management_form.cleaned_data[TOTAL_FORM_COUNT], 0)\n        self.assertEqual(formset.management_form.cleaned_data[INITIAL_FORM_COUNT], 0)\n"], "sample_94": ["def test_source_from_multiline_string() -> None:\n    multiline_string = \"\"\"\\\n        return '''This is a\n        multiline string\n        with indentation'''\n    \"\"\"\n    source = Source(multiline_string)\n    assert source.lines == [\n        \"def foo():\",\n        \"    return '''This is a\",\n        \"    multiline string\",\n        \"    with indentation'''\"\n    ]\n"], "sample_65": ["    def test_join09(self):\n        output = self.engine.render_to_string(\n            \"join09\", {\"a\": [\"alpha\", \"beta & me\"], \"var\": \" & \"}\n        )\n        self.assertEqual(output, \"ALPHA &AMP; BETA &AMP; ME\")\n"], "sample_72": ["def test_subplotparams_update():\n    params = SubplotParams(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)\n    assert params.left == 0.1\n    assert params.bottom == 0.1\n    assert params.right == 0.9\n    assert params.top == 0.9\n    assert params.wspace == 0.2\n    assert params.hspace == 0.2\n\n    params.update(left=0.2, bottom=0.2)\n    assert params.left == 0.2\n    assert params.bottom == 0.2\n    assert params.right == 0.9\n    assert params.top == 0.9\n    assert params.wspace == 0.2\n    assert params.hspace == 0.2\n\n    with pytest.raises(ValueError, match='left cannot be >= right'):\n        params.update(left=1.0)\n\n    with pytest.raises(ValueError, match='bottom cannot be >= top'):\n        params.update(bottom=1.0)\n"], "sample_122": ["def test_applyfunc():\n    # Test applyfunc with a simple lambda function\n    a = SparseMatrix(3, 3, lambda i, j: i + j)\n    b = a.applyfunc(lambda x: x * 2)\n    assert b == SparseMatrix(3, 3, lambda i, j: 2 * (i + j))\n\n    # Test applyfunc with a more complex function\n        return x**2 + 1\n\n    c = a.applyfunc(complex_func)\n    assert c == SparseMatrix(3, 3, lambda i, j: (i + j)**2 + 1)\n\n    # Test applyfunc with a function that returns zero for some elements\n    d = a.applyfunc(lambda x: x if x % 2 == 0 else 0)\n    assert d == SparseMatrix(3, 3, {(0, 0): 0, (0, 2): 2, (1, 1): 2, (2, 0): 2, (2, 2): 4})\n\n    # Test applyfunc with a function that returns non-zero for some elements\n    e = a.applyfunc(lambda x: x if x % 2 != 0 else 1)\n    assert e == SparseMatrix(3, 3, {(0, 1): 1, (0, 2): 1, (1, 0): 1, (1, 2): 1, (2, 1): 1})\n\n    # Test applyfunc with a function that returns a constant\n    f = a.applyfunc(lambda x: 5)\n    assert f == SparseMatrix(3, 3, lambda i, j: 5)\n\n    # Test applyfunc with a function that returns a different type\n    g = a.applyfunc(lambda x: float(x))\n    assert g == SparseMatrix(3, 3, lambda i, j: float(i + j))\n\n    # Test applyfunc with a non-callable argument\n    raises(TypeError, lambda: a.applyfunc(5))\n"], "sample_91": ["def test_evaluate_condition_syntax_error(testdir):\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.skipif(\"invalid syntax\")\n            pass\n    \"\"\"\n    )\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_condition(item, item.get_closest_marker(\"skipif\"), \"invalid syntax\")\n    assert \"SyntaxError: invalid syntax\" in excinfo.value.msg\n"], "sample_115": ["def test__wrap_data_with_container():\n    \"\"\"Check _wrap_data_with_container works as expected.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    original_input = pd.DataFrame(X, columns=[\"a\", \"b\", \"c\"])\n\n    est = EstimatorWithSetOutput().fit(X)\n    est.set_output(transform=\"pandas\")\n\n    wrapped_data = _wrap_data_with_container(\"transform\", X, original_input, est)\n    assert isinstance(wrapped_data, pd.DataFrame)\n    assert_array_equal(wrapped_data.columns, [\"X0\", \"X1\", \"X2\"])\n    assert_array_equal(wrapped_data.index, original_input.index)\n\n    est.set_output(transform=\"default\")\n    wrapped_data = _wrap_data_with_container(\"transform\", X, original_input, est)\n    assert isinstance(wrapped_data, np.ndarray)\n    assert_array_equal(wrapped_data, X)\n"], "sample_15": ["    def test_consistent_language_settings(self):\n        for tag in ['en', 'fr']:\n            with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n                self.assertEqual(check_language_settings_consistent(None), [])\n"], "sample_12": ["    def test_alter_field_with_check_constraint(self):\n        \"\"\"Tests autodetection of altering a field with a check constraint.\"\"\"\n        changes = self.get_changes([self.author_name], [self.author_name_check_constraint])\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, [\"AddConstraint\"])\n        self.assertOperationAttributes(\n            changes, 'testapp', 0, 0, model_name='author',\n            constraint=models.CheckConstraint(check=models.Q(name__contains='Bob'), name='name_contains_bob')\n        )\n"], "sample_100": ["def test_ordinal_encoder_handle_unknown():\n    X = np.array([['a', 'b'], ['c', 'd']], dtype=object)\n    X2 = np.array([['a', 'e'], ['c', 'f']], dtype=object)\n\n    # Test that ordinal encoder raises error for unknown features\n    # present during transform.\n    oe = OrdinalEncoder(categories=[['a', 'b', 'c', 'd']])\n    oe.fit(X)\n    with pytest.raises(ValueError, match=\"Found unknown categories\"):\n        oe.transform(X2)\n\n    # Test the ignore option, ignores unknown features (giving all 0's)\n    oe = OrdinalEncoder(categories=[['a', 'b', 'c', 'd']], handle_unknown='ignore')\n    oe.fit(X)\n    X2_transformed = oe.transform(X2)\n    expected = np.array([[0., 0.], [2., 0.]])\n    assert_array_equal(X2_transformed, expected)\n"], "sample_81": ["    def test_encoding_error(self) -> None:\n        code = b\"\"\"# coding: invalid-encoding\n                a = 1\n                \"\"\"\n        with self.assertAddsMessages(\n            MessageTest(\n                msg_id=\"syntax-error\",\n                line=1,\n                args=\"Cannot decode using encoding 'invalid-encoding', bad encoding\",\n            )\n        ):\n            self.checker.process_module(self._module_node_from_bytes(code))\n"], "sample_4": ["    def test_file_response(self):\n        filename = os.path.join(os.path.dirname(__file__), 'abc.txt')\n        with open(filename, 'wb') as f:\n            f.write(b'file content')\n\n        with open(filename, 'rb') as f:\n            response = FileResponse(f, as_attachment=True, filename='abc.txt')\n            self.assertEqual(response.status_code, 200)\n            self.assertEqual(response['Content-Disposition'], 'attachment; filename=\"abc.txt\"')\n            self.assertEqual(response['Content-Type'], 'application/octet-stream')\n            self.assertEqual(response['Content-Length'], str(os.path.getsize(filename)))\n\n        os.remove(filename)\n"], "sample_1": ["def test_inconsistent_columns():\n    example_qdp = \"\"\"\n    ! Initial comment line 1\n    ! Initial comment line 2\n    READ TERR 1\n    READ SERR 3\n    ! Table 0 comment\n    !a a(pos) a(neg) b c ce d\n    53000.5   0.25  -0.5   1  1.5  3.5 2\n    54000.5   1.25  -1.5   2  2.5  4.5 3\n    NO NO NO NO NO\n    ! Table 1 comment\n    !a a(pos) a(neg) b c ce d\n    54000.5   2.25  -2.5   NO  3.5  5.5 5\n    55000.5   3.25  -3.5   4  4.5  6.5 nan\n    ! Inconsistent number of columns\n    56000.5   4.25  -4.5   5  5.5  7.5\n    \"\"\"\n    with pytest.raises(ValueError, match=\"Inconsistent number of columns\"):\n        Table.read(example_qdp, format=\"ascii.qdp\", table_id=1, names=[\"a\", \"b\", \"c\", \"d\"])\n"], "sample_102": ["def test_iforest_predict():\n    \"\"\"Test the predict method of IsolationForest.\"\"\"\n    rng = check_random_state(42)\n    X_train = rng.randn(100, 2)\n    X_test = rng.randn(20, 2)\n\n    clf = IsolationForest(n_estimators=10, random_state=rng).fit(X_train)\n    predictions = clf.predict(X_test)\n\n    # Check that predictions are either -1 or 1\n    assert np.all(np.isin(predictions, [-1, 1]))\n\n    # Check that the number of outliers is consistent with the contamination parameter\n    contamination = clf.contamination if clf.contamination != \"auto\" else 0.1\n    n_outliers = np.sum(predictions == -1)\n    expected_outliers = int(contamination * X_test.shape[0])\n    assert abs(n_outliers - expected_outliers) <= 2  # Allow some tolerance\n"], "sample_139": ["def test_polar_lift():\n    from sympy import polar_lift, exp_polar, I, pi, symbols\n\n    x, y = symbols('x y')\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(I + 2) == polar_lift(2 + I)\n\n    p = Symbol('p', polar=True)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*p) == 4*p\n\n    assert polar_lift(1 + I) == polar_lift(1 + I)\n    assert polar_lift(x + y*I) == polar_lift(x + y*I)\n    assert polar_lift(x*y) == polar_lift(x*y)\n    assert polar_lift(x/y) == polar_lift(x/y)\n    assert polar_lift(x**y) == polar_lift(x**y)\n"], "sample_125": ["def test_mpf_norm_special_cases():\n    # Test special cases for mpf_norm function\n    assert mpf_norm((1, 0, 0, 0), 10) == (0, 0, 0, 0)  # zero mantissa and exponent\n    assert mpf_norm((1, 1, 0, 0), 10) == (1, 1, 0, 0)  # non-zero mantissa, zero exponent\n    assert mpf_norm((1, 1, 1, 0), 10) == (1, 1, 1, 0)  # non-zero mantissa and exponent\n    assert mpf_norm((1, 0, 1, 0), 10) == (0, 0, 0, 0)  # zero mantissa, non-zero exponent\n    assert mpf_norm((1, 1, 1, 1), 10) == (1, 1, 1, 1)  # non-zero mantissa and exponent with non-zero bit count\n    assert mpf_norm((1, 0, 0, 1), 10) == (0, 0, 0, 0)  # zero mantissa, zero exponent, non-zero bit count\n    assert mpf_norm((1, 1, 0, 1), 10) == (1, 1, 0, 1)  # non-zero mantissa, zero exponent, non-zero bit count\n    assert mpf_norm((1, 0, 1, 1), 10) == (0, 0, 0, 0)  # zero mantissa, non-zero exponent, non-zero bit count\n"], "sample_131": ["def test_Sum():\n    assert mcode(Sum(x, (x, 1, 10))) == \"Hold[Sum[x, {x, 1, 10}]]\"\n    assert mcode(Sum(x**2, (x, 0, 5))) == \"Hold[Sum[x^2, {x, 0, 5}]]\"\n    assert mcode(Sum(x*y, (x, 1, 3), (y, 1, 2))) == \"Hold[Sum[x*y, {x, 1, 3}, {y, 1, 2}]]\"\n"], "sample_29": ["    def setUp(self):\n        self.sql = \"SELECT * FROM test_table WHERE id = %s\"\n        self.using = DEFAULT_DB_ALIAS\n        self.params = (1,)\n        self.raw_query = RawQuery(self.sql, self.using, self.params)\n"], "sample_32": ["    def test_key_transform_preprocess_lhs(self):\n        transform = KeyTransform('key', 'value')\n        compiler = mock.Mock()\n        connection = mock.Mock()\n        connection.vendor = 'postgresql'\n        lhs, params, key_transforms = transform.preprocess_lhs(compiler, connection)\n        self.assertEqual(lhs, compiler.compile.return_value[0])\n        self.assertEqual(params, compiler.compile.return_value[1])\n        self.assertEqual(key_transforms, ['key'])\n"], "sample_62": ["    def setUp(self):\n        super().setUp()\n        self.dirname = tempfile.mkdtemp()\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n"], "sample_33": ["    def test_disconnect_with_dispatch_uid(self):\n            return val\n\n        a_signal.connect(receiver_with_uid, dispatch_uid=\"unique_id\")\n        self.assertTrue(a_signal.has_listeners())\n        disconnected = a_signal.disconnect(dispatch_uid=\"unique_id\")\n        self.assertTrue(disconnected)\n        self.assertTestIsClean(a_signal)\n"], "sample_93": ["def test_get_user_with_env_vars(monkeypatch):\n    \"\"\"Test that get_user() function correctly returns the user name when environment variables are set.\"\"\"\n    monkeypatch.setenv(\"USER\", \"testuser\")\n    assert get_user() == \"testuser\"\n    monkeypatch.delenv(\"USER\", raising=False)\n    monkeypatch.setenv(\"USERNAME\", \"testuser2\")\n    assert get_user() == \"testuser2\"\n"], "sample_42": ["    def test_serialize_custom_deconstructable(self):\n        @deconstructible\n        class CustomDeconstructible:\n                self.param1 = param1\n                self.param2 = param2\n\n                return (\n                    'migrations.test_writer.CustomDeconstructible',\n                    [self.param1, self.param2],\n                    {}\n                )\n\n        instance = CustomDeconstructible('value1', 'value2')\n        string, imports = MigrationWriter.serialize(instance)\n        self.assertEqual(\n            string,\n            \"migrations.test_writer.CustomDeconstructible('value1', 'value2')\"\n        )\n        self.assertEqual(imports, {'import migrations.test_writer'})\n        self.assertEqual(self.serialize_round_trip(instance), instance)\n"], "sample_142": ["def test_ibin():\n    assert ibin(2) == [1, 0]\n    assert ibin(2, 4) == [0, 0, 1, 0]\n    assert list(ibin(2, 'all')) == [(0, 0), (0, 1), (1, 0), (1, 1)]\n    assert ibin(123, 10, str=True) == '0001111011'\n    assert ibin(123, 10, str=True)[::-1] == '1101111000'\n    assert list(ibin(3, 'all', str=True)) == ['000', '001', '010', '011', '100', '101', '110', '111']\n    raises(ValueError, lambda: ibin(-1))\n    raises(ValueError, lambda: ibin(2, -1))\n"], "sample_120": ["def test_as_real_imag():\n    A = MatrixSymbol('A', n, m)\n    real, imag = A.as_real_imag()\n    assert real == (S(1)/2) * (A + A._eval_conjugate())\n    assert imag == (A - A._eval_conjugate()) / (2 * S.ImaginaryUnit)\n"], "sample_14": ["    def test_serialize_functools_partial_with_kwargs(self):\n        value = functools.partial(datetime.timedelta, days=1, seconds=2)\n        result = self.serialize_round_trip(value)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n"], "sample_157": ["def test_tensor_product_trace():\n    assert TP(A, B)._eval_trace() == Tr(A).doit() * Tr(B).doit()\n    assert TP(A, B, C)._eval_trace(indices=[0, 2]) == Tr(A).doit() * B * Tr(C).doit()\n    assert TP(mat1, mat2)._eval_trace() == Tr(mat1).doit() * Tr(mat2).doit()\n    assert TP(mat1, mat2, mat1)._eval_trace(indices=[0, 2]) == Tr(mat1).doit() * mat2 * Tr(mat1).doit()\n"], "sample_110": ["def test_affinity_propagation_damping():\n    # Test AffinityPropagation with different damping factors\n    S = -euclidean_distances(X, squared=True)\n    preference = np.median(S) * 10\n\n    # Test with damping factor at the lower bound\n    af = AffinityPropagation(preference=preference, damping=0.5, affinity=\"precomputed\")\n    labels_low_damping = af.fit(S).labels_\n    assert len(np.unique(labels_low_damping)) == n_clusters\n\n    # Test with damping factor at the upper bound\n    af = AffinityPropagation(preference=preference, damping=0.99, affinity=\"precomputed\")\n    labels_high_damping = af.fit(S).labels_\n    assert len(np.unique(labels_high_damping)) == n_clusters\n\n    # Test with an invalid damping factor (should raise ValueError)\n    with pytest.raises(ValueError):\n        AffinityPropagation(preference=preference, damping=1.0, affinity=\"precomputed\").fit(S)\n"], "sample_136": ["def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', n, n)\n    X = BlockMatrix([[A, B], [C, D]])\n\n    real_X, imag_X = X.as_real_imag()\n    assert real_X == BlockMatrix([[re(A), re(B)], [re(C), re(D)]])\n    assert imag_X == BlockMatrix([[im(A), im(B)], [im(C), im(D)]])\n"], "sample_80": ["def test_wrap_indent():\n    text = \"This is a test string\\nwith multiple lines\\nand indentation.\"\n    start = \">> \"\n    length = 4\n    expected = \">> This is a test string\\n    with multiple lines\\n    and indentation.\"\n    actual = formatting.wrap_indent(text, start, length)\n    assert expected == actual\n\n    text = \"Single line text\"\n    start = \"-- \"\n    expected = \"-- Single line text\"\n    actual = formatting.wrap_indent(text, start)\n    assert expected == actual\n\n    text = \"\"\n    start = \">> \"\n    expected = \">> \"\n    actual = formatting.wrap_indent(text, start)\n    assert expected == actual\n"], "sample_99": ["def test_check_weights():\n    # Test the _check_weights function\n    assert_equal(_check_weights(None), None)\n    assert_equal(_check_weights('uniform'), 'uniform')\n    assert_equal(_check_weights('distance'), 'distance')\n    \n        return dist ** -2\n    \n    assert_equal(_check_weights(custom_weights), custom_weights)\n    \n    with assert_raises(ValueError):\n        _check_weights('invalid')\n"], "sample_6": ["    def test_ascii_validator(self):\n        valid_usernames = ['joe', 'john_doe', 'jane.doe', 'user+name', 'user-name', 'user@name']\n        invalid_usernames = [\n            \"o'connell\", \"user name\", \"user!name\", \"user#name\", \"user$name\", \"user%name\",\n            \"user^name\", \"user&name\", \"user*name\", \"user(name\", \"user)name\", \"user=name\",\n            \"user{name\", \"user}name\", \"user|name\", \"user\\\\name\", \"user/name\", \"user:name\",\n            \"user;name\", \"user'name\", \"user\\\"name\", \"user<name\", \"user>name\", \"user,name\",\n            \"user?name\", \"user~name\", \"user`name\", \"user[name\", \"user]name\"\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n"], "sample_66": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n"], "sample_25": ["    def test_alter_field_with_default(self):\n        \"\"\"Tests autodetection of altering a field to add a default value.\"\"\"\n        changes = self.get_changes([self.author_name], [self.author_name_default])\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\", preserve_default=True)\n        self.assertOperationFieldAttributes(changes, 'testapp', 0, 0, default='Ada Lovelace')\n"], "sample_63": ["    def test_get_context_no_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        context = widget.get_context(name=\"password\", value=None, attrs={})\n        self.assertIn(\"summary\", context)\n        self.assertEqual(context[\"summary\"], [{\"label\": gettext(\"No password set.\")}])\n"], "sample_96": ["def test_ridge_regression_return_n_iter():\n    # Test that ridge_regression returns the correct number of iterations\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 6, 5\n    X = rng.randn(n_samples, n_features)\n    y = rng.randn(n_samples)\n\n    for solver in [\"sparse_cg\", \"lsqr\", \"sag\", \"saga\"]:\n        coef, n_iter = ridge_regression(X, y, alpha=1.0, solver=solver, max_iter=100, tol=1e-3, return_n_iter=True)\n        assert n_iter is not None, f\"n_iter should not be None for solver {solver}\"\n        assert n_iter > 0, f\"n_iter should be greater than 0 for solver {solver}\"\n"], "sample_36": ["    def test_invert(self):\n        q = Q(price__gt=F('discounted_price'))\n        inverted_q = ~q\n        self.assertTrue(inverted_q.negated)\n        self.assertEqual(inverted_q.connector, Q.AND)\n        self.assertEqual(inverted_q.children, [q])\n"], "sample_78": ["def test_find_app_by_string():\n    class Module:\n        app = Flask(\"appname\")\n        create_app = lambda: Flask(\"created_app\")\n        make_app = lambda: Flask(\"made_app\")\n        app_with_args = lambda x: Flask(f\"app_{x}\")\n        app_with_kwargs = lambda x, y: Flask(f\"app_{x}_{y}\")\n\n    assert find_app_by_string(Module, \"app\") == Module.app\n    assert find_app_by_string(Module, \"create_app\") == Module.create_app()\n    assert find_app_by_string(Module, \"make_app\") == Module.make_app()\n    assert find_app_by_string(Module, \"app_with_args('test')\").name == \"app_test\"\n    assert find_app_by_string(Module, \"app_with_kwargs(x='foo', y='bar')\").name == \"app_foo_bar\"\n\n    with pytest.raises(NoAppException):\n        find_app_by_string(Module, \"non_existent_app\")\n\n    with pytest.raises(NoAppException):\n        find_app_by_string(Module, \"app_with_args()\")\n\n    with pytest.raises(NoAppException):\n        find_app_by_string(Module, \"app_with_kwargs(x='foo')\")\n"], "sample_2": ["def test_wcs_copy():\n    \"\"\"\n    Test the copy and deepcopy methods of the WCS class.\n    \"\"\"\n    header = get_pkg_data_contents('data/sip.fits', encoding='binary')\n    w = wcs.WCS(header)\n\n    # Test shallow copy\n    w_copy = w.copy()\n    assert w.wcs.compare(w_copy.wcs)\n    assert w.sip.a_order == w_copy.sip.a_order\n    assert w.sip.b_order == w_copy.sip.b_order\n\n    # Test deep copy\n    w_deepcopy = w.deepcopy()\n    assert w.wcs.compare(w_deepcopy.wcs)\n    assert w.sip.a_order == w_deepcopy.sip.a_order\n    assert w.sip.b_order == w_deepcopy.sip.b_order\n\n    # Modify the original and ensure the copies are unaffected\n    w.wcs.crval = [0, 0]\n    assert not w.wcs.compare(w_copy.wcs)\n    assert not w.wcs.compare(w_deepcopy.wcs)\n    assert w_copy.wcs.crval != [0, 0]\n    assert w_deepcopy.wcs.crval != [0, 0]\n"], "sample_71": ["def test_remove_blacklisted_style_params():\n    settings = {\n        'interactive': True,\n        'backend': 'Agg',\n        'image.cmap': 'viridis',\n        'figure.max_open_warning': 0,\n        'axes.titlesize': 'large'\n    }\n    expected = {\n        'image.cmap': 'viridis',\n        'axes.titlesize': 'large'\n    }\n    result = style.core._remove_blacklisted_style_params(settings)\n    assert result == expected\n"], "sample_26": ["    def test_create_test_db(self):\n        test_connection = get_connection_copy()\n        creation = BaseDatabaseCreation(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db') as mock_create_test_db, \\\n                 mock.patch.object(creation, 'log') as mock_log, \\\n                 mock.patch('django.core.management.call_command') as mock_call_command:\n                test_db_name = creation.create_test_db(verbosity=2, autoclobber=True, serialize=True, keepdb=False)\n                self.assertEqual(test_db_name, creation._get_test_db_name())\n                mock_create_test_db.assert_called_once_with(2, True, False)\n                mock_log.assert_any_call('Creating test database for alias \\'default\\' (\\'%s\\')...' % test_db_name)\n                mock_call_command.assert_any_call('migrate', verbosity=1, interactive=False, database=test_connection.alias, run_syncdb=True)\n                mock_call_command.assert_any_call('createcachetable', database=test_connection.alias)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n"], "sample_23": ["    def test_union_with_defer(self):\n        qs1 = Number.objects.defer('other_num').filter(num__lte=1)\n        qs2 = Number.objects.defer('other_num').filter(num__gte=8)\n        self.assertNumbersEqual(qs1.union(qs2), [0, 1, 8, 9], ordered=False)\n"], "sample_117": ["def test_get_type_hints():\n        return True\n\n    class SampleClass:\n        x: int\n        y: str\n\n            pass\n\n    assert get_type_hints(sample_function) == {'a': int, 'b': str, 'return': bool}\n    assert get_type_hints(SampleClass) == {'x': int, 'y': str}\n    assert get_type_hints(SampleClass.method) == {'z': float, 'return': None}\n"], "sample_127": ["def test_latex_modifiers_combined():\n    # Test combinations of modifiers\n    assert latex(symbols(\"xHatDot\")) == r\"\\dot{\\hat{x}}\"\n    assert latex(symbols(\"xVecTilde\")) == r\"\\tilde{\\vec{x}}\"\n    assert latex(symbols(\"xBarPrime\")) == r\"{\\bar{x}}'\"\n    assert latex(symbols(\"xBoldAbs\")) == r\"\\left|{\\boldsymbol{x}}\\right|\"\n    assert latex(symbols(\"xNormHat\")) == r\"\\left\\|{\\hat{x}}\\right\\|\"\n    assert latex(symbols(\"xCheckGrave\")) == r\"\\grave{\\check{x}}\"\n    assert latex(symbols(\"xBreveAcute\")) == r\"\\acute{\\breve{x}}\"\n    assert latex(symbols(\"xMathringGrave\")) == r\"\\grave{\\mathring{x}}\"\n    assert latex(symbols(\"xDdDotHat\")) == r\"\\hat{\\dddot{x}}\"\n    assert latex(symbols(\"xDdDotBar\")) == r\"\\bar{\\dddot{x}}\"\n"], "sample_87": ["def test_exit_code_enum():\n    assert ExitCode.OK == 0\n    assert ExitCode.TESTS_FAILED == 1\n    assert ExitCode.INTERRUPTED == 2\n    assert ExitCode.INTERNAL_ERROR == 3\n    assert ExitCode.USAGE_ERROR == 4\n    assert ExitCode.NO_TESTS_COLLECTED == 5\n"], "sample_153": ["def test_pretty_printer_settings():\n    from sympy import Symbol, sqrt, Rational\n\n    # Test imaginary_unit setting\n    i = Symbol('i')\n    j = Symbol('j')\n    expr = 1 + i\n    assert pretty(expr, imaginary_unit='i') == '1 + i'\n    assert pretty(expr, imaginary_unit='j') == '1 + j'\n    assert upretty(expr, imaginary_unit='i') == '1 + i'\n    assert upretty(expr, imaginary_unit='j') == '1 + j'\n\n    # Test use_unicode_sqrt_char setting\n    expr = sqrt(2)\n    assert pretty(expr, use_unicode_sqrt_char=True) == '\u221a2'\n    assert pretty(expr, use_unicode_sqrt_char=False) == '2**(1/2)'\n    assert upretty(expr, use_unicode_sqrt_char=True) == '\u221a2'\n    assert upretty(expr, use_unicode_sqrt_char=False) == '2**(1/2)'\n\n    # Test root_notation setting\n    expr = Rational(1, 3)\n    assert pretty(expr, root_notation=True) == '1/3'\n    assert pretty(expr, root_notation=False) == '1/3'\n    assert upretty(expr, root_notation=True) == '1/3'\n    assert upretty(expr, root_notation=False) == '1/3'\n\n    # Test wrap_line and num_columns settings\n    expr = Symbol('x')**100\n    assert pretty(expr, wrap_line=True, num_columns=10) == 'x**100'\n    assert pretty(expr, wrap_line=False, num_columns=10) == 'x**100'\n    assert upretty(expr, wrap_line=True, num_columns=10) == 'x**100'\n    assert upretty(expr, wrap_line=False, num_columns=10) == 'x**100'\n"], "sample_82": ["def test_groupby_fillna():\n    array = xr.DataArray(\n        data=[1, np.nan, 3, np.nan, 5, 6], coords={\"x\": [1, 1, 1, 2, 2, 2]}, dims=\"x\"\n    )\n\n    # Fill NaN with a scalar\n    expected = xr.DataArray(\n        data=[1, 0, 3, 0, 5, 6], coords={\"x\": [1, 1, 1, 2, 2, 2]}, dims=\"x\"\n    )\n    actual = array.groupby(\"x\").fillna(0)\n    assert_identical(expected, actual)\n\n    # Fill NaN with a DataArray\n    fill_value = xr.DataArray([10, 20], coords={\"x\": [1, 2]}, dims=\"x\")\n    expected = xr.DataArray(\n        data=[1, 10, 3, 20, 5, 6], coords={\"x\": [1, 1, 1, 2, 2, 2]}, dims=\"x\"\n    )\n    actual = array.groupby(\"x\").fillna(fill_value)\n    assert_identical(expected, actual)\n\n    # Fill NaN with a Dataset\n    ds = xr.Dataset({\"foo\": array})\n    fill_value_ds = xr.Dataset({\"foo\": (\"x\", [10, 20])}, coords={\"x\": [1, 2]})\n    expected_ds = xr.Dataset(\n        {\"foo\": (\"x\", [1, 10, 3, 20, 5, 6])}, coords={\"x\": [1, 1, 1, 2, 2, 2]}\n    )\n    actual_ds = ds.groupby(\"x\").fillna(fill_value_ds)\n    assert_identical(expected_ds, actual_ds)\n"], "sample_0": ["compilation error"], "sample_70": ["def test_legend_set_ncols():\n    fig, ax = plt.subplots()\n    ax.plot(np.arange(10), label='line1')\n    ax.plot(np.arange(10) * 2, label='line2')\n    ax.plot(np.arange(10) * 3, label='line3')\n    leg = ax.legend(ncols=1)\n    assert leg._ncols == 1\n    leg.set_ncols(2)\n    assert leg._ncols == 2\n    leg.set_ncols(3)\n    assert leg._ncols == 3\n"], "sample_56": ["    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n"], "sample_18": ["    def test_foreign_key_to_swapped_model(self):\n        class Replacement(models.Model):\n            pass\n\n        class SwappedModel(models.Model):\n            class Meta:\n                swappable = 'TEST_SWAPPED_MODEL'\n\n        class Model(models.Model):\n            foreign_key = models.ForeignKey(SwappedModel, models.CASCADE)\n\n        field = Model._meta.get_field('foreign_key')\n        expected_error = Error(\n            \"Field defines a relation with the model 'invalid_models_tests.SwappedModel', which has been swapped out.\",\n            hint=\"Update the relation to point at 'settings.TEST_SWAPPED_MODEL'.\",\n            obj=field,\n            id='fields.E301',\n        )\n        self.assertEqual(field.check(from_model=Model), [expected_error])\n"], "sample_75": ["def test_grid_set_get_axes_pad():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 2), axes_pad=(0.1, 0.2))\n    assert grid.get_axes_pad() == (0.1, 0.2)\n    grid.set_axes_pad((0.3, 0.4))\n    assert grid.get_axes_pad() == (0.3, 0.4)\n"], "sample_114": ["def test_ovr_decision_function():\n    # Test the _ovr_decision_function with a simple example\n    predictions = np.array([[0, 1, 0], [1, 0, 1]])\n    confidences = np.array([[0.1, 0.4, 0.3], [0.2, 0.5, 0.6]])\n    n_classes = 3\n\n    decision_function = _ovr_decision_function(predictions, confidences, n_classes)\n    expected_decision_function = np.array([[1.03333333, 0.96666667, 1.03333333],\n                                           [0.96666667, 1.03333333, 1.03333333]])\n\n    assert_allclose(decision_function, expected_decision_function, rtol=1e-6)\n"], "sample_112": ["def test_isotonic_regression_increasing_false():\n    # Test isotonic regression with increasing=False\n    y = np.array([3, 7, 5, 9, 8, 7, 10])\n    y_ = np.array([9, 9, 9, 9, 8, 7, 7])\n    assert_array_equal(y_, isotonic_regression(y, increasing=False))\n\n    y = np.array([10, 0, 2])\n    y_ = np.array([10, 10, 10])\n    assert_array_equal(y_, isotonic_regression(y, increasing=False))\n\n    x = np.arange(len(y))\n    ir = IsotonicRegression(y_min=0.0, y_max=1.0, increasing=False)\n    ir.fit(x, y)\n    assert_array_equal(ir.fit(x, y).transform(x), ir.fit_transform(x, y))\n    assert_array_equal(ir.transform(x), ir.predict(x))\n\n    # check that it is immune to permutation\n    perm = np.random.permutation(len(y))\n    ir = IsotonicRegression(y_min=0.0, y_max=1.0, increasing=False)\n    assert_array_equal(ir.fit_transform(x[perm], y[perm]), ir.fit_transform(x, y)[perm])\n    assert_array_equal(ir.transform(x[perm]), ir.transform(x)[perm])\n\n    # check we don't crash when all x are equal:\n    ir = IsotonicRegression(increasing=False)\n    assert_array_equal(ir.fit_transform(np.ones(len(x)), y), np.mean(y))\n"], "sample_138": ["def test_BlockMatrix_as_real_imag():\n    from sympy import I\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', n, n)\n    X = BlockMatrix([[A + I*B, C], [D, A - I*B]])\n    \n    real_part, imag_part = X.as_real_imag()\n    \n    assert real_part == BlockMatrix([[A, C], [D, A]])\n    assert imag_part == BlockMatrix([[B, ZeroMatrix(n, n)], [ZeroMatrix(n, n), -B]])\n"], "sample_16": ["    def test_prepare_lookup_value(self):\n        \"\"\"\n        Test prepare_lookup_value function.\n        \"\"\"\n        self.assertEqual(prepare_lookup_value('field__in', '1,2,3'), ['1', '2', '3'])\n        self.assertEqual(prepare_lookup_value('field__isnull', ''), False)\n        self.assertEqual(prepare_lookup_value('field__isnull', 'false'), False)\n        self.assertEqual(prepare_lookup_value('field__isnull', '0'), False)\n        self.assertEqual(prepare_lookup_value('field__isnull', 'true'), True)\n        self.assertEqual(prepare_lookup_value('field__isnull', '1'), True)\n        self.assertEqual(prepare_lookup_value('field', 'value'), 'value')\n"], "sample_89": ["def test_node_add_marker():\n    node = nodes.Node(\"test_node\", parent=None, config=pytest.Config.fromdictargs({}), session=None, nodeid=\"test_node\")\n    marker = pytest.mark.skip(reason=\"skip reason\")\n    node.add_marker(marker)\n    assert marker.mark in node.own_markers\n    assert \"skip\" in node.keywords\n"], "sample_13": ["    def test_invalid_decode(self):\n        with self.assertRaises(ValueError):\n            urlsafe_base64_decode('invalid_base64')\n"], "sample_50": ["    def test_empty_message_list(self):\n        \"\"\"\n        Test that an empty message list is correctly handled by the storage.\n        \"\"\"\n        storage = self.get_storage()\n        response = self.get_response()\n        storage.update(response)\n        self.assertEqual(self.stored_messages_count(storage, response), 0)\n        self.assertEqual(list(storage), [])\n"], "sample_92": ["def test_xfail_with_raises_and_strict(testdir):\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(raises=ValueError, strict=True, reason=\"expecting ValueError\")\n            raise ValueError(\"expected error\")\n    \"\"\"\n    )\n    reports = runtestprotocol(item, log=False)\n    assert len(reports) == 3\n    callreport = reports[1]\n    assert callreport.skipped\n    assert callreport.wasxfail == \"expecting ValueError\"\n"], "sample_135": ["def test_compare():\n    x, y = symbols('x y')\n    assert Basic(x).compare(Basic(x)) == 0\n    assert Basic(x).compare(Basic(y)) == -1\n    assert Basic(y).compare(Basic(x)) == 1\n    assert Basic(x, y).compare(Basic(x, y)) == 0\n    assert Basic(x, y).compare(Basic(y, x)) == -1\n    assert Basic(y, x).compare(Basic(x, y)) == 1\n    assert Basic(x, y).compare(Basic(x)) == 1\n    assert Basic(x).compare(Basic(x, y)) == -1\n"], "sample_46": ["    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], \n            lambda column: column.upper(), \n            col_suffixes=['ASC', 'DESC'], \n            opclasses=['opclass1', 'opclass2']\n        )\n"], "sample_159": ["def test_prefix_properties():\n    p = PREFIXES['p']\n    assert p.name == 'pico'\n    assert p.abbrev == 'p'\n    assert p.scale_factor == 10**-12\n    assert p._latex(None) == r'\\text{p}'\n    assert str(p) == 'p'\n    assert repr(p) == \"Prefix('pico', 'p', -12)\"\n\n    mu = PREFIXES['mu']\n    assert mu._latex(None) == r'\\mu'\n"], "sample_24": ["compilation error"], "sample_147": ["def test_Function_kind():\n    f = Function('f')\n    g = Function('g', nargs=2)\n    assert f.kind is UndefinedKind\n    assert g.kind is UndefinedKind\n    assert f(comm_x).kind is UndefinedKind\n    assert g(comm_x, comm_x).kind is UndefinedKind\n    assert g(comm_x, noncomm_x).kind is UndefinedKind\n"], "sample_57": ["    def test_management_form_clean(self):\n        \"\"\"\n        Test that the ManagementForm's clean method correctly sets default values\n        for TOTAL_FORMS and INITIAL_FORMS when the form is invalid.\n        \"\"\"\n        class InvalidManagementForm(ManagementForm):\n                raise ValidationError(\"Invalid management form\")\n\n        class InvalidManagementFormSet(BaseFormSet):\n            @cached_property\n                return InvalidManagementForm(\n                    self.data,\n                    auto_id=self.auto_id,\n                    prefix=self.prefix,\n                    renderer=self.renderer,\n                )\n\n        InvalidFormSet = formset_factory(Choice, formset=InvalidManagementFormSet)\n        data = {\n            \"choices-TOTAL_FORMS\": \"1\",\n            \"choices-INITIAL_FORMS\": \"0\",\n        }\n        formset = InvalidFormSet(data, auto_id=False, prefix=\"choices\")\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(formset.management_form.cleaned_data[TOTAL_FORM_COUNT], 0)\n        self.assertEqual(formset.management_form.cleaned_data[INITIAL_FORM_COUNT], 0)\n"], "sample_103": ["def test_mutual_info_classif_sparse():\n    # Test mutual information classification with sparse input\n    X_dense = np.array([[0, 0, 0],\n                        [1, 1, 0],\n                        [2, 0, 1],\n                        [2, 0, 1],\n                        [2, 0, 1]])\n    y = np.array([0, 1, 2, 2, 1])\n    X_sparse = csr_matrix(X_dense)\n\n    mi_dense = mutual_info_classif(X_dense, y, discrete_features=True)\n    mi_sparse = mutual_info_classif(X_sparse, y, discrete_features=True)\n\n    assert_array_equal(mi_dense, mi_sparse)\n"], "sample_101": ["def test_pipeline_with_none_step():\n    # Test pipeline with None step\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n\n    clf = SVC(gamma='scale', probability=True, random_state=0)\n    transf = DummyTransf()\n    pipe = Pipeline([('transf', transf), ('none_step', None), ('svc', clf)])\n\n    # Ensure pipeline works with None step\n    pipe.fit(X, y)\n    assert_array_equal(pipe.predict(X), clf.predict(transf.transform(X)))\n    assert_array_equal(pipe.predict_proba(X), clf.predict_proba(transf.transform(X)))\n    assert_array_equal(pipe.predict_log_proba(X), clf.predict_log_proba(transf.transform(X)))\n    assert_array_equal(pipe.score(X, y), clf.score(transf.transform(X), y))\n\n    # Ensure setting None step to passthrough works\n    pipe.set_params(none_step='passthrough')\n    pipe.fit(X, y)\n    assert_array_equal(pipe.predict(X), clf.predict(transf.transform(X)))\n    assert_array_equal(pipe.predict_proba(X), clf.predict_proba(transf.transform(X)))\n    assert_array_equal(pipe.predict_log_proba(X), clf.predict_log_proba(transf.transform(X)))\n    assert_array_equal(pipe.score(X, y), clf.score(transf.transform(X), y))\n"], "sample_108": ["def test_libsvm_fit_invalid_gamma():\n    # Test that an invalid gamma value raises the appropriate error\n    clf = svm.SVC(kernel='rbf', gamma=0)\n    with pytest.raises(ValueError, match=\"The gamma value of 0.0 is invalid. Use 'auto' to set gamma to a value of 1 / n_features.\"):\n        clf.fit(X, Y)\n\n    clf = svm.SVC(kernel='rbf', gamma='invalid')\n    with pytest.raises(ValueError, match=\"When 'gamma' is a string, it should be either 'scale' or 'auto'. Got 'invalid' instead.\"):\n        clf.fit(X, Y)\n"], "sample_22": ["    def test_capfirst(self):\n        self.assertEqual(text.capfirst('hello'), 'Hello')\n        self.assertEqual(text.capfirst('Hello'), 'Hello')\n        self.assertEqual(text.capfirst(''), '')\n        self.assertEqual(text.capfirst('123abc'), '123abc')\n        self.assertEqual(text.capfirst(' hello'), ' hello')\n        self.assertEqual(text.capfirst(lazystr('hello')), 'Hello')\n"]}, "raw_scored_generations": {"sample_0": [false], "sample_2": [false], "sample_3": [false], "sample_1": [true], "sample_6": [true], "sample_4": [false], "sample_5": [false], "sample_7": [false], "sample_9": [false], "sample_8": [false], "sample_10": [false], "sample_11": [false], "sample_13": [false], "sample_12": [true], "sample_14": [true], "sample_15": [true], "sample_16": [false], "sample_17": [false], "sample_18": [false], "sample_19": [false], "sample_21": [false], "sample_20": [false], "sample_23": [true], "sample_22": [true], "sample_24": [false], "sample_25": [false], "sample_28": [false], "sample_26": [false], "sample_27": [true], "sample_29": [false], "sample_31": [false], "sample_30": [true], "sample_32": [false], "sample_33": [false], "sample_34": [false], "sample_35": [false], "sample_36": [false], "sample_37": [false], "sample_39": [true], "sample_38": [false], "sample_40": [true], "sample_42": [false], "sample_41": [false], "sample_43": [true], "sample_45": [false], "sample_44": [false], "sample_46": [false], "sample_48": [false], "sample_47": [false], "sample_50": [true], "sample_49": [false], "sample_51": [false], "sample_52": [false], "sample_53": [false], "sample_55": [true], "sample_54": [false], "sample_56": [false], "sample_58": [true], "sample_57": [false], "sample_60": [false], "sample_59": [true], "sample_61": [false], "sample_63": [false], "sample_62": [false], "sample_64": [false], "sample_66": [true], "sample_65": [false], "sample_68": [false], "sample_67": [false], "sample_69": [false], "sample_70": [true], "sample_71": [false], "sample_72": [false], "sample_73": [false], "sample_74": [true], "sample_75": [true], "sample_76": [true], "sample_77": [false], "sample_78": [false], "sample_79": [false], "sample_80": [true], "sample_82": [true], "sample_81": [false], "sample_83": [false], "sample_84": [false], "sample_85": [false], "sample_86": [false], "sample_87": [true], "sample_88": [false], "sample_89": [false], "sample_90": [false], "sample_91": [false], "sample_92": [false], "sample_93": [true], "sample_95": [false], "sample_94": [false], "sample_96": [false], "sample_97": [true], "sample_98": [false], "sample_99": [false], "sample_100": [false], "sample_101": [true], "sample_102": [false], "sample_103": [true], "sample_104": [false], "sample_105": [true], "sample_107": [false], "sample_106": [true], "sample_108": [false], "sample_109": [false], "sample_110": [false], "sample_111": [false], "sample_112": [false], "sample_113": [false], "sample_114": [false], "sample_115": [false], "sample_116": [false], "sample_117": [false], "sample_118": [false], "sample_119": [true], "sample_120": [true], "sample_121": [false], "sample_122": [false], "sample_123": [false], "sample_124": [true], "sample_125": [false], "sample_126": [true], "sample_127": [false], "sample_128": [true], "sample_129": [false], "sample_130": [false], "sample_131": [true], "sample_132": [false], "sample_133": [false], "sample_134": [true], "sample_135": [true], "sample_136": [false], "sample_137": [true], "sample_138": [false], "sample_139": [true], "sample_140": [true], "sample_142": [true], "sample_141": [false], "sample_143": [false], "sample_144": [true], "sample_145": [false], "sample_146": [false], "sample_147": [false], "sample_148": [false], "sample_149": [false], "sample_150": [false], "sample_151": [true], "sample_152": [true], "sample_153": [false], "sample_154": [false], "sample_155": [false], "sample_156": [false], "sample_157": [false], "sample_158": [false], "sample_159": [false]}}