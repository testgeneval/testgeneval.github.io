{"raw_generations": {"sample_33": ["def test_connect_disconnect_multiple_times(self):\n    a_signal = Signal()\n    receiver_1 = Callable()\n    receiver_2 = Callable()\n    receiver_3 = Callable()\n    a_signal.connect(receiver_1)\n    a_signal.connect(receiver_2)\n    a_signal.connect(receiver_1)\n    a_signal.connect(receiver_3)\n    self.assertEqual(len(a_signal.receivers), 3)\n    a_signal.disconnect(receiver_1)\n    self.assertEqual(len(a_signal.receivers), 2)\n    a_signal.disconnect(receiver_3)\n    self.assertEqual(len(a_signal.receivers), 1)\n    a_signal.disconnect(receiver_2)\n    self.assertEqual(len(a_signal.receivers), 0)\n    self.assertTestIsClean(a_signal)\n", "def test_disconnect_uid(self):\n    \"\"\"\n    Test disconnecting a receiver by its dispatch_uid.\n    \"\"\"\n        pass\n\n        pass\n\n    a_signal.connect(receiver_1, dispatch_uid=\"uid\")\n    a_signal.connect(receiver_2, dispatch_uid=\"uid\")\n    a_signal.disconnect(dispatch_uid=\"uid\")\n    self.assertEqual(len(a_signal.receivers), 0)\n    self.assertTestIsClean(a_signal)\n\n    # Test that disconnecting twice doesn't raise an exception\n    a_signal.connect(receiver_1, dispatch_uid=\"uid\")\n    a_signal.disconnect(dispatch_uid=\"uid\")\n    self.assertEqual(len(a_signal.receivers), 0)\n    a_signal.disconnect(dispatch_uid=\"uid\")\n    self.assertTestIsClean(a_signal)\n", "    def test_weak_reference_cleanup(self):\n        \"\"\"\n        Make sure that weak references are properly cleaned up when the object\n        is garbage collected.\n        \"\"\"\n        class Obj:\n            pass\n\n        obj = Obj()\n            pass\n\n        a_signal.connect(receiver, sender=obj, weak=False)\n        self.assertIsNone(a_signal.disconnect(receiver, sender=obj, weak=False))\n        del obj\n        garbage_collect()\n        self.assertIsNone(a_signal.disconnect(receiver, sender=obj, weak=False))\n        self.assertTestIsClean(a_signal)\n", "def test_caching(self):\n    c_signal.connect(receiver_1_arg, sender=self, dispatch_uid=\"test_uid\")\n    c_signal.connect(receiver_1_arg, sender=self, dispatch_uid=\"test_uid\")\n    self.assertEqual(len(c_signal.receivers), 1)\n    self.assertTrue(c_signal.use_caching)\n    c_signal.disconnect(dispatch_uid=\"test_uid\")\n    self.assertTestIsClean(c_signal)\n", "def test_disconnect_kwargs(self):\n    @receiver(a_signal, **{'foo': 'bar'})\n        pass\n\n    self.assertEqual(a_signal.disconnect(**{'foo': 'bar'}), True)\n    self.assertTestIsClean(a_signal)\n\n    @receiver(a_signal, sender=self)\n        pass\n\n    self.assertEqual(a_signal.disconnect(sender=self, **{'foo': 'bar'}), True)\n    self.assertTestIsClean(a_signal)\n\n    @receiver(a_signal)\n        pass\n\n    with self.assertRaises(ValueError):\n        a_signal.disconnect(**{'foo': 'bar'})\n\n    @receiver(a_signal, sender=self)\n        pass\n\n    with self.assertRaises(ValueError):\n        a_signal.disconnect(sender=self, **{'foo': 'bar'})\n"], "sample_42": ["def test_serialize_decimal_class(self):\n    \"\"\"\n    Tests serializing a custom Decimal class.\n    \"\"\"\n    class CustomDecimal(decimal.Decimal):\n        pass\n\n    self.assertSerializedResultEqual(\n        CustomDecimal('1.3'),\n        (\"CustomDecimal('1.3')\", {'from decimal import Decimal'})\n    )\n", "    def test_serialize_enum_member(self):\n        \"\"\"\n        Test serialization of enum members.\n        \"\"\"\n        class MyEnum(enum.Enum):\n            A = 1\n            B = 2\n        self.assertSerializedResultEqual(\n            MyEnum.A,\n            (\"migrations.test_writer.MyEnum['A']\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedEqual(MyEnum.A)\n        field = models.CharField(default=MyEnum.B, choices=[(m.value, m) for m in MyEnum])\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.CharField(choices=[(1, migrations.test_writer.MyEnum['A']), (2, migrations.test_writer.MyEnum['B'])], \"\n            \"default=migrations.test_writer.MyEnum['B'])\"\n        )\n", "    def test_serialize_decimal_instance_with_parent(self):\n        # Test that a Decimal instance with a parent class is properly serialized\n        class ParentDecimal(decimal.Decimal):\n            pass\n\n        decimal_value = decimal.Decimal('1.3')\n        parent_decimal_value = ParentDecimal(decimal_value)\n        self.assertSerializedResultEqual(\n            parent_decimal_value,\n            (\"migrations.test_writer.ParentDecimal('1.3')\", {'import migrations.test_writer'})\n        )\n", "def test_serialize_regex_flags(self):\n    \"\"\"\n    Test serialization of regex flags.\n    \"\"\"\n    validator = RegexValidator(r'^\\w+$', flags=re.IGNORECASE)\n    string = MigrationWriter.serialize(validator)[0]\n    self.assertEqual(string, \"django.core.validators.RegexValidator(regex=re.compile('^\\\\\\\\w+$'), flags=re.RegexFlag['IGNORECASE'])\")\n    self.serialize_round_trip(validator)\n\n    # Test a flag that is not a member of RegexFlag.\n    with self.assertRaisesMessage(ValueError, \"Could not find object re.IGNORECASE in django.re\"):\n        validator = RegexValidator(r'^\\w+$', flags=re.IGNORECASE)\n", "def test_serialize_default_lambda(self):\n    \"\"\"Serializing a default lambda function\"\"\"\n    class TestModel:\n            self.value = lambda x: x + 1\n    model = models.Model()\n    field = models.IntegerField(default=TestModel().value)\n    self.assertSerializedResultEqual(\n        field,\n        (\"models.IntegerField(default=migrations.test_writer.TestModel().value)\", {'from django.db import models'})\n    )\n"], "sample_112": ["def test_isotonic_regression_increasing_auto_on_ties():\n    x = [1, 1, 2, 3, 4, 5]\n    y = [1, 2, 2, 4, 5, 6]\n    ir = IsotonicRegression(increasing=\"auto\")\n    with warnings.catch_warnings(record=True) as w:\n        warnings.simplefilter(\"always\")\n        y_ = ir.fit_transform(x, y)\n        # work-around for pearson divide warnings in scipy <= 0.17.0\n        assert all([\"invalid value encountered in \" in str(warn.message) for warn in w])\n    assert_array_equal(y_, np.array([1, 2, 2, 4, 5, 6]))\n", "def test_isotonic_regression_y_min_y_max_unbounded():\n    # Test that y_min and y_max are not applied when unbounded\n    x = np.array([1, 2, 3, 4, 5, 6, 7])\n    y = np.array([3, 7, 5, 9, 8, 7, 10])\n\n    ir = IsotonicRegression(y_min=-np.inf, y_max=np.inf)\n    assert_array_equal(ir.fit_transform(x, y), isotonic_regression(y))\n\n    ir = IsotonicRegression(y_min=-np.inf, y_max=np.inf, increasing=False)\n    assert_array_equal(ir.fit_transform(x, y), isotonic_regression(y, increasing=False))\n", "def test_isotonic_regression_out_of_bounds_clip_with_extreme_values():\n    # Test from #16617\n    # Check that predictions are clipped to out of bounds when extreme values are used\n    y = np.array([3, 7, 5, 9, 8, 7, 10])\n    x = np.arange(len(y))\n\n    # Create model and fit\n    ir = IsotonicRegression(increasing=\"auto\", out_of_bounds=\"clip\", y_min=-10, y_max=10)\n    ir.fit(x, y)\n\n    # Predict from  training and test x and check that min/max match.\n    y1 = ir.predict([min(x) - 1000, max(x) + 1000])\n    y2 = ir.predict(x)\n    assert max(y1) == max(y2)\n    assert min(y1) == min(y2)\n", "def test_isotonic_regression_ymin_ymax_infinite():\n    # Test from @GaelVaroquaux's comment:\n    # https://github.com/scikit-learn/scikit-learn/issues/6724\n    # check that it is possible to specify ymin or ymax as np.inf\n    y = np.array([3, 7, 5, 9, 8, 7, 10])\n    x = np.arange(len(y))\n\n    # Create model and fit\n    ir = IsotonicRegression(y_max=np.inf)\n    ir.fit(x, y)\n\n    # Predict from  training and test x and check that max is np.inf\n    y1 = ir.predict([min(x) - 10, max(x) + 10])\n    assert np.isinf(y1.max())\n\n    # Create model and fit\n    ir = IsotonicRegression(y_min=-np.inf)\n    ir.fit(x, y)\n\n    # Predict from  training and test x and check that min is -np.inf\n    y1 = ir.predict([min(x) - 10, max(x) + 10])\n    assert np.isinf(y1.min())\n\n    # Create model and fit\n    ir = IsotonicRegression(y_min=-np.inf, y_max=np.inf)\n    ir.fit(x, y)\n\n    # Predict from  training and test x and check that min and max are -np.inf and np.inf\n    y1 = ir.predict([min(x) - 10, max(x) + 10])\n    assert np.isinf(y1.min())\n    assert np.isinf(y1.max())\n", "def test_isotonic_regression_nans():\n    \"\"\"Regression test for #15858.\n\n    Check that isotonic regression handles NaN values correctly.\n    \"\"\"\n    x = np.array([1, 2, np.nan, 4, 5, 6])\n    y = np.array([1, 2, 3, 4, 5, 6])\n    with pytest.raises(ValueError, match=\"Found input values with NaN\"):\n        isotonic_regression(y, x)\n\n    ir = IsotonicRegression()\n    with pytest.raises(ValueError, match=\"Found input values with NaN\"):\n        ir.fit(x, y)\n\n    y = np.array([1, 2, np.nan, 4, 5, 6])\n    with pytest.warns(UserWarning, match=\"Found input values with NaN\"):\n        isotonic_regression(y, y_min=0.0, y_max=10.0)\n"], "sample_84": ["    def test_conftest_module_overrides_autouse_fixture_module(self, testdir):\n        testdir.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(autouse=True)\n                pass\n\n            @pytest.fixture(scope=\"module\")\n                pass\n\n            @pytest.fixture(autouse=True)\n                pass\n        \"\"\"\n        )\n        testdir.makepyfile(\n            \"\"\"\n                pass\n                pass\n        \"\"\"\n        )\n        reprec = testdir.inline_run()\n        reprec.assertoutcome(passed=2)\n", "    def testdir(self, request):\n        testdir = request.getfixturevalue(\"testdir\")\n        testdir.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture(scope=\"session\")\n                return \"session\"\n            @pytest.fixture(scope=\"package\")\n                return \"package\"\n            @pytest.fixture(scope=\"module\")\n                return \"module\"\n            @pytest.fixture(scope=\"function\")\n                return \"function\"\n            @pytest.fixture\n                return \"conftest\"\n            class TestClass(object):\n                @pytest.fixture(scope=\"class\")\n                    return \"class\"\n                    pass\n        \"\"\"\n        )\n        return testdir\n", "    def test_pseudo_fixturedef_repr(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(autouse=True)\n                pass\n                pass\n        \"\"\"\n        )\n        fixturedef = testdir.getitem(\"test_func\").fixtureinfo.fixturedefs[\"something\"]\n        assert repr(fixturedef) == \"<PseudoFixtureDef something at 0x...>\"\n", "    def test_added_twice(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n\n            @pytest.fixture\n                request.addfinalizer(lambda: values.append(\"fin1\"))\n                request.addfinalizer(lambda: values.append(\"fin2\"))\n                pass\n        \"\"\"\n        )\n        reprec = testdir.inline_run()\n        reprec.assertoutcome(passed=1)\n        assert reprec.getcalls(\"pytest_runtest_call\")[0].item.module.values == [\"fin1\", \"fin2\"]\n", "    def test_autouse_class_conftest_and_module(self, testdir):\n        testdir.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture(autouse=True)\n                self.hello = \"world\"\n            @pytest.fixture\n                return \"arg1\"\n                assert self.hello == \"world\"\n        \"\"\"\n        )\n        reprec = testdir.inline_run()\n        reprec.assertoutcome(passed=1)\n"], "sample_85": ["def test_log_level_from_ini_override_cli(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_level=ERROR\n        \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_handler.level == logging.INFO\n            logging.getLogger('catchlog').debug(\"This log message won't be shown\")\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n\n    result = testdir.runpytest(\"-s\", \"--log-cli-level=INFO\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_log_level_from_ini_override_cli.py*This log message will be shown\",\n            \"PASSED\",  # 'PASSED' on its own line because the log message prints a new line\n        ]\n    )\n    assert \"This log message won't be shown\" not in result.stdout.str()\n\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n", "def test_log_file_auto_enable(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        \"\"\".format(log_file)\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_file_handler is not None\n            logging.getLogger('catchlog').info(\"This log message won't be shown\")\n            logging.getLogger('catchlog').warning(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"test_log_file_auto_enable.py PASSED\"])\n\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert \"This log message will be shown\" in contents\n        assert \"This log message won't be shown\" not in contents\n", "def test_multiple_log_file_handlers(testdir):\n    log_file1 = testdir.tmpdir.join(\"pytest.log1\").strpath\n    log_file2 = testdir.tmpdir.join(\"pytest.log2\").strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={0}\n        log_file_level = INFO\n        log_file_format = %(asctime)s %(levelname)-8s %(message)s\n        log_file2={1}\n        log_file2_level = WARNING\n        log_file2_format = %(asctime)s %(levelname)-8s %(message)s\n        \"\"\".format(\n            log_file1, log_file2\n        )\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logging.getLogger('catchlog').info(\"This is info message\")\n            logging.getLogger('catchlog').warning(\"This is warning message\")\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n    assert os.path.isfile(log_file1)\n    assert os.path.isfile(log_file2)\n    with open(log_file1, encoding=\"utf-8\") as rfh:\n        contents = rfh.read()\n        assert \"This is info message\" in contents\n        assert \"This is warning message\" in contents\n    with open(log_file2, encoding=\"utf-8\") as rfh:\n        contents = rfh.read()\n        assert \"This is info message\" not in contents\n        assert \"This is warning message\" in contents\n", "def test_log_file_at_level(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = INFO\n        \"\"\".format(\n            log_file\n        )\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            log = logging.getLogger(__name__)\n            log.setLevel(logging.DEBUG)\n            log.debug(\"This log message will be shown because we set log level to DEBUG\")\n            log.info(\"This log message won't be shown\")\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file, encoding=\"utf-8\") as rfh:\n        contents = rfh.read()\n        assert \"This log message will be shown because we set log level to DEBUG\" in contents\n        assert \"This log message won't be shown\" not in contents\n", "def test_custom_log_file_formatter(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = INFO\n        log_file_format = \"%(asctime)s %(levelname)s %(message)s\"\n        \"\"\".format(log_file)\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        import datetime\n\n            logging.getLogger('catchlog').info(\"Normal message\")\n            timestamp = datetime.datetime.now()\n            logging.getLogger('catchlog').info(\n                \"Custom log format: {asctime} - {levelname} - {message}\".format(\n                    asctime=timestamp.strftime(\"%Y-%m-%d %H:%M:%S\"),\n                    levelname=\"INFO\",\n                    message=\"Custom log message\"\n                )\n            )\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file, encoding=\"utf-8\") as rfh:\n        contents = rfh.read()\n        assert \"Normal message\" in contents\n        assert \"Custom log format: \" in contents\n        assert \"INFO - Custom log message\" in contents\n"], "sample_4": ["    def test_not_found(self):\n        response = HttpResponseNotFound()\n        self.assertEqual(response.status_code, 404)\n        self.assertNotIn('Content-Type', response)\n", "    def test_non_string_content_encoding(self):\n        # Bug 16494: HttpResponse should behave consistently with non-strings\n        r = HttpResponse(12345)\n        self.assertEqual(r.charset, settings.DEFAULT_CHARSET)\n\n        r = HttpResponse(object())\n        self.assertEqual(r.charset, settings.DEFAULT_CHARSET)\n\n        r = HttpResponse({'key': 'value'})\n        self.assertEqual(r.charset, settings.DEFAULT_CHARSET)\n", "    def test_writable(self):\n        r = HttpResponse()\n        self.assertTrue(r.writable())\n        with self.assertRaises(AttributeError):\n            r.writable()\n        r = StreamingHttpResponse(iter([]))\n        self.assertFalse(r.writable())\n", "    def test_multibyte_encoding(self):\n        # Test that response headers are properly encoded in multibyte encodings.\n        r = HttpResponse()\n        r['Content-Type'] = 'text/html; charset=euc-jp'\n        self.assertEqual(r.charset, 'euc-jp')\n        self.assertEqual(r['Content-Type'], 'text/html; charset=euc-jp')\n        r['Content-Type'] = 'text/html; charset=euc-jp; charset=UTF-8'\n        self.assertEqual(r.charset, 'euc-jp')\n        self.assertEqual(r['Content-Type'], 'text/html; charset=euc-jp; charset=UTF-8')\n\n        r = HttpResponse()\n        r['Content-Type'] = 'text/html; charset=ISO-2022-JP'\n        self.assertEqual(r.charset, 'ISO-2022-JP')\n        self.assertEqual(r['Content-Type'], 'text/html; charset=ISO-2022-JP')\n\n        r = HttpResponse()\n        r['Content-Type'] = 'text/html; charset=ISO-8859-1'\n        self.assertEqual(r.charset, 'ISO-8859-1')\n        self.assertEqual(r['Content-Type'], 'text/html; charset=ISO-8859-1')\n", "    def test_file_response(self):\n        filename = os.path.join(os.path.dirname(__file__), 'abc.txt')\n        response = FileResponse(open(filename), as_attachment=True, filename='example.txt')\n        self.assertEqual(response['Content-Type'], 'text/plain; charset=utf-8')\n        self.assertEqual(response['Content-Disposition'], 'attachment; filename=\"example.txt\"')\n        self.assertEqual(response['Content-Length'], os.path.getsize(filename))\n"], "sample_66": ["    def test_invalid_type(self):\n        class FakeFormSet:\n            pass\n\n        class ValidationTestInline(TabularInline):\n            model = ValidationTestInlineModel\n            formset = FakeFormSet\n\n        class TestModelAdmin(ModelAdmin):\n            inlines = [ValidationTestInline]\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'formset' must inherit from 'BaseModelFormSet'.\",\n            \"admin.E206\",\n            invalid_obj=ValidationTestInline,\n        )\n", "    def test_valid_case(self):\n        @admin.action\n            pass\n\n        class BandAdmin(ModelAdmin):\n            actions = (action,)\n\n        self.assertIsValid(BandAdmin, Band)\n", "    def test_max_num_not_specified(self):\n        class ValidationTestInline(TabularInline):\n            model = ValidationTestInlineModel\n            min_num = 2\n\n        class TestModelAdmin(ModelAdmin):\n            inlines = [ValidationTestInline]\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'ValidationTestInline.max_num' must be an integer.\",\n            \"admin.E204\",\n            invalid_obj=ValidationTestInline,\n        )\n", "    def test_invalid_type(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = \"field_name\"\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields[0]' refers to 'field_name', \"\n            \"which is not a callable, an attribute of 'TestModelAdmin', \"\n            \"or an attribute or method on 'modeladmin.ValidationTestModel'.\",\n            \"admin.E035\",\n        )\n", "    def test_prepopulated_fields_has_prepopulated_fields(self):\n        class TestModelAdmin(ModelAdmin):\n            prepopulated_fields = {}\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'prepopulated_fields' refers to 'dictproxy object', \"\n            \"which must not be a DateTimeField, a ForeignKey, a OneToOneField, or \"\n            \"a ManyToManyField.\",\n            \"admin.E028\",\n        )\n"], "sample_116": ["def test_create_single_index_no_uri(app):\n    text = (\".. index:: docutils\\n\"\n            \".. index:: Python\\n\"\n            \".. index:: pip; install\\n\"\n            \".. index:: Sphinx\\n\"\n            \".. index:: \u0415\u043b\u044c\\n\"\n            \".. index:: \u0451\u043b\u043a\u0430\\n\"\n            \".. index:: \u200f\u05ea\u05d9\u05e8\u05d1\u05e2\u200e\\n\")\n    restructuredtext.parse(app, text)\n    builder = app.builder\n    with pytest.raises(NoUri):\n        IndexEntries(app.env).create_index(builder)\n", "def test_create_triple_index_with_subentry(app):\n    text = (\".. index:: triple: foo; bar; baz\\n\"\n            \".. index:: triple: Python; Sphinx; reStructuredText\\n\"\n            \".. index:: triple: Python; Sphinx; reStructuredText\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 5\n    assert index[0] == ('B', [('bar', [[], [('baz, foo', [('', '#index-0')])], None),\n                              ('baz', [[], [('foo bar', [('', '#index-1')])], None])])\n    assert index[1] == ('F', [('foo', [[], [('bar baz', [('', '#index-0')])], None)])\n    assert index[2] == ('P', [('Python', [[], [('reStructuredText, Sphinx', [('', '#index-1')])], None]])\n    assert index[3] == ('R', [('reStructuredText', [[], [('Python Sphinx', [('', '#index-2')])], None)])\n    assert index[4] == ('S', [('Sphinx', [[], [('reStructuredText, Python', [('', '#index-1')])], None]])\n", "def test_create_single_index_with_duplicates(app):\n    text = (\".. index:: docutils\\n\"\n            \".. index:: Python\\n\"\n            \".. index:: pip; install\\n\"\n            \".. index:: pip; install\\n\"\n            \".. index:: Sphinx\\n\"\n            \".. index:: docutils\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 4\n    assert index[0] == ('D', [('docutils', [[('', '#index-0')], [], None],\n                               [('docutils', [[('', '#index-3')], [], None])]])\n    assert index[1] == ('P', [('pip', [[], [('install', [('', '#index-2')])], None]])\n    assert index[2] == ('P', [('install', [[('', '#index-2')], [], None]])\n    assert index[3] == ('S', [('Sphinx', [[('', '#index-1')], [], None]]))\n", "def test_create_triple_index_with_links(app):\n    text = (\".. index:: triple: foo; bar; baz\\n\"\n            \".. index:: triple: Python; Sphinx; :reST:\\n\"\n            \".. index:: triple: Sphinx; :documentation tool:; docutils\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 6\n    assert index[0] == ('B', [('bar', [[], [('baz, foo', [('', '#index-0')])], None),\n                              ('baz', [[], [('foo bar', [('', '#index-0')])], None])])\n    assert index[1] == ('D', [('docutils', [[], [('documentation tool', [('', '#index-2')]), \n                                                  ('see documentation tool', [])], None])])\n    assert index[2] == ('F', [('foo', [[], [('bar baz', [('', '#index-0')])], None)])\n    assert index[3] == ('P', [('Python', [[], [('reST', [('', '#index-1')])], None)])\n    assert index[4] == ('R', [('reST', [[], [('Python Sphinx', [('', '#index-1')])], None])]\n    assert index[5] == ('S', [('Sphinx', [[], [('reST, Python', [('', '#index-1')])], None])]\n", "def test_create_single_index_with_duplicate_entries(app):\n    text = (\".. index:: docutils\\n\"\n            \".. index:: docutils\\n\"\n            \".. index:: pip; install\\n\"\n            \".. index:: Sphinx\\n\"\n            \".. index:: \u0415\u043b\u044c\\n\"\n            \".. index:: \u0404\u043b\u044c\\n\"\n            \".. index:: \u200f\u05ea\u05d9\u05e8\u05d1\u05e2\u200e\\n\"\n            \".. index:: 9-symbol\\n\"\n            \".. index:: &-symbol\\n\"\n            \".. index:: \u00a3100\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 6\n    assert index[0] == ('Symbols', [('&-symbol', [[('', '#index-8')], [], None]),\n                                    ('9-symbol', [[('', '#index-7')], [], None]),\n                                    ('\u00a3100', [[('', '#index-9')], [], None])])\n    assert index[1] == ('D', [('docutils', [[('', '#index-0')], ['docutils', None])])\n    assert index[2] == ('D', [('docutils', [[('', '#index-1')], ['docutils', None])])\n    assert index[3] == ('P', [('pip', [[], [('install', [('', '#index-3')])], None)])\n    assert index[4] == ('S', [('Sphinx', [[('', '#index-4')], [], None]))\n    assert index[5] == ('\u0404', [('\u0404\u043b\u044c', [[('', '#index-6')], [], None],\n                               ('\u0415\u043b\u044c', [[('', '#index-5')], [], None]))])\n"], "sample_52": ["    def test_alter_together(self):\n        \"\"\"\n        Tests the AlterUniqueTogether operation.\n        \"\"\"\n        project_state = self.set_up_test_model(\"test_aluto\")\n        # Test the state alteration\n        operation = migrations.AlterUniqueTogether(\"Pony\", [(\"pink\", \"weight\")])\n        self.assertEqual(\n            operation.describe(), \"Alter unique_together for Pony (1 constraint(s))\"\n        )\n        self.assertEqual(\n            operation.migration_name_fragment,\n            \"alter_pony_unique_together\",\n        )\n        new_state = project_state.clone()\n        operation.state_forwards(\"test_aluto\", new_state)\n        self.assertEqual(\n            len(\n                project_state.models[\"test_aluto\", \"pony\"].options.get(\n                    \"unique_together\", set()\n                )\n            ),\n            0,\n        )\n        self.assertEqual(\n            len(\n                new_state.models[\"test_aluto\", \"pony\"].options.get(\n                    \"unique_together\", set()\n                )\n            ),\n            1,\n        )\n        # Make sure we can insert duplicate rows\n        with connection.cursor() as cursor:\n            cursor.execute(\"INSERT INTO test_aluto_pony (pink, weight) VALUES (1, 1)\")\n            cursor.execute(\"INSERT INTO test_aluto_pony (pink, weight) VALUES (1, 1)\")\n            cursor.execute(\"DELETE FROM test_aluto_pony\")\n            # Test the database alteration\n            with connection.schema_editor() as editor:\n                operation.database_forwards(\n                    \"test_aluto\", editor, project_state, new_state\n                )\n            cursor.execute(\"INSERT INTO test_aluto_pony (pink, weight) VALUES (1, 1)\")\n            with self.assertRaises(IntegrityError):\n                with atomic():\n                    cursor.execute(\n                        \"INSERT INTO test_aluto_pony (pink, weight) VALUES (1, 1)\"\n                    )\n            cursor.execute(\"DELETE FROM test_aluto_pony\")\n            # And test reversal\n            with connection.schema_editor() as editor:\n                operation.database_backwards(\n                    \"test_aluto\", editor, new_state, project_state\n                )\n            cursor.execute(\"INSERT INTO test_aluto_pony (pink, weight) VALUES (1, 1)\")\n            cursor.execute(\"INSERT INTO test_aluto_pony", "def test_create_model_managers_with_same_manager_name(self):\n    \"\"\"\n    The managers on a model are set.\n    \"\"\"\n    project_state = self.set_up_test_model(\"test_cmomsm\")\n    # Test the state alteration\n    operation = migrations.CreateModel(\n        \"Food\",\n        fields=[\n            (\"id\", models.AutoField(primary_key=True)),\n        ],\n        managers=[\n            (\"food_qs\", FoodQuerySet.as_manager()),\n            (\"food_mgr\", FoodManager(\"a\", \"b\")),\n            (\"food_mgr\", models.Manager()),\n        ],\n    )\n    self.assertEqual(operation.describe(), \"Create model Food\")\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_cmomsm\", new_state)\n    self.assertIn((\"test_cmomsm\", \"food\"), new_state.models)\n    managers = new_state.models[\"test_cmomsm\", \"food\"].managers\n    self.assertEqual(managers[0][0], \"food_qs\")\n    self.assertIsInstance(managers[0][1], models.Manager)\n    self.assertEqual(managers[1][0], \"food_mgr\")\n    self.assertIsInstance(managers[1][1], FoodManager)\n    self.assertEqual(managers[1][1].args, (\"a\", \"b\", 1, 2))\n    self.assertEqual(managers[2][0], \"food_mgr\")\n    self.assertIsInstance(managers[2][1], models.Manager)\n", "    def test_create_index(self):\n        \"\"\"\n        Tests the AddIndex operation.\n        \"\"\"\n        project_state = self.set_up_test_model(\"test_add_index\")\n        # Test the state alteration\n        operation = migrations.AddIndex(\"Pony\", models.Index(fields=[\"pink\"]))\n        msg = (\n            \"Indexes passed to AddIndex operations require a name argument. \"\n            \"<Index: fields=['pink']> doesn't have one.\"\n        )\n        with self.assertRaisesMessage(ValueError, msg):\n            operation.state_forwards(\"test_add_index\", project_state)\n        index = models.Index(fields=[\"pink\"], name=\"test_add_index_pony_pink_idx\")\n        operation = migrations.AddIndex(\"Pony\", index)\n        new_state = project_state.clone()\n        operation.state_forwards(\"test_add_index\", new_state)\n        self.assertEqual(len(new_state.models[\"test_add_index\", \"pony\"].options[\"indexes\"]), 1)\n        self.assertIndexNotExists(\"test_add_index_pony\", [\"pink\"])\n        # Test the database alteration\n        with connection.schema_editor() as editor:\n            operation.database_forwards(\"test_add_index\", editor, project_state, new_state)\n        self.assertIndexExists(\"test_add_index_pony\", [\"pink\"])\n        # And test reversal\n        with connection.schema_editor() as editor:\n            operation.database_backwards(\"test_add_index\", editor, new_state, project_state)\n        self.assertIndexNotExists(\"test_add_index_pony\", [\"pink\"])\n        # And deconstruction\n        definition = operation.deconstruct()\n        self.assertEqual(definition[0], \"AddIndex\")\n        self.assertEqual(definition[1], [])\n        self.assertEqual(definition[2], {\"model_name\": \"Pony\", \"index\": index})\n", "def test_rename_model_with_proxy(self):\n    \"\"\"\n    Tests the RenameModel operation on a model which has a superclass that\n    has a proxy.\n    \"\"\"\n    project_state = self.set_up_test_model(\n        \"test_rmwsp\", proxy_model=True, related_model=True\n    )\n    # Test the state alteration\n    operation = migrations.RenameModel(\"ProxyRider\", \"HorseRider\")\n    self.assertEqual(\n        operation.describe(), \"Rename model ProxyRider to HorseRider\"\n    )\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_rmwsp\", new_state)\n    self.assertNotIn((\"test_rmwsp\", \"proxyrider\"), new_state.models)\n    self.assertIn((\"test_rmwsp\", \"horserider\"), new_state.models)\n    # RenameModel also repoints all incoming FKs and M2Ms\n    self.assertEqual(\n        new_state.models[\"test_rmwsp\", \"horserider\"]\n        .fields[\"friend\"]\n        .remote_field.model,\n        \"self\",\n    )\n    HorseRider = new_state.apps.get_model(\"test_rmwsp\", \"horserider\")\n    self.assertIs(\n        HorseRider._meta.get_field(\"horserider\").remote_field.model, HorseRider\n    )\n    # Before running the migration we have a table for Proxy Rider, not\n    # Horse Rider.\n    self.assertTableExists(\"test_rmwsp_proxyrider\")\n    self.assertTableNotExists(\"test_rmwsp_horserider\")\n    if connection.features.supports_foreign_keys:\n        self.assertFKNotExists(\n            \"test_rmwsp_proxyrider\", [\"friend_id\"], (\"test_rmwsp_proxyrider\", \"id\")\n        )\n        self.assertFKNotExists(\n            \"test_rmwsp_rider\", [\"friend_id\"], (\"test_rmwsp_proxyrider\", \"id\")\n        )\n    with connection.schema_editor(\n        atomic=connection.features.supports_atomic_references_rename\n    ) as editor:\n        operation.database_forwards(\"test_rmwsp\", editor, project_state, new_state)\n    # Now we have a horse rider table, not proxy rider.\n    self.assertTableNotExists(\"test_rmwsp_proxyrider\")\n    self.assertTableExists(\"test_rmwsp_horserider\")\n    if connection.features.supports_foreign_keys:\n        # but the Foreign keys still point at proxy rider, not horse rider\n        self.assertFKNotExists(\n", "    def test_references_field(self):\n        operation = AddIndex(\"Model\", models.Index(fields=[\"field\"]))\n        # References field.\n        self.assertTrue(operation.references_field(\"Model\", \"field\", \"migrations\"))\n        # Doesn't reference.\n        self.assertFalse(operation.references_field(\"Model\", \"other_field\", \"migrations\"))\n"], "sample_69": ["def test_set_in_layout():\n    fig, ax = plt.subplots()\n    ln, = ax.plot(range(5))\n    assert ln.get_in_layout()\n    ax.set_in_layout(False)\n    assert not ln.get_in_layout()\n    ln.set_in_layout(True)\n    assert ln.get_in_layout()\n", "def test_set_transform():\n    \"\"\"Test setting of transform on an Artist.\"\"\"\n    art = martist.Artist()\n    art.set_transform(mtransforms.IdentityTransform())\n    assert art.is_transform_set()\n\n    art.set_transform(mtransforms.IdentityTransform())\n    assert art.is_transform_set()\n\n    with pytest.raises(TypeError, match=\"'set_transform' got an unexpected keyword argument\"):\n        art.set_transform(transform=None)\n", "def test_alpha():\n    art = martist.Artist()\n    art.set_alpha(0.5)\n    assert art.get_alpha() == 0.5\n    art.set_alpha(None)\n    assert art.get_alpha() is None\n\n    # test array of alpha values\n    art._set_alpha_for_array([0.5, 0.5])\n    assert art.get_alpha().shape == (2,)\n    assert np.allclose(art.get_alpha(), 0.5)\n    art._set_alpha_for_array([0.5, 0.1, np.nan])\n    assert art.get_alpha().shape == (3,)\n    assert np.allclose(art.get_alpha()[:2], 0.5)\n    assert np.isnan(art.get_alpha()[2])\n", "def test_set_property():\n    \"\"\"Test behavior when a property is set using the auto-generated set() function.\"\"\"\n    class MyArtist(martist.Artist):\n            self._myparam1 = val\n\n    art = MyArtist()\n    with pytest.raises(ValueError, match='^cannot set property myparam1'):\n        art.set(myparam1='value')\n    art.set(myparam1=1)\n    assert art.get_myparam1() == 1\n", "def test_get_units():\n    \"\"\"Test Artist units conversion.\"\"\"\n    # Test units without axes\n    art = martist.Artist()\n    assert art.have_units() is False\n    assert art.convert_xunits(1) == 1\n    assert art.convert_yunits(1) == 1\n\n    # Test units with axes\n    fig, ax = plt.subplots()\n    ax.xaxis.set_units('cm')\n    ax.yaxis.set_units('cm')\n    assert art.have_units() is False\n    with pytest.raises(AttributeError):\n        art.convert_xunits(1)\n    with pytest.raises(AttributeError):\n        art.convert_yunits(1)\n    art.axes = ax\n    assert art.have_units()\n    assert art.convert_xunits(1) == 1\n    assert art.convert_yunits(1) == 1\n    ax.set_xlim(1, 2)\n    assert art.convert_xunits(1) == 1  # value is in data units\n    assert art.convert_yunits(1) == 1  # value is in data units\n    ax.set_xlim(1, 10)\n    assert art.convert_xunits(1) == 10  # value is in data units\n    assert art.convert_yunits(1) == 1  # value is in data units\n"], "sample_127": ["def test_latex_RationalField():\n    assert latex(field('x', 2)) == r\"\\mathbb{Z}/(2)\"\n    assert latex(field('x', 7)) == r\"\\mathbb{Z}/(7)\"\n", "compilation error", "compilation error", "def test_latex_FourierSeries_periodic():\n    from sympy import symbols, sin, cos, exp, fourier_series\n    x = symbols('x')\n    assert latex(fourier_series(sin(x), (x, -pi, pi), periodic=True)) == \\\n        r'\\left(2 \\sin{\\left (x \\right )} + \\frac{1}{2} \\sin{\\left (x \\right )} + \\frac{1}{2} \\sin{\\left (2 x \\right )} + \\frac{1}{3} \\sin{\\left (3 x \\right )} + \\ldots\\right)'\n", "def test_latex_Indexed():\n    i, j = symbols('i j')\n    M = MatrixSymbol('M', 3, 3)\n    assert latex(IndexedBase(M)[i]) == r\"M_{i}\"\n    assert latex(IndexedBase(M)[i, j]) == r\"M_{i, j}\"\n    assert latex(M[i, j]) == r\"M_{i, j}\"\n    assert latex(M[i, j] + 1) == r\"M_{i, j} + 1\"\n    assert latex(2 * M[i, j]) == r\"2 M_{i, j}\"\n    assert latex(M[i, j] * 3) == r\"M_{i, j} 3\"\n    assert latex(3 * M[i, j]) == r\"3 M_{i, j}\"\n    assert latex(M[i, j] + M[j, i]) == r\"M_{i, j} + M_{j, i}\"\n    assert latex(M[i, j] * M[j, i]) == r\"M_{i, j} M_{j, i}\"\n    assert latex(2 * M[i, j] + 3 * M[j, i]) == r\"2 M_{i, j} + 3 M_{j, i}\"\n    assert latex(M[i, j] * 2 + M[j, i] * 3) == r\"M_{i, j} 2 + M_{j, i} 3\"\n"], "sample_65": ["    def test_make_list01(self):\n        output = self.engine.render_to_string(\"makelist01\", {\"var\": \"hello\"})\n        self.assertEqual(output, \"h\")\n", "    def test_dictsort01(self):\n        output = self.engine.render_to_string(\"dictsort01\", {\"a\": [{\"foo\": 1}, {\"foo\": 2}]})\n        self.assertEqual(output, \"[{'foo': 1}, {'foo': 2}]\")\n", "    def test_stringformat01(self):\n        output = self.engine.render_to_string(\"stringformat01\", {\"value\": \"Hello\"})\n        self.assertEqual(output, \"Hello is good.\")\n", "    def test_default_places(self):\n        self.assertEqual(floatformat(34.23234), \"34.2\")\n        self.assertEqual(floatformat(34.00000), \"34\")\n        self.assertEqual(floatformat(34.26000), \"34.3\")\n", "    def test_stringformat(self):\n        self.assertEqual(stringformat(\"Hello, %s\", \"World\"), \"Hello, World\")\n        self.assertEqual(stringformat(\"Hello, %s\", \"World\", 1), \"Hello, World\")\n        self.assertEqual(stringformat(\"Hello, %s\", \"World\", 2), \"Hello, World\")\n        self.assertEqual(stringformat(\"Hello, %s\", \"World\", -1), \"Hello, World\")\n        self.assertEqual(stringformat(\"Hello, %s\", \"World\", \"-2\"), \"\")\n        self.assertEqual(stringformat(\"Hello, %s\", \"World\", \"2g\"), \"Hello, 2.0\")\n        self.assertEqual(stringformat(\"Hello, %s\", \"World\", \"2u\"), \"Hello, 2.0\")\n        self.assertEqual(stringformat(\"Hello, %s\", 123), \"Hello, 123\")\n        self.assertEqual(stringformat(\"Hello, %s\", 123.456), \"Hello, 123.5\")\n        self.assertEqual(stringformat(\"Hello, %s\", \"123.456\"), \"Hello, 123.5\")\n        self.assertEqual(stringformat(\"Hello, %s\", \"123e-5\"), \"Hello, 0.0000123\")\n"], "sample_28": ["    def setUp(self):\n        self.site = admin.AdminSite()\n        self.request_factory = RequestFactory()\n        self.u1 = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n", "    def setUp(self):\n        self.request_factory = RequestFactory()\n", "    def setUpTestData(cls):\n        cls.u1 = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.Article = Article.objects.create(title='Test Article', content='Test content')\n", "    def setUp(self):\n        self.request_factory = RequestFactory()\n        self.u1 = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        self.site = admin.AdminSite(name=\"test_adminsite\")\n        self.site.register(User)\n        self.site.register(Article)\n\n        self.urlconf = [\n            path('test_admin/admin/', self.site.urls),\n        ]\n", "    def setUp(self):\n        self.site = admin.AdminSite()\n        self.request_factory = RequestFactory()\n"], "sample_89": ["def test_get_fslocation_from_item():\n    \"\"\"Ensure get_fslocation_from_item handles various possible cases.\"\"\"\n    item = nodes.Item(\"test_name\", session=nodes.Session())\n    assert get_fslocation_from_item(item) == (None, -1)\n\n    item.location = (\"path/to/file.py\", 10, \"docstring\")\n    assert get_fslocation_from_item(item) == (\"path/to/file.py\", 10)\n\n    item.obj = object()\n    assert get_fslocation_from_item(item) == getfslineno(item.obj)\n\n    item.fspath = py.path.local(\"path/to/file.py\")\n    assert get_fslocation_from_item(item) == (\"path/to/file.py\", None)\n\n    item.fspath = None\n    assert get_fslocation_from_item(item) == (\"unknown location\", -1)\n", "def test_get_fslocation_from_item():\n    \"\"\"Test get_fslocation_from_item method\n\n    Ensure it returns the correct location information for different item types.\n    \"\"\"\n    item = nodes.Item(\"test_item\", nodeid=\"path/to/item.py\")\n    # Item with location attribute\n    item.location = (\"path/to/item.py\", 10, \"some content\")\n    assert get_fslocation_from_item(item) == (\"path/to/item.py\", 10)\n\n    # Item with fspath attribute\n    item.fspath = py.path.local(\"path/to/item.py\")\n    assert get_fslocation_from_item(item) == (\"path/to/item.py\", -1)\n\n    # Item without location or fspath attribute\n    item.location = None\n    item.fspath = None\n    assert get_fslocation_from_item(item) == (\"unknown location\", -1)\n\n    # Item with obj attribute\n    item.obj = object()\n    assert get_fslocation_from_item(item) == (\"unknown location\", -1)\n", "def test_splitnode():\n    result1 = nodes._splitnode(\"\")\n    assert result1 == ()\n\n    result2 = nodes._splitnode(\"foo\")\n    assert result2 == (\"foo\",)\n\n    result3 = nodes._splitnode(\"foo/bar\")\n    assert result3 == (\"foo\", \"bar\")\n\n    result4 = nodes._splitnode(\"foo/bar::TestBaz\")\n    assert result4 == (\"foo\", \"bar\", \"TestBaz\")\n\n    result5 = nodes._splitnode(\"foo/bar\")\n    result5[-1] = \"bar::TestBaz\"\n    assert result5 == (\"foo\", \"bar::TestBaz\")\n\n    result6 = nodes._splitnode(\"foo/bar::TestBaz\")\n    assert result6 == (\"foo\", \"bar\", \"TestBaz\")\n\n    result7 = nodes._splitnode(\"foo/bar\")\n    result7[-1] = \"TestBaz\"\n    assert result7 == (\"foo\", \"bar\", \"TestBaz\")\n\n    result8 = nodes._splitnode(\"foo/bar::TestBaz\")\n    result8 = tuple(result8)\n    assert result8 == (\"foo\", \"bar\", \"TestBaz\")\n\n", "def test_Node_listchain():\n    \"\"\"Test the listchain method of the Node class.\"\"\"\n    node = nodes.Node(\"test_node\", nodeid=\"test_node\")\n    assert node.listchain() == [node]\n\n", "def test_NodeMeta_warn():\n    \"\"\"Check warning is issued when using NodeMeta\"\"\"\n    class TestClass(metaclass=nodes.NodeMeta):\n        pass\n\n    assert warnings.warn.warn_log is not None\n\n"], "sample_80": ["def test_format_timedelta(self):\n    cases = [\n        (pd.Timedelta(\"10 days 1 hour\"), \"10 days 01:00:00\"),\n        (pd.Timedelta(\"-3 days\"), \"-3 days +00:00:00\"),\n        (pd.Timedelta(\"3 hours\"), \"0 days 03:00:00\"),\n        (pd.Timedelta(\"NaT\"), \"NaT\"),\n        (\"foo\", \"'foo'\"),\n        (b\"foo\", \"b'foo'\"),\n        (1, \"1\"),\n        (1.0, \"1.0\"),\n        (pd.Timedelta(\"00:00:00\"), \"00:00:00\"),\n        (pd.Timedelta(\"0 days 00:00:00\"), \"0 days 00:00:00\"),\n    ]\n    for item, expected in cases:\n        actual = formatting.format_timedelta(item)\n        assert expected == actual\n\n    # Test with timedelta_format='date'\n    cases_date = [\n        (pd.Timedelta(\"10 days 1 hour\"), \"10 days\"),\n        (pd.Timedelta(\"-3 days\"), \"-3 days\"),\n        (pd.Timedelta(\"3 hours\"), \"0 days\"),\n        (pd.Timedelta(\"NaT\"), \"NaT\"),\n    ]\n    for item, expected in cases_date:\n        actual = formatting.format_timedelta(item, timedelta_format=\"date\")\n        assert expected == actual\n\n    # Test with timedelta_format='time'\n    cases_time = [\n        (pd.Timedelta(\"10 days 1 hour\"), \"01:00:00\"),\n        (pd.Timedelta(\"-3 days\"), \"+00:00:00\"),\n        (pd.Timedelta(\"3 hours\"), \"03:00:00\"),\n        (pd.Timedelta(\"NaT\"), \"NaT\"),\n    ]\n    for item, expected in cases_time:\n        actual = formatting.format_timedelta(item, timedelta_format=\"time\")\n        assert expected == actual\n", "def test_inline_dask_repr(self):\n    import dask.array as da\n\n    array = da.from_array(np.arange(100))\n\n    actual = formatting.inline_dask_repr(array)\n    expected = \"dask.array<chunksize=(100,)>\"\n    assert actual == expected\n\n    array = da.from_array(np.arange(10).reshape(2, 5))\n    actual = formatting.inline_dask_repr(array)\n    expected = \"dask.array<chunksize=(5, 2)>\"\n    assert actual == expected\n\n    array = da.from_array(np.arange(10).reshape(2, 5))\n    actual = formatting.inline_dask_repr(array)\n    expected = \"dask.array<chunksize=(5, 2)>\"\n    assert actual == expected\n\n    array = da.from_array(np.arange(10).reshape(5, 2))\n    actual = formatting.inline_dask_repr(array)\n    expected = \"dask.array<chunksize=(2, 5)>\"\n    assert actual == expected\n\n    array = da.from_array(np.arange(10).reshape(5, 2))\n    actual = formatting.inline_dask_repr(array)\n    expected = \"dask.array<chunksize=(2, 5)>\"\n    assert actual == expected\n\n    array = da.from_array(np.arange(10).reshape(2, 5, 2))\n    actual = formatting.inline_dask_repr(array)\n    expected = \"dask.array<chunksize=(2, 5, 2)>\"\n    assert actual == expected\n\n    array = da.from_array(np.arange(10).reshape(2, 5, 2))\n    actual = formatting.inline_dask_repr(array)\n    expected = \"dask.array<chunksize=(2, 5, 2)>\"\n    assert actual == expected\n\n    array = da.from_array(np.arange(10).reshape(5, 2, 2))\n    actual = formatting.inline_dask_repr(array)\n    expected = \"dask.array<chunksize=(2, 2, 5)>\"\n    assert actual == expected\n\n    array = da.from_array(np.arange(10).reshape(5, 2, 2))\n    actual = formatting.inline_dask_repr(array)\n    expected = \"dask.array<chunksize=(2, 2, 5)>\"\n    assert actual == expected\n", "def test_inline_sparse_repr(self):\n    array = sparse.COO(\n        np.array([0, 1, 2]),\n        np.array([0, 1, 2]),\n        np.array([3, 3, 3]),\n        shape=(3, 3)\n    )\n    expected = \"<COO: nnz=3, fill_value=3>\"\n    actual = formatting.inline_sparse_repr(array)\n    assert expected == actual\n\n    array = sparse.COO(\n        np.array([0, 0, 1]),\n        np.array([1, 2, 0]),\n        np.array([3, 3, 3]),\n        shape=(3, 3)\n    )\n    expected = \"<COO: nnz=3, fill_value=3>\"\n    actual = formatting.inline_sparse_repr(array)\n    assert expected == actual\n", "def test_inline_dask_repr(self):\n    da = xr.DataArray(\n        np.random.randn(10),\n        dims=\"x\",\n        coords={\"x\": np.arange(10)},\n    )\n\n    # dask default repr\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10,) meta=np.ndarray>\n        \"\"\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    # dask with meta attribute repr\n    da.meta = da\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10,) meta=np.ndarray meta=np.ndarray>\n        \"\"\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    # dask with meta attribute repr and meta is not np.ndarray\n    class CustomArray:\n            self.value = value\n\n            return \"CustomArray\"\n\n    da.meta = CustomArray(da)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10,) meta=CustomArray meta=np.ndarray>\n        \"\"\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n", "def test_inline_sparse_repr(self):\n    array = sparse.COO(np.array([0, 2, 2]), np.array([0, 2, 0]), np.array([3, 2, 1]))\n    actual = formatting.inline_sparse_repr(array)\n    expected = \"<COO: nnz=3, fill_value=0>\"\n    assert actual == expected\n\n"], "sample_124": ["def test_acsch_series():\n    x = Symbol('x')\n    assert acsch(x).series(x, 0, 8) == \\\n        1/x - x/6 + 7*x**3/360 - 31*x**5/15120 + 127*x**7/604800 + O(x**8)\n    t5 = acsch(x).expansion_term(5, x)\n    assert t5 == -7*x**5/360\n    assert acsch(x).expansion_term(7, x, t5, 0) == -31*x**7/15120\n", "def test_acsch_expansion():\n    x, y = symbols('x,y')\n    assert acsch(x+y).expand(trig=True) == acsch(x)*acsch(y) + acsch(x)*csch(y)\n    assert acsch(2*x).expand(trig=True) == 2*acsch(x)*csch(x)\n    assert acsch(3*x).expand(trig=True).expand() == \\\n        acsch(x)**3 + 3*acsch(x)*csch(x)**2\n", "def test_acsch_series():\n    x = Symbol('x')\n    t3 = acsch(x).expansion_term(3, x)\n    assert t3 == -1/x**3\n    assert acsch(x).expansion_term(5, x, t3, 0) == 2/x**5\n", "def test_acsc_series():\n    x = Symbol('x')\n    assert acsch(x).series(x, 0, 10) == \\\n        1/x + x/6 - 7*x**3/360 + 31*x**5/15120 - 127*x**7/604800 + O(x**8)\n    t5 = acsch(x).expansion_term(6, x)\n    assert t5 == 7*x**5/360\n    assert acsch(x).expansion_term(8, x, t5, 0) == -31*x**7/15120\n", "def test_acsch_simplifications():\n    x = Symbol('x')\n    assert acsch(x).simplify() == acsch(x)\n    assert acsch(1/x).simplify() == asinh(1/x)\n    assert acsch(x).simplify(acot) == -I*asin(I/x)\n    assert sech(x).simplify(acsc) == 1/(sqrt(x - 1) * sqrt(x + 1))\n"], "sample_64": ["    def test_override_prepopulated_fields_js(self):\n        \"\"\"\n        admin_modify template tags follow the standard search pattern\n        admin/app_label/model/template.html.\n        \"\"\"\n        article = Article.objects.all()[0]\n        request = self.request_factory.get(\n            reverse(\"admin:admin_views_article_change\", args=[article.pk])\n        )\n        request.user = self.superuser\n        admin = ArticleAdmin(Article, site)\n        extra_context = {\"show_publish\": True, \"extra\": True}\n        response = admin.change_view(\n            request, str(article.pk), extra_context=extra_context\n        )\n        template_context = prepopulated_fields_js(response.context_data)\n        self.assertIs(response.context_data[\"show_publish\"], True)\n        self.assertIs(response.context_data[\"extra\"], True)\n        self.assertIn('id=\"id_title\"', response.context_data[\"prepopulated_fields_json\"])\n        self.assertIn('id=\"id_content\"', response.context_data[\"prepopulated_fields_json\"])\n", "    def test_prepopulated_fields_js(self):\n        \"\"\"\n        prepopulated_fields_js template tag should pass whole context.\n        \"\"\"\n        request = self.request_factory.get(\n            reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n        )\n        request.user = self.superuser\n        admin = UserAdmin(User, site)\n        extra_context = {\"extra\": True}\n        response = admin.change_view(\n            request, str(self.superuser.pk), extra_context=extra_context\n        )\n        template_context = prepopulated_fields_js(response.context_data)\n        self.assertIs(template_context[\"extra\"], True)\n        self.assertIsNotNone(template_context[\"prepopulated_fields\"])\n        self.assertIsNotNone(template_context[\"prepopulated_fields_json\"])\n", "    def test_prepopulated_fields_js(self):\n        \"\"\"\n        prepopulated_fields_js template tag should render prepopulated fields.\n        \"\"\"\n        article = Article.objects.all()[0]\n        request = self.request_factory.get(\n            reverse(\"admin:admin_views_article_change\", args=[article.pk])\n        )\n        request.user = self.superuser\n        admin = ArticleAdmin(Article, site)\n        extra_context = {\"extra\": True}\n        response = admin.change_view(\n            request, str(article.pk), extra_context=extra_context\n        )\n        template_context = prepopulated_fields_js(response.context_data)\n        self.assertIs(template_context[\"extra\"], True)\n        self.assertIn('id\": \"#id_title\"', template_context[\"prepopulated_fields_json\"])\n", "    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(\n            username=\"super\", password=\"secret\", email=\"super@example.com\"\n        )\n        cls.article = Article.objects.create(title=\"Test title\", content=\"Test content\")\n", "    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(\n            username=\"super\", password=\"secret\", email=\"super@example.com\"\n        )\n"], "sample_15": ["def test_valid_language_code_in_languages(self):\n    self.assertEqual(check_setting_language_code(None), [])\n", "    def test_consistent_language_settings_valid_language_code(self):\n        for tag in self.valid_tags:\n            with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n                self.assertEqual(check_language_settings_consistent(None), [])\n", "def test_valid_language_settings_consistent(self):\n    # Test when LANGUAGE_CODE is valid and in LANGUAGES\n    with self.settings(LANGUAGE_CODE='en', LANGUAGES=[('en', 'English')]):\n        self.assertEqual(check_language_settings_consistent(None), [])\n\n    # Test when LANGUAGE_CODE is valid but not in LANGUAGES\n    with self.settings(LANGUAGE_CODE='fr', LANGUAGES=[('en', 'English')]):\n        self.assertEqual(check_language_settings_consistent(None), [E004])\n\n    # Test when LANGUAGE_CODE is invalid but in LANGUAGES\n    with self.settings(LANGUAGE_CODE='123', LANGUAGES=[('en', 'English')]):\n        self.assertEqual(check_language_settings_consistent(None), [\n            Error(E001.msg.format('123'), id=E001.id),\n            E004,\n        ])\n\n    # Test when LANGUAGE_CODE is invalid and not in LANGUAGES\n    with self.settings(LANGUAGE_CODE='123', LANGUAGES=[('en', 'English')]):\n        self.assertEqual(check_language_settings_consistent(None), [\n            Error(E001.msg.format('123'), id=E001.id),\n            E004,\n        ])\n", "def test_language_settings_consistent_valid(self):\n    for tag in self.valid_tags:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag, LANGUAGES=[(tag, tag)]):\n            self.assertEqual(check_language_settings_consistent(None), [])\n", "def test_inconsistent_language_settings_with_languages_bidi(self):\n    msg = (\n        'You have provided a value for the LANGUAGE_CODE setting that is '\n        'not in the LANGUAGES setting.'\n    )\n    for tag in ['fr', 'fr-CA', 'fr-357']:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag, LANGUAGES_BIDI=['en']):\n            self.assertEqual(check_language_settings_consistent(None), [\n                Error(msg, id='translation.E004'),\n            ])\n"], "sample_2": ["def test_p4_pix2foc_with_invalid_shape():\n    \"\"\"\n    Issue #1395\n    \"\"\"\n    w = wcs.WCS(naxis=2)\n\n    xy = np.random.random((2, 3))\n    with pytest.raises(ValueError) as exc:\n        xy2 = w.p4_pix2foc(xy, 1)\n    assert exc.value.args[0] == 'When providing two arguments, the array must be of shape (N, 2)'\n\n    xy = np.random.random((2, 1))\n    with pytest.raises(ValueError) as exc:\n        xy2 = w.p4_pix2foc(xy, 1)\n    assert exc.value.args[0] == 'When providing two arguments, the array must be of shape (N, 2)'\n", "def test_sip_init():\n    \"\"\"\n    Test initialization with SIP coefficients in the header.\n    \"\"\"\n    header = get_pkg_data_contents('data/siponly.hdr', encoding='binary')\n    w = wcs.WCS(header)\n    assert isinstance(w.sip, wcs.Sip)\n    assert w.sip.a_order == 4\n    assert w.sip.b_order == 4\n    assert w.sip.ap_order == 0\n    assert w.sip.bp_order == 0\n    assert_array_equal(w.sip.crpix, [2048., 1024.])\n", "def test_radians():\n    \"\"\"\n    Test for #5457\n    \"\"\"\n    header = get_pkg_data_contents(\n        'data/units.hdr', encoding='binary')\n    w = wcs.WCS(header)\n    w.wcs.unit = 'rad'\n    assert w.wcs.cdelt[0] == 1\n    assert w.wcs.cunit[0] == 'rad'\n    w = wcs.WCS(header, naxis=[1])\n    w.wcs.unit = 'rad'\n    assert w.wcs.cdelt[0] == 1\n    assert w.wcs.cunit[0] == 'rad'\n", "def test_subclassing():\n    \"\"\"\n    Test that WCS objects can be subclassed without breaking any of the\n    WCS methods.\n    \"\"\"\n    class MyWCS(wcs.WCS):\n        pass\n\n    # Make sure that the methods are actually subclasses, not just\n    # inherited.\n    assert not hasattr(MyWCS, '_all_world2pix')\n    assert not hasattr(MyWCS, '_array_converter')\n    assert not hasattr(MyWCS, 'all_world2pix')\n    assert not hasattr(MyWCS, 'all_pix2world')\n\n    # Make sure that we can subclass WCS and still use the WCS\n    # methods.\n    w = MyWCS({'CTYPE1': 'RA---TAN', 'CTYPE2': 'DEC--TAN',\n               'CUNIT1': 'deg', 'CUNIT2': 'deg',\n               'CRPIX1': 1, 'CRPIX2': 1,\n               'CRVAL1': 0., 'CRVAL2': 0.,\n               'CDELT1': 1., 'CDELT2': 1.})\n    w.wcs.set()\n\n    w2 = wcs.WCS({'CTYPE1': 'RA---TAN', 'CTYPE2': 'DEC--TAN',\n                  'CUNIT1': 'deg', 'CUNIT2': 'deg',\n                  'CRPIX1': 1, 'CRPIX2': 1,\n                  'CRVAL1': 0., 'CRVAL2': 0.,\n                  'CDELT1': 1., 'CDELT2': 1.})\n    w2.wcs.set()\n\n    assert_array_almost_equal(w.all_pix2world([0., 0.], 1), w2.all_pix2world([0., 0.], 1))\n    assert_array_almost_equal(w.wcs_pix2world([0., 0.], 1), w2.wcs_pix2world([0., 0.], 1))\n", "def test_tolerance():\n    \"\"\"\n    Test that tolerance is respected in `all_world2pix`\n    \"\"\"\n    w = wcs.WCS(naxis=2)\n    w.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\"]\n    w.wcs.cdelt = [1, 1]\n    w.wcs.crpix = [1, 1]\n    w.wcs.crval = [1, 1]\n    w.wcs.set()\n\n    # The distortion coefficients in this WCS are generated by\n    # `distortion_paper` to make sure that some points are slowly\n    # converging.  The tolerance should be respected by the iterative\n    # solver.\n    # The distortion coefficients are generated to have a maximum\n    # value of 1000.\n    distortion = np.linspace(0, 1000, 100)\n    distortion2 = np.linspace(0, 1000, 100)\n    w.sip = wcs.Sip(np.zeros((2, 2)), np.zeros((2, 2)), None, None, [1, 1])\n    w.det2im1 = wcs.DistortionLookupTable(\n        np.array([distortion, distortion]).T, [1, 1], [0, 0], [1, 1])\n    w.det2im2 = wcs.DistortionLookupTable(\n        np.array([distortion2, distortion2]).T, [1, 1], [0, 0], [1, 1])\n\n        w.tolerance = tolerance\n        w.wcs_world2pix = lambda x, o: np.array(x) + np.array(distortion)\n        return w\n\n    with pytest.raises(wcs.wcs.NoConvergence):\n        make_wcs(1e-5).all_world2pix(np.array([[1, 1]]), origin=1)\n\n    make_wcs(0.05).all_world2pix(np.array([[1, 1]]), origin=1)\n"], "sample_41": ["def test_formset_get_form_kwargs(self):\n    class CustomBaseFormSet(BaseFormSet):\n            if index == 0:\n                return {'custom_kwarg': 'zero'}\n            elif index == 1:\n                return {'custom_kwarg': 'one'}\n            else:\n                return {}\n\n    CustomFormSet = formset_factory(CustomKwargForm, formset=CustomBaseFormSet, extra=3)\n    formset = CustomFormSet(form_kwargs={'custom_kwarg': 'form_kwargs'})\n    for i, form in enumerate(formset):\n        if i == 0:\n            self.assertEqual(form.custom_kwarg, 'zero')\n        elif i == 1:\n            self.assertEqual(form.custom_kwarg, 'one')\n        else:\n            self.assertEqual(form.custom_kwarg, 'form_kwargs')\n", "def test_formset_total_error_count_with_formset_errors(self):\n    \"\"\"A formset with errors on each form should count those errors.\"\"\"\n    data = [\n        [('Calexico', '100'), ('Calexico', '')],\n        [('Calexico', ''), ('Calexico', '')],\n    ]\n    for formset_data, expected_error_count in data:\n        formset = self.make_choiceformset(formset_data)\n        self.assertEqual(formset.total_error_count(), expected_error_count * len(formset.forms))\n        formset = self.make_choiceformset(formset_data, validate_max=True)\n        self.assertEqual(formset.total_error_count(), expected_error_count * len(formset.forms))\n", "    def test_ordered_forms_ordering_field_value_is_none(self):\n        \"\"\"\n        If the ordering field is left blank, the form will be placed at the\n        end of the ordered_forms list.\n        \"\"\"\n        ChoiceFormSet = formset_factory(Choice, can_order=True)\n        initial = [{'choice': 'Calexico', 'votes': 100}, {'choice': 'Fergie', 'votes': 900}]\n        formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n        self.assertEqual(\n            [form.cleaned_data for form in formset.ordered_forms],\n            [\n                {'votes': 100, 'ORDER': 1, 'choice': 'Calexico'},\n                {'votes': 900, 'ORDER': 2, 'choice': 'Fergie'},\n            ],\n        )\n        # Leave the ordering field blank.\n        data = {\n            'choices-TOTAL_FORMS': '3',  # the number of forms rendered\n            'choices-INITIAL_FORMS': '2',  # the number of forms with initial data\n            'choices-MAX_NUM_FORMS': '0',  # max number of forms\n            'choices-0-choice': 'Calexico',\n            'choices-0-votes': '100',\n            'choices-0-ORDER': '',\n            'choices-1-choice': 'Fergie',\n            'choices-1-votes': '900',\n            'choices-1-ORDER': '2',\n            'choices-2-choice': 'The Decemberists',\n            'choices-2-votes': '500',\n            'choices-2-ORDER': '',\n        }\n        formset = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertTrue(formset.is_valid())\n        self.assertEqual(\n            [form.cleaned_data for form in formset.ordered_forms],\n            [\n                {'votes': 500, 'ORDER': None, 'choice': 'The Decemberists'},\n                {'votes': 100, 'ORDER': 1, 'choice': 'Calexico'},\n                {'votes': 900, 'ORDER': 2, 'choice': 'Fergie'},\n            ],\n        )\n", "    def setUp(self):\n        data = {\n            'choices-TOTAL_FORMS': '3',\n            'choices-INITIAL_FORMS': '2',\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-MAX_NUM_FORMS': '0',\n            'choices-0-choice': 'Calexico',\n            'choices-0-votes': '100',\n            'choices-0-ORDER': '0',\n            'choices-0-DELETE': 'on',\n            'choices-1-choice': 'Fergie',\n            'choices-1-votes': '900',\n            'choices-1-ORDER': '1',\n            'choices-1-DELETE': '',\n            'choices-2-choice': '',\n            'choices-2-votes': '',\n            'choices-2-ORDER': '1',\n            'choices-2-DELETE': '',\n        }\n        self.formset = ChoiceFormSet(data, auto_id=False, prefix='choices')\n", "    def test_valid_deletion_field(self):\n        \"\"\"Deletion field is valid if set to False.\"\"\"\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '0',\n            'choices-MAX_NUM_FORMS': '2',\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': '0',\n            'choices-0-DELETE': '',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '1',\n            'choices-1-DELETE': '',\n        }\n        ChoiceFormSet = formset_factory(Choice)\n        formset = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertTrue(formset.is_valid())\n"], "sample_132": ["def test_farthest_points():\n    points = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4)]\n    assert farthest_points(*points) == {(Point2D(-5, 2), Point2D(15, 4))}\n    p = Polygon((0, 0), (10, 0), (10, 10))\n    q = Polygon((5, 5), (15, 5), (15, 15))\n    assert farthest_points(p, q) == {(Point2D(5, 5), Point2D(15, 15))}\n    points = [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n    assert farthest_points(*points) == {(Point2D(1, 1), Point2D(1, 5))}\n    points = [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5)]\n    assert farthest_points(*points) == {(Point2D(1, 1), Point2D(5, 5))}\n", "def test_farthest_points():\n    p = Point2D(1, 1), Point2D(1, 2), Point2D(3, 1), Point2D(-5, 2), Point2D(15, 4)\n    assert farthest_points(*p) == {(Point2D(-5, 2), Point2D(15, 4))}\n    p = Point2D(1, 1), Point2D(1, 2), Point2D(3, 1), Point2D(-5, 2), Point2D(5, 4)\n    assert farthest_points(*p) == {(Point2D(-5, 2), Point2D(5, 4))}\n    p = Point2D(1, 1), Point2D(1, 2), Point2D(3, 1), Point2D(-5, 2), Point2D(15, 4), Point2D(15, 4)\n    assert farthest_points(*p) == {(Point2D(-5, 2), Point2D(15, 4)), (Point2D(15, 4), Point2D(15, 4))}\n    p = Point2D(1, 1), Point2D(1, 2), Point2D(3, 1), Point2D(-5, 2), Point2D(15, 4), Point2D(-5, 2)\n    assert farthest_points(*p) == {(Point2D(-5, 2), Point2D(15, 4))}\n    p = Point2D(1, 1), Point2D(1, 2), Point2D(3, 1), Point2D(-5, 2), Point2D(15, 4), Point2D(-5, 2), Point2D(-5, 2)\n    assert farthest_points(*p) == {(Point2D(-5, 2), Point2D(15, 4))}\n    p = Point2D(1, 1), Point2D(1, 2), Point2D(3, 1), Point2D(-5, 2), Point2D(15, 4), Point2D(-5, 2), Point2D(15, 4)\n   ", "def test_farthest_points():\n    p = Point2D(0, 0)\n    q = Point2D(2, 0)\n    r = Point2D(3, 4)\n    s = Point2D(-5, 2)\n    assert farthest_points(p, q, r, s) == {(p, r)}\n    assert farthest_points(Point2D(1, 1), Point2D(1, 1), Point2D(1, 1), Point2D(1, 1)) == {(Point2D(1, 1), Point2D(1, 1))}\n    p = Point2D(0, 0)\n    q = Point2D(2, 0)\n    r = Point2D(3, 4)\n    s = Point2D(-5, 2)\n    t = Point2D(-5, -2)\n    assert farthest_points(p, q, r, s, t) == {(p, r)}\n", "def test_closest_points():\n    assert closest_points(Point2D(0, 0), Point2D(3, 0), Point2D(2, 2)) == {(Point2D(0, 0), Point2D(3, 0))}\n    assert closest_points(Point2D(0, 0), Point2D(3, 0), Point2D(0, 2)) == {(Point2D(0, 0), Point2D(3, 0))}\n    points = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4)]\n    assert closest_points(*points) == {(Point2D(0, 0), Point2D(1, 0))}\n    raises(ValueError, lambda: closest_points(Point2D(0, 0), Point2D(3, 0)))\n    raises(ValueError, lambda: closest_points(Point2D(0, 0), Point2D(3, 0), '3'))\n    points_with_nan = [Point2D(0, 0), Point2D(3, float('nan'))]\n    raises(ValueError, lambda: closest_points(*points_with_nan))\n", "def test_farthest_points():\n    from sympy.geometry import Point2D, Triangle, farthest_points\n    from sympy.geometry.util import closest_points\n    assert farthest_points(Point2D(0, 0), Point2D(3, 0), Point2D(3, 4)) == {(Point2D(0, 0), Point2D(3, 4))}\n    assert farthest_points(Point2D(0, 0), Point2D(3, 0), Point2D(0, 2), Point2D(3, 4)) == {(Point2D(0, 0), Point2D(3, 4))}\n    assert farthest_points(Point2D(0, 0), Point2D(3, 0), Point2D(0, 2), Point2D(3, 4), Point2D(0, 1)) == {(Point2D(0, 0), Point2D(3, 4))}\n\n    # Test with a Polygon and a Point\n    t = Triangle(Point2D(0, 0), Point2D(3, 0), Point2D(3, 4))\n    p = Point2D(0, 0)\n    assert farthest_points(t, p) == {(Point2D(0, 0), Point2D(3, 4))}\n\n    # Test with the closest_points function\n    assert set(closest_points(*farthest_points(Point2D(0, 0), Point2D(3, 0), Point2D(3, 4)))) == {(Point2D(0, 0), Point2D(3, 0))}\n\n    # Test with fewer than 2 points\n    raises(ValueError, lambda: farthest_points(Point2D(0, 0)))\n    raises(ValueError, lambda: farthest_points(Point2D(0, 0), Point2D(3, 0)))\n"], "sample_152": ["def test_issue_20223():\n    A = ImmutableDenseNDimArray([1, 2, 3, 4])\n    B = ImmutableDenseNDimArray([5, 6, 7, 8])\n    C = A + B\n    assert C.tolist() == [[6, 8], [7, 9]]\n\n    A = ImmutableDenseNDimArray([1, 2, 3, 4])\n    B = ImmutableDenseNDimArray([5, 6, 7, 8])\n    C = A - B\n    assert C.tolist() == [[-4, -4], [-5, -4]]\n\n    A = ImmutableDenseNDimArray([1, 2, 3, 4])\n    B = ImmutableDenseNDimArray([5, 6, 7, 8])\n    C = A * 2\n    assert C.tolist() == [[2, 4], [6, 8]]\n\n    A = ImmutableDenseNDimArray([1, 2, 3, 4])\n    B = ImmutableDenseNDimArray([5, 6, 7, 8])\n    C = 2 * A\n    assert C.tolist() == [[2, 4], [6, 8]]\n\n    A = ImmutableDenseNDimArray([1, 2, 3, 4])\n    B = ImmutableDenseNDimArray([5, 6, 7, 8])\n    C = A / 2\n    assert C.tolist() == [[0.5, 1.0], [1.5, 2.0]]\n\n    A = ImmutableDenseNDimArray([1, 2, 3, 4])\n    B = ImmutableDenseNDimArray([5, 6, 7, 8])\n    C = -A\n    assert C.tolist() == [[-1, -2], [-3, -4]]\n", "def test_issue_12345():\n    # Test transpose operation\n    A = ImmutableDenseNDimArray([[1, 2], [3, 4]])\n    B = A.transpose()\n    assert B == ImmutableDenseNDimArray([[1, 3], [2, 4]])\n\n    # Test transpose operation with an array of shape (1, 1)\n    C = ImmutableDenseNDimArray([[1]])\n    D = C.transpose()\n    assert D == ImmutableDenseNDimArray([[1]])\n\n    # Test transpose operation with an empty array\n    E = ImmutableDenseNDimArray([])\n    F = E.transpose()\n    assert F == ImmutableDenseNDimArray([])\n\n    # Test transpose operation with a 3D array\n    G = ImmutableDenseNDimArray([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n    H = G.transpose()\n    assert H == ImmutableDenseNDimArray([[[1, 5], [2, 6], [3, 7], [4, 8]]])\n\n    # Test transpose operation with a non-square 2D array\n    I = ImmutableDenseNDimArray([[1, 2, 3], [4, 5, 6]])\n    J = I.transpose()\n    assert J == ImmutableDenseNDimArray([[1, 4], [2, 5], [3, 6]])\n", "def test_issue_17756():\n    A = ImmutableDenseNDimArray([[1, 2, 3], [4, 5, 6]])\n    B = ImmutableDenseNDimArray([[7, 8, 9], [10, 11, 12]])\n    C = A + B\n    assert C.shape == (2, 3)\n    assert C == ImmutableDenseNDimArray([[8, 10, 12], [14, 16, 18]])\n    assert C._eval_transpose() == ImmutableDenseNDimArray([[8, 14], [10, 16], [12, 18]])\n\n    A = ImmutableDenseNDimArray([[1, 2], [3, 4]])\n    C = A.transpose()\n    assert C == ImmutableDenseNDimArray([[1, 3], [2, 4]])\n\n    A = ImmutableDenseNDimArray([[1, 2], [3, 4]])\n    C = A.conjugate()\n    assert C == ImmutableDenseNDimArray([[1, 2], [3, 4]])\n\n    A = ImmutableDenseNDimArray([[1, 2], [3, 4]])\n    C = A.adjoint()\n    assert C == ImmutableDenseNDimArray([[1, 3], [2, 4]])\n\n    A = ImmutableDenseNDimArray([1, 2, 3])\n    C = A.conjugate()\n    assert C == ImmutableDenseNDimArray([1, 2, 3])\n\n    A = ImmutableDenseNDimArray([1, 2, 3])\n    C = A.adjoint()\n    assert C == ImmutableDenseNDimArray([1, 2, 3])\n\n    A = ImmutableDenseNDimArray([[1, 2], [3, 4]])\n    C = A[0, :]\n    assert C == ImmutableDenseNDimArray([1, 2])\n\n    A = ImmutableDenseNDimArray([[1, 2], [3, 4]])\n    C = A[:, 0]\n    assert C == ImmutableDenseNDimArray([1, 3])\n\n    A = ImmutableDenseNDimArray([[1, 2], [3, 4]])\n    C = A[0, 0]\n    assert C == 1\n\n    A", "def test_array_shape_operations():\n    # Test shape assignment\n    for ArrayType in array_types:\n        A = ArrayType([1, 2, 3, 4])\n        A.shape = (2, 2)\n        assert A.shape == (2, 2)\n\n        # Test shape comparison\n        A = ArrayType([1, 2, 3, 4])\n        B = ArrayType([1, 2, 3, 4])\n        assert A.shape == B.shape\n        assert A.shape != (1, 1)\n\n        # Test shape inequality\n        A = ArrayType([1, 2, 3, 4])\n        B = ArrayType([5, 6, 7, 8])\n        assert A.shape != B.shape\n\n        # Test invalid shape assignment\n        raises(ValueError, lambda: A.shape = (1,))\n\n        # Test invalid shape assignment\n        A = ArrayType([1, 2, 3, 4])\n        raises(ValueError, lambda: A.shape = (-1,))\n\n        # Test invalid shape assignment\n        A = ArrayType([1, 2, 3, 4])\n        raises(ValueError, lambda: A.shape = (1, -1))\n\n    # Test shape operations on immutable array\n    A = ImmutableDenseNDimArray([1, 2, 3, 4])\n    raises(NotImplementedError, lambda: A.shape = (2, 2))\n\n    # Test shape operations on mutable array\n    A = MutableDenseNDimArray([1, 2, 3, 4])\n    A.shape = (2, 2)\n    assert A.shape == (2, 2)\n", "def test_issue_16737():\n    from sympy.tensor.array.dense_ndim_array import ImmutableDenseNDimArray\n    from sympy.tensor.array.dense_ndim_array import ImmutableDenseNDimArray\n    for ArrayType in array_types:\n        array = ArrayType([1, 2, 3, 4, 5])\n        assert array[0:5] == array\n        assert array[:5] == array\n        assert array[0:10] == array\n        assert array[:10] == array\n        assert array[-5:] == array\n        assert array[-10:] == array\n        assert array[0] == Array([1])\n        assert array[:1] == Array([1])\n        raises(ValueError, lambda: array[1:0])\n        raises(ValueError, lambda: array[-6:])\n        raises(ValueError, lambda: array[10:])\n        raises(ValueError, lambda: array[-10:0])\n"], "sample_51": ["def test_directory_index_template_translations(self):\n    \"\"\"Directory index template translations are used correctly\"\"\"\n    # Create a translation of the default directory index template\n    from django.utils.translation import ugettext as _\n    with override_settings(\n        LANGUAGES=[\n            (\"fr\", _(\"French\")),\n            (\"en\", _(\"English\")),\n        ]\n    ):\n        response = self.client.get(\"/%s/\" % self.prefix)\n        self.assertContains(response, _(\"Index of ./\"))\n\n        # Test that the template is overridden when a custom template is provided\n        self.assertNotContains(response, _(\"Index of ./\"))\n        with override_settings(\n            TEMPLATES=[\n                {\n                    \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n                    \"OPTIONS\": {\n                        \"loaders\": [\n                            (\n                                \"django.template.loaders.locmem.Loader\",\n                                {\n                                    \"static/directory_index.html\": _(\"Test index in French\"),\n                                },\n                            ),\n                        ],\n                    },\n                }\n            ]\n        ):\n            response = self.client.get(\"/%s/\" % self.prefix)\n            self.assertContains(response, _(\"Test index in French\"))\n", "def test_show_index(self):\n    \"\"\"Test serving a directory with show_indexes set to True\"\"\"\n    response = self.client.get(\"/%s/\" % self.prefix)\n    self.assertContains(response, \"Index of ./\")\n    self.assertContains(response, \"file.txt\")\n", "    def test_absolute_path(self):\n        \"\"\"Test serving a file with an absolute path\"\"\"\n        file_name = \"file.txt\"\n        response = self.client.get(\"/%s/%s\" % (self.prefix, file_name))\n        self.assertEqual(404, response.status_code)\n", "def test_directory_index_template_override(self):\n    \"\"\"Directory index template can be overridden by user.\"\"\"\n    response = self.client.get(\"/%s/\" % self.prefix)\n    self.assertContains(response, \"Index of ./\")\n    # Directories have a trailing slash.\n    self.assertIn(\"subdir/\", response.context[\"file_list\"])\n    # Check if the correct template was used\n    self.assertEqual(response.template_name, \"static/directory_index\")\n", "def test_directory_index_custom_template_found(self):\n    \"\"\"Test directory_index view uses the provided custom template\"\"\"\n    response = self.client.get(\"/%s/\" % self.prefix)\n    self.assertEqual(response.template.name, \"static/directory_index.html\")\n    self.assertEqual(response.content, b\"Test index\")\n"], "sample_134": ["def test_cbrt():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    f = lambdify((a,), Cbrt(a), 'numpy')\n    assert abs(f(8) - 2) < 1e-16\n", "def test_identity():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    I = Identity(5)\n    assert I.shape == (5, 5)\n    printer = NumPyPrinter()\n    assert printer.doprint(I) == 'numpy.eye(5)'\n", "def test_CodegenArrayPermuteDims():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    M = MatrixSymbol(\"M\", 3, 3)\n    cg = CodegenArrayPermuteDims(M, [2, 1, 0])\n    f = lambdify((M,), cg, 'numpy')\n    ma = np.matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    assert (f(ma).all() == ma.T).all()\n", "def test_CodegenArrayDiagonal_regression():\n    \"\"\"\n    Test CodegenArrayDiagonal printer regression\n    \"\"\"\n    M = MatrixSymbol(\"M\", 2, 2)\n    N = MatrixSymbol(\"N\", 2, 2)\n    cg = CodegenArrayDiagonal(CodegenArrayTensorProduct(M, N), (1, 1))\n    f = lambdify((M, N), cg, 'numpy')\n\n    ma = np.matrix([[1, 2], [3, 4]])\n    mb = np.matrix([[1,-2], [-1, 3]])\n    assert (f(ma, mb) == np.diagonal(np.einsum(ma, [0, 1], mb, [2, 3]), axis1=1, axis2=1)).all()\n", "def test_BlockMatrix():\n    \"\"\"Tests BlockMatrix printing\"\"\"\n    A = BlockMatrix([[1, 2], [3, 4]])\n    assert A.shape == (2, 2)\n    assert NumPyPrinter().doprint(A) == 'numpy.block([[1, 2], [3, 4]])'\n    assert NumPyPrinter().doprint(A.T) == 'numpy.block([[3, 1], [4, 2]])'\n    B = BlockMatrix([[A, A], [A, A]])\n    assert B.shape == (4, 4)\n    assert NumPyPrinter().doprint(B) == 'numpy.block([[1, 2, 1, 2], [3, 4, 3, 4], [1, 2, 1, 2], [3, 4, 3, 4]])'\n"], "sample_55": ["def test_create_parser_suppress_base_arguments(self):\n    \"\"\"\n    BaseCommand.add_base_argument() should suppress help text for base arguments\n    if their help attribute is set to argparse.SUPPRESS.\n    \"\"\"\n    class CustomCommand(BaseCommand):\n        suppressed_base_arguments = {\"--help\", \"--version\"}\n\n    parser = CustomCommand().create_parser(\"prog_name\", \"subcommand\")\n    self.assertEqual(parser.format_usage(), \"usage: prog_name subcommand\")\n    with self.assertRaises(SystemExit):\n        parser.print_help()\n", "def test_check_migrations_required(self):\n    requires_migrations_checks = dance.Command.requires_migrations_checks\n    self.assertIs(requires_migrations_checks, False)\n    try:\n        with mock.patch.object(BaseCommand, \"check_migrations\") as check_migrations:\n            management.call_command(\"dance\", verbosity=0)\n            self.assertFalse(check_migrations.called)\n            dance.Command.requires_migrations_checks = True\n            management.call_command(\"dance\", verbosity=0)\n            self.assertTrue(check_migrations.called)\n            dance.Command.requires_migrations_checks = [DEFAULT_DB_ALIAS]\n            management.call_command(\"dance\", verbosity=0)\n            self.assertTrue(check_migrations.called)\n            with self.assertRaises(SystemCheckError):\n                management.call_command(\"dance\", verbosity=0)\n    finally:\n        dance.Command.requires_migrations_checks = requires_migrations_checks\n", "    def test_get_version(self):\n        class TestCommand(BaseCommand):\n            help = \"Test command\"\n            get_version = lambda self: \"1.0\"\n\n        command = TestCommand()\n        self.assertEqual(command.get_version(), \"1.0\")\n", "    def test_no_system_checks(self):\n        class Command(BaseCommand):\n            requires_system_checks = False\n\n        try:\n            with mock.patch.object(BaseCommand, \"check\") as mocked_check:\n                management.call_command(\"command_without_system_checks\")\n                self.assertIs(mocked_check.called, False)\n        finally:\n            BaseCommand.check = BaseCommand.original_check\n", "    def test_command_error_in_handle(self):\n        \"\"\"A CommandError raised in handle() should be caught and a CommandError\n        raised with a suitable return code\"\"\"\n        with self.assertRaisesMessage(CommandError, \"Something went wrong\"):\n            management.call_command(\"raise_error\", example=\"handle\")\n"], "sample_49": ["def test_get_dirs_no_template_backends(self, mock_get_dirs):\n    mock_get_dirs.return_value = []\n    self.assertSetEqual(\n        autoreload.get_template_directories(),\n        set()\n    )\n", "def test_template_dirs_invalid_paths(self):\n    with self.assertRaises(ValueError):\n        autoreload.get_template_directories()\n", "def test_template_changed_with_multiple_django_backends(self):\n    template_path = Path(__file__).parent / 'templates' / 'index.html'\n    self.assertTrue(autoreload.template_changed(None, template_path))\n", "    def test_get_template_directories_with_non_existent_loader(self):\n        self.assertSetEqual(\n            autoreload.get_template_directories(),\n            {\n                ROOT / 'templates_extra',\n                ROOT / 'templates',\n            }\n        )\n", "def test_watch_for_template_changes_with_invalid_backend(self):\n    mock_reloader = mock.MagicMock()\n    autoreload.watch_for_template_changes(mock_reloader)\n    # Mock the engine.all() method to return an invalid backend\n    engines.all.return_value = ['invalid_backend']\n    # Assert that no exception is raised\n    self.assertTrue(mock_reloader.watch_dir.call_count, 0)\n"], "sample_13": ["    def test_empty_string(self):\n        self.assertEqual(urlencode('', doseq=False), '')\n", "    def test_http_date_custom_epoch(self):\n        t = 1000000000.0\n        self.assertEqual(http_date(t), 'Sat, 01 Jan 1970 08:00:00 GMT')\n", "    def test_parse_none(self):\n        self.assertIsNone(parse_etags(''))\n", "    def test_limited_parse_qsl(self):\n        qsl = 'a=1&b=2&c=3&a=4'\n        self.assertEqual(limited_parse_qsl(qsl, fields_limit=2), [('a', '1'), ('b', '2')])\n        self.assertEqual(limited_parse_qsl(qsl, fields_limit=3), [('a', '1'), ('b', '2'), ('c', '3')])\n        with self.assertRaises(TooManyFieldsSent):\n            limited_parse_qsl(qsl, fields_limit=2)\n", "    def test_empty_string(self):\n        self.assertEqual(limited_parse_qsl(''), [])\n"], "sample_48": ["    def test_references_field_by_through_remote_field_model(self):\n        operation = FieldOperation('Model', 'field', models.ManyToManyField('Other', through='Through'))\n        self.assertIs(operation.references_field('Other', 'whatever', 'migrations'), True)\n        self.assertIs(operation.references_field('Through', 'whatever', 'migrations'), True)\n        self.assertIs(operation.references_field('Missing', 'whatever', 'migrations'), False)\n", "    def test_alter_field_with_db_column_set_to_none(self):\n        \"\"\"\n        Tests the AlterField operation on a field with db_column set to None.\n        \"\"\"\n        project_state = self.set_up_test_model(\"test_alflinbcsettonone\")\n        # Test the state alteration\n        operation = migrations.AlterField(\"Pony\", \"field\", models.IntegerField())\n        new_state = project_state.clone()\n        operation.state_forwards(\"test_alflinbcsettonone\", new_state)\n        self.assertEqual(new_state.models[\"test_alflinbcsettonone\", \"pony\"].fields['field'].db_column, None)\n        # Test the database alteration\n        self.assertColumnNotExists(\"test_alflinbcsettonone_pony\", \"db_field\")\n        with connection.schema_editor() as editor:\n            operation.database_forwards(\"test_alflinbcsettonone\", editor, project_state, new_state)\n        self.assertColumnExists(\"test_alflinbcsettonone_pony\", \"field\")\n        self.assertColumnNotExists(\"test_alflinbcsettonone_pony\", \"db_field\")\n        # And test reversal\n        with connection.schema_editor() as editor:\n            operation.database_backwards(\"test_alflinbcsettonone\", editor, new_state, project_state)\n        self.assertColumnNotExists(\"test_alflinbcsettonone_pony\", \"field\")\n        self.assertColumnNotExists(\"test_alflinbcsettonone_pony\", \"db_field\")\n        # And deconstruction\n        definition = operation.deconstruct()\n        self.assertEqual(definition[0], \"AlterField\")\n        self.assertEqual(definition[1], [])\n        self.assertEqual(sorted(definition[2]), [\"field\", \"model_name\", \"name\"])\n", "def test_rename_model_with_mti_parent_fk(self):\n    \"\"\"\n    RenameModel should repoint the parent relation's foreign key.\n    \"\"\"\n    app_label = 'test_rename_model_with_mti_parent_fk'\n    project_state = self.apply_operations(app_label, ProjectState(), operations=[\n        migrations.CreateModel('ShetlandPony', fields=[\n            ('pony_ptr', models.OneToOneField(\n                'test_rename_model_with_mti_parent_fk.Pony',\n                models.CASCADE,\n                auto_created=True,\n                primary_key=True,\n                to_field='id',\n                serialize=False,\n            )),\n            (\"cuteness\", models.IntegerField(default=1)),\n        ]),\n        migrations.CreateModel('Pony', fields=[\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n    ])\n    project_state = self.apply_operations(app_label, project_state, operations=[\n        migrations.AlterField('Pony', 'id', models.CharField(primary_key=True, max_length=100)),\n    ])\n    project_state = self.apply_operations(app_label, project_state, operations=[\n        migrations.RenameModel('Pony', 'NewPony')\n    ])\n    new_state = project_state.clone()\n    operation = migrations.AlterField('ShetlandPony', 'pony_ptr', models.ForeignKey('test_rename_model_with_mti_parent_fk.NewPony', models.CASCADE))\n    new_state = self.apply_operations(app_label, project_state, operations=[operation], atomic=connection.features.supports_atomic_references_rename)\n    self.assertEqual(new_state.models[app_label, 'shetlandpony'].fields['pony_ptr'].remote_field.model, 'test_rename_model_with_mti_parent_fk.NewPony')\n", "    def test_alter_field_deferred(self):\n        \"\"\"\n        Tests the AlterField operation on a deferred unique constraint.\n        \"\"\"\n        app_label = 'test_alterfield_deferred'\n        project_state = self.set_up_test_model(app_label)\n        deferred_unique_constraint = models.UniqueConstraint(\n            fields=['pink'],\n            name='deferred_pink_constraint',\n            deferrable=models.Deferrable.DEFERRED,\n        )\n        project_state = self.apply_operations(app_label, project_state, [\n            migrations.CreateModel('Pony', fields=[\n                ('id', models.AutoField(primary_key=True)),\n                ('weight', models.FloatField()),\n            ]),\n            migrations.AlterUniqueTogether('Pony', [('weight',)]),\n            migrations.AlterUniqueTogether('Pony', [('pink',)]),\n            migrations.AddConstraint('Pony', deferred_unique_constraint),\n        ])\n        # Alter field.\n        project_state = self.apply_operations(app_label, project_state, [\n            migrations.AlterField('Pony', 'weight', models.DecimalField(max_digits=10, decimal_places=3)),\n        ])\n        if connection.features.supports_deferrable_unique_constraints:\n            # Unique constraint is deferred.\n            with transaction.atomic():\n                obj = project_state.apps.get_model(app_label, 'Pony').objects.create(pink=1, weight=3.0)\n                obj.weight = 3.1\n                obj.save()\n            # Constraint behavior can be changed with SET CONSTRAINTS.\n            with self.assertRaises(IntegrityError):\n                with transaction.atomic(), connection.cursor() as cursor:\n                    quoted_name = connection.ops.quote_name(deferred_unique_constraint.name)\n                    cursor.execute('SET CONSTRAINTS %s IMMEDIATE' % quoted_name)\n                    obj = project_state.apps.get_model(app_label, 'Pony').objects.create(pink=1, weight=3.1)\n                    obj.weight = 3.0\n                    obj.save()\n        else:\n            self.assertEqual(project_state.apps.get_model(app_label, 'Pony').objects.filter(pink=1, weight=3.0).count(), 0)\n", "    def test_reduce_create_model(self):\n        \"\"\"\n        ModelOperation.reduce() should reduce a CreateModel operation to nothing\n        if the model is already in the state, but has different fields.\n        \"\"\"\n        project_state = self.set_up_test_model(\"test_redcem\")\n        project_state.models['test_redcem', 'pony'].fields = [\n            ('id', models.AutoField(primary_key=True)),\n            ('pink', models.IntegerField(default=1)),\n        ]\n        operation = migrations.CreateModel(\n            \"Pony\",\n            [\n                ('id', models.AutoField(primary_key=True)),\n                ('pink', models.IntegerField(default=2)),\n            ],\n        )\n        new_state = project_state.clone()\n        new_state.models['test_redcem', 'pony'].fields = [\n            ('id', models.AutoField(primary_key=True)),\n            ('pink', models.IntegerField(default=2)),\n        ]\n        self.assertEqual(operation.reduce(operation, 'test_redcem'), new_state.models['test_redcem', 'pony'].fields)\n"], "sample_12": ["def test_remove_order_with_respect_to(self):\n    \"\"\"Removing order_with_respect_to adds an operation.\"\"\"\n    changes = self.get_changes([self.author_with_book_order_wrt], [self.author_name])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterOrderWithRespectTo\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"author\", order_with_respect_to=None)\n", "def test_alter_manager(self):\n    \"\"\"Changing a model's managers should add an AlterModelManagers operation.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_empty, self.author_with_managers])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelManagers\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"author\", managers=[\n        (\"original_mgr\", \"OriginalAuthorManager\"),\n        (\"new_mgr\", \"NewAuthorManager\"),\n    ])\n    self.assertEqual(changes['testapp'][0].operations[0].managers[0][1].__name__, \"OriginalAuthorManager\")\n    self.assertEqual(changes['testapp'][0].operations[0].managers[1][1].__name__, \"NewAuthorManager\")\n\n    # Changing them back to the original state should also make a change\n    changes = self.get_changes([self.author_empty, self.author_with_managers], [self.author_empty])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelManagers\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"author\", managers=[\n        (\"original_mgr\", \"OriginalAuthorManager\"),\n    ])\n", "def test_swappable_bases_first(self):\n    \"\"\"\n    #24029 - Swappable bases should be ordered first.\n    \"\"\"\n    aardvark = ModelState(\"testapp\", \"Aardvark\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=100)),\n    ])\n    custom_user = ModelState(\"testapp\", \"CustomUser\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"username\", models.CharField(max_length=255)),\n    ], bases=(AbstractBaseUser,))\n    changes = self.get_changes([], [custom_user, aardvark])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"CreateModel\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"CustomUser\")\n    self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"Aardvark\")\n", "def test_add_field_with_choices(self):\n    \"\"\"Adding a field with choices should work.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_name])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n\n    # Now, we change the field to have choices.\n    changes = self.get_changes([self.author_name], [self.author_name_check_constraint])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n\n    # Now, we change the field again.\n    changes = self.get_changes([self.author_name_check_constraint], [self.author_name])\n    self.assertEqual(len(changes), 0)\n\n    # Now, we change the field to have choices again.\n    changes = self.get_changes([self.author_name], [self.author_name_check_constraint])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n\n    # Now, we change the choices.\n    changes = self.get_changes([self.author_name_check_constraint], [self.author_name_check_constraint])\n    # Right number/type of migrations?\n    self.assertEqual(len(changes), 0)\n", "def test_alter_model_managers_with_custom_deconstruct(self):\n    \"\"\"\n    Changing the model managers when a field has a custom deconstruct method\n    should add a new operation.\n    \"\"\"\n    # Custom deconstructible object.\n    class DeconstructibleField(models.CharField):\n            return (\n                'testapp.models',\n                'DeconstructibleField',\n                [],\n                {'max_length': 200},\n            )\n    \n    changes = self.get_changes([self.author_empty], [self.author_empty, self.author_empty, self.author_empty])\n    changes['testapp'][0].operations[0].fields[0][1].model = DeconstructibleField\n\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelManagers\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"author\")\n    self.assertEqual([name for name, mgr in changes['testapp'][0].operations[0].managers],\n                     ['deconstructiblefield', 'deconstructiblefield', 'deconstructiblefield'])\n"], "sample_6": ["    def test_validate(self):\n        valid_usernames = ['joe', 'Ren\u00e9', '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f']\n        invalid_usernames = [\n            \"o'connell\", \"\u0639\u0628\u062f \u0627\u0644\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A',\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n", "    def test_validate(self):\n        valid_usernames = ['joe', 'Ren\u00e9', '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f', 'hello-world']\n        invalid_usernames = [\n            \"o'connell\", \"\u0639\u0628\u062f \u0627\u0644\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A',\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n", "    def test_validate(self):\n        valid_usernames = ['joe', 'John.Doe', 'abc123!', 'hello@world.com']\n        invalid_usernames = [\n            \"o'connell\", \"\u0639\u0628\u062f \u0627\u0644\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A',\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n", "    def test_validate(self):\n        expected_error = \"This username is not ASCII.\"\n        self.assertIsNone(ASCIIUsernameValidator().validate('joe'))\n\n        v = ASCIIUsernameValidator()\n        for invalid in ['Ren\u00e9', '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f']:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n", "    def test_validate(self):\n        v = validators.ASCIIUsernameValidator()\n        valid_usernames = ['joe', 'A', '0', '@', '.']\n        invalid_usernames = [\n            'o\\'connell', '\u0639\u0628\u062f \u0627\u0644', 'zerowidth\\u200Bspace', 'nonbreaking\\u00A0space',\n            'en\\u2013dash', 'trailingnewline\\u000A',\n        ]\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n"], "sample_153": ["def test_Covariance():\n    from sympy.stats import Covariance\n    from sympy import symbols\n\n    a, b = symbols('a b')\n\n    cov = Covariance('a', 'b')\n    assert pretty(cov) == 'Cov(a, b)'\n    assert upretty(cov) == 'Cov(a, b)'\n    assert latex(cov) == '\\\\mathrm{Cov}(a,b)'\n", "def test_latex_printing_with_unicode():\n    from sympy import symbols, sin, cos, pi, UnevaluatedExpr\n\n    N = CoordSys3D('N')\n    C = N.orient_new_axis('C', 1, N.k)  # type: ignore\n    v = (N.i + C.k)  # type: ignore\n    s = 3*N.x**2*C.y  # type: ignore\n    d = [v | N.k]  # type: ignore\n\n    assert latex(upretty(v)) == '\\\\mathbf{\\\\hat{i}_{N}} + \\\\mathbf{\\\\hat{k}_{C}}'\n    assert latex(upretty(s)) == '3 \\\\mathbf{{y}_{C}} \\\\mathbf{{x}_{N}}^{2}'\n    assert latex(upretty(d[0])) == '(\\\\mathbf{\\\\hat{i}_{N}}|\\\\mathbf{\\\\hat{k}_{N}})'\n", "def test_power_expression():\n    from sympy import sin, cos, pi, symbols, Rational\n    from sympy.printing import pretty as xpretty\n    from sympy.printing.latex import latex\n\n    a, b = symbols('a b')\n    expr = (a**2 + b)**(1/2)\n    assert xpretty(expr, use_unicode=True, wrap_line=False) == r'\\sqrt{{a^{2} + b}}'\n    assert latex(expr) == r'{\\sqrt{a^{2} + b}}'\n\n    expr = (a**2 + b)**(1/3)\n    assert xpretty(expr, use_unicode=True, wrap_line=False) == r'\\sqrt[3]{{a^{2} + b}}'\n    assert latex(expr) == r'{\\sqrt[3]{a^{2} + b}}'\n\n    expr = (a**2 + b)**(1/4)\n    assert xpretty(expr, use_unicode=True, wrap_line=False) == r'\\sqrt[4]{{a^{2} + b}}'\n    assert latex(expr) == r'{\\sqrt[4]{a^{2} + b}}'\n\n    expr = (a**2 + b)**(1/5)\n    assert xpretty(expr, use_unicode=True, wrap_line=False) == r'\\sqrt[5]{{a^{2} + b}}'\n    assert latex(expr) == r'{\\sqrt[5]{a^{2} + b}}'\n\n    expr = (a**2 + b)**(Rational(1, 4))\n    assert xpretty(expr, use_unicode=True, wrap_line=False) == r'\\sqrt[4]{{a^{2} + b}}'\n    assert latex(expr) == r'{\\sqrt[4]{a^{2} + b}}'\n\n    expr = (a**2 + b)**(Rational(1, 3))\n    assert xpretty(expr, use_unicode=True, wrap_line=False) == r'\\sqrt[3]{{a^{2} + b}}'\n    assert latex(expr) == r'{\\sqrt[3]{a^{2} + b}}'\n\n    expr = (a**2 + b)**(Rational(1, 2))\n    assert xpretty(expr, use_unicode=True, wrap_line=False) == r'\\sqrt{{a^{2} + b}}'\n    assert latex(expr) == r'{\\sqrt{", "def test_pretty_printing_powers():\n    from sympy import symbols, exp, pi, sin, cos, Rational\n\n    x, y = symbols('x y')\n\n    # Test single exponent\n    assert upretty(x**2) == \"x**2\"\n\n    # Test negative exponent\n    assert upretty(x**(-2)) == \"1/x**2\"\n\n    # Test multiple exponents\n    assert upretty(x**2 * y**3) == \"x**2*y**3\"\n\n    # Test square root\n    assert upretty(x**Rational(1, 2)) == \"\u221ax\"\n\n    # Test cube root\n    assert upretty(x**Rational(1, 3)) == \"3\u22c5\u221bx\"\n\n    # Test power of a power\n    assert upretty(x**(2*3)) == \"x**(2*3)\"\n\n    # Test power of a power of a power\n    assert upretty(x**(2*3*4)) == \"x**(2*3*4)\"\n\n    # Test exp\n    assert upretty(exp(x)) == \"e**x\"\n\n    # Test sin\n    assert upretty(sin(x)) == \"sin(x)\"\n\n    # Test cos\n    assert upretty(cos(x)) == \"cos(x)\"\n\n    # Test pi\n    assert upretty(pi) == \"\u03c0\"\n\n    # Test trigonometric functions with a power\n    assert upretty(sin(x)**2) == \"sin(x)**2\"\n    assert upretty(cos(x)**2) == \"cos(x)**2\"\n", "def test_issue_15786():\n    from sympy import Point, Ray, Line, Matrix, sqrt, Abs, simplify, sin, cos, pi\n    from sympy.printing import pretty_print\n\n    A = Point(0, 0)\n    B = Point(3, 4)\n    C = Point(1, 1)\n    D = Point(3, 1)\n\n    r = Ray(A, B)\n    r1 = r.translate(-C)\n    l = Line(A, B)\n    m = Matrix([[1, 2], [2, 1]])\n    m2 = Matrix([[1, 0], [0, 1]])\n\n    upretty_r = \"\"\"\\"], "sample_140": ["def test_point_a2pt_theory_no_fixedframe():\n    q = dynamicsymbols('q')\n    qd = dynamicsymbols('q', 1)\n    qdd = dynamicsymbols('q', 2)\n    N = ReferenceFrame('N')\n    B = N.orientnew('B', 'Axis', [q, N.z])\n    O = Point('O')\n    P = O.locatenew('P', 0)\n    P.set_pos(O, B.x)\n    raises(ValueError, lambda: P.a2pt_theory(P, N, B))\n", "def test_partial_velocity_multiple_frame():\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    p = Point('p')\n    u1, u2, u3 = dynamicsymbols('u1, u2, u3')\n    p.set_vel(N, u1 * A.x + u2 * N.y + u3 * A.z)\n    assert p.partial_velocity(N, u1, u2, u3) == (A.x, N.y, A.z)\n    assert p.partial_velocity(A, u1) == raises(ValueError)\n", "def test_auto_point_vel_longer_path():\n    t = dynamicsymbols._t\n    q1, q2, u1, u2 = dynamicsymbols('q1 q2 u1 u2')\n    B = ReferenceFrame('B')\n    P = Point('P')\n    P.set_vel(B, u1 * B.x)\n    P1 = Point('P1')\n    P1.set_pos(P, q2 * B.y)\n    P1.set_vel(B, q1 * B.z)\n    P2 = Point('P2')\n    P2.set_pos(P1, q1 * B.z)\n    P3 = Point('P3')\n    P3.set_pos(P2, 10 * q1 * B.y)\n    O = Point('O')\n    O.set_vel(B, u2 * B.y)\n    O1 = Point('O1')\n    O1.set_pos(O, q2 * B.z)\n    O2 = Point('O2')\n    O2.set_pos(O1, 5 * q2 * B.y)\n    P4 = Point('P4')\n    P4.set_pos(O2, q1 * B.x + q2 * B.z)\n    assert P4.vel(B) == q1.diff(t) * B.x + 5 * q2.diff(t) * B.y + 2 * q2.diff(t) * B.z\n", "def test_auto_point_vel_multiple_path_with_vel_defined_at_least_once():\n    t = dynamicsymbols._t\n    q1, q2, u1, u2 = dynamicsymbols('q1 q2 u1 u2')\n    B = ReferenceFrame('B')\n    P = Point('P')\n    P.set_vel(B, u1 * B.x)\n    P1 = Point('P1')\n    P1.set_pos(P, q2 * B.y)\n    P1.set_vel(B, q1 * B.z)\n    P2 = Point('P2')\n    P2.set_pos(P1, q1 * B.z)\n    P3 = Point('P3')\n    P3.set_pos(P2, 10 * q1 * B.y)\n    O = Point('O')\n    O.set_vel(B, u2 * B.y)\n    O1 = Point('O1')\n    O1.set_pos(O, q2 * B.z)\n    P4 = Point('P4')\n    P4.set_pos(P3, q1 * B.x)\n    P4.set_pos(O1, q1 * B.x + q2 * B.z)\n    assert P4.vel(B) == q1.diff(t) * B.x + u2 * B.y + 2 * q2.diff(t) * B.z\n    P1.set_vel(B, 0)\n    raises(ValueError, lambda: P4.vel(B))\n", "def test_set_vel_rewriting():\n    t = dynamicsymbols._t\n    q1, q2 = dynamicsymbols('q1 q2')\n    N = ReferenceFrame('N')\n    B = N.orientnew('B', 'Axis', [q1, N.z])\n    P = Point('P')\n    P.set_vel(B, q1 * B.x + q2 * B.y)\n    P1 = Point('P1')\n    P1.set_pos(P, 0)\n    P1.set_vel(B, -q1 * B.x - q2 * B.y)\n    assert P1.vel(B) == 0\n    assert P1.acc(B) == -q1.diff(t) * B.x - q2.diff(t) * B.y\n    P1.set_vel(N, q1 * N.y)\n    assert P1.vel(N) == q1 * N.y\n    assert P1.acc(N) == q1.diff(t) * N.y\n"], "sample_19": ["    def setUp(self):\n        get_default_exception_reporter_filter.cache_clear()\n", "    def test_safe_settings(self):\n        \"\"\"\n        The debug page should not show some sensitive settings.\n        \"\"\"\n        sensitive_settings = [\n            'SECRET_KEY',\n            'PASSWORD',\n            'API_KEY',\n            'AUTH_TOKEN',\n            'DATABASE_URL',\n        ]\n        for setting in sensitive_settings:\n            with self.settings(DEBUG=True, **{setting: \"should not be displayed\"}):\n                response = self.client.get('/raises500/')\n                self.assertNotContains(response, 'should not be displayed', status_code=500)\n", "    def test_non_sensitive_request(self):\n        \"\"\"\n        Everything (request info and frame variables) can bee seen\n        in the default error reports for non-sensitive requests.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=True)\n\n        with self.settings(DEBUG=False):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=True)\n", "    def test_sensitive_variables_decorator(self):\n        \"\"\"\n        The sensitive_variables decorator works correctly.\n        \"\"\"\n        @sensitive_variables('password')\n            return index_page(request)\n\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(sensitive_view)\n            self.verify_unsafe_email(sensitive_view)\n\n        with self.settings(DEBUG=False):\n            self.verify_safe_response(sensitive_view)\n            self.verify_safe_email(sensitive_view)\n", "    def test_reporting_frame_variables(self):\n        try:\n            try:\n                    raise AttributeError('Inner exception')\n                inner()\n            except AttributeError:\n                pass\n            raise ValueError('Outer exception')\n        except ValueError:\n            exc_type, exc_value, tb = sys.exc_info()\n        request = self.rf.get('/test_view/')\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        frames = reporter.get_traceback_frames()\n        last_frame = frames[-1]\n        self.assertIn('raise AttributeError', last_frame['context_line'])\n        self.assertEqual(last_frame['filename'], __file__)\n        self.assertEqual(last_frame['function'], 'test_reporting_frame_variables')\n        self.assertEqual(last_frame['lineno'], 11)\n        html = reporter.get_traceback_html()\n        self.assertIn(\n            '<span class=\"fname\">%s</span>, line 11, in test_reporting_frame_variables' % __file__,\n            html,\n        )\n        self.assertIn(\n            '<code class=\"fname\">%s</code>, line 11, in test_reporting_frame_variables' % __file__,\n            html,\n        )\n        self.assertIn(\n            '\"%s\", line 11, in test_reporting_frame_variables\\n' % __file__,\n            html,\n        )\n        text = reporter.get_traceback_text()\n        self.assertIn(\n            '\"%s\", line 11, in test_reporting_frame_variables\\n' % __file__,\n            text,\n        )\n"], "sample_119": ["def test_ArcTrigonometric():\n    assert mcode(asin(x)) == \"ArcSin[x]\"\n    assert mcode(acos(x)) == \"ArcCos[x]\"\n    assert mcode(atan(x)) == \"ArcTan[x]\"\n    assert mcode(asinh(x)) == \"ArcSinh[x]\"\n    assert mcode(acosh(x)) == \"ArcCosh[x]\"\n    assert mcode(atanh(x)) == \"ArcTanh[x]\"\n    assert mcode(asech(x)) == \"ArcSech[x]\"\n    assert mcode(acsch(x)) == \"ArcCsch[x]\"\n    assert mcode(acot(x)) == \"ArcCot[x]\"\n", "def test_Sum():\n    assert mcode(Sum(x, (x, 1, 10))) == \"Hold[Sum[x, {x, 1, 10}]}\"\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]}\"\n    assert mcode(Sum(x**2, (x, 1, 10), (y, 1, 5))) == \\\n        \"Hold[Sum[x^2, {x, 1, 10}, {y, 1, 5}]}\"\n", "def test_Sum():\n    assert mcode(Sum(x, (1, 10))) == \"Hold[Sum[x, {1, 10}]}\"\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]}\"\n    assert mcode(Sum(x**2, (x, 1, 10)) + x) == \"Hold[Sum[x^2, {x, 1, 10}] + x]\"\n", "compilation error", "def test_Tuple():\n    A, B = symbols('A B', commutative=False)\n    assert mcode(Tuple(*[x, y, z])) == \"{x, y, z}\"\n    assert mcode(Tuple(x, y, z)) == \"{x, y, z}\"\n    assert mcode(Tuple(*[A, B, x])) == \"{A, B, x}\"\n    assert mcode(Tuple(x, A, B)) == \"{x, A, B}\"\n    assert mcode(Tuple(A, B, x, y)) == \"{A, B, x, y}\"\n    assert mcode(Tuple([x, y, z])) == \"{x, y, z}\"\n    assert mcode(Tuple([A, B, x])) == \"{A, B, x}\"\n"], "sample_133": ["def test_fcode_result_order():\n    x, y, z = symbols('x,y,z')\n    e1 = x + y\n    e2 = Matrix([[x, y], [z, 16]])\n    name_expr = (\"test\", (e2, e1))\n    result = codegen(name_expr, \"f95\", \"test\", header=False, empty=False)\n    source = result[0][1]\n    expected = (\n        \"REAL*8 function test(out_%(hash)s, x, y, z)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(out), dimension(1:2, 1:2) :: out_%(hash)s\\n\"\n        \"REAL*8, intent(in) :: x\\n\"\n        \"REAL*8, intent(in) :: y\\n\"\n        \"REAL*8, intent(in) :: z\\n\"\n        \"out_%(hash)s(1, 1) = x\\n\"\n        \"out_%(hash)s(2, 1) = y\\n\"\n        \"out_%(hash)s(1, 2) = z\\n\"\n        \"out_%(hash)s(2, 2) = 16\\n\"\n        \"test = x + y\\n\"\n        \"end function\\n\"\n    )\n    # look for the magic number\n    a = source.splitlines()[5]\n    b = a.split('_')\n    out = b[1]\n    expected = expected % {'hash': out}\n    assert source == expected\n", "def test_c_code_common_subexpression_elimination():\n    x, y = symbols('x,y')\n    expr = cos(x)**2 + sin(x)**2\n    routine = make_routine(\"test\", expr)\n    code_gen = CCodeGen(cse=True)\n    result = code_gen.write([routine], \"test\", header=False, empty=False)\n    assert result[0][0] == \"test.c\"\n    expected = (\n        '#include \"test.h\"\\n'\n        '#include <math.h>\\n'\n        'double test(double x) {\\n'\n        '   const double const_0 = cos(x);\\n'\n        '   const double const_1 = const_0**2;\\n'\n        '   const double const_2 = sin(x);\\n'\n        '   const double const_3 = const_2**2;\\n'\n        '   double test_result;\\n'\n        '   test_result = const_1 + const_3;\\n'\n        '   return test_result;\\n'\n        '}\\n'\n    )\n    assert result[0][1] == expected\n", "def test_c_code_input_args_with_dimensions():\n    A = MatrixSymbol('A', 5, 3)\n    x = MatrixSymbol('x', 3, 1)\n    y = MatrixSymbol('y', 5, 1)\n    z = symbols('z')\n    name_expr = (\"test\", Eq(y, A*x + z))\n    c = C99CodeGen()\n    result = c.write([name_expr[1]], \"test\", header=False, empty=False,\n                     argument_sequence=(x, z))\n    assert result[0][0] == \"test.c\"\n    expected = (\n        '#include \"test.h\"\\n'\n        '#include <math.h>\\n'\n        'void test(double *x, double z) {\\n'\n        '   double test_result;\\n'\n        '   double y[5];\\n'\n        '   for (int i=0; i<5; i++){\\n'\n        '      y[i] = 0;\\n'\n        '   }\\n'\n        '   for (int i=0; i<5; i++){\\n'\n        '      for (int j=0; j<3; j++){\\n'\n        '         y[i] = %(rhs)s + y[i];\\n'\n        '      }\\n'\n        '   }\\n'\n        '   for (int i=0; i<5; i++){\\n'\n        '      y[i] = y[i] + z;\\n'\n        '   }\\n'\n        '}\\n'\n    )\n    assert result[0][1] == expected % {'rhs': 'A[i, j]*x[j]'}\n", "def test_ccode_indexed_with_dimensions():\n    from sympy.tensor import IndexedBase, Idx\n    x, y = symbols('x,y')\n    z = symbols('z', integer=True, cls=Dummy)\n    I = Idx('i', z)\n    A = IndexedBase('A')[I, I]\n    expr = A + 1\n    name_expr = (\"test\", expr)\n    expected = (\n        \"#include \\\"test.h\\\"\\n\"\n        \"#include <math.h>\\n\"\n        \"double test(double *A, int z) {\\n\"\n        \"   double test_result;\\n\"\n        \"   A[0*z + 0] = A[0*z + 0] + 1;\\n\"\n        \"   return test_result;\\n\"\n        \"}\\n\"\n    )\n    result = codegen(name_expr, \"C\", \"test\", header=False, empty=False)\n    assert result[0][1] == expected\n", "def test_custom_c99_printer():\n    # Issue #13586\n    from sympy.printing.ccode import C99CodePrinter\n    class CustomPrinter(C99CodePrinter):\n            return \"fastpow({}, {})\".format(self._print(expr.base),\n                                            self._print(expr.exp))\n\n    x, y = symbols('x y')\n    expr = x**y\n    printer = CustomPrinter()\n    expected = (\n        '#include \"expr.h\"\\n'\n        '#include <math.h>\\n'\n        'double expr(double x, double y) {\\n'\n        '   double expr_result;\\n'\n        '   expr_result = fastpow(x, y);\\n'\n        '   return expr_result;\\n'\n        '}\\n'\n    )\n\n    code_gen = C99CodeGen(printer=printer)\n    result = codegen(('expr', expr), header=False, empty=False)\n    source = result[0][1]\n    assert source == expected\n\n    # check that the printer can also be used as a c_code_printer\n    from sympy.printing.codeprinter import CodePrinter\n    assert issubclass(CustomPrinter, CodePrinter)\n"], "sample_148": ["def test_conjugate_issue_21765():\n    assert conjugate(Arg(0)) == Arg(0)\n    assert conjugate(Arg(1)) == Arg(0)\n    assert conjugate(Arg(-1)) == Arg(pi)\n    assert conjugate(Arg(I)) == Arg(-pi/2)\n    assert conjugate(Arg(-I)) == Arg(pi/2)\n    assert conjugate(Arg(1 + I)) == Arg(pi/4)\n    assert conjugate(Arg(-1 + I)) == Arg(3*pi/4)\n    assert conjugate(Arg(1 - I)) == Arg(-pi/4)\n    assert conjugate(Arg(exp_polar(4*pi*I))) == Arg(4*pi)\n    assert conjugate(Arg(exp_polar(-7*pi*I))) == Arg(-7*pi)\n    assert conjugate(Arg(exp_polar(5 - 3*pi*I/4))) == Arg(pi*Rational(-3, 4))\n\n    x = Symbol('x')\n    p = Function('p', extended_positive=True)\n    assert conjugate(Arg(p(x))) == Arg(0)\n    assert conjugate(Arg((3 + I)*p(x))) == Arg(3 + I)\n\n    p = Symbol('p', positive=True)\n    assert conjugate(Arg(p)) == Arg(0)\n\n    n = Symbol('n', negative=True)\n    assert conjugate(Arg(n)) == Arg(pi)\n\n    x = Symbol('x')\n    assert conjugate(conjugate(Arg(x))) == Arg(x)\n\n    e = p + I*p**2\n    assert conjugate(Arg(e)) == Arg(1 + p*I)\n    # make sure sign doesn't swap\n    e = -2*p + 4*I*p**2\n    assert conjugate(Arg(e)) == Arg(-1 + 2*p*I)\n    # make sure sign isn't lost\n    x = symbols('x', real=True)  # could be zero\n    e = x + I*x\n    assert conjugate(Arg(e)) == Arg(x*(1 + I))\n    assert conjugate(Arg(e/p)) == Arg(x*(1 + I))\n    e = p*cos(p) + I*log(p)*exp(p)\n    assert conjugate(Arg(e)).args[0] == e\n    # keep it simple -- let the user do more advanced cancellation\n    e = (p + 1) + I*(p**2 - 1)\n    assert conjugate(Arg(e)).args[", "def test_is_real():\n    x, y = symbols('x,y')\n    a, b = symbols('a,b', real=True)\n\n    assert re(x).is_real is None\n    assert im(x).is_real is False\n\n    assert re(a).is_real is True\n    assert im(a).is_real is False\n\n    assert re(a + b*I).is_real is None\n    assert im(a + b*I).is_real is None\n\n    assert Abs(x).is_real is None\n    assert sign(x).is_real is None\n\n    assert re(nan) is nan\n    assert im(nan) is nan\n\n    assert re(oo) is oo\n    assert im(oo) is oo\n\n    assert re(-oo) is -oo\n    assert im(-oo) is -oo\n\n    assert im(0) == 0\n    assert re(0) == 0\n    assert Abs(0) == 0\n    assert sign(0) == 0\n    assert arg(0) is nan\n    assert arg(0) is nan\n\n    assert im(1) == 0\n    assert re(1) == 1\n    assert Abs(1) == 1\n    assert sign(1) == 1\n    assert arg(1) == 0\n    assert arg(1) == 0\n\n    assert im(-1) == 0\n    assert re(-1) == -1\n    assert Abs(-1) == 1\n    assert sign(-1) == -1\n    assert arg(-1) == pi\n    assert arg(-1) == pi\n", "def test_unpolarify_conjugate():\n    from sympy import unpolarify, exp_polar, polar_lift\n    from sympy.abc import x\n\n    assert unpolarify(conjugate(exp_polar(x))) == conjugate(exp(x))\n    assert unpolarify(polar_lift(exp_polar(x))) == polar_lift(exp(x))\n    assert unpolarify(conjugate(polar_lift(exp_polar(x)))) == conjugate(polar_lift(exp(x)))\n\n    p = Symbol('p', positive=True)\n    z = Symbol('z', imaginary=True)\n    assert unpolarify(conjugate(p + I*z)) == conjugate(p + I*z)\n    assert unpolarify(polar_lift(conjugate(p + I*z))) == polar_lift(conjugate(p + I*z))\n\n    assert unpolarify(conjugate(exp_polar(x)*polar_lift(p))) == conjugate(exp(x)*polar_lift(p))\n    assert unpolarify(polar_lift(conjugate(exp_polar(x)*polar_lift(p)))) == polar_lift(conjugate(exp(x)*polar_lift(p)))\n\n    assert unpolarify(conjugate(exp_polar(x) + p)) == conjugate(exp(x) + p)\n    assert unpolarify(polar_lift(conjugate(exp_polar(x) + p))) == polar_lift(conjugate(exp(x) + p))\n", "def test_unbranched_argument():\n    from sympy import periodic_argument, exp_polar, oo\n\n    x = Symbol('x')\n    p = Symbol('p', positive=True)\n\n    assert unbranched_argument(x) == periodic_argument(x, oo)\n    assert unbranched_argument(1 + I) == oo\n\n    assert unbranched_argument(exp_polar(2*pi*I)*p) == 2*pi\n    assert unbranched_argument(p) == 0\n\n    assert unbranched_argument(2*exp_polar(pi*I)*x) == 2*pi\n    assert unbranched_argument(exp_polar(3*pi*I)*x) == 3*pi\n\n    assert unbranched_argument(exp_polar(pi*I)*x + exp_polar(3*pi*I)*x) == \\\n        periodic_argument(exp_polar(pi*I)*x + exp_polar(3*pi*I)*x, oo)\n    assert unbranched_argument(exp_polar(7*pi*I)*x) == 7*pi\n", "def test_unbranched_argument():\n    x = Symbol('x')\n    p = Symbol('p', positive=True)\n    assert unbranched_argument(2 + I) == pi\n    assert unbranched_argument(2 + x) == pi\n    assert unbranched_argument(p) == 0\n    assert unbranched_argument(2 + I*x) == pi\n    assert unbranched_argument(2 + I*p) == pi\n    assert unbranched_argument(p + I*x) == pi\n    assert unbranched_argument(polar_lift(x)) == unbranched_argument(x)\n    assert unbranched_argument(polar_lift(2 + I)) == pi\n    assert unbranched_argument(2 + polar_lift(x)) == pi\n    assert unbranched_argument(polar_lift(2 + I)*x) == pi\n    assert unbranched_argument(polar_lift(2 + I)*p) == pi\n    assert unbranched_argument(polar_lift(p + I*x)) == pi\n    assert unbranched_argument(2*p + I*x) == pi\n    assert unbranched_argument(2*I*p + x) == pi\n    assert unbranched_argument(p + I*x*p) == pi\n    assert unbranched_argument(p + I*p*x) == pi\n    assert unbranched_argument(x + I*p*p) == pi\n    assert unbranched_argument(p + x + I*p*x) == pi\n    assert unbranched_argument(2*x + I*p + p) == pi\n    assert unbranched_argument(2*p + I*x + x) == pi\n    assert unbranched_argument(2*x + I*p + p) == pi\n    assert unbranched_argument(2*p + I*x + x) == pi\n    assert unbranched_argument(p + x + I*p*x) == pi\n"], "sample_23": ["def test_difference_with_values_list_and_order(self):\n    ReservedName.objects.create(name='rn1', order=7)\n    ReservedName.objects.create(name='rn2', order=5)\n    ReservedName.objects.create(name='rn0', order=6)\n    ReservedName.objects.create(name='rn9', order=-1)\n    qs1 = ReservedName.objects.filter(order__gte=6)\n    qs2 = ReservedName.objects.filter(order__lte=5)\n    union_qs = qs1.difference(qs2)\n    for qs, expected_result in (\n        # Order by a single column.\n        (union_qs.order_by('-pk').values_list('order', flat=True), [-1, 6, 7]),\n        (union_qs.order_by('pk').values_list('order', flat=True), [7, 6, -1]),\n        (union_qs.values_list('order', flat=True).order_by('-pk'), [-1, 6, 7]),\n        (union_qs.values_list('order', flat=True).order_by('pk'), [7, 6, -1]),\n        # Order by multiple columns.\n        (union_qs.order_by('-name', 'pk').values_list('order', flat=True), [7, 6, -1]),\n        (union_qs.values_list('order', flat=True).order_by('-name', 'pk'), [7, 6, -1]),\n    ):\n        with self.subTest(qs=qs):\n            self.assertEqual(list(qs), expected_result)\n", "def test_difference_with_distinct(self):\n    qs1 = Number.objects.all()\n    qs2 = Number.objects.filter(num__lte=5)\n    self.assertEqual(len(list(qs1.difference(qs2, distinct=True))), 5)\n", "def test_difference_with_empty_qs_and_values_list(self):\n    qs1 = Number.objects.all()\n    qs2 = Number.objects.none()\n    self.assertCountEqual(qs1.difference(qs2).values_list('num', flat=True), list(range(10)))\n    qs3 = Number.objects.filter(num=5)\n    self.assertCountEqual(qs1.difference(qs3).values_list('num', flat=True), list(range(10))[:5] + list(range(5+1, 10)))\n    self.assertCountEqual(qs1.difference(qs2, qs3).values_list('num', flat=True), list(range(10))[:5] + list(range(5+1, 10)))\n", "def test_intersection_with_raw_query(self):\n    qs1 = Number.objects.filter(num__lte=5)\n    raw_qs = Number.objects.raw('SELECT * FROM myapp_number WHERE num <= 5')\n    self.assertEqual(len(qs1.intersection(raw_qs)), 5)\n", "def test_union_with_union(self):\n    qs1 = Number.objects.all()\n    qs2 = Number.objects.all()\n    qs3 = Number.objects.filter(num__lt=5)\n    union_qs = qs1.union(qs2)\n    union_qs = union_qs.union(qs3)\n    self.assertNumbersEqual(union_qs, list(range(10)), ordered=False)\n"], "sample_146": ["def test_Trace():\n    A, B, C = symbols('A B C', commutative=False)\n    t = Tr(A*B*C)\n    assert str(t) == 'Tr(A*B*C)'\n    t = Tr(A*B)\n    assert str(t) == 'Tr(A*B)'\n", "def test_BlockMatrix():\n    M = Matrix([[1, 2, 3], [4, 5, 6]])\n    assert str(M.as_block_matrix()) == \"Matrix([\\n[1, 2, 3],\\n[4, 5, 6]])\"\n", "def test_dict_print():\n    d = {1: {2: {3: 4, 4: 5}, 5: 6}, 7: 8}\n    assert sstr(d) == \"{1: {2: {3: 4, 4: 5}, 5: 6}, 7: 8}\"\n", "def test_Derivative_with_multiple_variables_and_points():\n    from sympy.core import Expr\n    from sympy.diff import diff\n    assert str(Derivative(2*x + y, (x, y, z), (x, y, z))) == \"Derivative(2*x + y, (x, y, z), (x, y, z))\"\n    assert str(Derivative(2*x + y, (x, y, z), (x, 0, 0))) == \"Derivative(2*x + y, (x, y, z), (x, 0, 0))\"\n    assert str(Derivative(2*x + y, (x, y, z), (0, 0, 0))) == \"Derivative(2*x + y, (x, y, z), (0, 0, 0))\"\n", "def test_Tensor_printing():\n    from sympy import TensorIndex, TensorHead, Tensor, TensMul, TensAdd\n    from sympy.tensor import NDimArray\n    t1 = TensorHead('t1', (1, 2), (3, 4))\n    t2 = TensorHead('t2', (5, 6), (7, 8))\n    assert str(t1) == 't1'\n    assert str(t2) == 't2'\n\n    ti1 = TensorIndex('i', 1, 2)\n    ti2 = TensorIndex('j', 3, 4)\n    ti3 = TensorIndex('k', 5, 6)\n    ti4 = TensorIndex('l', 7, 8)\n\n    assert str(ti1) == 'i'\n    assert str(ti2) == 'j'\n    assert str(ti3) == 'k'\n    assert str(ti4) == 'l'\n\n    t = Tensor(t1, [ti1, ti2])\n    assert str(t) == \"t1(i, j)\"\n\n    t2 = Tensor(TensMul(t1, t2), [ti3, ti4])\n    assert str(t2) == \"t1(i, j) * t2(k, l)\"\n\n    t3 = TensAdd(t1, t2)\n    assert str(t3) == \"t1(i, j) + t1(i, j) * t2(k, l)\"\n\n    assert str(Tensor(TensAdd(t1, t2))) == \"t1(i, j) + t2(k, l)\"\n    assert str(Tensor(TensMul(t1, t2))) == \"t1(i, j) * t2(k, l)\"\n\n    n = NDimArray([1.0, 2.0])\n    assert str(n) == '[1.0, 2.0]'\n"], "sample_17": ["    def test_createcachetable_called(self, mocked_createcachetable, mocked_migrate):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n            mocked_createcachetable.assert_called_once()\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n", "    def test_serialize_db(self):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['NAME'] = 'prod_name'\n        creation = test_connection.creation_class(test_connection)\n        test_data = 'Serialized test data'\n        with mock.patch.object(creation, 'serialize_db_to_string', return_value=test_data):\n            serialized_data = creation.serialize_db_to_string()\n            self.assertEqual(serialized_data, test_data)\n", "    def test_clone_test_db(self, mocked_ensure_connection, mocked_call_command):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['NAME'] = 'test_hodor'\n        creation = test_connection.creation_class(test_connection)\n        creation.clone_test_db('suffix', verbosity=0, autoclobber=True)\n        mocked_call_command.assert_called_once_with('createcachetable', database=test_connection.alias)\n        mocked_ensure_connection.assert_called_once()\n", "    def test_migrate_database_error(self, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        test_connection.settings_dict['TEST']['NAME'] = 'non_existent_database'\n        with self.assertRaises(Exception):\n            creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n", "    def test_serialize_db_to_string(self):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['NAME'] = 'test_hodor'\n        creation = test_connection.creation_class(test_connection)\n\n        # Serialize some data\n        obj = Object.objects.create(name='hodor')\n        data = creation.serialize_db_to_string()\n\n        # Deserialize the data\n        creation.deserialize_db_from_string(data)\n\n        # Check that the data is the same\n        self.assertEqual(Object.objects.count(), 1)\n        self.assertEqual(Object.objects.get().name, 'hodor')\n"], "sample_99": ["def test_KNeighborsRegressor_sparse_weights():\n    # Test k-neighbors in multi-output regression with weights\n    rng = check_random_state(0)\n    n_features = 5\n    n_samples = 40\n    n_output = 4\n\n    X = rng.rand(n_samples, n_features)\n    y = rng.rand(n_samples, n_output)\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\n    weights = ['uniform', 'distance']\n\n    for algorithm, weights in product(ALGORITHMS, weights):\n        knn = neighbors.KNeighborsRegressor(weights=weights,\n                                            algorithm=algorithm)\n        knn.fit(X_train, y_train)\n\n        neigh_idx = knn.kneighbors(X_test, return_distance=False)\n        y_pred_idx = np.array([np.mean(y_train[idx], axis=0)\n                               for idx in neigh_idx])\n\n        y_pred = knn.predict(X_test)\n\n        assert_equal(y_pred.shape, y_test.shape)\n        assert_equal(y_pred_idx.shape, y_test.shape)\n        assert_array_almost_equal(y_pred, y_pred_idx)\n", "def test_radius_neighbors_regressor_sparse(n_samples=40,\n                                          n_features=5,\n                                          n_test_pts=10,\n                                          n_neighbors=3,\n                                          random_state=0):\n    # Test radius-based regression on sparse matrices\n    # Like the above, but with various types of sparse matrices\n    rng = np.random.RandomState(random_state)\n    X = 2 * rng.rand(n_samples, n_features) - 1\n    y = ((X ** 2).sum(axis=1) < .25).astype(np.int)\n\n    for sparsemat in SPARSE_TYPES:\n        rnn = neighbors.RadiusNeighborsRegressor(n_neighbors=n_neighbors,\n                                                 algorithm='auto')\n        rnn.fit(sparsemat(X), y)\n\n        for sparsev in SPARSE_OR_DENSE:\n            X2 = sparsev(X)\n            assert_true(np.mean(rnn.predict(X2).round() == y) > 0.95)\n\n            assert_raises(ValueError, rnn.predict, X2, y)\n", "def test_radius_neighbors_regressor_sparse_input():\n    # Test radius-based regression on sparse matrices\n    rng = np.random.RandomState(0)\n    X = 2 * rng.rand(10, 5) - 1\n    X = X * (X > .2)\n    Xsparse = csr_matrix(X)\n    y = np.sqrt((X ** 2).sum(1))\n    y /= y.max()\n\n    for sparsemat in SPARSE_TYPES:\n        rnn = neighbors.RadiusNeighborsRegressor(radius=0.5,\n                                                  algorithm='auto')\n        rnn.fit(sparsemat(Xsparse), y)\n        for sparsev in SPARSE_OR_DENSE:\n            X2 = sparsev(X)\n            assert_true(np.mean(rnn.predict(X2).round() == y) > 0.95)\n\n        rnn_pre = neighbors.RadiusNeighborsRegressor(radius=0.5,\n                                                     algorithm='auto',\n                                                     metric='precomputed')\n        rnn_pre.fit(pairwise_distances(X, metric='euclidean'), y)\n\n        for sparsev in SPARSE_OR_DENSE:\n            X2_pre = sparsev(pairwise_distances(X, metric='euclidean'))\n            if issparse(sparsev(X2_pre)):\n                assert_raises(ValueError, rnn_pre.predict, X2_pre)\n            else:\n                assert_true(np.mean(rnn_pre.predict(X2_pre).round() == y) > 0.95)\n", "def test_radius_neighbors_regressor_sparse_invalid_input():\n    # Test radius_neighbors_regressor for sparse matrix with invalid input\n    rng = np.random.RandomState(0)\n    X = 2 * rng.rand(5, 5) - 1\n    y = np.sqrt((X ** 2).sum(1))\n    y /= y.max()\n    y = np.vstack([y, y]).T\n\n    # Test with sparse matrix and invalid radius\n    for sparsemat in SPARSE_TYPES:\n        Xsparse = sparsemat(X)\n        Xsparse[0, 0] = 0\n        Xsparse[1, 0] = 0\n        for radius in [0, -1, None]:\n            assert_raises(ValueError, neighbors.RadiusNeighborsRegressor,\n                          n_neighbors=3, weights='distance',\n                          algorithm='auto', radius=radius).fit, Xsparse, y)\n    # Test with empty sparse matrix\n    for sparsemat in SPARSE_TYPES:\n        Xsparse = sparsemat([])\n        assert_raises(ValueError, neighbors.RadiusNeighborsRegressor,\n                      n_neighbors=3, weights='distance',\n                      algorithm='auto').fit, Xsparse, y)\n", "def test_fit_transform():\n    X = np.array([[0, 0], [1, 1], [1, 2]])\n    y = np.array([[1], [2], [1]])\n    X_dense = np.array([[0, 0], [1, 1], [1, 2], [3, 3]])\n    y_dense = np.array([[1], [2], [1], [2]])\n\n    for Est in (neighbors.KNeighborsClassifier, neighbors.RadiusNeighborsClassifier,\n                neighbors.KNeighborsRegressor, neighbors.RadiusNeighborsRegressor):\n        for sparse_type in (np.asarray, csr_matrix):\n            X_sparse = sparse_type(X)\n            X_sparse_dense = sparse_type(X_dense)\n            y_sparse = sparse_type(y)\n            y_sparse_dense = sparse_type(y_dense)\n\n            est = Est()\n            est.fit(X_sparse, y_sparse)\n            X_transformed, y_transformed = est.fit_transform(X_sparse, y_sparse)\n\n            est_dense = Est()\n            est_dense.fit(X_sparse_dense, y_sparse_dense)\n            X_transformed_dense, y_transformed_dense = est_dense.fit_transform(\n                X_sparse_dense, y_sparse_dense)\n\n            assert_equal(X_transformed.shape, X_sparse.shape)\n            assert_equal(y_transformed.shape, y_sparse.shape)\n            assert_equal(X_transformed_dense.shape, X_sparse_dense.shape)\n            assert_equal(y_transformed_dense.shape, y_sparse_dense.shape)\n\n            assert_array_almost_equal(X_transformed, X_sparse)\n            assert_array_almost_equal(y_transformed, y_sparse)\n            assert_array_almost_equal(X_transformed_dense, X_sparse_dense)\n            assert_array_almost_equal(y_transformed_dense, y_sparse_dense)\n\n            # Test when no neighbors found\n            est.fit(X_sparse)\n            X_transformed, y_transformed = est.fit_transform(X_sparse)\n            assert_equal(X_transformed.shape, X_sparse.shape)\n            assert_equal(y_transformed.shape, X_sparse.shape)\n"], "sample_34": ["    def test_explicit_auto_field(self):\n        class Model(models.Model):\n            id = models.AutoField()\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n", "    def test_collision_in_same_model(self):\n        class Model(models.Model):\n            name = models.CharField(max_length=20)\n            age = models.IntegerField()\n\n            class Meta:\n                unique_together = [('name', 'age')]\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"'name' and 'age' together are not unique for model check_framework.Model.\",\n                id='models.E011',\n            ),\n        ])\n", "    def test_collision_in_same_model(self):\n        class Model(models.Model):\n            class Meta:\n                unique_together = [('id', 'name')]\n\n            id = models.AutoField(primary_key=True)\n            name = models.CharField(max_length=20)\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"Unique constraint is not unique among fields for model \"\n                \"check_framework.Model.\",\n                id='models.E011',\n            ),\n        ])\n", "    def test_ordering_with_relation(self):\n        class Model1(models.Model):\n            class Meta:\n                ordering = ['name']\n\n        class Model2(models.Model):\n            name = models.CharField(max_length=20)\n            class Meta:\n                ordering = ['name']\n\n        class RelatedModel(models.Model):\n            model1 = models.ForeignKey(Model1, on_delete=models.CASCADE)\n            model2 = models.ForeignKey(Model2, on_delete=models.CASCADE)\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"'ordering' refers to the related field 'name'.\",\n                obj=RelatedModel,\n                id='models.E015',\n            ),\n        ])\n", "    def test_swapped_model_name_format(self):\n        class Model(models.Model):\n            class Meta:\n                swappable = 'invalid_model_name'\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                self.msg % {'model': Model._meta.swappable},\n                obj=Model,\n                id='models.E001',\n            ),\n        ])\n"], "sample_123": ["def test_invert_symbolic_expr():\n    a = Symbol('a', integer=True)\n    b = Symbol('b', integer=True)\n    c = Symbol('c', integer=True)\n    d = Symbol('d', integer=True)\n    e = Symbol('e', integer=True)\n    f = Symbol('f', integer=True)\n\n    assert S(2).invert(a + b) == S(1)/(a + b)\n    assert S(3).invert(a + b + c) == S(1)/(a + b + c)\n    assert S(4).invert(a + b + c + d) == S(1)/(a + b + c + d)\n    assert S(5).invert(a + b + c + d + e) == S(1)/(a + b + c + d + e)\n    assert S(6).invert(a + b + c + d + e + f) == S(1)/(a + b + c + d + e + f)\n", "def test_NaN_is_comparable():\n    class Uncomparable(object):\n            return NotImplemented\n\n            return NotImplemented\n\n            return NotImplemented\n\n            return NotImplemented\n\n            return NotImplemented\n\n            return NotImplemented\n\n    a = NaN\n    b = Uncomparable()\n    c = Uncomparable()\n\n    assert (a == a) == (a != a)\n    assert (a == b) is NotImplemented\n    assert (a != b) is NotImplemented\n    assert (a < b) is NotImplemented\n    assert (a > b) is NotImplemented\n    assert (a <= b) is NotImplemented\n    assert (a >= b) is NotImplemented\n    assert (b < a) is NotImplemented\n    assert (b > a) is NotImplemented\n    assert (b <= a) is NotImplemented\n    assert (b >= a) is NotImplemented\n\n    assert (a == c) is NotImplemented\n    assert (a != c) is NotImplemented\n    assert (a < c) is NotImplemented\n    assert (a > c) is NotImplemented\n    assert (a <= c) is NotImplemented\n    assert (a >= c) is NotImplemented\n    assert (c < a) is NotImplemented\n    assert (c > a) is NotImplemented\n    assert (c <= a) is NotImplemented\n    assert (c >= a) is NotImplemented\n", "def test_mod_inverse():\n    assert mod_inverse(-1, 5) == 4\n    assert mod_inverse(-2, 5) == 3\n    assert mod_inverse(-4, 5) == 2\n    assert mod_inverse(-6, 5) == 4\n    assert mod_inverse(-8, 5) == 3\n    assert mod_inverse(-1, 9) == 8\n    assert mod_inverse(-2, 9) == 7\n    assert mod_inverse(-4, 9) == 5\n    assert mod_inverse(-6, 9) == 8\n    assert mod_inverse(-8, 9) == 7\n    assert mod_inverse(-1, 11) == 10\n    assert mod_inverse(-2, 11) == 9\n    assert mod_inverse(-4, 11) == 7\n    assert mod_inverse(-6, 11) == 10\n    assert mod_inverse(-8, 11) == 9\n    assert mod_inverse(-1, 13) == 12\n    assert mod_inverse(-2, 13) == 11\n    assert mod_inverse(-4, 13) == 10\n    assert mod_inverse(-6, 13) == 12\n    assert mod_inverse(-8, 13) == 11\n    assert mod_inverse(-1, 17) == 16\n    assert mod_inverse(-2, 17) == 15\n    assert mod_inverse(-4, 17) == 14\n    assert mod_inverse(-6, 17) == 16\n    assert mod_inverse(-8, 17) == 15\n    assert mod_inverse(1, 5) == 1\n    assert mod_inverse(2, 5) == 3\n    assert mod_inverse(4, 5) == 2\n    assert mod_inverse(3, 5) == 4\n    assert mod_inverse(6, 5) == 1\n    assert mod_inverse(8, 5) == 3\n    assert mod_inverse(1, 9) == 1\n    assert mod_inverse(2, 9) == 5\n    assert mod_inverse(4, 9) == 7\n    assert mod_inverse(3, 9) == 6\n    assert mod_inverse(6, 9) == 5\n   ", "def test_Float_add():\n    from mpmath.libmp.libmpf import _mpf_zero, mpf_add\n    from mpmath.libmp import mpf_pow\n    mlib = mpmath.libmp\n    mpf = mlib.mpf\n    mpf_pow = mlib.mpf_pow\n\n    mpf1 = mlib.mpf('1.2')\n    mpf2 = mlib.mpf('3.4')\n\n    Float.add = lambda self, other: mpf_add(self._mpf_, other._as_mpf_val(self._prec), self._prec, mlib.round_nearest)\n\n    # simple\n    f = Float('1.2', 2)\n    assert f._mpf_ == Float('1.2')._as_mpf_val(2)._mpf_\n    assert f._prec == 2\n    assert f._mpf_ == Float(1.2)._as_mpf_val(2)._mpf_\n\n    f = Float('1.2e3', 2)\n    assert f._mpf_ == Float(1.2)._as_mpf_val(2)._mpf_\n    assert f._prec == 20\n\n    f = Float(1.2, 2)\n    assert f._mpf_ == Float('1.2')._as_mpf_val(2)._mpf_\n    assert f._prec == 2\n\n    f = Float(1.2e3, 2)\n    assert f._mpf_ == Float(1.2)._as_mpf_val(2)._mpf_\n    assert f._prec == 20\n\n    # precision change\n    f = Float('1.2', '')\n    assert f._mpf_ == Float('1.2')._as_mpf_val(15)._mpf_\n    assert f._prec == 15\n\n    f = Float('1.2e3', '')\n    assert f._mpf_ == Float('1.2')._as_mpf_val(15)._mpf_\n    assert f._prec == 20\n\n    f = Float(1.2, '')\n    assert f._mpf_ == Float('1.2')._as_mpf_val(15)._mpf_\n    assert f._prec == 15\n\n    f = Float(1.2e3, '')\n    assert f", "def test_AlgebraicNumber():\n    from sympy import S, sqrt, I, oo, sympify, float\n    from sympy.core.numbers import (igcd, ilcm, Rational, igcdex,\n                                   AlgebraicNumber)\n    a = AlgebraicNumber(sqrt(2), [1, -1])\n    assert a.is_AlgebraicNumber\n    assert a.is_number\n    assert a.is_algebraic\n    assert not a.is_rational\n    assert not a.is_real\n    assert not a.is_integer\n    assert a.is_irrational\n    assert not a.is_negative\n    assert not a.is_positive\n    assert not a.is_finite\n    assert a.is_infinite is False\n    assert a.is_zero is False\n    assert a.is_prime is False\n    assert a.is_number is True\n    assert a.is_commutative is True\n\n    assert a.root == sqrt(2)\n    assert a.alias is None\n    assert a.minpoly == S(2).as_poly()\n    assert a.coeffs() == [1, -1]\n\n    assert a.as_expr().is_Pow\n    assert a.as_expr().args[0] == S(2)\n    assert a.as_expr().args[1] == S.Half\n    assert a.as_poly() == S(2).as_poly()\n    assert a.as_poly().args == (S('x'),)\n\n    assert a.factors(100) == {S(2): 1}\n\n    n = AlgebraicNumber((S(2)*S(x)**2 - 1).as_poly(), [1])\n    assert n.is_AlgebraicNumber\n    assert n.is_number\n    assert n.is_algebraic\n    assert not n.is_rational\n    assert not n.is_real\n    assert not n.is_integer\n    assert n.is_irrational\n    assert not n.is_negative\n    assert not n.is_positive\n    assert not n.is_finite\n    assert n.is_infinite is False\n    assert n.is_zero is False\n    assert n.is_prime is False\n    assert n.is_number is True\n    assert n.is_commutative is True\n\n    assert n.root == x\n    assert n.alias is None\n    assert n.minpoly == S(2).as_poly(x)\n    assert n.coeffs() == [1]\n\n    assert n.as_expr().is_Poly\n"], "sample_149": ["def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 3)) is None\n    assert monomial_ldiv((3, 4, 1), (4, 5, 6)) is None\n    assert monomial_ldiv((0, 0, 0), (1, 2, 3)) is None\n    assert monomial_ldiv((1, 1, 1), (0, 0, 0)) is None\n    assert monomial_ldiv((0, 0, 0), (0, 0, 0)) == (0, 0, 0)\n", "def test_monomial_deg():\n    assert monomial_deg((1, 2)) == 3\n    assert monomial_deg((1, 3)) == 4\n    assert monomial_deg((1, 4)) == 5\n    assert monomial_deg((2, 2)) == 4\n    assert monomial_deg((3, 3)) == 6\n    assert monomial_deg((0, 0)) == 0\n", "def test_monomial_divides_comm():\n    i, j, k = symbols('i j k', commutative=False)\n    assert monomial_divides((1, 2), (1, 2)) is True\n    assert monomial_divides((1, 2), (1, 0)) is False\n    assert monomial_divides((1, 2), (1, 3)) is False\n    assert monomial_divides((1, 2), (2, 2)) is True\n    assert monomial_divides((1, 2), (3, 2)) is False\n", "def test_Monomial():\n    assert Monomial((1, 2)).exponents == (1, 2)\n    assert Monomial((1, 2)).gens == (x, y)\n    assert Monomial((1, 2), [x, y]).exponents == (1, 2)\n    assert Monomial((1, 2), [x, y]).gens == [x, y]\n\n    m = Monomial((1, 2))\n    assert m.as_expr() == x**2*y\n    assert m.as_expr(x, y) == x**2*y\n    assert m.as_expr(x, z) == x**2*y\n    assert m.as_expr() == x**2*y\n\n    m = Monomial((1, 2), [x, y])\n    assert m.as_expr() == x**2*y\n    assert m.as_expr(x, y) == x**2*y\n    assert m.as_expr(x, z) == x**2*y\n    assert m.as_expr([x, z]) == x**2*y\n    assert m.as_expr([x, w]) == x**2*y\n\n    m = Monomial(3)\n    assert m.as_expr() == x**3\n    assert m.as_expr(x) == x**3\n\n    m = Monomial(3, [x, y])\n    assert m.as_expr() == x**3\n    assert m.as_expr(x) == x**3\n    assert m.as_expr(x, y) == x**3\n    assert m.as_expr([x, z]) == x**3\n    assert m.as_expr([x, w]) == x**3\n\n    m = Monomial(3)\n    assert m.as_expr().is_Mul\n    assert m.as_expr(x).is_Mul\n\n    m = Monomial(3, [x, y])\n    assert m.as_expr().is_Mul\n    assert m.as_expr(x).is_Mul\n    assert m.as_expr(x, y).is_Mul\n    assert m.as_expr([x, z]).is_Mul\n    assert m.as_expr([x, w]).is_Mul\n\n    m = Monomial((1, 2))\n    assert str(m) == 'x**2*y'\n    assert str(m) == str(m.as_expr())\n    assert str(m) == str(m.as_expr(x, y))\n\n    m =", "def test_Monomial():\n    # Monomial tests\n    M = Monomial((1, 2, 3))\n    assert isinstance(M.exponents, tuple)\n    assert M.exponents == (1, 2, 3)\n    assert M.gens is None\n    assert M.as_expr() == x**1*y**2*z**3\n    assert M.as_expr(x, y, z) == x**1*y**2*z**3\n    assert M == Monomial((1, 2, 3))\n    assert M != Monomial((1, 2, 4))\n    assert M != (1, 2, 3)\n    assert M == (1, 2, 3)\n    assert M * (2, 3, 4) == (2, 4, 12)\n    assert M / (2, 3, 4) == (0.5, 0.6666666666666666, 0.75)\n    assert M ** 2 == (2, 4, 9)\n    assert M.gcd((2, 3, 4)) == (1, 2, 3)\n    assert M.lcm((2, 3, 4)) == (2, 3, 4)\n    assert M.as_expr(*['x', 'y', 'z']) == 'x**1*y**2*z**3'\n    assert M.as_expr(*['x', 'y', 'z']) == 'x**1*y**2*z**3'\n    assert len(M) == 3\n    assert M[0] == 1\n    assert M[1] == 2\n    assert M[2] == 3\n    assert M.__hash__() is not None\n    M2 = M.rebuild((2, 3, 4))\n    assert M2.as_expr() == x**2*y**3*z**4\n\n    # Commutative variable test\n    M = Monomial((1, 2, 3), [x, y, z])\n    assert M.exponents == (1, 2, 3)\n    assert M.gens == [x, y, z]\n    assert M.as_expr() == x**1*y**2*z**3\n    M2 = M.rebuild((2, 3, 4), [x, y, z])\n   "], "sample_46": ["    def setUp(self):\n            return ', '.join(\"%s_%s_%s\" % (table_name, column_name, suffix) for column_name in column_names)\n        self.reference = IndexName(\n            'table', ['first_column', 'second_column'], 'suffix', create_index_name\n        )\n", "    def setUp(self):\n        self.reference = IndexName(\n            'table', ['first_column', 'second_column'], 'suffix', lambda table, columns, suffix: '_'.join(map(str, (table, columns, suffix)))\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(), col_suffixes=['suffix_1', 'suffix_2']\n        )\n", "    def test_rename_table_references_multiple(self):\n        reference = MockReference('', {'table'}, {})\n        statement = Statement('', reference=reference, non_reference='')\n        statement.rename_table_references('table', 'other')\n        statement.rename_table_references('other', 'other_table')\n        self.assertEqual(reference.referenced_tables, {'other_table'})\n", "    def test_rename_column_references_with_multiple_columns(self):\n        reference = MockReference('reference', {'table'}, {('table', 'first_column'), ('table', 'second_column')})\n        statement = Statement('', reference=reference, non_reference='')\n        statement.rename_column_references('table', 'first_column', 'other')\n        statement.rename_column_references('table', 'second_column', 'third')\n        self.assertEqual(reference.referenced_columns, {('table', 'other'), ('table', 'third')})\n"], "sample_93": ["    def test_cleanup_on_basetemp_change(self, pytester: Pytester) -> None:\n        \"\"\"Test that the basetemp is cleaned up when it is changed between sessions.\"\"\"\n        mytemp = pytester.mkdir(\"mytemp\")\n        p = pytester.makepyfile(\n            \"\"\"\n                pass\n                pass\n        \"\"\"\n        )\n        pytester.runpytest(p, \"--basetemp=%s\" % mytemp)\n        assert mytemp.exists()\n        mytemp.joinpath(\"hello\").touch()\n        pytester.runpytest(p, \"--basetemp=new-%s\" % mytemp)\n        assert not mytemp.exists()\n", "    def test_basetemp_absolute(self, tmp_path):\n        config = cast(Config, FakeConfig(tmp_path))\n        t = TempPathFactory.from_config(config, _ispytest=True)\n        assert t.getbasetemp() == tmp_path\n", "def test_mkdir_relative_basetemp_absolute_path(monkeypatch):\n    \"\"\"#4425\"\"\"\n    tmp_path = Path(\"/absolute/path\")\n    monkeypatch.setenv(\"PYTEST_DEBUG_TEMPROOT\", str(tmp_path))\n    config = cast(Config, FakeConfig(tmp_path))\n    t = TempPathFactory.from_config(config, _ispytest=True)\n    assert t.getbasetemp().resolve() == tmp_path.resolve()\n\n    t = TempPathFactory.from_config(config, basetemp=Path(\"/another/absolute/path\"), _ispytest=True)\n    assert t.getbasetemp().resolve() == Path(\"/another/absolute/path\").resolve()\n\n    with pytest.raises(ValueError):\n        t = TempPathFactory.from_config(config, basetemp=Path(\"/absolute/path\"), _ispytest=True)\n        t.mktemp(\"basename\")\n\n    with pytest.raises(ValueError):\n        t = TempPathFactory.from_config(config, basetemp=Path(\"/absolute/path\"), _ispytest=True)\n        t.mktemp(\"/absolute/path\")\n", "    def test_getbasetemp_empty_basetemp(self, tmp_path: Path) -> None:\n        config = cast(Config, FakeConfig(tmp_path))\n        t = TempPathFactory.from_config(config, _ispytest=True)\n        assert t.getbasetemp() is None\n", "    def test_getbasetemp_none(self, monkeypatch):\n        \"\"\"Test that TempPathFactory raises an assertion error if basetemp is not set.\"\"\"\n        monkeypatch.setenv(\"PYTEST_DEBUG_TEMPROOT\", \"\")\n        config = cast(Config, FakeConfig(\"tmp\"))\n        t = TempPathFactory.from_config(config, _ispytest=True)\n        with pytest.raises(AssertionError):\n            t.getbasetemp()\n"], "sample_16": ["def test_label_for_field_boolean_field(self):\n    \"\"\"\n    Tests for label_for_field when the field is a BooleanField\n    \"\"\"\n    self.assertEqual(\n        label_for_field(\"is_active\", models.BooleanField()),\n        \"Is active\"\n    )\n\n    self.assertEqual(\n        label_for_field(\"is_active\", models.BooleanField(), return_attr=True),\n        (\"Is active\", None)\n    )\n\n    class MockModelAdmin:\n            return \"custom is_active\"\n\n    self.assertEqual(\n        label_for_field(\"is_active\", models.BooleanField(), model_admin=MockModelAdmin),\n        \"custom is_active\"\n    )\n\n    self.assertEqual(\n        label_for_field(\"is_active\", models.BooleanField(), model_admin=MockModelAdmin, return_attr=True),\n        (\"custom is_active\", MockModelAdmin.is_active)\n    )\n\n    class MockModelAdmin:\n        is_active = models.BooleanField()\n\n    self.assertEqual(\n        label_for_field(\"is_active\", models.BooleanField(), model_admin=MockModelAdmin),\n        \"Is active\"\n    )\n", "    def test_number_formats_display_for_value(self):\n        \"\"\"\n        Regression test for #12550: display_for_value should handle numbers.\n        \"\"\"\n        display_value = display_for_value(12345.6789, self.empty_value)\n        self.assertEqual(display_value, '12345.6789')\n\n        display_value = display_for_value(Decimal('12345.6789'), self.empty_value)\n        self.assertEqual(display_value, '12345.6789')\n\n        display_value = display_for_value(12345, self.empty_value)\n        self.assertEqual(display_value, '12345')\n", "def test_quoting_for_admin_url(self):\n    \"\"\"\n    Regression test for #12345\n    \"\"\"\n    self.assertEqual(\n        quote(\"/path/to/field\"),\n        \"/path/to/_field\"\n    )\n\n    self.assertEqual(\n        quote(123),\n        '_7B'\n    )\n\n    self.assertEqual(\n        quote(\":\"),\n        '_3A'\n    )\n\n    self.assertEqual(\n        unquote(\"/path/_to/_field\"),\n        \"/path/to/field\"\n    )\n", "    def test_lookup_needs_distinct(self):\n        class MyModel(models.Model):\n            pk = models.AutoField(primary_key=True)\n            f1 = models.IntegerField()\n            f2 = models.ManyToManyField(MyModel)\n\n        opts = MyModel._meta\n        self.assertTrue(lookup_needs_distinct(opts, 'f1'))\n        self.assertTrue(lookup_needs_distinct(opts, 'f2__f1'))\n        self.assertTrue(lookup_needs_distinct(opts, 'f2__f1__f1'))\n        self.assertFalse(lookup_needs_distinct(opts, 'f1__in'))\n        self.assertFalse(lookup_needs_distinct(opts, 'f1__isnull'))\n\n        class MyModel(models.Model):\n            pk = models.AutoField(primary_key=True)\n            f1 = models.ForeignKey('self')\n\n        opts = MyModel._meta\n        self.assertFalse(lookup_needs_distinct(opts, 'f1'))\n\n        class MyModel(models.Model):\n            pk = models.AutoField(primary_key=True)\n            f1 = models.GenericForeignKey()\n\n        opts = MyModel._meta\n        self.assertFalse(lookup_needs_distinct(opts, 'f1'))\n", "    def test_label_for_field_callable_on_form(self):\n        \"\"\"\n        Regression test for #13961\n        \"\"\"\n        class ArticleForm(forms.ModelForm):\n            extra_form_field = forms.BooleanField()\n\n            class Meta:\n                fields = '__all__'\n                model = Article\n\n            return \"test callable on form\"\n\n        form = ArticleForm()\n        self.assertEqual(\n            label_for_field(test_callable_form, Article, form=form, return_attr=True),\n            (\"test callable on form\", test_callable_form)\n        )\n"], "sample_82": ["def test_groupby_quantile_empty_dataset():\n    ds = xr.Dataset()\n    with pytest.raises(ValueError):\n        ds.groupby(\"foo\").quantile(0.5)\n", "def test_da_groupby_quantile_single_value_group():\n    array = xr.DataArray([1, 1, 1, 2, 2, 2], [(\"x\", [1, 1, 1, 2, 2, 2]))\n    expected = xr.DataArray([3, 3], [(\"x\", [1, 2])])\n    actual = array.groupby(\"x\").quantile(0)\n    assert_identical(expected, actual)\n", "def test_da_groupby_reduce_list_of_dims():\n    array = xr.DataArray([1, 2, 3], [(\"x\", [1, 1, 2])])\n    with raises_regex(ValueError, \"cannot reduce over dimensions\"):\n        array.groupby(\"x\").reduce(np.mean, [\"x\", \"y\"])\n\n    array = xr.DataArray([1, 2, 3], [(\"x\", [1, 1, 1])])\n    with raises_regex(ValueError, \"cannot reduce over dimensions\"):\n        array.groupby(\"x\").reduce(np.mean, [\"x\", \"y\", \"z\"])\n\n    array = xr.DataArray([1, 2, 3], [(\"x\", [1, 1, 1])])\n    assert_identical(array, array.groupby(\"x\").reduce(np.mean, \"x\"))\n\n    array = xr.DataArray([1, 2, 3], [(\"x\", [1, 1, 1]))\n    with raises_regex(ValueError, \"cannot reduce over dimensions\"):\n        array.groupby(\"x\").reduce(np.mean, \"x\", \"y\")\n", "def test_groupby_unstack_empty():\n    # GH3083\n    # Fix for unstacking an empty group by result\n    array = xr.DataArray([1, 2, 3], [(\"x\", [1, 1, 1])])\n    grouped = array.groupby(\"x\")\n    actual = grouped.unstack(\"x\")\n    assert_identical(grouped._maybe_unstack(array), actual)\n", "def test_groupby_last():\n    # test for the last method\n    array = xr.DataArray([1, 2, 3], [(\"x\", [1, 2, 3])])\n    expected = xr.DataArray([3], [(\"x\", [3])])\n    actual = array.groupby(\"x\").last()\n    assert_equal(expected, actual)\n\n    # test for the last method when the groupby object is non-trivial\n    array = xr.DataArray([1, 2, 3, 4, 5, 6], [(\"x\", [1, 1, 1, 2, 2, 2]))\n    expected = xr.DataArray([3, 6], [(\"x\", [1, 2]))\n    actual = array.groupby(\"x\").last()\n    assert_equal(expected, actual)\n\n    # test for the last method when the groupby object has multiple groups\n    array = xr.DataArray([1, 2, 3, 4, 5, 6, 7, 8, 9], [(\"x\", [1, 1, 1, 2, 2, 2, 3, 3, 3]))\n    expected = xr.DataArray([3, 6, 9], [(\"x\", [1, 2, 3]))\n    actual = array.groupby(\"x\").last()\n    assert_equal(expected, actual)\n\n    # test for the last method when the groupby object has a non-trivial coordinate\n    array = xr.DataArray(\n        [1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [(\"x\", [1, 1, 1, 2, 2, 2, 3, 3, 3]), (\"y\", [0, 0, 0, 1, 1, 1, 0, 0, 0])],\n    )\n    expected = xr.DataArray(\n        [[3, 8], [6, 9]], coords={\"x\": [1, 2, 3], \"y\": [0, 1]}, dims=(\"x\", \"y\")\n    )\n    actual = array.groupby(\"x\").last()\n    assert_equal(expected, actual)\n"], "sample_20": ["    def test_unique_constraint_pointing_to_non_local_field_inheritance(self):\n        class Parent(models.Model):\n            field1 = models.IntegerField()\n\n        class Child(Parent):\n            field2 = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(fields=['field1', 'field2'], name='name'),\n                ]\n\n        self.assertEqual(Child.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to field 'field1' which is not local to \"\n                \"model 'Child'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Child,\n                id='models.E016',\n            ),\n        ])\n", "    def test_index_with_condition(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                indexes = [\n                    models.Index(fields=['age'], name='index_age_gte_10', condition=models.Q(age__gte=10)),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_partial_indexes else [\n            Warning(\n                '%s does not support indexes with conditions.' % connection.display_name,\n                hint=(\n                    \"Conditions will be ignored. Silence this warning if you \"\n                    \"don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W037',\n            )\n        ]\n        self.assertEqual(errors, expected)\n", "    def test_check_datefield(self):\n        class Model(models.Model):\n            field = models.DateField()\n\n        error = Error(\n            '%s does not support DateFields.' % connection.display_name,\n            obj=Model,\n            id='fields.E181',\n        )\n        expected = [] if connection.features.supports_date_field else [error]\n        self.assertEqual(Model.check(databases=self.databases), expected)\n", "    def test_m2m_autogenerated_table_name_clash_database_routers_installed(self):\n        class Foo(models.Model):\n            class Meta:\n                db_table = 'bar_foos'\n\n        class Bar(models.Model):\n            # The autogenerated `db_table` will be bar_foos.\n            foos = models.ManyToManyField(Foo)\n\n            class Meta:\n                db_table = 'bar'\n\n        self.assertEqual(Bar.check(), [\n            Warning(\n                \"The field's intermediary table 'bar_foos' clashes with the \"\n                \"table name of 'invalid_models_tests.Foo'.\",\n                obj=Bar._meta.get_field('foos'),\n                hint=(\n                    \"You have configured settings.DATABASE_ROUTERS. Verify \"\n                    \"that the table of 'invalid_models_tests.Foo' is correctly \"\n                    \"routed to a separate database.\"\n                ),\n                id='fields.W344',\n            ),\n        ])\n", "    def test_swapped_model(self):\n        class Model(models.Model):\n            class Meta:\n                swappable = 'invalid_models_tests.swapped_model'\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"'invalid_models_tests.swapped_model' is not of the form 'app_label.app_name'.\",\n                id='models.E001',\n            ),\n        ])\n"], "sample_136": ["def test_BlockMatrix_equals():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n    Y = BlockMatrix([[A, B], [C, D]])\n    Z = BlockMatrix([[A, B + C], [C, D]])\n\n    assert X.equals(Y)\n    assert X.equals(X)\n    assert not X.equals(Z)\n", "def test_BlockDiagMatrix_blockadd():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', m, m)\n    C = MatrixSymbol('C', l, l)\n    M = MatrixSymbol('M', n + m + l, n + m + l)\n    X = BlockDiagMatrix(A, B, C)\n    Y = BlockDiagMatrix(A, B, C)\n\n    assert block_collapse(X + Y).equals(BlockDiagMatrix(2*A, 2*B, 2*C))\n    assert block_collapse(X + B).equals(BlockDiagMatrix(A, B + B, C))\n", "def test_BlockDiagMatrix_add():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', m, m)\n    C = MatrixSymbol('C', l, l)\n    X = BlockDiagMatrix(A, B, C)\n    Y = BlockDiagMatrix(A, B, C)\n    assert bc_block_plus_ident(X + Y) == BlockDiagMatrix(2*A, 2*B, 2*C)\n", "def test_BlockMatrix_Determinant_2x2():\n    A, B, C, D = [MatrixSymbol(s, 3, 3) for s in 'ABCD']\n    X = BlockMatrix([[A, B], [C, D]])\n    from sympy import assuming, Q\n    with assuming(Q.invertible(A)):\n        assert det(X) == det(A) * det(D - C*A.I*B)\n\n    with assuming(Q.invertible(D)):\n        assert det(X) == det(D) * det(A - B*D.I*C)\n", "def test_Inverse_BlockMatrix():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    C = MatrixSymbol('C', n, n)\n    X = BlockMatrix([[A, B], [C, B.inv()]])\n    assert bc_matmul(X.I) == BlockMatrix([[(A-B*B.inv()).I, -(A-B*B.inv()).I*B*B.inv().I],\n                                         [-B*B.inv().I*A.I, (B.inv())**2]])\n\n    X = BlockDiagMatrix(A, B.inv())\n    assert bc_matmul(X.I) == BlockDiagMatrix(A.inv(), (B.inv())**2)\n\n    # Issue 17624\n    a = MatrixSymbol(\"a\", 2, 2)\n    z = ZeroMatrix(2, 2)\n    b = BlockMatrix([[a, z], [z, z]])\n    assert bc_matmul(b.I*b) == BlockMatrix([[a.inv(), z], [z, z]])\n"], "sample_91": ["    def test_xfail_raises(self, expected, actual, matchline, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(raises=%s)\n                raise %s()\n        \"\"\"\n            % (expected, actual)\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([matchline])\n", "def test_xfail_report_status(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            import pytest\n            @pytest.mark.xfail\n                assert 0\n        \"\"\"\n    )\n    result = testdir.runpytest(\"-rxs\")\n    result.stdout.fnmatch_lines([\"*XFAIL*test_func*\", \"*test_func*\"])\n", "    def test_str_condition_with_invalid_syntax(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'nope' + 'attr')\")\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_skip_marks(item)\n        assert excinfo.value.msg is not None\n        assert \"Error evaluating 'skipif': you need to specify reason=STRING when using booleans as conditions.\" not in excinfo.value.msg\n        assert \"SyntaxError: invalid syntax\" in excinfo.value.msg\n", "    def test_multiple_reasons(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\", reason=\"first reason\")\n            @pytest.mark.skipif(\"hasattr(os, 'sep')\", reason=\"second reason\")\n                pass\n        \"\"\"\n        )\n        skipped = evaluate_skip_marks(item)\n        assert skipped\n        assert skipped.reason == \"second reason\"\n", "    def test_failing_xfail_raises(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(raises=TypeError)\n                raise ValueError(\"test failure\")\n        \"\"\"\n        )\n        reports = runtestprotocol(item, log=False)\n        assert len(reports) == 3\n        callreport = reports[1]\n        assert callreport.skipped\n        assert callreport.wasxfail == \"\"\n        assert isinstance(callreport.longrepr[2], xfail.Exception)\n        assert callreport.longrepr[2].msg.startswith(\"value raised ValueError('test failure')\")\n"], "sample_118": ["def test_ccode_AugmentedAssignment():\n    from sympy.tensor import IndexedBase, Idx\n    from sympy import symbols\n    n = symbols('n', integer=True)\n    A = IndexedBase('A')\n    x = IndexedBase('x')\n    y = IndexedBase('y')\n    z = IndexedBase('z')\n    i = Idx('i', n)\n    j = Idx('j', n)\n\n    s = (\n        'for (int i=0; i<n; i++){\\n'\n        '   for (int j=0; j<n; j++){\\n'\n        '      y[i] += A[%s]*x[j];\\n' % (i*n + j) +\\\n        '   }\\n'\n        '}\\n'\n    )\n    c = ccode(A[i, j]*x[j] += y[i])\n    assert c == s\n", "def test_ccode_For():\n    n = symbols('n', integer=True)\n    A = IndexedBase('A')\n    i = Idx('i', n)\n    B = IndexedBase('B')\n    j = Idx('j', n)\n    expr = For(i, A[i]*B[i, j])\n    assert ccode(expr) == (\n        'for (int i=0; i<n; i++){\\n'\n        '   A[i] = B[i][j];\\n'\n        '}')\n", "def test_ccode_For():\n    from sympy import For, symbols\n    n = symbols('n', integer=True)\n    i = symbols('i', integer=True)\n    x = symbols('x')\n    y = symbols('y')\n    expr = For(i, n, 'x[i] = x[i] + 1')\n    assert ccode(expr) == (\n        'for (int i=0; i<n; i++){\\n'\n        '   x[i] = x[i] + 1;\\n'\n        '}')\n", "def test_ccode_Matrix():\n    from sympy import Matrix, MatrixSymbol, symbols\n    A = MatrixSymbol('A', 3, 3)\n    M = Matrix([[x, y, z], [x**2, y**2, z**2], [x**3, y**3, z**3]])\n    assert ccode(M, A) == (\n        \"A[0] = x;\\n\"\n        \"A[1] = y;\\n\"\n        \"A[2] = z;\\n\"\n        \"A[3] = x**2;\\n\"\n        \"A[4] = y**2;\\n\"\n        \"A[5] = z**2;\\n\"\n        \"A[6] = x**3;\\n\"\n        \"A[7] = y**3;\\n\"\n        \"A[8] = z**3;\"\n    )\n    assert ccode(M.as_matrix(), A) == (\n        \"A[0] = x;\\n\"\n        \"A[1] = y;\\n\"\n        \"A[2] = z;\\n\"\n        \"A[3] = x**2;\\n\"\n        \"A[4] = y**2;\\n\"\n        \"A[5] = z**2;\\n\"\n        \"A[6] = x**3;\\n\"\n        \"A[7] = y**3;\\n\"\n        \"A[8] = z**3;\"\n    )\n", "def test_ccode_loops_multiple_terms_with_contract():\n    from sympy.tensor import IndexedBase, Idx\n    from sympy import symbols\n    n, m, o, p = symbols('n m o p', integer=True)\n    a = IndexedBase('a')\n    b = IndexedBase('b')\n    c = IndexedBase('c')\n    y = IndexedBase('y')\n    i = Idx('i', m)\n    j = Idx('j', n)\n    k = Idx('k', o)\n    l = Idx('l', p)\n\n    s0 = (\n        'for (int i=0; i<m; i++){\\n'\n        '   y[i] = 0;\\n'\n        '}\\n'\n    )\n    s1 = (\n        'for (int i=0; i<m; i++){\\n'\n        '   for (int j=0; j<n; j++){\\n'\n        '      for (int k=0; k<o; k++){\\n'\n        '         for (int l=0; l<p; l++){\\n'\n        '            y[i] = a[i, j, k, l] + b[i, j, k, l];\\n'\n        '         }\\n'\n        '      }\\n'\n        '   }\\n'\n        '}\\n'\n    )\n    s2 = (\n        'for (int i=0; i<m; i++){\\n'\n        '   for (int j=0; j<n; j++){\\n'\n        '      for (int k=0; k<o; k++){\\n'\n        '         for (int l=0; l<p; l++){\\n'\n        '            y[i] = a[i, j, k, l]*c[j, k, l] + y[i];\\n'\n        '         }\\n'\n        '      }\\n'\n        '   }\\n'\n        '}\\n'\n    )\n    c = ccode(a[i, j, k, l] + b[i, j, k, l]*c[j, k, l], assign_to=y[i], contract=True)\n    assert (c == s0 + s1 + s2[:-1] or\n            c == s0 + s2 + s1[:-1])\n"], "sample_62": ["    def setUp(self):\n        super().setUp()\n        self.dirname = \"/tmp/django_cache_test\"\n        # Caches location cannot be modified through override_settings /\n        # modify_settings, hence settings are manipulated directly here and the\n        # setting_changed signal is triggered manually.\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n", "    def setUp(self):\n        super().setUp()\n        # LocMem requires a hack to make the other caches\n        # share a data store with the 'normal' cache.\n        caches[\"prefix\"]._cache = cache._cache\n        caches[\"prefix\"]._expire_info = cache._expire_info\n\n        caches[\"v2\"]._cache = cache._cache\n        caches[\"v2\"]._expire_info = cache._expire_info\n\n        caches[\"custom_key\"]._cache = cache._cache\n        caches[\"custom_key\"]._expire_info = cache._expire_info\n\n        caches[\"custom_key2\"]._cache = cache._cache\n        caches[\"custom_key2\"]._expire_info = cache._expire_info\n", "    def setUp(self):\n        super().setUp()\n        self.dirname = self.mkdtemp()\n        # Caches location cannot be modified through override_settings /\n        # modify_settings, hence settings are manipulated directly here and the\n        # setting_changed signal is triggered manually.\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n", "    def setUp(self):\n        super().setUp()\n        self.dirname = self.mkdtemp()\n        # Caches location cannot be modified through override_settings /\n        # modify_settings, hence settings are manipulated directly here and the\n        # setting_changed signal is triggered manually.\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n", "    def setUp(self):\n        self.dirname = self.mkdtemp()\n        # Caches location cannot be modified through override_settings /\n        # modify_settings, hence settings are manipulated directly here and the\n        # setting_changed signal is triggered manually.\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n"], "sample_8": ["    def test_template_not_found_error(self):\n        # Raises a TemplateDoesNotExist exception and shows the debug view.\n        url = reverse('raises_template_does_not_exist', kwargs={\"path\": \"notfound.html\"})\n        with self.assertLogs('django.request', 'ERROR'):\n            response = self.client.get(url)\n        self.assertContains(response, '<div class=\"context\" id=\"', status_code=500)\n", "    def test_tried_urls(self):\n        response = self.client.get('/raises404/')\n        self.assertContains(response, \"<code>not-in-urls</code>, didn't match\", status_code=404)\n        self.assertContains(response, \"Django tried these URL patterns\", status_code=404)\n        self.assertContains(response, r\"^regex-post/(?P&lt;pk&gt;[0-9]+)/$\", status_code=404)\n        self.assertContains(response, \"[name='regex-post']\", status_code=404)\n        self.assertContains(response, r\"path-post/&lt;int:pk&gt;/\", status_code=404)\n        self.assertContains(response, \"[name='path-post']\", status_code=404)\n", "    def test_plain_text_status_code(self):\n        response = HttpResponse('test', status=500)\n        self.assertEqual(response.status_code, 500)\n", "    def test_frame_variables_for_dict(self):\n        try:\n            d = {'k1': 'v1', 'k2': 'v2', 'sensitive': 'v3'}\n            raise Exception(d)\n        except Exception:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(None, exc_type, exc_value, tb)\n        html = reporter.get_traceback_html()\n        self.assertInHTML('<tr><th>k1</th><td class=\"code\"><pre>v1</pre></td></tr>', html)\n        self.assertInHTML('<tr><th>k2</th><td class=\"code\"><pre>v2</pre></td></tr>', html)\n        self.assertNotIn('<tr><th>sensitive</th><td class=\"code\"><pre>***************</pre></td></tr>', html)\n", "    def test_custom_urlconf_path(self):\n        \"\"\"\n        When the request path is not in the URLconf, the technical 404 page should\n        display the URLconf path that the request path was trying to match against.\n        \"\"\"\n        response = self.client.get('/url/')\n        self.assertEqual(response.status_code, 404)\n        self.assertContains(response, '<h2>Page not found</h2>', status_code=404)\n        self.assertContains(response, 'Raised by:', status_code=404)\n        self.assertContains(response, 'view_tests.views.index_page', status_code=404)\n"], "sample_101": ["def test_pipeline_clone():\n    # Test whether the cloned pipeline is able to transform the data\n    iris = load_iris()\n    X = iris.data\n    pca = PCA(n_components=2, svd_solver='full')\n    pipeline = Pipeline([('pca', pca)])\n    cloned_pipeline = clone(pipeline)\n    assert not pca is cloned_pipeline.named_steps['pca']\n    X_transformed = pipeline.fit_transform(X)\n    X_transformed_cloned = cloned_pipeline.fit_transform(X)\n    assert_array_almost_equal(X_transformed, X_transformed_cloned)\n", "def test_pipeline_last_step_passthrough_inverse_transform():\n    # Test whether pipeline with passthrough as last step supports\n    # inverse_transform.\n    pca = PCA(n_components=2, svd_solver='full')\n    pipeline = Pipeline([('pca', pca), ('passthrough', 'passthrough')])\n    X = np.array([[1, 2, 3, 4, 5]])\n    X_trans = pipeline.fit_transform(X)\n    assert_array_almost_equal(X, pipeline.inverse_transform(X_trans))\n", "def test_pipeline_invalid_step_fit():\n    # Test that a ValueError is raised when an invalid estimator is passed\n    # in the pipeline steps.\n    pipe = Pipeline([('transf', Transf()), ('clf', DummyEstimatorParams())])\n    assert_raises_regex(\n        ValueError,\n        r\"'DummyEstimatorParams' object has no attribute 'fit'\",\n        pipe.fit, np.asarray([[1, 2]]), np.asarray([1])\n    )\n", "def test_feature_union_transformer_attributes():\n    # Test that FeatureUnion passes on attributes of transformers\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    pca = PCA(n_components=2, svd_solver='randomized', random_state=0)\n    select = SelectKBest(k=1)\n    pca.component_ = 'pca_component'\n    select.support_ = 'select_support'\n    fs = FeatureUnion([(\"pca\", pca), (\"select\", select)])\n\n    fs.fit(X, y)\n    # check that attributes are passed on correctly\n    assert_equal(fs.named_steps.pca.component_, pca.component_)\n    assert_equal(fs.named_steps.select.support_, select.support_)\n    assert_equal(pca.component_, 'pca_component')\n    assert_equal(select.support_, 'select_support')\n", "def test_pipeline_get_feature_names():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    pca = PCA(n_components=2, svd_solver='randomized', random_state=0)\n    select = SelectKBest(k=1)\n\n    # test using fit followed by transform\n    fs = FeatureUnion([(\"pca\", pca), (\"select\", select)])\n    fs.fit(X, y)\n    X_transformed = fs.transform(X)\n    assert_equal(fs.get_feature_names(), ['pca__%s' % i for i in range(4)])\n\n    # test using fit_transform\n    X_transformed = fs.fit_transform(X, y)\n    assert_equal(fs.get_feature_names(), ['pca__%s' % i for i in range(4)])\n\n    # test that get_feature_names is a method of the FeatureUnion\n    assert hasattr(fs, 'get_feature_names')\n    assert callable(fs.get_feature_names)\n\n    # test that if the last transformer in FeatureUnion is not a transformer\n    # that implements get_feature_names, the FeatureUnion should raise an error\n    fs = FeatureUnion([(\"pca\", pca), (\"select\", SelectKBest(k=1)]))\n    assert_raises_regex(\n        AttributeError,\n        'Transformer pca (type PCA) does not provide get_feature_names',\n        fs.get_feature_names\n    )\n"], "sample_11": ["def test_serialize_functools_partialmethod_with_args(self):\n    value = functools.partialmethod(datetime.timedelta, seconds=2)\n    result = self.serialize_round_trip(value)\n    self.assertIsInstance(result, functools.partialmethod)\n    self.assertEqual(result.func, value.func)\n    self.assertEqual(result.args, value.args)\n    self.assertEqual(result.keywords, value.keywords)\n", "def test_register_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return 'complex(%r)' % self.value, {}\n    self.assertEqual(\n        Serializer.register(models.CharField, ComplexSerializer),\n        None\n    )\n    self.assertEqual(\n        Serializer.serialize(models.CharField(max_length=255)),\n        (\"models.CharField(max_length=255)\", {\"from django.db import models\"})\n    )\n    self.assertEqual(\n        Serializer.serialize(ComplexSerializer(models.CharField(max_length=255))),\n        (\"complex(models.CharField(max_length=255))\", set())\n    )\n    self.assertEqual(\n        Serializer.serialize(models.CharField(max_length=255)),\n        (\"models.CharField(max_length=255)\", {\"from django.db import models\"})\n    )\n    Serializer.unregister(models.CharField)\n    self.assertEqual(\n        Serializer.serialize(models.CharField(max_length=255)),\n        (\"models.CharField(max_length=255)\", {\"from django.db import models\"})\n    )\n", "def test_serialize_floatmath_operations(self):\n    \"\"\"\n    Tests serializing float and math operations.\n    \"\"\"\n    self.assertSerializedEqual(float('nan'))\n    self.assertSerializedEqual(math.pi)\n    self.assertSerializedEqual(math.e)\n    self.assertSerializedEqual(math.sin(1))\n    self.assertSerializedResultEqual(\n        math.sin(1),\n        (\"math.sin(1)\", set())\n    )\n", "    def test_money_deconstruct(self):\n        value = Money(1.3)\n        self.serialize_round_trip(value)\n", "def test_serialize_user(self):\n    \"\"\"\n    Test serialization of User object.\n    \"\"\"\n    user = self.user  # Assuming self.user is set up elsewhere in the test case\n    # User objects cannot be serialized.\n    with self.assertRaisesMessage(ValueError, \"Cannot serialize: <User: user>\"):\n        self.assertSerializedEqual(user)\n"], "sample_122": ["def test_row_structure_symbolic_cholesky():\n    testmat = SparseMatrix([[1, 0, 3, 2],\n                            [0, 0, 1, 0],\n                            [4, 0, 0, 5],\n                            [0, 6, 7, 0]])\n    Lrow = testmat.row_structure_symbolic_cholesky()\n    assert Lrow == [[0], [], [0], [1, 2]]\n", "def test_solve_least_squares():\n    A = SparseMatrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    b = SparseMatrix([[10, 20, 30], [40, 50, 60], [70, 80, 90]])\n    assert A.solve_least_squares(b) == A.inv(method='LDL') * b\n    assert A.solve_least_squares(b, method='CH') == A.inv(method='CH') * b\n", "def test_symmetric():\n    m = SparseMatrix(((1, 0, 0), (0, 2, 0), (0, 0, 3)))\n    assert m.is_symmetric(simplify=False)\n    assert m.is_symmetric(simplify=True)\n    assert not m.is_symmetric(simplify=False, symmetric=True)\n\n    m = SparseMatrix(((1, 0, 0), (0, 2, 1), (0, 1, 3)))\n    assert not m.is_symmetric(simplify=False)\n    assert m.is_symmetric(simplify=True)\n    assert not m.is_symmetric(simplify=False, symmetric=True)\n\n    m = SparseMatrix(((1, 2, 0), (2, 1, 0), (0, 0, 4)))\n    assert m.is_symmetric(simplify=False)\n    assert m.is_symmetric(simplify=True)\n    assert m.is_symmetric(simplify=False, symmetric=True)\n", "def test_modulus():\n    x = Symbol('x')\n    y = Symbol('y')\n    a = SparseMatrix(((x, 1), (y, 2*y)))\n    assert a.modulus() == SparseMatrix(((Abs(x), 1), (Abs(y), 2*Abs(y))))\n", "def test_zeros_like():\n    assert SparseMatrix.zeros(2, 3).zeros_like() == SparseMatrix.zeros(2, 3)\n    assert SparseMatrix.zeros(0, 3).zeros_like() == SparseMatrix.zeros(0, 3)\n    assert SparseMatrix.zeros(2, 0).zeros_like() == SparseMatrix.zeros(2, 0)\n\n    a = SparseMatrix([[0, 1], [2, 0]])\n    assert a.zeros_like() == SparseMatrix.zeros(a.rows, a.cols)\n    a = SparseMatrix([[0, 1, 2], [3, 0, 4], [5, 6, 0]])\n    assert a.zeros_like() == SparseMatrix.zeros(a.rows, a.cols)\n\n    # test_zeros_like on matrices that are already zero\n    a = SparseMatrix.zeros(2, 3)\n    assert a.zeros_like() == a\n\n    a = SparseMatrix.zeros(0, 3)\n    assert a.zeros_like() == a\n\n    a = SparseMatrix.zeros(2, 0)\n    assert a.zeros_like() == a\n\n    # test_zeros_like on matrices with different sizes\n    a = SparseMatrix([[0, 1], [2, 0]])\n    assert a.zeros_like(3, 3) == SparseMatrix.zeros(3, 3)\n    a = SparseMatrix([[0, 1, 2], [3, 0, 4], [5, 6, 0]])\n    assert a.zeros_like(3, 2) == SparseMatrix.zeros(3, 2)\n"], "sample_54": ["def test_smart_urlquote_invalid_url(self):\n    # Invalid URLs raise ValueError.\n    items = (\n        \"http://example.com/./\",\n        \"http://example.com/..\",\n        \"http://example.com/\",\n        \"http://example.com/path/to///file.txt\",\n    )\n    for value in items:\n        with self.subTest(value=value):\n            with self.assertRaises(ValueError):\n                smart_urlquote(value)\n", "def test_urlize_email_with_trailing_punctuation(self):\n    tests = (\n        (\n            \"Search for foo@example.com.\",\n            'Search for <a href=\"mailto:foo@example.com\">foo@example.com.</a>',\n        ),\n        (\n            \"Search for foo@example.com, bar@example.com.\",\n            'Search for <a href=\"mailto:foo@example.com\">foo@example.com,</a> '\n            '<a href=\"mailto:bar@example.com\">bar@example.com.</a>',\n        ),\n        (\"Search for foo@example.com:bar@example.com.\", 'Search for <a href=\"mailto:foo@example.com\">foo@example.com:</a><a href=\"mailto:bar@example.com\">bar@example.com.</a>'),\n        (\"Search for foo@example.com!bar@example.com.\", 'Search for <a href=\"mailto:foo@example.com\">foo@example.com!</a><a href=\"mailto:bar@example.com\">bar@example.com.</a>'),\n        (\"Search for foo@example.com?bar@example.com.\", 'Search for <a href=\"mailto:foo@example.com\">foo@example.com?</a><a href=\"mailto:bar@example.com\">bar@example.com.</a>'),\n        (\"Search for foo@example.com;bar@example.com.\", 'Search for <a href=\"mailto:foo@example.com\">foo@example.com;</a><a href=\"mailto:bar@example.com\">bar@example.com.</a>'),\n        (\"Search for foo@example.com:bar@example.com!\", 'Search for <a href=\"mailto:foo@example.com\">foo@example.com:</a><a href=\"mailto:bar@example.com\">bar@example.com!</a>'),\n        (\"Search for foo@example.com?bar@example.com!\", 'Search for <a href=\"mailto:foo@example.com\">foo@example.com?</a><a href=\"mailto:bar@example.com\">bar@example.com!</a>'),\n        (\"Search for foo@example.com;bar@example.com!\", 'Search for <a href=\"mailto:foo@example.com\">foo@example.com;</a><a href=\"mailto:bar@example.com\">bar@example.com!</a>'),\n        (\"Search for foo@example.com @ bar@example.com\", 'Search for <a href=\"mailto:foo@example.com\">foo@example.com @ </a><a href=\"mailto:bar@example.com\">bar@example.com</a>'),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n", "    def test_urlize_trailing_punctuation(self):\n        # URL with trailing punctuation\n        self.assertEqual(\n            urlize(\"http://example.com/?q=abc.\"),\n            '<a href=\"http://example.com/?q=abc.\">http://example.com/?q=abc.</a>',\n        )\n        self.assertEqual(\n            urlize(\"http://example.com/?q=abc.\"),\n            '<a href=\"http://example.com/?q=abc.\">http://example.com/?q=abc.</a>',\n        )\n        self.assertEqual(\n            urlize(\"http://example.com/?q=abc!\"),\n            '<a href=\"http://example.com/?q=abc!\">http://example.com/?q=abc!</a>',\n        )\n        self.assertEqual(\n            urlize(\"http://example.com/?q=abc;\"),\n            '<a href=\"http://example.com/?q=abc;\">http://example.com/?q=abc;</a>',\n        )\n        self.assertEqual(\n            urlize(\"http://example.com/?q=abc?\"),\n            '<a href=\"http://example.com/?q=abc&amp;\">http://example.com/?q=abc?</a>',\n        )\n        self.assertEqual(\n            urlize(\"http://example.com/?q=abc&\"),\n            '<a href=\"http://example.com/?q=abc&amp;\">http://example.com/?q=abc&amp;</a>',\n        )\n\n        # URL with leading punctuation\n        self.assertEqual(\n            urlize(\"(http://example.com/?q=abc\"),\n            '(<a href=\"http://example.com/?q=abc\">http://example.com/?q=abc</a>)',\n        )\n        self.assertEqual(\n            urlize(\"(http://example.com/?q=abc\"),\n            '(<a href=\"http://example.com/?q=abc\">http://example.com/?q=abc</a>)',\n        )\n        self.assertEqual(\n            urlize(\"[http://example.com/?q=abc\"),\n            '[<a href=\"http://example.com/?q=abc\">http://example.com/?q=abc</a>',\n        )\n        self.assertEqual(\n            urlize(\"[http://example.com/?q=abc\"),\n            '[<a href=\"http://example.com/?q=abc\">http://example.com/?q=abc</a>',\n        )\n\n        # URL with wrapping punctuation\n        self.assertEqual(\n            urlize(\"(http://example.com/?q", "def test_urlize_trailing_punctuation(self):\n    tests = (\n        (\"Search for google.com,.\", 'Search for <a href=\"http://google.com/\">google.com</a>,.'),\n        (\"Search for google.com:.\", 'Search for <a href=\"http://google.com/\">google.com</a>:.'),\n        (\"Search for google.com;.\", 'Search for <a href=\"http://google.com/\">google.com</a>;.'),\n        (\"Search for google.com!.\", 'Search for <a href=\"http://google.com/\">google.com</a>!.'),\n        (\"Search for google.com?.\", 'Search for <a href=\"http://google.com/\">google.com</a>?.'),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n", "def test_strip_tags_large_content(self):\n    # Test with a large amount of HTML content\n    html_content = (\n        \"<p>Large content with multiple lines of text and various HTML tags.</p>\"\n        \"<p>More content with <b>bold</b> text and <i>italic</i> text.</p>\"\n        \"<p>Even more content with <u>underline</u> text and <strike>strike-through</strike> text.</p>\"\n    )\n    start = datetime.now()\n    stripped_content = strip_tags(html_content)\n    elapsed = datetime.now() - start\n    self.assertEqual(elapsed.seconds, 0)\n    self.assertNotIn(\"<\", stripped_content)\n"], "sample_29": ["    def test_resolve_output_field(self):\n        tests = [\n            (IntegerField, AutoField, IntegerField),\n            (AutoField, IntegerField, IntegerField),\n            (IntegerField, DecimalField, DecimalField),\n            (DecimalField, IntegerField, DecimalField),\n            (IntegerField, FloatField, FloatField),\n            (FloatField, IntegerField, FloatField),\n        ]\n        for lhs, rhs, combined in tests:\n            with self.subTest(lhs=lhs, rhs=rhs, combined=combined):\n                expr = ExpressionList(\n                    Expression(lhs()),\n                    Expression(rhs()),\n                )\n                self.assertIsInstance(expr.output_field, combined)\n", "    def setUpTestData(cls):\n        cls.n = Number.objects.create(integer=42, float=15.5)\n        cls.n1 = Number.objects.create(integer=-42, float=-15.5)\n", "    def test_F_expression_with_value_as_rhs(self):\n        with self.assertRaises(FieldError):\n            F('name') == Value('name')\n", "    def setUpTestData(cls):\n        cls.gmbh = Company.objects.create(name='Test GmbH', num_employees=32, num_chairs=1, ceo=Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30))\n        cls.employee = Employee.objects.create(firstname='John', lastname='Doe', salary=100)\n", "    def setUpTestData(cls):\n        cls.start = datetime.datetime(2010, 6, 25, 12, 15, 30, 747000)\n        cls.start_date = cls.start.date()\n        cls.start_time = cls.start.time()\n        cls.start_delta = cls.start - cls.start_date\n        cls.start_delta_millisec = cls.start - cls.start_time\n        cls.start_delta_microsec = cls.start - cls.start.replace(microsecond=0)\n        cls.e1 = Experiment.objects.create(\n            name='e1',\n            assigned=cls.start_date,\n            start=cls.start,\n            end=cls.start + datetime.timedelta(hours=1),\n            completed=cls.start_date + datetime.timedelta(days=1),\n            estimated_time=cls.start_delta,\n        )\n"], "sample_37": ["    def test_repr(self):\n        f = F('name')\n        self.assertEqual(repr(f), \"F(name)\")\n", "    def test_repr(self):\n        self.assertEqual(repr(Col('alias', 'field')), \"Col(alias, field)\")\n", "    def test_update_with_func(self):\n        # F expressions can also update fields using functions\n        Employee.objects.create(firstname='Test', lastname='Test')\n        self.assertEqual(\n            Employee.objects.update(salary=Lower(F('firstname'))),\n            1\n        )\n        self.assertEqual(Employee.objects.get().salary, 'test')\n        self.assertEqual(\n            Employee.objects.update(salary=Lower(F('firstname')) + Lower(F('lastname'))),\n            1\n        )\n        self.assertEqual(Employee.objects.get().salary, 'testtest')\n", "    def test_invalid_outer_ref(self):\n        with self.assertRaisesMessage(ValueError, 'This queryset contains a reference to an outer query and may only be used in a subquery.'):\n            Company.objects.annotate(is_point_of_contact=OuterRef('name'))\n", "    def setUpTestData(cls):\n        cls.c1 = Company.objects.create(name='C1')\n        cls.c2 = Company.objects.create(name='C2')\n        cls.c3 = Company.objects.create(name='C3')\n        cls.e1 = Employee.objects.create(firstname='E1', lastname='E1', company=cls.c1, salary=1000)\n        cls.e2 = Employee.objects.create(firstname='E2', lastname='E2', company=cls.c2, salary=2000)\n        cls.e3 = Employee.objects.create(firstname='E3', lastname='E3', company=cls.c3, salary=3000)\n"], "sample_56": ["    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_library = Error(\n            E003.msg.format(\n                \"'same_library'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n", "    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n", "    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n", "    def test_template_tags_with_same_name_and_library_in_installed_apps(self):\n        with self.settings(TEMPLATES=self.TEMPLATES_LIBRARY_NAME_IN_INSTALLED_APPS):\n            self.assertEqual(\n                check_for_template_tags_with_the_same_name(None), []\n            )\n", "    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_different_library_name = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n"], "sample_88": ["def test_repr_on_oldstyle():\n    \"\"\"\n    Test saferepr() with old-style classes.\n    \"\"\"\n    class Function:\n            return \"<%s>\" % (self.name)\n\n    class OldStyleFunction:\n        name = \"old_style\"\n\n    assert saferepr(OldStyleFunction()) == \"<OldStyleFunction object at 0x{:x}>\".format(id(OldStyleFunction()))\n", "def test_recursive_repr():\n    \"\"\"Test saferepr() with deeply nested objects.\"\"\"\n    class A:\n            self.x = x\n            self.__repr__ = lambda: repr(self.x)\n\n    class B:\n            self.x = x\n\n    a = A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A(A", "def test_reprlib_exception():\n    \"\"\"Test exception handling for librepr.\"\"\"\n\n    class RaisingReprlibException(Exception):\n        __repr__ = None\n        __str__ = None\n\n    assert \"reprlib\" in saferepr(RaisingReprlibException())\n    assert \"reprlib\" in saferepr(BrokenRepr(RaisingReprlibException()))\n", "def test_complex_object():\n    \"\"\"Test saferepr() with complex objects, including iterators and generators.\"\"\"\n    class Generator:\n            self.gen = iter([1, 2, 3])\n\n            raise Exception(\"Test\")\n\n    gen = Generator()\n    assert \"Exception\" in saferepr(gen)\n\n    class Iterator:\n            self.iter = iter([1, 2, 3])\n\n            raise Exception(\"Test\")\n\n    it = Iterator()\n    assert \"Exception\" in saferepr(it)\n\n    class ComplexObject:\n            self.attr = \"value\"\n            self.gen = gen\n            self.it = it\n\n            raise Exception(\"Test\")\n\n    obj = ComplexObject()\n    assert \"Exception\" in saferepr(obj)\n", "def test_reprlib_wrapped_repr():\n    class RaisingOnRepr:\n            raise ValueError(\"...\")\n\n    s = saferepr(RaisingOnRepr())\n    assert \"ValueError\" in s\n    assert s.startswith(\"<[\")\n\n    class ReprLibWrapped:\n            self.ex = ex\n\n    assert saferepr(ReprLibWrapped(ValueError(\"wrapped value\"))) == (\n        \"<[ValueError raised in repr()] ReprLibWrapped object at 0x{:x}>\".format(id(ReprLibWrapped(ValueError(\"wrapped value\"))))\n    )\n"], "sample_74": ["def test_colorbar_update_ticks():\n    fig, ax = plt.subplots()\n    im = ax.pcolormesh(np.random.randn(10, 10))\n    cbar = fig.colorbar(im)\n    loc = FixedLocator(np.arange(10))\n    cbar.ax.yaxis.set_major_locator(loc)\n    cbar.ax.yaxis.set_major_formatter(LogFormatter())\n    assert cbar.formatter is cbar.ax.yaxis.get_major_formatter()\n    assert cbar.locator is cbar.ax.yaxis.get_major_locator()\n    cbar.update_normal()\n    assert cbar.formatter is cbar.ax.yaxis.get_major_formatter()\n    assert cbar.locator is cbar.ax.yaxis.get_major_locator()\n", "def test_colorbar_cax_location():\n    # Test passing `location` and `cax` to `fig.colorbar` together.\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cax = fig.add_axes([0.05, 0.85, 0.9, 0.1])\n    fig.colorbar(im, cax=cax, location='left')\n    assert cax in ax._colorbars\n", "def test_colorbar_location_and_orientation_reorder():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cbar = fig.colorbar(im)\n    with pytest.raises(TypeError, match=\"location and orientation are mutually exclusive\"):\n        cbar.ax.set_position([0.1, 0.2, 0.3, 0.4], panchor=(0.5, 0.6))\n    cbar.ax.set_position([0.1, 0.2, 0.3, 0.4], panchor=(0.5, 0.6), location='left')\n    cbar.ax.set_position([0.1, 0.2, 0.3, 0.4], panchor=(0.5, 0.6), orientation='horizontal')\n    cbar.ax.set_position([0.1, 0.2, 0.3, 0.4], panchor=(0.5, 0.6), location='top', orientation='horizontal')\n    with pytest.raises(TypeError, match=\"location and orientation are mutually exclusive\"):\n        cbar.ax.set_position([0.1, 0.2, 0.3, 0.4], panchor=(0.5, 0.6), location='top', orientation='horizontal')\n", "def test_colorbar_alpha(alpha, expected_alpha):\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.ones((10, 10)))\n    cb = fig.colorbar(pc)\n    cb.set_alpha(alpha)\n    assert cb.alpha == expected_alpha\n\n    im = ax.imshow([[0, 1], [2, 3]], alpha=0.3)\n    cb = fig.colorbar(im)\n    cb.set_alpha(alpha)\n    assert cb.alpha == expected_alpha\n\n    assert isinstance(cb.mappable, cm.ScalarMappable)\n    assert cb.mappable.colorbar is cb\n    assert cb.mappable.colorbar_cid is not None\n", "def test_colorbar_drawedges_rectangle():\n    # Test drawedges with rectangle extensions\n    fig, ax = plt.subplots(figsize=(6, 2))\n    fig.subplots_adjust(bottom=0.3)\n    ax.grid(True)\n\n    cmap = mpl.colormaps[\"viridis\"].resampled(10)\n\n    data = np.linspace(0, 1, 10)\n    norm = BoundaryNorm([0, 0.25, 0.5, 0.75, 1], cmap.N)\n\n    cbar = Colorbar(ax, cmap=cmap, norm=norm, orientation=\"vertical\", drawedges=True,\n                    extendrect=True)\n    assert cbar.drawedges\n    assert isinstance(cbar.dividers, collections.LineCollection)\n    cbar.dividers.set_linestyle('dashed')\n    cbar.dividers.set_edgecolor('red')\n    assert cbar.dividers.get_edgecolor() == mpl.colors.to_rgba('red')\n"], "sample_111": ["def test_lower_bound(metric_name):\n    # all normalized metrics have a lower bound > 0\n    metric = SUPERVISED_METRICS[metric_name]\n    upper_bound_1 = [0, 0, 0, 1, 1, 1]\n    upper_bound_2 = [0, 0, 0, 1, 1, 1]\n    lower_bound_1 = [0, 0, 0, 0, 0, 0]\n    lower_bound_2 = [0, 1, 2, 3, 4, 5]\n    score = np.array([metric(lower_bound_1, lower_bound_2),\n                      metric(lower_bound_2, lower_bound_1)])\n    assert (score > 0).all()\n", "def test_v_measure_mutual_info(metric_name, beta):\n    # Check if V-measure is equal to mutual_info_score\n    y_true = [0, 0, 1, 1]\n    y_pred = [0, 0, 1, 1]\n    if metric_name == \"mutual_info_score\":\n        metric = SUPERVISED_METRICS[metric_name]\n        score_1 = metric(y_true, y_pred)\n    else:\n        metric = SUPERVISED_METRICS[metric_name]\n        score_1 = metric(y_true, y_pred, beta=beta)\n    score_2 = SUPERVISED_METRICS[\"mutual_info_score\"](y_true, y_pred)\n    assert_allclose(score_1, score_2)\n", "def test_no_overlapping_clusters(metric_name):\n    # All clustering metrics should return a score of 0 when\n    # there are no overlapping clusters\n    y_label = np.array([0, 0, 1, 1, 2, 2])\n    y_pred = np.array([0, 0, 1, 1, 2, 3])\n    if metric_name in SUPERVISED_METRICS:\n        metric = SUPERVISED_METRICS[metric_name]\n        assert metric(y_label, y_pred) == 0.0\n    else:\n        metric = UNSUPERVISED_METRICS[metric_name]\n        X = np.random.randint(10, size=(6, 10))\n        assert metric(X, y_label) == 0.0\n\n    # check if the value is exactly 0, not a small floating point value\n    assert metric(y_label, y_pred) != 1e-9\n", "def test_sparse_contingency_eps_error(metric_name):\n    if metric_name in SUPERVISED_METRICS:\n        metric = SUPERVISED_METRICS[metric_name]\n    else:\n        metric = UNSUPERVISED_METRICS[metric_name]\n    with pytest.raises(ValueError):\n        contingency_matrix([0, 0, 0, 1, 2, 2], [0, 1, 2, 2, 1, 1], eps=1.0, sparse=True)\n        metric([0, 0, 0, 1, 2, 2], [0, 1, 2, 2, 1, 1])\n", "def test_contingency_matrix(eps):\n    # Test the contingency_matrix function with different eps values\n    labels_true = np.array([0, 0, 1, 1])\n    labels_pred = np.array([0, 0, 0, 1])\n    contingency = contingency_matrix(labels_true, labels_pred, eps=eps)\n    if eps is not None:\n        assert np.isclose(contingency, 0.9 + eps).all()\n    else:\n        assert contingency.dtype == np.int64\n    assert contingency.shape == (2, 2)\n"], "sample_47": ["def test_detect_soft_applied_custom_user(self):\n    \"\"\"\n    Tests detection of initial migrations already having been applied, when\n    the user model has been customised.\n    \"\"\"\n    state = {\"faked\": None}\n\n        state[\"faked\"] = fake\n    executor = MigrationExecutor(connection, progress_callback=fake_storer)\n    # Were the tables there before?\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_tribble\")\n    # Run it normally\n    self.assertEqual(\n        executor.migration_plan([(\"migrations\", \"0001_initial\")]),\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n        ],\n    )\n    executor.migrate([(\"migrations\", \"0001_initial\")])\n    # Are the tables there now?\n    self.assertTableExists(\"migrations_author\")\n    self.assertTableExists(\"migrations_tribble\")\n    # We shouldn't have faked that one\n    self.assertIs(state[\"faked\"], False)\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Fake-reverse that\n    executor.migrate([(\"migrations\", None)], fake=True)\n    # Are the tables still there?\n    self.assertTableExists(\"migrations_author\")\n    self.assertTableExists(\"migrations_tribble\")\n    # Make sure that was faked\n    self.assertIs(state[\"faked\"], True)\n    # Finally, migrate forwards; this should fake-apply our initial migration\n    executor.loader.build_graph()\n    self.assertEqual(\n        executor.migration_plan([(\"migrations\", \"0001_initial\")]),\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n        ],\n    )\n    # Applying the migration should raise a database level error\n    # because we haven't given the --fake-initial option\n    with self.assertRaises(DatabaseError):\n        executor.migrate([(\"migrations\", \"0001_initial\")])\n    # Reset the faked state\n    state = {\"faked\": None}\n    # Allow faking of initial CreateModel operations\n    executor.migrate([(\"migrations\", \"0001_initial\")], fake_initial=True)\n   ", "def test_migration_state_preserved_across_migrations(self):\n    executor = MigrationExecutor(connection)\n    # Were the tables there before?\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_tribble\")\n\n    # Migrate to the first migration\n    executor.migrate([(\"migrations\", \"0001_initial\")])\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n\n    # Check that the initial state of the first migration is preserved\n    state = executor._create_project_state()\n    self.assertIn(('migrations', 'author'), state.models)\n    self.assertIn(('migrations', 'tribble'), state.models)\n\n    # Migrate to the second migration\n    executor.migrate([(\"migrations\", \"0002_second\")])\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n\n    # Check that the state after the first migration is preserved\n    state = executor._create_project_state(with_applied_migrations=True)\n    self.assertIn(('migrations', 'author'), state.models)\n    self.assertIn(('migrations', 'tribble'), state.models)\n    self.assertIn(('migrations', 'book'), state.models)\n", "    def test_migration_plan_handles_replaced_migration(self):\n        \"\"\"\n        Test migration_plan handles replaced migration correctly.\n        \"\"\"\n        a1_impl = FakeMigration('a1')\n        a1 = ('a', '1')\n        a2_impl = FakeMigration('a2')\n        a2 = ('a', '2')\n        graph = MigrationGraph()\n        graph.add_node(a1, a1_impl)\n        graph.add_node(a2, a2_impl)\n        graph.add_dependency(None, None, a1)\n\n        executor = MigrationExecutor(None)\n        executor.loader = FakeLoader(graph, {\n            a1: a1_impl,\n        })\n\n        # Test that replaced migration is handled correctly\n        plan = executor.migration_plan([(\"a\", \"0001_initial\")])\n        self.assertEqual(plan, [(a1_impl, False)])\n\n        # Test that replacement migration is handled correctly\n        plan = executor.migration_plan([(\"a\", \"0001_squashed_0002\")])\n        self.assertEqual(plan, [(a2_impl, False)])\n\n        # Test that migration plan is built correctly when replacement migration is replaced\n        graph.add_dependency(None, None, a2)\n        executor.loader.replace_migrations = True\n        plan = executor.migration_plan([(\"a\", \"0001_initial\")])\n        self.assertEqual(plan, [(a2_impl, True)])\n", "def test_replaced_migration_marks_replacement_as_applied(self):\n    \"\"\"\n    When a migration is replaced, its replacement should be marked as applied\n    after it has been applied.\n    \"\"\"\n    recorder = MigrationRecorder(connection)\n    # Place the database in a state where the replaced migration is not applied,\n    # but its replacement is.\n    executor = MigrationExecutor(connection)\n    executor.migrate([(\"migrations\", \"0001_squashed_0002\")])\n\n    # Now the replacement should be marked as applied.\n    self.assertIn(\n        (\"migrations\", \"0001_squashed_0002\"),\n        recorder.applied_migrations(),\n    )\n\n    # Now apply the original migrations again, so the replaced migration is\n    # applied.\n    executor.migrate([(\"migrations\", \"0001_squashed_0002\")])\n\n    # The replacement should still be marked as applied.\n    self.assertIn(\n        (\"migrations\", \"0001_squashed_0002\"),\n        recorder.applied_migrations(),\n    )\n", "    def test_plan_no_migrations(self):\n        \"\"\"\n        Empty migration plan should raise a InvalidMigrationPlan error.\n        \"\"\"\n        executor = MigrationExecutor(None)\n        with self.assertRaises(InvalidMigrationPlan):\n            executor.migration_plan([])\n"], "sample_75": ["def test_axesgrid_colorbar_single_right_label_mode_1():\n    fig = plt.figure()\n    grid = AxesGrid(fig, 111, nrows_ncols=(1, 1),\n                    ngrids=1,\n                    label_mode=\"1\",\n                    cbar_location=\"right\",\n                    cbar_mode=\"single\",\n                    )\n\n    Z = 10000 * np.random.rand(10, 10)\n    im = grid[0].imshow(Z, interpolation=\"nearest\", norm=LogNorm())\n\n    grid.cbar_axes[0].colorbar(im)\n", "def test_axesgrid_colorbar_location_top():\n    fig = plt.figure()\n    grid = AxesGrid(fig, 111, nrows_ncols=(1, 1),\n                    ngrids=1, label_mode=\"L\",\n                    cbar_location=\"top\",\n                    cbar_mode=\"single\",\n                    )\n    Z = 10000 * np.random.rand(10, 10)\n    im = grid[0].imshow(Z, interpolation=\"nearest\", norm=LogNorm())\n    grid.cbar_axes[0].colorbar(im)\n", "def test_axesgrid_colorbar_each_label_mode_all():\n    imdata = np.arange(100).reshape((10, 10))\n\n    fig = plt.figure(1, (3, 3))\n    grid = ImageGrid(fig, (1, 1, 1), nrows_ncols=(3, 2), axes_pad=(0.5, 0.3),\n                     cbar_mode=\"each\", cbar_location=\"left\", cbar_size=\"15%\",\n                     label_mode=\"all\")\n    assert grid.get_axes_pad() == (0.5, 0.3)\n    assert grid.get_aspect()  # True by default for ImageGrid\n    for ax, cax in zip(grid, grid.cbar_axes):\n        im = ax.imshow(imdata, interpolation='none')\n        cax.colorbar(im)\n    # Test that all colorbars are labelled\n    for cax in grid.cbar_axes:\n        assert cax.get_label().get_text().get_text() == \"Colorbar\"\n", "def test_anchored_locator_sized_call():\n    fig = plt.figure(figsize=(3, 3))\n    fig1, fig2 = fig.subfigures(nrows=2, ncols=1)\n\n    ax = fig1.subplots()\n    ax.set(aspect=1, xlim=(-15, 15), ylim=(-20, 5))\n    ax.set(xticks=[], yticks=[])\n\n    Z = cbook.get_sample_data(\"axes_grid/bivariate_normal.npy\")\n    extent = (-3, 4, -4, 3)\n\n    axins = zoomed_inset_axes(ax, zoom=2, loc=\"upper left\", width=1.5, height=1.5)\n    axins.set(xticks=[], yticks=[])\n    axins.set(xlim=(-5, 5), ylim=(-10, 0))\n    axins.imshow(Z, extent=extent, origin=\"lower\")\n", "def test_imagegrid_cbar_mode_each():\n    arr = np.arange(16).reshape((4, 4))\n\n    fig = plt.figure(figsize=(18, 9))\n\n    positions = (241, 242, 243, 244, 245, 246, 247, 248)\n    directions = ['row']*4 + ['column']*4\n    cbar_locations = ['left', 'right', 'top', 'bottom']*2\n\n    for position, direction, location in zip(\n            positions, directions, cbar_locations):\n        grid = ImageGrid(fig, position,\n                         nrows_ncols=(2, 2),\n                         direction=direction,\n                         cbar_location=location,\n                         cbar_size='20%',\n                         cbar_mode='each')\n        ax1, ax2, ax3, ax4 = grid\n\n        ax1.imshow(arr, cmap='nipy_spectral')\n        ax2.imshow(arr.T, cmap='hot')\n        ax3.imshow(np.hypot(arr, arr.T), cmap='jet')\n        ax4.imshow(np.arctan2(arr, arr.T), cmap='hsv')\n\n        # In each row/column, the colorbars must be the ones from the axes on\n        # which they are displayed.\n        for ax, cax, i in zip(grid, grid.cbar_axes, range(4)):\n            assert cax is ax.cax\n            cb = ax.cax.colorbar(ax.images[0])\n            assert cb is ax.cax.colorbar\n"], "sample_147": ["def test_Derivative_kind_Matrix():\n    A = MatrixSymbol('A', 2,2)\n    assert Derivative(A*A, comm_x).kind is MatrixKind(NumberKind)\n    assert Derivative(A*A, noncomm_x).kind is MatrixKind(UndefinedKind)\n", "def test_MatMul_kind():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    assert MatMul(A, B).kind is MatrixKind(NumberKind)\n    assert MatMul(A, B, evaluate=False).kind is MatrixKind(NumberKind)\n    assert MatMul(A, noncomm_x).kind is MatrixKind(UndefinedKind)\n    assert MatMul(A, noncomm_x, evaluate=False).kind is MatrixKind(UndefinedKind)\n", "compilation error", "def test_Mul_cancelled_terms():\n    A = MatrixSymbol('A', 2,2)\n    assert Mul(2, 3, 0, evaluate=False).kind is NumberKind\n    assert Mul(2, 0, 3, evaluate=False).kind is NumberKind\n    assert Mul(0, 3, 2, evaluate=False).kind is NumberKind\n    assert Mul(0, 0, 3, evaluate=False).kind is NumberKind\n    assert Mul(A, 0, 3, evaluate=False).kind is MatrixKind(NumberKind)\n    assert Mul(0, A, 3, evaluate=False).kind is MatrixKind(NumberKind)\n    assert Mul(A, A, 0, evaluate=False).kind is MatrixKind(UndefinedKind)\n", "def test_Mul_einsum():\n    A = MatrixSymbol('A', 2,2)\n    B = MatrixSymbol('B', 2,2)\n    C = MatrixSymbol('C', 2,2)\n    assert Mul(A,B,C).kind is MatrixKind(NumberKind)\n"], "sample_115": ["    def transform(self, X, y=None):\n        return X\n", "def test_set_output_mixin_non_configured():\n    \"\"\"Check that _SetOutputMixin does not have set_output without\n    auto_wrap_output_keys.\"\"\"\n    class NoSetOutputEstimator:\n        pass\n\n    assert not hasattr(NoSetOutputEstimator, \"set_output\")\n", "def test_set_output_mixin_init_subclass_auto_wrap_output_keys():\n    \"\"\"Check that init_subclass respects auto_wrap_output_keys in the case of multiple inheritance.\"\"\"\n\n    class Base(_SetOutputMixin, auto_wrap_output_keys=(\"fit_transform\",)):\n            return X\n\n    class A(Base, auto_wrap_output_keys=(\"transform\",)):\n        pass\n\n    class Estimator(A):\n        pass\n\n    assert Estimator._sklearn_auto_wrap_output_keys == {\"fit_transform\", \"transform\"}\n", "def test__wrap_data_with_container():\n    \"\"\"Check that _wrap_data_with_container preserves sparse data.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    X_csr = csr_matrix(X)\n    X_csc = X_csr.T.tocsr()\n\n    est = EstimatorWithSetOutput()\n    est.set_output(transform=\"default\")\n\n    X_default_wrapped = _wrap_data_with_container(\"transform\", X, X, est)\n    assert_array_equal(X_default_wrapped, X)\n\n    X_pandas_wrapped = _wrap_data_with_container(\n        \"transform\", X_csr.toarray(), X, est\n    )\n    assert isinstance(X_pandas_wrapped, np.ndarray)\n\n    X_pandas_wrapped = _wrap_data_with_container(\n        \"transform\", X_csc.toarray(), X, est\n    )\n    assert isinstance(X_pandas_wrapped, np.ndarray)\n", "def test_set_output_mixin_custom_mixin_config():\n    \"\"\"Check that auto_wrap_output_keys tuple is handled correctly by init_subclass.\"\"\"\n    class Mixin1(_SetOutputMixin, auto_wrap_output_keys=(\"transform\",)):\n            return X\n\n    class Mixin2(_SetOutputMixin, auto_wrap_output_keys=(\"fit_transform\",)):\n            return X, X\n\n    class Estimator(Mixin1, Mixin2):\n            return input_features\n\n    est = Estimator()\n    assert hasattr(est, \"set_output\")\n    assert hasattr(est, \"transform\")\n    assert hasattr(est, \"fit_transform\")\n    assert \"set_output\" in dir(Estimator.__mro__[-1])\n"], "sample_126": ["def test_Floor_Ceiling():\n    # test floor and ceiling methods\n    assert Float(3.7).floor() == 3\n    assert Float(3.7).ceiling() == 4\n    assert Float(0.7).floor() == 0\n    assert Float(0.7).ceiling() == 1\n    assert Float(-0.7).floor() == -1\n    assert Float(-0.7).ceiling() == 0\n\n    # test floor and ceiling with negative numbers\n    assert Float(-3.7).floor() == -4\n    assert Float(-3.7).ceiling() == -3\n    assert Float(-0.7).floor() == -1\n    assert Float(-0.7).ceiling() == 0\n    assert Float(0.7).floor() == 0\n    assert Float(0.7).ceiling() == 1\n\n    # test floor and ceiling with numbers greater than 1\n    assert Float(10.7).floor() == 10\n    assert Float(10.7).ceiling() == 11\n    assert Float(-10.7).floor() == -11\n    assert Float(-10.7).ceiling() == -10\n", "def test_integer_nthroot():\n    p, r = integer_nthroot(1000000000000000000, 100)\n    assert p % (10**10) == 0\n    assert not r\n    p, r = integer_nthroot(int(fibonacci(10000)), 100)\n    assert p % (10**10) == 5322420655\n    assert not r\n    p, r = integer_nthroot(2**61, 2)\n    assert type(p) is int\n    p, r = integer_nthroot(2**64 + 1, 2)\n    assert type(p) is int\n    p, r = integer_nthroot(2**64 - 1, 2)\n    assert type(p) is int\n", "def test_igcdex_integer_arguments():\n    assert igcdex(2, 3) == (-1, 1, 1)\n    assert igcdex(10, 12) == (-1, 1, 2)\n    assert igcdex(100, 2004) == (-20, 1, 4)\n    assert igcdex(0, 0) == (0, 0, 0)\n    assert igcdex(1, 1) == (1, 0, 1)\n    assert igcdex(0, 1) == (1, 0, 1)\n    assert igcdex(1, 0) == (0, 1, 1)\n    assert igcdex(-1, 1) == (1, 0, 1)\n    assert igcdex(1, -1) == (1, 0, 1)\n    assert igcdex(-1, -1) == (1, 0, 1)\n    assert igcdex(-2, 2) == (2, -1, 1)\n    assert igcdex(2, -2) == (2, -1, 1)\n    assert igcdex(-2, -2) == (2, -1, 1)\n    assert igcdex(0, 2) == (2, 0, 1)\n    assert igcdex(2, 0) == (2, 0, 1)\n    assert igcdex(-2, 0) == (2, 0, 1)\n    assert igcdex(0, -2) == (2, 0, 1)\n    assert igcdex(-3, 3) == (3, -1, 1)\n    assert igcdex(3, -3) == (3, -1, 1)\n    assert igcdex(-3, -3) == (3, -1, 1)\n    assert igcdex(0, 3) == (3, 0, 1)\n    assert igcdex(3, 0) == (3, 0, 1)\n    assert igcdex(-3, 0) == (3, 0, 1)\n    assert igcdex(0, -3) == (3, 0", "def test_Mul_with_Infinity():\n    from sympy import Mul, oo, pi, I, Rational, Integer\n\n    assert Mul.__class__(oo, oo) is oo\n    assert Mul.__class__(oo, pi) == oo\n    assert Mul.__class__(oo, I) == oo\n    assert Mul.__class__(oo, Rational(3)) == oo\n    assert Mul.__class__(oo, Integer(5)) == oo\n\n    assert Mul.__class__(oo, oo, pi) is oo\n    assert Mul.__class__(oo, oo, I) is oo\n    assert Mul.__class__(oo, oo, Rational(3)) is oo\n    assert Mul.__class__(oo, oo, Integer(5)) is oo\n\n    assert Mul.__class__(pi, oo) is oo\n    assert Mul.__class__(I, oo) is oo\n    assert Mul.__class__(Rational(3), oo) is oo\n    assert Mul.__class__(Integer(5), oo) is oo\n\n    assert Mul.__class__(pi, oo, oo) is oo\n    assert Mul.__class__(I, oo, oo) is oo\n    assert Mul.__class__(Rational(3), oo, oo) is oo\n    assert Mul.__class__(Integer(5), oo, oo) is oo\n\n    assert Mul.__class__(I, pi) == I*pi\n    assert Mul.__class__(I, Rational(3)) == I*Rational(3)\n    assert Mul.__class__(I, Integer(5)) == I*Integer(5)\n\n    assert Mul.__class__(I, pi, oo) is oo\n    assert Mul.__class__(I, Rational(3), oo) is oo\n    assert Mul.__class__(I, Integer(5), oo) is oo\n\n    assert Mul.__class__(I, pi, oo, oo) is oo\n    assert Mul.__class__(I, Rational(3), oo, oo) is oo\n    assert Mul.__class__(I, Integer(5), oo, oo) is oo\n\n    assert Mul.__class__(Rational(3), pi) == pi*Rational(3)\n    assert Mul.__class__(Rational(3), I) == I*Rational(3)\n    assert Mul.__class__(Rational(3), Integer(5)) == Integer(15)\n\n    assert Mul.__class__(Rational(3), pi,", "def test_Float_approximation():\n    # See issue 14128\n    from sympy import Float, pi, oo\n    assert Float(pi).approximation(Number).is_finite is None\n    assert Float(pi).approximation(Integer).is_finite is False\n    assert Float(pi).approximation(Rational).is_finite is None\n    assert Float(pi).approximation(Float).is_finite is True\n    assert Float(pi).approximation(Integer, max_precision=100).is_finite is True\n    assert Float(pi).approximation(Integer, max_denominator=1000000).is_finite is False\n    assert Float(pi).approximation(Rational, max_denominator=1000000).is_finite is None\n"], "sample_138": ["def test_BlockMatrix_equality():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', n, m)\n    X = BlockMatrix([[A, B]])\n    Y = BlockMatrix([[A, B]])\n\n    assert X.equals(Y)\n\n    Z = BlockMatrix([[A, C]])\n    assert X.equals(Z) == False\n\n    W = BlockMatrix([[B, A]])\n    assert X.equals(W) == False\n", "def test_BlockMatrix_determinant_2x2():\n    A, B, C, D = [MatrixSymbol(s, 2, 2) for s in 'ABCD']\n    X = BlockMatrix([[A, B], [C, D]])\n    from sympy import assuming, Q\n\n    assert det(X) == det(A)*det(D - C*A.I*B)\n    with assuming(Q.invertible(A)):\n        assert det(X) == det(A)*det(D - C*A.I*B)\n\n    assert det(X) != det(B)\n    assert det(X) != det(C)\n", "def test_BlockMatrix_properties():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n\n    assert X.is_square == (X.shape[0] == X.shape[1])\n\n    assert X.is_symmetric == (X == X.T)\n\n    assert X.is_skew_symmetric == (X == -X.T)\n\n    assert X.is_upper_triangular == (X < X.T)\n\n    assert X.is_lower_triangular == (X > X.T)\n\n    assert X.is_diagonal == (X == X.diag())\n\n    assert X.is_zero == (X == ZeroMatrix(X.shape))\n\n    assert X.is_Identity == (X == Identity(X.shape[0]))\n\n    assert X.is_invertible == (not X.is_zero)\n", "def test_blockcut_slicing():\n    A = MatrixSymbol('A', 3, 3)\n    B = blockcut(A, (1, 2), (1, 2))\n    assert B == BlockMatrix([[A[:1, :1], A[:1, 1:2]],\n                             [A[1:2, :1], A[1:2, 1:2]]])\n\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (0, 2), (0, 2))\n    assert M == ImmutableMatrix(B)\n\n    B = blockcut(M, (3, 4), (2, 2))\n    assert ImmutableMatrix(B.blocks[0, 1]) == ImmutableMatrix([[12, 13]])\n\n    B = blockcut(M, (1, 3), (0, 1))\n    assert ImmutableMatrix(B.blocks[0, 0]).shape == (2, 1)\n\n    B = blockcut(M, (1, 3), (1, 3))\n    assert ImmutableMatrix(B.blocks[0, 1]).shape == (2, 3)\n\n    B = blockcut(M, (0, 0), (0, 0))\n    assert ImmutableMatrix(B.blocks[0, 0]).shape == (0, 0)\n\n    B = blockcut(M, (4, 4), (4, 4))\n    assert ImmutableMatrix(B.blocks[0, 0]).shape == (0, 0)\n", "def test_BlockMatrix_BlockDiagMatrix_equality():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    C = MatrixSymbol('C', n, n)\n    X = BlockMatrix([[A, ZeroMatrix(n, n)], [ZeroMatrix(n, n), B]])\n    Y = BlockDiagMatrix(A, C)\n    assert X.structurally_equal(Y)\n    assert not X.equals(Y)\n"], "sample_117": ["def test_restify_type_hints_NewType():\n    MyStr = NewType('MyStr', str)\n    MyTuple = NewType('MyTuple', Tuple[str, str])\n    assert restify(MyStr) == \":class:`MyStr`\"\n    assert restify(MyTuple) == \":class:`MyTuple`\\\\ [:class:`Tuple`\\\\ [:class:`str`, :class:`str`]]\"\n", "def test_restify_type_hints_NewType():\n    MyStr = NewType(\"MyStr\", str)\n    MyInt = NewType(\"MyInt\", int)\n\n    assert restify(MyStr) == \":class:`MyStr`\"\n    assert restify(MyInt) == \":class:`MyInt`\"\n    assert restify(NewType(\"int\", int)) == \":class:`int`\"\n", "def test_stringify_type_hints_ellipsis():\n    assert stringify(Ellipsis) == \"...\"\n    assert stringify(Tuple[int, ...]) == \"Tuple[int, ...]\"\n    assert stringify(Union[int, ...]) == \"Union[int, ...]\"\n    assert stringify(Callable[[int, ...], int]) == \"Callable[[int, ...], int]\"\n\n    # Test that restify handles ellipsis correctly\n    assert restify(Ellipsis) == \":obj:`...`\"\n    assert restify(Tuple[int, ...]) == \":class:`Tuple`\\\\ [:class:`int`, ...]\"\n    assert restify(Union[int, ...]) == \":obj:`Union`\\\\ [:class:`int`, ...]\"\n    assert restify(Callable[[int, ...], int]) == \":class:`Callable`\\\\ [[:class:`int`, ...], :class:`int`]\"\n", "def test_stringify_type_hints_forward_ref():\n    \"\"\"Test the handling of forward references.\"\"\"\n    from typing import ForwardRef  # type: ignore\n\n    forward_ref = ForwardRef(\"MyForwardRef\")\n    assert stringify(forward_ref) == \"MyForwardRef\"\n    assert stringify(ForwardRef(\"MyForwardRef\")) == \"MyForwardRef\"\n", "def test_stringify_type_hints_Type():\n    assert stringify(Type) == \"Type\"\n    assert stringify(Any) == \"Any\"\n    assert stringify(Union) == \"Union\"\n    assert stringify(Dict) == \"Dict\"\n    assert stringify(List) == \"List\"\n    assert stringify(Tuple) == \"Tuple\"\n    assert stringify(GenericMeta) == \"GenericMeta\"\n    assert stringify(TypeVar) == \"TypeVar\"\n    assert stringify(ForwardRef) == \"ForwardRef\"\n    assert stringify(NewType) == \"NewType\"\n    assert stringify(UnionMeta) == \"UnionMeta\"\n    assert stringify(CallableMeta) == \"CallableMeta\"\n    assert stringify(TupleMeta) == \"TupleMeta\"\n    assert stringify(SpecialForm) == \"SpecialForm\"\n"], "sample_63": ["    def test_link_to_password_reset_in_helptext_via_to_field(self):\n        user = User.objects.get(username=\"testclient\")\n        form = AdminPasswordChangeForm(user)\n        password_help_text = form.fields[\"password1\"].help_text\n        matches = re.search('<a href=\"(.*?)\">', password_help_text)\n\n        # URL to UserChangeForm in admin via to_field (instead of pk).\n        admin_user_change_url = reverse(\n            f\"admin:{user._meta.app_label}_{user._meta.model_name}_change\",\n            args=(user.username,),\n        )\n        joined_url = urllib.parse.urljoin(admin_user_change_url, matches.group(1))\n\n        pw_change_url = reverse(\n            f\"admin:{user._meta.app_label}_{user._meta.model_name}_password_change\",\n            args=(user.pk,),\n        )\n        self.assertEqual(joined_url, pw_change_url)\n", "    def test_bug_17944_render_with_unusable_password(self):\n        \"\"\"\n        Rendering the widget with an unusable password\n        mustn't raise an exception.\n        \"\"\"\n        widget = ReadOnlyPasswordHashWidget()\n        value = UNUSABLE_PASSWORD_PREFIX + \"foo\"\n        self.assertHTMLEqual(\n            widget.render(\"name\", value, {\"id\": \"id_password\"}),\n            '<div id=\"id_password\">'\n            \"    <strong>No password set.</strong>\"\n            \"</div>\",\n        )\n", "    def test_render_with_summary(self):\n        # Test that the widget renders when the password is invalid or unusable.\n        widget = ReadOnlyPasswordHashWidget()\n        value = (\n            \"pbkdf2_sha256$100000$a6Pucb1qSFcD$WmCkn9Hqidj48NVe5x0FEM6A9YiOqQcl/83m2Z5u\"\n            \"dm0=\"\n        )\n        # Invalid password.\n        self.assertHTMLEqual(\n            widget.render(\"name\", \"invalid\", {\"id\": \"id_password\"}),\n            '<div id=\"id_password\">'\n            \"    <strong>algorithm</strong>: <bdi>unknown</bdi>\"\n            \"    <strong>iterations</strong>: <bdi>0</bdi>\"\n            \"    <strong>salt</strong>: <bdi>a6Pucb******</bdi>\"\n            \"    <strong>hash</strong>: \"\n            \"       <bdi>WmCkn9**************************************</bdi>\"\n            \"</div>\",\n        )\n        # Unusable password.\n        self.assertHTMLEqual(\n            widget.render(\"name\", UNUSABLE_PASSWORD_PREFIX + \"invalid\", {\"id\": \"id_password\"}),\n            '<div id=\"id_password\">'\n            \"    <strong>algorithm</strong>: <bdi>unknown</bdi>\"\n            \"    <strong>iterations</strong>: <bdi>0</bdi>\"\n            \"    <strong>salt</strong>: <bdi>a6Pucb******</bdi>\"\n            \"    <strong>hash</strong>: \"\n            \"       <bdi>WmCkn9**************************************</bdi>\"\n            \"</div>\",\n        )\n", "    def test_readonly_field_no_value(self):\n        \"\"\"Rendering the widget with no value set mustn't raise an exception.\"\"\"\n        widget = ReadOnlyPasswordHashWidget()\n        html = widget.render(name=\"password\", value=None, attrs={\"id\": \"id_password\"})\n        self.assertIn(_(\"No password set.\"), html)\n", "    def test_no_change(self):\n        # When the password is not changed, the save method should not\n        # call the password_changed function.\n        user = User.objects.get(username=\"testclient\")\n        data = {\"password1\": \"test123\", \"password2\": \"test123\"}\n        form = AdminPasswordChangeForm(user, data)\n        self.assertTrue(form.is_valid())\n        form.save(commit=False)\n        self.assertEqual(password_changed.call_count, 0)\n        form.save()\n        self.assertEqual(password_changed.call_count, 0)\n"], "sample_31": ["def test_shell_with_bpython_not_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import bpython interface.\"):\n        call_command('shell', interface='bpython')\n", "def test_shell_with_bpython_not_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import bpython interface.\"):\n        call_command('shell', interface='bpython')\n", "def test_python_startup_script(self, select):\n    with captured_stdout() as stdout:\n        with captured_stdin() as stdin:\n            stdin.write('print(\"startup script\")')\n            stdin.seek(0)\n            os.environ['PYTHONSTARTUP'] = 'python_startup.py'\n            call_command('shell')\n    self.assertEqual(stdout.getvalue().strip(), 'startup script')\n", "def test_no_startup_option(self, select):\n    with captured_stdout() as stdout:\n        with captured_stdin() as stdin:\n            stdin.write('import os; print(os.environ.get(\"PYTHONSTARTUP\"))\\n')\n            stdin.seek(0)\n            call_command('shell', no_startup=True)\n    self.assertIsNone(stdout.getvalue().strip())\n", "def test_shell_with_bpython_not_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import bpython interface.\"):\n        call_command('shell', interface='bpython')\n"], "sample_81": ["def test_pylint_disable_clause(self) -> None:\n    code = \"\"\"a = 1\n            # pylint: disable=FIXME\n            # FIXME\n            \"\"\"\n    with self.assertNoMessages():\n        self.checker.process_tokens(_tokenize_str(code))\n", "def test_disable_with_pylint_option(self) -> None:\n    code = \"\"\"a = 1\n            # pylint: disable=fixme\n            # FIXME\n            \"\"\"\n    with self.assertNoMessages():\n        self.checker.process_tokens(_tokenize_str(code))\n", "    def test_encoding_ascii(self) -> None:\n        code = \"\"\"a = 1\n                # FIXME\n                \"\"\"\n        with self.assertNoMessages():\n            self.checker.process_module(nodes.Module(\"<module>\", file_encoding=\"ascii\"))\n", "def test_pragma_disable(self) -> None:\n    code = \"\"\"a = 1\n                # pylint: disable=FIXME\n                # FIXME\n                \"\"\"\n    with self.assertNoMessages():\n        self.checker.process_tokens(_tokenize_str(code))\n", "    def test_encoding_warning(self) -> None:\n        code = \"a = 1\\n# coding: utf-8\"\n        with self.assertAddsMessages(\n            MessageTest(msg_id=\"syntax-error\", line=2, args=\"Cannot decode using encoding 'utf-8', bad encoding\")\n        ):\n            self.checker.process_module(self._make_module(code))\n"], "sample_114": ["def test_check_classification_targets_multilabel_sequences():\n    for example in MULTILABEL_SEQUENCES:\n        with pytest.raises(ValueError):\n            check_classification_targets(example)\n", "def test_ovr_decision_function():\n    # Test the _ovr_decision_function function\n    # Test with 3 classes\n    y = np.array([[0, 1, 0], [1, 0, 1]])\n    confidences = np.array([[0.5, 0.5, 0.5], [0.5, 0.5, 0.5]])\n    n_classes = 3\n    out = _ovr_decision_function(y, confidences, n_classes)\n    assert out.shape == (2, 3)\n    assert np.allclose(out[:, 0] == 0.5, True)\n    assert np.allclose(out[:, 1] == 0.5, True)\n    assert np.allclose(out[:, 2] == 0.5, True)\n\n    # Test with 4 classes\n    y = np.array([[0, 1, 0, 0], [1, 0, 1, 0]])\n    confidences = np.array([[0.2, 0.3, 0.5, 0.0], [0.0, 0.5, 0.3, 0.2]])\n    n_classes = 4\n    out = _ovr_decision_function(y, confidences, n_classes)\n    assert out.shape == (2, 4)\n\n    # Test with multiple classes and multiple samples\n    y = np.array([[0, 1, 0, 1, 0], [1, 0, 1, 0, 1]])\n    confidences = np.array(\n        [\n            [0.1, 0.2, 0.3, 0.4, 0.5],\n            [0.5, 0.4, 0.3, 0.2, 0.1],\n        ]\n    )\n    n_classes = 4\n    out = _ovr_decision_function(y, confidences, n_classes)\n    assert out.shape == (2, 4)\n\n    # Test with different tie-breaking\n    y = np.array([[0, 1, 0, 1, 0], [1, 0, 1, 0, 1]])\n    confidences = np.array(\n        [\n            [0.1, 0.2, 0.3, ", "def test_ovr_decision_function():\n    # Check that _ovr_decision_function works with binary classifier predictions\n    # and confidences.\n    predictions = np.array([[0, 1], [1, 0]])\n    confidences = np.array([[0.9, 0.1], [0.1, 0.9]])\n    n_classes = 2\n    expected = np.array([[0.7, -0.2]])\n    assert_array_almost_equal(_ovr_decision_function(predictions, confidences, n_classes),\n                             expected)\n\n    # Check that _ovr_decision_function works with multiclass classifier predictions\n    # and confidences.\n    predictions = np.array([[0, 1, 0], [1, 0, 1]])\n    confidences = np.array([[0.9, 0.05, 0.05], [0.1, 0.7, 0.2]])\n    n_classes = 3\n    expected = np.array([[0.5, -0.3, 0.1]])\n    assert_array_almost_equal(_ovr_decision_function(predictions, confidences, n_classes),\n                             expected)\n\n    # Check that _ovr_decision_function raises an error when number of classes\n    # is not correct.\n    with pytest.raises(ValueError):\n        _ovr_decision_function(predictions, confidences, 1)\n\n    # Check that _ovr_decision_function raises an error when number of classifiers\n    # is not correct.\n    predictions = np.array([[0, 1, 0], [1, 0, 1]])\n    confidences = np.array([[0.9, 0.05, 0.05, 0.05], [0.1, 0.7, 0.2, 0.05]])\n    n_classes = 3\n    with pytest.raises(ValueError):\n        _ovr_decision_function(predictions, confidences, n_classes)\n\n    # Check that _ovr_decision_function works with empty predictions.\n    predictions = np.array([[0, 1], []])\n    confidences = np.array([[0.9, 0.1], [0.1, 0.9]])\n    n_classes = 2\n    expected = np.array([])\n    assert_array_almost_equal(_ovr_decision_function(predictions, confidences, n_classes),\n                             expected)\n\n    # Check that _ovr_decision_function works with 1d predictions.\n   ", "def test_ovr_decision_function():\n    \"\"\"Test the _ovr_decision_function function.\"\"\"\n    X = np.array([[0, 1], [0, 1], [1, 1]])\n    confidences = np.array([[0.3, 0.7], [0.7, 0.3], [0.4, 0.6]])\n    predictions = np.array([[0, 1], [0, 1], [1, 0]])\n    n_classes = 2\n\n    result = _ovr_decision_function(predictions, confidences, n_classes)\n    assert result.shape == (3, 2)\n    assert np.allclose(result[:, 0], [-0.4, 0.5, 0.6])\n\n    # Check that a zero confidence gives a lower decision value\n    confidences[0, 0] = 0.0\n    result = _ovr_decision_function(predictions, confidences, n_classes)\n    assert np.allclose(result[0, 0], -1.0)\n\n    # Check that a confidence of 1 gives a higher decision value\n    confidences[0, 1] = 1.0\n    result = _ovr_decision_function(predictions, confidences, n_classes)\n    assert np.allclose(result[0, 0], 0.5)\n\n    # Check that a zero confidence gives a lower decision value\n    confidences[1, 0] = 0.0\n    result = _ovr_decision_function(predictions, confidences, n_classes)\n    assert np.allclose(result[1, 0], 0.4)\n", "def test_ovr_decision_function():\n    # Smoke test for all supported format\n    for group, group_examples in EXAMPLES.items():\n        if group == \"binary\":\n            binary_example = group_examples[0]\n            for example in group_examples:\n                if isinstance(example, (csr_matrix, csc_matrix)):\n                    example = example.toarray()\n                elif not hasattr(example, \"__array__\") and not isinstance(example, list):\n                    continue\n                try:\n                    _ovr_decision_function(\n                        np.array(\n                            [\n                                [0, 1, 0, 1, 0, 0, 1, 1, 1, 1],\n                                [1, 1, 1, 0, 0, 0, 0, 1, 1, 0],\n                            ]\n                        ),\n                        np.array(\n                            [\n                                [1.0, -1.0, 1.0, 1.0, 0.0, 1.0, -1.0, -1.0, 1.0, 1.0],\n                                [-1.0, 1.0, -1.0, -1.0, 0.0, 1.0, -1.0, 1.0, -1.0, 1.0],\n                            ]\n                        ),\n                        3,\n                    )\n                except (IndexError, ValueError) as e:\n                    if \"expected n_classifiers to be\" not in str(e):\n                        raise\n        elif group == \"multiclass\":\n            multiclass_example = group_examples[0]\n            for example in group_examples:\n                if isinstance(example, (csr_matrix, csc_matrix)):\n                    example = example.toarray()\n                elif not hasattr(example, \"__array__\") and not isinstance(example, list):\n                    continue\n                try:\n                    _ovr_decision_function(\n                        np.array(\n                            [\n                                [0, 1, 2, 2, 1, 4, 2, 4, 4, 4],\n                                [1, 0, 2, 2, 1, 4, 2, 4, 4, 4],\n                            ]\n                        ),\n                        np.array(\n                            [\n                                [1.0, -1.0, -1.0, 1.0, 1.0, -1.0,"], "sample_130": ["def test_tensorflow_shape():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    x = tensorflow.Variable(1.0, shape=(3, 4), dtype=tensorflow.float32)\n    s = tensorflow.Session()\n    if V(tensorflow.__version__) < '1.0':\n        s.run(tensorflow.initialize_all_variables())\n    else:\n        s.run(tensorflow.global_variables_initializer())\n    assert lambdify(x, x).eval(session=s).shape == (3, 4)\n", "def test_special_printers_numexpr():\n    if not numexpr:\n        skip(\"numexpr not installed.\")\n    if not numpy:\n        skip(\"numpy not installed.\")\n\n    # if translation/printing is done incorrectly then evaluating\n    # a lambdified numexpr expression will throw an exception\n    from sympy.printing.lambdarepr import NumExprPrinter\n    from sympy import S\n\n    blacklist = ('where', 'complex', 'contains')\n    arg_tuple = (x, y, z) # some functions take more than one argument\n    for sym in NumExprPrinter._numexpr_functions.keys():\n        if sym in blacklist:\n            continue\n        ssym = S(sym)\n        if hasattr(ssym, '_nargs'):\n            nargs = ssym._nargs[0]\n        else:\n            nargs = 1\n        args = arg_tuple[:nargs]\n        f = lambdify(args, ssym(*args), modules='numexpr')\n        assert f(*(1, )*nargs) is not None\n\n    # Test custom NumExpr printer\n    class CustomNumExprPrinter(NumExprPrinter):\n            return \"my_sin\"\n\n    f = lambdify(x, sin(x), modules='numexpr', printer=CustomNumExprPrinter())\n    assert f(1) == \"my_sin(1)\"\n", "def test_issue_13228():\n    if not numexpr:\n        skip(\"numexpr not installed.\")\n    x = sympy.Symbol('x')\n    f = lambdify(x, sympy.sqrt(x**2), modules=['numexpr'])\n    arr = numpy.array([1, 2, 3])\n    assert numpy.allclose(f(arr), numpy.array([1., 1.41421356, 1.73205081]))\n", "def test_lambdify_user_functions_with_args():\n    if not numexpr:\n        skip(\"numexpr not installed.\")\n\n    # Test that user-defined functions with multiple arguments are handled\n    # correctly. Specifically, that the arguments are passed correctly and\n    # that the user-defined function's implementation is used.\n    uf = type('uf', (Function, ),\n              {'eval' : classmethod(lambda x, y : y**2 + x**2 + 2*x*y)})\n    func = lambdify((x, y), 1 - uf(x, y), modules='numexpr')\n    assert func(1, 2) == 0\n    assert func(3, 4) == 0\n", "def test_dummify_issue_13239():\n    # Test for issue 13239. If an argument is a Matrix, it should be dummified.\n    # This can cause a crash if you use the function before all variables have been\n    # assigned. This test is not 100% coverage because it is hard to cover all\n    # cases where this might fail.\n    from sympy import Matrix\n    A = Matrix([[1, 2], [3, 4]])\n    f = lambdify(A, A, 'sympy', dummify=True)\n    assert f() == A\n    raises(TypeError, lambda: f(1))\n"], "sample_131": ["def test_Abs():\n    assert mcode(abs(x)) == \"Abs[x]\"\n    assert mcode(abs(x - 1)) == \"Abs[x - 1]\"\n    assert mcode(abs(x + y)) == \"Abs[x + y]\"\n    assert mcode(abs(x + y) + z) == \"Abs[x + y] + z\"\n    assert mcode(x - abs(x)) == \"x - Abs[x]\"\n", "def test_MaxMin():\n    assert mcode(Max(x, y)) == \"Max[x, y]\"\n    assert mcode(Min(x, y)) == \"Min[x, y]\"\n    assert mcode(Max(x, Min(y, z))) == \"Max[x, Min[y, z]]\"\n    assert mcode(Min(x, Max(y, z))) == \"Min[x, Max[y, z]]\"\n    assert mcode(Max(x**2, y**2)) == \"Max[x^2, y^2]\"\n    assert mcode(Max(f(x), y)) == \"Max[f[x], y]\"\n    assert mcode(Min(x, f(x))) == \"Min[x, f[x]]\"\n", "def test_Tuple():\n    assert mcode(Tuple(1, 2, 3)) == \"{1, 2, 3}\"\n    assert mcode(Tuple(x, y, z)) == \"{x, y, z}\"\n    assert mcode(Tuple(1, 2, (3, 4))) == \"{1, 2, {3, 4}}\"\n    assert mcode(Tuple(x, y, (z, w))) == \"{x, y, {z, w}}\"\n    assert mcode(Tuple(x, y, (z, w, v))) == \"{x, y, {z, w, v}}\"\n    assert mcode(Tuple(1, 2, 3, 4)) == \"{1, 2, 3, 4}\"\n    assert mcode(Tuple()) == \"{}\"\n    assert mcode(Tuple()) == \"{}\"\n", "def test_Csch():\n    assert mcode(1 / sinh(x)) == \"1/Sinh[x]\"\n    assert mcode(1 / sinh(x**2)) == \"1/Sinh[x**2]\"\n    assert mcode(csch(3)) == \"1/Sinh[3]\"\n    assert mcode(acsc(3)) == \"ArcSinh[3]\"\n    assert mcode(acsc(x**2)) == \"ArcSinh[x**2]\"\n", "def test_PiExpansion():\n    from sympy import exp, sin, cos, tan, tanh, sech, csch, asin, acos, atan\n    assert mcode(exp(x).series(x).removeO()) == \"E^(x)\"\n    assert mcode(sin(x).series(x).removeO()) == \"x - x^3/6 + x^5/120\"\n    assert mcode(cos(x).series(x).removeO()) == \"1 - x^2/2 + x^4/24\"\n    assert mcode(tan(x).series(x).removeO()) == \"x + x^3/3 + x^5/5 + x^7/63\"\n    assert mcode(tanh(x).series(x).removeO()) == \"x + x^3/3 + x^5/5 + x^7/63\"\n    assert mcode(sech(x).series(x).removeO()) == \"1 - x^2/2 + 7*x^4/24 - 31*x^6/720\"\n    assert mcode(csch(x).series(x).removeO()) == \"1/x + 1/6*x + 1/40*x^3 + 1/336*x^5\"\n    assert mcode(asin(x).series(x).removeO()) == \"x + x^3/6 + 3*x^5/40 + 15*x^7/336\"\n    assert mcode(acos(x).series(x).removeO()) == \"Pi/2 - x + x^2/2 - x^4/8 + 3*x^6/96\"\n    assert mcode(atan(x).series(x).removeO()) == \"x - x^3/3 + x^5/5 - x^7/7\"\n    assert mcode(atanh(x).series(x).removeO()) == \"x + x^3/3 + x^5/5 + x^7/63\"\n    assert mcode(asech(x).series(x).removeO()) == \"1/x + 1/2*x + 3/8*x^3 + 15/384*x^5\"\n    assert mcode(acosh(x).series(x).removeO()) == \"Log[x + sqrt(x^2 - 1)]\"\n    assert mcode(acoth(x).series(x).removeO()) == \"1/x +"], "sample_32": ["    def test_isnull_key_is_false(self):\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__c__isnull=False),\n            [self.objs[3], self.objs[4]],\n        )\n", "    def test_contains_with_null_value(self):\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__contains=None),\n            [self.objs[4]],\n        )\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__contains=[]),\n            [self.objs[7]],\n        )\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__contains={}),\n            [self.objs[2], self.objs[7]],\n        )\n", "    def setUpTestData(cls):\n        cls.json_model = JSONModel.objects.create(value={'a': 'b', 'c': 'd'})\n        cls.json_model_without_key = JSONModel.objects.create(value={'e': 'f'})\n        cls.json_model_with_multiple_keys = JSONModel.objects.create(\n            value={'a': 'b', 'c': 'd', 'g': 'h'},\n        )\n", "    def test_exact_value(self):\n        obj = NullableJSONModel.objects.create(value={'baz': {'a': 'b', 'c': 'd'}})\n        tests = [\n            ({'baz': {'a': 'b', 'c': 'd'}}, [obj]),\n            ({'baz': {'a': 'b'}}, [obj]),\n            ({'baz': {'c': 'd'}}, [obj]),\n            ({'baz': {'c': 'e'}}, []),\n        ]\n        for value, expected in tests:\n            with self.subTest(value=value):\n                self.assertSequenceEqual(\n                    NullableJSONModel.objects.filter(value__contains=value),\n                    expected,\n                )\n", "    def test_json_path_invalid(self):\n        msg = 'Invalid JSON path'\n        with self.assertRaisesMessage(ValueError, msg):\n            NullableJSONModel.objects.filter(value__json_path=['invalid'])\n"], "sample_128": ["def test_Method_postprocess():\n    opt = {'method': 'div'}\n    Method.postprocess(opt)\n\n    assert opt == {'method': 'div'}\n", "def test_Order_preprocess():\n    assert Order.preprocess(lex) == lex\n\n    raises(OptionError, lambda: Order.preprocess(False))\n    raises(OptionError, lambda: Order.preprocess(True))\n    raises(OptionError, lambda: Order.preprocess(0))\n    raises(OptionError, lambda: Order.preprocess(1))\n    raises(OptionError, lambda: Order.preprocess('foo'))\n    raises(OptionError, lambda: Order.preprocess([1, 2]))\n", "def test_BuildOptions_preprocess():\n    opt = Options((x, y), {'domain': 'ZZ'})\n    assert build_options((x, y), {'domain': 'ZZ'}) == opt\n\n    opt = {'opt': {'domain': 'ZZ'}}\n    assert build_options(opt) == opt['opt']\n\n    raises(OptionError, lambda: build_options((x, y), {'domain': 'ZZ', 'gens': (x, y)}))\n    raises(OptionError, lambda: build_options((x, y, z), {'gens': (x, y)}))\n", "def test_Domain_preprocess_invalid_realfield():\n    raises(OptionError, lambda: Domain.preprocess('R(abc)'))\n    raises(OptionError, lambda: Domain.preprocess('RR(abc)'))\n    raises(OptionError, lambda: Domain.preprocess('R_-1'))\n    raises(OptionError, lambda: Domain.preprocess('R_-1(abc)'))\n    raises(OptionError, lambda: Domain.preprocess('R(abc_-1)'))\n    raises(OptionError, lambda: Domain.preprocess('RR(abc_-1)'))\n    raises(OptionError, lambda: Domain.preprocess('R(abc_-1_(abc)')))\n    raises(OptionError, lambda: Domain.preprocess('RR(abc_-1_(abc)')))\n\n", "def test_BuildOptions():\n    assert build_options() == {}\n    assert build_options(gens=(x, y)) == {}\n    assert build_options(args={'opt': Options((x, y), {'domain': 'ZZ'})}) == {'domain': ZZ}\n    assert build_options(gens=(x, y), args={'opt': Options((x, y), {'domain': 'ZZ'})}) == {'gens': (x, y), 'domain': ZZ}\n\n    raises(OptionError, lambda: build_options(gens=(x, y, z), args={'opt': Options((x, y), {'domain': 'ZZ'})}))\n\n    assert build_options(gens=(x, y), args={'opt': Options((x, y), {'gens': (x, y), 'domain': 'ZZ'})}) == {'domain': ZZ}\n\n    assert build_options(gens=(x, y), args={'opt': Options((x, y), {'auto': True})}) == {'auto': True}\n\n    opt = Options((x, y), {'domain': ZZ})\n    assert build_options(gens=(x, y), opt=opt) == opt\n\n    raises(TypeError, lambda: build_options(gens=(x, y), args=123))\n"], "sample_144": ["def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 0], Q.symmetric(X)) == X[0, 0]\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[0, 2], Q.symmetric(X)) == X[2, 0]\n\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 1], Q.symmetric(X)) == X[1, 1]\n    assert refine(X[1, 2], Q.symmetric(X)) == X[2, 1]\n\n    assert refine(X[2, 0], Q.symmetric(X)) == X[0, 2]\n    assert refine(X[2, 1], Q.symmetric(X)) == X[1, 2]\n    assert refine(X[2, 2], Q.symmetric(X)) == X[2, 2]\n", "def test_pow3():\n    x = Symbol('x', real = True)\n    assert refine(x**2, Q.positive(x)) == x**2\n    assert refine(x**2, Q.negative(x)) != x**2\n    assert refine(x**2, Q.zero(x)) == 0\n    assert refine(x**2, Q.real(x)) == x**2\n    assert refine(x**2, Q.imaginary(x)) == 0\n\n    x = Symbol('x', imaginary = True)\n    assert refine(x**2, Q.positive(x)) == -x**2\n    assert refine(x**2, Q.negative(x)) == x**2\n    assert refine(x**2, Q.zero(x)) == 0\n    assert refine(x**2, Q.real(x)) == 0\n    assert refine(x**2, Q.imaginary(x)) == -x**2\n\n    x = Symbol('x', complex = True)\n    assert refine(x**2, Q.positive(x)) == x**2\n    assert refine(x**2, Q.negative(x)) != x**2\n    assert refine(x**2, Q.zero(x)) == 0\n    assert refine(x**2, Q.real(x)) == x**2\n    assert refine(x**2, Q.imaginary(x)) == -x**2\n", "def test_refine_issue_12345():\n    from sympy import MatrixElement, MatrixSymbol, Q\n    X = MatrixSymbol('X', 2, 2)\n    assert refine(MatrixElement(X[0, 1], Q.symmetric(X))) == MatrixElement(X[0, 1], Q.symmetric(X))\n    assert refine(MatrixElement(X[0, 1], ~Q.symmetric(X))) != MatrixElement(X[0, 1], Q.symmetric(X))\n    assert refine(MatrixElement(X[0, 1], Q.symmetric(X)), Q.symmetric(X)) == MatrixElement(X[1, 0], Q.symmetric(X))\n    assert refine(MatrixElement(X[0, 1], Q.symmetric(X)), ~Q.symmetric(X)) == MatrixElement(X[0, 1], Q.symmetric(X))\n    assert refine(MatrixElement(X[0, 1], Q.symmetric(X)), Q.asymmetric(X)) == MatrixElement(X[0, 1], Q.symmetric(X))\n", "def test_refine_Pow():\n    assert refine((-1)**x, Q.integer(x)) == (-1)**x\n    assert refine((-1)**(x + 1), Q.integer(x)) == (-1)**(x + 1)\n    assert refine((-1)**(x + 2), Q.integer(x)) == 1\n\n    assert refine((-1)**(-x), Q.integer(x)) == (-1)**(-x)\n    assert refine((-1)**(-x - 1), Q.integer(x)) == (-1)**(-x - 1)\n    assert refine((-1)**(-x - 2), Q.integer(x)) == 1\n\n    # Test with Rational exponent\n    assert refine((-1)**Rational(1, 2), Q.integer(x)) == S.sqrt(-1)\n    assert refine((-1)**Rational(1, 2) * (-1)**Rational(1, 2), Q.integer(x)) == S.sqrt(-1) * S.sqrt(-1)\n    assert refine((-1)**Rational(1, 2) * (-1)**Rational(1, 2), Q.real(x)) == 1\n\n    # Test with multiple bases\n    assert refine((-1)**x * (-1)**y, Q.integer(x) & Q.integer(y)) == (-1)**(x + y)\n    assert refine((-1)**x * (-1)**(x + 1), Q.integer(x)) == (-1)**(2*x + 1)\n    assert refine((-1)**x * (-1)**(x + 1), Q.real(x)) == (-1)**(2*x + 1)\n\n    # Test with negative base\n    assert refine((-1)**x, Q.negative(x)) == (-1)**x\n    assert refine((-1)**(-x), Q.negative(x)) == (-1)**(-x)\n\n    # Test with complex exponent\n    assert refine((-1)**(x + I*y), Q.real(x)) == (-1)**(x + I*y)\n    assert refine((-1)**(x + I*y), Q.imaginary(x)) == (-1)**(x + I*y)\n", "def test_Pow():\n    assert refine((-1)**(x + 5), Q.even(x)) == (-1)**5\n    assert refine((-1)**(x + 6), Q.odd(x)) == -1\n    assert refine((-1)**(x + 7), Q.even(x)) == (-1)**7\n    assert refine((-1)**(x + 8), Q.odd(x)) == (-1)\n\n    assert refine((-1)**(x + y), Q.even(x)) == refine((-1)**y, Q.real(x))\n    assert refine((-1)**(x + y + 1), Q.odd(x)) == refine((-1)**(y + 1), Q.real(x))\n    assert refine((-1)**(x + y + 2), Q.even(x)) == refine((-1)**(y + 2), Q.real(x))\n\n    assert refine((-1)**(x + 3/2), Q.even(x)) == refine((-1)**(3/2), Q.real(x))\n    assert refine((-1)**(x + 5/2), Q.odd(x)) == refine((-1)**(5/2), Q.real(x))\n\n    assert refine((-1)**(x + Rational(1, 2)), Q.even(x)) == refine((-1)**(1/2), Q.real(x))\n    assert refine((-1)**(x + Rational(3, 2)), Q.odd(x)) == refine((-1)**(3/2), Q.real(x))\n\n    assert refine((-1)**(x + S.Pi), Q.even(x)) == refine((-1)**(S.Pi), Q.real(x))\n    assert refine((-1)**(x + S.Pi + 2), Q.odd(x)) == refine((-1)**(S.Pi + 2), Q.real(x))\n\n    assert refine((-1)**(x + S.Pi/2), Q.even(x)) == refine((-1)**(S.Pi/2), Q.real(x))\n    assert refine((-1)**(x + 3*S.Pi/2), Q.odd(x)) == refine((-1)**(3*S.Pi/2), Q.real(x))\n\n    assert refine((-1)**(x + S.Pi/4), Q.even(x)) == refine((-1)**(S.Pi/4), Q.real(x))\n    assert refine((-"], "sample_35": ["    def test_modelform_error_messages(self):\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': '%(value)s IS INVALID CHOICE',\n        }\n        f = modelform_factory(ChoiceModel, fields=('name',), error_messages=e)()\n        self.assertFormErrors(['REQUIRED'], f.clean, {})\n        self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, {'name': '4'})\n\n        f = modelform_factory(ChoiceModel, fields=('name',), error_messages=e)()\n        self.assertFormErrors(['REQUIRED'], f.clean, {})\n        self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, {'name': '4'})\n\n        f = modelform_factory(ChoiceModel, fields=('name',), error_messages=e)()\n        self.assertFormErrors(['REQUIRED'], f.clean, {})\n        self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, {'name': '4'})\n\n        f = modelform_factory(ChoiceModel, fields=('name',), error_messages=e)()\n        self.assertFormErrors(['REQUIRED'], f.clean, {})\n        self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, {'name': '4'})\n\n        f = modelform_factory(ChoiceModel, fields=('name',), error_messages=e)()\n        self.assertFormErrors(['REQUIRED'], f.clean, {})\n        self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, {'name': '4'})\n", "    def test_modelchoicefield_save(self):\n        # Create choices for the model choice field tests below.\n        ChoiceModel.objects.create(pk=1, name='a')\n        ChoiceModel.objects.create(pk=2, name='b')\n        ChoiceModel.objects.create(pk=3, name='c')\n\n        # ModelChoiceField\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': 'INVALID CHOICE',\n        }\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e)\n        instance = ChoiceModel()\n        instance.name = f.clean('1')\n        instance.save()\n        self.assertEqual(ChoiceModel.objects.get(id=1).name, 'a')\n\n        # Test that invalid choice raises a ValidationError\n        with self.assertRaises(ValidationError):\n            instance.name = f.clean('4')\n            instance.save()\n\n        # ModelMultipleChoiceField\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': '%(value)s IS INVALID CHOICE',\n            'invalid_list': 'NOT A LIST OF VALUES',\n        }\n        f = ModelMultipleChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e)\n        instance = ChoiceModel()\n        instance.name = f.clean('1')\n        instance.save()\n        self.assertEqual(ChoiceModel.objects.get(id=1).name, 'a')\n\n        # Test that invalid list raises a ValidationError\n        with self.assertRaises(ValidationError):\n            instance.name = f.clean(['4'])\n            instance.save()\n\n        # Test that invalid choice raises a ValidationError\n        with self.assertRaises(ValidationError):\n            instance.name = f.clean(['4', '3'])\n            instance.save()\n", "    def test_modelchoicefield_widgets(self):\n        # ModelChoiceField\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': 'INVALID CHOICE',\n        }\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e, widget=Select)\n        self.assertHTMLEqual(str(f.widget), '<select name=\"field\"><option value=\"\">---------</option><option value=\"1\">a</option><option value=\"2\">b</option><option value=\"3\">c</option></select>')\n        self.assertEqual(f.widget.choices, [(None, '---------'), (1, 'a'), (2, 'b'), (3, 'c')])\n\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e, widget=RadioSelect)\n        self.assertHTMLEqual(str(f.widget), '<ul class=\"checkbox-list\"><li><label for=\"id_field_0\">---------</label><input type=\"radio\" id=\"id_field_0\" name=\"field\" value=\"\"/></li><li><label for=\"id_field_1\">a</label><input type=\"radio\" id=\"id_field_1\" name=\"field\" value=\"1\"/></li><li><label for=\"id_field_2\">b</label><input type=\"radio\" id=\"id_field_2\" name=\"field\" value=\"2\"/></li><li><label for=\"id_field_3\">c</label><input type=\"radio\" id=\"id_field_3\" name=\"field\" value=\"3\"/></li></ul>')\n        self.assertEqual(f.widget.choices, [(None, '---------'), (1, 'a'), (2, 'b'), (3, 'c')])\n\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e, widget=SelectMultiple)\n        self.assertHTMLEqual(str(f.widget), '<select multiple name=\"field\"><option value=\"\">---------</option><option value=\"1\">a</option><option value=\"2\">b</option><option value=\"3\">c</option></select>')\n        self.assertEqual(f.widget.choices, [(None, '---------'), (1, 'a'), (2, 'b'), (3, 'c')])\n\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e, widget=HiddenInput)\n        self.assertHTMLEqual(str", "    def test_modelformset(self):\n        # Create choices for the model choice field tests below.\n        ChoiceModel.objects.create(pk=1, name='a')\n        ChoiceModel.objects.create(pk=2, name='b')\n        ChoiceModel.objects.create(pk=3, name='c')\n\n        # ModelChoiceField\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': 'INVALID CHOICE',\n        }\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e)\n        formset = BaseFormSet(data={'field': '2'})\n        self.assertFormErrors(['REQUIRED'], f.clean, formset.data)\n\n        # ModelMultipleChoiceField\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': '%(value)s IS INVALID CHOICE',\n            'invalid_list': 'NOT A LIST OF VALUES',\n        }\n        f = ModelMultipleChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e)\n        formset = BaseFormSet(data={'field': ['2']})\n        self.assertFormErrors(['REQUIRED'], f.clean, formset.data)\n        self.assertFormErrors(['NOT A LIST OF VALUES'], f.clean, formset.data)\n        self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, formset.data)\n", "    def test_formfield_callback(self):\n        class TestModel(models.Model):\n            field = models.CharField()\n\n        class TestForm(ModelForm):\n            class Meta:\n                model = TestModel\n                formfield_callback = lambda f: CharField()\n\n        f = TestForm({'field': 'value'})\n        self.assertIsInstance(f.fields['field'], CharField)\n\n        class TestModel(models.Model):\n            field = models.CharField()\n\n        class TestForm(ModelForm):\n            class Meta:\n                model = TestModel\n                formfield_callback = 'invalid'\n\n        with self.assertRaises(TypeError):\n            TestForm({'field': 'value'})\n"], "sample_61": ["def test_decimal_pos_zero(self):\n    self.assertEqual(nformat(1234, \".\", decimal_pos=0), \"1234\")\n    self.assertEqual(nformat(1234.5, \".\", decimal_pos=0), \"1235\")\n    self.assertEqual(nformat(-1234.5, \".\", decimal_pos=0), \"-1235\")\n    self.assertEqual(nformat(1234, \".\", decimal_pos=0, thousand_sep=\",\"), \"1234\")\n    self.assertEqual(\n        nformat(1234, \".\", decimal_pos=0, grouping=2, thousand_sep=\",\"), \"1234\"\n    )\n    self.assertEqual(\n        nformat(1234, \".\", decimal_pos=0, grouping=2, thousand_sep=\",\", force_grouping=True),\n        \"12,34\",\n    )\n    # Test decimal_pos=0 with float and Decimal instances\n    self.assertEqual(nformat(float(1234.5), \".\", decimal_pos=0), \"1235\")\n    self.assertEqual(nformat(Decimal(\"1234.5\"), \".\", decimal_pos=0), \"1235\")\n", "def test_format_float_overflow(self):\n    tests = [\n        (1e308, None, \"1e+308\"),\n        (1e309, None, \"inf\"),\n        (-1e308, None, \"-inf\"),\n        (1e308, 2, \"1e+308\"),\n        (1e309, 2, \"inf\"),\n        (-1e308, 2, \"-inf\"),\n        (1e308, 0, \"1e+308\"),\n        (1e309, 0, \"inf\"),\n        (-1e308, 0, \"-inf\"),\n        (1e308, 300, \"1e+308\"),\n        (1e309, 300, \"inf\"),\n        (-1e308, 300, \"-inf\"),\n    ]\n    for value, decimal_pos, expected_value in tests:\n        with self.subTest(value=value, decimal_pos=decimal_pos):\n            self.assertEqual(nformat(value, \".\", decimal_pos), expected_value)\n", "    def test_edge_case_large_decimal_pos(self):\n        self.assertEqual(nformat(1234, \".\", decimal_pos=100), \"1234.00\")\n", "def test_format_with_large_grouping(self):\n    # Large grouping with negative number\n    self.assertEqual(\n        nformat(-1234567890123456789, \".\", grouping=(3, 2, 0), thousand_sep=\",\"),\n        \"-123,456,789,012,345\"\n    )\n    # Large grouping with positive number\n    self.assertEqual(\n        nformat(1234567890123456789, \".\", grouping=(3, 2, 0), thousand_sep=\",\"),\n        \"123,456,789,012,345\"\n    )\n    # Large grouping with no decimal positions\n    self.assertEqual(\n        nformat(1234567890123456789, \".\", grouping=(3, 2, 0), thousand_sep=\",\", decimal_pos=0),\n        \"123,456,789,012,345\"\n    )\n    # Large grouping with negative number and no decimal positions\n    self.assertEqual(\n        nformat(-1234567890123456789, \".\", grouping=(3, 2, 0), thousand_sep=\",\", decimal_pos=0),\n        \"-123,456,789,012,345\"\n    )\n", "def test_decimal_sep_and_thousand_sep(self):\n    \"\"\"\n    Test that decimal and thousand separators can be set to different characters.\n    \"\"\"\n    self.assertEqual(nformat(1234, \"#\", decimal_sep=\"#\"), \"1234\")\n    self.assertEqual(nformat(1234, \"#\", decimal_sep=\"#\", thousand_sep=\"$\"), \"1234\")\n    self.assertEqual(nformat(1234.5, \"#\", decimal_sep=\"#\"), \"1234.5\")\n    self.assertEqual(nformat(1234.5, \"#\", decimal_sep=\"#\", decimal_pos=2), \"1234.50\")\n    self.assertEqual(\n        nformat(1234.5, \"#\", decimal_sep=\"#\", grouping=2, thousand_sep=\"$\"),\n        \"1234\",\n    )\n    self.assertEqual(\n        nformat(1234.5, \"#\", decimal_sep=\"#\", grouping=2, thousand_sep=\"$\", force_grouping=True),\n        \"1#2#4\",\n    )\n\n    self.assertEqual(nformat(1234, \"#\", decimal_sep=\"#\", thousand_sep=\"$\"), \"1234\")\n    self.assertEqual(\n        nformat(1234, \"#\", decimal_sep=\"#\", grouping=2, thousand_sep=\"$\", force_grouping=True),\n        \"1#2#4\",\n    )\n    self.assertEqual(nformat(1234.5, \"#\", decimal_sep=\"#\"), \"1234.5\")\n    self.assertEqual(\n        nformat(1234.5, \"#\", decimal_sep=\"#\", decimal_pos=2), \"1234.50\"\n    )\n\n    # Test that setting USE_L10N to True affects the thousand separator.\n    with self.settings(USE_THOUSAND_SEPARATOR=True):\n        self.assertEqual(\n            nformat(1234, \"#\", grouping=2, thousand_sep=\"$\", use_l10n=True),\n            \"1#2#4\",\n        )\n"], "sample_108": ["def test_linear_svr_coef_sign():\n    # Test that LinearSVR has coef_ with the right sign.\n    # Non-regression test for #2933.\n    X = np.random.RandomState(21).randn(10, 3)\n    y = np.random.RandomState(12).randn(10)\n\n    for svr in [svm.LinearSVR()]:\n        svr.fit(X, y)\n        assert_array_almost_equal(svr.predict(X),\n                                  np.dot(X, svr.coef_.ravel()) + svr.intercept_)\n", "def test_svr_coef_sign():\n    # Test that SVR(kernel=\"linear\") has coef_ with the right sign.\n    # Non-regression test for #2933.\n    X = np.random.RandomState(21).randn(10, 3)\n    y = np.random.RandomState(12).randn(10)\n\n    for svr in [svm.SVR(kernel='linear'), svm.NuSVR(kernel='linear'), svm.LinearSVR()]:\n        svr.fit(X, y)\n        assert_array_almost_equal(svr.predict(X),\n                                  np.dot(X, svr.coef_.ravel()) + svr.intercept_)\n", "def test_nu_svr_coef_sign():\n    # Test that NuSVR(kernel=\"linear\") has coef_ with the right sign.\n    # Non-regression test for #2933.\n    X = np.random.RandomState(21).randn(10, 3)\n    y = np.random.RandomState(12).randn(10)\n\n    for nu_svr in [svm.NuSVR(kernel='linear'), svm.LinearSVR(kernel='linear')]:\n        nu_svr.fit(X, y)\n        assert_array_almost_equal(nu_svr.predict(X),\n                                 np.dot(X, nu_svr.coef_.ravel()) + nu_svr.intercept_)\n", "def test_ovr_decision_function_shape():\n    # check that decision_function_shape='ovr' gives\n    # correct shape and is consistent with predict\n\n    X, y = make_blobs(n_samples=100, n_features=10, centers=3,\n                       random_state=0)\n\n    for n_classes in [2, 3]:\n        for clf in (svm.SVC(kernel='linear', C=0.1,\n                            decision_function_shape='ovr'),\n                    svm.SVC(kernel='rbf', gamma=1,\n                            decision_function_shape='ovr')):\n            clf.fit(X, y)\n\n            dec = clf.decision_function(X)\n            assert dec.shape == (len(X), n_classes)\n\n            assert_array_equal(clf.predict(X), np.argmax(dec, axis=1))\n\n            # test that predict_proba also returns a shape\n            # that matches the decision_function_shape\n            assert dec.shape == clf.predict_proba(X).shape[1:]\n", "def test_sparse_support_vectors_empty():\n    # Regression test for #14893\n    X_train = sparse.csr_matrix([[0, 1, 0, 0],\n                                 [0, 0, 0, 1],\n                                 [0, 0, 1, 0],\n                                 [0, 0, 0, 1]])\n    y_train = np.array([0.04, 0.04, 0.10, 0.16])\n    model = svm.SVR(kernel='linear')\n    model.fit(X_train, y_train)\n    assert not model.support_vectors_.data.size\n    assert not model.dual_coef_.data.size\n    assert model.predict(X_train) == y_train\n    assert model.score(X_train, y_train) > 0.5\n"], "sample_141": ["def test_issue_14933():\n    assert (sin(inch) - sin(foot)).simplify() == sin(foot - inch)\n    p = symbols('p', positive=True)\n    assert (sin(inch) - sin(p)).simplify() == sin(p - inch)\n    assert (sin(inch) - sin(foot + inch)).simplify() == sin(foot)\n", "def test_quantity_get_dimension():\n    u = Quantity('u')\n    v = Quantity('v')\n    w = Quantity('w')\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    w.set_global_relative_scale_factor(S(2), second)\n\n    assert u.dimension == Dimension(meter)\n    assert v.dimension == Dimension(meter)\n    assert w.dimension == Dimension(second)\n\n    assert u.get_dimension() == meter\n    assert v.get_dimension() == meter\n    assert w.get_dimension() == second\n\n    assert u.get_dimension() is not v.get_dimension()\n    assert u.get_dimension() == v.get_dimension().args[0]\n", "def test_quantity_simplify_with_nested_quantities():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n\n    expr = u * v * meter\n    assert quantity_simplify(expr) == (50*meter**2)\n\n    expr = u / v * meter\n    assert quantity_simplify(expr) == (2*meter)\n\n    expr = u * (u/v) * meter\n    assert quantity_simplify(expr) == (50*meter)\n\n    expr = u * (u/v) * (u/v) * meter\n    assert quantity_simplify(expr) == (2500*meter)\n\n    expr = u * v * (u/v) * meter\n    assert quantity_simplify(expr) == (10*meter)\n", "def test_quantity_simplify_expression():\n    u = Quantity('u')\n    v = Quantity('v')\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n\n    # Test when the input is a single quantity\n    assert quantity_simplify(u) == u\n\n    # Test when the input is a simple Add expression\n    expr = u + v\n    assert quantity_simplify(expr) == 15*meter\n\n    # Test when the input is a complex expression\n    expr = u + v + meter\n    assert quantity_simplify(expr) == 16*meter\n\n    # Test when the input is a complex expression with different dimensions\n    v.set_global_relative_scale_factor(S(2), second)\n    expr = u + v\n    assert quantity_simplify(expr) == 10*meter + 2*second\n\n    # Test when the input is a complex expression with different dimensions and a constant\n    expr = u + v + 5\n    assert quantity_simplify(expr) == 10*meter + 2*second + 5\n\n    # Test when the input is a Mul expression\n    expr = u * v\n    assert quantity_simplify(expr) == 50*meter**2\n\n    # Test when the input is a complex Mul expression\n    expr = u * v + meter\n    assert quantity_simplify(expr) == 50*meter**2 + meter\n\n    # Test when the input is a complex Mul expression with different dimensions\n    expr = u * v + second\n    assert quantity_simplify(expr) == 50*meter**2 + second\n", "def test_units_with_fractional_exponents():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n\n    assert u**2.5 == u**2 * u**(0.5)\n    assert (u**2.5) ** 0.5 == u**1\n    assert (u**2.5) ** 2 == u**5\n    assert (u**-2.5) ** 2 == u**-5\n    assert u**(-2.5) == u**-2.5\n\n    # Test that fractional exponents are supported in conversions\n    assert convert_to(u**2.5, meter) == 100 * meter**(2.5)\n    assert convert_to(u**(-2.5), meter) == 1 / (100 * meter**2.5)\n\n    # Test that fractional exponents are supported in additions\n    assert (u + v)**2.5 == (u + v)**2 * (u + v)**0.5\n    assert (u + v)**(-2.5) == (u + v)**-2 * (u + v)**-0.5\n"], "sample_142": ["def test_captured():\n    assert capture(lambda: True) == ''\n    assert capture(lambda: print('hello')) == 'hello\\n'\n    assert capture(lambda: raise ZeroDivisionError) == ''\n    assert capture(lambda: print('hello\\nworld')) == 'hello\\nworld\\n'\n", "def test_rotate_left():\n    assert rotate_left([]) == []\n    assert rotate_left([1]) == [1]\n    assert rotate_left([1, 2, 3, 4, 5]) == [2, 3, 4, 5, 1]\n    assert rotate_left([1, 2, 3, 4, 5], 2) == [3, 4, 5, 1, 2]\n    assert rotate_left([1, 2, 3, 4, 5], 6) == [2, 3, 4, 5, 1]\n    assert rotate_left([1, 2, 3, 4, 5], -1) == [5, 1, 2, 3, 4]\n    assert rotate_left([1, 2, 3, 4, 5], -6) == [5, 1, 2, 3, 4]\n    A = [0, 1, 2, 3, 4, 5]\n    rotate_left(A, 2)\n    assert A == [2, 3, 4, 5, 0, 1]\n    rotate_left(A, 2)\n    assert A == [4, 5, 0, 1, 2, 3]\n", "def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((0, 1, 2))) == list(signed_permutations((0, 1, 2)))\n    assert list(permute_signs((-2, 1, 0))) == [(1, 1, 0), (-1, 1, 0), (1, -1, 0), (-1, -1, 0)]\n    assert list(permute_signs((0, 0, 2))) == [(0, 0, 2), (0, 0, -2)]\n\n    assert list(permute_signs([0, 1, 2])) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs([0, 1, 2])) == list(signed_permutations([0, 1, 2]))\n    assert list(permute_signs([-2, 1, 0])) == [(1, 1, 0), (-1, 1, 0), (1, -1, 0), (-1, -1, 0)]\n    assert list(permute_signs([0, 0, 2])) == [(0, 0, 2), (0, 0, -2)]\n", "def test_permute_signs():\n    assert list(permute_signs((1, -2, 3))) == [(1, -2, 3), (1, 2, 3), (1, -2, -3), (1, 2, -3)]\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((1, -2, -3))) == [(1, -2, -3), (1, 2, -3), (1, -2, 3), (1, 2, 3)]\n    assert list(permute_signs((0, 0, 0))) == [(0, 0, 0)]\n    assert list(permute_signs((0, 1, 0))) == [(0, 1, 0), (0, -1, 0), (0, 1, 0), (0, -1, 0)]\n    assert list(permute_signs((0, 0, 1))) == [(0, 0, 1), (0, 0, -1)]\n    assert list(permute_signs((1, 0, 0))) == [(1, 0, 0), (1, 0, 0)]\n    assert list(permute_signs((1, 1, 1))) == [(1, 1, 1)]\n    assert list(permute_signs((0, 0, 1))) == [(0, 0, 1), (0, 0, -1)]\n", "def test_permute_signs():\n    assert list(permute_signs((0, 1, 0))) == [(0, 1, 0), (0, -1, 0), (0, 1, 0), (0, -1, 0)]\n    assert list(permute_signs((1, 0, -1))) == [(1, 0, -1), (1, 0, 1), (1, 0, -1), (1, 0, 1)]\n    assert list(permute_signs((1, 0))) == [(1, 0), (-1, 0), (1, 0), (-1, 0)]\n    assert list(permute_signs((0, 0))) == [(0, 0)]\n    assert list(permute_signs((0,))) == [(0,)]\n    assert list(permute_signs((0, 1))) == [(0, 1), (0, -1)]\n    assert list(permute_signs()) == [()]\n    assert list(permute_signs('abc')) == ['abc', '-abc', 'abc', '-abc']\n    assert list(permute_signs('abc', repeat=2)) == [('abc', 'abc'), ('abc', '-abc'), ('abc', 'abc'), ('abc', '-abc')]\n    assert list(permute_signs(list(range(3)))) == [(0, 1, 2), (0, 1, -2), (0, -1, 2), (0, -1, -2)]\n"], "sample_105": ["def test_transform_multilabel():\n    \"\"\"Check if transform method works for multilabel classification.\"\"\"\n    X, y = make_multilabel_classification(n_classes=3, n_labels=2,\n                                          allow_unlabeled=True,\n                                          random_state=123)\n    clf = OneVsRestClassifier(SVC(kernel='linear'))\n\n    eclf = VotingClassifier(estimators=[('ovr', clf)], voting='soft')\n    try:\n        eclf.fit(X, y)\n    except NotImplementedError:\n        return\n\n    assert_array_equal(eclf.transform(X).shape, (X.shape[0], 3, 2))\n", "def test_transform_default_flatten():\n    \"\"\"Check transform method of VotingRegressor on boston dataset.\"\"\"\n    reg1 = DummyRegressor(strategy='mean')\n    reg2 = DummyRegressor(strategy='median')\n    reg3 = DummyRegressor(strategy='quantile', quantile=.2)\n    ereg = VotingRegressor([('mean', reg1), ('median', reg2),\n                            ('quantile', reg3)])\n\n    X_r_train, X_r_test, y_r_train, y_r_test = \\\n        train_test_split(X_r, y_r, test_size=.25)\n\n    reg1_pred = reg1.fit(X_r_train, y_r_train).predict(X_r_test)\n    reg2_pred = reg2.fit(X_r_train, y_r_train).predict(X_r_test)\n    reg3_pred = reg3.fit(X_r_train, y_r_train).predict(X_r_test)\n    ereg_pred = ereg.fit(X_r_train, y_r_train).predict(X_r_test)\n\n    avg = np.average(np.asarray([reg1_pred, reg2_pred, reg3_pred]), axis=0)\n    assert_almost_equal(ereg_pred, avg, decimal=2)\n\n    ereg_default = VotingRegressor([('mean', reg1), ('median', reg2),\n                                   ('quantile', reg3)],\n                                  flatten_transform=False).fit(X_r_train, y_r_train)\n    ereg_default_pred = ereg_default.transform(X_r_test)\n    assert_array_almost_equal(ereg_pred.reshape((ereg_pred.shape[0], 1, -1)),\n                              ereg_default_pred)\n\n    ereg_default = VotingRegressor([('mean', reg1), ('median', reg2),\n                                   ('quantile', reg3)]).fit(X_r_train, y_r_train)\n    ereg_default_pred = ereg_default.transform(X_r_test)\n    assert_array_almost_equal(ereg_pred.reshape((ereg_pred.shape[0], 1, -1)),\n                              ereg_default_pred)\n", "def test_voting_regressor_with_multinomial_loss():\n    \"\"\"Check if VotingRegressor works with multinomial loss.\"\"\"\n    reg1 = LogisticRegression(random_state=123, max_iter=10000, multi_class='multinomial')\n    reg2 = DummyRegressor(strategy='mean')\n    ereg = VotingRegressor([('lr', reg1), ('dr', reg2)], weights=[1, 2])\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([0, 1, 2])\n\n    with pytest.raises(NotImplementedError):\n        ereg.fit(X, y)\n", "def test_voting_regressor_transform():\n    \"\"\"Check transform method of VotingRegressor on boston dataset.\"\"\"\n    reg1 = DummyRegressor(strategy='mean')\n    reg2 = DummyRegressor(strategy='median')\n    reg3 = DummyRegressor(strategy='quantile', quantile=.2)\n    ereg = VotingRegressor([('mean', reg1), ('median', reg2),\n                            ('quantile', reg3)],\n                           weights=[1, 2, 10]).fit(X_r, y_r)\n    X_r_transform = ereg.transform(X_r)\n\n    # Check shape of output\n    assert_array_equal(X_r_transform.shape, (506, 3))\n    assert_array_almost_equal(X_r_transform[:, 0], y_r)\n\n    # Check that predictions are weighted average of individual predictions\n    reg1_pred = reg1.fit(X_r, y_r).predict(X_r)\n    reg2_pred = reg2.fit(X_r, y_r).predict(X_r)\n    reg3_pred = reg3.fit(X_r, y_r).predict(X_r)\n    avg_pred = np.average(np.asarray([reg1_pred, reg2_pred, reg3_pred]),\n                          axis=0, weights=[1, 2, 10])\n    assert_array_almost_equal(X_r_transform[:, 0], avg_pred)\n\n    # Check that weights are applied correctly\n    ereg_weights_none = VotingRegressor([('mean', reg1), ('median', reg2),\n                                         ('quantile', reg3)], weights=None)\n    ereg_weights_none.fit(X_r, y_r)\n    ereg_weights_none_transform = ereg_weights_none.transform(X_r)\n    ereg_weights_equal = VotingRegressor([('mean', reg1), ('median', reg2),\n                                         ('quantile', reg3)],\n                                        weights=[1, 1, 1])\n    ereg_weights_equal.fit(X_r, y_r)\n    ereg_weights_equal_transform = ereg_weights_equal.transform(X_r)\n    assert_array_almost_equal(ereg_weights_none_transform, ereg_weights_equal_transform)\n", "def test_voting_regressor_tie_situation():\n    \"\"\"Check voting regressor selects smaller prediction in tie situation.\"\"\"\n    r1 = LinearRegression()\n    r2 = RandomForestRegressor(random_state=123)\n    ereg = VotingRegressor([('lr', r1), ('rf', r2)])\n    X = np.array([[1, 1], [2, 4], [3, 9], [4, 16], [5, 25], [6, 36]])\n    y = np.array([2, 6, 12, 20, 30, 42])\n    assert_equal(r1.fit(X, y).predict(X)[3], 20)\n    assert_equal(r2.fit(X, y).predict(X)[3], 19.5)\n    assert_equal(ereg.fit(X, y).predict(X)[3], 19.5)\n\n"], "sample_53": ["def test_add_field_with_default_expression(self):\n    \"\"\"#22031 - Adding a field with an expression default should work.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_name])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=models.F(\"id\"))\n", "def test_remove_check_constraint(self):\n    \"\"\"Tests the removal of check constraints.\"\"\"\n    changes = self.get_changes(\n        [self.author_empty, self.book],\n        [self.author_empty, self.book_check_constraint],\n    )\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AddConstraint\"])\n    added_constraint = models.CheckConstraint(\n        check=models.Q(name__contains=\"Bob\"), name=\"name_contains_bob\"\n    )\n    self.assertOperationAttributes(\n        changes, \"otherapp\", 0, 0, model_name=\"book\", constraint=added_constraint\n    )\n\n    changes = self.get_changes(\n        [self.author_empty, self.book, self.book_check_constraint],\n        [self.author_empty, self.book],\n    )\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"RemoveConstraint\"])\n    self.assertOperationAttributes(\n        changes, \"otherapp\", 0, 0, model_name=\"book\", name=\"name_contains_bob\"\n    )\n\n    changes = self.get_changes(\n        [self.author_empty, self.book],\n        [self.author_empty, self.book_check_constraint],\n        questioner=MigrationQuestioner({\"ask_remove_constraint\": True}),\n    )\n    self.assertEqual(\n        changes[\"otherapp\"][0].operations[0].options,\n        {\"check\": models.Q(name__contains=\"Bob\")},\n    )\n", "def test_remove_mti_inheritance_model(self):\n    \"\"\"\n    Removing a model that's an MTI inheritance model will remove all of its\n    inherited models first.\n    \"\"\"\n    Animal = ModelState(\n        \"app\",\n        \"Animal\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n        ],\n    )\n    Dog = ModelState(\"app\", \"Dog\", [], bases=(\"app.Animal\",))\n    Cat = ModelState(\"app\", \"Cat\", [], bases=(\"app.Animal\",))\n    changes = self.get_changes([Animal, Dog, Cat], [Animal])\n    self.assertNumberMigrations(changes, \"app\", 1)\n    self.assertOperationTypes(changes, \"app\", 0, [\"DeleteModel\", \"DeleteModel\"])\n    self.assertOperationAttributes(changes, \"app\", 0, 0, name=\"Cat\")\n    self.assertOperationAttributes(changes, \"app\", 0, 1, name=\"Dog\")\n", "def test_add_field_with_unique(self):\n    \"\"\"#22951 -- Adding a field with a unique constraint should work.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_name])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n\n    # Adding a field with a unique constraint that already exists should\n    # automatically change the field to be unique.\n    changes = self.get_changes([self.author_empty, self.author_name], [self.author_name])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 0)\n\n    # Adding a field with a unique constraint that already exists should\n    # automatically change the field to be unique.\n    changes = self.get_changes([self.author_empty, self.author_name], [self.author_name])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 0)\n\n    # Adding a field with a unique constraint that already exists should\n    # automatically change the field to be unique.\n    changes = self.get_changes(\n        [self.author_empty, self.author_name], [self.author_empty, self.author_name]\n    )\n    # Right number/type of migrations?\n    self.assertEqual(len(changes), 0)\n\n    # Adding a field with a unique constraint that already exists should\n    # automatically change the field to be unique.\n    changes = self.get_changes(\n        [self.author_empty, self.author_name],\n        [self.author_empty, self.author_name, self.author_name],\n    )\n    # Right number/type of migrations?\n    self.assertEqual(len(changes), 0)\n", "def test_proxy_model_delete_related_fields(self):\n    \"\"\"Tests deletion of fields in related models of a proxy model.\"\"\"\n    # First, we test deleting a related field that does not depend on any other\n    # migrations. This must not be split into two migrations.\n    changes = self.get_changes(\n        [self.author_empty, self.author_proxy, self.author_with_book],\n        [self.author_empty, self.author_proxy, self.book],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"DeleteModel\", \"DeleteModel\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"AuthorProxy\")\n    self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"Book\")\n    self.assertOperationAttributes(changes, \"testapp\", 0, 2, name=\"Author\")\n\n    # Now, we test a related field that depends on a migration. This should be\n    # split into two migrations. The related field should be removed first.\n    changes = self.get_changes(\n        [self.author_empty, self.author_proxy, self.author_with_m2m],\n        [self.author_empty, self.author_proxy, self.book],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(\n        changes, \"testapp\", 0, [\"DeleteModel\", \"RemoveField\", \"DeleteModel\"]\n    )\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"AuthorProxy\")\n    self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"publishers\", model_name=\"author\")\n    self.assertOperationAttributes(changes, \"testapp\", 0, 2, name=\"Author\")\n"], "sample_137": ["def test_permute_signs():\n    assert list(permute_signs([1, 0, 2])) == [(1, 0, 2), (1, 0, -2), (1, -2, 2), (1, 2, 2), (1, -2, -2),\n                                              (1, 2, -2), (-1, 0, 2), (-1, 0, -2), (-1, -2, 2), (-1, 2, 2),\n                                              (-1, -2, -2), (-1, 2, -2)]\n    assert list(permute_signs([0, 0, 0])) == [(0, 0, 0)]\n    assert list(signed_permutations([1, 0, 2])) == [\n        (1, 0, 2), (1, 0, -2), (1, -2, 2), (1, 2, 2), (1, -2, -2),\n        (1, 2, -2), (-1, 0, 2), (-1, 0, -2), (-1, -2, 2), (-1, 2, 2),\n        (-1, -2, -2), (-1, 2, -2), (2, 0, 1), (-2, 0, 1), (2, 0, -1),\n        (-2, 0, -1), (2, 1, 0), (-2, 1, 0), (2, -1, 0), (-2, -1, 0),\n        (2, 1, -1), (-2, 1, -1), (2, -1, -1), (-2, -1, -1)]\n", "def test_generate_oriented_forest_with_zero():\n    assert list(generate_oriented_forest(3)) == [[0, 1, 2], [0, 1, 1], [0, 1, 0], [0, 0, 1],\n                                               [0, 0, 0], [1, 1, 2], [1, 1, 1],\n                                               [1, 1, 0], [1, 0, 2], [1, 0, 1],\n                                               [1, 0, 0], [2, 1, 2], [2, 1, 1],\n                                               [2, 1, 0], [2, 0, 2], [2, 0, 1],\n                                               [2, 0, 0]]\n    assert len(list(generate_oriented_forest(10))) == 1842\n", "def test_reshape():\n    assert reshape([1, 2, 3, 4, 5, 6], [2, 1, 3]) == \\\n        [[1, 2], 3, [4, 5, 6]]\n    assert reshape([1, 2, 3, 4, 5, 6], [[2], 1, 3]) == \\\n        [[1, 2], [3], [4, 5, 6]]\n    assert reshape([1, 2, 3, 4, 5, 6], ([2], 1, 3)) == \\\n        [[1, 2], [3], [4, 5, 6]]\n    assert reshape([1, 2, 3, 4, 5, 6], [2, (1,), 3]) == \\\n        [[1, 2], (3,), [4, 5, 6]]\n    assert reshape([1, 2, 3, 4, 5, 6], [[2], (1,), 3]) == \\\n        [[1, 2], (3,), [4, 5, 6]]\n    assert reshape([1, 2, 3, 4, 5, 6], ([2], (1,), 3)) == \\\n        [[1, 2], (3,), [4, 5, 6]]\n    assert reshape([1, 2, 3, 4, 5, 6], [2, [1], 3]) == \\\n        [[1, 2], [3], [4, 5, 6]]\n    assert reshape([1, 2, 3, 4, 5, 6], [[2], [1], 3]) == \\\n        [[1, 2], [3], [4, 5, 6]]\n    assert reshape([1, 2, 3, 4, 5, 6], ([2], [1], 3)) == \\\n        [[1, 2], [3], [4, 5, 6]]\n    assert reshape([1, 2, 3, 4, 5, 6], [2, 1, (3,)]) == \\\n        [[1, 2], [3], (4", "def test_generate_oriented_forest_coverage():\n    assert len(list(generate_oriented_forest(4))) == 38\n    assert len(list(generate_oriented_forest(5))) == 1842\n    assert len(list(generate_oriented_forest(6))) == 18401\n    assert len(list(generate_oriented_forest(7))) == 184185\n    assert len(list(generate_oriented_forest(8))) == 1856402\n    assert len(list(generate_oriented_forest(9))) == 18513980\n    assert len(list(generate_oriented_forest(10))) == 185835057\n", "def test_reshape():\n    assert reshape([0, 1, 2], 3) == [[0], [1], [2]]\n    assert reshape([0, 1, 2], (3,)) == [(0,), (1,), (2,)]\n    assert reshape([0, 1, 2], (2, 2)) == [(0, 1), (1, 2), (2, 0)]\n    assert reshape([0, 1, 2], (2, [2])) == [(0, [1]), (1, [2]), (2, [0])]\n    assert reshape([0, 1, 2], ((2,), [2])) == [((0, 1), [2]), ((1, 2), [0])]\n    assert reshape([0, 1, 2], (1, [2], 1)) == [(0, [1], 2), (1, [2], 0), (2, [0], 1)]\n    assert reshape(tuple([0, 1, 2]), ([[0], 1, (1,)],)) == \\\n        (([[0], 1, (1,)],),)\n    assert reshape(tuple([0, 1, 2]), ([0], 1, (1,))) == \\\n        (([0], 1, (1,)),)\n    assert reshape(list(range(3)), [3, [1], {1}, (0, (1,), 1)]) == \\\n        [[0, 1, 2]]\n\n    # Test incorrect reshape value\n    raises(ValueError, lambda: reshape(list(range(3)), [2]))\n    raises(ValueError, lambda: reshape(list(range(3)), [-1]))\n    raises(ValueError, lambda: reshape(list(range(3)), [1, -1]))\n"], "sample_86": ["def test_record_property_overwrite(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_property(\"foo\", \"bar\")\n            record_property(\"foo\", \"baz\")\n            record_property(\"foo\", \"qux\")\n    \"\"\"\n    )\n    result, dom = runandparse(testdir, \"-rw\")\n    node = dom.find_first_by_tag(\"testsuite\")\n    tnode = node.find_first_by_tag(\"testcase\")\n    psnode = tnode.find_first_by_tag(\"properties\")\n    pnodes = psnode.find_by_tag(\"property\")\n    pnodes[0].assert_attr(name=\"foo\", value=\"baz\")\n    pnodes[1].assert_attr(name=\"foo\", value=\"qux\")\n", "def test_record_testsuite_property_non_string_value(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", \"all good\")\n\n            record_testsuite_property(\"stats\", 10)\n    \"\"\"\n    )\n    result, dom = runandparse(testdir, \"-o\", \"junit_family=xunit2\")\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    assert properties_node == \"\"\n", "def test_record_testsuite_property_with_unicode_name(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"\u00dfSTATS\", \"all good\")\n\n            record_testsuite_property(\"STATS\", 10)\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p2_node = properties_node.find_nth_by_tag(\"property\", 1)\n    p1_node.assert_attr(name=\"\u00dfSTATS\", value=\"all good\")\n    p2_node.assert_attr(name=\"STATS\", value=\"10\")\n", "def test_record_attribute_xunit1(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        junit_family = xunit1\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            record_xml_attribute(\"bar\", 1)\n            record_xml_attribute(\"foo\", \"<1\");\n    \"\"\"\n    )\n    result, dom = runandparse(testdir, \"-rw\")\n    node = dom.find_first_by_tag(\"testsuite\")\n    tnode = node.find_first_by_tag(\"testcase\")\n    assert 'foo=\"&lt;1&quot;\"' in tnode.toxml()\n    assert 'bar=\"1\"' not in tnode.toxml()\n    result.stdout.fnmatch_lines(\n        [\"*test_record_attribute.py:6:*record_xml_attribute is an experimental feature\"]\n    )\n", "def test_record_attribute_with_duplicate_names_xunit1(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        junit_family = xunit1\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            record_xml_attribute(\"bar\", 1)\n            record_xml_attribute(\"foo\", \"<1\");\n            record_xml_attribute(\"foo\", \"<2\");\n    \"\"\"\n    )\n    result, dom = runandparse(testdir, \"-rw\")\n    node = dom.find_first_by_tag(\"testsuite\")\n    tnode = node.find_first_by_tag(\"testcase\")\n    tnode.assert_attr(bar=\"1\")\n    pnodes = tnode.find_by_tag(\"properties\")\n    pnodes = pnodes[1:]  # skip the one that wasn't added because xunit1 doesn't allow duplicate names\n    expected = [\n        {\"name\": \"foo\", \"value\": \"<1\"},\n        {\"name\": \"foo\", \"value\": \"<2\"},\n    ]\n    for i, pnode in enumerate(pnodes):\n        pnode.assert_attr(**expected[i])\n"], "sample_83": ["def test_colorized_output_deprecated():\n    \"\"\"TODO remove in 3.0.\"\"\"\n    with warnings.catch_warnings(record=True) as cm:\n        warnings.simplefilter(\"always\")\n        ColorizedTextReporter()\n\n    assert len(cm) == 1\n    assert isinstance(cm[0].message, DeprecationWarning)\n", "def test_colorized_reporter():\n    output = StringIO()\n    linter = PyLinter(reporter=ColorizedTextReporter(output=output))\n    checkers.initialize(linter)\n    linter.config.persistent = 0\n    linter.open()\n    linter.set_current_module(\"my_module\")\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n    linter.add_message(\n        \"line-too-long\", line=2, end_lineno=2, end_col_offset=4, args=(3, 4)\n    )\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert out_lines[1] == \"my_module:1:0: C0301: Line too long (1/2) (line-too-long)\"\n    assert out_lines[2] == \"my_module:2:0: C0301: Line too long (3/4) (line-too-long)\"\n    assert output.getvalue().endswith(\"\\x1b[0m\")\n", "def test_colorized_reporter(linter: PyLinter):\n    \"\"\"Test the ColorizedTextReporter.\"\"\"\n    output = StringIO()\n    linter.reporter.out = output\n    linter.config.msg_template = \"{path}:{line}:{column}: {msg_id}: {msg}\"\n    linter.open()\n    linter.set_current_module(\"my_mod\")\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n    linter.add_message(\n        \"line-too-long\", line=2, end_lineno=2, end_col_offset=4, args=(3, 4)\n    )\n\n    linter.reporter = ColorizedTextReporter(output)\n\n    assert linter.reporter._get_decoration(\"C\") == MessageStyle(\"magenta\", (\"bold\",))\n    assert linter.reporter._get_decoration(\"R\") == MessageStyle(\"magenta\", (\"bold\", \"italic\"))\n    assert linter.reporter._get_decoration(\"I\") == MessageStyle(\"green\")\n    assert linter.reporter._get_decoration(\"W\") == MessageStyle(\"magenta\")\n    assert linter.reporter._get_decoration(\"E\") == MessageStyle(\"red\", (\"bold\",))\n    assert linter.reporter._get_decoration(\"F\") == MessageStyle(\"red\", (\"bold\", \"underline\"))\n    assert linter.reporter._get_decoration(\"S\") == MessageStyle(None)\n\n    linter.reporter.handle_message(linter.linter.messages[0])\n    output_value = output.getvalue()\n    assert output_value.startswith(\"my_mod:1:0: C0301: Line too long (1/2) \")\n    assert output_value.startswith(ANSI_PREFIX)\n\n    # Test that the reporter correctly handles unknown message types\n    linter.reporter.handle_message(Message(\"unknown\", \"C9999\", \"my_mod\", 1, 2, \"\"))\n    output_value = output.getvalue()\n    assert \"my_mod:1:0: C9999: \" in output_value\n    assert output_value.startswith(ANSI_PREFIX)\n", "def test_colorized_reporter_output(tmp_path):\n    \"\"\"Test the output of the colorized reporter.\"\"\"\n    output = StringIO()\n    linter = PyLinter()\n    linter.load_default_plugins()\n    linter.set_option(\"persistent\", False)\n    linter.set_option(\"output-format\", \"colorized\")\n    linter.set_option(\"colorized-report\", True)\n\n    # ColorizedTextReporter should support both string and MessageStyle color arguments\n    color_mapping = {\n        \"I\": \"green\",\n        \"C\": \"bold\",\n        \"R\": \"magenta bold\",\n        \"W\": \"magenta\",\n        \"E\": \"red bold\",\n        \"F\": \"red underline\",\n        \"S\": \"yellow inverse\",\n    }\n    linter.reporter = ColorizedTextReporter(output, color_mapping=color_mapping)\n\n    source_file = tmp_path / \"somemodule.py\"\n    source_file.write_text('NOT_EMPTY = \"This module is not empty\"\\n')\n    linter.check_single_file_item(FileItem(\"somemodule\", source_file, \"somemodule\"))\n    linter.add_message(\"line-too-long\", line=1, args=(1, 2))\n\n    linter.generate_reports()\n    output_value = output.getvalue()\n\n    # Test if the output is as expected\n    expected_output = (\n        \"\\033[38;5;40m************* Module somemodule\\033[0m\\n\"\n        \"\\033[38;5;40m************* somemodule\\033[0m\\n\"\n        \"\\033[32mC0301: Line too long (1/2) (line-too-long)\\033[0m\\n\"\n    )\n    assert output_value == expected_output\n", "def test_colorize_ansi_deprecation(recwarn):\n    \"\"\"Test that colorize_ansi still accepts color and style parameters for backwards compatibility.\"\"\"\n    # noinspection PyDeprecation\n    msg_style = ColorizedTextReporter._get_decoration(\"C\")\n    warnings.simplefilter(\"always\")\n    with pytest.warns(DeprecationWarning) as warnings_rec:\n        msg_style = MessageStyle(\"red\", (\"bold\",))\n        colorize_ansi(\"test message\", msg_style)\n        assert len(warnings_rec) == 1\n        assert \"In pylint 3.0, the colorize_ansi function of Text reporters will only accept a MessageStyle parameter\" in str(warnings_rec[-1].message)\n\n    assert len(recwarn) == 1\n    assert \"In pylint 3.0, the colorize_ansi function of Text reporters will only accept a MessageStyle parameter\" in str(recwarn[-1].message)\n    assert colorize_ansi(\"test message\", msg_style).startswith(\"\\033[91m\")  # Red color\n"], "sample_7": ["    def test_tick_no_new_files(self):\n        with self.tick_twice():\n            self.assertEqual(self.reloader.tick().__next__(), None)\n", "    def test_tick(self):\n        # Call tick() multiple times to ensure it works correctly\n        with self.tick_twice() as ticker:\n            self.assertEqual(next(ticker), None)\n        with self.tick_twice() as ticker:\n            self.assertEqual(next(ticker), None)\n        with self.tick_twice() as ticker:\n            self.assertEqual(next(ticker), None)\n", "    def setUp(self):\n        self._tempdir = tempfile.TemporaryDirectory()\n        self.tempdir = Path(self._tempdir.name).resolve().absolute()\n        self.existing_file = self.ensure_file(self.tempdir / 'test.py')\n        self.nonexistent_file = (self.tempdir / 'does_not_exist.py').absolute()\n        self.reloader = autoreload.StatReloader()\n", "    def setUp(self):\n        self._tempdir = tempfile.TemporaryDirectory()\n        self.tempdir = Path(self._tempdir.name).resolve().absolute()\n        self.existing_file = self.ensure_file(self.tempdir / 'test.py')\n        self.nonexistent_file = (self.tempdir / 'does_not_exist.py').absolute()\n        self.reloader = autoreload.StatReloader()\n", "    def setUp(self):\n        self._tempdir = tempfile.TemporaryDirectory()\n        self.tempdir = Path(self._tempdir.name).resolve().absolute()\n"], "sample_22": ["def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('hello World'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('hello-world'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('hello-World'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('hello-World-'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces(''), '')\n    self.assertEqual(text.camel_case_to_spaces('a-b-c'), 'a b c')\n", "def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('hello_World'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('hello-world'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('hello_World123'), 'hello world123')\n    self.assertEqual(text.camel_case_to_spaces(lazystr('HelloWorld')), 'hello world')\n", "def test_camel_case_to_spaces(self):\n    items = (\n        ('HelloWorld', 'hello world'),\n        ('helloWorld', 'hello world'),\n        ('hello WORLD', 'hello world'),\n        ('Hello', 'hello'),\n        ('', ''),\n        ('hello world', 'hello world'),  # test that it doesn't change existing spaces\n        ('hello-world', 'hello world'),  # test that it converts hyphens to spaces\n    )\n    for value, expected in items:\n        self.assertEqual(text.camel_case_to_spaces(value), expected)\n        self.assertEqual(text.camel_case_to_spaces(lazystr(value)), expected)\n\n    # Test with unicode\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld\u00e4\u00f6\u00fc'), 'hello world\u00e4\u00f6\u00fc')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld\u00e4\u00f6\u00fc'), 'hello world\u00e4\u00f6\u00fc')\n\n    # Test with camel case in the middle of the string\n    self.assertEqual(text.camel_case_to_spaces('hello worldHelloWorld'), 'hello world hello world')\n", "def test_get_valid_filename(self):\n    filename = \"test!\"\n    self.assertEqual(text.get_valid_filename(filename), \"test\")\n    self.assertEqual(text.get_valid_filename(lazystr(filename)), \"test\")\n\n    filename = \"   test   \"\n    self.assertEqual(text.get_valid_filename(filename), \"test\")\n    self.assertEqual(text.get_valid_filename(lazystr(filename)), \"test\")\n\n    filename = \"test:valid:filename.txt\"\n    self.assertEqual(text.get_valid_filename(filename), \"test-valid-filename.txt\")\n    self.assertEqual(text.get_valid_filename(lazystr(filename)), \"test-valid-filename.txt\")\n\n    filename = \"test invalid:filename.txt\"\n    self.assertEqual(text.get_valid_filename(filename), \"test-invalid-filename.txt\")\n    self.assertEqual(text.get_valid_filename(lazystr(filename)), \"test-invalid-filename.txt\")\n\n    filename = \"test*invalid:filename.txt\"\n    self.assertEqual(text.get_valid_filename(filename), \"test-invalid-filename.txt\")\n    self.assertEqual(text.get_valid_filename(lazystr(filename)), \"test-invalid-filename.txt\")\n\n    filename = \"!test!invalid:filename.txt\"\n    self.assertEqual(text.get_valid_filename(filename), \"test-invalid-filename.txt\")\n    self.assertEqual(text.get_valid_filename(lazystr(filename)), \"test-invalid-filename.txt\")\n", "    def test_camel_case_to_spaces(self):\n        self.assertEqual(text.camel_case_to_spaces('HelloWorld'), 'hello world')\n        self.assertEqual(text.camel_case_to_spaces('helloWorld'), 'hello world')\n        self.assertEqual(text.camel_case_to_spaces('world'), 'world')\n        self.assertEqual(text.camel_case_to_spaces(''), '')\n        self.assertEqual(text.camel_case_to_spaces('Hello-World'), 'hello-world')\n        self.assertEqual(text.camel_case_to_spaces('hello-world'), 'hello-world')\n        self.assertEqual(text.camel_case_to_spaces('world'), 'world')\n"], "sample_72": ["def test_figure_subplot_params():\n    fig = plt.figure()\n    params = fig.subplotpars\n    assert params.left == mpl.rcParams['figure.subplot.left']\n    assert params.bottom == mpl.rcParams['figure.subplot.bottom']\n    assert params.right == mpl.rcParams['figure.subplot.right']\n    assert params.top == mpl.rcParams['figure.subplot.top']\n    assert params.wspace == mpl.rcParams['figure.subplot.wspace']\n    assert params.hspace == mpl.rcParams['figure.subplot.hspace']\n\n    # Test updating with some parameters\n    params.update(left=0.1, top=0.8, wspace=0.2)\n    assert params.left == 0.1\n    assert params.top == 0.8\n    assert params.wspace == 0.2\n    assert params.bottom == mpl.rcParams['figure.subplot.bottom']\n    assert params.right == mpl.rcParams['figure.subplot.right']\n    assert params.top == 0.8\n\n    # Test invalid parameters\n    with pytest.raises(ValueError):\n        params.update(left=0.1, right=0.1)\n    with pytest.raises(ValueError):\n        params.update(bottom=0.1, top=0.1)\n", "def test_figure_savefig():\n    fig = plt.figure()\n    fig.text(0.5, 0.5, 'Hello', ha='center', va='center')\n    fig.savefig('test.png')\n    assert os.path.exists('test.png')\n    os.remove('test.png')\n\n    fig.savefig('test.png', facecolor='blue')\n    assert os.path.exists('test.png')\n    os.remove('test.png')\n\n    fig.savefig('test.pdf', format='pdf')\n    assert os.path.exists('test.pdf')\n    os.remove('test.pdf')\n\n    fig.savefig('test.jpg', format='jpg')\n    assert os.path.exists('test.jpg')\n    os.remove('test.jpg')\n\n    fig.savefig('test.png', bbox_inches='tight')\n    assert os.path.exists('test.png')\n    os.remove('test.png')\n\n    fig.savefig('test.png', dpi=100)\n    assert os.path.exists('test.png')\n    os.remove('test.png')\n\n    fig.savefig('test.png', pad_inches=0.5)\n    assert os.path.exists('test.png')\n    os.remove('test.png')\n\n    fig.savefig('test.png', facecolor='red', edgecolor='green')\n    assert os.path.exists('test.png')\n    os.remove('test.png')\n", "def test_set_subplotpars():\n    fig = plt.figure()\n    # Test defaults\n    fig.subplotpars.left = 0.1\n    assert fig.subplotpars.left == 0.1\n    assert fig.subplotpars.bottom == 0.1\n    assert fig.subplotpars.right == 0.9\n    assert fig.subplotpars.top == 0.9\n    assert fig.subplotpars.wspace == 0.2\n    assert fig.subplotpars.hspace == 0.2\n\n    # Test setting individual parameters\n    fig.subplotpars.left = 0.1\n    fig.subplotpars.bottom = 0.2\n    fig.subplotpars.right = 0.3\n    fig.subplotpars.top = 0.4\n    fig.subplotpars.wspace = 0.5\n    fig.subplotpars.hspace = 0.6\n    assert fig.subplotpars.left == 0.1\n    assert fig.subplotpars.bottom == 0.2\n    assert fig.subplotpars.right == 0.3\n    assert fig.subplotpars.top == 0.4\n    assert fig.subplotpars.wspace == 0.5\n    assert fig.subplotpars.hspace == 0.6\n\n    # Test invalid input\n    with pytest.raises(ValueError):\n        fig.subplotpars.update(left=-1)\n    with pytest.raises(ValueError):\n        fig.subplotpars.update(bottom=-1)\n    with pytest.raises(ValueError):\n        fig.subplotpars.update(right=-1)\n    with pytest.raises(ValueError):\n        fig.subplotpars.update(top=-1)\n    with pytest.raises(ValueError):\n        fig.subplotpars.update(wspace=-1)\n    with pytest.raises(ValueError):\n        fig.subplotpars.update(hspace=-1)\n", "def test_align_labels():\n    fig, axs = plt.subplots(1, 3)\n    for i, ax in enumerate(axs):\n        ax.set_title('Label', loc='left')\n        ax.set_xlabel('XLabel')\n        ax.set_ylabel('YLabel')\n    fig.align_labels(axs[0])\n    fig.canvas.draw()\n    fig.canvas.flush_events()\n    # This test can be made more robust by checking the actual position of the\n    # labels, but that is quite complicated. Here, we just check that the\n    # labels don't get removed.\n    assert len(axs[0].get_xticklabels()) == 1\n    assert len(axs[0].get_yticklabels()) == 1\n", "def test_figure_subplot_mosaic():\n    fig, axs = plt.subplots(1, 2)\n    # basic usage\n    mosaic = [['A', 'B'], ['C', 'D']]\n    ret = fig.subplot_mosaic(mosaic)\n    assert len(ret) == 4\n    assert list(ret.keys()) == ['A', 'B', 'C', 'D']\n\n    # nested mosaic\n    mosaic = [['A', 'B'], ['C', ['D', 'E']]]\n    ret = fig.subplot_mosaic(mosaic)\n    assert len(ret) == 4\n    assert list(ret.keys()) == ['A', 'B', 'D', 'E']\n\n    # empty sentinel\n    mosaic = [['A', '.'], ['C', 'D']]\n    ret = fig.subplot_mosaic(mosaic)\n    assert len(ret) == 3\n    assert list(ret.keys()) == ['A', 'C', 'D']\n\n    # sharex and sharey\n    fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n    mosaic = [['A', 'B'], ['C', 'D']]\n    ret = fig.subplot_mosaic(mosaic, sharex=True, sharey=True)\n    assert len(ret) == 4\n    assert list(ret.keys()) == ['A', 'B', 'C', 'D']\n    for ax in axs.flat:\n        assert ax.get_shared_x_axes().all_shared()\n\n    # subplotspec\n    gs = fig.add_gridspec(2, 2)\n    ret = fig.subplot_mosaic(mosaic, subplot_kw={'subplotspec': gs[:, :]})\n    assert len(ret) == 4\n    assert list(ret.keys()) == ['A', 'B', 'C', 'D']\n\n    # validate error messages\n    with pytest.raises(ValueError, match='List mosaic specification must be 2D'):\n        fig.subplot_mosaic([['A', 'B'], ['C']])\n    with pytest.raises(ValueError, match='List mosaic specification must be 2D'):\n        fig.subplot_mosaic([['A', 'B'], ['C', ['D']]))\n    with pytest.raises(ValueError, match='List mosaic specification must be 2D'):\n        fig.subplot_mosaic(['A', 'B'])\n    with pytest.raises(ValueError, match='All of the rows must be the same length'):\n        fig.subplot_mosaic([['A', 'B', 'C"], "sample_150": ["def test_solve_generic():\n    assert solve_generic([x - y, y - x], x, y) is None\n\n    assert solve_generic([y**2 - 1, y - 2], x, y) == [(1, 1), (-1, -1)]\n\n    assert solve_generic([y - x, y - x + 1], x, y) is None\n\n    assert solve_generic([x - 2, y - 1], x, y) == [(2, 1)]\n\n    assert solve_generic([y - x**2, y + x**2 + 1], x, y) == \\\n        [(-I*sqrt(S.Half), Rational(-1, 2)), (I*sqrt(S.Half), Rational(-1, 2))]\n\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n\n    a, b = sqrt(2) - 1, -sqrt(2) - 1\n\n    assert solve_generic([f_1, f_2, f_3], x, y, z) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0), (a, a, a), (b, b, b)]\n\n    solution = [(1, -1), (1, 1)]\n\n    assert solve_generic([Poly(x**2 - y**2), Poly(x - 1)]) == solution\n    assert solve_generic([x**2 - y**2, x - 1], x, y) == solution\n    assert solve_generic([x**2 - y**2, x - 1]) == solution\n\n    assert solve_generic(\n        [x + x*y - 3, y + x*y - 4], x, y) == [(-3, -2), (1, 2)]\n\n    raises(NotImplementedError, lambda: solve_generic([x**3 - y**3], x, y))\n    raises(NotImplementedError, lambda: solve_generic(\n        [z, -2*x*y**2 + x + y**2*z, y**2*(-z - 4) + 2]))\n    raises(PolynomialError, lambda: solve_generic([1/x", "def test_solve_generic():\n    x, y, z = symbols('x y z')\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n\n    a, b = sqrt(2) - 1, -sqrt(2) - 1\n\n    assert solve_generic([f_1, f_2, f_3], (x, y, z)) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0), (a, a, a), (b, b, b)]\n\n    solution = [(1, -1), (1, 1)]\n\n    assert solve_generic([Poly(x**2 - y**2), Poly(x - 1)], (x, y)) == solution\n    assert solve_generic([x**2 - y**2, x - 1], (x, y)) == solution\n\n    raises(NotImplementedError, lambda: solve_generic([x**3 - y**3], (x, y)))\n    raises(NotImplementedError, lambda: solve_generic(\n        [z, -2*x*y**2 + x + y**2*z, y**2*(-z - 4) + 2], (x, y, z)))\n    raises(PolynomialError, lambda: solve_generic([1/x], x))\n\n    raises(NotImplementedError, lambda: solve_generic(\n          [x-1,], (x, y)))\n    raises(NotImplementedError, lambda: solve_generic(\n          [y-1,], (x, y)))\n\n    f_1 = x + y + z - 1\n    f_2 = x + y + z**2 - 1\n    f_3 = x**2 + y + z - 1\n\n    assert solve_generic([f_1, f_2, f_3], (x, y, z)) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0), (a, a, a), (b, b, b)]\n\n    # Check for some non-zero-dimensional system\n    raises(NotImplementedError, lambda: solve_generic([x + y + z - 1,", "def test_solve_generic():\n    x, y = symbols('x y')\n    assert solve_generic([x + y - 3], x, y) == [(2, -1)]\n    assert solve_generic([x - 2*y + 5, 2*x - y - 3], x, y) == [(11/3, 13/3)]\n    assert solve_generic([x**2 + y, x + y*4], x, y) == [(0, 0), (1/4, -1/16)]\n\n    x, y, z = symbols('x y z')\n    assert solve_generic([x + y + z - 1, x + y**2 + z - 1, x + y + z**2 - 1], x, y, z) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0)]\n\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n\n    a, b = sqrt(2) - 1, -sqrt(2) - 1\n\n    assert solve_generic([f_1, f_2, f_3], x, y, z) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0), (a, a, a), (b, b, b)]\n\n    assert solve_generic([x**2 - y**2, x - 1], x, y) == [(1, 1), (-1, -1)]\n\n    x0, y0, z0 = symbols('x0 y0 z0')\n    assert solve_generic([x0**2 - y0**2, y0**2 - z0], x0, y0, z0) == [(0, 0, 0)]\n    assert solve_generic([x0**2 - y0**2, y0**2 - 1], x0, y0) == [(0, -1), (0, 1)]\n\n    raises(PolynomialError, lambda: solve_generic([1/x], x))\n    raises(NotImplementedError, lambda: solve_generic([x**3 - y**3", "def test_solve_generic():\n    x, y = symbols('x y')\n\n    # Test a system with three equations\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n\n    assert solve_generic([f_1, f_2, f_3], x, y, z) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0), (sqrt(2) - 1, sqrt(2) - 1, sqrt(2) - 1), \\\n         (-sqrt(2) - 1, -sqrt(2) - 1, -sqrt(2) - 1)]\n\n    # Test a system with four equations\n    f_1 = x**3 + y + z + w - 1\n    f_2 = x + y**2 + z + w - 1\n    f_3 = x + y + z**2 + w - 1\n    f_4 = x + y + z + w**2 - 1\n\n    assert solve_generic([f_1, f_2, f_3, f_4], x, y, z, w) is None\n\n    # Test a system with one equation\n    f_1 = x - 1\n    assert solve_generic([f_1], x) == [(1,)]\n\n    # Test a system with two equations\n    f_1 = x + y - 2\n    f_2 = x + y + 2\n\n    assert solve_generic([f_1, f_2], x, y) == []\n\n    # Test a system with zero equations\n    assert solve_generic([], x, y, z, w) is None\n\n    # Test a system with no variables\n    assert solve_generic([x - 1], ) is None\n\n    # Test a system with non-polynomial equations\n    f_1 = x**2 + sin(y) - 1\n    f_2 = x + y**2 - 1\n\n    raises(SolveFailed, lambda: solve_generic([f_1, f_2], x, y))\n\n    # Test a system with non-algebraic coefficients\n    f_1 = x", "def test_solve_generic():\n    x, y, z = symbols('x y z')\n\n    # Testing systems with more than 3 equations\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n    f_4 = x + y + z - 3\n\n    assert solve_generic([f_1, f_2, f_3, f_4], x, y, z) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0)]\n\n    # Testing systems with no solutions\n    f_1 = x + y + z - 2\n    f_2 = x + y + z - 2\n    assert solve_generic([f_1, f_2], x, y, z) == None\n\n    # Testing systems with a variable only appearing in one equation\n    f_1 = x + y + z - 2\n    f_2 = x + y - 2\n    assert solve_generic([f_1, f_2], x, y, z) == [(0, -2, 2)]\n\n    # Testing systems with a variable not appearing in the equations\n    f_1 = x + y - 2\n    f_2 = y + z - 2\n    assert solve_generic([f_1, f_2], x, y, z) == [(-2, 0, 2)]\n\n    # Testing systems with only one equation\n    f_1 = x + y + z - 2\n    assert solve_generic([f_1], x, y, z) == None\n\n    # Testing systems with two equations, one of which is identically zero\n    f_1 = x + y + z - 2\n    f_2 = 0\n    assert solve_generic([f_1, f_2], x, y, z) == [(-2, 0, 2)]\n\n    # Testing systems with one equation, and the variable only appearing in the\n    # equation with degree 0\n    f_1 = z - 2\n    assert solve_generic([f_1], x, y, z) == [(2, 0, 0)]\n"], "sample_40": ["def test_boundfield_subwidgets(self):\n    class SomeForm(Form):\n        field = MultipleChoiceField(\n            choices=[('a', 'A'), ('b', 'B')],\n            widget=RadioSelect,\n        )\n\n    form = SomeForm(auto_id=False)\n    self.assertEqual(len(form['field'].subwidgets), 2)\n    self.assertEqual(form['field'].subwidgets[0].choice_label, 'A')\n    self.assertEqual(form['field'].subwidgets[1].choice_label, 'B')\n\n    form = SomeForm({'field': 'a'}, auto_id=False)\n    self.assertEqual(len(form['field'].subwidgets), 2)\n    self.assertEqual(form['field'].subwidgets[0].checked, True)\n    self.assertEqual(form['field'].subwidgets[1].checked, False)\n\n    form = SomeForm({'field': 'b'}, auto_id=False)\n    self.assertEqual(len(form['field'].subwidgets), 2)\n    self.assertEqual(form['field'].subwidgets[0].checked, False)\n    self.assertEqual(form['field'].subwidgets[1].checked, True)\n\n    form = SomeForm({'field': 'a', 'other': 'other'}, auto_id=False)\n    self.assertEqual(len(form['field'].subwidgets), 2)\n    self.assertEqual(form['field'].subwidgets[0].checked, True)\n    self.assertEqual(form['field'].subwidgets[1].checked, False)\n", "def test_boundfield_label_suffix(self):\n    class SomeForm(Form):\n        field = CharField()\n\n    form = SomeForm()\n    boundfield = form['field']\n\n    testcases = [  # (args, kwargs, expected)\n        # without anything: just print the <label>\n        ((), {}, '<label for=\"id_field\">Field:</label>'),\n\n        # passing just one argument: overrides the field's label\n        (('custom',), {}, '<label for=\"id_field\">custom:</label>'),\n\n        # the overridden label is escaped\n        (('custom&',), {}, '<label for=\"id_field\">custom&amp;:</label>'),\n        ((mark_safe('custom&'),), {}, '<label for=\"id_field\">custom&:</label>'),\n\n        # Passing attrs to add extra attributes on the <label>\n        ((), {'attrs': {'class': 'pretty'}}, '<label for=\"id_field\" class=\"pretty\">Field:</label>'),\n\n        # Form.label_suffix is used to create the label\n        ((), {'label_suffix': '!'}, '<label for=\"id_field\">Field!</label>'),\n        ((mark_safe('custom!'),), {'label_suffix': '!'}, '<label for=\"id_field\">custom!</label>'),\n        ((mark_safe('custom!'),), {'label_suffix': mark_safe('!')}, '<label for=\"id_field\">custom!</label>'),\n\n        # Label suffix is applied even if field's label doesn't end with punctuation\n        ((), {'label_suffix': '!'}, '<label for=\"id_field\">Field:</label>'),\n    ]\n\n    for args, kwargs, expected in testcases:\n        with self.subTest(args=args, kwargs=kwargs):\n            self.assertHTMLEqual(boundfield.label_tag(*args, **kwargs), expected)\n", "def test_boundfield_iterable_checkbox(self):\n    # Test that you can iterate over an iterable BoundField with CheckboxSelectMultiple.\n    class BeatleForm(Form):\n        name = ChoiceField(\n            choices=[('john', 'John'), ('paul', 'Paul'), ('george', 'George'), ('ringo', 'Ringo')],\n            widget=CheckboxSelectMultiple,\n        )\n\n    f = BeatleForm(auto_id=False)\n    bf = f['name']\n    self.assertEqual([str(item) for item in bf], [\n        '<input type=\"checkbox\" name=\"name\" value=\"john\"> John',\n        '<input type=\"checkbox\" name=\"name\" value=\"paul\"> Paul',\n        '<input type=\"checkbox\" name=\"name\" value=\"george\"> George',\n        '<input type=\"checkbox\" name=\"name\" value=\"ringo\"> Ringo'\n    ])\n    self.assertEqual([str(item) for item in bf[1:]], [\n        '<input type=\"checkbox\" name=\"name\" value=\"paul\"> Paul',\n        '<input type=\"checkbox\" name=\"name\" value=\"george\"> George',\n        '<input type=\"checkbox\" name=\"name\" value=\"ringo\"> Ringo'\n    ])\n\n    # Test that BoundField correctly handles indexing and slicing with an iterable BoundField.\n    self.assertEqual(str(bf[0]), '<input type=\"checkbox\" name=\"name\" value=\"john\"> John')\n    self.assertEqual(str(bf[1]), '<input type=\"checkbox\" name=\"name\" value=\"paul\"> Paul')\n    self.assertEqual(str(bf[1:]), '<input type=\"checkbox\" name=\"name\" value=\"paul\"> Paul')\n    self.assertEqual(str(bf[1:3]), '<input type=\"checkbox\" name=\"name\" value=\"paul\"> Paul')\n    self.assertEqual(str(bf[1:4]), '<input type=\"checkbox\" name=\"name\" value=\"paul\"> Paul')\n    self.assertEqual(str(bf[2:]), '<input type=\"checkbox\" name=\"name\" value=\"george\"> George')\n    self.assertEqual(str(bf[2:4]), '<input type=\"checkbox\" name=\"name\" value=\"george\"> George')\n    self.assertEqual(str(bf[2:5]), '<input type=\"checkbox\" name=\"name\" value=\"george\"> George')\n    self.assertEqual(str(bf[3:]), '<input type=\"checkbox\" name=\"name", "def test_dynamic_form_validation(self):\n    class DynamicForm(Form):\n        field1 = CharField()\n\n            self.field2 = CharField()\n            super().__init__(*args, **kwargs)\n\n    form = DynamicForm()\n    self.assertEqual(form.fields, {'field1': form.fields['field1'], 'field2': form.fields['field2']})\n\n    form2 = DynamicForm({'field1': 'value1', 'field2': 'value2'})\n    self.assertEqual(form2.errors, {'field1': ['This field is required.'], 'field2': ['This field is required.']})\n    self.assertEqual(form2.cleaned_data, {'field1': 'value1', 'field2': 'value2'})\n\n    class DynamicFormWithValidator(Form):\n        field1 = CharField()\n\n            self.field2 = CharField(validators=[RegexValidator(r'^abc.*$')])\n            super().__init__(*args, **kwargs)\n\n    form = DynamicFormWithValidator()\n    self.assertEqual(form.fields, {'field1': form.fields['field1'], 'field2': form.fields['field2']})\n\n    form2 = DynamicFormWithValidator({'field1': 'value1', 'field2': 'value2'})\n    self.assertEqual(form2.errors, {'field2': ['Enter a valid value.']})\n    self.assertEqual(form2.cleaned_data, {'field1': 'value1', 'field2': 'value2'})\n\n    class DynamicFormWithRequired(Form):\n        field1 = CharField()\n\n            self.field2 = CharField(required=False)\n            super().__init__(*args, **kwargs)\n\n    form = DynamicFormWithRequired({'field1': 'value1', 'field2': 'value2'})\n    self.assertEqual(form.errors, {})\n    self.assertEqual(form.cleaned_data, {'field1': 'value1', 'field2': 'value2'})\n\n    class DynamicFormWithHiddenInput(Form):\n        field1 = CharField()\n\n            self.field2 = CharField(widget=HiddenInput())\n            super().__init__(*args, **kwargs)\n\n    form = DynamicFormWithHiddenInput()\n    self.assertEqual(form.fields, {'field1': form.fields['field1'], 'field2': form.fields['field2", "def test_multivalue_subfield_has_error(self):\n    class CountryField(MultiValueField):\n            fields = (\n                CharField(label='Country Code', max_length=3),\n                CharField(label='Country Name', max_length=50),\n            )\n            super().__init__(fields=fields, *args, **kwargs)\n\n            return ' '.join(data_list)\n\n    class CountryForm(Form):\n        country = CountryField(required=False, validators=[\n            RegexValidator(r'^[A-Z]{3}$', message='Invalid country code.'),\n        ])\n\n    data = {'country': ['ABC', 'Country 1']}\n    f = CountryForm(data)\n    self.assertTrue(f.is_valid())\n    self.assertEqual(f.cleaned_data['country'], 'ABC Country 1')\n\n    # Now, let's check if the first subfield has an error.\n    self.assertEqual(f['country'].errors, {})\n    self.assertEqual(f['country'].fields[0].errors, {'country_code': ['Invalid country code.']})\n    self.assertEqual(f['country'].fields[1].errors, {'country_name': ['This field is required.']})\n\n    # And now let's check if the second subfield has an error.\n    f = CountryForm({'country': ['DEF', '']})\n    self.assertEqual(f['country'].errors, {})\n    self.assertEqual(f['country'].fields[0].errors, {'country_code': ['Invalid country code.']})\n    self.assertEqual(f['country'].fields[1].errors, {'country_name': ['This field is required.']})\n"], "sample_155": ["def test_set_quantity_dimension_with_dimension_system():\n    u = Quantity(\"u\")\n    SI.set_quantity_dimension(u, charge*length/time)\n    assert u.dimension == charge*length/time\n    assert u.scale_factor == 1\n", "def test_issue_28172():\n    from sympy.physics.units import Quantity\n    from sympy.physics.units.quantities import PhysicalConstant\n    from sympy.physics.units.systems import SI\n    c = Quantity('c')\n    SI.set_quantity_dimension(c, speed_of_light)\n    c.set_global_relative_scale_factor(speed_of_light)\n    assert c.scale_factor == 299792458\n", "def test_issue_20889():\n    from sympy.physics.units import Quantity\n    u = Quantity('u')\n    v = Quantity('v')\n    u.set_global_relative_scale_factor(S(1), 1000*second)\n    v.set_global_relative_scale_factor(S(1), second)\n    expr = v / u\n    assert SI.get_dimensional_expr(expr) == second / (1000*second)\n    assert SI._collect_factor_and_dimension(expr) == (1/1000, Dimension(1))\n", "def test_get_units_with_prefix():\n    # Test that a unit system returns the units with prefix\n    si = SI\n    assert si.get_units_non_prefixed() == {\n        joule, volt, second, ampere, meter, kilogram, kelvin, mole, candela\n    }\n    assert set(si._units) == {\n        joule, volt, second, ampere, meter, kilogram, kelvin, mole, candela, \n        kilo, meter, ampere, kelvin, kilogram, mole, kilo, \n        joule, volt, second, meter, ampere, kelvin, mole, candela, second, meter, \n        joule, meter, meter, meter, meter, meter, meter, meter, meter, kilogram, meter, \n        meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, \n        meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, \n        meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, \n        meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, \n        meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, \n        meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, \n        meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, \n        meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, \n        meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, \n        meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, \n        meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, \n        meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, \n        meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, meter, \n        meter", "def test_set_quantity_dimension():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n    w = Quantity(\"w\")\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    w.set_global_relative_scale_factor(S(2), second)\n\n    # Setting dimension of an already set dimension should raise an error\n    with raises(ValueError, lambda: SI.set_quantity_dimension(u, length)):\n        pass\n    with raises(ValueError, lambda: SI.set_quantity_dimension(v, length)):\n        pass\n    with raises(ValueError, lambda: SI.set_quantity_dimension(w, length)):\n        pass\n\n    # Setting dimension of a dimensionless unit should raise an error\n    u.set_global_relative_scale_factor(S.One, meter)\n    with raises(ValueError, lambda: SI.set_quantity_dimension(u, length)):\n        pass\n\n    # Setting dimension of a unit with incompatible dimension should raise an error\n    v.set_global_relative_scale_factor(S(5), meter)\n    with raises(ValueError, lambda: SI.set_quantity_dimension(v, time)):\n        pass\n\n    # Setting dimension of a unit with incompatible dimension should raise an error\n    w.set_global_relative_scale_factor(S(2), second)\n    with raises(ValueError, lambda: SI.set_quantity_dimension(w, pressure)):\n        pass\n\n    # Setting dimension of a unit with different dimension should raise an error\n    u.set_global_relative_scale_factor(S(10), meter)\n    with raises(ValueError, lambda: SI.set_quantity_dimension(u, length**2)):\n        pass\n\n    # Setting dimension of a unit with the same dimension should not raise an error\n    v.set_global_relative_scale_factor(S(5), meter)\n    SI.set_quantity_dimension(v, length)\n\n    # Getting dimension of a unit should return the new dimension\n    assert SI.get_quantity_dimension(v) == length\n\n    # Getting scale factor of a unit should return the current scale factor\n    assert v.scale_factor == 5\n\n    # Getting dimension of a dimensionless unit should return the original dimension\n    u.set_global_relative_scale_factor(S.One, meter)\n    SI.set_quantity_dimension(u, length)\n    assert SI.get_quantity_dimension(u) == length\n\n    # Getting scale factor of a dimensionless unit should return the current scale factor\n    assert u.scale_factor == 1\n"], "sample_21": ["    def test_delete_with_keeping_parents_inheritance(self):\n        child = RChild.objects.create()\n        parent_id = child.r_ptr_id\n        parent_referent_id = S.objects.create(r=child.r_ptr).pk\n        child.delete(keep_parents=True)\n        self.assertFalse(RChild.objects.filter(id=child.id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n\n        childchild = RChildChild.objects.create()\n        parent_id = childchild.rchild_ptr.r_ptr_id\n        child_id = childchild.rchild_ptr_id\n        parent_referent_id = S.objects.create(r=childchild.rchild_ptr.r_ptr).pk\n        childchild.delete(keep_parents=True)\n        self.assertFalse(RChildChild.objects.filter(id=childchild.id).exists())\n        self.assertTrue(RChild.objects.filter(id=child_id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n", "    def test_setdefault_with_delete(self):\n        a = create_a('setdefault')\n        a.setdefault.delete()\n        a = A.objects.get(pk=a.pk)\n        self.assertEqual(self.DEFAULT, a.setdefault.pk)\n", "    def test_field_update_multiple_values(self):\n        a = create_a('setvalue')\n        a.setvalue.delete()\n        a = A.objects.get(pk=a.pk)\n        self.assertEqual(self.DEFAULT, a.setvalue.pk)\n        # Test that the field can be updated with different values.\n        self.assertNotEqual(a.setvalue, self.DEFAULT)\n        a.setvalue.delete()\n        a = A.objects.get(pk=a.pk)\n        self.assertEqual(self.DEFAULT, a.setvalue.pk)\n", "    def test_delete_with_protected_relationship(self):\n        a = create_a('protect')\n        b = B.objects.create(protect=a.protect)\n        msg = (\n            \"Cannot delete some instances of model 'B' because they are \"\n            \"referenced through protected foreign keys: 'B.protect'.\"\n        )\n        with self.assertRaisesMessage(ProtectedError, msg):\n            a.protect.delete()\n        self.assertTrue(B.objects.exists())\n        self.assertFalse(B.objects.filter(protect_id=None).exists())\n        a = A.objects.get(pk=a.pk)\n        self.assertIsNotNone(a.protect)\n        self.assertIsNotNone(a.protect.b)\n        a.protect.b.delete()\n        self.assertTrue(B.objects.filter(protect_id=None).exists())\n", "    def test_delete_with_keeping_parents_multiple_levels(self):\n        \"\"\"\n        Test keeping parents with multiple levels.\n        \"\"\"\n        parent = R.objects.create()\n        child1 = RChild.objects.create(r_ptr=parent)\n        grandchild1 = RChildChild.objects.create(rchild_ptr=child1)\n        grandchild2 = RChildChild.objects.create(rchild_ptr=child1)\n        parent.delete(keep_parents=True)\n        self.assertFalse(RChildChild.objects.filter(id=grandchild1.id).exists())\n        self.assertFalse(RChild.objects.filter(id=child1.id).exists())\n        self.assertFalse(R.objects.filter(id=parent.id).exists())\n        self.assertTrue(RChildChild.objects.filter(id=grandchild2.id).exists())\n        self.assertTrue(RChild.objects.filter(id=child1.id).exists())\n        self.assertTrue(R.objects.filter(id=parent.id).exists())\n"], "sample_71": ["def test_context_with_multiple_styles():\n    original_value = 'gray'\n    mpl.rcParams[PARAM] = original_value\n    with temp_style('test1', DUMMY_SETTINGS):\n        with temp_style('test2', DUMMY_SETTINGS):\n            with style.context(['test1', 'test2']):\n                assert mpl.rcParams[PARAM] == VALUE\n    assert mpl.rcParams[PARAM] == original_value\n", "def test_style_context_after_reset():\n    original_value = 'gray'\n    other_value = 'blue'\n    mpl.rcParams[PARAM] = original_value\n    with temp_style('test', DUMMY_SETTINGS):\n        with style.context('test', after_reset=True):\n            assert mpl.rcParams[PARAM] == VALUE\n    assert mpl.rcParams[PARAM] == original_value\n", "def test_update_nested_dict():\n    original_dict = {'a': {'b': {'c': 1}, 'd': 2}, 'e': 3}\n    new_dict = {'b': {'c': 4}, 'f': 5}\n    result = style.update_nested_dict(original_dict, new_dict)\n    assert result == {'a': {'b': {'c': 4}, 'd': 2}, 'e': 3, 'f': 5}\n    assert original_dict == {'a': {'b': {'c': 1}, 'd': 2}, 'e': 3}\n", "def test_contextmanager_restore_context():\n    # Test that use() restores matplotlib's rcParams when an exception is raised\n    # in the context manager.\n    original_value = 'gray'\n    other_value = 'blue'\n    mpl.rcParams[PARAM] = original_value\n    try:\n        with style.context({PARAM: other_value}):\n            raise RuntimeError(\"Test error\")\n    except RuntimeError:\n        assert mpl.rcParams[PARAM] == original_value\n", "def test_style_reload(tmpdir):\n    # Test that reloading the style library updates user-defined styles.\n    mpl.rcParams[PARAM] = 'gray'\n    with temp_style('test', DUMMY_SETTINGS):\n        style.reload_library()\n        with style.context('test'):\n            assert mpl.rcParams[PARAM] == VALUE\n    assert mpl.rcParams[PARAM] == 'gray'\n    # Test that reloading the style library does not reload the base library.\n    # Add a new style to the base library to verify this.\n    with open(os.path.join(BASE_LIBRARY_PATH, 'test.mplstyle'), 'w') as f:\n        f.write(f\"{PARAM}: {VALUE}\")\n    style.reload_library()\n    with style.context('test'):\n        assert mpl.rcParams[PARAM] == VALUE\n    style.reload_library()  # Should not reload the base library.\n    assert mpl.rcParams[PARAM] == VALUE\n"], "sample_10": ["def test_year_lookup(self):\n    # Test year lookups\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 4>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 7>',\n            '<Article: Article 1>',\n        ],\n        ordered=False\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__exact=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 4>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 7>',\n            '<Article: Article 1>',\n        ],\n        ordered=False\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year=2006),\n        []\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__exact=2006),\n        []\n    )\n", "def test_transformed_lookup(self):\n    \"\"\"Transforms are used for lookups.\"\"\"\n    Season.objects.create(year=1, nulled_text_field='not null')\n    self.assertTrue(Season.objects.filter(nulled_text_field__nulled__gt=1))\n    self.assertTrue(Season.objects.filter(nulled_text_field__nulled__gte=1))\n    self.assertFalse(Season.objects.filter(nulled_text_field__nulled__lt=1))\n    self.assertFalse(Season.objects.filter(nulled_text_field__nulled__lte=1))\n", "def test_year_lookup(self):\n    # Year lookup can be used to check the year part of DateField and DateTimeField.\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 4>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 7>',\n            '<Article: Article 1>',\n        ],\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gt=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n        ],\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gte=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 4>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 7>',\n            '<Article: Article 1>',\n        ],\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lt=2005),\n        [],\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lte=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 4>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 7>',\n            '<Article: Article 1>',\n        ],\n    )\n\n    # Test YearExact, YearGt, YearGte, YearLt, YearLte lookups\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__exact=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 4>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 7>',\n            '<Article: Article 1>',\n        ],\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gt=2005),\n        [\n            '<Article: Article 6>',\n            '<Article: Article 4>',\n            '<Article: Article 7>',\n        ],\n    )\n    self.assertQuerysetEqual", "def test_year_lookup(self):\n    \"\"\"Tests the year lookup.\"\"\"\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 7>',\n        ],\n        ordered=False\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__exact=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 7>',\n        ],\n        ordered=False\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gt=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n        ],\n        ordered=False\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__exact=2005, headline='Article 1'),\n        ['<Article: Article 1>'],\n        ordered=False\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lt=2005),\n        [],\n        ordered=False\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__exact=2005, headline__startswith='A'),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 7>',\n        ],\n        ordered=False\n    )\n", "def test_exact_subquery_rhs(self):\n    # A subquery can be used as a lookup value in an exact lookup\n    season = Season.objects.create(year=2012)\n    season.games.create(home=\"Houston Astros\", away=\"St. Louis Cardinals\")\n    qs = Article.objects.filter(author__id__in=Season.objects.values('id').filter(year=2012))\n    self.assertEqual(len(list(qs)), 3)\n"], "sample_25": ["def test_add_field_with_blank(self):\n    \"\"\"Adding a field with blank=True and no default should work.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_with_biography_blank])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"biography\")\n    self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"name\")\n", "def test_circular_dependency_proxy(self):\n    \"\"\"\n    Tests the autodetector can handle circular FK dependencies involving\n    a proxy model.\n    \"\"\"\n    # Note that testapp (author) has no dependencies,\n    # otherapp (book) depends on testapp (authorproxy)\n    changes = self.get_changes([], [self.author_empty, self.author_proxy, self.book_proxy_fk])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Author\")\n    self.assertMigrationDependencies(changes, 'testapp', 0, [])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, [\"CreateModel\"])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"Book\")\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [(\"testapp\", \"auto_1\")])\n", "def test_alter_field_and_add_default(self):\n    \"\"\"\n    #23609 - AlterField with a new default should work.\n    \"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_name_default])\n    self.assertEqual(changes, {})\n    changes = self.get_changes([self.author_empty], [self.author_name])\n    self.assertEqual(changes, {})\n    changes = self.get_changes([self.author_name], [self.author_name_default])\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=\"Ada Lovelace\")\n", "    def test_add_fk_field_with_default(self):\n        \"\"\"#22030 - Adding an FK with a default should work.\"\"\"\n        changes = self.get_changes([self.author_empty], [self.author_with_book])\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"AddField\"])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Author\")\n        self.assertOperationAttributes(changes, 'testapp', 0, 1, model_name=\"author\", name=\"book\")\n\n        # And with a related model that has no default value for the field\n        book = ModelState(\"otherapp\", \"Book\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"title\", models.CharField(max_length=200)),\n        ])\n        changes = self.get_changes([self.author_empty], [self.author_with_book, book])\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertNumberMigrations(changes, 'otherapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"AddField\"])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Author\")\n        self.assertOperationAttributes(changes, 'testapp', 0, 1, model_name=\"author\", name=\"book\")\n        self.assertOperationTypes(changes, 'otherapp', 0, [\"CreateModel\"])\n        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"Book\")\n\n        # And with a related model that has a default value for the field\n        book = ModelState(\"otherapp\", \"Book\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"title\", models.CharField(max_length=200)),\n            (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE, default=1)),\n        ])\n        changes = self.get_changes([self.author_empty], [self.author_with_book, book])\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertNumberMigrations(changes, 'otherapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\",", "def test_alter_unique_together_before_field_removal(self):\n    \"\"\"Tests detection for unique_together being updated before a field removal.\"\"\"\n    # Explicitly testing for not specified, since this is the case after\n    # a CreateModel operation w/o any definition on the original model\n    model_state_not_specified = ModelState(\"a\", \"model\", [(\"id\", models.AutoField(primary_key=True))])\n    # Explicitly testing for None, since this was the issue in #23452 after\n    # an AlterUniqueTogether operation with e.g. () as value\n    model_state_none = ModelState(\"a\", \"model\", [\n        (\"id\", models.AutoField(primary_key=True))\n    ], {\n        \"index_together\": None,\n        \"unique_together\": None,\n    })\n    # Explicitly testing for the empty set, since we now always have sets.\n    # During removal (('col1', 'col2'),) --> () this becomes set([])\n    model_state_empty = ModelState(\"a\", \"model\", [\n        (\"id\", models.AutoField(primary_key=True))\n    ], {\n        \"index_together\": set(),\n        \"unique_together\": set(),\n    })\n    model_state_changed = ModelState(\"a\", \"model\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200)),\n    ], {\n        \"unique_together\": {('name', '_order')},\n        \"index_together\": {('name', '_order')},\n    })\n    # Change model_state to not have unique_together but still have index_together\n    # Right number/type of migrations?\n    changes = self.get_changes([model_state_not_specified], [model_state_none, model_state_changed])\n    self.assertNumberMigrations(changes, \"a\", 1)\n    self.assertOperationTypes(changes, \"a\", 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\"])\n    # Change model_state to have an empty set for unique_together\n    changes = self.get_changes([model_state_not_specified, model_state_changed], [model_state_not_specified, model_state_empty])\n    self.assertNumberMigrations(changes, \"a\", 1)\n    self.assertOperationTypes(changes, \"a\", 0, [\"AlterUniqueTogether\"])\n    # Change model_state to have unique_together before having a field to remove\n    changes = self.get_changes([model_state_not_specified, model_state_none], [model_state_none, model"], "sample_9": ["    def test_django_main_module(self):\n        with mock.patch('django.__main__.__file__', 'django.__main__'):\n            self.assertEqual(autoreload.get_child_arguments(), ['/path/to/python', '-Wall', '-m', 'django', 'runserver'])\n", "    def test_tick_sleep_time(self):\n        self.reloader.SLEEP_TIME = 0.01\n        with self.assertRaises(StopIteration):\n            list(self.reloader.tick())\n", "    def setUp(self):\n        self._directory = tempfile.TemporaryDirectory()\n        self.directory = Path(self._directory.name).resolve().absolute()\n        self.file = self.directory / 'test'\n        self.file.touch()\n", "    def test_glob(self):\n        \"\"\"\n        glob() correctly handles glob expressions.\n        \"\"\"\n        filename = self.temporary_file('test_glob.py')\n        filename.write_text(\"import os; print(os.path.expandvars('~/'))\")\n        with extend_sys_path(str(filename.parent)):\n            self.import_and_cleanup('test_glob')\n        self.assertFileFound(filename)\n        self.assertFileFound(filename.parent / '~/.glob')\n", "    def test_caching(self):\n        \"\"\"\n        Check that iter_modules_and_files() uses the LRU cache.\n        \"\"\"\n        filename = self.temporary_file('test_module.py')\n        filename.write_text('pass')\n        filename.touch()\n\n        with extend_sys_path(str(filename.parent)):\n            self.import_and_cleanup('test_module')\n\n        self.assertFileFound(filename.absolute())\n\n        # Remove the file to trigger a cache miss\n        filename.unlink()\n\n        # The first call should be a cache miss\n        self.assertNotIn(filename, list(autoreload.iter_modules_and_files((), frozenset())))\n        # The second call should be a cache hit\n        self.assertIn(filename, list(autoreload.iter_modules_and_files((), frozenset())))\n"], "sample_96": ["def test_sparse_svd_solver():\n    # Test the SVD solver for sparse matrices\n    rng = np.random.RandomState(42)\n    X = sp.csr_matrix(rng.randn(5, 10))\n    y = rng.randn(5)\n    ridge = Ridge(solver='svd', fit_intercept=False)\n    try:\n        ridge.fit(X, y)\n        assert False, \"SVD solver should not support sparse inputs\"\n    except TypeError as e:\n        assert True\n", "def test_ridge_regression_solver_switch():\n    # Test that solver switch and warning when fitting sparse data\n    X = sp.csr_matrix(np.eye(3))\n    y = np.ones(3)\n    ridge = Ridge(alpha=1., tol=1.e-15, solver='cholesky', fit_intercept=True)\n    assert_warns(UserWarning, ridge.fit, X, y)\n    assert_equal(ridge.solver, 'sag')\n    assert_almost_equal(ridge.intercept_, 1.)\n    assert_array_almost_equal(ridge.coef_, np.array([1., 0., 0.]))\n\n    ridge = Ridge(alpha=1., tol=1.e-15, solver='lsqr', fit_intercept=True)\n    assert_warns(UserWarning, ridge.fit, X, y)\n    assert_equal(ridge.solver, 'sag')\n    assert_almost_equal(ridge.intercept_, 1.)\n    assert_array_almost_equal(ridge.coef_, np.array([1., 0., 0.]))\n\n    ridge = Ridge(alpha=1., tol=1.e-15, solver='svd', fit_intercept=True)\n    assert_warns(UserWarning, ridge.fit, X, y)\n    assert_equal(ridge.solver, 'sag')\n    assert_almost_equal(ridge.intercept_, 1.)\n    assert_array_almost_equal(ridge.coef_, np.array([1., 0., 0.]))\n\n    ridge = Ridge(alpha=1., tol=1.e-15, solver='sparse_cg', fit_intercept=True)\n    assert_warns(UserWarning, ridge.fit, X, y)\n    assert_equal(ridge.solver, 'sag')\n    assert_almost_equal(ridge.intercept_, 1.)\n    assert_array_almost_equal(ridge.coef_, np.array([1., 0., 0.]))\n", "def test_solver_switch():\n    # Test that solver switch doesn't raise an error and still fits the model.\n    rng = np.random.RandomState(0)\n    X = rng.randn(100, 10)\n    y = rng.randn(100)\n    ridge = Ridge(solver='lsqr')\n    ridge.fit(X, y)\n    assert_greater(ridge.score(X, y), 0.4)\n\n    # Test that using a non-supported solver raises a ValueError\n    ridge = Ridge(solver='non-supported-solver')\n    assert_raises(ValueError, ridge.fit, X, y)\n", "def test_ridge_regression_stability():\n    # Test that ridge regression output is stable.\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 6, 5\n    y = rng.randn(n_samples)\n    X = rng.randn(n_samples, n_features)\n\n    # With more samples than features\n    for solver in (\"svd\", \"sparse_cg\", \"cholesky\", \"lsqr\"):\n        ridge1 = Ridge(alpha=1.0, solver=solver)\n        ridge2 = Ridge(alpha=1.0, solver=solver)\n\n        # Fit ridge regression with the same parameters multiple times\n        for _ in range(10):\n            ridge1.fit(X, y)\n            ridge2.fit(X, y)\n\n        # Check that the coefficients and intercept are the same\n        assert_array_almost_equal(ridge1.coef_, ridge2.coef_, decimal=3)\n        assert_almost_equal(ridge1.intercept_, ridge2.intercept_, decimal=3)\n\n    # With more features than samples\n    for solver in (\"svd\", \"sparse_cg\", \"cholesky\", \"lsqr\"):\n        ridge1 = Ridge(alpha=1.0, solver=solver)\n        ridge2 = Ridge(alpha=1.0, solver=solver)\n\n        # Fit ridge regression with the same parameters multiple times\n        for _ in range(10):\n            ridge1.fit(X, y)\n            ridge2.fit(X, y)\n\n        # Check that the coefficients and intercept are the same\n        assert_array_almost_equal(ridge1.coef_, ridge2.coef_, decimal=3)\n        assert_almost_equal(ridge1.intercept_, ridge2.intercept_, decimal=3)\n", "def test_ridge_kernel():\n    # Test kernel ridge regression\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 5, 10\n    X = rng.randn(n_samples, n_features)\n    y = rng.randn(n_samples)\n\n    # create a kernel matrix\n    K = np.dot(X, X.T) + 1\n    alpha = 1.0\n\n    # test that the kernel matrix is correctly converted to a LinearOperator\n    coefs = _solve_cholesky_kernel(K, y, alpha)\n    K_coefs = safe_sparse_dot(coefs.T, K)\n    assert_array_almost_equal(y, K_coefs)\n\n    # test that the kernel matrix is correctly converted to a LinearOperator\n    # with sample weights\n    sample_weight = np.ones(n_samples)\n    coefs = _solve_cholesky_kernel(K, y, alpha, sample_weight)\n    K_coefs = safe_sparse_dot(coefs.T, K)\n    K_coefs *= sample_weight[:, np.newaxis]\n    assert_array_almost_equal(y, K_coefs)\n\n    # test that the kernel matrix is correctly converted to a LinearOperator\n    # with multiple targets\n    y_multitarget = np.random.rand(n_samples, 2)\n    coefs = _solve_cholesky_kernel(K, y_multitarget, alpha)\n    K_coefs = safe_sparse_dot(coefs.T, K)\n    assert_array_almost_equal(y_multitarget, K_coefs)\n\n    # test that the kernel matrix is correctly converted to a LinearOperator\n    # with sample weights and multiple targets\n    sample_weight = np.ones(n_samples)\n    coefs = _solve_cholesky_kernel(K, y_multitarget, alpha, sample_weight)\n    K_coefs = safe_sparse_dot(coefs.T, K)\n    K_coefs *= sample_weight[:, np.newaxis]\n    assert_array_almost_equal(y_multitarget, K_coefs)\n"], "sample_94": ["def test_getstatementrange_with_trailing_newlines() -> None:\n    source = Source(\n        \"\"\"\\", "def test_empty_source() -> None:\n    source = Source()\n    assert str(source) == \"\"\n    assert len(source) == 0\n    with pytest.raises(IndexError, match=r\"lineno out of range\"):\n        source.getstatement(0)\n    with pytest.raises(IndexError, match=r\"lineno out of range\"):\n        source.getstatement(1)\n    with pytest.raises(TypeError):\n        source[0:2]\n    with pytest.raises(TypeError):\n        source[::2]\n", "def test_getstatementrange_within_finally_issue65() -> None:\n    source = Source(\n        \"\"\"\\", "def test_getstatementrange_with_multiple_statements() -> None:\n    source = Source(\n        \"\"\"\\", "def test_getstatementrange_with_empty_line_between_statements() -> None:\n    source = Source(\n        \"\"\"\\\n        try:\n            raise ValueError\n        except ValueError:\n            pass\n    \"\"\"\n    )\n    assert len(source) == 5\n    assert source.getstatementrange(0) == (0, 5)\n    assert source.getstatementrange(1) == (0, 5)\n    assert source.getstatementrange(2) == (0, 5)\n    assert source.getstatementrange(3) == (0, 5)\n    assert source.getstatementrange(4) == (0, 5)\n"], "sample_0": ["def test_build_attrs_locale(self):\n    with translation.override('de'):\n        form = AlbumForm()\n        attrs = form['featuring'].field.widget.get_context(name='name', value=None, attrs={})['widget']['attrs']\n        self.assertEqual(attrs['data-placeholder'], _('Select an item'))\n", "    def test_build_attrs_with_html_id(self):\n        form = AlbumForm()\n        attrs = form['band'].field.widget.get_context(name='my_field', value=None, attrs={'id': 'my-id'})['widget']['attrs']\n        self.assertEqual(attrs['data-allow-clear'], 'false')\n        self.assertEqual(attrs['data-ajax--cache'], 'true')\n        self.assertEqual(attrs['data-ajax--type'], 'GET')\n        self.assertEqual(attrs['data-ajax--url'], '/admin_widgets/band/autocomplete/')\n        self.assertEqual(attrs['data-theme'], 'admin-autocomplete')\n        self.assertEqual(attrs['id'], 'my-id')\n", "    def test_render_checkbox(self):\n        form = NotRequiredBandForm()\n        widget = form['band'].field.widget\n        output = widget.render('name', None, attrs={'class': 'my-class'})\n        self.assertIn('<input type=\"checkbox\"', output)\n        self.assertIn('data-allow-clear=\"true\"', output)\n", "    def test_render_checkbox(self):\n        form = AlbumForm()\n        output = form.as_table()\n        checkbox_input = '<input type=\"checkbox\" id=\"id_band-clear\" name=\"band-clear\" class=\"select-once\"'\n        self.assertIn(checkbox_input, output)\n", "    def test_build_attrs_initial_value(self):\n        form = AlbumForm(initial={'band': Band.objects.all().first()})\n        attrs = form['band'].field.widget.get_context(name='my_field', value=form['band'].value(), attrs={})['widget']['attrs']\n        self.assertEqual(attrs, {\n            'class': 'my-class admin-autocomplete',\n            'data-ajax--cache': 'true',\n            'data-ajax--type': 'GET',\n            'data-ajax--url': '/admin_widgets/band/autocomplete/',\n            'data-theme': 'admin-autocomplete',\n            'data-allow-clear': 'false',\n            'data-placeholder': ''\n        })\n"], "sample_27": ["def test_token_with_different_password(self):\n    \"\"\"\n    A valid token can be created with a new password.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk1), True)\n    # Create and check a token with a new password.\n    user.set_password('newpw')\n    user.save()\n    self.assertIs(p0.check_token(user, tk1), False)\n    tk2 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk2), True)\n", "def test_token_with_different_password(self):\n    \"\"\"A valid token can be created with a user having a different password.\"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    user.set_password('newpw')\n    user.save()\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk1), True)\n    self.assertIs(p0.check_token(user, tk1), False)  # Should return False\n", "    def test_make_token_with_different_password(self):\n        \"\"\"A token is invalidated when the user's password is changed.\"\"\"\n        user = User.objects.create_user('passwordchangenottestuser', 'test2@example.com', 'testpw')\n        p0 = PasswordResetTokenGenerator()\n        tk1 = p0.make_token(user)\n        self.assertIs(p0.check_token(user, tk1), True)\n        user.set_password('newpw')\n        user.save()\n        self.assertIs(p0.check_token(user, tk1), False)\n", "def test_token_with_no_email(self):\n    \"\"\"The token is invalid if the user has no email address.\"\"\"\n    user = User.objects.create_user('tokenuser', 'test2@example.com', 'testpw')\n    user.email = None\n    user.save()\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk1), False)\n", "def test_token_with_different_user_state(self):\n    \"\"\"\n    The token is invalidated when the user's state changes in ways that aren't\n    captured by email changes.\n    \"\"\"\n    tests = [\n        (User, 'test5@example.com', 'testpw'),\n        (User, 'test5@example.com', 'newtestpw'),\n        (User, 'test5@example.com', 'testpw', '2022-01-01 00:00:00'),\n    ]\n    for model, email, password, last_login in tests:\n        with self.subTest(model=model.__qualname__, email=email):\n            user = model.objects.create_user(\n                'changestateuser',\n                email=email,\n                password=password,\n                last_login=datetime.strptime(last_login, '%Y-%m-%d %H:%M:%S'),\n            )\n            p0 = PasswordResetTokenGenerator()\n            tk1 = p0.make_token(user)\n            self.assertIs(p0.check_token(user, tk1), True)\n            user.password = 'newtestpw'\n            user.save()\n            self.assertIs(p0.check_token(user, tk1), False)\n            user.last_login = datetime.now()\n            user.save()\n            self.assertIs(p0.check_token(user, tk1), False)\n"], "sample_145": ["compilation error", "compilation error", "def test_latex_args():\n    assert latex((x + 1)*x) == r\"\\left(x + 1\\right) x\"\n    assert latex(2*x + x) == r\"2 x + x\"\n    assert latex((2*x + x)*y) == r\"\\left(2 x + x\\right) y\"\n    assert latex((x + 1)*x + x) == r\"\\left(x + 1\\right) x + x\"\n    assert latex(2*x + x + y) == r\"2 x + x + y\"\n    assert latex((2*x + x + y)*z) == r\"\\left(2 x + x + y\\right) z\"\n    assert latex((2*x + (x + y)*z)) == r\"\\left(2 x + \\left(x + y\\right) z\\right)\"\n    assert latex((2*x + (x + y)*z)*w) == r\"\\left(2 x + \\left(x + y\\right) z\\right) w\"\n    assert latex((x + y)*(z + w)) == r\"\\left(x + y\\right)\\left(z + w\\right)\"\n    assert latex((x + y)*z*w) == r\"\\left(x + y\\right)\\left(z w\\right)\"\n", "def test_latex_LeviCivita_indexed():\n    from sympy.tensor.tensor import TensorIndexType, tensor_indices, TensorHead, TensorElement, TensorProduct\n    from sympy.tensor.tensor import LeviCivita, TensorIndexType, tensor_indices, TensorHead, TensorElement, TensorProduct\n    from sympy.diffgeom import R3\n    from sympy import symbols\n\n    L = TensorIndexType(\"L\")\n    i, j, k, l = tensor_indices(\"i j k l\", L)\n    i0 = tensor_indices(\"i_0\", L)\n\n    # Test indices\n    assert latex(LeviCivita(i, j, k)) == r\"\\varepsilon_{i j k}\"\n    assert latex(LeviCivita(i, j, k)**2) == r\"\\left(\\varepsilon_{i j k}\\right)^{2}\"\n    assert latex(LeviCivita(i, j, k + 1)) == r\"\\varepsilon_{i j, k + 1}\"\n    assert latex(LeviCivita(i + 1, j, k)) == r\"\\varepsilon_{i + 1, j k}\"\n    assert latex(LeviCivita(i, j + 1, k)) == r\"\\varepsilon_{i, j + 1 k}\"\n    assert latex(LeviCivita(i, k + 1, j)) == r\"\\varepsilon_{i, k + 1 j}\"\n    assert latex(LeviCivita(i, j, -k)) == r\"\\varepsilon_{i j, - k}\"\n    assert latex(LeviCivita(-i, j, k)) == r\"\\varepsilon_{- i j k}\"\n\n    # Test TensorElement\n    A = TensorHead(\"A\", [L, L])\n    assert latex(TensorElement(A, {i: 2})) == r\"A^{i=2}_{j}\"\n\n    # Test TensorProduct\n    B = TensorHead(\"B\", [L, L, L, L])\n    assert latex(TensorProduct(B, {i: 2, j: 3})) == r\"B^{i=2 j=3}_{k l}\"\n", "def test_latex_FourierSeries():\n    from sympy import fourier_series\n\n    # test case from https://en.wikipedia.org/wiki/Periodic_function#Fourier_series\n    n = Symbol('n', integer=True)\n    a, b = symbols('a b')\n\n    # Here is a series with n = 1\n    n1 = fourier_series(n, (n, -pi, pi))\n    assert latex(n1) == r\"2 \\sin{\\left(n \\pi \\right)\"\n\n    # Here is the series with n = 2\n    n2 = fourier_series(n, (n, -pi, pi))\n    assert latex(n2) == r\"- 2 \\cos{\\left(n \\pi \\right)\"\n\n    # Here is the series with n = 3\n    n3 = fourier_series(n, (n, -pi, pi))\n    assert latex(n3) == r\"- 2 \\sin{\\left(n \\pi \\right)\"\n\n    # Here is the series with n = 4\n    n4 = fourier_series(n, (n, -pi, pi))\n    assert latex(n4) == r\"2 \\cos{\\left(n \\pi \\right)\"\n\n    # test case from https://en.wikipedia.org/wiki/Periodic_function#Fourier_series\n    s = fourier_series((a + b)**n, (n, -pi, pi))\n    assert latex(s) == \\\n        r\"- 4 \\sin{\\left( a \\pi \\right)} \\sin{\\left(\\left(n - 1\\right) \\pi \\right) \\sin{\\left(\\left(a + b\\right) \\pi\\right)} - 4 \\cos{\\left(n \\pi \\right)} \\sin{\\left(a \\pi\\right)} \\sin{\\left(b \\pi \\right)} + 4 \\cos{\\left(a + b\\right) \\pi} \\sin{\\left(n \\pi \\right)}\"\n\n    # test case from https://en.wikipedia.org/wiki/Periodic_function#Fourier_series\n    s = fourier_series((a + b)**n, (n, -pi, pi), poly=True)\n    assert latex(s) == \\\n        r\"- \\frac{8}{\\left(b + 1\\right) \\left(a - b\\right)} \\left(a - b\\right)^{\\left(-1\\right)} \\left(b"], "sample_1": ["def test_read_write_simple_multiple_tables(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3, 4]))\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0, 1.0], name=\"b\", mask=[False, False, False, True]\n        )\n    )\n    t1.write(test_file, format=\"ascii.qdp\", table_id=0)\n    with pytest.warns(UserWarning) as record:\n        t2 = Table.read(test_file, format=\"ascii.qdp\", table_id=0)\n    assert np.any(\n        [\n            \"table_id not specified. Reading the first available table\"\n            in r.message.args[0]\n            for r in record\n        ]\n    )\n\n    assert np.allclose(t2[\"col1\"], t1[\"a\"])\n    assert np.all(t2[\"col1\"] == t1[\"a\"])\n\n    good = ~np.isnan(t1[\"b\"])\n    assert np.allclose(t2[\"col2\"][good], t1[\"b\"][good])\n\n    t3 = Table()\n    t3.add_column(Column(name=\"c\", data=[5, 6, 7, 8]))\n    t3.add_column(\n        MaskedColumn(\n            data=[8.0, np.nan, 7.0, 5.0], name=\"d\", mask=[False, False, False, True]\n        )\n    )\n    t3.write(test_file, format=\"ascii.qdp\", table_id=1)\n    with pytest.warns(UserWarning) as record:\n        t4 = Table.read(test_file, format=\"ascii.qdp\", table_id=1)\n    assert np.any(\n        [\n            \"table_id not specified. Reading the first available table\"\n            in r.message.args[0]\n            for r in record\n        ]\n    )\n\n    assert np.allclose(t4[\"col1\"], t3[\"c\"])\n    assert np.all(t4[\"col1\"] == t3[\"c\"])\n\n    good = ~np.isnan(t3[\"d\"])\n    assert np.allclose(t4[\"col2\"][good], t3[\"d\"][good])\n", "def test_roundtrip_example_negative_numbers(tmp_path):\n    example_qdp = \"\"\"\n        ! Initial comment line 1\n        ! Initial comment line 2\n        READ TERR 1\n        READ SERR 3\n        ! Table 0 comment\n        !a a(pos) a(neg) b c ce d\n        -53000.5   -0.25  0.5   1  -1.5  -3.5 2\n        -54000.5   -1.25  1.5   2  -2.5  -4.5 3\n        NO NO NO NO NO\n        ! Table 1 comment\n        !a a(pos) a(neg) b c ce d\n        -54000.5   -2.25  2.5   NO  -3.5  -5.5 5\n        -55000.5   -3.25  3.5   4  -4.5  -6.5 nan\n        \"\"\"\n    test_file = tmp_path / \"test.qdp\"\n\n    t = Table.read(\n        example_qdp, format=\"ascii.qdp\", table_id=1, names=[\"a\", \"b\", \"c\", \"d\"]\n    )\n    t.write(test_file, err_specs={\"terr\": [1], \"serr\": [3]})\n    t2 = Table.read(test_file, names=[\"a\", \"b\", \"c\", \"d\"], table_id=0)\n\n    for col1, col2 in zip(t.itercols(), t2.itercols()):\n        assert np.allclose(col1, col2, equal_nan=True)\n", "def test_read_write_table_id_none(tmp_path):\n    example_qdp = \"\"\"\n    ! Initial comment line 1\n    ! Initial comment line 2\n    READ TERR 1\n    READ SERR 2\n    ! Table 0 comment\n    !a a(pos) a(neg) b c ce d\n    53000.5   0.25  -0.5   1  1.5  3.5 2\n    54000.5   1.25  -1.5   2  2.5  4.5 3\n    NO NO NO NO NO\n    ! Table 1 comment\n    !a a(pos) a(neg) b c ce d\n    54000.5   2.25  -2.5   NO  3.5  5.5 5\n    55000.5   3.25  -3.5   4  4.5  6.5 nan\n    \"\"\"\n    test_file = tmp_path / \"test.qdp\"\n\n    t = Table.read(\n        example_qdp, format=\"ascii.qdp\", table_id=None, names=[\"a\", \"b\", \"c\", \"d\"]\n    )\n    t.write(test_file, err_specs={\"terr\": [1], \"serr\": [2]})\n    t2 = Table.read(test_file, names=[\"a\", \"b\", \"c\", \"d\"], table_id=None)\n\n    for col1, col2 in zip(t.itercols(), t2.itercols()):\n        assert np.allclose(col1, col2, equal_nan=True)\n\n    assert np.allclose(t2[\"a\"], [53000, 54000, 55000])\n    assert t2[\"c_err\"][0] == 5.5\n    assert np.ma.is_masked(t2[\"b\"][0])\n    assert np.isnan(t2[\"d\"][1])\n", "def test_read_invalid_table_id(tmp_path):\n    example_qdp = \"\"\"\n    ! Swift/XRT hardness ratio of trigger: XXXX, name: BUBU X-2\n    ! Columns are as labelled\n    READ TERR 1\n    READ SERR 2\n    ! WT -- hard data\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   -0.212439       0.212439\n    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   0.000000        0.000000\n    NO NO NO NO NO\n    ! WT -- soft data\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   0.726155        0.583890\n    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   2.410935        1.393592\n    NO NO NO NO NO\n    ! WT -- hardness ratio\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   -0.292553       -0.374935\n    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   0.000000        -nan\n    \"\"\"\n\n    path = tmp_path / \"test.qdp\"\n\n    with open(path, \"w\") as fp:\n        print(example_qdp, file=fp)\n\n    # Test table_id out of range\n    with pytest.raises(IndexError):\n        _read_table_qdp(fp.name, table_id=5)\n    # Test table_id less than 0\n    with pytest.raises(ValueError):\n        _read_table_qdp(fp.name, table_id=-1)\n", "def test_read_write_error_cols(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3]))\n    t1.add_column(MaskedColumn(data=[np.nan, 4.0, 3.0], name=\"a_err\", mask=[True, False, False]))\n    t1.add_column(MaskedColumn(data=[3.0, 4.0, np.nan], name=\"a_nerr\", mask=[False, False, True]))\n    t1.write(test_file, format=\"ascii.qdp\")\n    t2 = Table.read(test_file, table_id=0, format=\"ascii.qdp\", names=[\"a\"])\n    assert np.allclose(t2[\"a\"], t1[\"a\"])\n    assert np.ma.is_masked(t2[\"a_err\"][0])\n    assert np.allclose(t2[\"a_err\"][1:], t1[\"a_err\"][1:])\n    assert np.allclose(t2[\"a_nerr\"][1:], t1[\"a_nerr\"][1:])\n"], "sample_156": ["def test_parser_mathematica_factorial():\n    parser = MathematicaParser()\n\n    chain = lambda expr: parser._from_tokens_to_fullformlist(parser._from_mathematica_to_tokens(expr))\n\n    # Test cases for Factorial and Factorial2\n    assert chain(\"5!\") == [\"Factorial\", 5]\n    assert chain(\"5!!\") == [\"Factorial2\", 5]\n    assert chain(\"5!\") == [\"Factorial\", 5]\n    assert chain(\"5!!\") == [\"Factorial2\", 5]\n    assert chain(\"0!\") == [\"Factorial\", 0]\n    assert chain(\"0!!\") == [\"Factorial2\", 0]\n    assert chain(\"-5!\") == [\"Times\", \"-1\", [\"Factorial\", 5]]\n    assert chain(\"-5!!\") == [\"Times\", \"-1\", [\"Factorial2\", 5]]\n    assert chain(\"(5!)\") == [\"Factorial\", 5]\n    assert chain(\"(5!!)\") == [\"Factorial2\", 5]\n    assert chain(\"(a!)\") == [\"Function\", [\"Slot\", \"1\"], [\"Factorial\", [\"Slot\", \"1\"]]]\n    assert chain(\"(a!!)\") == [\"Function\", [\"Slot\", \"1\"], [\"Factorial2\", [\"Slot\", \"1\"]]]\n    assert chain(\"Factorial[5]\") == [\"Factorial\", 5]\n    assert chain(\"Factorial2[5]\") == [\"Factorial2\", 5]\n\n    # Test cases for invalid inputs\n    raises(SyntaxError, lambda: chain(\"5!a\"))\n    raises(SyntaxError, lambda: chain(\"(5!a)\"))\n    raises(SyntaxError, lambda: chain(\"a!\"))\n    raises(SyntaxError, lambda: chain(\"a!!\"))\n", "def test_parser_mathematica_tokenizer_cse():\n    parser = MathematicaParser()\n\n    chain = lambda expr: parser._from_tokens_to_fullformlist(parser._from_mathematica_to_tokens(expr))\n\n    # Cross-Summyification (CSE) expressions\n    assert chain(\"Sum[x^2, {x, 1, 5}]\") == [\"Sum\", \"x\", \"1\", \"5\", \"2\"]\n    assert chain(\"Sum[x^2, {x, 1, 5}, {y, 1, 7}]\") == [\"Sum\", \"x\", \"1\", \"5\", \"2\", \"Sum\", \"y\", \"1\", \"7\", \"2\"]\n    assert chain(\"Sum[x^2, {x, 1, 5}, {y, 1, 7}, {z, 1, 9}]\") == [\"Sum\", \"x\", \"1\", \"5\", \"2\", \"Sum\", \"y\", \"1\", \"7\", \"2\", \"Sum\", \"z\", \"1\", \"9\", \"2\"]\n\n    # Product expressions\n    assert chain(\"Product[x^2, {x, 1, 5}]\") == [\"Product\", \"x\", \"1\", \"5\", \"2\"]\n    assert chain(\"Product[x^2, {x, 1, 5}, {y, 1, 7}]\") == [\"Product\", \"x\", \"1\", \"5\", \"2\", \"Product\", \"y\", \"1\", \"7\", \"2\"]\n    assert chain(\"Product[x^2, {x, 1, 5}, {y, 1, 7}, {z, 1, 9}]\") == [\"Product\", \"x\", \"1\", \"5\", \"2\", \"Product\", \"y\", \"1\", \"7\", \"2\", \"Product\", \"z\", \"1\", \"9\", \"2\"]\n\n    # Integrate expressions\n    assert chain(\"Integrate[x^2, x]\") == [\"Integrate\", \"x\", \"2\", \"x\"]\n    assert chain(\"Integrate[x^2, {x, 1, 5}]\") == [\"Integrate\", \"x\", \"2\", \"1\", \"5\"]\n    assert chain(\"Integrate[x^2, {x, 1, 5}, {y, 1, ", "def test_parser_mathematica_fractions():\n    parser = MathematicaParser()\n\n    chain = lambda expr: parser._from_tokens_to_fullformlist(parser._from_mathematica_to_tokens(expr))\n\n    # Test cases for fractions\n    assert chain(\"1/2\") == [\"Fraction\", 1, 2]\n    assert chain(\"2/3\") == [\"Fraction\", 2, 3]\n    assert chain(\"3/4\") == [\"Fraction\", 3, 4]\n    assert chain(\"1/(2/3)\") == [\"Power\", \"1\", [\"Fraction\", 2, 3], \"-1\"]\n    assert chain(\"(1/2)/3\") == [\"Times\", [\"Fraction\", 1, 2], [\"Power\", \"3\", \"-1\"]]\n    assert chain(\"1/2*3\") == [\"Times\", [\"Fraction\", 1, 2], 3]\n    assert chain(\"1/2/3\") == [\"Times\", [\"Fraction\", 1, 2], [\"Power\", \"3\", \"-1\"]]\n    assert chain(\"1/(2*3)\") == [\"Power\", \"1\", [\"Times\", \"2\", \"3\"], \"-1\"]\n    assert chain(\"(1/2)*(3/4)\") == [\"Times\", [\"Fraction\", 1, 2], [\"Fraction\", 3, 4]]\n    assert chain(\"(1/2)/(3/4)\") == [\"Power\", [\"Fraction\", 1, 2], [\"Fraction\", 3, 4], \"-1\"]\n    assert chain(\"1/2/(3/4)\") == [\"Times\", [\"Fraction\", 1, 2], [\"Power\", [\"Fraction\", 3, 4], \"-1\"]]\n    assert chain(\"(1/2)*(3/4/5)\") == [\"Times\", [\"Fraction\", 1, 2], [\"Fraction\", 3, [\"Times\", 4, [\"Power\", 5, \"-1\"]]]]\n    assert chain(\"(1/2)/(3/4/5)\") == [\"Power\", [\"Fraction\", 1, 2], [\"Fraction\", [\"Times\", 3, [\"Power\", 4, \"-1\"]], [\"Power\", 5, \"-1\"]], \"-1\"]\n    assert chain(\"1/2/3/4\") == [\"Times\", [\"Fraction\", 1, 2], [\"Power\", [\"Fraction\", 3, 4], \"-1", "def test_parser_mathematica_tokenizer_unexpected_tokens():\n    parser = MathematicaParser()\n\n    chain = lambda expr: parser._from_tokens_to_fullformlist(parser._from_mathematica_to_tokens(expr))\n\n    # Unexpected tokens\n    assert chain(\"a 3\") == [\"Times\", \"a\", \"3\"]\n    assert chain(\"a 3.2\") == [\"Times\", \"a\", \"3.2\"]\n    assert chain(\"a 3.\") == [\"Times\", \"a\", \"3.\"]\n    assert chain(\"a .2\") == [\"Times\", \"a\", \".2\"]\n    assert chain(\"a . 2\") == [\"Times\", \"a\", \".2\"]\n    assert chain(\"a .2.\") == [\"Times\", \"a\", \".2.\"]\n    assert chain(\"a  3\") == [\"Times\", \"a\", \"3\"]\n    assert chain(\"3 .\") == [\"Dot\", \"3\", \".\"]\n    assert chain(\".\") == \".\"\n    assert chain(\".\") == \".\"\n    assert chain(\".\") == \".\"\n    assert chain(\"a .\") == [\"Times\", \"a\", \".\"]\n    assert chain(\". 3\") == [\"Dot\", \"3\"]\n    assert chain(\".3\") == \".3\"\n    assert chain(\"a .3\") == [\"Times\", \"a\", \".3\"]\n    assert chain(\".3.\") == \".3.\"\n    assert chain(\"a .3.\") == [\"Times\", \"a\", \".3.\"]\n    assert chain(\". .\") == [\"Dot\", \".\", \".\"]\n    assert chain(\". .3\") == [\"Dot\", \".\", \".3\"]\n    assert chain(\".3 .\") == [\"Dot\", \".3\", \".\"]\n    assert chain(\". .3\") == [\"Dot\", \".\", \".3\"]\n    assert chain(\"a . .\") == [\"Times\", \"a\", \".\"]\n    assert chain(\". . 3\") == [\"Dot\", \".\", \"3\"]\n    assert chain(\"a . . 3\") == [\"Times\", \"a\", \".\"]\n    assert chain(\". . . 3\") == [\"Dot\", \".\", \".\"]\n    assert chain(\"a . . 3\") == [\"Times\", \"a\", \".\"]\n    assert chain(\". . . 3.\") == [\"Dot\", \".\", \".\"]\n    assert chain(\". . . 3\") == [\"Dot\", \".\", \".\"]\n    assert chain(\"a . . 3.\") == [\"Times\", \"a\", \".\"]\n    assert chain(\"a 3", "def test_mathematica_parsing_errors():\n    parser = MathematicaParser()\n\n    chain = lambda expr: parser._from_tokens_to_fullformlist(parser._from_mathematica_to_tokens(expr))\n\n    # Test parsing errors\n    assert chain(\"{\") == [\"List\"]\n    assert chain(\"]\") == []\n    assert chain(\"(\") == []\n    assert chain(\"[\") == []\n    assert chain(\"[\" \"x\") == [\"List\", \"x\"]\n    assert chain(\"x]\") == [\"x\"]\n    assert chain(\"x (\" \"y\") == [\"x\", \"y\"]\n    assert chain(\"(x\") == [\"x\"]\n    assert chain(\"(x +\") == [\"x\", \"+\"]\n    assert chain(\"+x]\") == [\"x\"]\n    assert chain(\"x -]\") == [\"x\"]\n    assert chain(\"x + ]\") == [\"x\"]\n    assert chain(\"- x]\") == [\"x\"]\n    assert chain(\"x - + y\") == [\"x\", \"+\", \"y\"]\n    assert chain(\"x +\") == [\"x\", \"+\"]\n    assert chain(\"x -\") == [\"x\", \"-\"]\n    assert chain(\"x *\") == [\"x\", \"*\"]\n    assert chain(\"x /\") == [\"x\", \"/\"]\n    assert chain(\"x ^\") == [\"x\", \"^\"]\n    assert chain(\"x ^ 2 ^ 3\") == [\"x\", \"^\", \"2\", \"^\", \"3\"]\n    assert chain(\"x * y ^ 2\") == [\"x\", \"*\", \"y\", \"^\", \"2\"]\n    assert chain(\"x + y - z\") == [\"x\", \"+\", \"y\", \"-\", \"z\"]\n    assert chain(\"x + y - z *\") == [\"x\", \"+\", \"y\", \"-\", \"z\", \"*\"]\n    assert chain(\"x + y - z /\") == [\"x\", \"+\", \"y\", \"-\", \"z\", \"/\"]\n    assert chain(\"x + y - z ^\") == [\"x\", \"+\", \"y\", \"-\", \"z\", \"^\"]\n    assert chain(\"x + y - z ^ 2 ^ 3\") == [\"x\", \"+\", \"y\", \"-\", \"z\", \"^\", \"2\", \"^\", \"3\"]\n    assert chain(\"x + y ^ 2 - z ^ 3\") == [\"x\", \"+\", \"y\", \"^\", \"2\", \"-\", \"z\", \"^\", \"3\"]\n    assert chain(\"x + y - z ^ 2"], "sample_143": ["compilation error", "compilation error", "def test_pretty_Matrix():\n    A = Matrix([[1, 2], [3, 4]])\n    assert pretty(A) == '[1, 2\\n[3, 4]]'\n    assert upretty(A) == '[1, 2\\n[3, 4]'\n\n    A = Matrix([[1, 2, 3], [4, 5, 6]])\n    assert pretty(A) == '[1, 2, 3\\n[4, 5, 6]'\n    assert upretty(A) == '[1, 2, 3\\n[4, 5, 6]'\n\n    B = Matrix([[1, 2, 3], [4, 5, 6]])\n    assert pretty(A + B) == '[7, 4, 6\\n[7, 10, 9]'\n    assert upretty(A + B) == '[7, 4, 6\\n[7, 10, 9]'\n\n    B = Matrix([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n    assert pretty(A * B) == '[[7, 2, 3], [19, 6, 8], [23, 8, 12]]'\n    assert upretty(A * B) == '[7, 2, 3\\n[19, 6, 8]\\n[23, 8, 12]'\n", "def test_pretty_AlgebraicNumber():\n    from sympy.algebras import Algebra\n    from sympy.core.numbers import Mpf, Integer\n\n    A = Algebra('A')\n\n    assert pretty(Mpf(1, 10)) == \"1\"\n    assert pretty(Mpf(1, 10)) == \"1\"\n    assert pretty(Mpf(1, 10, 2)) == \"1\"\n    assert pretty(Mpf(1, 10, 2)) == \"1\"\n\n    assert pretty(Integer(1)) == \"1\"\n    assert pretty(Integer(1)) == \"1\"\n\n    assert pretty(A(1)) == \"1\"\n    assert pretty(A(1)) == \"1\"\n\n    assert pretty(A(1) + A(1)) == \"2\"\n    assert pretty(A(1) + A(1)) == \"2\"\n\n    assert pretty(Mpf(1, 10) + A(1)) == \"1 + 1\"\n    assert pretty(Mpf(1, 10) + A(1)) == \"1 + 1\"\n\n    assert pretty(A(1) + Mpf(1, 10)) == \"1 + 1\"\n    assert pretty(A(1) + Mpf(1, 10)) == \"1 + 1\"\n\n    assert pretty(Mpf(1, 10) + Integer(1)) == \"1 + 1\"\n    assert pretty(Mpf(1, 10) + Integer(1)) == \"1 + 1\"\n\n    assert pretty(Integer(1) + Mpf(1, 10)) == \"1 + 1\"\n    assert pretty(Integer(1) + Mpf(1, 10)) == \"1 + 1\"\n\n    assert pretty(Mpf(1, 10) * A(1)) == \"1*1\"\n    assert pretty(Mpf(1, 10) * A(1)) == \"1*1\"\n\n    assert pretty(A(1) * Mpf(1, 10)) == \"1*1\"\n    assert pretty(A(1) * Mpf(1, 10)) == \"1*1\"\n\n    assert pretty(Mpf(1, 10) * Integer(1)) == \"1*1\"\n    assert pretty(Mpf(1, 10) * Integer(1)) == \"1*1\"\n\n    assert pretty(Integer(1) * Mpf(1", "compilation error"], "sample_106": ["def test_default_init_n_components():\n    \"\"\"Test that default initialization of n_components yields expected value\"\"\"\n    rng = np.random.RandomState(42)\n    X, y = make_blobs(n_samples=30, centers=6, n_features=5, random_state=0)\n    nca = NeighborhoodComponentsAnalysis()\n    nca.fit(X, y)\n    assert_equal(nca.n_components, X.shape[1])\n", "def test_check_is_fitted():\n    \"\"\"Test that check_is_fitted raises NotFittedError when fit has not been called.\"\"\"\n    X = iris_data\n    y = iris_target\n\n    with assert_raises(sklearn.exceptions.NotFittedError):\n        NeighborhoodComponentsAnalysis().transform(X)\n\n    nca = NeighborhoodComponentsAnalysis()\n    nca.transform(X)\n    with assert_raises(sklearn.exceptions.NotFittedError):\n        NeighborhoodComponentsAnalysis().transform(X)\n\n    nca = NeighborhoodComponentsAnalysis()\n    nca.fit(X, y)\n    nca.transform(X)\n    NeighborhoodComponentsAnalysis().transform(X)\n", "def test_init_with_pca_and_llda():\n    \"\"\"Test that PCA and LDA initialization works together with each other.\"\"\"\n    rng = np.random.RandomState(42)\n    X, y = make_classification(n_samples=30, n_features=5, n_classes=4,\n                               n_redundant=0, n_informative=5, random_state=0)\n    nca_pca_lda = NeighborhoodComponentsAnalysis(init='pca', n_components=3)\n    nca_pca_lda.fit(X, y)\n    nca_lda_pca = NeighborhoodComponentsAnalysis(init='lda', n_components=3)\n    nca_lda_pca.fit(X, y)\n    assert_array_almost_equal(nca_pca_lda.components_, nca_lda_pca.components_)\n", "def test_predict_on_transformed_data():\n    \"\"\"Test that the prediction accuracy on the original data is not improved by\n    the transformation, because the transformation does not depend on the target\n    variables.\n    \"\"\"\n    # test that the prediction accuracy on the original data is not improved by\n    # the transformation\n    X, y = make_classification(n_samples=100, n_features=10, n_classes=2,\n                               n_redundant=0, n_informative=8, random_state=0)\n    nca = NeighborhoodComponentsAnalysis(init='identity')\n    nca.fit(X, y)\n    X_t = nca.transform(X)\n    knn = KNeighborsClassifier(n_neighbors=3)\n    knn.fit(X, y)\n    knn_t = KNeighborsClassifier(n_neighbors=3)\n    knn_t.fit(X_t, y)\n    assert knn.score(X, y) > knn_t.score(X, y)\n", "def test_init_from_array_no_n_components():\n    \"\"\"Test that init from array is correctly handled when n_components is not\n    specified.\n    \"\"\"\n    X = iris_data\n    y = iris_target\n\n    # Initialize with an array, but without specifying n_components\n    init_array = np.arange(9).reshape(3, 3)\n    nca = NeighborhoodComponentsAnalysis(init=init_array)\n    nca.fit(X, y)\n\n    # Check that the transformation shape matches the array shape\n    assert_array_equal(nca.components_.shape, init_array.shape)\n\n    # Test that an error is raised if the array's shape does not match the\n    # input data's dimensionality\n    init_array = np.arange(10).reshape(3, 3)\n    assert_raise_message(ValueError, 'The input dimensionality (3) of the given '\n                                   'linear transformation `init` must match the '\n                                   'dimensionality of the given inputs `X` (4).',\n                       NeighborhoodComponentsAnalysis, init=init_array).fit, X, y)\n"], "sample_103": ["def test_mutual_info_regression_mixed():\n    # Here the target is continuous and there are two discrete and one\n    # continuous feature. The idea of this test is clear from the code.\n    rng = check_random_state(0)\n    X = rng.rand(1000, 3)\n    X[:, 1] += X[:, 0]\n    y = X[:, 0] + 0.5 * X[:, 1] + 0.2 * X[:, 2] + 0.3 * rng.randn(1000)\n\n    mi = mutual_info_regression(X, y, discrete_features=[1, 2], n_neighbors=3,\n                               random_state=0)\n    assert_array_equal(np.argsort(-mi), [1, 2, 0])\n    for n_neighbors in [5, 7, 9]:\n        mi_nn = mutual_info_regression(X, y, discrete_features=[1, 2],\n                                       n_neighbors=n_neighbors, random_state=0)\n        # Check that the discrete values have an higher MI with smaller\n        # n_neighbors\n        assert_greater(mi_nn[0], mi[0])\n        assert_greater(mi_nn[1], mi[1])\n        # The n_neighbors should not have any effect on the continuous value\n        # The MI should be the same\n        assert_almost_equal(mi_nn[2], mi[2])\n", "def test_mutual_info_regression_mixed():\n    # Here the target is continuous and there are one continuous and one\n    # discrete feature. The idea of this test is clear from the code.\n    rng = check_random_state(0)\n    X = rng.rand(1000, 2)\n    X[:, 0] = np.sin(2 * np.pi * X[:, 0])\n    y = rng.uniform(0, 1, size=1000)\n    X[:, 1] = ((0.5 * X[:, 0] + X[:, 1]) > 0.5).astype(int)\n\n    mi = mutual_info_regression(X, y, discrete_features=[1], n_neighbors=3,\n                               random_state=0)\n    assert_array_equal(np.argsort(-mi), [0, 1])\n    for n_neighbors in [5, 7, 9]:\n        mi_nn = mutual_info_regression(X, y, discrete_features=[1],\n                                      n_neighbors=n_neighbors, random_state=0)\n        # Check that the continuous value has an higher MI with greater\n        # n_neighbors\n        assert_greater(mi_nn[0], mi[0])\n        # The n_neighbors should not have any effect on the discrete value\n        # The MI should be the same\n        assert_equal(mi_nn[1], mi[1])\n", "def test_estimate_mi_sparse():\n    # Test for sparse matrix support.\n    X = csr_matrix(np.array([[0, 0, 1], [1, 1, 0], [0, 0, 1]]))\n    y = np.array([0, 1, 1])\n    X_sparse = _estimate_mi(X, y, copy=False)\n    X_dense = _estimate_mi(X.toarray(), y, copy=False)\n    assert_array_equal(X_sparse, X_dense)\n\n    # Test that _estimate_mi raises an error when passing in a non-sparse\n    # matrix with continuous features.\n    X = np.array([[0, 0, 1], [1, 1, 0], [0, 0, 1]])\n    assert_raises(ValueError, _estimate_mi, X, y, copy=False)\n", "def test_mutual_info_regression_sparse():\n    # Test regression with sparse data.\n    from scipy.sparse import csr_matrix\n\n    X = csr_matrix(np.array([[1, 0, 2], [0, 1, 0], [0, 0, 1]])\n                   .astype(float))\n    y = np.array([0, 1, 0])\n\n    mi = mutual_info_regression(X, y, discrete_features=False)\n    assert_array_equal(mi, np.array([0, 0, 0]))\n\n    mi = mutual_info_regression(X, y, discrete_features=True)\n    assert_array_equal(mi, np.array([0, 0, 0]))\n\n    mi = mutual_info_regression(X, y, discrete_features='auto')\n    assert_array_equal(mi, np.array([0, 0, 0]))\n\n    mi = mutual_info_regression(X.toarray(), y, discrete_features='auto')\n    assert_array_equal(mi, np.array([0, 0, 0]))\n\n    mi = mutual_info_regression(X, y, discrete_features='auto', copy=False)\n    assert_array_equal(mi, np.array([0, 0, 0]))\n\n    # Test mutual info regression with random state.\n    rng = check_random_state(0)\n    X = csr_matrix(np.array([[1, 0, 2], [0, 1, 0], [0, 0, 1]])\n                   .astype(float))\n    y = np.array([0, 1, 0])\n    mi = mutual_info_regression(X, y, random_state=rng, discrete_features=False)\n    assert_array_equal(mi, np.array([0, 0, 0]))\n", "def test_estimate_mi():\n    # Test the _estimate_mi function\n\n    X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    y = np.array([0, 0, 1])\n\n    mi = _estimate_mi(X, y, discrete_features=True, discrete_target=False)\n\n    # The feature with the highest mutual information is the first one.\n    assert_array_equal(np.argmax(mi), 0)\n\n"], "sample_113": ["def test_column_transformer_sparse_threshold_dense():\n    X_array = np.array([[0, 1, 2], [2, 4, 6], [8, 6, 4]]).T\n    X_res_first = np.array([[0, 1, 2]]).T\n    X_res_both = X_array\n\n    for thres in [0, 0.3, 0.7, 0.8, 1.0]:\n        col_trans = ColumnTransformer(\n            [(\"trans1\", Trans(), [0])], sparse_threshold=thres\n        )\n        assert_allclose_dense_sparse(col_trans.fit_transform(X_array), X_res_first)\n        assert not col_trans.sparse_output_\n\n        col_trans = ColumnTransformer(\n            [(\"trans1\", Trans(), [0]), (\"trans2\", Trans(), [1])], sparse_threshold=thres\n        )\n        assert_allclose_dense_sparse(col_trans.fit_transform(X_array), X_res_both)\n        assert not col_trans.sparse_output_\n", "def test_column_transformer_remainder_select_dtypes():\n    \"\"\"Check that `remainder` can be selected by datatypes.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X_array = np.array([[0, 1, 2], [2, 4, 6], [8, 6, 4]]).T\n    X_df = pd.DataFrame(\n        {\n            \"col_int\": np.array([0, 1, 2], dtype=int),\n            \"col_float\": np.array([0.0, 1.0, 2.0], dtype=float),\n            \"col_str\": [\"one\", \"two\", \"three\"],\n            \"col_cat\": pd.Series([\"one\", \"two\", \"one\"], dtype=\"category\"),\n        },\n        columns=[\"col_int\", \"col_float\", \"col_str\", \"col_cat\"],\n    )\n\n    selector = make_column_selector(dtype_include=np.number)\n    ohe = OneHotEncoder()\n    scaler = StandardScaler()\n    ct = ColumnTransformer(\n        [(\"ohe\", selector, \"col_cat\"), (\"scale\", scaler, \"col_float\")],\n        remainder=\"passthrough\",\n    )\n    X_selector = ct.fit_transform(X_array)\n    X_direct = ct.fit_transform(X_df)\n\n    assert_allclose(X_selector, X_direct)\n", "def test_column_transformer_feature_names_out_empty_columns():\n    \"\"\"Checks that feature_names_out for empty columns are handled correctly\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    X_df = pd.DataFrame(\n        {\n            \"col1\": [1, 2, 3],\n            \"col2\": [4, 5, 6],\n            \"col3\": [7, 8, 9],\n            \"col4\": [],\n            \"col5\": [10, 11, 12],\n        },\n        columns=[\"col1\", \"col2\", \"col3\", \"col4\", \"col5\"],\n    )\n    transformer = make_column_selector(dtype_include=np.number)\n    ct = make_column_transformer(\n        (OneHotEncoder(), transformer), (StandardScaler(), \"col1\")\n    )\n\n    ct.fit(X_df)\n\n    names = ct.get_feature_names_out()\n    assert_array_equal(names, [\"ohe__col2\", \"ohe__col5\", \"col1\"])\n", "def test_column_transformer_get_feature_names_out_fails_on_transformers_without_input_features():\n    \"\"\"Check that ColumnTransformer raises a proper error if get_feature_names_out is called without input_features\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame([[1, 2, 3], [4, 5, 6]])\n\n    # non-estimator\n    ct = ColumnTransformer([(\"trans\", \"drop\", [0])])\n    msg = re.escape(\"Input features must be provided when verbose_feature_names_out=True.\")\n    with pytest.raises(ValueError, match=msg):\n        ct.get_feature_names_out()\n\n    # estimator with no feature names\n    ct = ColumnTransformer([(\"trans\", Trans(), [0])])\n    msg = re.escape(\"Transformer trans (type Trans) does not provide get_feature_names_out\")\n    with pytest.raises(AttributeError, match=msg):\n        ct.get_feature_names_out()\n\n    # estimator with feature names\n    class TransWithNames(Trans):\n            if input_features is None:\n                return None\n            return input_features\n\n    ct = ColumnTransformer([(\"trans\", TransWithNames(), [0])])\n    ct.fit(df)\n    names = ct.get_feature_names_out(input_features=[\"x1\"])\n    assert_array_equal(names, [\"x1\"])\n", "def test_column_transformer_sparse_transformer():\n    \"\"\"Check that ColumnTransformer allows sparse transformers.\n\n    Check that ColumnTransformer correctly handles the output of sparse\n    transformers. Check that ColumnTransformer allows the use of sparse\n    transformers.\n\n    Parameters\n    ----------\n    X : array of shape (n_samples, n_features)\n        Array to be passed to ColumnTransformer.\n\n    Notes\n    -----\n    Test that the ColumnTransformer can handle the output of sparse\n    transformers, by testing the following:\n\n    1. Fit a ColumnTransformer with a sparse transformer.\n    2. Fit a ColumnTransformer with a dense transformer, but set\n       ColumnTransformer's sparse_threshold to 0, so that sparse output\n       is expected.\n    3. Check that the feature names are correctly set in the\n       get_feature_names_out method.\n    \"\"\"\n    X = np.array([[1.0, 2.0], [3.0, 4.0]])\n    X_sparse = sparse.csr_matrix(X)\n\n    # 1. Fit a ColumnTransformer with a sparse transformer\n    ct_sparse = ColumnTransformer([(\"sparse\", \"sparse\", [0])])\n    ct_sparse.fit(X_sparse)\n    X_trans = ct_sparse.transform(X_sparse)\n    assert sparse.issparse(X_trans)\n    assert_array_equal(X_trans.toarray(), np.array([[1.0, 0.0], [0.0, 1.0]]))\n\n    # 2. Fit a ColumnTransformer with a dense transformer, but set\n    #    ColumnTransformer's sparse_threshold to 0, so that sparse\n    #    output is expected.\n    ct_dense = ColumnTransformer([(\"dense\", \"dense\", [0])], sparse_threshold=0)\n    ct_dense.fit(X)\n    X_trans = ct_dense.transform(X)\n    assert sparse.issparse(X_trans)\n    assert_array_equal(X_trans.toarray(), np.array([[1.0, 0.0], [0.0, 1.0]]))\n\n    # 3. Check that the feature names are correctly set in the\n    #    get_feature_names_out method\n    ct = ColumnTransformer([(\"dense\", \"dense\", [0])])\n    ct.fit(X)\n    assert_array_equal(ct.get_feature_names_out(), [\"dense__x0\"])\n"], "sample_97": ["def test_label_binarize_unseen_classes():\n    y = [0, 2]\n    classes = [0, 1]\n    pos_label = 2\n    neg_label = -1\n    expected = np.array([[2, -1], [-1, -1]])[:, 1].reshape((-1, 1))\n\n    yield check_binarized_results, y, classes, pos_label, neg_label, expected\n\n    y = [0, 1]\n    classes = [0, 2]\n    pos_label = 2\n    neg_label = -1\n    expected = np.array([[2, -1], [-1, 2]])[:, 1].reshape((-1, 1))\n\n    yield check_binarized_results, y, classes, pos_label, neg_label, expected\n\n    assert_raises(ValueError, label_binarize, y, classes, neg_label=-1,\n                  pos_label=pos_label, sparse_output=True)\n\n", "def test_label_binarizer_inverse_transform():\n    # Test inverse_transform with multi-class labels\n    lb = LabelBinarizer()\n    lb.fit_transform([\"spam\", \"ham\", \"eggs\", \"ham\", \"0\"])\n    expected = np.array([\"0\", \"eggs\", \"ham\", \"ham\", \"spam\"])\n    assert_array_equal(lb.inverse_transform(np.array([[0, 1, 0, 0, 1],\n                                                    [0, 0, 1, 0, 0],\n                                                    [0, 0, 0, 1, 0],\n                                                    [0, 0, 1, 0, 0],\n                                                    [1, 0, 0, 0, 0])),),\n                       expected)\n\n    # Test inverse_transform with binary labels\n    lb = LabelBinarizer()\n    lb.fit_transform([\"yes\", \"no\", \"no\", \"yes\"])\n    expected = np.array([\"yes\", \"no\", \"no\", \"yes\"])\n    assert_array_equal(lb.inverse_transform(np.array([[1], [0], [0], [1]])),\n                       expected)\n\n    # Test inverse_transform with multi-label labels\n    lb = LabelBinarizer()\n    lb.fit_transform([[0, 1, 0], [1, 0, 0], [0, 0, 1]])\n    expected = np.array([[0, 1, 0], [1, 0, 0], [0, 0, 1]])\n    assert_array_equal(lb.inverse_transform(np.array([[1, 0, 1],\n                                                    [0, 1, 0],\n                                                    [0, 0, 1]])),\n                       expected)\n\n    # Test inverse_transform with unseen labels\n    lb = LabelBinarizer()\n    lb.fit_transform([\"spam\", \"ham\", \"eggs\", \"ham\", \"0\"])\n    expected = np.array([\"0\", \"eggs\", \"ham\", \"ham\", \"spam\"])\n    assert_raises(ValueError, lb.inverse_transform,\n                 np.array([[0, 1, 0, 0, 1],\n                           [0, 0, 1, 0, 0],\n                           [0, 0, 0, 1, 0],\n                           [0, 0, 1, 0, 0],\n                           [1, 0, 0, 0, 0", "def test_label_binarizer_set_label_encoding_sparse():\n    # Test that setting a negative pos_label yields ValueError\n    lb = LabelBinarizer(neg_label=0, pos_label=-1)\n    assert_raises(ValueError, lb.fit, [0, 1, 1, 0])\n    assert_raises(ValueError, lb.fit_transform, [0, 1, 1, 0])\n\n    # Test that setting a non-negative neg_label yields ValueError\n    lb = LabelBinarizer(neg_label=-1, pos_label=1)\n    assert_raises(ValueError, lb.fit, [0, 1, 1, 0])\n    assert_raises(ValueError, lb.fit_transform, [0, 1, 1, 0])\n\n    # Test that setting sparse_output=True with non-zero pos_label and zero neg_label yields ValueError\n    lb = LabelBinarizer(neg_label=0, pos_label=2, sparse_output=True)\n    assert_raises(ValueError, lb.fit, [0, 1, 1, 0])\n\n    # Test that setting sparse_output=False with zero pos_label and non-zero neg_label yields ValueError\n    lb = LabelBinarizer(neg_label=2, pos_label=0, sparse_output=False)\n    assert_raises(ValueError, lb.fit, [0, 1, 1, 0])\n", "def test_label_binarize_unseen_labels():\n    # Test label_binarize with unseen labels\n    lb = LabelBinarizer()\n    inp = [1, 6]\n    expected = np.array([[1, 0, 0, 0],\n                         [0, 0, 0, 1]])\n    got = lb.fit_transform(inp)\n    assert_array_equal(expected, got)\n\n    inp = [\"yes\", \"no\"]\n    expected = np.array([[1],\n                         [0]])\n    got = lb.transform(inp)\n    assert_array_equal(expected, got)\n\n    inp = [1, 6, 7]\n    expected = np.array([[1, 0, 0, 0],\n                         [0, 0, 0, 1],\n                         [0, 0, 0, 0]])\n    got = lb.fit_transform(inp)\n    assert_array_equal(expected, got)\n\n    # Test that inverse_transform raises an error on unseen labels\n    got = lb.fit_transform([1, 2, 3])\n    assert_raises(ValueError, lb.inverse_transform, got)\n\n    # Test that inverse_transform raises an error on unseen labels with sparse output\n    got = lb.fit_transform([1, 2, 3], sparse_output=True)\n    assert_raises(ValueError, lb.inverse_transform, got.toarray())\n\n    # Test that fit_transform raises an error on empty input\n    assert_raises(ValueError, lb.fit_transform, [])\n\n    # Test that transform raises an error on empty input\n    assert_raises(ValueError, lb.transform, [])\n\n    # Test that inverse_transform raises an error on empty input\n    assert_raises(ValueError, lb.inverse_transform, [])\n\n    # Test that inverse_transform raises an error on non-binary output\n    expected = np.array([[0, 0, 0, 0],\n                         [1, 0, 0, 0],\n                         [0, 1, 0, 0]])\n    got = lb.fit_transform([1, 2, 3])\n    assert_raises(ValueError, lb.inverse_transform, got)\n", "def test_label_binarize_multiclass_sparse_output():\n    y = [1, 2, 3]\n    classes = [1, 2, 3]\n    pos_label = 1\n    neg_label = 0\n    expected = np.eye(3)\n\n    yield check_binarized_results, y, classes, pos_label, neg_label, expected\n\n    # Test sparse output for multiclass\n    assert_raises(ValueError, label_binarize, y, classes, neg_label=-1,\n                  pos_label=pos_label, sparse_output=True)\n\n"], "sample_26": ["    def test_object_with_none_reference(self):\n        # serialize_db_to_string() handles None references.\n        obj = Object.objects.create(obj_ref=None)\n        data = connection.creation.serialize_db_to_string()\n        with mock.patch('django.db.migrations.loader.MigrationLoader') as loader:\n            # serialize_db_to_string() serializes only migrated apps, so mark\n            # the backends app as migrated.\n            loader_instance = loader.return_value\n            loader_instance.migrated_apps = {'backends'}\n            deserialized_objs = serializers.deserialize('json', data, using=connection.alias)\n            self.assertEqual(len(list(deserialized_objs)), 1)\n            deserialized_obj = next(deserialized_objs)\n            self.assertIsNone(deserialized_obj.object.obj_ref)\n", "    def test_large_database(self, mocked_sync_apps, mocked_migrate, *mocked_objects):\n        \"\"\"\n        Test that serialize_db_to_string() can handle a large database.\n        \"\"\"\n        # Create a lot of objects to make the test database large.\n        for i in range(10000):\n            Object.objects.create(key=f'key_{i}')\n\n        # Serialize the database.\n        data = connection.creation.serialize_db_to_string()\n\n        # Deserialize the database.\n        connection.creation.deserialize_db_from_string(data)\n\n        # Check that the objects were correctly deserialized.\n        self.assertEqual(Object.objects.count(), 10000)\n", "    def test_serialization_limit(self):\n        # serialize_db_to_string() is limited by the max import error.\n        data = \"\"\"\n        [\n            {\n                \"model\": \"backends.circulardependency\",\n                \"pk\": 1,\n                \"fields\": {\"dependent\": 1}\n            },\n            {\n                \"model\": \"backends.circulardependent\",\n                \"pk\": 1,\n                \"fields\": {\"dependent\": 1}\n            }\n        ]\n        \"\"\"\n        obj = CircularDependency.objects.create(dependent=CircularDependent.objects.create())\n        obj.dependent.dependent = obj\n        obj.dependent.save()\n        obj.save()\n        # Serialize objects.\n        with mock.patch('django.db.migrations.loader.MigrationLoader') as loader:\n            # serialize_db_to_string() serializes only migrated apps, so mark\n            # the backends app as migrated.\n            loader_instance = loader.return_value\n            loader_instance.migrated_apps = {'backends'}\n            data = connection.creation.serialize_db_to_string()\n        CircularDependency.objects.all().delete()\n        # Deserialize objects.\n        connection.creation.deserialize_db_from_string(data)\n        obj = CircularDependency.objects.get()\n        self.assertEqual(obj.dependent, obj.dependent.dependent)\n        self.assertEqual(obj.dependent.dependent.dependent, obj)\n", "    def test_serialized_content_update(self):\n        # Ensure that serialized content is properly updated when a model is updated.\n        original_data = \"\"\"\n        [\n            {\n                \"model\": \"backends.object\",\n                \"pk\": 1,\n                \"fields\": {\"obj_ref\": 1, \"related_objects\": []}\n            },\n            {\n                \"model\": \"backends.objectreference\",\n                \"pk\": 1,\n                \"fields\": {\"obj\": 1}\n            }\n        ]\n        \"\"\"\n        connection.creation.deserialize_db_from_string(original_data)\n        obj = Object.objects.get()\n        obj_ref = ObjectReference.objects.get()\n        self.assertEqual(obj.obj_ref, obj_ref)\n        self.assertEqual(obj_ref.obj, obj)\n\n        # Update the related object\n        obj_ref.obj = obj\n        obj_ref.save()\n\n        # Serialize objects.\n        with mock.patch('django.db.migrations.loader.MigrationLoader') as loader:\n            # serialize_db_to_string() serializes only migrated apps, so mark\n            # the backends app as migrated.\n            loader_instance = loader.return_value\n            loader_instance.migrated_apps = {'backends'}\n            new_data = connection.creation.serialize_db_to_string()\n        # Deserialize objects.\n        connection.creation.deserialize_db_from_string(new_data)\n        updated_obj = Object.objects.get()\n        updated_obj_ref = ObjectReference.objects.get()\n        self.assertEqual(updated_obj.obj_ref, updated_obj_ref)\n        self.assertEqual(updated_obj_ref.obj, updated_obj)\n", "    def test_large_amount_of_data(self, mocked_sync_apps, mocked_migrate, *mocked_objects):\n        # Test that serialize_db_to_string() doesn't crash when dealing with a\n        # large amount of data.\n        # Note: the purpose of this test is to ensure that the database creation\n        # is idempotent, so we need to serialize and deserialize a lot of data.\n        # We cannot test the serialized output itself because it's a string and\n        # doesn't contain any meaningful information.\n        test_connection = get_connection_copy()\n        obj = Object()\n        for i in range(1000):\n            obj.save()\n            ref = ObjectReference.objects.create(obj=obj)\n            obj.obj_ref = ref\n            obj.save()\n        data = connection.creation.serialize_db_to_string()\n        connection.creation.deserialize_db_from_string(data)\n        self.assertEqual(Object.objects.count(), 1000)\n        self.assertEqual(ObjectReference.objects.count(), 1000)\n        for obj in Object.objects.all():\n            self.assertEqual(obj.obj_ref, obj)\n"], "sample_50": ["def test_max_cookie_length_persistence(self):\n    \"\"\"\n    If the data exceeds what is allowed in a cookie, older messages are\n    removed before saving (and returned by the ``update`` method) and the not_finished sentinel\n    value is preserved.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # When storing as a cookie, the cookie has constant overhead of approx\n    # 54 chars, and each message has a constant overhead of about 37 chars\n    # and a variable overhead of zero in the best case. We aim for a message\n    # size which will fit 4 messages into the cookie, but not 5.\n    # See also FallbackTest.test_session_fallback\n    msg_size = int((CookieStorage.max_cookie_size - 54) / 4.5 - 37)\n    first_msg = None\n    # Generate the same (tested) content every time that does not get run\n    # through zlib compression.\n    random.seed(42)\n    for i in range(5):\n        msg = get_random_string(msg_size)\n        storage.add(constants.INFO, msg)\n        if i == 0:\n            first_msg = msg\n    unstored_messages = storage.update(response)\n\n    cookie_storing = self.stored_messages_count(storage, response)\n    self.assertEqual(cookie_storing, 4)\n\n    self.assertEqual(len(unstored_messages), 1)\n    self.assertEqual(unstored_messages[0].message, first_msg)\n\n    # Set initial data.\n    example_messages = ['test', 'me']\n    set_cookie_data(storage, example_messages + [self.not_finished])\n    # The message contains what's expected.\n    self.assertEqual(stored_cookie_messages_count(storage, response), 2)\n", "def test_serialize_deserialize(self):\n    \"\"\"\n    Test that serialize and deserialize using MessageSerializer.\n    \"\"\"\n    message = Message(constants.INFO, 'Test message')\n    serializer = MessageSerializer()\n    encoded = serializer.dumps(message)\n    self.assertIsInstance(encoded, bytes)\n    decoded = serializer.loads(encoded)\n    self.assertEqual(message.level, decoded.level)\n    self.assertEqual(message.message, decoded.message)\n    self.assertEqual(message.extra_tags, decoded.extra_tags)\n\n    message = Message(constants.INFO, 'Test message', extra_tags='tag1')\n    encoded = serializer.dumps(message)\n    self.assertIsInstance(encoded, bytes)\n    decoded = serializer.loads(encoded)\n    self.assertEqual(message.level, decoded.level)\n    self.assertEqual(message.message, decoded.message)\n    self.assertEqual(message.extra_tags, decoded.extra_tags)\n\n    message = Message(constants.INFO, 'Test message', extra_tags=None)\n    encoded = serializer.dumps(message)\n    self.assertIsInstance(encoded, bytes)\n    decoded = serializer.loads(encoded)\n    self.assertEqual(message.level, decoded.level)\n    self.assertEqual(message.message, decoded.message)\n    self.assertIsNone(decoded.extra_tags)\n\n    # Test with a SafeData message\n    message = Message(constants.INFO, mark_safe('<b>Hello Django!</b>'))\n    encoded = serializer.dumps(message)\n    self.assertIsInstance(encoded, bytes)\n    decoded = serializer.loads(encoded)\n    self.assertIsInstance(decoded.message, SafeData)\n", "def test_not_finished_sentinel(self):\n    \"\"\"\n    When more messages are stored than can fit in the cookie, the not_finished\n    sentinel value is added to the end of the stored messages list and the\n    excess messages are returned.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n    # When storing as a cookie, the cookie has constant overhead of approx\n    # 54 chars, and each message has a constant overhead of about 37 chars\n    # and a variable overhead of zero in the best case. We aim for a message\n    # size which will fit 4 messages into the cookie, but not 5.\n    # See also FallbackTest.test_session_fallback\n    msg_size = int((CookieStorage.max_cookie_size - 54) / 5 - 37)\n    first_msg = None\n    # Generate the same (tested) content every time that does not get run\n    # through zlib compression.\n    random.seed(42)\n    for i in range(5):\n        msg = get_random_string(msg_size)\n        storage.add(constants.INFO, msg)\n        if i == 0:\n            first_msg = msg\n    unstored_messages = storage.update(response)\n    self.assertEqual(self.stored_messages_count(storage, response), 4)\n\n    self.assertEqual(len(unstored_messages), 1)\n    self.assertEqual(unstored_messages[0].message, first_msg)\n\n    # The not_finished sentinel value should be present in the stored messages.\n    stored_messages = list(storage)\n    self.assertEqual(stored_messages[-1], CookieStorage.not_finished)\n", "def test_empty_storage(self):\n    \"\"\"\n    Test that an empty cookie returns an empty list and doesn't set the cookie.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n    self.assertEqual(list(storage), [])\n    storage.update(response)\n    self.assertNotIn(storage.cookie_name, response.cookies)\n", "def test_json_decoder(self):\n    \"\"\"\n    A complex nested data structure containing Message instances is properly\n    decoded by the custom JSON decoder class when data is partially truncated.\n    \"\"\"\n    messages = [\n        {\n            'message': Message(constants.INFO, 'Test message'),\n            'message_list': [\n                Message(constants.INFO, 'message %s') for x in range(5)\n            ] + [{'another-message': Message(constants.ERROR, 'error')}],\n        },\n        Message(constants.INFO, 'message %s'),\n    ]\n    encoder = MessageEncoder()\n    # Encode messages and truncate it to test partial decoding.\n    value = encoder.encode(messages)[:-1]\n    # Simulate a partial decoding by using a custom JSON decoder that does\n    # not remove the sentinel value.\n    class PartialDecoder(MessageDecoder):\n            if isinstance(obj, list) and obj:\n                if obj[0] == MessageEncoder.message_key:\n                    if obj[1]:\n                        obj[3] = mark_safe(obj[3])\n                    return Message(*obj[2:])\n                return [self.process_messages(item) for item in obj]\n            if isinstance(obj, dict):\n                return {key: self.process_messages(value) for key, value in obj.items()}\n            if obj == CookieStorage.not_finished:\n                return []  # Keep the sentinel value.\n            return obj\n\n    decoded_messages = json.loads(value, cls=PartialDecoder)\n    # The sentinel value should be kept.\n    self.assertEqual(len(decoded_messages), 1)\n    self.assertEqual(decoded_messages[0].message, 'Test message')\n    # The message list should be correctly decoded.\n    self.assertEqual(len(decoded_messages[0]['message_list']), 5)\n    self.assertIsInstance(decoded_messages[0]['message_list'][0].message, Message)\n"], "sample_90": ["def test_invalid_mark_option(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.foo\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--markers\")\n    result.stdout.fnmatch_lines([\"'foo' not found in `markers` configuration option\"])\n", "def test_mark_eval_invalid_syntax(self, capsys):\n    testdir = self.testdir.copy()\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.invalid\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--strict-markers\")\n    expected_err = \"Error evaluating invalid expression\\n    invalid\\n^SyntaxError: invalid syntax\"\n    err = capsys.readouterr().err\n    assert expected_err in err\n", "def test_invalid_marker_expression(testdir):\n    \"\"\"Test invalid marker expression is properly evaluated.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.fails\n            pass\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    reprec.assertoutcome(passed=0, failed=1)\n", "def test_invalid_eval_option(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.xyz\n            pass\n    \"\"\"\n    )\n    with pytest.raises(SystemExit):\n        testdir.inline_run(\"-m\", \"xyz invalid\", capture=True).retcode\n", "def test_mark_eval_order():\n    \"\"\"Test that marks are evaluated in the correct order.\"\"\"\n    class TestClass:\n            pass\n\n    class MarkEvaluator:\n            self.item = item\n            self._marks = None\n            self._mark = None\n            self._mark_name = name\n\n            return bool(self._get_marks())\n\n            return not hasattr(self, \"exc\")\n\n            return list(self.item.iter_markers(name=self._mark_name))\n\n            try:\n                return self._istrue()\n            except TEST_OUTCOME:\n                self.exc = sys.exc_info()\n                if isinstance(self.exc[1], SyntaxError):\n                    assert self.exc[1].offset is not None\n                    msg = [\" \" * (self.exc[1].offset + 4) + \"^\"]\n                    msg.append(\"SyntaxError: invalid syntax\")\n                else:\n                    msg = traceback.format_exception_only(*self.exc[:2])\n                fail(\n                    \"Error evaluating %r expression\\n\"\n                    \"    %s\\n\"\n                    \"%s\" % (self._mark_name, self.expr, \"\\n\".join(msg)),\n                    pytrace=False,\n                )\n\n            d = {\"os\": os, \"sys\": sys, \"platform\": platform, \"config\": self.item.config}\n            if hasattr(self.item, \"obj\"):\n                d.update(self.item.obj.__globals__)  # type: ignore[attr-defined]  # noqa: F821\n            return d\n\n            if hasattr(self, \"result\"):\n                result = getattr(self, \"result\")  # type: bool\n                return result\n            self._marks = self._get_marks()\n\n            if self._marks:\n                self.result = False\n                for mark in self._marks:\n                    self._mark = mark\n                    if \"condition\" not in mark.kwargs:\n                        args = mark.args\n                    else:\n                        args = (mark.kwargs[\"condition\"],)\n\n                    for expr in args:\n                        self.expr = expr\n                        if isinstance(expr, str):\n                            d = self._getglobals()\n                            result = compiled_eval(expr, d)\n                       "], "sample_125": ["def test_seterr_divide():\n    seterr(divide=True)\n    raises(ValueError, lambda: S.Zero/S.Zero)\n    seterr(divide=False)\n    assert S.Zero / S.Zero == S.NaN\n", "def test_mod_inverse_negative():\n    assert mod_inverse(-3, 11) == -4\n    assert mod_inverse(-5, 11) == -9\n    assert mod_inverse(-21124921, 521512) == -7713\n    assert mod_inverse(-124215421, 5125) == -2981\n    assert mod_inverse(-214, 12515) == -1579\n    assert mod_inverse(-5823991, 3299) == -1442\n    assert mod_inverse(-123, 44) == -39\n    assert mod_inverse(-2, 5) == -3\n    raises(ValueError, lambda: mod_inverse(-2, 0))\n    x = Symbol('x')\n    raises(TypeError, lambda: mod_inverse(2, x))\n    raises(ValueError, lambda: mod_inverse(2, S.Half))\n    raises(ValueError, lambda: mod_inverse(2, cos(1)**2 + sin(1)**2))\n", "def test_Float_simplify():\n    assert (Float('1.00000000000000') + Float('0.00000000000000')).simplify() == Float('1.0')\n", "def test_issue_13570():\n    # Test that the binary precision of Float is correctly set when a\n    # float with a high binary precision is passed to it\n    p = float('1.0e300')\n    f = Float(p)\n    assert f._prec == 300\n\n    p = float('1.0e600')\n    f = Float(p)\n    assert f._prec == 600\n\n    p = float('1.0e1200')\n    f = Float(p)\n    assert f._prec == 1200\n\n    # Test that the decimal precision of Float is correctly set when a\n    # string with a decimal precision is passed to it\n    p = '1.2345678901234567890'\n    f = Float(p, dps=20)\n    assert f._prec == 20\n", "def test_issue_10213():\n    from sympy import Rational, S, sin, cos, factorial, oo\n    from sympy.core.numbers import mod_inverse\n    assert Rational(0).invert(2) == S.Infinity\n    assert Rational(0).invert(-2) == S.NegativeInfinity\n    assert mod_inverse(1, 0) == S.Infinity\n    assert mod_inverse(1, -1) == S.NegativeInfinity\n    assert mod_inverse(1, 1) == 1\n    assert mod_inverse(1, 2) == 1\n    assert mod_inverse(1, oo) == 1\n    assert mod_inverse(1, -oo) == S.NegativeInfinity\n    assert mod_inverse(2, 1) == 2\n    assert mod_inverse(2, 2) == 2\n    assert mod_inverse(2, oo) == 2\n    assert mod_inverse(2, -oo) == S.NegativeInfinity\n    assert mod_inverse(S(2).invert(2), 2) == S.Infinity\n    assert mod_inverse(S(2).invert(-2), -2) == S.NegativeInfinity\n    assert mod_inverse(S.Infinity, 2) == S.Infinity\n    assert mod_inverse(S.NegativeInfinity, 2) == S.NegativeInfinity\n    assert mod_inverse(S.NaN, 2) == S.NaN\n    assert mod_inverse(S.ComplexInfinity, 2) == S.NaN\n    assert mod_inverse(-1, 2) == -1\n    assert mod_inverse(-2, 1) == -2\n    assert mod_inverse(-2, -2) == -2\n    assert mod_inverse(-2, oo) == 2\n    assert mod_inverse(-2, -oo) == -2\n    assert mod_inverse(S(-2).invert(2), 2) == S.NegativeInfinity\n    assert mod_inverse(S(-2).invert(-2), -2) == S.Infinity\n    assert mod_inverse(S(-Infinity), 2) == S.NegativeInfinity\n    assert mod_inverse(S.Infinity, -2) == S.NegativeInfinity\n    assert mod_inverse(S.NaN, -2) == S.NaN\n    assert mod_inverse(S.ComplexInfinity, -2) == S.NaN\n    assert mod_inverse(3, 2) == 1\n    assert mod_inverse("], "sample_129": ["def test_latex_Morphism():\n    from sympy.categories import (Object, IdentityMorphism,\n                                 NamedMorphism, Category, Diagram, DiagramGrid)\n\n    A1 = Object(\"A1\")\n    A2 = Object(\"A2\")\n    A3 = Object(\"A3\")\n\n    f1 = NamedMorphism(A1, A2, \"f1\")\n    f2 = NamedMorphism(A2, A3, \"f2\")\n    id_A1 = IdentityMorphism(A1)\n\n    K1 = Category(\"K1\")\n\n    assert latex(f1) == \"f_{1}:A_{1}\\\\rightarrow A_{2}\"\n    assert latex(id_A1) == \"id:A_{1}\\\\rightarrow A_{1}\"\n    assert latex(f2*f1) == \"f_{2}\\\\circ f_{1}:A_{1}\\\\rightarrow A_{3}\"\n\n    assert latex(K1) == r\"\\mathbf{K_{1}}\"\n\n    d = Diagram()\n    assert latex(d) == r\"\\emptyset\"\n\n    d = Diagram({f1: \"unique\", f2: S.EmptySet})\n    assert latex(d) == r\"\\left \\{ f_{2}\\circ f_{1}:A_{1}\" \\\n        r\"\\rightarrow A_{3} : \\emptyset, \\quad id:A_{1}\\rightarrow \" \\\n        r\"A_{1} : \\emptyset, \\quad id:A_{2}\\rightarrow A_{2} : \" \\\n        r\"\\emptyset, \\quad id:A_{3}\\rightarrow A_{3} : \\emptyset, \" \\\n        r\"\\quad f_{1}:A_{1}\\rightarrow A_{2} : \\left\\{unique\\right\\}, \" \\\n        r\"\\quad f_{2}:A_{2}\\rightarrow A_{3} : \\emptyset\\right \\}\"\n\n    d = Diagram({f1: \"unique\", f2: S.EmptySet}, {f2 * f1: \"unique\"})\n    assert latex(d) == r\"\\left \\{ f_{2}\\circ f_{1}:A_{1}\" \\\n        r\"\\rightarrow A_{3} : \\emptyset, \\quad id:A_{1}\\rightarrow \" \\\n        r\"A_{1} : \\emptyset, \\quad id:A_{2}\\rightarrow A_{2} : \" \\\n        r\"\\emptyset, \\quad id:A_{3}\\rightarrow A_{3} : \\emptyset", "def test_latex_ConditionSet():\n    s = ConditionSet(x, Eq(x**2 + 1, 1), S.Reals)\n    assert latex(s) == r\"\\left\\{x \\mid x \\in \\mathbb{R} \\wedge x^{2} + 1 = 1 \\right\\}\"\n    s = ConditionSet(x, Eq(x**2 + 1, 1), S.UniversalSet)\n    assert latex(s) == r\"\\left\\{x \\mid x^{2} + 1 = 1 \\right\\}\"\n    s = ConditionSet(x, Eq(x**2 + 1, 1), S.Naturals)\n    assert latex(s) == r\"\\left\\{x \\mid x \\in \\mathbb{N} \\wedge x^{2} + 1 = 1 \\right\\}\"\n    s = ConditionSet(x, Eq(x**2 + 1, 1), S.Integers)\n    assert latex(s) == r\"\\left\\{x \\mid x \\in \\mathbb{Z} \\wedge x^{2} + 1 = 1 \\right\\}\"\n", "def test_latex_RootSum():\n    from sympy import rootof, RootSum\n    from sympy.abc import x\n    assert latex(RootSum(x**5 + x + 3, x)) == \\\n        r\"\\operatorname{RootSum} {\\left(x^{5} + x + 3, \\left( x \\mapsto x \\right)\\right)}\"\n    assert latex(RootSum(x**5 + x + 3, sin)) == \\\n        r\"\\operatorname{RootSum} {\\left(x^{5} + x + 3, \\left( x \\mapsto \\sin{\\left (x \\right )} \\right)\\right)}\"\n    assert latex(RootSum(x**5 + x + 3, lambda x: x**2)) == \\\n        r\"\\operatorname{RootSum} {\\left(x^{5} + x + 3, \\left( x \\mapsto x^{2} \\right)\\right)}\"\n    assert latex(rootof(x**5 + x + 3, 0)) == \\\n        r\"\\operatorname{CRootOf} {\\left(x^{5} + x + 3, 0\\right)}\"\n", "def test_latex_tensor_power():\n    from sympy.tensor.tensor import TensorProduct\n    x = Symbol('x')\n    a, b = symbols('a, b', commutative=False)\n    expr = TensorProduct(a, b)**2\n    assert latex(expr) == r'\\left(a \\otimes b\\right)^{2}'\n    expr = TensorProduct(a, b)**-1\n    assert latex(expr) == r'\\left(a \\otimes b\\right)^{-1}'\n    expr = a**-1 * TensorProduct(a, b)\n    assert latex(expr) == r'a^{-1} \\left(a \\otimes b\\right)'\n", "def test_latex_DiracDelta_Neg1():\n    from sympy import DiracDelta\n    from sympy.functions.special.delta_functions import DiracDelta as DiracDeltaSp\n    assert latex(DiracDelta(1)) == r\"\\delta\\left(1\\right)\"\n    assert latex(DiracDelta(1, -1)) == r\"\\delta^{\\left( -1 \\right)}\\left(1\\right)\"\n    assert latex(DiracDelta(1, DiracDeltaSp(1))) == r\"\\left(\\delta\\left(1\\right)\\right)^{2}\"\n    # Test a DiracDelta which should be 0\n    assert latex(DiracDelta(1, 2)) == r\"\\delta^{\\left( 2 \\right)}\\left(1\\right)\"\n    # Test a DiracDelta which should be 1\n    assert latex(DiracDelta(1, -1, evaluate=False)) == r\"\\delta^{\\left( -1 \\right)}\\left(1\\right)\"\n    assert latex(DiracDelta(1, -1, evaluate=True)) == r\"\\delta\\left(1\\right)\"\n"], "sample_70": ["def test_legend_title_fontsize():\n    fig, ax = plt.subplots()\n    ax.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontsize=22)\n    assert leg.get_title().get_fontsize() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark')\n    assert leg5.get_title().get_fontsize() == 20\n", "def test_legend_title_fontprop():\n    # test the title_fontproperties kwarg\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontproperties={'family': 'serif', 'size': 22, 'weight': 'bold'})\n\n    leg = plt.legend(title='Aardvark', title_fontproperties={'family': 'serif', 'weight': 'bold'})\n    assert leg.get_title().get_fontproperties().get_weight() == 'bold'\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontproperties={'family': 'serif', 'weight': 'bold'})\n    assert leg0.get_title().get_fontproperties().get_weight() == 'bold'\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark')\n    assert leg1.get_title().get_fontproperties().get_weight() == 'normal'\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark', title_fontproperties={'family': 'serif', 'weight': 'bold'})\n    assert leg2.get_title().get_fontproperties().get_weight() == 'bold'\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontproperties().get_weight() == 'normal'\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark', title_fontproperties={'family': 'serif', 'weight': 'bold'})\n    assert leg4.get_title().get_fontproperties().get_weight() == 'bold'\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark')\n    assert leg5.get_title().get_fontproperties().get_weight() == 'normal'\n", "def test_legend_title_fontprop_size():\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontproperties=FontProperties(\n                               family='serif', size=22),\n                   title_fontsize=22)\n\n    leg = plt.legend(title='Aardvark', title_fontsize=22)\n    assert leg.get_title().get_fontsize() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg1.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark')\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 20})\n    assert leg3.get_title().get_fontsize() == 20\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark')\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 20})\n    assert leg5.get_title().get_fontsize() == 20\n", "def test_legend_title_fontprop_fontsize():\n    \"\"\"\n    Test font size of the legend title when using title_fontproperties\n    \"\"\"\n    fig, ax = plt.subplots()\n    ax.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontproperties=FontProperties(\n                                       family='serif', size=22))\n    assert leg.get_title().get_size() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark')\n    assert leg5.get_title().get_fontsize() == 20\n", "def test_custom_handler_multiple_keys():\n    \"\"\"\n    Test custom handler with multiple keys.\n    \"\"\"\n    fig, ax = plt.subplots()\n    p1, = ax.plot([1, 2, 3], '-o', label='line')\n    p2, = ax.plot([2, 3, 4], '-x', label='line2')\n    p3, = ax.plot([3, 4, 5], '-d', label='line3')\n\n    custom_handler = mlegend.HandlerTuple(ndivide=None, pad=0)\n    with mock.patch('matplotlib.legend.Legend') as Legend:\n        fig.legend([p1, p2], ['line', 'line2'], handler_map={(p1, p2): custom_handler})\n    Legend.assert_called_with(fig, [p1, p2], ['line', 'line2'], handler_map={(p1, p2): custom_handler})\n\n    # Test that the custom handler is called for each key\n    with mock.patch('matplotlib.legend.Legend') as Legend:\n        fig.legend([p1, p2, p3], ['line', 'line2', 'line3'],\n                   handler_map={(p1, p2): custom_handler, (p2, p3): custom_handler})\n    Legend.assert_called_with(fig, [p1, p2, p3], ['line', 'line2', 'line3'],\n                             handler_map={(p1, p2): custom_handler, (p2, p3): custom_handler})\n"], "sample_3": ["def test_separability_matrix_custom_model():\n    @custom_model\n        return x\n\n    @custom_model\n        return x\n\n    cm = model_a & model_b\n    result = separability_matrix(cm)\n    assert result.shape == (2, 1)\n\n    cm = model_a | model_b\n    result = separability_matrix(cm)\n    assert result.shape == (1, 2)\n\n    cm = model_a + model_b\n    with pytest.raises(ModelDefinitionError,\n                     match=r\"Unsupported operands for arithmetic operator: .*\"):\n        separability_matrix(cm)\n\n    cm = model_a - model_b\n    with pytest.raises(ModelDefinitionError,\n                     match=r\"Unsupported operands for arithmetic operator: .*\"):\n        separability_matrix(cm)\n\n    cm = model_a * model_b\n    with pytest.raises(ModelDefinitionError,\n                     match=r\"Unsupported operands for arithmetic operator: .*\"):\n        separability_matrix(cm)\n\n    cm = model_a / model_b\n    with pytest.raises(ModelDefinitionError,\n                     match=r\"Unsupported operands for arithmetic operator: .*\"):\n        separability_matrix(cm)\n\n    cm = model_a ** model_b\n    with pytest.raises(ModelDefinitionError,\n                     match=r\"Unsupported operands for arithmetic operator: .*\"):\n        separability_matrix(cm)\n", "def test_separable_polynomial():\n    p1 = models.Polynomial1D(2, name='p1')\n    p2 = models.Polynomial1D(2, name='p2')\n    result = is_separable(p1 + p2)\n    assert result.all()\n    result = is_separable(p1 - p2)\n    assert result.all()\n    result = is_separable(p1 * p2)\n    assert not result.all()\n    result = is_separable(p1 / p2)\n    assert not result.all()\n    result = is_separable(p1 ** p2)\n    assert not result.all()\n", "def test_separability_matrix():\n    # Test separability_matrix function\n    result = separability_matrix(sh1)\n    assert result.shape == (1, 1)\n    assert result[0, 0]\n\n    result = separability_matrix(rot)\n    assert result.shape == (2, 2)\n    assert result[0, 0]\n    assert result[1, 1]\n\n    result = separability_matrix(map1)\n    assert result.shape == (4, 2)\n    assert result[0, 0]\n    assert result[3, 1]\n\n    result = separability_matrix(p2)\n    assert result.shape == (2, 2)\n    assert result[0, 0]\n    assert result[1, 1]\n\n    result = separability_matrix(p22)\n    assert result.shape == (2, 2)\n    assert result[0, 0]\n    assert result[1, 1]\n\n    result = separability_matrix(sh2)\n    assert result.shape == (1, 1)\n    assert result[0, 0]\n\n    # Test ModelDefinitionError\n    with pytest.raises(ModelDefinitionError):\n        separability_matrix(map2 | map3)\n\n    with pytest.raises(ModelDefinitionError):\n        separability_matrix(map2 & map3)\n\n    with pytest.raises(ModelDefinitionError):\n        separability_matrix(sh1 | sh2)\n", "def test_separability_matrix_custom_model():\n    # Test that the custom model's separability is correctly detected\n    # and that the separability matrix is correctly generated\n    result = is_separable(model_a)\n    assert_allclose(result, np.array([True]))\n\n    result = separability_matrix(model_a)\n    assert_allclose(result, np.array([[True]]))\n\n    # Test that a custom model with a separable component has the correct\n    # separability\n    @custom_model\n        return x + 1\n\n    result = is_separable(model_b)\n    assert_allclose(result, np.array([False]))\n\n    result = separability_matrix(model_b)\n    assert_allclose(result, np.array([[False]]))\n\n    # Test that a custom model with a non-separable component has the correct\n    # separability\n    @custom_model\n        return x * x\n\n    result = is_separable(model_c)\n    assert_allclose(result, np.array([False]))\n\n    result = separability_matrix(model_c)\n    assert_allclose(result, np.array([[False]]))\n\n    # Test that a custom model with multiple components has the correct\n    # separability\n    @custom_model\n        return x + x + 1\n\n    result = is_separable(model_d)\n    assert_allclose(result, np.array([False]))\n\n    result = separability_matrix(model_d)\n    assert_allclose(result, np.array([[False]]))\n\n    # Test that a compound model with a custom model has the correct\n    # separability\n    @custom_model\n        return x + 1\n\n    cm = (sh1 & sh2 | model_e)\n    result = is_separable(cm)\n    assert_allclose(result, np.array([False]))\n\n    result = separability_matrix(cm)\n    assert_allclose(result, np.array([[True, False], [False, True]]))\n", "def test_separable_model_with_mapping():\n    # Test a model that is not separable due to the presence of a Mapping.\n    map1 = Mapping((1, 0, 1), name='map1')\n    p2 = models.Polynomial2D(1, name='p2')\n    result = is_separable(map1 & p2)\n    assert result is False\n\n    # Test a model that is separable when combined with a Mapping that doesn't\n    # change the input or output indices.\n    map2 = Mapping((0, 1), name='map2')\n    p22 = models.Polynomial2D(2, name='p22')\n    result = is_separable(map2 | p22)\n    assert result is True\n\n    # Test a model that is separable when combined with a Mapping that swaps the input\n    # indices.\n    map3 = Mapping((1, 0), name='map3')\n    result = is_separable(map3 & p2)\n    assert result is True\n\n    # Test a model that is not separable when combined with a Mapping that changes the\n    # output indices.\n    map4 = Mapping((0, 1, 2, 3), name='map4')\n    result = is_separable(map4 | p22)\n    assert result is False\n"], "sample_157": ["def test_tensor_product_add():\n    assert TensorProduct(A, B) + TensorProduct(B, C) == \\\n        TensorProduct(A, B) + TensorProduct(B, C)\n    assert (TensorProduct(A, B) + TensorProduct(B, C)).args_cnc() == \\\n        ([A, B], [TensorProduct(B, C)])\n    assert (TensorProduct(A, B) + TensorProduct(B, C)).is_commutative is False\n    assert (TensorProduct(A, B) + TensorProduct(B, C)).subs(A, C) == \\\n        TensorProduct(C, B) + TensorProduct(B, C)\n", "def test_tensor_product_simp_with_Pow():\n    assert tensor_product_simp(TP(A, B)**2) == TP(A**2, B**2)\n    assert tensor_product_simp(TP(A, B)**2*C) == TP(A**2, B**2)*C\n    assert tensor_product_simp(C*TP(A, B)**2) == C*TP(A**2, B**2)\n    assert tensor_product_simp(TP(A, B)**2 + TP(A, C)) == TP(A**2, B**2) + TP(A, C)\n    assert tensor_product_simp(TP(A, B) + TP(A, C)**2) == TP(A, B) + TP(A, C)**2\n", "def test_tensor_product_trace():\n    assert tensor_product_simp(TP(A, B)*TP(C, D))._eval_trace(indices=[0, 2]) == \\\n        (Tr(A) * Tr(D)) * TP(C, B)\n    assert tensor_product_simp(TP(A, B)*TP(C, D))._eval_trace(indices=[1, 3]) == \\\n        (Tr(B) * Tr(D)) * TP(A, C)\n    assert tensor_product_simp(TP(A, B)*TP(C, D))._eval_trace() == \\\n        (Tr(A)*Tr(B)*Tr(C)*Tr(D))\n", "def test_tensor_product_simp_with_Pow_and_Add():\n    assert tensor_product_simp(TP(A, B) + TP(A, C) + 2 * TP(C, D)) == \\\n        2 * TP(C, D) + TP(A, B) + TP(A, C)\n    assert tensor_product_simp(2 * TP(A, B) + TP(A, C) + TP(C, D) + 3 * TP(B, C)) == \\\n        3 * TP(B, C) + 2 * TP(A, B) + TP(A, C) + TP(C, D)\n    assert tensor_product_simp(TP(A, B) + TP(C, D)**2) == TP(A, B) + TP(C**2, D**2)\n", "def test_issue_15751():\n    # Test for tensors with more than two arguments\n    assert tensor_product_simp(TP(A, B, C) * TP(D, E)) == TP(A, B, C, D, E)\n    assert tensor_product_simp(TP(A, B, C)**2) == TP(A, B, C)**2\n    assert tensor_product_simp(2*TP(A, B, C)) == 2*TP(A, B, C)\n    # Test for scalars being pulled out\n    assert tensor_product_simp(3*TP(A, B, C)) == 3*TP(A, B, C)\n    assert tensor_product_simp(TP(3, A, B, C)) == TP(3, A, B, C)\n"], "sample_139": ["def test_abs_integer():\n    from sympy import Abs, I, oo, Rational, sqrt\n    x, y = symbols('x y')\n    assert Abs(0) == 0\n    assert Abs(1) == 1\n    assert Abs(-1) == 1\n    assert Abs(I) == 1\n    assert Abs(-I) == 1\n    assert Abs(Rational(1, 2)) == Rational(1, 2)\n    assert Abs(-Rational(1, 2)) == Rational(1, 2)\n    assert Abs(-oo) is oo\n    assert Abs(oo) is oo\n    assert Abs(oo - I) is oo\n    assert Abs(oo + I) is oo\n    assert Abs(oo + I*oo) is oo\n    assert Abs(sqrt(-1)) == I\n    assert Abs(-sqrt(-1)) == I\n", "def test_conjugate_mixed():\n    from sympy import conjugate, Im, conjugate as c\n    x = Symbol('x', real=True)\n    y = Symbol('y', imaginary=True)\n    assert conjugate(Im(x)*y) == Im(conjugate(x))*conjugate(y)\n    assert conjugate(c(x + y)) == conjugate(x) + conjugate(y)\n", "def test_issue_11768():\n    from sympy import exp, S, I, oo, exp_polar, periodic_argument\n    from sympy.abc import x\n    # it's a bit annoying that this will currently not run\n    assert periodic_argument(oo) is oo\n", "def test_principal_branch_domain():\n    from sympy import principal_branch, oo\n    p = Symbol('p', positive=True)\n    x = Symbol('x')\n    e = Symbol('e', even=True, positive=True)\n    o = Symbol('o', odd=True, positive=True)\n    ne = Symbol('ne', even=True, negative=True)\n    no = Symbol('no', odd=True, negative=True)\n    nz = Symbol('nz', nonzero=True)\n    z = Symbol('z', zero=True)\n    assert principal_branch(z, p).is_zero\n    assert principal_branch(nz, p).is_nonnegative is None\n    assert principal_branch(nz, p).is_nonpositive is None\n    assert principal_branch(z, p).is_finite is None\n    assert principal_branch(nz, p).is_nonzero is None\n    assert principal_branch(e, p).is_even\n    assert principal_branch(e, p).is_odd is None\n    assert principal_branch(o, p).is_even is None\n    assert principal_branch(o, p).is_odd\n    assert principal_branch(ne, p).is_even is None\n    assert principal_branch(ne, p).is_odd\n    assert principal_branch(no, p).is_even\n    assert principal_branch(no, p).is_odd is None\n    assert principal_branch(z, p).is_positive is None\n    assert principal_branch(nz, p).is_positive is None\n    assert principal_branch(nz, p).is_negative is None\n    assert principal_branch(z, p).is_extended_positive is None\n    assert principal_branch(nz, p).is_extended_positive is None\n    assert principal_branch(nz, p).is_extended_negative is None\n    assert principal_branch(z, p).is_extended_nonpositive is None\n    assert principal_branch(nz, p).is_extended_nonpositive is None\n    assert principal_branch(z, p).is_algebraic is None\n    assert principal_branch(nz, p).is_algebraic is None\n    assert principal_branch(z, p).is_rational is None\n    assert principal_branch(nz, p).is_rational is None\n    assert principal_branch(z, p).is_real is None\n    assert principal_branch(nz, p).is_real is None\n    assert principal_branch(z, p).is_extended_real is None\n    assert principal_branch(nz, p).is_extended_real is None\n    assert principal_branch(nz", "def test_issue_15165():\n    from sympy import symbols, im, re, oo, Interval, polar_lift, polarify, exp, exp_polar, sqrt, Abs\n    x, y = symbols('x y', complex=True)\n    assert re(polar_lift(x + y)).is_unbounded\n    assert im(polar_lift(x + y)).is_unbounded\n    assert re(polar_lift(x + y)).is_extended_real is None\n    assert im(polar_lift(x + y)).is_extended_real is None\n    assert re(Interval(-oo, oo)).is_unbounded\n    assert im(Interval(-oo, oo)).is_unbounded\n    assert re(polar_lift(x + y) + Interval(-oo, oo)).is_unbounded\n    assert im(polar_lift(x + y) + Interval(-oo, oo)).is_unbounded\n    assert re(Interval(-oo, oo) + polar_lift(x + y)).is_unbounded\n    assert im(Interval(-oo, oo) + polar_lift(x + y)).is_unbounded\n\n    assert re(polarify(x + y)).is_unbounded\n    assert im(polarify(x + y)).is_unbounded\n    assert re(polar_lift(x + y)).is_unbounded\n    assert im(polar_lift(x + y)).is_unbounded\n\n    assert re(exp(x + y)).is_unbounded\n    assert im(exp(x + y)).is_unbounded\n    assert re(exp_polar(x + y)).is_unbounded\n    assert im(exp_polar(x + y)).is_unbounded\n    assert re(sqrt(x + y)).is_unbounded\n    assert im(sqrt(x + y)).is_unbounded\n    assert re(Abs(x + y)).is_unbounded\n    assert im(Abs(x + y)).is_unbounded\n"], "sample_95": ["    def test_marks_on_class(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.skip\n            class TestSomething(object):\n                    pass\n                    pass\n            @pytest.mark.xfail\n            class TestSomething2(object):\n                    assert 0\n                    pass\n            class TestSomething3(object):\n                    pass\n                @pytest.mark.skip\n                    pass\n        \"\"\"\n        )\n        rec = pytester.inline_run()\n        rec.assertoutcome(skipped=1, passed=2, xfailed=1)\n", "    def test_single_parametrize(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.parametrize('arg1, arg2', [(1, 2), (3, 4)])\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*2 passed*\"])\n", "    def test_parametrize_non_callable(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.parametrize(\"arg1\", [1, 2], ids=[\"one\", \"two\"])\n                assert 0\n            @pytest.mark.parametrize(\"arg2\", [3, 4, 5], ids=[\"three\", \"four\", \"five\"])\n                assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*1 failed*2 failed*\"])\n", "    def test_parametrize_wrong_arg_values(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.parametrize('arg1, arg2', [[1, 2], 3])\n                assert 0\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            pytester.runpytest()\n        assert \"In test_func: function already takes an argument 'arg2' with a default value\" in excinfo.value.msg\n", "    def test_importorskip_replaces_mark(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            importorskip(\"sys\")\n                assert 0\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*importorskip*\"])\n"], "sample_44": ["def test_limit_choices_to(self):\n    class ModelChoiceFieldWithLimitChoicesTo(forms.ModelChoiceField):\n            return {'is_active': True}\n\n    field = ModelChoiceFieldWithLimitChoicesTo(Category.objects.all())\n    self.assertEqual(len(field.choices), 2)\n    self.assertEqual(list(field.choices), [\n        ('', '---------'),\n        (self.c1.pk, 'Entertainment'),\n    ])\n    self.assertEqual(field.clean(self.c2.id).name, 'A test')\n    with self.assertRaises(ValidationError):\n        field.clean(self.c3.id)\n\n    # Test that limit_choices_to is applied to the queryset when the field is\n    # accessed.\n    self.assertEqual(len(field.queryset.all()), 1)\n    self.assertEqual(list(field.queryset.all()), [\n        self.c1,\n    ])\n", "    def setUpTestData(cls):\n        cls.c1 = Category.objects.create(name='Entertainment', slug='entertainment', url='entertainment')\n        cls.c2 = Category.objects.create(name='A test', slug='test', url='test')\n        cls.c3 = Category.objects.create(name='Third', slug='third-test', url='third')\n", "    def setUpTestData(cls):\n        cls.c1 = Category.objects.create(name='Entertainment', slug='entertainment', url='entertainment')\n        cls.c2 = Category.objects.create(name='A test', slug='test', url='test')\n        cls.c3 = Category.objects.create(name='Third', slug='third-test', url='third')\n", "def test_modelchoicefield_field_ordering(self):\n    class ModelChoiceForm(forms.Form):\n        category = forms.ModelChoiceField(Category.objects.all())\n\n        class Meta:\n            fields = ['category']\n\n    form = ModelChoiceForm(data={'category': self.c1.pk})\n    self.assertEqual(form.fields['category'].has_changed('x', 'y'), False)\n\n    # Test that the field is ordered correctly when the ModelChoiceField is\n    # first in the form's fields.\n    form = ModelChoiceForm()\n    self.assertEqual(form['category'].field.ordering, (None, None))\n\n    # Test that the field is ordered correctly when the ModelChoiceField is\n    # not first in the form's fields.\n    class AnotherModelChoiceForm(forms.Form):\n        category = forms.ModelChoiceField(Category.objects.all())\n        name = forms.CharField()\n\n        class Meta:\n            fields = ['name', 'category']\n\n    form = AnotherModelChoiceForm()\n    self.assertEqual(form['name'].field.ordering, (None, None))\n    self.assertEqual(form['category'].field.ordering, (None, None))\n\n    # Test that the field is ordered correctly when the ModelChoiceField is\n    # last in the form's fields.\n    class LastModelChoiceForm(forms.Form):\n        name = forms.CharField()\n        category = forms.ModelChoiceField(Category.objects.all())\n\n        class Meta:\n            fields = ['name', 'category']\n\n    form = LastModelChoiceForm()\n    self.assertEqual(form['name'].field.ordering, (None, None))\n    self.assertEqual(form['category'].field.ordering, (None, None))\n", "def test_localize_choices(self):\n    f = forms.ModelChoiceField(Category.objects.all(), localize=True)\n    self.assertEqual(len(f.choices), 4)\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c1.pk, 'Entertainment'),\n        (self.c2.pk, 'A test'),\n        (self.c3.pk, 'Third'),\n    ])\n    self.assertEqual(f.clean(self.c1.pk).name, 'Entertainment')\n\n    class ModelChoiceForm(forms.Form):\n        category = forms.ModelChoiceField(Category.objects.all(), localize=True)\n\n    form = ModelChoiceForm()\n    self.assertCountEqual(form.fields['category'].queryset, [self.c1, self.c2, self.c3])\n    self.assertEqual(form.fields['category'].widget.choices[0][1], '---------')\n\n    # Test localize_choices with a non-model choice\n    f = forms.ModelChoiceField(Category.objects.all(), localize=True, choices=[(1, 'Test')])\n    self.assertEqual(len(f.choices), 2)\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (1, 'Test'),\n    ])\n\n    # Test localized_choices with an empty label\n    f = forms.ModelChoiceField(Category.objects.all(), localize=True, empty_label='Empty')\n    self.assertEqual(len(f.choices), 4)\n    self.assertEqual(list(f.choices), [\n        ('', 'Empty'),\n        (self.c1.pk, 'Entertainment'),\n        (self.c2.pk, 'A test'),\n        (self.c3.pk, 'Third'),\n    ])\n"], "sample_76": ["def test_order(self, df):\n\n    groupby = GroupBy([\"group\"])\n    res = PolyFit(order=3, gridsize=100)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n\n    assert_array_equal(res.columns, [\"x\", \"y\"])\n\n    grid = np.linspace(df[\"x\"].min(), df[\"x\"].max(), 100)\n    assert_array_equal(res[\"x\"], grid)\n    assert_array_almost_equal(res[\"y\"], np.polyval(np.polyfit(df[\"x\"], df[\"y\"], 3), grid))\n", "def test_unnecessary_gridsize(self, df):\n\n    groupby = GroupBy([\"group\"])\n    res = PolyFit(order=5, gridsize=100)(df, groupby, \"x\", {})\n\n    assert_array_equal(res.columns, [\"x\", \"y\"])\n\n    grid = np.linspace(df[\"x\"].min(), df[\"x\"].max(), 100)\n    assert_array_equal(res[\"x\"], grid)\n    assert_array_almost_equal(res[\"y\"].diff().diff().dropna(), np.zeros(grid.size - 2))\n", "def test_default_order(self, df):\n\n    groupby = GroupBy([\"group\"])\n    res = PolyFit(gridsize=100)(df, groupby, \"x\", {})\n\n    assert res.columns.to_list() == [\"x\", \"y\", \"group\"]\n\n    ngroups = df[\"group\"].nunique()\n    assert_array_equal(res.index, np.arange(ngroups * 100))\n\n    for _, part in res.groupby(\"group\"):\n        order = part.shape[0] - 1\n        p = np.polyfit(part[\"x\"], part[\"y\"], order)\n        assert_array_almost_equal(np.polyval(p, part[\"x\"]), part[\"y\"], decimal=1)\n", "def test_different_gridsize_for_each_group(self, df):\n\n    groupby = GroupBy([\"group\"])\n    res = PolyFit(order=2, gridsize=\"auto\")(df, groupby, \"x\", {})\n\n    assert res.columns.to_list() == [\"x\", \"y\", \"group\"]\n\n    for _, part in res.groupby(\"group\"):\n        assert \"gridsize\" not in part.columns\n\n    for group in df[\"group\"].unique():\n        part = res[res[\"group\"] == group]\n        gridsize = len(part) // 3  # assuming 3 groups in total\n        assert_array_equal(part[\"x\"], np.linspace(part[\"x\"].min(), part[\"x\"].max(), gridsize))\n", "def test_order_greater_than_uniques(self, df):\n\n    groupby = GroupBy([\"group\"])\n    res = PolyFit(order=3, gridsize=100)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n\n    assert_array_equal(res.columns, [\"x\", \"y\"])\n\n    grid = np.linspace(df[\"x\"].min(), df[\"x\"].max(), 100)\n    assert_array_equal(res[\"x\"], grid)\n\n    # In this case, we're trying to fit a 3rd degree polynomial to data with\n    # fewer than 4 unique x values. The polyfit function will raise an error.\n    with pytest.raises(ValueError):\n        res[\"y\"]\n"], "sample_24": ["def test_repr(self):\n    error1 = ValidationError('message')\n    error2 = ValidationError('message', code='my_code1')\n    error3 = ValidationError('message', code='my_code2')\n    error4 = ValidationError(\n        'error %(parm1)s %(parm2)s',\n        code='my_code1',\n        params={'parm1': 'val1', 'parm2': 'val2'},\n    )\n    error5 = ValidationError({'field1': 'message', 'field2': 'other'})\n    error6 = ValidationError({'field1': 'message'})\n    error7 = ValidationError([\n        ValidationError({'field1': 'field error', 'field2': 'other'}),\n        'message',\n    ])\n\n    self.assertEqual(repr(error1), \"ValidationError('message')\")\n    self.assertEqual(repr(error2), \"ValidationError('message', code='my_code1')\")\n    self.assertEqual(\n        repr(error4),\n        \"ValidationError('error %(parm1)s %(parm2)s', code='my_code1', params={'parm1': 'val1', 'parm2': 'val2'})\",\n    )\n    self.assertEqual(\n        repr(error5),\n        \"ValidationError({'field1': 'message', 'field2': 'other'})\",\n    )\n    self.assertEqual(\n        repr(error7),\n        \"ValidationError([ValidationError({'field1': 'field error', 'field2': 'other'}), 'message'])\",\n    )\n\n    self.assertEqual(repr(error1), str(error1))\n    self.assertEqual(repr(error2), str(error2))\n    self.assertEqual(repr(error3), str(error3))\n    self.assertEqual(repr(error4), str(error4))\n    self.assertEqual(repr(error5), str(error5))\n    self.assertEqual(repr(error6), str(error6))\n    self.assertEqual(repr(error7), str(error7))\n    self.assertEqual(repr(error1), str(ValidationError('message')))\n    self.assertEqual(repr(error2), str(ValidationError('message', code='my_code1')))\n    self.assertEqual(repr(error3), str(ValidationError('message', code='my_code2')))\n    self.assertEqual(\n        repr(error4),\n        str(ValidationError(\n            'error %(parm1)s %(parm2)s',\n            code='my_code1',\n            params={'parm1': 'val1', 'parm2': 'val2'},\n        )),\n    )\n    self.assertEqual(\n        repr(error5),\n        str(ValidationError({'field1': 'message', 'field2':", "def test_update_error_dict(self):\n    error1 = ValidationError('message')\n    error2 = ValidationError({'field1': 'message', 'field2': 'other'})\n    error3 = ValidationError([\n        ValidationError({'field1': 'field error', 'field2': 'other'}),\n        'message',\n    ])\n\n    error_dict = {}\n    error1.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['message']})\n    error2.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['message'], 'field2': ['other']})\n    error3.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {\n        'field1': ['field error', 'message'],\n        'field2': ['other'],\n    })\n\n    error_dict = {}\n    error1.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['message']})\n    error2.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['message'], 'field2': ['other']})\n    error3.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {\n        'field1': ['field error', 'message'],\n        'field2': ['other'],\n    })\n\n    error_dict = {'field1': ['message']}\n    error1.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['message'], '__all__': ['message']})\n    error2.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {\n        'field1': ['message'],\n        'field2': ['other'],\n        '__all__': ['message'],\n    })\n    error3.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {\n        'field1': ['field error', 'message'],\n        'field2': ['other'],\n        '__all__': ['message'],\n    })\n\n    error_dict = {'field2': ['other']}\n    error1.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['message'], 'field2': ['other'], '__all__': ['message']})\n    error2.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {\n        'field1': ['message'],\n        'field2': ['other', 'other'],\n        '__all__': ['message'],\n    })\n    error3.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {\n        'field1': ['field error', 'message'],\n        '", "def test_message_dict(self):\n    error = ValidationError('message')\n    self.assertEqual(error.message_dict, {'__all__': ['message']})\n\n    error = ValidationError({'field1': 'message', 'field2': 'other'})\n    self.assertEqual(error.message_dict, {'field1': ['message'], 'field2': ['other']})\n\n    error = ValidationError([\n        'message',\n        ValidationError({'field1': 'field error', 'field2': 'other'}),\n    ])\n    self.assertEqual(error.message_dict, {'__all__': ['message', {'field1': ['field error'], 'field2': ['other']}]})\n\n    error = ValidationError([\n        ValidationError({'field1': 'field error', 'field2': 'other'}),\n        'message',\n    ])\n    self.assertEqual(error.message_dict, {'__all__': ['message', {'field1': ['field error'], 'field2': ['other']}]})\n\n    error = ValidationError({\n        'field1': 'error %(parm1)s %(parm2)s',\n        'field2': 'error %(parm1)s %(parm2)s',\n    }, code='my_code', params={'parm1': 'val1', 'parm2': 'val2'})\n    self.assertEqual(error.message_dict, {\n        'field1': ['error val1 val2'],\n        'field2': ['error val1 val2'],\n    })\n\n    error = ValidationError({\n        'field1': ValidationError('error %(parm1)s %(parm2)s', code='my_code', params={'parm1': 'val1', 'parm2': 'val2'}),\n        'field2': 'other',\n    })\n    self.assertEqual(error.message_dict, {\n        'field1': ['error val1 val2'],\n        'field2': ['other'],\n    })\n\n    error = ValidationError({\n        'field1': ValidationError('error %(parm1)s %(parm2)s', code='my_code', params={'parm2': 'val2', 'parm1': 'val1'}),\n        'field2': 'other',\n    })\n    self.assertEqual(error.message_dict, {\n        'field1': ['error val1 val2'],\n        'field2': ['other'],\n    })\n", "def test_update_error_dict(self):\n    error_dict = {}\n    error = ValidationError({'field1': 'message', 'field2': 'other'})\n    error_dict = error.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['message'], 'field2': ['other']})\n\n    error = ValidationError({'field1': 'message'})\n    error_dict = error.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['message'], 'field2': ['other']})\n\n    error = ValidationError('message')\n    error_dict = error.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['message'], 'field2': ['other'], NON_FIELD_ERRORS: ['message']})\n\n    error = ValidationError([\n        ValidationError({'field1': 'field error', 'field2': 'other'}),\n        'message',\n    ])\n    error_dict = error.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {\n        'field1': ['field error'], 'field2': ['other'], NON_FIELD_ERRORS: ['message']\n    })\n\n    error_dict = {}\n    error = ValidationError({\n        'field1': ValidationError('error %(parm1)s %(parm2)s', code='my_code', params={'parm1': 'val1', 'parm2': 'val2'}),\n        'field2': 'other',\n    })\n    error_dict = error.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {\n        'field1': ['error val1 val2'], 'field2': ['other'], NON_FIELD_ERRORS: []\n    })\n\n    error_dict = {}\n    error = ValidationError('error %(parm1)s %(parm2)s', code='my_code', params={'parm1': 'val1', 'parm2': 'val2'})\n    error_dict = error.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {NON_FIELD_ERRORS: ['error val1 val2']})\n", "def test_hash_nested(self):\n    error_dict = {\n        'field1': ValidationError(\n            'error %(parm1)s %(parm2)s',\n            code='my_code',\n            params={'parm1': 'val1', 'parm2': 'val2'},\n        ),\n        'field2': ValidationError(\n            'error %(parm3)s %(parm4)s',\n            code='my_code',\n            params={'parm3': 'val3', 'parm4': 'val4'},\n        ),\n    }\n    error = ValidationError(error_dict)\n    self.assertEqual(hash(error), hash(error_dict))\n    error_dict['field1'].params = {'parm1': 'val3', 'parm2': 'val4'}\n    self.assertNotEqual(hash(error), hash(error_dict))\n    error_dict = {\n        'field1': ValidationError(\n            'error %(parm1)s %(parm2)s',\n            code='my_code',\n            params={'parm1': 'val1', 'parm2': 'val2'},\n        ),\n        'field2': ValidationError(\n            'error %(parm3)s %(parm4)s',\n            code='my_code',\n            params={'parm3': 'val3', 'parm4': 'val4'},\n        ),\n    }\n    error = ValidationError(error_dict)\n    self.assertEqual(hash(error), hash(dict(error_dict)))\n    self.assertNotEqual(hash(error), hash(error_dict))\n"], "sample_36": ["def test_combine_and_non_q_object(self):\n    obj = object()\n    q = Q(x=1)\n    with self.assertRaisesMessage(TypeError, str(obj)):\n        q & obj\n\n    q = Q(x__in={}.keys())\n    with self.assertRaisesMessage(TypeError, str(obj)):\n        q & obj\n\n    q = Q(x__in={}.keys()) | obj\n    with self.assertRaisesMessage(TypeError, str(obj)):\n        q & obj\n\n    q = Q(x__in={}.keys()) & obj\n    with self.assertRaisesMessage(TypeError, str(obj)):\n        q | obj\n", "def test_combine_or_not_q_object(self):\n    obj = object()\n    q = Q(x=1) | obj\n    self.assertIsInstance(q, Q)\n    self.assertIsInstance(q.children, list)\n    self.assertEqual(len(q.children), 1)\n    self.assertEqual(q.children[0], (obj,))\n\n    q = Q(x=1) & obj\n    self.assertIsInstance(q, Q)\n    self.assertIsInstance(q.children, list)\n    self.assertEqual(len(q.children), 1)\n    self.assertEqual(q.children[0], (obj,))\n", "def test_combine_and_not_empty(self):\n    q1 = Q(x=1)\n    q2 = Q(x=2)\n    self.assertNotEqual(q1 & Q(x=2), q1)\n    self.assertNotEqual(Q(x=2) & q1, q1)\n    self.assertNotEqual(q1 & Q(x=2), q2)\n    self.assertNotEqual(Q(x=2) & q1, q2)\n\n    q1 = Q(x__in=[1, 2])\n    self.assertNotEqual(q1 & Q(x=2), q1)\n    self.assertNotEqual(Q(x=2) & q1, q1)\n    self.assertNotEqual(q1 & Q(x=2), q2)\n    self.assertNotEqual(Q(x=2) & q1, q2)\n", "def test_combine_or_and(self):\n    q1 = Q(x=1)\n    q2 = Q(y=2)\n    q = q1 | (q2 & Q(z=3))\n    expected_q = Q(x=1, z=3)\n    path, args, kwargs = q.deconstruct()\n    self.assertEqual(Q(*args, **kwargs), expected_q)\n", "def test_reconstruct_and(self):\n    q1 = Q(price__gt=F('discounted_price'))\n    q2 = Q(price=F('discounted_price'))\n    q = q1 & q2\n    path, args, kwargs = q.deconstruct()\n    self.assertEqual(Q(*args, **kwargs), q)\n"], "sample_67": ["def test_serialize_module(self):\n    self.assertSerializedResultEqual(\n        sys,\n        (\"sys\", {\"import sys\"}),\n    )\n    self.assertSerializedResultEqual(\n        time,\n        (\"time\", {\"import time\"}),\n    )\n    self.assertSerializedResultEqual(\n        datetime,\n        (\"datetime\", {\"import datetime\"}),\n    )\n    self.assertSerializedResultEqual(\n        decimal,\n        (\"decimal\", {\"import decimal\"}),\n    )\n    self.assertSerializedResultEqual(\n        enum,\n        (\"enum\", {\"import enum\"}),\n    )\n    self.assertSerializedResultEqual(\n        functools,\n        (\"functools\", {\"import functools\"}),\n    )\n    self.assertSerializedResultEqual(\n        re,\n        (\"re\", {\"import re\"}),\n    )\n    self.assertSerializedResultEqual(\n        uuid,\n        (\"uuid\", {\"import uuid\"}),\n    )\n    self.assertSerializedResultEqual(\n        pathlib,\n        (\"pathlib\", {\"import pathlib\"}),\n    )\n    self.assertSerializedResultEqual(\n        os,\n        (\"os\", {\"import os\"}),\n    )\n", "def test_serialize_float_infinity_nan(self):\n    \"\"\"Tests serializing of float infinity and NaN values.\"\"\"\n    self.assertSerializedEqual(float(\"inf\"))\n    self.assertSerializedEqual(float(\"-inf\"))\n    self.assertSerializedEqual(float(\"nan\"))\n    self.assertSerializedResultEqual(float(\"inf\"), (\"float('inf')\", set()))\n    self.assertSerializedResultEqual(float(\"-inf\"), (\"float('-inf')\", set()))\n    self.assertSerializedResultEqual(float(\"nan\"), (\"float('nan')\", set()))\n", "def test_serialize_custom_types(self):\n    \"\"\"Test serialization of custom types.\"\"\"\n    class CustomType:\n        pass\n\n    string, imports = MigrationWriter.serialize(CustomType)\n    self.assertEqual(string, \"migrations.test_writer.CustomType\", {\"import migrations.test_writer\"})\n    self.serialize_round_trip(CustomType())\n\n    custom_type_instance = CustomType()\n    string, imports = MigrationWriter.serialize(custom_type_instance)\n    self.assertEqual(string, \"migrations.test_writer.CustomType\", {\"import migrations.test_writer\"})\n    self.serialize_round_trip(custom_type_instance)\n", "        def serialize(self):\n            return \"complex(%r)\" % self.value, {}\n", "def test_serialize_re(self):\n    self.assertSerializedResultEqual(\n        re.compile(r\"^\\w+$\"),\n        (\"re.compile('^\\\\w+$')\", {\"import re\"}),\n    )\n    string, imports = MigrationWriter.serialize(re)\n    self.assertEqual(string, \"re\")\n    self.assertEqual(imports, set())\n\n    # Test with a subclass.\n    class CustomRegex(re.compile):\n            super().__init__(pattern)\n\n    with self.assertRaisesMessage(ImportError, \"No module named 're'\"):\n        MigrationWriter.serialize(CustomRegex)\n\n    # Test with a subclass.\n    class InvalidRegex:\n            self.pattern = pattern\n\n    with self.assertRaisesMessage(\n        ValueError, \"Could not find object in re.\"\n    ):\n        MigrationWriter.serialize(InvalidRegex(r\"^\\w+$\"))\n"], "sample_5": ["    def test_setnull_from_parent_nullable(self):\n        a = create_a('child_setnull_nullable')\n        R.objects.get(pk=a.child_setnull_id).delete()\n        a = A.objects.get(pk=a.pk)\n        self.assertIsNone(a.child_setnull)\n", "    def test_inheritance_protect(self):\n        parent = Parent.objects.create()\n        child = RChild.objects.create(r_ptr=parent)\n        with self.assertRaisesMessage(ProtectedError, (\n            \"Cannot delete some instances of model 'Parent' because they are \"\n            \"referenced through a protected foreign key: 'RChild.r_ptr'\"\n        )):\n            child.delete()\n", "    def test_field_update_signal_order(self):\n        class TestModel(models.Model):\n            test_field = models.IntegerField(default=0)\n\n            self.assertEqual(kwargs['instance'].test_field, 1)\n\n        models.signals.post_delete.connect(update_field, sender=TestModel)\n\n        instance = TestModel.objects.create(test_field=0)\n        instance.delete()\n        self.assertEqual(instance.test_field, 1)\n\n        models.signals.post_delete.disconnect(update_field, sender=TestModel)\n", "    def test_setdefault(self):\n        a = create_a('setdefault')\n        a.setdefault.delete()\n        a = A.objects.get(pk=a.pk)\n        self.assertEqual(self.DEFAULT, a.setdefault.pk)\n", "    def test_sorting_of_instances_in_data(self):\n        # Test that instances are sorted by pk in data.\n        r = R.objects.create()\n        s1 = S.objects.create(r=r, pk=1)\n        s2 = S.objects.create(r=r, pk=2)\n        T.objects.create(s=s1)\n        T.objects.create(s=s2)\n        collector = Collector(using='default')\n        collector.data = {'R': {s1, s2}}\n        collector.sort()\n        self.assertEqual(list(collector.data['R']), [s1, s2])\n"], "sample_98": ["def test_check_X_y_complex_data_error():\n    \"\"\"Complex data not supported in y\"\"\"\n    # list of lists\n    y = [[1 + 2j, 3 + 4j, 5 + 7j], [2 + 3j, 4 + 5j, 6 + 7j]]\n    assert_raises_regex(ValueError, \"Complex data not supported\",\n                        check_X_y, [[1, 2], [3, 4]], y)\n    assert_raises_regex(ValueError, \"Complex data not supported\",\n                        check_X_y, sp.csr_matrix([[1, 2], [3, 4]]), y)\n\n    # tuple of tuples\n    y = ((1 + 2j, 3 + 4j, 5 + 7j), (2 + 3j, 4 + 5j, 6 + 7j))\n    assert_raises_regex(ValueError, \"Complex data not supported\",\n                        check_X_y, [[1, 2], [3, 4]], y)\n    assert_raises_regex(ValueError, \"Complex data not supported\",\n                        check_X_y, sp.csr_matrix([[1, 2], [3, 4]]), y)\n\n    # list of np arrays\n    y = [np.array([1 + 2j, 3 + 4j, 5 + 7j]),\n         np.array([2 + 3j, 4 + 5j, 6 + 7j])]\n    assert_raises_regex(ValueError, \"Complex data not supported\",\n                        check_X_y, [[1, 2], [3, 4]], y)\n    assert_raises_regex(ValueError, \"Complex data not supported\",\n                        check_X_y, sp.csr_matrix([[1, 2], [3, 4]]), y)\n\n    # tuple of np arrays\n    y = (np.array([1 + 2j, 3 + 4j, 5 + 7j]),\n         np.array([2 + 3j, 4 + 5j, 6 + 7j]))\n    assert_raises_regex(ValueError, \"Complex data not supported\",\n                        check_X_y, [[1, 2], [3, 4]], y)\n    assert_raises_regex(ValueError, \"Complex data not supported\",\n                        check_X_y, sp.csr_matrix([[1, 2], [3, 4]]), y)\n\n    # dataframe\n   ", "def test_check_X_y_non_finite_values():\n    X = np.array([[1, 2], [np.inf, 4]])\n    y = np.array([1, 2])\n    with pytest.raises(ValueError, match='Input contains infinity'):\n        check_X_y(X, y, force_all_finite=True)\n\n    X = np.array([[1, 2], [np.nan, 4]])\n    y = np.array([1, 2])\n    with pytest.raises(ValueError, match='Input contains NaN, infinity'):\n        check_X_y(X, y, force_all_finite=False)\n\n    X = np.array([[1, 2], [np.nan, 4]])\n    y = np.array([1, 2])\n    check_X_y(X, y, force_all_finite='allow-nan')\n\n    X = np.array([[1, 2], [np.inf, 4]])\n    y = np.array([1, 2])\n    with pytest.raises(ValueError, match='Input contains infinity'):\n        check_X_y(X, y, force_all_finite='allow-nan')\n\n    X = np.array([[1, 2], [np.nan, 4]])\n    y = np.array([1, 2, np.nan])\n    with pytest.raises(ValueError, match='Input contains NaN, infinity'):\n        check_X_y(X, y, force_all_finite=True)\n\n    X = np.array([[1, 2], [np.nan, 4]])\n    y = np.array([1, 2, np.nan])\n    check_X_y(X, y, force_all_finite='allow-nan')\n", "def test_check_symmetric_large_sparse():\n    # Test that check_symmetric function can handle large sparse matrices\n    # with 64bit indices.\n\n    arr_sym = sp.csr_matrix([[0, 1], [1, 2]])\n    for attr in ['indices', 'indptr']:\n        if hasattr(arr_sym, attr):\n            setattr(arr_sym, attr, getattr(arr_sym, attr).astype('int64'))\n    arr_asym = sp.csr_matrix([[0, 2], [0, 2]])\n\n    assert_warns(UserWarning, check_symmetric, arr_asym)\n    assert_raises(ValueError, check_symmetric, arr_asym, raise_exception=True)\n\n    arr_sym_checked = check_symmetric(arr_asym)\n    assert_array_equal(arr_sym_checked.toarray(), arr_sym.toarray())\n    assert_equal(arr_sym_checked.format, arr_asym.format)\n", "def test_check_X_y():\n    # Test that check_X_y correctly validates X and y\n    X = np.ones((10, 5))\n    y = np.ones(10)\n    X, y = check_X_y(X, y, multi_output=False)\n    assert_equal(X.shape, (10, 5))\n    assert_equal(y.shape, (10,))\n\n    # Test that check_X_y correctly validates multi-output y\n    X = np.ones((10, 5))\n    y = np.ones((10, 2))\n    X, y = check_X_y(X, y, multi_output=True)\n    assert_equal(X.shape, (10, 5))\n    assert_equal(y.shape, (10, 2))\n\n    # Test that check_X_y correctly validates X and y with sparse inputs\n    X = sp.csr_matrix(np.ones((10, 5)))\n    y = sp.csr_matrix(np.ones((10,)))\n    X, y = check_X_y(X, y, multi_output=False)\n    assert_equal(X.shape, (10, 5))\n    assert_equal(y.shape, (10,))\n\n    # Test that check_X_y correctly validates multi-output y with sparse inputs\n    X = sp.csr_matrix(np.ones((10, 5)))\n    y = sp.csr_matrix(np.ones((10, 2)))\n    X, y = check_X_y(X, y, multi_output=True)\n    assert_equal(X.shape, (10, 5))\n    assert_equal(y.shape, (10, 2))\n\n    # Test that check_X_y correctly raises an error for inconsistent lengths\n    X = np.ones((10, 5))\n    y = np.ones(9)\n    assert_raises(ValueError, check_X_y, X, y)\n\n    # Test that check_X_y correctly raises an error for non-numeric y\n    X = np.ones((10, 5))\n    y = np.ones(10, dtype=object)\n    assert_raises(TypeError, check_X_y, X, y)\n\n    # Test that check_X_y correctly validates X and y with allow_nd=True\n    X = np.ones((10, 5, 2))\n    y = np.ones((10, 2))\n    X, y = check_X_y(X, y, multi_output=True, allow_nd=True)\n    assert_equal(X.shape, (10, 5, 2))\n    assert_equal(y.shape, (10, 2))\n\n   ", "def test_check_array_large_sparse_format():\n    # Test that the sparse format is checked when accept_large_sparse is True\n    X = sp.rand(20, 10, format='csr')\n    if LARGE_SPARSE_SUPPORTED:\n        check_array(X, accept_sparse=True, accept_large_sparse=True)\n        check_array(X, accept_sparse='csr', accept_large_sparse=True)\n        check_array(X, accept_sparse=['csr'], accept_large_sparse=True)\n        check_array(X, accept_sparse=('csr',), accept_large_sparse=True)\n        assert_raises(ValueError, check_array, X, accept_sparse=['csr', 'dok'],\n                     accept_large_sparse=True)\n        assert_raises(ValueError, check_array, X, accept_sparse=['csr'],\n                     accept_large_sparse=False)\n        assert_raises(ValueError, check_array, X, accept_sparse=('csr',),\n                     accept_large_sparse=False)\n    else:\n        assert_raises(ValueError, check_array, X, accept_sparse=True,\n                     accept_large_sparse=True)\n        assert_raises(ValueError, check_array, X, accept_sparse='csr',\n                     accept_large_sparse=True)\n        assert_raises(ValueError, check_array, X, accept_sparse=['csr'],\n                     accept_large_sparse=True)\n        assert_raises(ValueError, check_array, X, accept_sparse=('csr',),\n                     accept_large_sparse=True)\n\n    # Test that the sparse format is not changed when accept_large_sparse is True\n    X = sp.rand(20, 10, format='csr')\n    if LARGE_SPARSE_SUPPORTED:\n        X_checked = check_array(X, accept_sparse=True, accept_large_sparse=True,\n                                copy=False)\n        assert_equal(X.format, X_checked.format)\n        X_checked = check_array(X, accept_sparse='csr', accept_large_sparse=True,\n                                copy=False)\n        assert_equal(X.format, X_checked.format)\n        X_checked = check_array(X, accept_sparse=['csr'], accept_large_sparse=True,\n                                copy=False)\n        assert_equal(X.format, X_checked.format)\n        X_checked = check_array(X, accept_sparse=('csr',), accept_large_sparse=True,\n                                copy=False)\n        assert_equal(X.format, X_checked.format)\n"], "sample_120": ["def test_MatPow_simplify():\n    A = MatrixSymbol('A', n, n)\n    assert simplify(MatPow(A, 3)).doit() == A**3\n    assert simplify(MatPow(A, -2)).doit() == (A**-1)**2\n    assert simplify(MatPow(A, -2)).doit() == Inverse(A)**2\n", "def test_Transpose_power():\n    A = MatrixSymbol('A', 2, 2)\n    T = Transpose(A)\n    assert T**2 == A\n    assert T**3 == A**2\n    assert T**-1 == Transpose(A**-1)\n    with raises(ShapeError):\n        Transpose(A)**2\n", "def test_Inverse():\n    A = MatrixSymbol('A', n, n)\n    I = Inverse(A)\n    assert I.is_Inverse\n    assert I.is_square\n    assert A*I == Identity(n)\n    assert I*A == Identity(n)\n    assert A*I == A.doit() * Inverse(A.doit())\n    assert I*A == A.doit() * Inverse(A.doit())\n    with raises(NotImplementedError):\n        Inverse(ZeroMatrix(n, m))\n    with raises(NotImplementedError):\n        Inverse(ZeroMatrix(m, n))\n", "def test_matrixexpr_simplify():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    C = MatrixSymbol('C', n, n)\n\n    assert simplify((A + B)**2) == simplify((A + B)*(A + B))\n    assert simplify((A + B + C)**2) == simplify((A + B + C)*(A + B + C))\n    assert simplify((A + B)*(B + C)) == simplify(A*B + A*C + B**2 + B*C)\n    assert simplify((A + B)*(C + D)) == simplify(A*C + A*D + B*C + B*D)\n\n    assert simplify((A - B)**2) == simplify((A - B)*(A - B))\n    assert simplify((A - B + C)**2) == simplify((A - B + C)*(A - B + C))\n    assert simplify((A - B)*(B - C)) == simplify(A*B - A*C - B**2 + B*C)\n    assert simplify((A - B)*(C - D)) == simplify(A*C - A*D - B*C + B*D)\n\n    assert simplify(A**2 + B**2) == simplify(A**2) + simplify(B**2)\n", "def test_matrixtranspose():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    assert transpose(A*B).args == (B, A)\n    assert (transpose(A*B).args[0].args == B.args)\n    assert (transpose(A*B).args[1].args == A.args)\n    assert (transpose(A*B)).shape == (l, n)\n    assert transpose(A).args == (A,)\n    assert (transpose(A)).shape == (m, n)\n    assert A*I == A\n    assert transpose(A*I) == I\n"], "sample_104": ["def test_nested_gridsearch():\n    # render a gridsearch inside another gridsearch\n    param_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n                   'C': [1, 10, 100, 1000]},\n                  {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n    gs = GridSearchCV(GridSearchCV(SVC(), param_grid, cv=5), param_grid, cv=5)\n    expected = \"\"\"", "def test_param_grid_dict_with_non_hashable_keys():\n    # Test with a grid search that has a dictionary with non-hashable keys\n    param_grid = {'a': [1, 2, 3], 'tuple_key': (1, 2, 3)}\n    gs = GridSearchCV(SVC(), param_grid)\n    expected = \"\"\"", "def test_nested_gridsearch():\n    # Render a gridsearch inside another gridsearch\n    pp = _EstimatorPrettyPrinter(compact=True, indent=1, indent_at_name=True)\n\n    param_grid_outer = [{'kernel': ['rbf', 'linear'], 'C': [1, 10]},\n                       {'kernel': ['rbf', 'linear'], 'C': [100, 1000]}]\n    param_grid_inner = {'kernel': ['rbf', 'linear'], 'C': [1, 10]}\n\n    gs_outer = GridSearchCV(SVC(), param_grid_outer, cv=5)\n    gs_inner = GridSearchCV(SVC(), param_grid_inner, cv=3)\n\n    gsgs = GridSearchCV(gs_inner, param_grid_outer, cv=5)\n\n    expected = \"\"\"", "def test_pickleable():\n    # Test that estimators that are picklable can be pickled\n    # and unpickled (see #12426)\n    from pickle import dumps, loads\n\n    # Make sure the estimator can be pickled\n    estimator = LogisticRegression()\n    pickled_estimator = dumps(estimator)\n\n    # Unpickle the estimator\n    unpickled_estimator = loads(pickled_estimator)\n\n    # Check that unpickled estimator is equal to original\n    assert estimator == unpickled_estimator\n\n    # Test that the unpickled estimator has the same repr as the original\n    expected = \"\"\"", "def test_compactness():\n    # Render a transformer with many parameters, but try to make it not be\n    # compact\n    pp = _EstimatorPrettyPrinter(indent=10, compact=False, indent_at_name=True)\n\n    imputer = SimpleImputer(missing_values=np.nan,\n                            strategy=\"mean\",\n                            fill_value=None,\n                            verbose=0,\n                            copy=True)\n\n    expected = \"\"\""], "sample_87": ["    def test_collect_custom_norecursedirs(self, testdir):\n        testdir.makeini(\n            \"\"\"\n            [pytest]\n            norecursedirs = dir1 dir2\n        \"\"\"\n        )\n        tmpdir = testdir.tmpdir\n        tmpdir.ensure(\"dir1\", \"test_notfound.py\")\n        tmpdir.ensure(\"dir2\", \"test_notfound.py\")\n        tmpdir.ensure(\"dir3\", \"test_found.py\")\n        for x in tmpdir.visit(\"test_*.py\"):\n            x.write(\"def test_hello(): pass\")\n\n        result = testdir.runpytest(\"--collect-only\")\n        s = result.stdout.str()\n        assert \"test_notfound\" not in s\n        assert \"test_found\" in s\n", "    def test_class_node_id(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            class TestClass:\n                    pass\n        \"\"\"\n        )\n        items, hookrec = testdir.inline_genitems()\n        assert len(items) == 1\n        item, = items\n        assert item.nodeid == \"TestClass::test_method\"\n        assert item.nodeid == item.fspath.basename + \"::test_method\"\n", "    def test_can_stop_session_on_collection_error_before_maxfail(self, testdir):\n        \"\"\"Verify that session is stopped on collection errors when maxfail is set\"\"\"\n        testdir.makepyfile(\n            \"\"\"\n                assert False\n                assert False\n                assert True\n        \"\"\"\n        )\n\n        res = testdir.runpytest(\"--maxfail=2\")\n        assert res.ret == 2\n        res.stdout.fnmatch_lines(\n            [\n                \"collected 3 items / 2 errors\",\n                \"*ERROR collecting test_01_failure.py*\",\n                \"*AssertionError*\",\n                \"*ERROR collecting test_02_failure.py*\",\n                \"*AssertionError*\",\n            ]\n        )\n\n        res = testdir.runpytest(\"--maxfail=2\", \"--continue-on-collection-errors\")\n        assert res.ret == 1\n        res.stdout.fnmatch_lines(\n            [\"collected 3 items / 2 errors\", \"*1 failed, 2 errors*\"]\n        )\n\n        res = testdir.runpytest(\"--maxfail=2\", \"--continue-on-collection-errors\", \"--strict-markers\")\n        assert res.ret == 2\n        res.stdout.fnmatch_lines(\n            [\n                \"collected 3 items / 2 errors\",\n                \"*ERROR collecting test_01_failure.py*\",\n                \"*AssertionError*\",\n                \"*ERROR collecting test_02_failure.py*\",\n                \"*AssertionError*\",\n            ]\n        )\n", "    def test_collect_directory_with_custom_node(self, testdir):\n        \"\"\"Test that the `pytest_collect_directory` hook is called with the correct path.\"\"\"\n        testdir.makeconftest(\n            \"\"\"\n            import pytest\n            class MyNode(pytest.Node):\n                    return [Item(name=\"hello\", parent=self)]\n            class MyCollector(pytest.Collector):\n                    return MyNode(path, parent)\n                if path.basename == \"hello\":\n                    return MyCollector(path, parent)\n        \"\"\"\n        )\n        testdir.mkdir(\"hello\")\n        result = testdir.runpytest(\"-v\")\n        result.stdout.fnmatch_lines([\"*hello::hello*\"])\n", "    def test_collect_init_with_chdir(self, testdir):\n        \"\"\"Check that we collect __init__.py files when the current working directory changes during import (#3711).\"\"\"\n        testdir.mkdir(\"sub\").join(\"conftest.py\").write(\n            textwrap.dedent(\n                \"\"\"\n            import os\n            os.chdir('%s')\n            \"\"\" % (str(testdir.mkpydir(\"sub\")),)\n            )\n        )\n        testdir.makepyfile(\n            \"\"\"\n            import os\n                assert os.getcwd() == '%s'\n                assert os.getcwd() == '%s'\n            \"\"\" % (str(testdir.mkpydir(\"sub\")), str(testdir.mkpydir(\"sub\")),)\n        )\n\n        with testdir.tmpdir.as_cwd():\n            result = testdir.runpytest(\"-v\", \"--collect-only\")\n        result.stdout.fnmatch_lines(\n            [\n                \"<Package */sub>\",\n                \"  <Module __init__.py>\",\n                \"    <Function test_1>\",\n                \"  <Module test_2.py>\",\n                \"    <Function test_2>\",\n            ]\n        )\n"], "sample_78": ["def test_appgroup_subcommand_app_context(runner):\n    @click.group(cls=AppGroup)\n        pass\n\n    @cli.command()\n        click.echo(current_app.name)\n\n    @cli.group()\n        pass\n\n    @subgroup.command()\n        click.echo(current_app.name)\n\n    obj = ScriptInfo()\n\n    result = runner.invoke(cli, [\"test\"], obj=obj)\n    assert result.exit_code == 0\n    assert result.output == \"cli\\n\"\n\n    result = runner.invoke(cli, [\"subgroup\", \"test2\"], obj=obj)\n    assert result.exit_code == 0\n    assert result.output == \"cli\\n\"\n", "def test_flaskgroup_context_settings(monkeypatch, runner):\n        app = Flask(__name__)\n        app.context_config = {\"foo\": \"bar\"}\n        return app\n\n    cli = FlaskGroup(create_app=create_app, context_settings={\"foo\": \"baz\"})\n    runner.invoke(cli)\n    assert cli.context_settings[\"foo\"] == \"baz\"\n\n    runner.invoke(cli, [\"--help\"])\n    assert cli.context_settings[\"foo\"] == \"baz\"\n\n    cli = FlaskGroup(context_settings={\"foo\": \"baz\"})\n    assert cli.context_settings[\"foo\"] == \"baz\"\n\n    runner.invoke(cli, [\"--help\"])\n    assert cli.context_settings[\"foo\"] == \"baz\"\n\n    cli = FlaskGroup()\n    assert cli.context_settings == {}\n", "def test_cert_param_type(runner):\n    \"\"\"Test the CertParamType option type\"\"\"\n        \"\"\"The ``--cert`` option must be specified when ``--key`` is a file.\"\"\"\n        cert = ctx.params.get(\"cert\")\n        is_adhoc = cert == \"adhoc\"\n\n        if value is not None:\n            if is_adhoc:\n                raise click.BadParameter(\n                    'When \"--cert\" is \"adhoc\", \"--key\" is not used.', ctx, param\n                )\n\n            ctx.params[\"cert\"] = cert, value\n\n        else:\n            if cert and not (is_adhoc):\n                raise click.BadParameter('\"--cert\" must also be specified.', ctx, param)\n\n        return value\n\n    @click.command()\n    @click.option(\"--cert\", type=click.STRING, callback=_validate_cert)\n    @click.option(\"--key\", type=click.Path(exists=True, dir_okay=False, resolve_path=True))\n        pass\n\n    runner.invoke(testcmd, [\"--key\", \"file\"])\n\n    runner.invoke(testcmd, [\"--cert\", \"adhoc\"])\n\n    runner.invoke(testcmd, [\"--cert\", \"import\"])\n\n    with pytest.raises(click.BadParameter):\n        runner.invoke(testcmd, [\"--cert\", \"import\", \"--key\", \"file\"])\n\n    with pytest.raises(click.BadParameter):\n        runner.invoke(testcmd, [\"--key\", \"file\", \"--cert\", \"import\"])\n\n    with pytest.raises(click.BadParameter):\n        runner.invoke(testcmd, [\"--key\", \"file\"])\n\n    with pytest.raises(click.BadParameter):\n        runner.invoke(testcmd, [\"--cert\", \"adhoc\", \"--key\", \"file\"])\n", "def test_load_env_file(monkeypatch):\n    \"\"\"Test that the .env and .flaskenv files are loaded correctly.\n\n    :func:`load_dotenv` checks if `python-dotenv` is installed. If it is,\n    it will attempt to load the .env and .flaskenv files, regardless of\n    the value of the FLASK_SKIP_DOTENV environment variable.\n    \"\"\"\n    monkeypatch.setenv(\"FLASK_SKIP_DOTENV\", \"1\")\n\n        assert path == \".env\"\n        return True\n\n    monkeypatch.setitem(sys.modules, \"dotenv\", types.ModuleType(\"dotenv\"))\n    monkeypatch.setitem(sys.modules[\"dotenv\"], \"load_dotenv\", mock_load_dotenv)\n\n    load_dotenv(\".env\")\n    assert \"TEST_VAR\" in os.environ\n    assert os.environ[\"TEST_VAR\"] == \"test_value\"\n\n    load_dotenv(\".flaskenv\")\n    assert \"FLASK_VAR\" in os.environ\n    assert os.environ[\"FLASK_VAR\"] == \"flask_value\"\n\n    load_dotenv(\".flaskenv\")\n    assert os.environ[\"FLASK_VAR\"] == \"flask_value\"\n\n    load_dotenv()\n    assert \"TEST_VAR\" in os.environ\n    assert os.environ[\"TEST_VAR\"] == \"test_value\"\n", "def test_load_dotenv_suppress_raise(test_apps):\n    class Module:\n            self.__path__ = str(test_path / \"cliapp\")\n\n    pytest.raises(NoAppException, locate_app, Module.__module__, \"notanapp\", raise_if_not_found=False)\n\n"], "sample_92": ["    def test_setup_exception(self, testdir):\n        testdir.makeconftest(\n            \"\"\"\n                0 / 0\n        \"\"\"\n        )\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail\n                assert 0\n        \"\"\"\n        )\n        result = testdir.runpytest(p)\n        assert result.ret == 0\n        assert \"xfailed\" in result.stdout.str()\n        result.stdout.no_fnmatch_line(\"*xpassed*\")\n", "    def test_single_exception(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(raises=TypeError)\n                raise TypeError()\n        \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n", "def test_unexpected_success(testdir):\n    \"\"\"\n    Verify that the unexpected success report works correctly.\n    \"\"\"\n    p = testdir.makepyfile(\n        \"\"\"\n            import pytest\n\n                pass\n    \"\"\"\n    )\n    result = testdir.runpytest(p)\n    result.assert_outcomes(passed=1)\n    result = testdir.runpytest(p, \"-rxf\")\n    result.stdout.fnmatch_lines([\"*Unexpected success: test_func*\"])\n    assert result.ret == 0\n", "    def test_dynamic_xfail_imperative(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n                pytest.mark.xfail(reason=\"hello\").add_to_node(request.node)\n                assert 0\n        \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n        result = testdir.runpytest(p, \"-rx\")\n        result.stdout.fnmatch_lines([\"*XFAIL*test_this*\", \"*reason:*hello*\"])\n        result = testdir.runpytest(p, \"--runxfail\")\n        result.stdout.fnmatch_lines([\"*1 pass*\"])\n", "    def test_condition_with_unbound_variable(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"x\")\n                pass\n            x = 3\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            evaluate_condition(item, item.get_marker(\"skipif\"), \"x\")\n        assert excinfo.value.msg is not None\n        assert \"name 'x' is not defined\" in excinfo.value.msg\n"], "sample_107": ["def test_logistic_regression_check_input():\n    # Test that the input arrays X and y are checked\n    X = [[1, 2, 3]]\n    X_sp = sp.csr_matrix(X)\n    y = [1]\n\n    # Check that the input arrays are not checked when check_input is False\n    lr = LogisticRegression(check_input=False)\n    lr.fit(X, y)\n\n    # Check that the input arrays are checked when check_input is True\n    lr = LogisticRegression(check_input=True)\n    with assert_raise_message(ValueError, \"Input contains NaN, infinity or a value too large for dtypes\":\n        lr.fit(X, y)\n\n    with assert_raise_message(ValueError, \"Input contains NaN, infinity or a value too large for dtypes\"):\n        lr.fit(X_sp, y)\n\n    # Check that the input arrays are not checked when check_input is False\n    lr = LogisticRegression(check_input=False)\n    lr.fit(X_sp, y)\n", "def test_logistic_regression_path_grid_search_cv():\n    # Test that the returned grid of Cs from logistic_regression_path is the same\n    # as the grid of Cs from GridSearchCV\n    n_samples, n_features = iris.data.shape\n    X, y = make_classification(n_samples=n_samples, n_features=n_features,\n                               n_classes=2, random_state=0)\n    Cs = np.logspace(-4, 4, 10)\n\n    param_grid = {'C': Cs}\n    lr = LogisticRegression(solver='lbfgs')\n    gs = GridSearchCV(lr, param_grid, cv=3)\n    gs.fit(X, y)\n\n    coefs, Cs_grid_search, _ = logistic_regression_path(X, y, Cs=Cs)\n    assert_array_almost_equal(Cs_grid_search, Cs)\n    assert_array_almost_equal(coefs, gs.best_estimator_.coef_)\n", "def test_logistic_regression_caching():\n    # Test that LogisticRegression does not cache the weights and predictions\n    # for cross-validation.\n    X, y = iris.data, iris.target\n    cv = StratifiedKFold(5, shuffle=True, random_state=0)\n    scores = list()\n    for train, test in cv.split(X, y):\n        scores.append(LogisticRegressionCV(cv=cv, random_state=0).fit(X[train], y[train]).score(X[test], y[test]))\n    assert len(LogisticRegressionCV(cv=cv, random_state=0).fit(X, y).scores_) != 0\n    assert len(LogisticRegressionCV(cv=cv, random_state=0).fit(X, y).scores_) == len(scores)\n", "def test_logistic_regression_path_zero_alpha():\n    # Test that alpha is correctly set to 0 when penalty is set to 'none'\n\n    X, y = make_classification(random_state=0)\n    alpha = 0\n    C = 1\n    tol = 1e-5\n    Cs = [1]\n    solver = 'lbfgs'\n    random_state = 0\n    penalty = 'none'\n\n    lr_path = LogisticRegressionCV(Cs=Cs, solver=solver, random_state=random_state,\n                                   tol=tol, fit_intercept=True, penalty=penalty,\n                                   multi_class='ovr')\n    with ignore_warnings():\n        lr_path.fit(X, y)\n\n    assert lr_path.C_ == 1e6\n\n    # Test for LogisticRegression\n    lr = LogisticRegression(C=C, fit_intercept=True, solver=solver,\n                            random_state=random_state, penalty=penalty, tol=tol,\n                            multi_class='ovr')\n    with ignore_warnings():\n        lr.fit(X, y)\n\n    assert lr.coef_[0, -1] == 0\n    assert lr.coef_[0, 0] == lr.coef_[0, 1]\n", "def test_logistic_regression_path_fmin_l_bfgs_b():\n    # Test that the fmin_l_bfgs_b call in _logistic_regression_path\n    # does not overflow when the parameter space is very large\n\n    X, y = make_classification(n_samples=50, n_features=20,\n                               random_state=0)\n    Cs = np.logspace(1, 10, 10)\n\n    rng = np.random.RandomState(42)\n    w = rng.rand(X.shape[1])\n    lr = LogisticRegression(random_state=42, solver='lbfgs')\n    loss, _, _ = _logistic_loss_and_grad(w, X, y, alpha=1.)\n\n    with ignore_warnings(category=ConvergenceWarning):\n        loss, _, _ = _logistic_regression_path(X, y, Cs=Cs, solver='lbfgs',\n                                                w0=w, max_iter=100)\n        # Make sure that _logistic_regression_path does not overflow\n        # the internal parameter space of fmin_l_bfgs_b\n        for c in Cs:\n            assert not np.isnan(loss)\n"], "sample_45": ["    def test_deny_decorator(self):\n        \"\"\"\n        Ensures @xframe_options_deny properly sets the X-Frame-Options header.\n        \"\"\"\n        @xframe_options_deny\n            return HttpResponse()\n        r = a_view(HttpRequest())\n        self.assertEqual(r.headers['X-Frame-Options'], 'DENY')\n", "def test_cache_page_kwargs(self):\n    \"\"\"\n    Test for cache_page decorator with kwargs.\n    \"\"\"\n        return HttpResponse(\"response\")\n    my_view_cached = cache_page(123, key_prefix=\"test\")(my_view)\n    self.assertEqual(my_view_cached(HttpRequest()), \"response\")\n    my_view_cached2 = cache_page(123, key_prefix=\"test2\")(my_view)\n    self.assertEqual(my_view_cached2(HttpRequest()), \"response\")\n    my_view_cached3 = cache_page(123, key_prefix=\"test3\", max_age=60 * 30)(my_view)\n    self.assertEqual(my_view_cached3(HttpRequest()), \"response\")\n", "    def test_cache_page_decorator(self):\n        \"\"\"Test the cache_page decorator.\"\"\"\n            return \"response\"\n        my_view_cached = cache_page(123)(my_view)\n        self.assertEqual(my_view_cached(HttpRequest()), \"response\")\n        my_view_cached2 = cache_page(123, key_prefix=\"test\")(my_view)\n        self.assertEqual(my_view_cached2(HttpRequest()), \"response\")\n", "def test_decorator_from_middleware_with_args(self):\n    \"\"\"\n    Test decorator_from_middleware_with_args\n    \"\"\"\n    class MyMiddleware:\n            self.view_func = view_func\n            self.args = args\n            self.kwargs = kwargs\n\n    @decorator_from_middleware_with_args(MyMiddleware)\n        return HttpResponse()\n\n    my_view_args = [1, 2, 3]\n    my_view_kwargs = {'key': 'value'}\n    response = my_view(HttpRequest(), *my_view_args, **my_view_kwargs)\n    self.assertEqual(response, \"response\")\n    self.assertEqual(MyMiddleware(my_view, *my_view_args, **my_view_kwargs).args, my_view_args)\n    self.assertEqual(MyMiddleware(my_view, *my_view_args, **my_view_kwargs).kwargs, my_view_kwargs)\n", "    def test_vary_decorator(self):\n        \"\"\"\n        Test that the vary decorators work correctly with a view.\n        \"\"\"\n        @vary_on_cookie\n            return \"response\"\n\n        request = HttpRequest()\n        response = my_view(request)\n        self.assertEqual(response, \"response\")\n        self.assertEqual(response.cookies, {})\n\n        request = HttpRequest()\n        request.COOKIES['cookie'] = 'value'\n        response = my_view(request)\n        self.assertEqual(response, \"response\")\n        self.assertEqual(len(response.cookies), 1)\n        self.assertEqual(response.cookies['cookie']['value'], 'value')\n\n        @vary_on_headers('Cookie')\n            return \"response\"\n\n        request = HttpRequest()\n        response = my_view(request)\n        self.assertEqual(response, \"response\")\n        self.assertEqual(response.headers.get('Vary'), 'Cookie')\n\n        request = HttpRequest()\n        request.COOKIES['cookie'] = 'value'\n        response = my_view(request)\n        self.assertEqual(response, \"response\")\n        self.assertEqual(len(response.headers), 1)\n        self.assertEqual(response.headers['Vary'], 'Cookie')\n"], "sample_100": ["def test_one_hot_encoder_handle_unknown_dtype():\n    X = np.array([[0, 1]], dtype=np.int32).T\n    X2 = np.array([[2, 1]], dtype=np.int32).T\n    oh = OneHotEncoder(categories='auto', handle_unknown='ignore')\n    oh.fit(X)\n    assert_raises_regex(ValueError, \"Input contains NaN\", oh.transform, X2)\n", "def test_one_hot_encoder_preserve_original_order():\n    X = [['abc', 2, 55], ['def', 1, 55], ['abc', 3, 55]]\n    X2 = [['def', 1, 55], ['abc', 3, 55], ['abc', 2, 55]]\n    enc = OneHotEncoder()\n    X_trans = enc.fit_transform(X).toarray()\n    X2_trans = enc.transform(X2).toarray()\n    assert_array_equal(X_trans, X2_trans)\n", "def test_ordinal_encoder_dtype():\n    # check that dtypes are preserved when determining categories\n    enc = OrdinalEncoder(categories='auto')\n    exp = np.array([[0., 1.],\n                    [1., 0.]], dtype='float64')\n\n    for X in [np.array([[1, 2], [3, 4]], dtype='int64'),\n              np.array([[1, 2], [3, 4]], dtype='float64'),\n              np.array([['a', 'b'], ['c', 'd']]),  # string dtype\n              np.array([[1, 'a'], [3, 'b']], dtype='object')]:\n        enc.fit(X)\n        assert all([enc.categories_[i].dtype == X.dtype for i in range(2)])\n        assert_array_equal(enc.transform(X).astype(X.dtype), exp)\n\n    X = [[1, 2], [3, 4]]\n    enc.fit(X)\n    assert all([np.issubdtype(enc.categories_[i].dtype, np.integer)\n                for i in range(2)])\n    assert_array_equal(enc.transform(X).astype(X.dtype), exp)\n\n    X = [[1, 'a'], [3, 'b']]\n    enc.fit(X)\n    assert all([enc.categories_[i].dtype == 'object' for i in range(2)])\n    assert_array_equal(enc.transform(X).astype(X.dtype), exp)\n\n    # Test with different output dtypes\n    enc = OrdinalEncoder(categories='auto', dtype=np.float32)\n    X = [[1, 2], [3, 4]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X).dtype, np.float32)\n", "def test_one_hot_encoder_n_values_auto():\n    # check that setting n_values to 'auto' works\n    X = [[3, 2, 1], [0, 1, 1]]\n    enc = OneHotEncoder(n_values='auto')\n    with ignore_warnings(category=DeprecationWarning):\n        X_trans = enc.fit_transform(X)\n    assert_equal(X_trans.shape, (2, 5))\n    assert_array_equal(enc.feature_indices_, [0, 4, 7, 9])\n\n    # check that the n_values_ attribute is set correctly\n    assert_array_equal(enc.n_values_, [4, 2, 2])\n\n    # check that setting n_values to 'auto' with handle_unknown='ignore'\n    # does not raise a warning\n    enc = OneHotEncoder(n_values='auto', handle_unknown='ignore')\n    with ignore_warnings(category=DeprecationWarning):\n        enc.fit(X)\n\n    # check that setting n_values to 'auto' with handle_unknown='error'\n    # raises a warning\n    enc = OneHotEncoder(n_values='auto', handle_unknown='error')\n    with assert_warns(DeprecationWarning):\n        enc.fit(X)\n\n    # check that setting n_values to 'auto' with legacy mode disabled\n    # raises a warning\n    enc = OneHotEncoder(categories='auto', n_values='auto')\n    with assert_warns(DeprecationWarning):\n        enc.fit(X)\n", "def test_one_hot_encoder_fit_transform_on_sparse_input():\n    X = sparse.csr_matrix([[1, 2, 3], [4, 5, 6]])\n    enc = OneHotEncoder(sparse=True)\n    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):\n        X_transformed = enc.fit_transform(X).toarray()\n    assert_array_equal(X_transformed.shape, (2, 7))\n    assert_array_equal(X_transformed,\n                       [[0., 0., 0., 1., 0., 1., 0.],\n                        [1., 0., 1., 0., 0., 0., 1.]])\n\n    # check that `fit_transform` doesn't fail with an empty array\n    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):\n        X_transformed = enc.fit_transform(np.array([]))\n    assert_array_equal(X_transformed.shape, (0, 7))\n\n    # check that `fit_transform` preserves the sparse format\n    X_transformed_sparse = enc.fit_transform(X)\n    assert sparse.isspmatrix_csr(X_transformed_sparse)\n\n    # check that error is raised when wrong number of features in fit\n    # with prespecified n_values\n    with ignore_warnings(category=DeprecationWarning):\n        assert_raises(ValueError, enc.fit, X[:, :-1])\n"], "sample_77": ["    def test_label_offset(self, x):\n        s = Continuous().label(base=2, offset=True)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        labels = a.major.formatter.format_ticks([100])\n        for text in labels:\n            assert r\"10^{2}\" in text\n", "    def test_tick_count_between(self, t, x):\n\n        n = 5\n        lo, hi = 0, 365\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(count=n, between=(lo, hi))._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        expected = np.linspace(lo, hi, n)\n        assert_array_equal(locator.locator().locator(), expected)\n", "    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n", "    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n", "    def test_norm_auto(self, x):\n\n        s = Continuous(norm=None)._setup(x, Coordinate())\n        assert s(x) == x\n"], "sample_68": ["def test_update_conflicts_invalid_update_fields_pk(self):\n    msg = \"bulk_create() cannot be used with primary keys in update_fields.\"\n    with self.assertRaisesMessage(ValueError, msg):\n        BigAutoFieldModel.objects.bulk_create(\n            [BigAutoFieldModel()],\n            update_conflicts=True,\n            update_fields=[\"id\", \"name\"],\n            unique_fields=[\"id\"],\n        )\n", "def test_update_conflicts_unsupported(self):\n    msg = \"This database backend does not support updating conflicts.\"\n    with self.assertRaisesMessage(NotSupportedError, msg):\n        UpsertConflict.objects.bulk_create(\n            [\n                UpsertConflict(number=1, rank=1, name=\"John\"),\n                UpsertConflict(number=2, rank=2, name=\"Mary\"),\n                UpsertConflict(number=3, rank=3, name=\"Hannah\"),\n            ],\n            update_conflicts=True,\n        )\n", "    def setUp(self):\n        self.data = [\n            Country(name=\"United States of America\", iso_two_letter=\"US\"),\n            Country(name=\"The Netherlands\", iso_two_letter=\"NL\"),\n            Country(name=\"Germany\", iso_two_letter=\"DE\"),\n            Country(name=\"Czech Republic\", iso_two_letter=\"CZ\"),\n        ]\n", "def test_update_conflicts_no_unique_fields_conflicts_exception(self):\n    with self.assertRaises(IntegrityError):\n        Country.objects.bulk_create(\n            [\n                Country(name=\"Germany\", iso_two_letter=\"DE\", description=\"Desc\"),\n                Country(name=\"Germany\", iso_two_letter=\"DE\", description=\"Desc2\"),\n            ],\n            update_conflicts=True,\n            update_fields=[\"name\"],\n        )\n", "    def setUp(self):\n        self.country = Country.objects.create(name=\"United States of America\", iso_two_letter=\"US\")\n        self.country2 = Country.objects.create(name=\"Germany\", iso_two_letter=\"DE\")\n        self.country3 = Country.objects.create(name=\"The Netherlands\", iso_two_letter=\"NL\")\n"], "sample_14": ["def test_serialize_deconstructable(self):\n    validator = deconstructible(\n        path=\"django.core.validators.EmailValidator\"\n    )(EmailValidator)(message=\"hello\")\n    string, imports = MigrationWriter.serialize(validator)\n    self.assertEqual(string, \"migrations.test_writer.EmailValidator(message='hello')\")\n\n    validator = deconstructible(\n        path=\"migrations.test_writer.EmailValidator\"\n    )(EmailValidator)(message=\"hello\")\n    string, imports = MigrationWriter.serialize(validator)\n    self.assertEqual(string, \"migrations.test_writer.EmailValidator(message='hello')\")\n", "def test_serialize_deconstructable(self):\n    \"\"\"Test serialization of classes that know how to deconstruct.\"\"\"\n    class DeconstructableClass:\n            return ('DeconstructableClass', [], {})\n\n    class DeconstructableClassWithArgs:\n            return ('DeconstructableClassWithArgs', [1, 2], {'kwarg': 3})\n\n    class DeconstructableClassWithKWArgs:\n            return ('DeconstructableClassWithKWArgs', [], {'kwarg': 3})\n\n    class DeconstructableClassWithPath:\n            return ('DeconstructableClassWithPath', ['path.to.module'], {'kwarg': 3})\n\n    self.assertSerializedResultEqual(DeconstructableClass, (\"migrations.test_writer.DeconstructableClass\", {'import migrations.test_writer'}))\n    self.assertSerializedResultEqual(DeconstructableClassWithArgs, (\"migrations.test_writer.DeconstructableClassWithArgs(1, 2)\", {'import migrations.test_writer'}))\n    self.assertSerializedResultEqual(DeconstructableClassWithKWArgs, (\"migrations.test_writer.DeconstructableClassWithKWArgs(kwarg=3)\", {'import migrations.test_writer'}))\n    self.assertSerializedResultEqual(DeconstructableClassWithPath, (\"migrations.test_writer.DeconstructableClassWithPath(path.to.module, **{'kwarg': 3})\", {'import migrations.test_writer'}))\n", "    def test_custom_serializer_import_path(self):\n        class ComplexSerializer(BaseSerializer):\n                return 'complex(%r)' % self.value, {}\n\n        Serializer.register(type(ComplexSerializer), ComplexSerializer)\n        value = DeconstructibleInstances()\n        string, imports = MigrationWriter.serialize(value)\n        self.assertEqual(string, \"complex(migrations.test_writer.DeconstructibleInstances)\")\n        self.assertEqual(imports, {'import migrations.test_writer'})\n        self.serialize_round_trip(value)\n\n        # Test that the import is not duplicated\n        string, imports = MigrationWriter.serialize(value)\n        self.assertEqual(len(imports), 1)\n", "def test_serialize_decimal_decimal(self):\n    \"\"\"\n    Test serialization of decimal.Decimal objects.\n    \"\"\"\n    self.assertSerializedResultEqual(\n        decimal.Decimal('1.3'),\n        (\"Decimal('1.3')\", {'from decimal import Decimal'})\n    )\n    self.assertSerializedResultEqual(\n        decimal.Decimal('123456789012345678901234567890'),\n        (\"Decimal('123456789012345678901234567890')\", {'from decimal import Decimal'})\n    )\n\n    self.assertSerializedResultEqual(\n        Money('1.3'),\n        (\"migrations.test_writer.Money('1.3')\", {'import migrations.test_writer'})\n    )\n    self.assertSerializedResultEqual(\n        Money('123456789012345678901234567890'),\n        (\"migrations.test_writer.Money('123456789012345678901234567890')\", {'import migrations.test_writer'})\n    )\n\n    # Test decimal.Decimal with custom decimal context\n    self.assertSerializedResultEqual(\n        decimal.Decimal('1.3'), \n        (\"Decimal('1.3')\", {'from decimal import Decimal'})\n    )\n    self.assertSerializedResultEqual(\n        decimal.Decimal('123456789012345678901234567890'), \n        (\"Decimal('123456789012345678901234567890')\", {'from decimal import Decimal'})\n    )\n\n    # Test serialization of decimal.Decimal with precision and scale\n    self.assertSerializedResultEqual(\n        decimal.Decimal('123.45'), \n        (\"Decimal('123.45')\", {'from decimal import Decimal'})\n    )\n    self.assertSerializedResultEqual(\n        decimal.Decimal('123456789012345678901234567890.123456'), \n        (\"Decimal('123456789012345678901234567890.123456')\", {'from decimal import Decimal'})\n    )\n", "    def test_simple_serializable(self):\n        value = 5\n        expected_imports = set()\n        expected_string = '5'\n        self.assertEqual(serializer_factory(value), serializer_factory(value))\n        string, imports = serializer_factory(value).serialize()\n        self.assertEqual(imports, expected_imports)\n        self.assertEqual(string, expected_string)\n"], "sample_57": ["    def test_can_order_flag_false_by_default(self):\n        ChoiceFormSet = formset_factory(Choice)\n        self.assertFalse(ChoiceFormSet().can_order)\n", "def test_formset_invalid_initial_forms(self):\n    \"\"\"\n    If an initial form is invalid, the entire formset is invalid.\n    \"\"\"\n    data = {\n        \"choices-TOTAL_FORMS\": \"2\",\n        \"choices-INITIAL_FORMS\": \"2\",\n        \"choices-MIN_NUM_FORMS\": \"0\",\n        \"choices-MAX_NUM_FORMS\": \"0\",\n        \"choices-0-choice\": \"Gin and Tonic\",\n        \"choices-0-votes\": \"100\",\n        \"choices-1-choice\": \"Gin and Tonic\",\n        \"choices-1-votes\": \"\",  # invalid\n    }\n    ChoiceFormSet = formset_factory(Choice, extra=1)\n    formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(\n        formset.errors,\n        [{\"votes\": [\"This field is required.\"]}, {\"votes\": [\"This field is required.\"]}],\n    )\n", "    def test_management_form_is_valid(self):\n        \"\"\"ManagementForm is valid if all formset data is correct.\"\"\"\n        data = {\n            \"choices-TOTAL_FORMS\": \"2\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-MAX_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Zero\",\n            \"choices-0-votes\": \"0\",\n            \"choices-1-choice\": \"One\",\n            \"choices-1-votes\": \"1\",\n        }\n        ChoiceFormSet = formset_factory(Choice)\n        formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        self.assertTrue(formset.management_form.is_valid())\n", "    def test_can_delete_extra_forms(self):\n        \"\"\"When can_delete_extra=True, extra forms can be deleted.\"\"\"\n        ChoiceFormFormset = formset_factory(form=Choice, can_delete=True, extra=2)\n        formset = ChoiceFormFormset()\n        # The forms in the formset are extra forms, so they can be deleted.\n        data = {\n            \"form-TOTAL_FORMS\": \"2\",\n            \"form-INITIAL_FORMS\": \"0\",\n            \"form-0-choice\": \"\",\n            \"form-0-votes\": \"\",\n            \"form-0-DELETE\": \"on\",\n            \"form-1-choice\": \"\",\n            \"form-1-votes\": \"\",\n            \"form-1-DELETE\": \"on\",\n        }\n        formset = ChoiceFormFormset(data, prefix=\"form\")\n        self.assertTrue(formset.is_valid())\n        self.assertEqual(formset.cleaned_data, [{}, {}, {}])\n        self.assertEqual(formset.deleted_forms, [formset.forms[0], formset.forms[1]])\n", "    def test_default_rendering_order(self):\n        \"\"\"The default rendering order is ascending form index.\"\"\"\n        ChoiceFormSet = formset_factory(Choice, extra=3)\n        formset = ChoiceFormSet()\n        # Rendered forms should be ordered by index.\n        self.assertHTMLEqual(\n            \"\\n\".join(form.as_ul() for form in formset.forms),\n            '<li>Choice: <input type=\"text\" name=\"choices-0-choice\"></li>'\n            '<li>Votes: <input type=\"number\" name=\"choices-0-votes\"></li>'\n            '<li>Choice: <input type=\"text\" name=\"choices-1-choice\"></li>'\n            '<li>Votes: <input type=\"number\" name=\"choices-1-votes\"></li>'\n            '<li>Choice: <input type=\"text\" name=\"choices-2-choice\"></li>'\n            '<li>Votes: <input type=\"number\" name=\"choices-2-votes\"></li>',\n        )\n"], "sample_151": ["def test_point_project():\n    p1 = Point3D(1, 2, 3)\n    p2 = Point3D(4, 5, 6)\n    p3 = Point3D(0, 0, 0)\n    assert Point.project(p1, p2) == Point3D(0.4117647058823529, 0.5882352941176471, 0.8235294117647058)\n    assert Point.project(p2, p1) == Point3D(0.4117647058823529, 0.5882352941176471, 0.8235294117647058)\n    assert Point.project(p1, p3) == Point3D(1, 2, 3)\n    assert Point.project(p3, p1) == Point3D(1, 2, 3)\n    raises(ValueError, lambda: Point.project(p1, Point3D(0, 0)))\n", "def test_ambient_dimension():\n    p1 = Point(1, 2, 3)\n    p2 = Point(1, 2)\n    p3 = Point(1, 2, 3, 4)\n    assert p1.ambient_dimension == 3\n    assert p2.ambient_dimension == 2\n    assert p3.ambient_dimension == 4\n    raises(ValueError, lambda: Point(1, 2, dim=2))\n    raises(ValueError, lambda: Point(1, 2, dim=5))\n    assert Point(1, 2, evaluate=False, dim=3).args[0].is_Float\n", "def test_issue_28765():\n    \"\"\"Test the Point.taxicab_distance method with multiple inputs.\"\"\"\n    x = Symbol('x', real=True)\n    y = Symbol('y', real=True)\n    p1 = Point(0, 0)\n    p2 = Point(1, 1)\n    p3 = Point(x, y)\n    assert p1.taxicab_distance(p2) == 2\n    assert p1.taxicab_distance(p3) == Abs(x) + Abs(y)\n    assert p2.taxicab_distance(p3) == Abs(x - 1) + Abs(y - 1)\n\n    # Test with different types of inputs\n    p4 = Point(0.5, 0.5)\n    p5 = (1, 2)\n    assert p1.taxicab_distance(p4) == 1\n    assert p1.taxicab_distance(p5) == 1.5\n", "def test_mpmath_precision():\n    # Test mpmath precision\n    p1 = Point3D(0.1, 0.2, 0.3)\n    p2 = Point3D(0.1, 0.2, 0.3)\n    assert p1.distance(p2) == S.Zero\n\n    p3 = Point3D(0.1, 0.2, 0.3)\n    p4 = Point3D(0.1, 0.2, 0.3)\n    assert p3.distance(p4) == S.Zero\n\n    p5 = Point3D(1.0, 2.0, 3.0)\n    p6 = Point3D(1, 2, 3)\n    assert p5.distance(p6) == S.Zero\n\n    p7 = Point3D(1.0, 2.0, 3.0)\n    p8 = Point3D(1, 2, 3)\n    assert p7.distance(p8) == S.Zero\n\n    # Test evalf\n    a, b, c = S.Half, Rational(1, 3), Rational(1, 4)\n    p = Point3D(a, b, c)\n    assert p.evalf(0) == Point3D(Rational(1, 2), Rational(1, 3), Rational(1, 4))\n    assert p.evalf(2) == Point3D(S.Half, Rational(1, 3), Rational(1, 4))\n    assert p.evalf(3) == Point3D(Rational(1, 2), Rational(1, 3), Rational(1, 4))\n    p = Point3D(0.1, 0.2, 0.3)\n    assert p.evalf(0) == Point3D(0.1, 0.2, 0.3)\n", "def test_perpendicular():\n    # Test Perpendicular\n    p1 = Point3D(1, 1, 1)\n    p2 = Point3D(1, 1, 0)\n    p3 = Point3D(1, 0, 0)\n\n    assert p1.perpendicular(p2) == p3\n    assert p1.perpendicular(p3) == p2\n    assert p2.perpendicular(p3) == p1\n    assert p3.perpendicular(p1) == Point3D(1, 1, 1)\n    assert p1.perpendicular(p1) == p1\n    assert p2.perpendicular(p2) == p2\n    assert p3.perpendicular(p3) == p3\n    with warns(UserWarning):\n        assert p1.perpendicular((1, 2, 3))\n    with warns(UserWarning):\n        assert (1, 2, 3).perpendicular(p1)\n\n    p1 = Point(1, 0)\n    p2 = Point(0, 1)\n    p3 = Point(-1, 0)\n    assert p1.perpendicular(p2) == p3\n    assert p1.perpendicular(p3) == p2\n    assert p2.perpendicular(p3) == p1\n    assert p3.perpendicular(p1) == Point(1, 0)\n    assert p1.perpendicular(p1) == p1\n    assert p2.perpendicular(p2) == p2\n    assert p3.perpendicular(p3) == p3\n    with warns(UserWarning):\n        assert p1.perpendicular((1, 2))\n    with warns(UserWarning):\n        assert (1, 2).perpendicular(p1)\n"], "sample_43": ["def test_to_field_resolution_with_mti_multiple_level(self):\n    \"\"\"\n    to_field resolution should correctly resolve for target models using MTI with multiple levels.\n    \"\"\"\n    tests = [\n        (Author, Authorship, 'author', 'author'),\n        (Author, Book, 'authorship', 'author'),\n    ]\n    for Target, Remote, related_name, to_field_name in tests:\n        with self.subTest(target_model=Target, remote_model=Remote, related_name=related_name, to_field_name=to_field_name):\n            o = Target.objects.create(name=\"Frida Kahlo\", gender=2, code=\"painter\", alive=False)\n            opts = {\n                'app_label': Remote._meta.app_label,\n                'model_name': Remote._meta.model_name,\n                'field_name': related_name,\n            }\n            request = self.factory.get(self.url, {'term': 'frida', **opts})\n            request.user = self.superuser\n            response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n            self.assertEqual(response.status_code, 200)\n            data = json.loads(response.content.decode('utf-8'))\n            self.assertEqual(data, {\n                'results': [{'id': str(o.pk), 'text': o.name}],\n                'pagination': {'more': False},\n            })\n", "def test_search_results_with_limit_choices_to(self):\n    \"\"\"Search results are filtered by limit_choices_to.\"\"\"\n    q = Question.objects.create(question='Question 1', question_with_to_field='Q1')\n    Question.objects.create(question='Question 2', question_with_to_field='Q2')\n    Question.objects.create(question='Not a question.', question_with_to_field='NQ')\n    request = self.factory.get(self.url, {'term': 'q', **self.opts, 'field_name': 'question_with_to_field'})\n    request.user = self.superuser\n    response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n    self.assertEqual(response.status_code, 200)\n    data = json.loads(response.content.decode('utf-8'))\n    self.assertEqual(data, {\n        'results': [{'id': str(q.uuid), 'text': q.question}],\n        'pagination': {'more': False},\n    })\n", "    def setUpTestData(self):\n        super().setUpTestData()\n        class CustomSearchQuestionAdmin(QuestionAdmin):\n            search_fields = ['question', 'related_questions__question']\n", "def test_limit_choices_to_permission_denied(self):\n    \"\"\"\n    A limit_choices_to should be allowed on a field of a model that the user has\n    the permission to view but not change.\n    \"\"\"\n    request = self.factory.get(self.url, {'term': 'is', **self.opts, 'field_name': 'question_with_to_field'})\n    request.user = self.user\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n    # Give the user the permission to change the question model.\n    p = Permission.objects.get(\n        content_type=ContentType.objects.get_for_model(Question),\n        codename='change_question',\n    )\n    self.user.user_permissions.add(p)\n    request.user = User.objects.get(pk=self.user.pk)\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n    # Give the user the permission to view the question model, but not change.\n    p = Permission.objects.get(\n        content_type=ContentType.objects.get_for_model(Question),\n        codename='view_question',\n    )\n    self.user.user_permissions.add(p)\n    request.user = User.objects.get(pk=self.user.pk)\n    response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n    self.assertEqual(response.status_code, 200)\n", "    def setUpTestData(cls):\n        super().setUpTestData()\n        cls.site.register(Employee, search_fields=['code'])\n        cls.site.register(Manager, search_fields=['code'])\n"], "sample_38": ["    def test_disabled_field(self):\n        field = ReadOnlyPasswordHashField()\n        self.assertIs(field.disabled, True)\n", "    def test_render_summary(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = 'pbkdf2_sha256$100000$a6Pucb1qSFcD$WmCkn9Hqidj48NVe5x0FEM6A9YiOqQcl/83m2Z5udm0='\n        summary = widget.get_context('name', value, {}).get('summary')\n        self.assertEqual(summary, [\n            {'label': 'algorithm', 'value': 'pbkdf2_sha256'},\n            {'label': 'iterations', 'value': '100000'},\n            {'label': 'salt', 'value': 'a6Pucb******'},\n            {'label': 'hash', 'value': 'WmCkn9**************************************'},\n        ])\n", "    def test_normalized_password(self):\n        # The password is hashed and then normalized.\n        user = User.objects.create_user(username='testuser', password='testuser')\n        form = UserChangeForm(instance=user)\n        self.assertIn(_(\"No password set.\"), form.as_table())\n", "    def test_custom_template(self):\n        \"\"\"\n        Test that we can specify a custom template for the read-only\n        password hash field.\n        \"\"\"\n        class TestForm(forms.Form):\n            hash_field = ReadOnlyPasswordHashField(template_name='auth/widgets/my_read_only_password_hash.html')\n\n        widget = TestForm()['hash_field'].field.widget\n        html = widget.render('name', 'aaa', {'id': 'id_password'})\n        self.assertIn('<div id=\"id_password\"', html)\n\n        with override_settings(TEMPLATES=[{'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [os.path.dirname(__file__)]}]):\n            html = widget.render('name', 'aaa', {'id': 'id_password'})\n            self.assertIn('<div id=\"id_password\">', html)\n", "    def test_readonly_widget_has_no_id(self):\n        widget = ReadOnlyPasswordHashWidget()\n        html = widget.render('name', 'password', {'id': 'id_password'})\n        self.assertNotIn('id=\"id_password\"', html)\n"], "sample_79": ["def test_concat_fill_value_non_na(self):\n    # Test that fill_value can be a non-NA value\n    foo = DataArray([1, 2], coords=[(\"x\", [1, 2])])\n    bar = DataArray([1, 2], coords=[(\"x\", [1, 3])])\n    expected = DataArray(\n        [[1, 2, 2], [1, 2, 2]],\n        dims=[\"y\", \"x\"],\n        coords={\"x\": [1, 2, 3]},\n    )\n    actual = concat((foo, bar), dim=\"y\", fill_value=2)\n    assert_identical(actual, expected)\n", "def test_concat_fill_value_array(self):\n    data = Dataset({\"a\": (\"x\", np.arange(10)), \"x\": np.arange(10)})\n    expected = Dataset({\"a\": (\"x\", np.arange(20)), \"x\": np.arange(20)})\n    actual = concat([data.isel(x=slice(10)), data.isel(x=slice(10, None))], \"x\", fill_value=10)\n    assert_identical(expected, actual)\n", "def test_concat_broadcast_equals():\n    ds1 = Dataset({\"foo\": (\"x\", [1])}, {\"x\": 1})\n    ds2 = Dataset({\"foo\": (\"x\", [1])}, {\"x\": 1})\n\n    result = concat([ds1, ds2], dim=\"x\", data_vars=\"minimal\", compat=\"broadcast_equals\")\n    expected = Dataset({\"foo\": (\"x\", [1, 1])}, {\"x\": [1, 1]})\n    assert_equal(result, expected)\n\n    result = concat([ds1, ds2], dim=\"x\", data_vars=\"minimal\", compat=\"equals\")\n    expected = Dataset({\"foo\": (\"x\", [1])}, {\"x\": [1]})\n    assert_equal(result, expected)\n\n    result = concat([ds1, ds2], dim=\"x\", data_vars=\"minimal\", compat=\"no_conflicts\")\n    expected = Dataset({\"foo\": (\"x\", [1, 1])}, {\"x\": [1, 1]})\n    assert_equal(result, expected)\n", "def test_concat_no_concat_dim_coord(self):\n    # infer the wrong dimension and coordinate for the concat dimension\n    ds1 = Dataset({\"foo\": (\"x\", [1, 2])}, coords={\"x\": [0, 1]})\n    ds2 = Dataset({\"foo\": (\"x\", [1, 2])}, coords={\"x\": [0, 1]})\n    with raises_regex(ValueError, \"is a coordinate in some datasets but not others\"):\n        concat([ds1, ds2], \"y\")\n", "    def test_concat_with_dask_array(self):\n        # Test that DataArray can be concatenated with Dask array\n        from dask.array import from_array\n\n        x = np.arange(4).reshape(2, 2)\n        arr = from_array(x, chunks=(2, 2))\n        da = DataArray(x, dims=[\"x\", \"y\"], coords={\"x\": [0, 1]})\n        expected = DataArray(\n            np.array([da.values, arr.values]),\n            dims=[\"w\", \"x\", \"y\"],\n            coords={\"x\": [0, 1]},\n        )\n        actual = concat([da, arr], \"w\")\n        assert_equal(expected, actual)\n"], "sample_135": ["def test_sort_key():\n    a = Basic(1)\n    b = Basic(2)\n    assert a.sort_key() < b.sort_key()\n    assert a.sort_key() == a.sort_key()\n    assert b.sort_key() > a.sort_key()\n\n    a, b = symbols('a b')\n    f = lambda x: x.sort_key()\n    sorted_a, sorted_b = sorted([a, b], key=f)\n    assert sorted_a == a\n    assert sorted_b == b\n\n    assert S(1/2).sort_key() < S(2).sort_key()\n    assert S(1/2).sort_key() == S(1/2).sort_key()\n    assert S(2).sort_key() > S(1/2).sort_key()\n\n    c = a*b\n    assert c.sort_key() > a.sort_key()\n    assert c.sort_key() < b.sort_key()\n", "def test_replace():\n    x, y = symbols('x y')\n    p1 = Wild('p1')\n    p2 = Wild('p2')\n    p3 = Wild('p3')\n    e = (x + y)**(x + y)\n    assert e.replace(p1*p2, p1 + p2) == (x + y)**(x + y)\n    assert e.replace(p1*p2, lambda p1, p2: p1 + p2) == (x + y)**(x + y)\n    assert e.replace(p1*p2, p3) == e\n    assert e.replace(p1, lambda p1: x) == (x + y)**x\n    assert e.replace(p1, p3) == (x + y)**(x + y)\n    assert e.replace(lambda p: p.is_Pow, lambda p: p.base**(1 - (p.exp - 1))) == x**(1 - y) + y\n    assert e.replace(lambda p: p.is_Pow and p.exp.is_Add and p.exp.args[0] == 1, lambda p: p.base**(1 - (p.exp - 1))) == x**(1 - y) + y\n    assert (x + y).replace(lambda p: p.is_Mul, lambda p: 2*p) == 2*(x + y)\n    assert ((x + y)*2).replace(lambda p: p.is_Mul, lambda p: 2*p) == (x + y)*4\n    assert ((x + y)*2).replace(lambda p: p.is_Mul, lambda p: 2*p, simultaneous=False) == (x + y)*(2*2)\n    assert ((x + y)*2).replace(lambda p: p.is_Mul, lambda p: 2*p, simultaneous=False) == (x + y)*4\n    assert ((x + y)*2).replace(lambda p: p.is_Mul, lambda p: 2*p, simultaneous=False, exact=True) == (x + y)*(2*2)\n    assert ((x + y)*2).replace(lambda p: p.is_Mul, lambda p: 2*p, simultaneous=False, exact=True) == (x + y)*4\n", "def test_replace():\n    x = symbols('x')\n    a = Wild('a')\n    b = Wild('b')\n    c = Wild('c')\n    expr = a*x**b + c*x**b\n    expr2 = x + x\n    assert expr.replace(a*x**b, b*x) == expr\n    assert expr.replace(a*x**b, b*x, simultaneous=False) == expr\n    assert expr.replace(a*x**b, b*x, map=True) == {(a*x**b): (b*x), (c*x**b): (c*x**b)}\n    assert expr.replace(a*x**b + c*x**b, b*x + c*x**b) == expr\n    assert expr.replace(lambda arg: arg.is_Mul, lambda arg: arg**2) == (a*x**b)**2 + (c*x**b)**2\n    assert expr.replace(lambda arg: arg.is_Mul and arg.args[0].is_Pow and arg.args[0].exp.is_Add, lambda arg: arg.args[0].args[0]**arg.args[0].args[1].args[0]) == a**c*x**b + c**c*x**b\n    assert expr.replace(x**b, x**2) == a*x**2 + c*x**2\n    assert expr2.replace(x, x+1) == x+1+x+1\n    assert expr2.replace(x, x+1, simultaneous=False) == x+1+x\n    assert expr2.replace(x, x+1, map=True) == {(x): (x+1)}\n    assert expr2.replace(lambda arg: arg.is_Add, lambda arg: arg.args[0]**2) == (x+1)**2\n", "def test_replace():\n    from sympy import sin, cos, tan\n    from sympy.abc import x, y\n    from sympy import symbols, Wild\n    a, b = symbols('a b')\n\n    expr = (x + y)**(x + y)\n    expr = expr.replace(sin(x), tan(x))\n    assert expr == log(tan(x)) + tan(tan(x**2))\n    assert expr.has(tan)\n\n    expr = (x + y)**(x + y)\n    expr = expr.replace(sin(a), tan(a))\n    assert expr == log(tan(a)) + tan(tan(a**2))\n    assert expr.has(tan)\n\n    expr = 2*(x + y)\n    expr = expr.replace(sin(x) + y, y)\n    assert expr == 2*y\n\n    expr = (x + y)**(x + y)\n    expr = expr.replace(sin(a) + y, y)\n    assert expr == (x + y)**(x + y)\n\n    expr = (x + y)**(x + y)\n    expr = expr.replace(sin(a), y)\n    assert expr == (y + y)**(y + y)\n\n    expr = (x + y)**(x + y)\n    expr = expr.replace(sin(a), lambda a: a + y)\n    assert expr == (x + y + y)**(x + y)\n\n    expr = (x + y)**(x + y)\n    expr = expr.replace(lambda x: x.is_Pow and x.exp.is_Add and x.exp.args[0] == 1,\n                      lambda x: x.base**(1 - (x.exp - 1)))\n    assert expr == (y + y)**(1 - (x + y))\n\n    # Test with no arguments\n    expr = (x + y)**(x + y)\n    expr = expr.replace()\n    assert expr == (x + y)**(x + y)\n\n    # Test with type -> type\n    expr = (x + y)**(x + y)\n    expr = expr.replace(x + y, 2)\n    assert expr == 2**2\n", "def test_sort_key():\n    from sympy import sin, cos, exp, exp_polar, I, S, pi, symbols\n    from sympy.abc import x, y, z\n    x, y, z = symbols('x y z')\n    assert Basic(S(5).as_content_primitive(radical=True)[1]).sort_key() == (2, (3, S(5)), S.One.sort_key(), S.One)\n    assert Basic(S(1).as_content_primitive(radical=True)[1]).sort_key() == (2, (3, S(1)), S.One.sort_key(), S.One)\n    assert Basic(S(2).as_content_primitive(radical=True)[1]).sort_key() == (2, (3, S(2)), S.One.sort_key(), S.One)\n    assert Basic(S(25).as_content_primitive(radical=True)[1]).sort_key() == (2, (3, S(5)), S.One.sort_key(), S.One)\n    assert Basic(S(1/25).as_content_primitive(radical=True)[1]).sort_key() == (2, (3, S(1)/S(5)), S.One.sort_key(), S.One)\n    assert Basic(S(2/5).as_content_primitive(radical=True)[1]).sort_key() == (2, (3, S(2)/S(5)), S.One.sort_key(), S.One)\n    assert Basic(S(1/25).as_content_primitive(radical=True, clear=False)[1]).sort_key() == (2, (S(1), S(5)), S.One.sort_key(), S.One)\n\n    assert exp(I*pi).sort_key() == (2, (1, exp(I*pi)), S.One.sort_key(), S.One)\n    assert exp(I*pi).sort_key(order=1) == (2, (1, exp(I*pi)), S.One.sort_key(order=1), S.One)\n    assert (exp(I*pi).sort_key(order=1) == (2, (1, exp(I*pi)), S.One.sort_key(order=1), S.One))\n    assert sin(x).sort_key() == (3, (1, sin(x)), S.One.sort_key(), S.One)\n    assert sin(x).sort_key(order=1) == (3, (1, sin(x)), S.One.sort_key(order=1), S.One)\n    assert cos(x).sort_key() == (3, (1,"], "sample_159": ["def test_latex_repr():\n    assert kilo._latex(None) == r'\\text{k}'\n    assert kibi._latex(None) == r'\\text{Y}'\n    assert kibi._latex_repr == r\"\\mathrm{Y}\"\n\n    k = Prefix('kilo_latex', 'k', 3, base=10, latex_repr=r'\\mathcal{K}')\n    assert k._latex(None) == r'\\mathcal{K}'\n", "def test_prefix_latex_repr():\n    m = PREFIXES['m']\n    assert m._latex(None) == r'\\text{milli}'\n    k = PREFIXES['k']\n    assert k._latex(None) == r'\\text{kilo}'\n\n    y = PREFIXES['Y']\n    assert y._latex(None) == r'\\text{yotta}'\n\n    kibi = BIN_PREFIXES['Ki']\n    assert kibi._latex(None) == r'\\mu'\n\n    assert kibi._latex_repr is not None\n\n    assert y._latex(None) == r'\\text{yotta}'\n", "def test_latex_repr():\n    y = PREFIXES['y']\n    z = PREFIXES['z']\n    y_octo = PREFIXES['y']\n    assert y._latex_repr is None\n    assert y._latex_repr == r'\\text{yocto}'\n    assert z._latex_repr == r'\\text{zepto}'\n    y._latex_repr = 'some latex repr'\n    assert y._latex_repr == 'some latex repr'\n    assert z._latex_repr is None\n    y._latex_repr = None\n    assert y._latex_repr is None\n", "def test_prefix_latex():\n    m = PREFIXES['m']\n    k = PREFIXES['k']\n    M = PREFIXES['M']\n    micro = PREFIXES['mu']\n\n    # Test latex representation\n    assert m._latex(None) == r'\\text{m}'\n    assert k._latex(None) == r'\\text{k}'\n    assert M._latex(None) == r'\\text{M}'\n    assert micro._latex(None) == r'\\mu'\n\n    # Test latex representation with custom latex_repr\n    assert micro._latex(None) == r'\\mu'\n    # We don't have any prefix with custom latex_repr other than micro\n\n    # Test latex representation with sympy printer\n    from sympy import latex\n    assert latex(m) == r'\\text{m}'\n    assert latex(k) == r'\\text{k}'\n    assert latex(M) == r'\\text{M}'\n    assert latex(micro) == r'\\mu'\n\n    # Test latex representation with custom latex_repr and sympy printer\n    assert latex(micro) == r'\\mu'\n", "def test_prefix_division():\n    m = PREFIXES['m']\n    k = PREFIXES['k']\n    M = PREFIXES['M']\n\n    # test division with another prefix\n    assert m / k == S(1000)\n\n    # test division with a unit\n    assert m / meter == meter / (m.scale_factor)\n\n    # test division with a non-Prefix object\n    assert m / S(3) == S(3) / m\n\n    # test division with a non-Quantity, non-Prefix object\n    assert m / S.One == S.One / m\n\n    # test division with a Prefix object with different base\n    assert kibi / k == S(1024)\n\n    # test division with a Prefix object and a unit\n    assert kibi / meter == meter / (kibi.scale_factor)\n\n    # test division with a Prefix object and a non-Prefix object\n    assert kibi / S(3) == S(3) / kibi\n\n    # test division with a Prefix object and a non-Quantity, non-Prefix object\n    assert kibi / S.One == S.One / kibi\n\n    # test division with a Prefix object and another Prefix object\n    assert kibi / k == S(1024)\n"], "sample_30": ["    def setUpTestData(cls):\n        cls.user = User.objects.create_user('testing', password='password', is_staff=True)\n        cls.user.user_permissions.add(\n            Permission.objects.get(codename='view_poll', content_type=ContentType.objects.get_for_model(Poll))\n        )\n        cls.user.user_permissions.add(\n            *Permission.objects.filter(\n                codename__endswith=\"question\", content_type=ContentType.objects.get_for_model(Question)\n            ).values_list('pk', flat=True)\n        )\n\n        cls.poll = Poll.objects.create(name=\"Survey\")\n        cls.add_url = reverse('admin:admin_inlines_poll_add')\n        cls.change_url = reverse('admin:admin_inlines_poll_change', args=(cls.poll.id,))\n", "    def setUpTestData(cls):\n        cls.user = User.objects.create_user('testing', password='password', is_staff=True)\n        cls.user.user_permissions.add(\n            Permission.objects.get(codename='change_holder', content_type=ContentType.objects.get_for_model(Holder))\n        )\n        cls.holder = Holder.objects.create(dummy=13)\n        cls.inner = Inner.objects.create(dummy=42, holder=cls.holder)\n", "    def setUp(self):\n        self.client.force_login(self.superuser)\n", "    def setUpTestData(cls):\n        cls.user = User.objects.create_user('testing', password='password', is_staff=True)\n        cls.user.user_permissions.add(\n            Permission.objects.get(codename='view_holder2', content_type=ContentType.objects.get_for_model(Holder2))\n        )\n        cls.user.user_permissions.add(\n            Permission.objects.get(codename='change_holder2', content_type=ContentType.objects.get_for_model(Holder2))\n        )\n\n        cls.holder = Holder2.objects.create(dummy=13)\n        cls.inner2 = Inner2.objects.create(dummy=42, holder=cls.holder)\n", "    def test_fieldset_validates(self):\n        \"\"\"\n        fieldsets should be validated.\n        \"\"\"\n        response = self.client.get(reverse('admin:admin_inlines_profilecollection_add'))\n        self.assertContains(response, '<fieldset class=\"module inline-related\">Profile</fieldset>', html=True)\n        response = self.client.post(\n            reverse('admin:admin_inlines_profilecollection_add'),\n            {'profile_set-TOTAL_FORMS': 1,\n             'profile_set-INITIAL_FORMS': 0,\n             'profile_set-MAX_NUM_FORMS': 0,\n             '_save': 'Save',\n             'profile_set-0-first_name': 'john',\n             'profile_set-0-last_name': 'dow',\n             'profile_set-0-profile_set-INITIAL_FORMS': 0,\n             'profile_set-0-profile_set-MAX_NUM_FORMS': 0,\n             'profile_set-0-profile_set-TOTAL_FORMS': 0},\n        )\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, 'Error: Please correct the errors below.')\n        self.assertContains(\n            response,\n            '<tr class=\"row-form-errors\">'\n            '<td class=\"conjugated-label\">First name:</td>'\n            '<td class=\"conjugated-data\"><ul class=\"errorlist nonfield\">'\n            '<li>First name must be at least 10 characters.</li></ul></td></tr>',\n            html=True\n        )\n        self.assertContains(\n            response,\n            '<tr class=\"row-form-errors\">'\n            '<td class=\"conjugated-label\">Last name:</td>'\n            '<td class=\"conjugated-data\"><ul class=\"errorlist nonfield\">'\n            '<li>Last name must be at least 10 characters.</li></ul></td></tr>',\n            html=True\n        )\n        self.assertContains(response, 'Profile collection first name:', html=True)\n        self.assertContains(response, 'Profile collection last name:', html=True)\n        self.assertContains(response, 'Fieldsets validation error', html=True)\n"], "sample_154": ["def test_cupy_sparse_matrix():\n    if not cupy:\n        skip(\"CuPy not installed.\")\n    if not scipy:\n        skip(\"scipy not installed.\")\n    A = SparseMatrix([[x, 0], [0, y]])\n    f = lambdify((x, y), A, modules=\"cupy\")\n    B = f(1, 2)\n    assert isinstance(B, cupy.sparse.coo_matrix)\n", "def test_tensorflow_array_like():\n    # Test for issue 14655 (tensorflow part)\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n\n    f = lambdify([[x, y]], x*x + y, 'tensorflow')\n\n    with tensorflow.compat.v1.Session() as s:\n        fcall = f(tensorflow.constant([2.0, 1.0]))\n        assert fcall.eval(session=s) == 5.0\n", "def test_lambdify_MatMul():\n    if not numpy:\n        skip(\"numpy not installed\")\n    A = Matrix([[x, y], [z, 1+z]])\n    B = Matrix([[x**2], [Abs(x)]])\n    mat_func = lambdify((x, y, z), A*B, modules=\"numpy\")\n    numpy.testing.assert_array_equal(mat_func(0.5, 3, 4), numpy.array([[1.625, 4.5], [4.5, 3.5]]))\n    numpy.testing.assert_array_equal(mat_func(-0.5, 3, 4), numpy.array([[1.375, 4.5], [4.5, 3.5]]))\n", "def test_scipy_zeros():\n    if not scipy:\n        skip(\"scipy not installed\")\n    x, y = symbols('x y')\n    f = lambdify((x, y), scipy.special.zeta(x, y), modules='scipy')\n    assert abs(f(1, 2) - scipy.special.zeta(1, 2)) <= 1e-10\n", "def test_lambdastr():\n    # Test the function lambdastr, specifically check that it correctly\n    # converts symbolic expressions to string and that the function\n    # signature is correctly generated.\n    x, y = symbols('x y')\n    f = lambdify(x, x + y)\n    assert lambdastr(x, x + y) == \"lambda x: (x + y)\"\n    assert lambdastr((x, y), x + y) == \"lambda x,y: (x + y)\"\n    assert f(x) == x + y\n\n    # test issue #11736\n    f = lambdify(x, x + y)\n    assert eval(lambdastr(x, x + y)) == x + y\n    assert eval(lambdastr(x, x + y, dummify=True)) == x + y\n\n    # test issue #11862\n    from sympy.abc import z\n    f = lambdify((x, y, z), z + y)\n    assert eval(lambdastr((x, y, z), z + y)) == z + y\n\n    # test issue #12586\n    f = lambdify(x, (x + 1, x + 2))\n    assert eval(lambdastr(x, (x + 1, x + 2))) == (x + 1, x + 2)\n    f = lambdify(x, {x + 1: x + 2})\n    assert eval(lambdastr(x, {x + 1: x + 2})) == {x + 1: x + 2}\n\n    # test issue #12840\n    f = lambdify(x, sin(x))\n    assert str(eval(lambdastr(x, sin(x)))) == \"sin(x)\"\n"], "sample_18": ["    def test_limit_choices_to_warning(self):\n        class Fan(models.Model):\n            pass\n\n        class Event(models.Model):\n            invitees = models.ManyToManyField(\n                Fan,\n                through='Invitation',\n                through_fields=('invitee', 'event'),\n                limit_choices_to={'name__startswith': 'J'},\n            )\n\n        class Invitation(models.Model):\n            event = models.ForeignKey(Event, models.CASCADE)\n            invitee = models.ForeignKey(Fan, models.CASCADE)\n            inviter = models.ForeignKey(Fan, models.CASCADE, related_name='+')\n\n        field = Event._meta.get_field('invitees')\n        self.assertEqual(field.check(from_model=Event), [\n            Warning(\n                'limit_choices_to has no effect on ManyToManyField with a through model.',\n                obj=field,\n                id='fields.W343',\n            ),\n        ])\n", "    def test_swapped_model(self):\n        class SwappableModel(models.Model):\n            class Meta:\n                swappable = 'TEST_SWAPPED_MODEL'\n\n        class Model(models.Model):\n            foreign_key = models.ForeignKey(SwappableModel, models.CASCADE)\n\n        self.assertEqual(Model.check(), [])\n", "    def test_m2m_table_name_conflicts(self):\n        class Fan(models.Model):\n            pass\n\n        class Event(models.Model):\n            invitees = models.ManyToManyField(Fan, through='Invitation', db_table='my_event_invitees')\n\n        class Invitation(models.Model):\n            event = models.ForeignKey(Event, models.CASCADE)\n            invitee = models.ForeignKey(Fan, models.CASCADE)\n\n        field = Event._meta.get_field('invitees')\n        self.assertEqual(field.check(from_model=Event), [\n            Error(\n                \"The field's intermediary table 'my_event_invitees' clashes with the table name of 'invalid_models_tests.Invitation'.\",\n                hint=(\n                    'You have configured settings.DATABASE_ROUTERS. Verify that the table of ' +\n                    \"'invalid_models_tests.Invitation' is correctly routed to a separate database.\"\n                ),\n                obj=field,\n                id='fields.E340',\n            ),\n        ])\n", "    def test_valid_model(self):\n        class Parent(models.Model):\n            pass\n\n        class Model(models.Model):\n            m2m = models.ManyToManyField('self', related_name='+')\n\n        self.assertEqual(Model.check(), [])\n", "    def test_m2m_field_argument_validation(self):\n        \"\"\"\n        ManyToManyField accepts the ``through`` kwarg only if it's a string\n        or an instance of a model class.\n        \"\"\"\n        class Fan(models.Model):\n            pass\n\n        class Event(models.Model):\n            invitees = models.ManyToManyField(Fan, through=\"Invitation\")\n\n        class Invitation(models.Model):\n            event = models.ForeignKey(Event, models.CASCADE)\n            invitee = models.ForeignKey(Fan, models.CASCADE)\n            inviter = models.ForeignKey(Fan, models.CASCADE, related_name='+')\n\n        class InvalidThrough(models.Model):\n            pass\n\n        with self.assertRaisesMessage(TypeError, 'through must be a string or a model class'):\n            models.ManyToManyField(Fan, through=InvalidThrough)\n\n        field = Event._meta.get_field('invitees')\n        self.assertEqual(field.check(from_model=Event), [])\n\n        with self.assertRaisesMessage(ValueError, 'Cannot specify a db_table if an intermediary model is used'):\n            models.ManyToManyField(Fan, through=\"Invitation\", db_table=\"not_through\")\n"], "sample_58": ["def test_empty_options(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env({\"NAME\": \"dbname\"}),\n        ([\"psql\", \"dbname\"], None),\n    )\n", "def test_default_database(self):\n    \"\"\"\n    Test that the default database 'postgres' is used when neither 'NAME' nor 'service' is specified.\n    \"\"\"\n    self.assertEqual(\n        self.settings_to_cmd_args_env({\"OPTIONS\": {\"service\": None}, \"USER\": \"someuser\", \"HOST\": \"somehost\", \"PORT\": \"444\"}),\n        ([\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"postgres\"], None),\n    )\n    self.assertEqual(\n        self.settings_to_cmd_args_env({\"NAME\": None, \"USER\": \"someuser\", \"HOST\": \"somehost\", \"PORT\": \"444\"}),\n        ([\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"postgres\"], None),\n    )\n", "def test_no_host(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env(\n            {\n                \"NAME\": \"dbname\",\n                \"USER\": \"someuser\",\n                \"PASSWORD\": \"somepassword\",\n                \"PORT\": \"444\",\n            }\n        ),\n        (\n            [\"psql\", \"-U\", \"someuser\", \"-p\", \"444\", \"dbname\"],\n            {\"PGPASSWORD\": \"somepassword\"},\n        ),\n    )\n", "def test_empty_settings(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env({\"OPTIONS\": {\"passfile\": \"~/.custompgpass\"}}),\n        ([\"psql\"], {\"PGPASSFILE\": \"~/.custompgpass\"}),\n    )\n", "    def test_ssl_mode(self):\n        self.assertEqual(\n            DatabaseClient.settings_to_cmd_args_env(\n                {\n                    \"NAME\": \"dbname\",\n                    \"USER\": \"someuser\",\n                    \"HOST\": \"somehost\",\n                    \"PORT\": \"444\",\n                    \"OPTIONS\": {\n                        \"sslmode\": \"disable\",\n                    },\n                }\n            ),\n            (\n                [\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"dbname\"],\n                {\"PGSSLMODE\": \"disable\"},\n            ),\n        )\n"], "sample_73": ["def test_anchoredoffsetbox_loc_codes_invalidate_bbox_transform():\n    # Check that invalid string location codes raise a ValueError\n    codes = {'upper right': 1,\n             'upper left': 2,\n             'lower left': 3,\n             'lower right': 4,\n             'right': 5,\n             'center left': 6,\n             'center right': 7,\n             'lower center': 8,\n             'upper center': 9,\n             'center': 10,\n             }\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100)\n    for code in codes:\n        with pytest.raises(ValueError):\n            anchored_box = AnchoredOffsetbox(loc=code, child=da, bbox_transform=ax.transAxes)\n            ax.add_artist(anchored_box)\n", "def test_offsetbox_stale_false():\n    # Ensure OffsetBox stale flag is updated correctly\n    fig, ax = plt.subplots()\n    offsetbox = OffsetBox()\n    offsetbox.stale = False\n    renderer = fig.canvas.get_renderer()\n    offsetbox.draw(renderer)\n    assert not offsetbox.stale\n    offsetbox.set_offset((1, 1))\n    offsetbox.draw(renderer)\n    assert offsetbox.stale\n", "def test_drawingarea_get_bbox(align):\n    # set the DPI to match points to make the math easier below\n    fig = plt.figure(dpi=72)\n    renderer = fig.canvas.get_renderer()\n\n    da = DrawingArea(100, 100, clip=True)\n\n    if align in (\"baseline\", \"left\", \"bottom\"):\n        y_height = 0\n    elif align in (\"right\", \"top\"):\n        y_height = 100\n    elif align == \"center\":\n        y_height = 50\n\n    if align in (\"baseline\", \"left\", \"bottom\"):\n        x_height = 0\n    elif align in (\"right\", \"top\"):\n        x_height = 100\n    elif align == \"center\":\n        x_height = 50\n\n    da._offset = (x_height, y_height)\n    assert_allclose(da.get_bbox(renderer).bounds, (0, 0, 100, 100))\n\n    da.clip_children = False\n    assert not da.clip_children\n\n    da.clip_children = True\n    assert da.clip_children\n", "def test_offsetbox_get_extent():\n    # Check that get_extent returns the same values as get_bbox\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100, 0, 0, clip=True)\n    ab = AnchoredOffsetbox('center', child=da)\n    ax.add_artist(ab)\n    fig.canvas.draw()\n    renderer = fig.canvas.get_renderer()\n\n    bbox = ab.get_bbox(renderer)\n    w, h, x, y = ab.get_extent(renderer)\n    assert_allclose(bbox.bounds, (x, y, w, h))\n", "def test_aux_transform_box():\n    fig, ax = plt.subplots()\n\n        return mpatches.Rectangle((0, 0), 1, 1, facecolor=color, edgecolor='none')\n\n    square1 = make_square(ax, 'red')\n    square2 = make_square(ax, 'blue')\n    square3 = make_square(ax, 'green')\n\n    aux_transform = mtransforms.Affine2D().scale(2).translate(1, 1)\n    box = AuxTransformBox(aux_transform)\n    box.add_artist(square1)\n    box.add_artist(square2)\n    box.add_artist(square3)\n\n    ax.add_artist(box)\n\n    fig.canvas.draw()\n    renderer = fig.canvas.get_renderer()\n\n    # Test that the children are drawn correctly\n    for child in box.get_children():\n        assert child.get_window_extent(renderer).p0 == (0, 0)\n\n    # Test that the box extent is correctly calculated\n    bbox = box.get_bbox(renderer)\n    assert_allclose(bbox.bounds, (0, 0, 2, 2))\n"], "sample_121": ["def test_not_implemented():\n    # test the next_lex method to ensure it raises NotImplementedError\n    p = Permutation([[0, 1], [2, 3]])\n    raises(NotImplementedError, lambda: p.next_lex())\n    # test the next_nonlex method to ensure it raises NotImplementedError\n    raises(NotImplementedError, lambda: p.next_nonlex())\n    # test the unrank_lex method to ensure it raises NotImplementedError\n    raises(NotImplementedError, lambda: p.unrank_lex(4, 15))\n    # test the unrank_nonlex method to ensure it raises NotImplementedError\n    raises(NotImplementedError, lambda: p.unrank_nonlex(4, 15))\n    # test the rank_nonlex method to ensure it raises NotImplementedError\n    raises(NotImplementedError, lambda: p.rank_nonlex())\n    # test the rank_trotterjohnson method to ensure it raises NotImplementedError\n    raises(NotImplementedError, lambda: p.rank_trotterjohnson())\n    # test the unrank_trotterjohnson method to ensure it raises NotImplementedError\n    raises(NotImplementedError, lambda: p.unrank_trotterjohnson(4, 15))\n    # test the next_trotterjohnson method to ensure it raises NotImplementedError\n    raises(NotImplementedError, lambda: p.next_trotterjohnson())\n", "def test_from_inversion_vector():\n    p = Permutation([1, 0, 2, 3, 4])\n    inv = p.inversion_vector()\n    q = Permutation.from_inversion_vector(inv)\n    assert list(q) == [1, 0, 2, 3, 4]\n    p = Permutation([1, 2, 0, 3, 4])\n    inv = p.inversion_vector()\n    q = Permutation.from_inversion_vector(inv)\n    assert list(q) == [1, 2, 0, 3, 4]\n    raises(ValueError, lambda: Permutation.from_inversion_vector([1, 1]))\n    raises(ValueError, lambda: Permutation.from_inversion_vector([1, 2, 0, 0]))\n    p = Permutation([0, 1, 2])\n    inv = p.inversion_vector()\n    q = Permutation.from_inversion_vector(inv)\n    assert list(q) == [0, 1, 2]\n    assert Permutation([0, 2, 1]).inversion_vector() == [1, 0]\n    assert Permutation([0, 1, 2]).inversion_vector() == [0]\n", "def test_transpositions():\n    p = Permutation([1, 2, 3])\n    assert p.transpositions() == [(1, 2)]\n    p = Permutation([3, 2, 1])\n    assert p.transpositions() == [(0, 1), (0, 2), (1, 2)]\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    assert p.transpositions() == [(0, 5), (0, 4), (0, 3), (0, 2), (0, 1)]\n    p = Permutation([0, 3, 1, 2, 4])\n    assert p.transpositions() == [(0, 4), (0, 3), (0, 2), (0, 1)]\n    p = Permutation([4, 3, 0, 1, 2])\n    assert p.transpositions() == [(0, 1), (0, 2), (0, 3), (0, 4)]\n    p = Permutation([0, 1, 2])\n    assert p.transpositions() == [(0, 1), (0, 2), (1, 2)]\n    p = Permutation([0, 1, 2, 3, 4, 5, 6, 7])\n    assert p.transpositions() == [(0, 7), (0, 6), (0, 5), (0, 4), (0, 3), (0, 2), (0, 1)]\n    p = Permutation([[0, 3, 2, 1], [5, 4]])\n    assert p.transpositions() == [(0, 3), (0, 2), (0, 1), (1, 3), (1, 2)]\n    p = Permutation([[0, 1, 2], [3, 4]])\n    assert p.transpositions() == [(0, 1), (0, 2), (1, 2)]\n    p = Permutation([[0, 2, 1], [3, 4]])\n    assert p.transpositions() == [(0, 1), (0, 2), (1, 2)]\n    p = Permutation([[0, ", "def test_signature():\n    # check all cycles have a positive signature\n    p = Permutation(3)\n    assert p.signature() == 1\n    p = Permutation(0, 2, 1)\n    assert p.signature() == -1\n\n    # check all cycles can have a signature of 1\n    p = Permutation([[3, 4], [0, 2, 1, 5]])\n    assert p.signature() == 1\n    # check all cycles can have a signature of -1\n    p = Permutation([[1, 4], [0, 2, 5, 3]])\n    assert p.signature() == -1\n\n    # check the signature of the identity permutation\n    p = Permutation()\n    assert p.signature() == 1\n\n    # check the signature of a permutation that is its own inverse\n    p = Permutation([0, 3, 2, 1])\n    assert p.signature() == 1\n    p = Permutation([0, 1, 2, 3])\n    assert p.signature() == 1\n\n    # check the signature of a permutation that is not its own inverse\n    p = Permutation([3, 2, 1, 0])\n    assert p.signature() == -1\n    p = Permutation([0, 3, 2, 1])\n    assert p.signature() == 1\n", "def test_from_inversion_vector():\n    # test that inversion_vector produces a valid permutation\n    for length in range(1, 10):\n        p = Permutation.unrank_lex(length, 0)\n        assert Permutation.from_inversion_vector(p.inversion_vector()).array_form == list(range(length))\n    # test that inversion_vector produces the correct permutation\n    for length in range(1, 10):\n        for i in range(length):\n            perm = list(range(length))\n            inv = perm[i]\n            perm[i] = perm[length - 1]\n            perm[length - 1] = inv\n            p = Permutation.from_inversion_vector([i, *(range(length - 1))])\n            assert p.array_form == perm\n    # test that inversion_vector raises an error for invalid input\n    for length in range(1, 10):\n        raises(ValueError, lambda: Permutation.from_inversion_vector([1] + [0]*length))\n    # test that inversion_vector produces the correct result for small inputs\n    assert Permutation.from_inversion_vector([2, 1, 0]) == Permutation([2, 1, 0])\n    assert Permutation.from_inversion_vector([3, 1, 0]) == Permutation([3, 0, 1, 2])\n    assert Permutation.from_inversion_vector([0, 1, 2]) == Permutation([0, 2, 1])\n"], "sample_158": ["def test_dimensionless():\n    from sympy.physics.units import Quantity\n\n    q1 = Quantity('q1')\n    q2 = Quantity('q2')\n\n    SI.set_quantity_dimension(q1, time)\n    q1.set_global_relative_scale_factor(1, second)\n\n    SI.set_quantity_dimension(q2, energy/time)\n    q2.set_global_relative_scale_factor(1, joule/second)\n\n    assert q1 ** q2 == q1 ** (q2.convert_to(time))\n    assert q1 / q2 == q1 / q2.convert_to(time)\n", "def test_dimensionless_unit():\n    from sympy.core.numbers import S, oo\n\n    u = Quantity('u')\n    SI.set_quantity_dimension(u, energy)\n\n    assert u.scale_factor == 1\n    assert u.is_dimensionless\n    assert u.is_dimension\n    assert u.is_physical_constant\n\n    v = Quantity('v')\n    v.set_global_relative_scale_factor(S(1), u)\n\n    assert v.scale_factor == 1\n    assert v.is_dimensionless\n    assert v.is_dimension\n    assert v.is_physical_constant\n\n    v.set_global_relative_scale_factor(oo, u)\n\n    assert v.scale_factor == oo\n    assert v.is_dimensionless\n    assert v.is_dimension\n    assert v.is_physical_constant\n\n    u.set_global_relative_scale_factor(2, u)\n\n    assert u.scale_factor == 2\n    assert u.is_dimensionless\n    assert u.is_dimension\n    assert u.is_physical_constant\n", "def test_issue_25000():\n    \"\"\"\n    Test that the get_dimensional_expr method handles a complex expression involving\n    the exp and sin functions.\n    \"\"\"\n    v_w1 = Quantity('v_w1')\n    v_w2 = Quantity('v_w2')\n    v_w3 = Quantity('v_w3')\n\n    v_w1.set_global_relative_scale_factor(1, meter/second)\n    v_w2.set_global_relative_scale_factor(1, meter/second)\n    v_w3.set_global_relative_scale_factor(1, meter/second)\n\n    expr = sin(v_w1**2) + 2*exp(v_w2)\n\n    assert SI.get_dimensional_expr(expr) == sin(SI.get_dimensional_expr(v_w1**2)) + 2*SI.get_dimensional_expr(exp(v_w2))\n\n    expr = exp(v_w2 + v_w1)\n    assert SI.get_dimensional_expr(expr) == exp(SI.get_dimensional_expr(v_w2 + v_w1))\n\n    expr = sin(v_w1**2) + 2*exp(v_w2 + v_w1)\n    assert SI.get_dimensional_expr(expr) == sin(SI.get_dimensional_expr(v_w1**2)) + 2*SI.get_dimensional_expr(exp(v_w2 + v_w1))\n", "def test_issue_23334():\n    from sympy.physics.units import prefix, kibibyte, kilo\n    assert kibibyte.convert_to(kilo * kilo, kibibyte) == 1024 * kilo\n    assert kibibyte.convert_to(kilo, kibibyte) == kilo / 1024\n\n    kilo_kibibyte = Quantity('kilo_kibibyte')\n    kilo_kibibyte.set_global_relative_scale_factor(kilo, kibibyte)\n\n    assert kilo_kibibyte.convert_to(kilo, kibibyte) == kilo * 1024\n\n    assert kilo_kibibyte.is_prefixed\n    assert kilo_kibibyte.scale_factor == kilo\n    assert kilo_kibibyte.dimension == kibibyte\n    assert kilo_kibibyte.name == Symbol('kilo_kibibyte')\n    assert kilo_kibibyte.abbrev == Symbol('kibibytes')  # default abbreviation\n", "def test_issue_24814():\n    from sympy.physics.units import SI, meter, second\n    from sympy.core.function import diff\n    from sympy.core.numbers import oo\n    from sympy.core.singleton import S\n\n    meter.set_global_relative_scale_factor(S(1), meter)\n    expr = diff(meter, meter)\n    assert SI._collect_factor_and_dimension(expr) == (1, Dimension(0))\n    expr = diff(meter**2, meter)\n    assert SI._collect_factor_and_dimension(expr) == (2, Dimension(1))\n    expr = diff(meter**-1, meter)\n    assert SI._collect_factor_and_dimension(expr) == (0, Dimension(-1))\n    expr = diff(meter**(-1)*meter, meter)\n    assert SI._collect_factor_and_dimension(expr) == (0, Dimension(0))\n\n    # Test for issue #24814: the `Diff` object is not properly handled in\n    # `_collect_factor_and_dimension`, causing incorrect dimension and factor extraction.\n    expr = diff(1/meter, meter)\n    assert SI._collect_factor_and_dimension(expr) == (0, Dimension(-1))\n"], "sample_59": ["def test_formset_all_valid_with_non_form_errors(self):\n    \"\"\"all_valid() validates all formsets, even when some have non-form errors.\"\"\"\n    data = {\n        \"choices-TOTAL_FORMS\": \"2\",\n        \"choices-INITIAL_FORMS\": \"0\",\n        \"choices-MIN_NUM_FORMS\": \"0\",\n        \"choices-0-choice\": \"Zero\",\n        \"choices-0-votes\": \"0\",\n        \"choices-1-choice\": \"One\",\n        \"choices-1-votes\": \"1\",\n    }\n    ChoiceFormSet = formset_factory(Choice)\n    ChoiceFormsetWithNonFormError = formset_factory(Choice, formset=ChoiceFormsetWithNonFormError)\n    formset1 = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n    formset2 = ChoiceFormsetWithNonFormError(data, auto_id=False, prefix=\"choices\")\n    self.assertIs(all_valid((formset1, formset2)), False)\n    self.assertEqual(formset1._errors, [])\n    self.assertEqual(formset2._non_form_errors(), [\"non-form error\"])\n", "def test_can_order_formset_forms(self):\n    \"\"\"\n    FormSets with ordering allow forms to be ordered.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_order=True)\n    initial = [\n        {\"choice\": \"Calexico\", \"votes\": 100},\n        {\"choice\": \"Fergie\", \"votes\": 900},\n        {\"choice\": \"The Decemberists\", \"votes\": 500},\n    ]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix=\"choices\")\n    self.assertHTMLEqual(\n        \"\\n\".join(form.as_ul() for form in formset.forms),\n        '<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"choices-0-votes\" value=\"100\"></li>'\n        '<li>Order: <input type=\"number\" name=\"choices-0-ORDER\" value=\"1\"></li>'\n        '<li>Delete: <input type=\"checkbox\" name=\"choices-0-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"choices-1-choice\" value=\"Fergie\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"choices-1-votes\" value=\"900\"></li>'\n        '<li>Order: <input type=\"number\" name=\"choices-1-ORDER\" value=\"2\"></li>'\n        '<li>Delete: <input type=\"checkbox\" name=\"choices-1-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"choices-2-choice\" '\n        'value=\"The Decemberists\"></li>'\n        '<li>Votes: <input type=\"number\" name=\"choices-2-votes\" value=\"500\"></li>'\n        '<li>Order: <input type=\"number\" name=\"choices-2-ORDER\" value=\"3\"></li>'\n        '<li>Delete: <input type=\"checkbox\" name=\"choices-2-DELETE\"></li>',\n    )\n    # To change the order of the items in the formset, set the order field.\n    data = {\n        \"choices-TOTAL_FORMS\": \"3\",  # the number of forms rendered\n        \"choices-INITIAL_FORMS\": \"3\",  # the number of forms with initial data\n        \"choices-M", "    def test_renderer_passed_to_form_errors(self):\n        from django.forms.renderers import Jinja2\n\n        renderer = Jinja2()\n        data = {\n            \"choices-TOTAL_FORMS\": \"2\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Zero\",\n            \"choices-0-votes\": \"\",\n            \"choices-1-choice\": \"One\",\n            \"choices-1-votes\": \"\",\n        }\n        ChoiceFormSet = formset_factory(Choice, renderer=renderer)\n        formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        self.assertEqual(formset.management_form.errors.renderer, renderer)\n        for form in formset.forms:\n            self.assertEqual(form.errors.renderer, renderer)\n        self.assertEqual(formset.non_form_errors().renderer, renderer)\n", "    def test_clean_method_called(self):\n        \"\"\"Formset's clean() method is called after form clean() methods.\"\"\"\n\n        class CustomForm(Form):\n                self.clean_called = True\n\n        CustomFormSet = formset_factory(CustomForm)\n        formset = CustomFormSet(auto_id=False)\n        self.assertFalse(formset.forms[0].clean_called)\n        formset.clean()\n        self.assertTrue(formset.forms[0].clean_called)\n        self.assertFalse(formset.forms[1].clean_called)\n", "    def test_absolute_max_invalid_form(self):\n        \"\"\"A FormSet that exceeds absolute_max is invalid.\"\"\"\n        data = {\n            \"form-TOTAL_FORMS\": \"2001\",\n            \"form-INITIAL_FORMS\": \"0\",\n            \"form-MAX_NUM_FORMS\": \"0\",\n        }\n        LimitedFavoriteDrinksFormSet = formset_factory(\n            FavoriteDrinkForm, absolute_max=2000\n        )\n        formset = LimitedFavoriteDrinksFormSet(data=data)\n        self.assertIs(formset.is_valid(), False)\n        self.assertEqual(formset.non_form_errors(), [\"Please submit at most 1000 forms.\"])\n        self.assertEqual(len(formset.forms), 2000)\n"], "sample_60": ["    def test_serialize_uuid_flag(self):\n        self.assertSerializedResultEqual(\n            uuid.UUID(\"c7853ec1-2ea3-4359-b02d-b54e8f1bcee2\") | uuid.UUID(\"5c859437-d061-4847-b3f7-e6b78852f8c8\"),\n            (\n                \"uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2') | \"\n                \"uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')\",\n                {\"import uuid\"},\n            ),\n        )\n", "def test_serializer_decimal_with_default(self):\n    \"\"\"\n    Test serialization of DecimalField with default value.\n    \"\"\"\n    field = models.DecimalField(default=decimal.Decimal(\"1.3\"))\n    string, imports = MigrationWriter.serialize(field)\n    self.assertEqual(string, \"models.DecimalField(default=Decimal('1.3'))\")\n    self.assertEqual(imports, {\"from decimal import Decimal\", \"from django.db import models\"})\n", "    def test_register_serializer_with_already_registered_type(self):\n        with self.assertRaisesMessage(\n            ValueError, \"'type' must inherit from 'BaseSerializer'.\"\n        ):\n            Serializer.register(str, str)\n\n        class NewSerializer(BaseSerializer):\n                return \"new(%r)\" % self.value, {}\n\n        with self.assertRaisesMessage(\n            ValueError, \"'NewSerializer' must inherit from 'BaseSerializer'.\"\n        ):\n            Serializer.register(int, NewSerializer)\n", "def test_serialize_class_based_manager(self):\n    class TestModel(models.Model):\n        class TestManager(models.Manager):\n                return super().get_queryset().filter(id=1)\n\n    manager = TestModel.TestManager()\n    self.assertSerializedResultEqual(manager, (\"TestModel.TestManager\", set()))\n\n    class ManagerWithArgs(models.Manager):\n            super().__init__(*args, **kwargs)\n\n    manager = ManagerWithArgs()\n    self.assertSerializedResultEqual(manager, (\"ManagerWithArgs\", set()))\n", "def test_serialize_deconstructable_instance_with_deconstruct_returning_path_with_nested_import(self):\n    class DeconstructableClass:\n            return (\"DeconstructableClass\", [\"migrations.test_writer\"], {\"path\": \"migrations.test_writer.deconstructable_nested_module\"})\n\n    instance = DeconstructableClass()\n    string, imports = MigrationWriter.serialize(instance)\n    self.assertEqual(imports, {\"import migrations.test_writer.deconstructable_nested_module\"})\n    self.assertEqual(\n        string,\n        \"migrations.test_writer.deconstructable_nested_module.DeconstructableClass\",\n    )\n"], "sample_102": ["def test_iforest_max_features():\n    \"\"\"Check max_features for various parameter settings.\"\"\"\n    X_train = np.array([[0, 1], [1, 2], [2, 1]])\n    X_test = np.array([[2, 1], [1, 1]])\n\n    grid = ParameterGrid({\"max_features\": [1.0, 2.0, 0.8]})\n\n    for params in grid:\n        IsolationForest(random_state=rng,\n                        max_samples=2,\n                        max_features=params[\"max_features\"]).fit(X_train).predict(X_test)\n", "def test_isolation_forest_errors_on_non_numeric_input():\n    \"\"\"Test that it raises an error when X contains non-numeric input.\"\"\"\n    X = [[0, 1], [1, 2], [\"a\", 2]]\n\n    assert_raises_regex(ValueError, \"Could not convert string to float:\",\n                      IsolationForest().fit, X)\n", "def test_iforest_decision_function_consistency():\n    \"\"\"Test the consistency of decision_function and predict methods.\"\"\"\n    rng = check_random_state(0)\n    X_train = [[1, 1], [1, 2], [2, 1], [1, 1], [1, 2]]\n    X_test = [[2., 2.]]\n\n    # Test with contamination parameter as 'auto'\n    clf1 = IsolationForest(contamination='auto').fit(X_train)\n    clf2 = IsolationForest(behaviour='new', contamination='auto').fit(X_train)\n    assert_array_equal(clf1.predict(X_test),\n                       clf2.predict(X_test))\n    assert_array_equal(clf1.decision_function(X_test),\n                       clf2.decision_function(X_test))\n\n    # Test with contamination parameter not as 'auto'\n    clf1 = IsolationForest(contamination=0.1).fit(X_train)\n    clf2 = IsolationForest(behaviour='new', contamination=0.1).fit(X_train)\n    assert_array_equal(clf1.predict(X_test),\n                       clf2.predict(X_test))\n    assert_array_equal(clf1.decision_function(X_test),\n                       clf2.decision_function(X_test))\n", "def test_iforest_decision_function_offset():\n    # It tests non-regression for #11316 which used the wrong offset value\n    rng = check_random_state(0)\n    X = [[1, 1], [1, 2], [2, 1]]\n    clf = IsolationForest(contamination='auto').fit(X)\n    # assuming X is normal, score should be close to 0\n    assert_array_almost_equal(clf.decision_function(X), clf.offset_)\n", "def test_contamination_param():\n    \"\"\"Test Isolation Forest with different contamination parameters.\"\"\"\n    X = [[0.0], [1.0], [6.0], [-4.0]]\n    clf1 = IsolationForest(contamination=0.25).fit(X)\n    clf2 = IsolationForest(contamination=\"auto\").fit(X)\n\n    decision_func1 = -clf1.decision_function(X)\n    decision_func2 = -clf2.decision_function(X)\n\n    # assert contamination=0.25 predicts same results as contamination=\"auto\"\n    assert_array_equal(decision_func1, decision_func2)\n\n    # test different contamination values\n    for contamination in [0.1, 0.5, 0.9]:\n        clf = IsolationForest(contamination=contamination).fit(X)\n        assert_greater(np.min(decision_func1[-2:]), np.max(decision_func1[:-2]))\n\n    # test incorrect contamination value\n    with assert_raises_regex(ValueError, \"contamination must be in\"):\n        IsolationForest(contamination=\"foo\").fit(X)\n"], "sample_109": ["def test_check_cv_allow_integers():\n    # Test that check_cv() can handle arbitrary integer inputs\n    cv = check_cv(cv=42)\n    assert cv.get_n_splits() == 42\n    np.testing.assert_equal(list(KFold(42).split(X, y)), list(cv.split(X, y)))\n", "def test_stratified_split():\n    # Check that StratifiedShuffleSplit stratifies even with a very small number\n    # of samples per class\n    y = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])\n    X = np.ones_like(y)\n\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=0)\n\n    train, test = next(sss.split(X, y))\n\n    y_train = y[train]\n    y_test = y[test]\n\n    # check the 1:1 ratio of ones and twos in the data is preserved\n    assert np.sum(y_train == 1) == np.sum(y_train == 2)\n    assert np.sum(y_test == 1) == np.sum(y_test == 2)\n\n    # check the 1:1 ratio of zeros and ones in the data is preserved\n    assert np.sum(y_train == 0) == np.sum(y_train == 1)\n    assert np.sum(y_test == 0) == np.sum(y_test == 1)\n\n    # check the 1:1 ratio of ones and twos in the data is preserved\n    assert np.sum(y_train == 0) == np.sum(y_train == 2)\n    assert np.sum(y_test == 0) == np.sum(y_test == 2)\n", "def test_check_cv_empty_parameter():\n    # Test that check_cv raises an error if the data is empty\n    assert_raise_message(ValueError, \"The 'X' parameter should not be None.\",\n                         check_cv, cv=5)\n    assert_raise_message(ValueError, \"The 'y' parameter should not be None.\",\n                         check_cv, cv=5, y=None, classifier=True)\n    # Test that check_cv raises an error if the cv parameter is empty\n    assert_raise_message(ValueError, \"Expected cv as an integer, cross-validation \"\n                         \"object (from sklearn.model_selection) \"\n                         \"or an iterable. Got 5.\",\n                         check_cv, cv=5)\n    # Test that check_cv raises an error if the cv parameter is an integer and\n    # classifier is True, but y is None\n    assert_raise_message(ValueError, \"The 'y' parameter should not be None.\",\n                         check_cv, cv=5, y=None, classifier=True)\n", "def test_kfold_get_n_splits_as_group_of_arrays():\n    # Test that kfold get_n_splits() works with arrays of arrays\n    X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n    y = np.array([[1, 1], [2, 2], [3, 3], [4, 4]])\n    groups = np.array([[0, 0], [0, 0], [1, 1], [1, 1]])\n    kf = KFold(n_splits=2)\n\n    n_splits_expected = 2\n    assert kf.get_n_splits(X, y, groups) == n_splits_expected\n\n    n_splits_expected = 2\n    assert kf.get_n_splits(groups=groups) == n_splits_expected\n", "def test_predefined_split():\n    X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n    folds = [1, 1, -1, 1, 2]\n    ps = PredefinedSplit(folds)\n    ps_repr = \"PredefinedSplit(test_fold=array([1, 1, -1, 1, 2]))\"\n    assert ps_repr == repr(ps)\n\n    # Test that the length is correct\n    assert ps.get_n_splits(X) == 2\n\n    # Test that the length is correct for a different dataset\n    assert ps.get_n_splits(X[:3]) == 2\n\n    # Test that the length is correct for a dataset with no test sets\n    assert ps.get_n_splits(X[:4]) == 2\n\n    # Test that the length is correct for a dataset with a single test set\n    assert ps.get_n_splits(X[:5]) == 2\n\n    # Test that the length is correct for a dataset with 2 test sets\n    assert ps.get_n_splits(X[:6]) == 2\n\n    # Test that the length is correct for a dataset with 3 test sets\n    assert ps.get_n_splits(X[:7]) == 2\n\n    # Test that the length is correct for a dataset with 4 test sets\n    assert ps.get_n_splits(X[:8]) == 2\n\n    # Test that the length is correct for a dataset with a single sample\n    assert ps.get_n_splits(np.array([[1, 2]])) == 2\n\n    # Test that the length is correct for a dataset with 2 samples\n    assert ps.get_n_splits(np.array([[1, 2], [3, 4]])) == 2\n\n    # Test that the length is correct for a dataset with 3 samples\n    assert ps.get_n_splits(np.array([[1, 2], [3, 4], [5, 6]])) == 2\n\n    # Test that the length is correct for a dataset with 4 samples\n    assert ps.get_n_splits(np.array([[1, 2], [3, 4], [5, 6], [7, 8]])) == 2\n\n    # Test that the length is correct for a dataset with 5 samples\n    assert ps.get_n_splits(np.array"], "sample_110": ["def test_affinity_propagation_warning():\n    # Test that the AffinityPropagation raises a UserWarning\n    # when affinity is set to a non-supported value\n    af = AffinityPropagation(affinity=\"unknown\")\n    with pytest.raises(UserWarning):\n        af.fit(X)\n", "def test_affinity_propagation_custom_affinity():\n    # Test AffinityPropagation with a custom affinity\n    af = AffinityPropagation(affinity=\"precomputed\", preference=-10)\n    # Create a precomputed affinity matrix\n    S = np.dot(X, X.T)\n    af.fit(S)\n    # Check if the cluster labels are the same as when using euclidean affinity\n    euclidean_af = AffinityPropagation(preference=-10).fit(X)\n    assert_array_equal(af.labels_, euclidean_af.labels_)\n", "def test_affinity_propagation_fit_predict_non_convergence_unequal_preferences():\n    # In case of non-convergence of affinity_propagation(), the cluster\n    # centers should be an empty array and training samples should be labelled\n    # as noise (-1)\n    X = np.array([[0, 0], [1, 1], [-2, -2]])\n\n    # Force non-convergence by allowing only a single iteration\n    af = AffinityPropagation(preference=-10, max_iter=1)\n\n    # Non-convergence happens only when affinity='precomputed' so test with it\n    S = np.dot(X, X.T)\n    af.fit(S)\n\n    # At prediction time, consider new samples as noise since there are no\n    # clusters\n    to_predict = np.array([[2, 2], [3, 3], [4, 4]])\n    y = af.predict(to_predict)\n    assert_array_equal(np.array([-1, -1, -1]), y)\n", "def test_affinity_propagation_copy_warning():\n    # Check that copy=False raises a warning and produces the same output\n    # as copy=True\n    af = AffinityPropagation(copy=False)\n    X = np.array([[1, 2], [1, 4], [1, 0],\n                  [4, 2], [4, 4], [4, 0]])\n    cluster_centers_indices, labels = af.fit(X).cluster_centers_indices_, af.fit(X).labels_\n    af = AffinityPropagation(copy=True)\n    cluster_centers_indices_copy, labels_copy = af.fit(X).cluster_centers_indices_, af.fit(X).labels_\n    assert_array_equal(cluster_centers_indices, cluster_centers_indices_copy)\n    assert_array_equal(labels, labels_copy)\n    assert_warns(UserWarning, af.fit, X, copy=False)\n", "def test_affinity_propagation_cluster_centers():\n    # Test whether the cluster centers are correctly computed\n    af = AffinityPropagation(preference=0.5, affinity=\"precomputed\")\n    S = -euclidean_distances(X, squared=True)\n    af.fit(S)\n    cluster_centers_indices = af.cluster_centers_indices_\n    cluster_centers = af.cluster_centers_\n\n    # Check if the cluster centers are correctly identified\n    labels = af.labels_\n    for i, label in enumerate(labels):\n        if label == cluster_centers_indices[0]:\n            cluster_center_indices = i\n\n    # Test if the cluster centers are correctly computed\n    assert_array_equal(cluster_centers, X[cluster_center_indices])\n"], "sample_39": ["    def test_reverse_lazy_in_settings(self):\n        # reverse_lazy can be used in settings without causing a circular\n        # import error.\n        self.assertEqual(reverse_lazy('login'), '/login/')\n", "    def test_reverse_resolution_tries_last_url_pattern(self):\n        \"\"\"\n        URLResolver should try the last URL pattern when multiple patterns have\n        the same name.\n        \"\"\"\n        resolver = get_resolver('urlpatterns_reverse.named_urls_conflict')\n        test_urls = [\n            # (name, args, kwargs, expected)\n            ('name-conflict', (), {}, 'conflict/'),\n            # With an arg, the last URL in urlpatterns has precedence.\n            ('name-conflict', ('arg',), {}, 'conflict-last/arg/'),\n            # With a kwarg, other URL patterns can be reversed.\n            ('name-conflict', (), {'first': 'arg'}, 'conflict-first/arg/'),\n            ('name-conflict', (), {'middle': 'arg'}, 'conflict-middle/arg/'),\n            ('name-conflict', (), {'last': 'arg'}, 'conflict-last/arg/'),\n            # The number and order of the arguments don't interfere with reversing.\n            ('name-conflict', ('arg', 'arg'), {}, 'conflict/arg/arg/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(resolver.reverse(name, *args, **kwargs), expected)\n", "    def test_decorator_view(self):\n        test_urls = [\n            ('decorator-view', [], {'arg1': 1, 'arg2': 2}, '/decorator/1/2/'),\n            ('decorator-view', [], {'arg1': 1}, '/decorator/1/'),\n            ('decorator-view', [], {'arg2': 2}, '/decorator//2/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n", "    def test_regex_pattern_reverse(self):\n        regex_pattern = RegexPattern(r'^$')\n        self.assertEqual(reverse(regex_pattern), '/')\n", "    def test_reverse_dict_order(self):\n        \"\"\"\n        The reverse_dict should return the matched view in the correct order.\n        \"\"\"\n        resolver = get_resolver('urlpatterns_reverse.named_urls')\n        test_urls = [\n            ('named-url2', ('arg',), {}),\n            ('named-url1', (), {}),\n            ('named-url3', (), {}),\n        ]\n        for name, args, kwargs in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                try:\n                    got = resolver.reverse(name, *args, **kwargs)\n                except NoReverseMatch:\n                    self.assertEqual(NoReverseMatch, None)\n                else:\n                    self.assertIn(name, got)\n"]}, "raw_scored_generations": {"sample_3": [false, false, false, false, false], "sample_1": [false, true, false, false, false], "sample_0": [true, true, false, false, true], "sample_2": [true, false, false, false, false], "sample_6": [false, false, false, false, true], "sample_4": [false, false, false, true, false], "sample_5": [true, false, false, false, false], "sample_7": [true, false, false, false, false], "sample_9": [false, false, false, false, false], "sample_8": [false, false, false, false, false], "sample_10": [true, true, true, true, true], "sample_11": [true, false, true, false, true], "sample_13": [true, false, false, false, false], "sample_12": [true, true, true, true, false], "sample_14": [true, false, false, true, false], "sample_15": [true, false, true, true, true], "sample_16": [false, true, true, false, false], "sample_17": [true, false, false, false, false], "sample_18": [false, true, false, true, false], "sample_19": [false, false, false, false, false], "sample_21": [true, false, false, false, false], "sample_20": [true, true, false, false, false], "sample_23": [true, true, true, true, true], "sample_22": [true, true, true, true, false], "sample_24": [false, false, true, true, true], "sample_25": [true, true, true, false, false], "sample_28": [false, false, false, false, false], "sample_26": [false, false, false, true, false], "sample_27": [true, true, true, true, true], "sample_29": [false, false, false, false, false], "sample_31": [true, true, true, true, true], "sample_30": [false, false, false, false, true], "sample_32": [true, false, false, false, false], "sample_33": [true, false, false, true, false], "sample_34": [false, false, false, false, false], "sample_35": [false, false, false, false, false], "sample_36": [true, true, true, true, true], "sample_37": [true, true, false, false, false], "sample_39": [false, true, false, false, false], "sample_38": [true, false, false, false, false], "sample_40": [true, true, false, false, false], "sample_42": [true, false, false, true, true], "sample_41": [false, true, false, false, true], "sample_43": [true, true, false, true, false], "sample_45": [false, false, false, false, false], "sample_44": [false, false, false, true, true], "sample_46": [false, false, false, true, true], "sample_48": [true, false, true, false, false], "sample_47": [false, true, false, true, false], "sample_50": [true, true, true, true, false], "sample_49": [true, true, true, false, true], "sample_51": [true, true, false, true, true], "sample_52": [false, true, false, false, false], "sample_53": [true, true, true, true, true], "sample_55": [true, true, true, false, false], "sample_54": [true, true, false, true, true], "sample_56": [false, false, false, false, false], "sample_58": [true, true, true, true, false], "sample_57": [true, true, true, false, false], "sample_60": [false, true, false, false, false], "sample_59": [true, false, false, false, true], "sample_61": [true, true, false, true, true], "sample_63": [false, false, false, true, false], "sample_62": [false, false, false, false, false], "sample_64": [false, false, false, false, false], "sample_66": [true, false, false, false, false], "sample_65": [false, false, false, false, false], "sample_68": [true, true, false, true, false], "sample_67": [true, true, true, false, true], "sample_69": [false, false, false, false, false], "sample_70": [true, false, true, true, false], "sample_71": [true, true, false, true, false], "sample_72": [false, false, false, false, false], "sample_73": [false, false, false, false, false], "sample_74": [false, false, false, false, false], "sample_75": [false, false, false, false, false], "sample_76": [false, false, false, false, false], "sample_77": [false, false, false, false, false], "sample_78": [false, false, false, false, false], "sample_79": [false, false, false, false, false], "sample_80": [false, false, false, false, false], "sample_82": [false, false, false, false, false], "sample_81": [false, false, false, false, false], "sample_83": [false, false, false, false, false], "sample_84": [true, false, true, true, true], "sample_85": [false, false, false, false, false], "sample_86": [false, false, false, false, false], "sample_87": [true, true, true, false, true], "sample_88": [false, false, false, false, false], "sample_89": [false, false, false, false, false], "sample_90": [false, false, true, false, false], "sample_91": [false, false, true, true, true], "sample_92": [true, true, false, true, true], "sample_93": [true, true, false, true, true], "sample_95": [true, false, true, true, true], "sample_94": [false, false, false, false, false], "sample_96": [true, false, false, true, false], "sample_97": [true, false, false, false, true], "sample_98": [false, false, true, false, false], "sample_99": [false, false, false, false, false], "sample_100": [false, false, false, false, false], "sample_101": [true, false, false, false, false], "sample_102": [false, false, false, false, false], "sample_103": [false, false, false, false, false], "sample_104": [false, false, false, false, false], "sample_105": [true, false, false, false, false], "sample_107": [false, false, false, false, false], "sample_106": [false, false, false, false, false], "sample_108": [true, true, false, false, false], "sample_109": [false, true, false, true, false], "sample_110": [false, false, true, false, false], "sample_111": [false, false, false, false, false], "sample_112": [false, true, true, false, false], "sample_113": [false, false, false, false, false], "sample_114": [true, false, false, false, false], "sample_115": [false, true, false, false, false], "sample_116": [false, false, false, false, false], "sample_117": [false, true, false, false, false], "sample_118": [false, false, false, false, false], "sample_119": [false, false, false, false, false], "sample_120": [false, false, false, false, false], "sample_121": [false, false, false, false, false], "sample_122": [true, true, false, false, false], "sample_123": [false, false, false, false, false], "sample_124": [false, false, false, false, false], "sample_125": [true, true, true, false, false], "sample_126": [true, false, false, false, false], "sample_127": [false, false, false, false, false], "sample_128": [true, false, false, false, false], "sample_129": [false, true, false, false, false], "sample_130": [true, false, true, true, false], "sample_131": [false, false, false, false, false], "sample_132": [false, false, false, false, false], "sample_133": [false, false, false, false, false], "sample_134": [true, true, true, false, false], "sample_135": [false, false, false, false, false], "sample_136": [false, false, false, true, false], "sample_137": [false, false, false, false, false], "sample_138": [false, false, false, false, false], "sample_139": [false, false, false, false, false], "sample_140": [false, false, false, false, false], "sample_142": [false, false, false, false, false], "sample_141": [false, false, false, false, false], "sample_143": [false, false, false, false, false], "sample_144": [false, false, false, false, false], "sample_145": [false, false, false, false, false], "sample_146": [true, false, true, false, false], "sample_147": [false, false, false, false, true], "sample_148": [false, false, false, false, false], "sample_149": [false, false, false, false, false], "sample_150": [false, false, false, false, false], "sample_151": [false, false, false, false, false], "sample_152": [false, false, false, false, false], "sample_153": [false, false, false, false, false], "sample_154": [true, true, true, true, false], "sample_155": [false, false, false, false, false], "sample_156": [false, false, false, false, false], "sample_157": [false, false, false, true, false], "sample_158": [true, false, false, false, false], "sample_159": [false, false, false, true, false]}}