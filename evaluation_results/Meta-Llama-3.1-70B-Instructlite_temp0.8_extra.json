{"raw_generations": {"sample_33": ["def test_connect_and_disconnect_with_sender(self):\n    receiver_1 = Callable()\n    receiver_2 = Callable()\n    a_signal.connect(receiver_1, sender=self)\n    a_signal.connect(receiver_2, sender=self)\n    result = a_signal.send(sender=self, val=\"test\")\n    self.assertEqual(len(result), 2)\n    self.assertEqual(len(a_signal.receivers), 2)\n    a_signal.disconnect(receiver_1, sender=self)\n    result = a_signal.send(sender=self, val=\"test\")\n    self.assertEqual(len(result), 1)\n    self.assertEqual(len(a_signal.receivers), 1)\n    a_signal.disconnect(receiver_2, sender=self)\n    result = a_signal.send(sender=self, val=\"test\")\n    self.assertEqual(len(result), 0)\n    self.assertEqual(len(a_signal.receivers), 0)\n    self.assertTestIsClean(a_signal)\n", "def test_receiver_decorator_with_kwargs(self):\n    @receiver(a_signal, sender=self)\n        self.state = val\n    self.state = False\n    a_signal.send(sender=self, val=True)\n    self.assertTrue(self.state)\n\n    @receiver([a_signal, b_signal], sender=self)\n        self.state.append(val)\n    self.state = []\n    a_signal.send(sender=self, val='a')\n    b_signal.send(sender=self, val='b')\n    self.assertIn('a', self.state)\n    self.assertIn('b', self.state)\n\n    with self.assertRaises(AssertionError):\n        @receiver(a_signal, sender=42)  # invalid sender\n            pass\n\n    with self.assertRaises(ValueError):\n        @receiver(a_signal, invalid_kwarg='value')  # invalid kwarg\n            pass\n", "def test_receiver_with_sender(self):\n    @receiver(a_signal, sender=self)\n        self.state.append(val)\n    other = object()\n    @receiver(a_signal, sender=other)\n        self.state.append(val)\n    self.state = []\n    a_signal.send(sender=self, val='self')\n    a_signal.send(sender=other, val='other')\n    a_signal.send(sender=object(), val='wrong')\n    self.assertIn('self', self.state)\n    self.assertIn('other', self.state)\n    self.assertEqual(len(self.state), 2)\n", "def test_connect_weakref_dead_reference(self):\n    \"\"\"Connecting a dead weak reference should not raise an exception.\"\"\"\n    a_signal = Signal()\n    class Receiver:\n        pass\n    receiver = weakref.ref(Receiver())\n    del receiver()\n    a_signal.connect(receiver)\n    a_signal.send(sender=self)\n    self.assertEqual(a_signal.receivers, [])\n", "    def test_connect_disconnect_weak_reference(self):\n        class Callable:\n                pass\n\n        receiver_1 = Callable()\n        receiver_2 = Callable()\n        a_signal.connect(receiver_1, weak=True)\n        a_signal.connect(receiver_2, weak=True)\n        del receiver_2\n        garbage_collect()\n        self.assertEqual(len(a_signal.receivers), 1)\n        self.assertIsNotNone(a_signal.receivers[0][1]())\n        a_signal.disconnect(receiver_1)\n        self.assertTestIsClean(a_signal)\n"], "sample_42": ["def test_serialize_nested_operation(self):\n    operation = custom_migration_operations.operations.ArgsOperation(\n        custom_migration_operations.operations.KwargsOperation(kwarg1=3, kwarg2=4),\n        custom_migration_operations.operations.ArgsOperation(1, 2)\n    )\n    buff, imports = OperationWriter(operation, indentation=0).serialize()\n    self.assertEqual(imports, {'import custom_migration_operations.operations'})\n    self.assertEqual(\n        buff,\n        'custom_migration_operations.operations.ArgsOperation(\\n'\n        '    arg1=custom_migration_operations.operations.KwargsOperation(\\n'\n        '        kwarg1=3,\\n'\n        '        kwarg2=4,\\n'\n        '    ),\\n'\n        '    arg2=custom_migration_operations.operations.ArgsOperation(\\n'\n        '        arg1=1,\\n'\n        '        arg2=2,\\n'\n        '    ),\\n'\n        '),'\n    )\n", "def test_serialize_pathlib_concrete(self):\n    \"\"\"\n    Concrete path objects should be converted to pure paths.\n    \"\"\"\n    path = pathlib.Path('.')\n    expected = (\"pathlib.PurePosixPath('.')\", {'import pathlib'})\n    if sys.platform == 'win32':\n        expected = (\"pathlib.PureWindowsPath('.')\", {'import pathlib'})\n    self.assertSerializedResultEqual(path, expected)\n", "def test_serialize_function_type(self):\n    # Test serializing a function type that's a method on a class.\n    class TestClass:\n            pass\n    test_instance = TestClass()\n    function = test_instance.method\n    serialized_function, imports = serializer_factory(function).serialize()\n    self.assertEqual(serialized_function, 'migrations.test_writer.TestClass.method')\n    self.assertEqual(imports, {'import migrations.test_writer'})\n    self.assertEqual(serializer_factory(serialized_function).serialize()[0], serialized_function)\n", "def test_serialize_functiontype(self):\n        pass\n\n    self.assertSerializedEqual(my_function)\n\n    string, imports = MigrationWriter.serialize(my_function)\n    self.assertEqual(string, 'migrations.test_writer.my_function')\n    self.assertEqual(imports, {'import migrations.test_writer'})\n\n            pass\n        return inner_function\n\n    self.assertSerializedEqual(my_nested_function())\n\n    string, imports = MigrationWriter.serialize(my_nested_function())\n    self.assertEqual(string, 'migrations.test_writer.my_nested_function.<locals>.inner_function')\n    self.assertEqual(imports, {'import migrations.test_writer'})\n\n    with self.assertRaisesMessage(ValueError, 'Could not find function my_function in migrations.test_writer.'):\n        self.serialize_round_trip(my_function, value={\"__module__\": \"wrong_module\", \"__name__\": \"my_function\"})\n\n    with self.assertRaisesMessage(ValueError, 'No module'):\n        self.serialize_round_trip(my_function, value={\"__name__\": \"my_function\"})\n\n    class MyClass:\n            pass\n\n    obj = MyClass()\n    self.assertSerializedEqual(obj.my_method)\n\n    string, imports = MigrationWriter.serialize(obj.my_method)\n    self.assertEqual(string, 'migrations.test_writer.MyClass.my_method')\n    self.assertEqual(imports, {'import migrations.test_writer'})\n\n    class Meta(type):\n                pass\n            dct['my_function'] = my_function\n            return super().__new__(cls, name, bases, dct)\n\n    class MyClass(metaclass=Meta):\n        pass\n\n    obj = MyClass()\n    self.assertSerializedEqual(MyClass.my_function)\n\n    string, imports = MigrationWriter.serialize(MyClass.my_function)\n    self.assertEqual(string, 'migrations.test_writer.MyClass.my_function')\n    self.assertEqual(imports, {'import migrations.test_writer'})\n", "def test_serialize_lazy_object_with_invalid_unwrap(self):\n    \"\"\"\n    Ticket #29370: Test the unwrapping of LazyObject with invalid __reduce__.\n    \"\"\"\n    class LazyObjectSubclass(SimpleLazyObject):\n            raise ValueError\n\n    lazy_object = LazyObjectSubclass(lambda: 42)\n    with self.assertRaisesMessage(ValueError, 'Cannot serialize:'):\n        self.serialize_round_trip(lazy_object)\n"], "sample_112": ["def test_isotonic_regression_out_of_bounds_edge_cases():\n    # Set y and x\n    y = np.array([3, 7, 5, 9, 8, 7, 10])\n    x = np.arange(len(y))\n\n    # Create model and fit\n    ir = IsotonicRegression(increasing=\"auto\", out_of_bounds=\"clip\")\n    ir.fit(x, y)\n\n    # Predict from edge cases\n    y1 = ir.predict([min(x)])\n    y2 = ir.predict([max(x)])\n\n    assert_array_equal(y1, [min(ir.f_.y)])\n    assert_array_equal(y2, [max(ir.f_.y)])\n", "def test_isotonic_regression_auto_increasing_with_warning():\n    # Set y and x for increasing with warning\n    y = np.array([0, 1, 2, 3, 4, 5])\n    x = np.array([0, 1, 2, 3, 3, 5])\n\n    # Create model and fit_transform\n    ir = IsotonicRegression(increasing=\"auto\")\n    with pytest.warns(UserWarning, match=\"interval\"):\n        y_ = ir.fit_transform(x, y)\n\n    # Check that relationship increases\n    is_increasing = y_[0] < y_[-1]\n    assert is_increasing\n", "def test_isotonic_regression_out_of_order():\n    # Test that isotonic regression can handle data that is not in order\n    x = np.array([5, 2, 8, 1, 9])\n    y = np.array([3, 7, 5, 9, 8])\n    ir = IsotonicRegression()\n    ir.fit(x, y)\n    assert_array_almost_equal(ir.transform(x), ir.fit_transform(x, y))\n    assert_array_almost_equal(ir.transform(x), ir.predict(x))\n", "def test_isotonic_regression_multiple_calls_to_transform():\n    # Create data\n    X = np.arange(10)\n    y = np.arange(10)\n\n    # Create IsotonicRegression instance and fit to data\n    iso_reg = IsotonicRegression()\n    iso_reg.fit(X, y)\n\n    # Call transform multiple times to check that the same result is returned\n    y_pred1 = iso_reg.transform(X)\n    y_pred2 = iso_reg.transform(X)\n    y_pred3 = iso_reg.transform(X)\n\n    assert_array_equal(y_pred1, y_pred2)\n    assert_array_equal(y_pred1, y_pred3)\n", "def test_isotonic_regression_out_of_bounds_edge_cases():\n    # Set y and x\n    y = np.array([3, 7, 5, 9, 8, 7, 10])\n    x = np.arange(len(y))\n\n    # Create model and fit\n    ir = IsotonicRegression(increasing=\"auto\", out_of_bounds=\"clip\")\n    ir.fit(x, y)\n\n    # Predict from  training and test x and check that min/max match.\n    # Test edge cases (min and max of X)\n    y1 = ir.predict([min(x), max(x)])\n    assert_array_equal(y1, [min(y), max(y)])\n\n    # Test just above min and just below max of X\n    y2 = ir.predict([min(x) + 1e-10, max(x) - 1e-10])\n    assert_array_equal(y2, [min(y), max(y)])\n\n    # Test edge cases with decreasing relationship\n    ir = IsotonicRegression(increasing=False, out_of_bounds=\"clip\")\n    ir.fit(x, y)\n\n    # Predict from  training and test x and check that min/max match.\n    y1 = ir.predict([min(x), max(x)])\n    assert_array_equal(y1, [max(y), min(y)])\n\n    # Test just above min and just below max of X\n    y2 = ir.predict([min(x) + 1e-10, max(x) - 1e-10])\n    assert_array_equal(y2, [max(y), min(y)])\n"], "sample_84": ["def test_xunit_teardown_in_setup_module_fixture(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        values = []\n            values.append(\"teardown_module\")\n            pytest.fail(\"teardown failed\")\n            values.append(\"setup_module\")\n            yield\n            pass\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        \"\"\"\n        *1 failed*2 passed*\n    \"\"\"\n    )\n    assert result.ret != 0\n    values = result.getcalls(\"pytest_runtest_setup\")[0].item.module.values\n    assert values == [\"setup_module\", \"teardown_module\"]\n", "def test_duplicated_conftest_same_level(testdir):\n    p = testdir.mkdir(\"tests\")\n    p.join(\"conftest.py\").write(\n        \"\"\"\n        import pytest\n\n        pytest_plugins = 'conftest2'\n\n        @pytest.fixture\n            return \"conftest\"\n    \"\"\"\n    )\n    p.join(\"conftest2.py\").write(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            return \"conftest2\"\n    \"\"\"\n    )\n    p.join(\"test_module.py\").write(\"def test_func(fixture1): assert fixture1 == 'conftest'\")\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n", "    def test_teardown_function_called_once(self, testdir):\n        \"\"\"Make sure that teardown_function is only called once after all tests are run (#3094)\"\"\"\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            DB_INITIALIZED = None\n            DB_TEARDOWN = None\n\n            @pytest.fixture(scope=\"session\", autouse=True)\n                global DB_INITIALIZED\n                DB_INITIALIZED = True\n                yield\n                global DB_TEARDOWN\n                DB_TEARDOWN = True\n\n                assert DB_INITIALIZED\n\n                assert DB_TEARDOWN\n\n            class TestClass(object):\n\n                    assert DB_INITIALIZED\n\n                    assert DB_TEARDOWN is None\n\n                    pass\n\n                    pass\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\"* 2 passed in *\"])\n", "    def test_setup_methods_ordering_with_fixtures(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n\n            class TestClass(object):\n                    values.append(1)\n                    values.append(2)\n                @pytest.fixture(autouse=True, scope=\"class\")\n                    values.append(3)\n                @pytest.fixture(autouse=True)\n                    values.append(4)\n                    assert values == [2, 3, 4]\n        \"\"\"\n        )\n        reprec = testdir.inline_run()\n        reprec.assertoutcome(passed=1)\n", "    def test_parametrize_fixture_names(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(params=[1,2])\n                return request.param\n                assert arg1 in (1,2)\n        \"\"\"\n        )\n        reprec = testdir.inline_run()\n        calls = reprec.getcalls(\"pytest_runtest_setup\")\n        for call in calls:\n            assert call.node.name == \"test_func[1-1]\" or call.node.name == \"test_func[1-2]\"\n            for call_ in call.funcargs.values():\n                assert call_.name == \"arg1\"\n                assert call_.request.param == call_.request.param\n"], "sample_85": ["def test_log_cli_sections_with_missing_sections(testdir, request):\n    filename = request.node.name + \".py\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n\n            logging.warning(\"log message from test_log_1\")\n\n            logging.warning(\"log message from test_log_2\")\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"{}::test_log_1 \".format(filename),\n            \"*-- live log start --*\",\n            \"*-- live log call --*\",\n            \"*WARNING*log message from test_log_1*\",\n            \"PASSED *50%*\",\n            \"{}::test_log_2 \".format(filename),\n            \"*-- live log start --*\",\n            \"*-- live log call --*\",\n            \"*WARNING*log message from test_log_2*\",\n            \"PASSED *100%*\",\n            \"=* 2 passed in *=\",\n        ]\n    )\n", "def test_log_set_path_absolute_file(testdir):\n    report_dir_base = \"/tmp/pytest_reports\"\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file_level = DEBUG\n        log_cli=true\n        \"\"\"\n    )\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n        @pytest.hookimpl(hookwrapper=True, tryfirst=True)\n            config = item.config\n            logging_plugin = config.pluginmanager.get_plugin(\"logging-plugin\")\n            report_file = \"{}/{}\".format(report_dir_base, item._request.node.name)\n            logging_plugin.set_log_path(report_file)\n            yield\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        logger = logging.getLogger(\"testcase-logger\")\n            logger.info(\"message from test 1\")\n            assert True\n\n            logger.debug(\"message from test 2\")\n            assert True\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 1\n    assert \"PermissionError\" in result.stderr.str()\n", "def test_live_logging_context_manager(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        import pytest\n\n            with caplog.at_level(logging.INFO):\n                logging.info('info message')\n            assert len(caplog.records) == 1\n            assert caplog.records[0].levelname == 'INFO'\n            assert caplog.records[0].message == 'info message'\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-s\", \"--log-cli-level=INFO\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*::test_live_logging_context_manager \",\n            \"*-- live log call --*\",\n            \"*INFO*info message*\",\n            \"PASSED *100%*\",\n            \"=* 1 passed in *=\",\n        ]\n    )\n", "def test_log_capture_handler_formatting(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n        logger = logging.getLogger(__name__)\n\n            logger.critical('Critical message')\n            logger.error('Error message')\n            logger.warning('Warning message')\n            logger.info('Info message')\n            logger.debug('Debug message')\n            assert False\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--log-level=DEBUG\", \"--log-format=%(name)s: %(message)s\")\n    assert result.ret == 1\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_log_capture_handler_formatting::test_log_capture_handler_formatting*\",\n            \"*test_log_capture_handler_formatting: Critical message*\",\n            \"*test_log_capture_handler_formatting: Error message*\",\n            \"*test_log_capture_handler_formatting: Warning message*\",\n            \"*test_log_capture_handler_formatting: Info message*\",\n            \"*test_log_capture_handler_formatting: Debug message*\",\n        ]\n    )\n", "def test_log_level_is_restored(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logger = logging.getLogger(__name__)\n            original_level = logger.level\n            logger.setLevel(logging.INFO)\n            assert logger.level == logging.INFO\n            request.config.pluginmanager.getplugin('logging-plugin').log_level = logging.DEBUG\n            logger.setLevel(logging.DEBUG)\n            assert logger.level == logging.DEBUG\n            request.addfinalizer(lambda: logger.setLevel(original_level))\n            logger.info('should not be shown')\n            logger.debug('should be shown')\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*should be shown*\",\n        ]\n    )\n    assert \"should not be shown\" not in result.stdout.str()\n"], "sample_4": ["    def test_set_signed_cookie(self):\n        # test setting a signed cookie\n        r = HttpResponse()\n        r.set_signed_cookie('test', 'value')\n        self.assertIn('Set-Cookie', r.serialize_headers())\n\n        # test setting a signed cookie with extra parameters\n        r = HttpResponse()\n        r.set_signed_cookie('test', 'value', max_age=3600, path='/test')\n        self.assertIn('Set-Cookie', r.serialize_headers())\n\n        # test setting a signed cookie with a custom salt\n        r = HttpResponse()\n        r.set_signed_cookie('test', 'value', salt='custom-salt')\n        self.assertIn('Set-Cookie', r.serialize_headers())\n", "    def test_content_type_is_set(self):\n        response = HttpResponseBase()\n        self.assertIn('Content-Type', response)\n", "    def test_status_code(self):\n        r = HttpResponseBase()\n        r.status_code = 200\n        self.assertEqual(r.status_code, 200)\n\n        with self.assertRaises(ValueError):\n            r.status_code = 600\n\n        with self.assertRaises(ValueError):\n            r.status_code = 0\n\n        with self.assertRaises(TypeError):\n            r.status_code = 'abc'\n", "    def test_headers_serialization(self):\n        response = HttpResponseBase()\n        response['Content-Type'] = 'application/json'\n        response['X-Custom-Header'] = 'custom value'\n        serialized_headers = response.serialize_headers()\n        self.assertIn(b'Content-Type: application/json', serialized_headers)\n        self.assertIn(b'X-Custom-Header: custom value', serialized_headers)\n", "    def test_headers(self):\n        response = HttpResponseBase()\n        response['Content-Type'] = 'text/html; charset=UTF-8'\n        self.assertEqual(response['Content-Type'], 'text/html; charset=UTF-8')\n        response['Accept'] = 'text/html'\n        self.assertEqual(response['accept'], 'text/html')\n"], "sample_66": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n", "    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n", "    def test_list_editable_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            list_editable = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'list_editable' must be a list or tuple.\",\n            \"admin.E120\",\n        )\n", "    def test_valid_case(self):\n        class InlineAdmin(admin.TabularInline):\n            model = ValidationTestInlineModel\n            readonly_fields = (\"parent\",)\n\n        class TestModelAdmin(ModelAdmin):\n            inlines = [InlineAdmin]\n\n        self.assertIsValid(TestModelAdmin, ValidationTestModel)\n", "    def test_attribute_accessed_through_model_instance(self):\n        class TestModel(Model):\n            test_attr = \"Test Attribute\"\n\n        class TestModelAdmin(ModelAdmin):\n            list_display = (\"test_attr\",)\n\n        self.assertIsValid(TestModelAdmin, TestModel)\n"], "sample_116": ["def test_create_index_with_fixre(app):\n    text = (\".. index:: func() (in module foo)\\n\"\n            \".. index:: func() (in module bar)\\n\"\n            \".. index:: func() (in module baz)\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 1\n    assert index[0] == ('F', [('func()', [[(' (in module bar)', '#index-1'),\n                                            (' (in module baz)', '#index-2'),\n                                            (' (in module foo)', '#index-0')], [], None])])\n", "def test_create_index_with_empty_target(app):\n    text = (\".. index:: single: \\n\"\n            \".. index:: single: docutils\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 1\n    assert index[0] == ('D', [('docutils', [[('', '#index-1')], [], None])])\n", "def test_create_index_with_fixre(app):\n    text = (\".. index:: func() (in module foo)\\n\"\n            \".. index:: func() (in module bar)\\n\"\n            \".. index:: func2() (in module foo)\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 1\n    assert index[0] == ('F', [('func()', [[], [('in module bar', [('', '#index-1')]),\n                                             ('in module foo', [('', '#index-0')])], None],\n                                   ('func2()', [[], [('in module foo', [('', '#index-2')])], None])])\n", "def test_create_index_with_group_entries_disabled(app):\n    text = (\".. index:: single: docutils\\n\"\n            \".. index:: single: docutils\\n\"\n            \".. index:: pip; install\\n\"\n            \".. index:: pip; upgrade\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder, group_entries=False)\n    assert len(index) == 2\n    assert index[0] == ('D', [('docutils', [[('', '#index-0')], [], None],\n                                ('docutils', [[('', '#index-1')], [], None])])\n    assert index[1] == ('P', [('pip', [[], [('install', [('', '#index-2')]),\n                                            ('upgrade', [('', '#index-3')])], None])])\n", "def test_create_index_with_unicode_and_symbols(app):\n    text = (\".. index:: Unicode: \u00fcber\\n\"\n            \".. index:: Symbol: \u00a3100\\n\"\n            \".. index:: Unicode: R\u00e9sum\u00e9\\n\"\n            \".. index:: Symbol: $50\\n\"\n            \".. index:: Unicode: \u00dcber\\n\"\n            \".. index:: Unicode: \u00fcber\\n\"\n            \".. index:: Symbol: \u20ac50\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 3\n    assert index[0] == ('R', [('R\u00e9sum\u00e9', [[('', '#index-2')], [], None])])\n    assert index[1] == ('S', [('Symbol', [[], [('\u00a3100', [('', '#index-1')]),\n                                                ('$50', [('', '#index-3')]),\n                                                ('\u20ac50', [('', '#index-5')])], None])])\n    assert index[2] == ('\u00dc', [('\u00fcber', [[], [('\u00dcber', [('', '#index-4')])], None])])\n"], "sample_52": ["def test_alter_field_preserve_default_with_db_column(self):\n    \"\"\"\n    Tests the AlterField operation's state alteration\n    when preserve_default = False and db_column is specified.\n    \"\"\"\n    project_state = self.set_up_test_model(\"test_adflpdb\")\n    # Test the state alteration\n    operation = migrations.AlterField(\n        \"Pony\",\n        \"pink\",\n        models.IntegerField(null=True, default=4, db_column=\"pink_column\"),\n        preserve_default=False,\n    )\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_adflpdb\", new_state)\n    self.assertEqual(len(new_state.models[\"test_adflpdb\", \"pony\"].fields), 3)\n    field = new_state.models[\"test_adflpdb\", \"pony\"].fields[\"pink\"]\n    self.assertEqual(field.default, models.NOT_PROVIDED)\n    self.assertEqual(field.db_column, \"pink_column\")\n    # Test the database alteration\n    project_state.apps.get_model(\"test_adflpdb\", \"pony\").objects.create(weight=4)\n    self.assertColumnExists(\"test_adflpdb_pony\", \"pink\")\n    with connection.schema_editor() as editor:\n        operation.database_forwards(\"test_adflpdb\", editor, project_state, new_state)\n    self.assertColumnExists(\"test_adflpdb_pony\", \"pink\")\n    # And deconstruction\n    definition = operation.deconstruct()\n    self.assertEqual(definition[0], \"AlterField\")\n    self.assertEqual(definition[1], [])\n    self.assertEqual(sorted(definition[2]), [\"field\", \"model_name\", \"name\", \"preserve_default\"])\n", "def test_rename_model_case_sensitive(self):\n    \"\"\"\n    Tests the RenameModel operation is case insensitive.\n    \"\"\"\n    app_label = \"test_rename_model_case_sensitive\"\n    project_state = self.apply_operations(\n        app_label,\n        ProjectState(),\n        operations=[\n            migrations.CreateModel(\n                \"Pony\",\n                fields=[\n                    (\"id\", models.AutoField(primary_key=True)),\n                ],\n            ),\n        ],\n    )\n    Pony = project_state.apps.get_model(app_label, \"Pony\")\n    Pony.objects.create()\n    new_state = project_state.clone()\n    operation = migrations.RenameModel(\"PoNy\", \"Horse\")\n    operation.state_forwards(app_label, new_state)\n    with connection.schema_editor() as editor:\n        operation.database_forwards(app_label, editor, project_state, new_state)\n    self.assertNotIn((\"test_rename_model_case_sensitive\", \"pony\"), new_state.models)\n    self.assertIn((\"test_rename_model_case_sensitive\", \"horse\"), new_state.models)\n    self.assertTableNotExists(\"test_rename_model_case_sensitive_pony\")\n    self.assertTableExists(\"test_rename_model_case_sensitive_horse\")\n", "def test_rename_index_invalid_name(self):\n    app_label = \"test_rninin\"\n    project_state = self.set_up_test_model(app_label, index=True)\n    table_name = app_label + \"_pony\"\n    self.assertIndexNameExists(table_name, \"pony_pink_idx\")\n\n    with self.assertRaisesMessage(\n        ValueError, \"Index name 'pony_pink_idx' does not conform to pattern '^[-a-zA-Z0-9_]+$'.\"\n    ):\n        migrations.RenameIndex(\"Pony\", new_name=\"pony_pink_idx!\", old_name=\"pony_pink_idx\")\n", "def test_reduce_operations(self):\n    app_label = \"test_reduce_operations\"\n    project_state = self.set_up_test_model(app_label)\n    new_state = project_state.clone()\n    operation = migrations.CreateModel(\n        \"ShetlandPony\",\n        [\n            (\"pony_ptr\", models.OneToOneField(\"Pony\", models.CASCADE, primary_key=True)),\n            (\"cuteness\", models.IntegerField(default=1)),\n        ],\n        options={\"unique_together\": (\"pony\", \"cuteness\")},\n    )\n    operation.state_forwards(app_label, new_state)\n    operations = [\n        migrations.AlterUniqueTogether(\"ShetlandPony\", [(\"pony\", \"cuteness\")]),\n        migrations.AlterField(\"ShetlandPony\", \"pony\", models.ForeignKey(\"Pony\", models.CASCADE)),\n        migrations.RenameField(\"ShetlandPony\", \"pony\", \"littlepony\"),\n        migrations.RenameModel(\"ShetlandPony\", \"LittlePony\"),\n    ]\n    reduced_operations = operation.reduce(\n        operations[0], app_label, allow_circular_references=True\n    )\n    self.assertEqual(len(reduced_operations), 1)\n    reduced_operation = reduced_operations[0]\n    self.assertIsInstance(reduced_operation, type(operation))\n    self.assertEqual(reduced_operation.name, operation.name)\n    self.assertEqual(\n        reduced_operation.options,\n        {\n            \"unique_together\": (\"littlepony\", \"cuteness\"),\n        },\n    )\n    self.assertEqual(\n        reduced_operation.fields,\n        [\n            (\"littlepony\", models.ForeignKey(\"Pony\", models.CASCADE, primary_key=True)),\n            (\"cuteness\", models.IntegerField(default=1)),\n        ],\n    )\n    reduced_operations = reduced_operation.reduce(\n        operations[1], app_label, allow_circular_references=True\n    )\n    self.assertEqual(len(reduced_operations), 1)\n    reduced_operation = reduced_operations[0]\n    self.assertIsInstance(reduced_operation, type(operation))\n    self.assertEqual(reduced_operation.name, operation.name)\n    self.assertEqual(\n        reduced_operation.options,\n        {\n            \"unique_together\": (\"littlepony\", \"cuteness\"),\n        },\n    )\n    self.assertEqual(\n        reduced_operation.fields,\n        [\n            (\"littlepony\", models.OneToOneField(\"Pony\", models.CASCADE, primary_key=True)),\n            (\"cuteness\", models.IntegerField(default=1)),\n        ],\n    )\n    reduced_operations = reduced_operation.reduce(\n        operations[2], app_label, allow_circular_references=True\n    )\n    self.assertEqual", "def test_create_model_custom_through_with_mti(self):\n    app_label = \"test_cmomti\"\n    project_state = self.set_up_test_model(app_label, mti_model=True)\n    pony_db_table = \"%s_pony\" % app_label\n\n    # Add the M2M field.\n    first_state = project_state.clone()\n    operation = migrations.AddField(\n        \"ShetlandPony\",\n        \"stables\",\n        models.ManyToManyField(\n            \"Stable\",\n            through=\"PonyStables\",\n            through_fields=(\"shetlandpony\", \"stable\"),\n        ),\n    )\n    operation.state_forwards(app_label, first_state)\n    with connection.schema_editor() as editor:\n        operation.database_forwards(app_label, editor, project_state, first_state)\n\n    # Check for correct table creation.\n    stable_db_table = \"%s_stable\" % app_label\n    pony_stable_db_table = \"%s_ponystables\" % app_label\n    self.assertTableExists(stable_db_table)\n    self.assertTableExists(pony_stable_db_table)\n\n    # Check the m2m table's column data types.\n    self.assertColumnExists(pony_stable_db_table, \"shetlandpony_id\")\n    self.assertColumnExists(pony_stable_db_table, \"stable_id\")\n\n    # Verify the through model.\n    PonyStables = first_state.apps.get_model(app_label, \"PonyStables\")\n    stable = PonyStables._meta.get_field(\"stable\")\n    self.assertIsInstance(stable, models.ForeignKey)\n    self.assertEqual(stable.remote_field.model, \"Stable\")\n    self.assertEqual(stable.remote_field.field_name, \"id\")\n    self.assertEqual(stable.column, \"stable_id\")\n    shetlandpony = PonyStables._meta.get_field(\"shetlandpony\")\n    self.assertIsInstance(shetlandpony, models.ForeignKey)\n    self.assertEqual(shetlandpony.remote_field.model, \"ShetlandPony\")\n    self.assertEqual(shetlandpony.remote_field.field_name, \"pony_ptr\")\n    self.assertEqual(shetlandpony.column, \"shetlandpony_id\")\n\n    # Check the M2M field actually works.\n    with atomic():\n        Pony = first_state.apps.get_model(app_label, \"Pony\")\n        ShetlandPony = first_state.apps.get_model(app_label, \"ShetlandPony\")\n        Stable = first_state.apps.get_model(app_label,"], "sample_69": ["def test_sticky_edges():\n    art = martist.Artist()\n    assert art.sticky_edges.x == []\n    assert art.sticky_edges.y == []\n    art.sticky_edges.x = [1, 2, 3]\n    art.sticky_edges.y = [4, 5, 6]\n    assert art.sticky_edges.x == [1, 2, 3]\n    assert art.sticky_edges.y == [4, 5, 6]\n    art.sticky_edges.x[:] = [7, 8, 9]\n    art.sticky_edges.y[:] = [10, 11, 12]\n    assert art.sticky_edges.x == [7, 8, 9]\n    assert art.sticky_edges.y == [10, 11, 12]\n", "def test_sticky_edges():\n    artist = martist.Artist()\n    assert artist.sticky_edges.x == []\n    assert artist.sticky_edges.y == []\n\n    artist.sticky_edges.x[:] = (1, 2)\n    artist.sticky_edges.y[:] = (3, 4)\n    assert artist.sticky_edges.x == [1, 2]\n    assert artist.sticky_edges.y == [3, 4]\n\n    artist.sticky_edges.x[:] = (5, 6)\n    artist.sticky_edges.y[:] = (7, 8)\n    assert artist.sticky_edges.x == [5, 6]\n    assert artist.sticky_edges.y == [7, 8]\n", "def test_sticky_edges():\n    \"\"\"Test the sticky edges functionality.\"\"\"\n    fig, ax = plt.subplots()\n    line, = ax.plot([1, 2, 3])\n    assert line.sticky_edges.x == [] and line.sticky_edges.y == []\n\n    # Setting sticky edges for a line should not have any effect on the plot.\n    line.sticky_edges.x = [1, 2, 3]\n    line.sticky_edges.y = [1, 2, 3]\n    plt.close()\n\n    fig, ax = plt.subplots()\n    bars = ax.bar([1, 2, 3], [1, 2, 3])\n    assert bars.sticky_edges.x == [0] and bars.sticky_edges.y == [0]\n\n    # Change the sticky edges for the bars.\n    bars.sticky_edges.x = [1, 2, 3]\n    bars.sticky_edges.y = [1, 2, 3]\n    plt.close()\n\n    fig, ax = plt.subplots()\n    hist = ax.hist([1, 2, 3], bins=[1, 2, 3, 4], align='left')\n    assert hist[2].sticky_edges.x == [1, 2, 3, 4] and hist[2].sticky_edges.y == [0]\n\n    # Change the sticky edges for the histogram.\n    hist[2].sticky_edges.x = [1, 2, 3, 4, 5]\n    hist[2].sticky_edges.y = [0, 1, 2, 3]\n    plt.close()\n", "def test_set_clip_path():\n    fig, ax = plt.subplots()\n    rect = mpatches.Rectangle((0, 0), 1, 1)\n    ax.add_patch(rect)\n\n    # Test that no clip path is set\n    assert rect.get_clip_path() is None\n\n    # Test setting a Path\n    clip_path = mpath.Path.unit_circle()\n    rect.set_clip_path(clip_path)\n    assert rect.get_clip_path() is clip_path\n\n    # Test setting a TransformedPath\n    clip_path_t = mtransforms.Affine2D().rotate_deg(45) + ax.transData\n    rect.set_clip_path(mpath.Path.unit_circle(), clip_path_t)\n    assert rect.get_clip_path().get_fully_transformed_path() is not None\n\n    # Test setting a TransformedPatchPath\n    patch = mpatches.Circle((0, 0), 1)\n    clip_path_tp = mtransforms.Affine2D().rotate_deg(45) + ax.transData\n    rect.set_clip_path(patch, clip_path_tp)\n    assert rect.get_clip_path().get_fully_transformed_path() is not None\n\n    # Test that clip_path can be set to None\n    rect.set_clip_path(None)\n    assert rect.get_clip_path() is None\n\n    # Test that clip_path can be set with a tuple of (Path, Transform)\n    rect.set_clip_path((mpath.Path.unit_circle(), clip_path_t))\n    assert rect.get_clip_path().get_fully_transformed_path() is not None\n\n    # Test that clip_path raises an error for invalid inputs\n    with pytest.raises(TypeError):\n        rect.set_clip_path(\"Invalid input\")\n\n    plt.close('all')\n", "def test_set_get_children():\n    fig, ax = plt.subplots()\n    line = ax.plot([1, 2, 3])[0]\n\n    # A single line has no children.\n    assert line.get_children() == []\n\n    # Patch collections do have children (the patches).\n    patches = ax.patches\n    collection = mcollections.PatchCollection(patches, facecolor='r')\n    ax.add_collection(collection)\n\n    # Collection's children should be the patches.\n    assert set(collection.get_children()) == set(patches)\n\n    # Now check the children of the axes.\n    assert set(ax.get_children()) == {line, collection} | set(ax.spines.values()) | {ax.xaxis, ax.yaxis}\n"], "sample_127": ["def test_latex_xi():\n    from sympy.abc import xi\n    assert latex(xi) == r'\\xi'\n", "def test_latex_ndimarray():\n    A = ImmutableDenseNDimArray([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n    assert latex(A) == r'\\left[\\begin{matrix}\\left[\\begin{matrix}1 & 2\\\\3 & 4\\end{matrix}\\right] & \\left[\\begin{matrix}5 & 6\\\\7 & 8\\end{matrix}\\right]\\end{matrix}\\right]'\n", "def test_latex_units_symbols():\n    expr1 = kg + meter\n    assert latex(expr1) == r\"\\detokenize {kilogram} + \\detokenize {meter}\"\n    expr2 = kg * meter**2\n    assert latex(expr2) == r\"\\detokenize {kilogram} \\cdot \\detokenize {meter}^{2}\"\n", "def test_latex_printing_of_boolean_functions():\n    A, B, C = symbols('A, B, C', cls=Function, commutative=False)\n    a, b, c = symbols('a, b, c', cls=Function)\n\n    assert latex(Implies(A, B)) == r\"A \\Rightarrow B\"\n    assert latex(Implies(B, A)) == r\"B \\Rightarrow A\"\n\n    assert latex(Equivalent(A, B)) == r\"A \\Leftrightarrow B\"\n    assert latex(Equivalent(B, A)) == r\"B \\Leftrightarrow A\"\n\n    assert latex(And(a, b, c, evaluate=False)) == r\"a \\wedge b \\wedge c\"\n    assert latex(Or(a, b, c, evaluate=False)) == r\"a \\vee b \\vee c\"\n\n    assert latex(Xor(a, b, c, evaluate=False)) == r\"a \\veebar b \\veebar c\"\n\n    assert latex(Not(a, evaluate=False)) == r\"\\neg a\"\n\n    # Test issue 2934\n    assert latex(Implies(x, y)) == r\"x \\Rightarrow y\"\n    assert latex(Equivalent(x, y)) == r\"x \\Leftrightarrow y\"\n\n    # Test issue 2934\n    assert latex(And(x, y)) == r\"x \\wedge y\"\n    assert latex(Or(x, y)) == r\"x \\vee y\"\n\n    # Test issue 2934\n    assert latex(Xor(x, y)) == r\"x \\veebar y\"\n\n    # Test issue 2934\n    assert latex(Not(x)) == r\"\\neg x\"\n", "def test_latex_Differential():\n    # Differential in free module\n    from sympy.diffgeom import CoordSys\n    from sympy.diffgeom import BaseCovarDifferential\n    from sympy import symbols\n    from sympy.diffgeom.rn import R2\n\n    # test covariant\n    x, y = symbols('x y')\n    C = CoordSys('C', x, y)\n    dx = BaseCovarDifferential(x)\n    dy = BaseCovarDifferential(y)\n    dC = C.differential_basis()\n    dc0 = dC[0]\n    dc1 = dC[1]\n    assert latex(dx) == r\"\\mathrm{d}x\"\n    assert latex(dy) == r\"\\mathrm{d}y\"\n    assert latex(dc0) == r\"\\mathrm{d}x_{C}\"\n    assert latex(dc1) == r\"\\mathrm{d}y_{C}\"\n\n    # test contravariant\n    dx_R2 = R2.dx\n    dy_R2 = R2.dy\n    assert latex(dx_R2) == r\"\\mathrm{d}x\"\n    assert latex(dy_R2) == r\"\\mathrm{d}y\"\n\n    # test sum\n    assert latex(dx + dy) == r\"\\mathrm{d}x + \\mathrm{d}y\"\n\n    # test scalar multiplication\n    assert latex(x*dx) == r\"x \\mathrm{d}x\"\n\n    # test wedge product\n    assert latex(dx_R2^dy_R2) == r\"\\mathrm{d}x \\wedge \\mathrm{d}y\"\n\n    # test BaseVectorField\n    C = CoordSys('C', symbols('x y z'))\n    e0, e1, e2 = C.base_vectors()\n    assert latex(e0) == r\"\\partial_{x_{C}}\"\n    assert latex(e1) == r\"\\partial_{y_{C}}\"\n    assert latex(e2) == r\"\\partial_{z_{C}}\"\n"], "sample_65": ["    def test_addslashes(self):\n        output = self.engine.render_to_string(\"addslashes\", {\"a\": 'Hello \"world\"!'})\n        self.assertEqual(output, 'Hello \\\\\"world\\\"!')\n", "    def test_truncatechars01(self):\n        output = self.engine.render_to_string(\"truncatechars01\", {\"a\": \"abcdefghi\"})\n        self.assertEqual(output, \"abcde\u2026\")\n", "    def test_addslashes(self):\n        output = self.engine.render_to_string(\"addslashes01\", {\"a\": \"Hello 'World'!\"})\n        self.assertEqual(output, \"Hello \\\\'World\\'!\")\n", "    def test_addslashes01(self):\n        output = self.engine.render_to_string(\"addslashes01\", {\"value\": 'hello \"world\"'})\n        self.assertEqual(output, 'hello \\\\\"world\\\"')\n", "    def test_stringformat01(self):\n        output = self.engine.render_to_string(\"stringformat01\")\n        self.assertEqual(output, 'Hello John')\n"], "sample_28": ["    def setUp(self):\n        self.site = admin.AdminSite()\n", "    def setUp(self):\n        self.site = admin.AdminSite()\n", "    def setUp(self):\n        self.site = admin.AdminSite()\n", "    def setUp(self):\n        self.site = admin.AdminSite()\n", "    def setUp(self):\n        self.site = admin.AdminSite()\n        self.user = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        self.request_factory = RequestFactory()\n"], "sample_89": ["def test_get_fslocation_from_item(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    item = testdir.getitems(p)[0]\n\n    # Test with 'location' attribute\n    item.location = (\"path/to/file.py\", 10, \"test_func\")\n    result = nodes.get_fslocation_from_item(item)\n    assert result == (\"path/to/file.py\", 10)\n\n    # Test with 'obj' attribute\n    item.location = None\n    item.obj = test_func\n    result = nodes.get_fslocation_from_item(item)\n    assert result == (str(p), 2)\n\n    # Test with 'fspath' attribute\n    item.obj = None\n    item.fspath = p\n    result = nodes.get_fslocation_from_item(item)\n    assert result == (p, None)\n\n    # Test with no attributes\n    item.fspath = None\n    result = nodes.get_fslocation_from_item(item)\n    assert result == (\"unknown location\", -1)\n", "def test_repr_failure_py_exception_with_long_tbstyle(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n            assert False\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-v\", \"--tb=long\", p)\n    result.stdout.fnmatch_lines([\"*AssertionError:*\"])\n    assert \"assert False\" in result.stdout.str()\n    assert \"1 failed in *\" in result.stdout.str()\n", "def test_prune_traceback(testdir):\n    \"\"\"\n    Test that the traceback is pruned correctly for test failures.\n    \"\"\"\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n            assert False\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([str(p) + \":*: AssertionError\", \"*1 failed in *\"])\n\n    # Check that the traceback is pruned\n    assert not any(\n        line.startswith(\"File\") and \"site-packages\" in line for line in result.stdout.lines\n    )\n", "def test_repr_failure_py(testdir):\n    \"\"\"Test _repr_failure_py method in Node class.\"\"\"\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            raise Exception(\"bad fixture\")\n\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*Exception: bad fixture*\"])\n\n    # Check for fulltrace option\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            raise Exception(\"bad fixture\")\n\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--fulltrace\")\n    result.stdout.fnmatch_lines([\"*Exception: bad fixture*\"])\n", "def test_node_repr_failure_with_conftest_import_failure(testdir):\n    \"\"\"Test that repr_failure returns a nice error message for ConftestImportFailure.\"\"\"\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        pytest_plugins = [\"nonexistent_plugin\"]\n    \"\"\"\n    )\n    items = testdir.getitems(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([f\"*{p.basename}:*\"])\n    excinfo = ExceptionInfo(\n        type=ConftestImportFailure, value=ConftestImportFailure(p), tb=()\n    )\n    assert items[0].repr_failure(excinfo) == f\"could not import 'nonexistent_plugin'\"\n"], "sample_80": ["def test_format_array_flat_edge_cases(self):\n    # Test with empty array\n    actual = formatting.format_array_flat(np.array([]), 10)\n    expected = \"\"\n    assert actual == expected\n\n    # Test with array of a single element\n    actual = formatting.format_array_flat(np.array([1]), 10)\n    expected = \"1\"\n    assert actual == expected\n\n    # Test with array of two elements\n    actual = formatting.format_array_flat(np.array([1, 2]), 10)\n    expected = \"1 2\"\n    assert actual == expected\n\n    # Test with array of three elements\n    actual = formatting.format_array_flat(np.array([1, 2, 3]), 10)\n    expected = \"1 2 3\"\n    assert actual == expected\n\n    # Test with array of four elements\n    actual = formatting.format_array_flat(np.array([1, 2, 3, 4]), 10)\n    expected = \"1 2 ... 4\"\n    assert actual == expected\n\n    # Test with very large array and small max_width\n    actual = formatting.format_array_flat(np.arange(1000), 5)\n    expected = \"...\"\n    assert actual == expected\n", "    def test_summarize_coord(self):\n        coord = xr.IndexVariable(\"x\", np.array([1, 2, 3]))\n        coord.attrs = {\"foo\": \"bar\"}\n\n        actual = formatting.summarize_coord(\"x\", coord, 10)\n        expected = \"  * x        (x) int64 1 2 3\"\n        assert actual == expected\n\n        coord = xr.IndexVariable(\"x\", np.array([1, 2, 3]), dims=(\"x\",))\n        coord.attrs = {\"foo\": \"bar\"}\n\n        actual = formatting.summarize_coord(\"x\", coord, 10)\n        expected = \"  * x        (x) int64 1 2 3\"\n        assert actual == expected\n", "    def test_diff_dim_summary(self):\n        a = xr.DataArray(np.arange(12).reshape(3, 4), dims=[\"x\", \"y\"])\n        b = xr.DataArray(np.arange(12).reshape(3, 4), dims=[\"x\", \"z\"])\n        expected = \"Differing dimensions:\\n    (x: 3, y: 4) != (x: 3, z: 4)\"\n        actual = formatting.diff_dim_summary(a, b)\n        assert actual == expected\n\n        c = xr.DataArray(np.arange(12).reshape(4, 3), dims=[\"x\", \"y\"])\n        expected = \"Differing dimensions:\\n    (x: 3, y: 4) != (x: 4, y: 3)\"\n        actual = formatting.diff_dim_summary(a, c)\n        assert actual == expected\n\n        d = xr.DataArray(np.arange(12).reshape(3, 4), dims=[\"x\", \"y\"])\n        expected = \"\"\n        actual = formatting.diff_dim_summary(a, d)\n        assert actual == expected\n", "def test_format_array_flat_edge_cases(self):\n    # Test edge case where max_width is less than 2\n    with pytest.raises(ValueError, match=\"max_width must be at least 2\"):\n        formatting.format_array_flat(np.arange(10), 1)\n\n    # Test edge case where array is empty\n    assert formatting.format_array_flat(np.array([]), 10) == \"\"\n\n    # Test edge case where max_width is very large\n    actual = formatting.format_array_flat(np.arange(100), 1000)\n    expected = \"0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99\"\n    assert actual == expected\n\n    # Test edge case where array contains very long strings\n    actual = formatting.format_array_flat(np.array([\"hello world\" * 10]), 10)\n    expected = \"'hello worldhello...\"\n    assert actual == expected\n", "def test_summarize_variable(self):\n    var = xr.Variable(\"x\", np.array([1, 2, 3]))\n    name = \"var_name\"\n    col_width = 10\n    marker = \"*\"\n\n    expected = \"     * var_name (x) int64 1 2 3\"\n    actual = formatting.summarize_variable(name, var, col_width, marker)\n    assert expected == actual\n\n    var = xr.Variable(\"x\", np.array([1, 2, 3]), dims=(\"x\", \"y\"))\n    expected = \"     * var_name (x, y) int64 1 2 3\"\n    actual = formatting.summarize_variable(name, var, col_width, marker)\n    assert expected == actual\n\n    var = xr.Variable(\"x\", np.array([1, 2, 3]), attrs={\"units\": \"m\"})\n    expected = \"     * var_name (x) int64 1 2 3\"\n    actual = formatting.summarize_variable(name, var, col_width, marker)\n    assert expected == actual\n"], "sample_124": ["def test_hyperbolic_functions_properties():\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z')\n\n    assert sinh(x + y).diff(x) == cosh(x + y)\n    assert sinh(x + y).diff(y) == cosh(x + y)\n    assert cosh(x + y).diff(x) == sinh(x + y)\n    assert cosh(x + y).diff(y) == sinh(x + y)\n    assert tanh(x + y).diff(x) == 1 - tanh(x + y)**2\n    assert tanh(x + y).diff(y) == 1 - tanh(x + y)**2\n    assert coth(x + y).diff(x) == -1/sinh(x + y)**2\n    assert coth(x + y).diff(y) == -1/sinh(x + y)**2\n\n    assert csch(x + y).diff(x) == -coth(x + y)*csch(x + y)\n    assert csch(x + y).diff(y) == -coth(x + y)*csch(x + y)\n    assert sech(x + y).diff(x) == -tanh(x + y)*sech(x + y)\n    assert sech(x + y).diff(y) == -tanh(x + y)*sech(x + y)\n\n    assert asinh(x + y).diff(x) == 1/sqrt((x + y)**2 + 1)\n    assert asinh(x + y).diff(y) == 1/sqrt((x + y)**2 + 1)\n    assert acosh(x + y).diff(x) == 1/sqrt((x + y)**2 - 1)\n    assert acosh(x + y).diff(y) == 1/sqrt((x + y)**2 - 1)\n    assert atanh(x + y).diff(x) == 1/(1 - (x + y)**2)\n    assert atanh(x + y).diff(y) == 1/(1 - (x + y)**2)\n    assert acoth(x + y).diff(x) == 1/((x + y)**2 - 1)\n    assert acoth(x + y).diff(y) == 1/((x + y)**2 - 1)\n    assert asech(x + y).diff(x) == -1/((x", "def test_issue_hyperbolic_functions_with_high_order_derivatives():\n    x = Symbol('x')\n\n    # Test high-order derivatives of hyperbolic functions\n    for func in [sinh, cosh, tanh, coth, sech, csch]:\n        for i in range(1, 11):  # Test up to 10th derivative\n            f = func(x)\n            df = f.diff(x, i)\n            assert df.diff(x) == f.diff(x, i+1)\n\n    # Test high-order derivatives of inverse hyperbolic functions\n    for func in [asinh, acosh, atanh, acoth, asech, acsch]:\n        for i in range(1, 11):  # Test up to 10th derivative\n            f = func(x)\n            df = f.diff(x, i)\n            assert df.diff(x) == f.diff(x, i+1)\n", "def test_peeloff_ipi():\n    from sympy import I, pi\n    from sympy.functions.elementary.hyperbolic import _peeloff_ipi\n\n    assert _peeloff_ipi(pi*I/2) == (0, pi*I/2)\n    assert _peeloff_ipi(pi*I) == (0, pi*I)\n    assert _peeloff_ipi(pi*I*2) == (0, pi*I*2)\n    assert _peeloff_ipi(2*pi*I/3) == (0, 2*pi*I/3)\n    assert _peeloff_ipi(4*pi*I/3) == (0, 4*pi*I/3)\n    assert _peeloff_ipi(5*pi*I/3) == (0, 5*pi*I/3)\n    assert _peeloff_ipi(7*pi*I/3) == (0, 7*pi*I/3)\n    assert _peeloff_ipi(pi*I/4) == (0, pi*I/4)\n    assert _peeloff_ipi(pi*I*3/4) == (0, pi*I*3/4)\n    assert _peeloff_ipi(pi*I*5/4) == (0, pi*I*5/4)\n    assert _peeloff_ipi(pi*I*7/4) == (0, pi*I*7/4)\n    assert _peeloff_ipi(pi*I/6) == (0, pi*I/6)\n    assert _peeloff_ipi(pi*I*5/6) == (0, pi*I*5/6)\n    assert _peeloff_ipi(pi*I*7/6) == (0, pi*I*7/6)\n    assert _peeloff_ipi(pi*I*11/6) == (0, pi*I*11/6)\n    assert _peeloff_ipi(pi*I/8) == (0, pi*I/8)\n    assert _peeloff_ipi(pi*I*3/8) == (0, pi*I*3/8)\n    assert _peeloff_ipi(pi*I*5/8) == (0, pi*I*5/8)\n    assert _peeloff_ipi(pi*I*7/8) == (0, pi*I*7/8)\n    assert _peeloff_ip", "def test_hyperbolic_identities():\n    x, y = symbols('x,y')\n\n    assert sinh(x + y) == sinh(x)*cosh(y) + cosh(x)*sinh(y)\n    assert sinh(x - y) == sinh(x)*cosh(y) - cosh(x)*sinh(y)\n    assert cosh(x + y) == cosh(x)*cosh(y) + sinh(x)*sinh(y)\n    assert cosh(x - y) == cosh(x)*cosh(y) - sinh(x)*sinh(y)\n    assert tanh(x + y) == (tanh(x) + tanh(y))/(1 + tanh(x)*tanh(y))\n    assert tanh(x - y) == (tanh(x) - tanh(y))/(1 - tanh(x)*tanh(y))\n    assert coth(x + y) == (coth(x)*coth(y) + 1)/(coth(y) + coth(x))\n    assert coth(x - y) == (coth(x)*coth(y) - 1)/(coth(y) - coth(x))\n\n    assert sinh(x)*cosh(x) == sinh(2*x)/2\n    assert sinh(x)**2 - cosh(x)**2 == -1\n    assert cosh(x)**2 - sinh(x)**2 == 1\n    assert cosh(x)**2 - sinh(x)**2 == 1\n    assert cosh(x)**2 - sinh(x)**2 == 1\n    assert sinh(x)**2 + 1 == cosh(x)**2\n    assert 1 - sinh(x)**2 == cosh(x)**2\n    assert cosh(x)**2 - 1 == sinh(x)**2\n    assert sinh(x)**2 + cosh(x)**2 == cosh(x)**2\n    assert 2*sinh(x)*cosh(x) == sinh(2*x)\n    assert cosh(2*x) == cosh(x)**2 + sinh(x)**2\n\n    assert tanh(x + y) == (tanh(x) + tanh(y))/(1 + tanh(x)*tanh(y))\n    assert tanh(x - y) == (tanh(x) - tanh(y))/(1 - tanh(x)*tanh(y))\n\n    assert coth(x + y) == (coth(x)*coth(y) + 1)/(coth(y) + coth", "def test_hyperbolic_functions():\n    x = Symbol('x')\n    # Testing eval of HyperbolicFunctions\n    for func in [sinh, cosh, tanh, coth, csch, sech, asinh, acosh, atanh, acoth, asech, acsch]:\n        assert func(x).func(x) == func(x)\n    \n    # Testing _peeloff_ipi function\n    assert _peeloff_ipi(x + I*pi/2) == (x, I*pi/2)\n    assert _peeloff_ipi(x + I*2*pi/3 + I*pi*y) == (x + I*pi*y + I*pi/6, I*pi/2)\n    \n    # Testing ReciprocalHyperbolicFunction\n    for func in [csch, sech]:\n        assert func(x).func(x) == func(x)\n        \n    # Testing InverseHyperbolicFunction\n    for func in [asinh, acosh, atanh, acoth, asech, acsch]:\n        assert func(x).func(x) == func(x)\n        \n    # Testing HyperbolicFunctions with complex numbers\n    z = Symbol('z')\n    for func in [sinh, cosh, tanh, coth, csch, sech, asinh, acosh, atanh, acoth, asech, acsch]:\n        assert func(z).func(z) == func(z)\n        \n    # Testing HyperbolicFunctions with imaginary numbers\n    for func in [sinh, cosh, tanh, coth, csch, sech, asinh, acosh, atanh, acoth, asech, acsch]:\n        assert func(I*pi).func(I*pi) == func(I*pi)\n"], "sample_64": ["def test_prepopulated_fields_js(self):\n    \"\"\"\n    Test the prepopulated_fields_js template tag.\n    \"\"\"\n    article = Article.objects.all()[0]\n    request = self.request_factory.get(\n        reverse(\"admin:admin_views_article_change\", args=[article.pk])\n    )\n    request.user = self.superuser\n    admin = ArticleAdmin(Article, site)\n    response = admin.change_view(request, str(article.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIn(\"prepopulated_fields\", template_context)\n    self.assertIn(\"prepopulated_fields_json\", template_context)\n    prepopulated_fields_json = json.loads(template_context[\"prepopulated_fields_json\"])\n    self.assertIsInstance(prepopulated_fields_json, list)\n    for field in prepopulated_fields_json:\n        self.assertIsInstance(field, dict)\n        self.assertIn(\"id\", field)\n        self.assertIn(\"name\", field)\n        self.assertIn(\"dependency_ids\", field)\n        self.assertIn(\"dependency_list\", field)\n        self.assertIn(\"maxLength\", field)\n        self.assertIn(\"allowUnicode\", field)\n", "def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should correctly generate prepopulated_fields_json.\n    \"\"\"\n    request = self.request_factory.get(reverse(\"admin:admin_views_article_change\", args=[self.article.pk]))\n    request.user = self.superuser\n    admin = ArticleAdmin(Article, site)\n    response = admin.change_view(request, str(self.article.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIsInstance(template_context[\"prepopulated_fields_json\"], str)\n    prepopulated_fields_json = json.loads(template_context[\"prepopulated_fields_json\"])\n    self.assertIsInstance(prepopulated_fields_json, list)\n    for field in prepopulated_fields_json:\n        self.assertIsInstance(field[\"id\"], str)\n        self.assertIsInstance(field[\"name\"], str)\n        self.assertIsInstance(field[\"dependency_ids\"], list)\n        self.assertIsInstance(field[\"dependency_list\"], list)\n        self.assertIsInstance(field[\"maxLength\"], int)\n        self.assertIsInstance(field[\"allowUnicode\"], bool)\n", "def test_prepopulated_fields_js(self):\n    \"\"\"\n    Test that prepopulated_fields_js template tag correctly generates the\n    JavaScript data for the prepopulated fields.\n    \"\"\"\n    request = self.request_factory.get(\n        reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n    )\n    request.user = self.superuser\n    admin = UserAdmin(User, site)\n    response = admin.change_view(request, str(self.superuser.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIn(\"prepopulated_fields\", template_context)\n    self.assertIn(\"prepopulated_fields_json\", template_context)\n    prepopulated_fields_json = template_context[\"prepopulated_fields_json\"]\n    prepopulated_fields_data = json.loads(prepopulated_fields_json)\n    self.assertIsInstance(prepopulated_fields_data, list)\n    for field_data in prepopulated_fields_data:\n        self.assertIn(\"id\", field_data)\n        self.assertIn(\"name\", field_data)\n        self.assertIn(\"dependency_ids\", field_data)\n        self.assertIn(\"dependency_list\", field_data)\n        self.assertIn(\"maxLength\", field_data)\n        self.assertIn(\"allowUnicode\", field_data)\n", "def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should render prepopulated fields as JSON.\n    \"\"\"\n    request = self.request_factory.get(\n        reverse(\"admin:admin_views_article_change\", args=[self.article.pk])\n    )\n    request.user = self.superuser\n    admin = ArticleAdmin(Article, site)\n    response = admin.change_view(request, str(self.article.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIn(\"prepopulated_fields_json\", template_context)\n    prepopulated_fields_json = json.loads(template_context[\"prepopulated_fields_json\"])\n    self.assertIsInstance(prepopulated_fields_json, list)\n    for field in prepopulated_fields_json:\n        self.assertIn(\"id\", field)\n        self.assertIn(\"name\", field)\n        self.assertIn(\"dependency_ids\", field)\n        self.assertIn(\"dependency_list\", field)\n        self.assertIn(\"maxLength\", field)\n        self.assertIn(\"allowUnicode\", field)\n", "    def test_prepopulated_fields_js(self):\n        \"\"\"\n        prepopulated_fields_js template tag should generate JavaScript data.\n        \"\"\"\n        article = Article.objects.all()[0]\n        request = self.request_factory.get(\n            reverse(\"admin:admin_views_article_change\", args=[article.pk])\n        )\n        request.user = self.superuser\n        admin = ArticleAdmin(Article, site)\n        response = admin.change_view(request, str(article.pk))\n        template_context = prepopulated_fields_js(response.context_data)\n        self.assertIn(\"prepopulated_fields_json\", template_context)\n        self.assertIn(\"prepopulated_fields\", template_context)\n\n        # Test JSON data structure.\n        prepopulated_fields_json = json.loads(template_context[\"prepopulated_fields_json\"])\n        for field in prepopulated_fields_json:\n            self.assertIn(\"id\", field)\n            self.assertIn(\"name\", field)\n            self.assertIn(\"dependency_ids\", field)\n            self.assertIn(\"dependency_list\", field)\n            self.assertIn(\"maxLength\", field)\n            self.assertIn(\"allowUnicode\", field)\n"], "sample_15": ["def test_consistent_language_settings_with_variant(self):\n    tests = [\n        # language + script.\n        'sr-latn',\n        # language.\n        'sr',\n    ]\n    for tag in tests:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [])\n", "def test_supported_language_variant(self):\n    tests = [\n        # language + script.\n        'sr-Latn',\n        'sr-Cyrl',\n    ]\n    for tag in tests:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [])\n\n    tests = [\n        # language + script (different script).\n        'sr-Grek',\n    ]\n    for tag in tests:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [\n                Error(E004.msg, id=E004.id),\n            ])\n", "def test_consistent_language_settings_in_LANGUAGES(self):\n    self.assertEqual(check_language_settings_consistent(None), [])\n", "    def test_invalid_variant_consistent_language_settings(self):\n        tests = [\n            # language + script (should be invalid, but currently not).\n            'sr-latn',\n            # language + script + region (should be invalid, but currently not).\n            'sr-latn-rs',\n            # language + script + region + variant (should be invalid, but currently not).\n            'sr-latn-rs-latn',\n        ]\n        for tag in tests:\n            with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n                self.assertEqual(check_language_settings_consistent(None), [\n                    Error('You have provided a value for the LANGUAGE_CODE setting that is not in the LANGUAGES setting.', id='translation.E004'),\n                ])\n", "    def test_valid_consistent_language_settings(self):\n        tests = [\n            ('en', [('en', 'English')]),\n            ('fr-CA', [('fr', 'French'), ('fr-CA', 'French (Canada)')]),\n            ('es-419', [('es', 'Spanish'), ('es-419', 'Spanish (Latin America)')]),\n            ('ca-ES-valencia', [('ca', 'Catalan'), ('ca-ES-valencia', 'Catalan (Valencian)')]),\n        ]\n        for tag, languages in tests:\n            with self.subTest(tag), self.settings(LANGUAGE_CODE=tag, LANGUAGES=languages):\n                self.assertEqual(check_language_settings_consistent(None), [])\n"], "sample_2": ["def test_reorient_celestial_first():\n    \"\"\"\n    Test the reorient_celestial_first method.\n    \"\"\"\n    h = fits.Header()\n    h['CTYPE1'] = 'FREQ'\n    h['CTYPE2'] = 'RA---TAN'\n    h['CTYPE3'] = 'DEC--TAN'\n    h['CTYPE4'] = 'STOKES'\n    w = wcs.WCS(h)\n    assert w.naxis == 4\n    w = w.reorient_celestial_first()\n    assert w.naxis == 4\n    assert w.wcs.ctype[0] == 'RA---TAN'\n    assert w.wcs.ctype[1] == 'DEC--TAN'\n    assert w.wcs.ctype[2] == 'FREQ'\n    assert w.wcs.ctype[3] == 'STOKES'\n", "def test_crpix_0():\n    \"\"\"\n    Regression test for https://github.com/astropy/astropy/issues/5466\n    \"\"\"\n    w = wcs.WCS(naxis=2)\n    w.wcs.crval = [50, 50]\n    w.wcs.cdelt = [1, 1]\n    w.wcs.ctype = ['RA---TAN', 'DEC--TAN']\n    w.wcs.crpix = [0, 0]\n    w.wcs.set()\n\n    header = w.to_header()\n    for ii in range(2):\n        assert header['CRVAL{0}'.format(ii + 1)] == w.wcs.crval[ii]\n        assert header['CDELT{0}'.format(ii + 1)] == w.wcs.cdelt[ii]\n", "def test_subarray():\n    \"\"\"\n    Test WCS subarray\n    \"\"\"\n    header = get_pkg_data_contents('data/sip.fits', encoding='binary')\n    w = wcs.WCS(header)\n    sub = w.sub([1, 2])\n    assert_array_equal(sub.wcs.crpix, w.wcs.crpix)\n    assert_array_equal(sub.wcs.pc, w.wcs.pc)\n    assert_array_equal(sub.wcs.crval, w.wcs.crval)\n    assert_array_equal(sub.wcs.cdelt, w.wcs.cdelt)\n    assert_array_equal(sub.wcs.ctype, w.wcs.ctype[1:])\n    assert sub.naxis == 1\n    assert sub.wcs.naxis == 1\n", "compilation error", "def test_non_square_lookup_tables():\n    \"\"\"\n    Test that WCS can be created from a non-square lookup table.\n    \"\"\"\n    fits_name = get_pkg_data_filename('data/dist.fits')\n    w = wcs.WCS(fits_name)\n    lookup_table = w.det2im1.data\n    assert lookup_table.shape == (101, 101)\n\n    # test a non-square lookup table\n    lookup_table = lookup_table[:, :50]\n    w.det2im1.data = lookup_table\n    assert w.det2im1.data.shape == (101, 50)\n\n    w.all_pix2world(lookup_table.shape[0] / 2, lookup_table.shape[1] / 2, 0)\n"], "sample_41": ["    def test_absolute_max_more_than_DEFAULT_MAX_NUM(self):\n        \"\"\"Setting absolute_max more than DEFAULT_MAX_NUM works.\"\"\"\n        data = {\n            'form-TOTAL_FORMS': '1001',\n            'form-INITIAL_FORMS': '0',\n            'form-MAX_NUM_FORMS': '0',\n        }\n        LimitedFavoriteDrinksFormSet = formset_factory(\n            FavoriteDrinkForm,\n            max_num=2000,\n            absolute_max=2000,\n        )\n        formset = LimitedFavoriteDrinksFormSet(data=data)\n        self.assertIs(formset.is_valid(), True)\n        self.assertEqual(len(formset.forms), 1001)\n", "def test_formset_cleaned_data(self):\n    \"\"\"\n    Test that formset.cleaned_data returns the correct data for each form.\n    \"\"\"\n    data = {\n        'choices-TOTAL_FORMS': '3',\n        'choices-INITIAL_FORMS': '0',\n        'choices-0-choice': 'Zero',\n        'choices-0-votes': '0',\n        'choices-1-choice': 'One',\n        'choices-1-votes': '1',\n        'choices-2-choice': 'Two',\n        'choices-2-votes': '2',\n    }\n    formset = self.make_choiceformset(data)\n    self.assertTrue(formset.is_valid())\n    expected_data = [\n        {'choice': 'Zero', 'votes': 0},\n        {'choice': 'One', 'votes': 1},\n        {'choice': 'Two', 'votes': 2},\n    ]\n    self.assertEqual(formset.cleaned_data, expected_data)\n", "def test_formset_with_deletion_remove_deletion_flag_invalid(self):\n    \"\"\"\n    If a form is filled with something and can_delete is also checked, that\n    form's errors shouldn't make the entire formset invalid since it's\n    going to be deleted. But it should be invalid if the delete flag is\n    removed.\n    \"\"\"\n    class CheckForm(Form):\n        field = IntegerField(min_value=100)\n\n    data = {\n        'check-TOTAL_FORMS': '3',  # the number of forms rendered\n        'check-INITIAL_FORMS': '2',  # the number of forms with initial data\n        'check-MIN_NUM_FORMS': '0',  # min number of forms\n        'check-MAX_NUM_FORMS': '0',  # max number of forms\n        'check-0-field': '200',\n        'check-0-DELETE': 'on',\n        'check-1-field': '50',\n        'check-1-DELETE': 'on',\n        'check-2-field': '50',\n        'check-2-DELETE': '',\n    }\n    CheckFormSet = formset_factory(CheckForm, can_delete=True)\n    formset = CheckFormSet(data, prefix='check')\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(len(formset._errors), 1)\n    self.assertEqual(formset._errors[0], {'field': ['Ensure this value is greater than or equal to 100.']})\n", "    def test_formset_str(self):\n        \"\"\"\n        Formsets have a custom __str__ method to convert them to strings.\n        This method returns the as_table() representation.\n        \"\"\"\n        formset = self.make_choiceformset([('Calexico', '100')])\n        self.assertEqual(str(formset), formset.as_table())\n", "def test_formset_with_deletion_and_invalid_data(self):\n    \"\"\"\n    Test that formset with can_delete=True handles invalid data correctly.\n    \"\"\"\n    class InvalidForm(Form):\n        field = CharField(min_length=5)\n\n    data = {\n        'form-TOTAL_FORMS': '2',\n        'form-INITIAL_FORMS': '0',\n        'form-MIN_NUM_FORMS': '0',\n        'form-MAX_NUM_FORMS': '0',\n        'form-0-field': 'abc',\n        'form-0-DELETE': '',\n        'form-1-field': 'abcdefgh',\n        'form-1-DELETE': 'on',\n    }\n    InvalidFormSet = formset_factory(InvalidForm, can_delete=True)\n    formset = InvalidFormSet(data, prefix='form')\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(len(formset._errors), 1)\n    self.assertEqual(formset._errors[0], {'field': ['Ensure this value has at least 5 characters (it has 3).']})\n    self.assertEqual(len(formset.deleted_forms), 1)\n    self.assertEqual(len(formset.forms), 2)\n"], "sample_132": ["def test_are_coplanar():\n    from sympy.geometry import Point3D, Line3D\n    a = Line3D(Point3D(5, 0, 0), Point3D(1, -1, 1))\n    b = Line3D(Point3D(0, -2, 0), Point3D(3, 1, 1))\n    c = Line3D(Point3D(0, -1, 0), Point3D(5, -1, 9))\n    assert not are_coplanar(a, b, c)\n\n    a = Line3D(Point3D(5, 0, 0), Point3D(1, -1, 0))\n    b = Line3D(Point3D(0, -2, 0), Point3D(3, 1, 0))\n    c = Line3D(Point3D(0, -1, 0), Point3D(5, -1, 0))\n    assert are_coplanar(a, b, c)\n", "def test_are_coplanar():\n    from sympy.geometry import Point3D, Line3D\n    a = Line3D(Point3D(5, 0, 0), Point3D(1, -1, 1))\n    b = Line3D(Point3D(0, -2, 0), Point3D(3, 1, 1))\n    c = Line3D(Point3D(0, -1, 0), Point3D(5, -1, 9))\n    assert are_coplanar(a, b, c) is False\n    assert are_coplanar(a, a, a) is True\n\n    # Test with points\n    p1 = Point3D(0, 0, 0)\n    p2 = Point3D(1, 0, 0)\n    p3 = Point3D(1, 1, 0)\n    p4 = Point3D(0, 1, 0)\n    assert are_coplanar(p1, p2, p3, p4) is True\n\n    # Test with non-3D entities\n    p1 = Point(0, 0)\n    p2 = Point(1, 0)\n    p3 = Point(1, 1)\n    p4 = Point(0, 1)\n    assert are_coplanar(p1, p2, p3, p4) is True\n\n    # Test with a mix of 2D and 3D points\n    p1 = Point3D(0, 0, 0)\n    p2 = Point3D(1, 0, 0)\n    p3 = Point(1, 1)\n    p4 = Point(0, 1)\n    assert are_coplanar(p1, p2, p3, p4) is True\n", "def test_are_coplanar():\n    from sympy.geometry import Point3D, Line3D\n    a = Line3D(Point3D(5, 0, 0), Point3D(1, -1, 1))\n    b = Line3D(Point3D(0, -2, 0), Point3D(3, 1, 1))\n    c = Line3D(Point3D(0, -1, 0), Point3D(5, -1, 9))\n    assert not are_coplanar(a, b, c)\n    assert are_coplanar(a, b)\n    assert are_coplanar(Point3D(1, 2, 3), Point3D(4, 5, 6))\n    assert are_coplanar(Point3D(0, 0, 0), Point3D(1, 0, 0), Point3D(0, 1, 0), Point3D(1, 1, 0))\n\n    from sympy.geometry import Plane\n    p = Plane((1, 0, 0), (0, 1, 0), (0, 0, 1))\n    assert are_coplanar(p, a, b)\n    assert are_coplanar(p, Point3D(0, 0, 0))\n", "def test_are_coplanar():\n    from sympy.geometry import Point3D, Line3D, Plane\n    a = Line3D(Point3D(5, 0, 0), Point3D(1, -1, 1))\n    b = Line3D(Point3D(0, -2, 0), Point3D(3, 1, 1))\n    c = Line3D(Point3D(0, -1, 0), Point3D(5, -1, 9))\n    assert are_coplanar(a, b, c) is False\n    p = Plane(Point3D(0, 0, 0), Point3D(1, 0, 0), Point3D(0, 1, 0))\n    assert are_coplanar(p, a, b) is True\n    assert are_coplanar(p, p) is True\n    assert are_coplanar(Point3D(1, 2, 3), Point3D(4, 5, 6)) is False\n    assert are_coplanar(Point3D(1, 2, 3), Point3D(1, 2, 3), Point3D(1, 2, 3)) is False\n    assert are_coplanar(Point3D(1, 2, 3), Point3D(4, 5, 6), Point3D(7, 8, 9)) is True\n", "def test_are_coplanar():\n    p1, p2, p3 = Point3D(0, 0, 0), Point3D(1, 0, 0), Point3D(0, 1, 0)\n    p4, p5 = Point3D(0, 1, 1), Point3D(1, 1, 1)\n    assert are_coplanar(p1, p2, p3) is True\n    assert are_coplanar(p1, p2, p3, p4) is False\n    assert are_coplanar(p1, p4, p5) is True\n    l1 = Line3D(p1, p2)\n    l2 = Line3D(p1, p3)\n    l3 = Line3D(p1, p4)\n    assert are_coplanar(l1, l2, l3) is True\n    assert are_coplanar(l1, l2, p4) is True\n    assert are_coplanar(p1, l1, l3) is True\n    raises(ValueError, lambda: are_coplanar(Point(1, 2)))\n    raises(ValueError, lambda: are_coplanar(p1, Point(1, 2)))\n"], "sample_152": ["def test_ndarray_conjugate_transpose_and_adjoint():\n    for ArrayType in array_types:\n        a = ArrayType([[1 + 2*x, 2 + 3*x], [3 + 4*x, 4 + 5*x]])\n        b = a.conjugate()\n        assert b == ArrayType([[1 - 2*x, 2 - 3*x], [3 - 4*x, 4 - 5*x]])\n\n        c = a.transpose()\n        assert c == ArrayType([[1 + 2*x, 3 + 4*x], [2 + 3*x, 4 + 5*x]])\n\n        d = a.adjoint()\n        assert d == ArrayType([[1 - 2*x, 3 - 4*x], [2 - 3*x, 4 - 5*x]])\n", "def test_ndim_array_operations():\n    for ArrayType in array_types:\n        A = ArrayType([[1, 2], [3, 4]])\n        B = ArrayType([[5, 6], [7, 8]])\n        assert A + B == ArrayType([[6, 8], [10, 12]])\n        assert A - B == ArrayType([[-4, -4], [-4, -4]])\n        assert A * 2 == ArrayType([[2, 4], [6, 8]])\n        assert 2 * A == ArrayType([[2, 4], [6, 8]])\n        assert A / 2 == ArrayType([[1/2, 1], [3/2, 2]])\n        assert -A == ArrayType([[-1, -2], [-3, -4]])\n\n        raises(ValueError, lambda: A + 1)\n        raises(ValueError, lambda: A - 1)\n        raises(ValueError, lambda: A * [[1, 2], [3, 4]])\n        raises(ValueError, lambda: A / [[1, 2], [3, 4]])\n", "def test_ndarray_arithmetic_operations():\n    for ArrayType in array_types:\n        a = ArrayType([[1, 2], [3, 4]])\n        b = ArrayType([[5, 6], [7, 8]])\n        c = ArrayType([[1, 1], [1, 1]])\n\n        assert a + b == ArrayType([[6, 8], [10, 12]])\n        assert a - b == ArrayType([[-4, -4], [-4, -4]])\n        assert 2 * a == ArrayType([[2, 4], [6, 8]])\n        assert a * 2 == ArrayType([[2, 4], [6, 8]])\n        assert a / 2 == ArrayType([[1/2, 1], [3/2, 2]])\n        assert -a == ArrayType([[-1, -2], [-3, -4]])\n\n        raises(ValueError, lambda: a + c)\n        raises(ValueError, lambda: a - c)\n        raises(ValueError, lambda: a / c)\n\n        raises(ValueError, lambda: a + 1)\n        raises(ValueError, lambda: a - 1)\n        raises(ValueError, lambda: a * 1)\n        raises(ValueError, lambda: a / 1)\n        raises(ValueError, lambda: a + x)\n        raises(ValueError, lambda: a - x)\n        raises(ValueError, lambda: a * x)\n        raises(ValueError, lambda: a / x)\n", "def test_array_indexing():\n    for ArrayType in array_types:\n        test_array = ArrayType([[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[10, 11, 12], [13, 14, 15], [16, 17, 18]]])\n        assert test_array[0, 0, 0] == 1\n        assert test_array[0, 1, 2] == 3\n        assert test_array[0, :, :] == Array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n        assert test_array[:, 0, 0] == Array([1, 10])\n        assert test_array[0, :, 1] == Array([2, 5, 8])\n        assert test_array[1, 2, :] == Array([16, 17, 18])\n        raises(ValueError, lambda: test_array[3, 0, 0])\n        raises(ValueError, lambda: test_array[0, 3, 0])\n        raises(ValueError, lambda: test_array[0, 0, 3])\n\n    for ArrayType in array_types:\n        test_array = ArrayType([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n        assert test_array[0, 0] == Array([1, 2])\n        assert test_array[1, 1] == Array([7, 8])\n        assert test_array[0, :] == Array([[1, 2], [3, 4]])\n        assert test_array[:, 0] == Array([[1, 2], [5, 6]])\n        assert test_array[:, 1] == Array([[3, 4], [7, 8]])\n        raises(ValueError, lambda: test_array[2, 0])\n        raises(ValueError, lambda: test_array[0, 2])\n\n    for ArrayType in array_types:\n        test_array = ArrayType([[1, 2, 3], [4, 5, 6]])\n        assert test_array[0, 0] == 1\n        assert test_array[1, 2] == 6\n        assert test_array[0, :] == Array([1, 2, ", "def test_ndim_array_operations():\n    # Test __add__, __sub__, __mul__, __truediv__\n    A = ImmutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    B = ImmutableDenseNDimArray([4, 4, 4, 4], (2, 2))\n\n    assert (A + B).tolist() == [[5, 6], [7, 8]]\n    assert (A - B).tolist() == [[-3, -2], [-2, -0]]\n    assert (A * 2).tolist() == [[2, 4], [6, 8]]\n    assert (B / 4).tolist() == [[1, 1], [1, 1]]\n\n    # Test __rmul__, __truediv__\n    assert (2 * A).tolist() == [[2, 4], [6, 8]]\n    raises(NotImplementedError, lambda: A / B)\n\n    # Test __neg__\n    assert (-A).tolist() == [[-1, -2], [-3, -4]]\n\n    # Test __eq__, __ne__\n    C = ImmutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    D = ImmutableDenseNDimArray([1, 2, 3, 5], (2, 2))\n    assert A == C\n    assert A != D\n\n    # Test _eval_derivative\n    x = y = S.Symbol('x')\n    A = ImmutableDenseNDimArray([[x, y], [x*y, x+y]], (2, 2))\n    assert A.diff(x).tolist() == [[1, 0], [y, 1]]\n\n    # Test _eval_conjugate, _eval_adjoint\n    A = ImmutableDenseNDimArray([[1 + x, 2 + y], [3 + x*y, 4 + x+y]], (2, 2))\n    assert A.conjugate().tolist() == [[1 - x, 2 - y], [3 - x*y, 4 - x-y]]\n    assert A.adjoint().tolist() == [[1 - x, 3 - x*y], [2 - y, 4 - x-y]]\n"], "sample_51": ["def test_directory_index_non_existent_template(self):\n    \"\"\"\n    Ensure that the directory index view falls back to the default template\n    if a custom template does not exist.\n    \"\"\"\n    with self.settings(\n        TEMPLATES=[\n            {\n                \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n                \"OPTIONS\": {\n                    \"loaders\": [\n                        (\n                            \"django.template.loaders.locmem.Loader\",\n                            {},\n                        ),\n                    ],\n                },\n            }\n        ]\n    ):\n        response = self.client.get(\"/%s/\" % self.prefix)\n        self.assertContains(response, \"Index of ./\")\n        # Directories have a trailing slash.\n        self.assertIn(\"subdir/\", response.context[\"file_list\"])\n        self.assertIn(\"Index of\", response.context[\"directory\"])\n", "def test_directory_index_rendering(self):\n    response = self.client.get(\"/%s/\" % self.prefix)\n    self.assertTemplateUsed(response, \"static/directory_index.html\")\n    self.assertEqual(response.status_code, 200)\n", "def test_was_modified_since_large_file(self):\n    \"\"\"Handle files with size larger than the maximum allowed value for an integer\"\"\"\n    mtime = 1343416141\n    size = 2147483648  # 2^31\n    header = http_date(mtime)\n    self.assertFalse(was_modified_since(header, mtime, size))\n    size = 2147483649  # larger than 2^31\n    self.assertTrue(was_modified_since(header, mtime, size))\n", "def test_directory_index_with_subdirectories(self):\n    \"\"\"\n    Test that directory index view works correctly with subdirectories.\n    \"\"\"\n    response = self.client.get(\"/%s/subdir/\" % self.prefix)\n    self.assertEqual(response.status_code, 200)\n    self.assertContains(response, \"Index of subdir/\")\n    # File with a leading dot (e.g. .hidden) aren't displayed.\n    self.assertEqual(response.context[\"file_list\"], [\"visible\"])\n    # Test that subdirectories are listed with a trailing slash\n    subdirectory_url = \"/%s/subdir/subdir2/\" % self.prefix\n    response = self.client.get(subdirectory_url)\n    self.assertEqual(response.status_code, 200)\n    self.assertContains(response, \"Index of subdir2/\")\n    self.assertEqual(response.context[\"file_list\"], [\"subdir2file.txt\"])\n", "def test_was_modified_since_with_large_mtime(self):\n    \"\"\"\n    was_modified_since handles large mtime values without overflowing (#30691).\n    \"\"\"\n    large_mtime = 2 ** 31 - 1\n    header = http_date(large_mtime)\n    self.assertFalse(was_modified_since(header, large_mtime))\n"], "sample_134": ["def test_issue_array_permutation():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    M = MatrixSymbol(\"M\", 2, 2)\n\n    cg = CodegenArrayPermuteDims(M, [1, 0])\n    f = lambdify((M,), cg, 'numpy')\n\n    ma = np.array([[1, 2], [3, 4]])\n    mr = np.array([[1, 3], [2, 4]])\n\n    assert (f(ma) == mr).all()\n", "def test_issue_17006_cbrt():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    assert abs(lambdify((a,), Cbrt(a), 'numpy')(27) - 3) < 1e-16\n    assert abs(lambdify((a,), cbrt(a), 'numpy')(27) - 3) < 1e-16\n", "def test_abs():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    e = abs(a)\n    f = lambdify((a,), e)\n\n    a_ = np.array([-1, 0, 1])\n    assert np.array_equal(f(a_), np.abs(a_))\n", "def test_pow():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    e = a ** b\n    f = lambdify((a, b), e, 'numpy')\n\n    a_ = np.array([0, 1, 2, 3])\n    b_ = np.array([2, 2, 2, 2])\n    assert np.array_equal(f(a_, b_), [0, 1, 4, 9])\n\n    e = a ** 0.5\n    f = lambdify((a,), e, 'numpy')\n\n    a_ = np.array([0, 1, 4, 9])\n    assert np.array_equal(f(a_), [0, 1, 2, 3])\n\n    e = a ** (1/3)\n    f = lambdify((a,), e, 'numpy')\n\n    a_ = np.array([0, 1, 8, 27])\n    assert np.allclose(f(a_), [0, 1, 2, 3])\n", "def test_issue_einsum():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    M = MatrixSymbol(\"M\", 2, 2)\n    N = MatrixSymbol(\"N\", 2, 2)\n    P = MatrixSymbol(\"P\", 2, 2)\n    Q = MatrixSymbol(\"Q\", 2, 2)\n    ma = np.matrix([[1, 2], [3, 4]])\n    mb = np.matrix([[1,-2], [-1, 3]])\n    mc = np.matrix([[2, 0], [1, 2]])\n    md = np.matrix([[1,-1], [4, 7]])\n\n    cg = CodegenArrayTensorProduct(M, CodegenArrayTensorProduct(N, P, Q))\n    f = lambdify((M, N, P, Q), cg, 'numpy')\n    result = f(ma, mb, mc, md)\n    expected_result = np.einsum(ma, [0, 1], np.einsum(mb, [2, 3], np.einsum(mc, [4, 5], md, [6, 7]), [4, 5, 6, 7]), [2, 3, 4, 5])\n    assert np.array_equal(result, expected_result)\n\n    cg = CodegenArrayTensorProduct(CodegenArrayTensorProduct(M, N), P, Q)\n    f = lambdify((M, N, P, Q), cg, 'numpy')\n    result = f(ma, mb, mc, md)\n    expected_result = np.einsum(np.einsum(ma, [0, 1], mb, [2, 3], [0, 1, 2, 3]), [0, 1, 2, 3], np.einsum(mc, [4, 5], md, [6, 7], [4, 5, 6, 7]), [4, 5, 6, 7])\n    assert np.array_equal(result, expected_result)\n"], "sample_55": ["def test_base_command_suppressed_base_arguments(self):\n    class Command(BaseCommand):\n        suppressed_base_arguments = {\"settings\", \"pythonpath\"}\n\n    parser = Command().create_parser(\"prog_name\", \"subcommand\")\n    self.assertNotIn(\"--settings\", parser.format_help())\n    self.assertNotIn(\"--pythonpath\", parser.format_help())\n    self.assertIn(\"--version\", parser.format_help())\n    self.assertIn(\"--verbosity\", parser.format_help())\n", "    def test_command_output_wrapper_flush_with_no_flush_method(self):\n        class NoFlushIO:\n                self.stream = stream\n\n                return getattr(self.stream, name)\n\n                raise AttributeError(\"No flush method\")\n\n        out = NoFlushIO(StringIO())\n        with mock.patch.object(out, \"flush\", side_effect=AttributeError):\n            management.call_command(\"outputwrapper\", stdout=out)\n        self.assertIn(\"Working...\", out.stream.getvalue())\n", "def test_base_stealth_options(self):\n    class Command(BaseCommand):\n        base_stealth_options = (\"example\",)\n\n            parser.add_argument(\"--example\", action=\"store_true\")\n\n            return \"example\"\n\n    out = StringIO()\n    with self.assertRaisesMessage(CommandError, \"Unknown option(s) for unknown command: example\"):\n        management.call_command(\"unknown\", \"--example\", stdout=out)\n    with mock.patch.object(Command, \"handle\") as handle:\n        out = StringIO()\n        management.call_command(\"unknown\", example=True, stdout=out)\n        self.assertEqual(out.getvalue(), \"example\\n\")\n        handle.assert_called_once_with(example=True)\n", "def test_command_parser_with_default_options(self):\n    \"\"\"\n    Test that CommandParser correctly handles default options.\n    \"\"\"\n    class TestCommand(BaseCommand):\n        stealth_options = (\"custom_option\",)\n        requires_system_checks = \"__all__\"\n\n    parser = TestCommand().create_parser(\"test_command\", \"subcommand\")\n    options = parser.parse_args([\"--custom_option\", \"value\"])\n    self.assertEqual(options.custom_option, \"value\")\n    self.assertTrue(hasattr(options, \"settings\"))\n    self.assertTrue(hasattr(options, \"pythonpath\"))\n    self.assertTrue(hasattr(options, \"traceback\"))\n    self.assertTrue(hasattr(options, \"no_color\"))\n    self.assertTrue(hasattr(options, \"force_color\"))\n    self.assertTrue(hasattr(options, \"skip_checks\"))\n\n    with self.assertRaises(CommandError):\n        parser.parse_args([\"--unknown_option\"])\n", "def test_output_wrapper_style_func(self):\n    \"\"\"Test that the style_func is used when writing to an OutputWrapper.\"\"\"\n    out = StringIO()\n    management.call_command(\"outputwrapper_style_func\", stdout=out)\n    self.assertIn(\"\\x1b[32mWorking...\\x1b[0m\", out.getvalue())\n"], "sample_49": ["def test_reset_all_loaders_with_cached_loader(self, mock_reset):\n    autoreload.reset_loaders()\n    self.assertEqual(mock_reset.call_count, 1)\n", "def test_template_changed_non_django_template_backend(self, mock_reset):\n    template_path = Path(__file__).parent / 'templates' / 'index.html'\n    self.assertIsNone(autoreload.template_changed(None, template_path))\n    mock_reset.assert_not_called()\n", "def test_template_changed_calls_reset_loaders_when_template_dir_matches(self, mock_get_template_directories):\n    mock_get_template_directories.return_value = {Path('/path/to/templates')}\n    mock_reset_loaders = mock.patch('django.template.autoreload.reset_loaders').start()\n    template_path = Path('/path/to/templates/template.html')\n    autoreload.template_changed(None, template_path)\n    mock_reset_loaders.assert_called_once()\n    mock_get_template_directories.assert_called_once()\n", "def test_template_changed_with_non_existent_template_dir(self, mock_get_template_dirs):\n    mock_get_template_dirs.return_value = {Path('/non-existent/path')}\n    self.assertIsNone(autoreload.template_changed(None, Path(__file__)))\n    mock_get_template_dirs.assert_called_once()\n", "def test_template_changed_with_py_file(self, mock_reset):\n    self.assertIsNone(autoreload.template_changed(None, Path(__file__)))\n    mock_reset.assert_not_called()\n"], "sample_13": ["    def test_no_fields_limit(self):\n        query_string = 'a=1&b=2&c=3'\n        expected_result = [('a', '1'), ('b', '2'), ('c', '3')]\n        self.assertEqual(limited_parse_qsl(query_string), expected_result)\n", "    def test_parse_qsl_fields_limit(self):\n        qs = \"a=1&b=2&c=3&a=4&a=5\"\n        result = limited_parse_qsl(qs, keep_blank_values=False, encoding='utf-8', errors='replace', fields_limit=5)\n        self.assertEqual(result, [('a', '1'), ('b', '2'), ('c', '3'), ('a', '4'), ('a', '5')])\n", "    def test_parse_qs_with_limit(self):\n        self.assertEqual(limited_parse_qsl('a=1&b=2&c=3', keep_blank_values=False, fields_limit=3), [('a', '1'), ('b', '2'), ('c', '3')])\n", "    def test_fields_limit(self):\n        qs = 'a=1&b=2&c=3'\n        with self.assertRaisesMessage(TooManyFieldsSent, 'The number of GET/POST parameters exceeded settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'):\n            limited_parse_qsl(qs, fields_limit=2)\n", "    def test_empty_string(self):\n        self.assertEqual(limited_parse_qsl(''), [])\n"], "sample_48": ["def test_alter_model_options_on_swapped_model(self):\n    \"\"\"\n    Tests that AlterModelOptions doesn't affect swapped models.\n    \"\"\"\n    project_state, new_state = self.make_test_state(\"test_almoopsw\", migrations.AlterModelOptions(\"Pony\", {\"permissions\": [(\"can_groom\", \"Can groom\")]}, swappable=True))\n    self.assertEqual(project_state.models[\"test_almoopsw\", \"pony\"].options.get(\"permissions\", []), [])\n    self.assertEqual(new_state.models[\"test_almoopsw\", \"pony\"].options.get(\"permissions\", []), [])\n    with connection.schema_editor() as editor:\n        migrations.AlterModelOptions(\"Pony\", {\"permissions\": [(\"can_groom\", \"Can groom\")]}).database_forwards(\"test_almoopsw\", editor, project_state, new_state)\n    self.assertEqual(project_state.apps.get_model(\"test_almoopsw\", \"pony\")._meta.permissions, [])\n", "def test_add_constraint_with_create_model(self):\n    \"\"\"\n    Test that AddConstraint works with CreateModel in the same migration.\n    \"\"\"\n    project_state = ProjectState()\n    constraint = models.UniqueConstraint(fields=['pink'], name='test_constraint_pony_pink')\n    operation = migrations.CreateModel(\n        'Pony',\n        [\n            ('id', models.AutoField(primary_key=True)),\n            ('pink', models.IntegerField(default=3)),\n        ],\n        options={'constraints': [constraint]},\n    )\n    # Test the state alteration\n    new_state = project_state.clone()\n    operation.state_forwards('test_addconstraint', new_state)\n    self.assertEqual(len(new_state.models['test_addconstraint', 'pony'].options['constraints']), 1)\n    Pony = new_state.apps.get_model('test_addconstraint', 'Pony')\n    self.assertEqual(len(Pony._meta.constraints), 1)\n    # Test the database alteration\n    with connection.schema_editor() as editor:\n        operation.database_forwards('test_addconstraint', editor, project_state, new_state)\n    with connection.cursor() as cursor:\n        with self.assertRaises(IntegrityError):\n            cursor.execute(\"INSERT INTO test_addconstraint_pony (id, pink) VALUES (1, 1)\")\n", "def test_alter_field_foreign_key_to_text(self):\n    \"\"\"\n    Tests the AlterField operation when changing a field from a foreign key to a text field.\n    \"\"\"\n    project_state = self.set_up_test_model(\"test_alflfkt\")\n    # Test adding and then altering the FK in one go\n    create_operation = migrations.CreateModel(\n        name=\"Rider\",\n        fields=[\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"pony\", models.ForeignKey(\"Pony\", models.CASCADE)),\n        ],\n    )\n    create_state = project_state.clone()\n    create_operation.state_forwards(\"test_alflfkt\", create_state)\n    alter_operation = migrations.AlterField(\n        model_name='Rider',\n        name='pony',\n        field=models.CharField(max_length=255),\n    )\n    alter_state = create_state.clone()\n    alter_operation.state_forwards(\"test_alflfkt\", alter_state)\n    with connection.schema_editor() as editor:\n        create_operation.database_forwards(\"test_alflfkt\", editor, project_state, create_state)\n        alter_operation.database_forwards(\"test_alflfkt\", editor, create_state, alter_state)\n\n    # Test the state alteration\n    self.assertEqual(len(alter_state.models[\"test_alflfkt\", \"rider\"].fields), 2)\n    self.assertIsInstance(alter_state.models['test_alflfkt', 'rider'].fields['pony'], models.Field)\n    self.assertIsInstance(alter_state.models['test_alflfkt', 'rider'].fields['pony'], models.CharField)\n\n    # Test the database alteration\n    self.assertColumnExists(\"test_alflfkt_rider\", \"pony_id\")\n    self.assertColumnNotExists(\"test_alflfkt_rider\", \"pony\")\n    with connection.schema_editor() as editor:\n        alter_operation.database_forwards(\"test_alflfkt\", editor, create_state, alter_state)\n    self.assertColumnExists(\"test_alflfkt_rider\", \"pony\")\n    self.assertColumnNotExists(\"test_alflfkt_rider\", \"pony_id\")\n    # And test reversal\n    with connection.schema_editor() as editor:\n        alter_operation.database_backwards(\"test_alflfkt\", editor, alter_state, create_state)\n    self.assertColumnExists(\"test_alflfkt_rider\", \"pony_id\")\n    self.assertColumnNotExists(\"test_alflfkt_rider\", \"pony\")\n", "def test_create_model_with_deferred_unique_constraint_for_deferrable_database(self):\n    \"\"\"\n    CreateModel ignores deferred unique constraint if the database supports\n    deferrable unique constraints.\n    \"\"\"\n    if not connection.features.supports_deferrable_unique_constraints:\n        self.skipTest(\"Database does not support deferrable unique constraints.\")\n\n    deferred_unique_constraint = models.UniqueConstraint(\n        fields=['pink'],\n        name='deferrable_pink_constraint',\n        deferrable=models.Deferrable.DEFERRED,\n    )\n    operation = migrations.CreateModel(\n        'Pony',\n        [\n            ('id', models.AutoField(primary_key=True)),\n            ('pink', models.IntegerField(default=3)),\n        ],\n        options={'constraints': [deferred_unique_constraint]},\n    )\n    # Test the state alteration\n    project_state = ProjectState()\n    new_state = project_state.clone()\n    operation.state_forwards('test_crmoud', new_state)\n    self.assertEqual(len(new_state.models['test_crmoud', 'pony'].options['constraints']), 1)\n    self.assertTableNotExists('test_crmoud_pony')\n    # Create table.\n    with connection.schema_editor() as editor:\n        operation.database_forwards('test_crmoud', editor, project_state, new_state)\n    self.assertTableExists('test_crmoud_pony')\n    Pony = new_state.apps.get_model('test_crmoud', 'Pony')\n    Pony.objects.create(pink=1)\n    Pony.objects.create(pink=2).delete()\n    # Reversal.\n    with connection.schema_editor() as editor:\n        operation.database_backwards('test_crmoud', editor, new_state, project_state)\n    self.assertTableNotExists('test_crmoud_pony')\n    # Deconstruction.\n    definition = operation.deconstruct()\n    self.assertEqual(definition[0], 'CreateModel')\n    self.assertEqual(definition[1], [])\n    self.assertEqual(\n        definition[2]['options']['constraints'],\n        [deferred_unique_constraint],\n    )\n", "    def test_rename_model_mti_with_self_referential_fk(self):\n        \"\"\"\n        Tests the RenameModel operation on a model which has a superclass that\n        has a self-referential FK.\n        \"\"\"\n        project_state = self.set_up_test_model(\"test_rmwscsrf\", related_model=True, mti_model=True)\n        # Test the state alteration\n        operation = migrations.RenameModel(\"Rider\", \"HorseRider\")\n        self.assertEqual(operation.describe(), \"Rename model Rider to HorseRider\")\n        new_state = project_state.clone()\n        operation.state_forwards(\"test_rmwscsrf\", new_state)\n        self.assertNotIn((\"test_rmwscsrf\", \"rider\"), new_state.models)\n        self.assertIn((\"test_rmwscsrf\", \"horserider\"), new_state.models)\n        # RenameModel shouldn't repoint the superclass's relations, only local ones\n        self.assertEqual(\n            new_state.models[\"test_rmwscsrf\", \"shetlandrider\"].fields['pony'].remote_field.model,\n            new_state.models['test_rmwscsrf', 'shetlandpony'],\n        )\n        self.assertEqual(\n            new_state.models[\"test_rmwscsrf\", \"horserider\"].fields['friend'].remote_field.model,\n            new_state.models[\"test_rmwscsrf\", \"horserider\"],\n        )\n        # Before running the migration we have a table for Rider, not HorseRider\n        self.assertTableExists(\"test_rmwscsrf_rider\")\n        self.assertTableNotExists(\"test_rmwscsrf_horserider\")\n        if connection.features.supports_foreign_keys:\n            # and the foreign key on ShetlandPony points to Pony, not ShetlandPony\n            self.assertFKExists(\"test_rmwscsrf_shetlandpony\", [\"pony_ptr_id\"], (\"test_rmwscsrf_pony\", \"id\"))\n            # and the foreign key on Rider points to Rider, not HorseRider\n            self.assertFKExists(\"test_rmwscsrf_rider\", [\"friend_id\"], (\"test_rmwscsrf_rider\", \"id\"))\n        with connection.schema_editor(atomic=connection.features.supports_atomic_references_rename) as editor:\n            operation.database_forwards(\"test_rmwscsrf\", editor, project_state, new_state)\n        # Now we have a HorseRider table,"], "sample_12": ["def test_alter_field_db_column(self):\n    \"\"\"Tests autodetection of db_column changes.\"\"\"\n    before = [\n        ModelState('app', 'Foo', [\n            ('id', models.AutoField(primary_key=True)),\n            ('field', models.IntegerField(db_column='old_column')),\n        ])\n    ]\n    after = [\n        ModelState('app', 'Foo', [\n            ('id', models.AutoField(primary_key=True)),\n            ('field', models.IntegerField(db_column='new_column')),\n        ])\n    ]\n    changes = self.get_changes(before, after)\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['AlterField'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='field')\n    self.assertEqual(changes['app'][0].operations[0].field.deconstruct(), (\n        'field', 'django.db.models.IntegerField', [], {'db_column': 'new_column'},\n    ))\n", "def test_alter_field_to_swappable(self):\n    \"\"\"\n    Altering a field to a swappable model should create an AlterField operation.\n    \"\"\"\n    before = [\n        ModelState(\"app\", \"Model\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"user\", models.ForeignKey(\"auth.User\", models.CASCADE)),\n        ]),\n    ]\n    with override_settings(AUTH_USER_MODEL=\"a.CustomUser\"):\n        with isolate_lru_cache(apps.get_swappable_settings_name):\n            after = [\n                ModelState(\"app\", \"Model\", [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\"user\", models.ForeignKey(settings.AUTH_USER_MODEL, models.CASCADE)),\n                ]),\n            ]\n            changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'app', 1)\n        self.assertOperationTypes(changes, 'app', 0, [\"AlterField\"])\n        self.assertOperationAttributes(changes, 'app', 0, 0, name=\"user\")\n        fk_field = changes['app'][0].operations[0].field\n        to_model = '%s.%s' % (\n            fk_field.remote_field.model._meta.app_label,\n            fk_field.remote_field.model._meta.object_name,\n        )\n        self.assertEqual(to_model, 'a.CustomUser')\n", "def test_alter_field_related_to_renamed_model(self):\n    \"\"\"\n    Tests that AlterField operations for fields related to renamed models\n    have correct dependencies.\n    \"\"\"\n    before = [\n        ModelState('app', 'Foo', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'Bar', [\n            ('id', models.AutoField(primary_key=True)),\n            ('foo', models.ForeignKey('app.Foo', models.CASCADE)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'RenamedFoo', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'Bar', [\n            ('id', models.AutoField(primary_key=True)),\n            ('renamed_foo', models.ForeignKey('app.RenamedFoo', models.CASCADE)),\n        ]),\n    ]\n    changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename_model': True}))\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, [\"RenameModel\", \"RenameField\", \"AlterField\"])\n    self.assertOperationAttributes(changes, 'app', 0, 0, old_name='Foo', new_name='RenamedFoo')\n    self.assertOperationAttributes(changes, 'app', 0, 1, old_name='foo', new_name='renamed_foo', model_name='bar')\n    self.assertOperationAttributes(changes, 'app', 0, 2, model_name='bar', name='renamed_foo')\n    self.assertMigrationDependencies(changes, 'app', 0, [('app', 'auto_1'), ('app', 'auto_1')])\n", "def test_alter_field_unique_together_dependency(self):\n    \"\"\"\n    #24088 - AlterField depends on unique_together removal.\n    \"\"\"\n    before = [\n        ModelState('app', 'Model', [\n            ('id', models.AutoField(primary_key=True)),\n            ('field1', models.IntegerField()),\n            ('field2', models.IntegerField()),\n        ], {\n            \"unique_together\": {(\"field1\", \"field2\")},\n        })\n    ]\n    after = [\n        ModelState('app', 'Model', [\n            ('id', models.AutoField(primary_key=True)),\n            ('field1', models.CharField(max_length=200)),\n            ('field2', models.IntegerField()),\n        ])\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, [\"AlterUniqueTogether\", \"AlterField\"])\n    self.assertMigrationDependencies(changes, 'app', 0, [])\n", "def test_renamed_base(self):\n    \"\"\"Renaming a model that is inherited from has the correct effect.\"\"\"\n    animal = ModelState(\"testapp\", \"Animal\", [(\"id\", models.AutoField(primary_key=True))])\n    dog = ModelState(\"testapp\", \"Dog\", [], bases=(\"testapp.Animal\",))\n    new_animal = ModelState(\"testapp\", \"Creature\", [(\"id\", models.AutoField(primary_key=True))])\n    changes = self.get_changes([animal, dog], [new_animal, dog], MigrationQuestioner({\"ask_rename_model\": True}))\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"RenameModel\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name=\"Animal\", new_name=\"Creature\")\n    # Now, check that the base changed properly\n    self.assertEqual(changes['testapp'][0].operations[0].bases[0], ('testapp.Creature',))\n"], "sample_6": ["    def test_regex(self):\n        v = UnicodeUsernameValidator()\n        self.assertEqual(v.regex, r'^[\\w.@+-]+\\Z')\n        self.assertEqual(v.flags, 0)\n", "    def test_ascii_flags(self):\n        v = ASCIIUsernameValidator()\n        self.assertEqual(v.flags, re.ASCII)\n", "    def test_unicode_validator_max_length(self):\n        v = validators.UnicodeUsernameValidator()\n        with self.assertRaises(ValidationError):\n            v('a' * 31)\n", "    def test_unicode_validator_flags(self):\n        v = validators.UnicodeUsernameValidator()\n        self.assertEqual(v.flags, 0)\n        self.assertIsNone(v('Ren\u00e9'))  # Matches with the Unicode flag\n", "    def test_regex_validator_valid_input(self):\n        validator = validators.RegexValidator(\n            regex=r'^[a-zA-Z0-9]+$',\n            message='Enter a valid input. This value may contain only English letters and numbers.',\n        )\n        self.assertIsNone(validator('test123'))\n"], "sample_153": ["def test_pretty_printing_unicode_d():\n    assert upretty(d[0]) == '(0|0)'\n    assert upretty(d[1]) == '(i_N|k_N)'\n    assert upretty(d[4]) == '(a) (i_N|k_N)'\n    assert upretty(d[5]) == '(a) (i_N|k_N) + (-b) (j_N|k_N)'\n    assert upretty(d[7]) == upretty_d_7\n    assert upretty(d[10]) == '(cos(a)) (i_C|k_N) + (-sin(a)) (j_C|k_N)'\n", "def test_pretty_print_unicode_d():\n    assert upretty(d[0]) == '(0|0)'\n    assert upretty(d[1]) == '(i_N|k_N)'\n    assert upretty(d[5]) == '(a) (i_N|k_N) + (-b) (j_N|k_N)'\n    assert upretty(d[7]) == upretty_d_7\n    assert upretty(d[10]) == '(cos(a)) (i_C|k_N) + (-sin(a)) (j_C|k_N)'\n", "def test_custom_names_unicode():\n    A = CoordSys3D('A', vector_names=['x', 'y', 'z'],\n                   variable_names=['i', 'j', 'k'])\n    assert upretty(A.i) == 'i_A'\n    assert upretty(A.x) == 'x_A'\n", "def test_function_names():\n    from sympy import sin, cos\n    f = Function('f')\n    assert pretty(sin(x)) == 'sin(x)'\n    assert pretty(cos(x)) == 'cos(x)'\n    assert pretty(f(x)) == 'f(x)'\n    assert pretty(sin(x + 1)) == 'sin(x + 1)'\n    assert pretty(cos(x + 1)) == 'cos(x + 1)'\n    assert pretty(f(x + 1)) == 'f(x + 1)'\n\n    assert upretty(sin(x)) == 'sin(x)'\n    assert upretty(cos(x)) == 'cos(x)'\n    assert upretty(f(x)) == 'f(x)'\n    assert upretty(sin(x + 1)) == 'sin(x + 1)'\n    assert upretty(cos(x + 1)) == 'cos(x + 1)'\n    assert upretty(f(x + 1)) == 'f(x + 1)'\n", "def test_issue_23059():\n    from sympy import symbols, cos, pi, UnevaluatedExpr, Matrix, sin\n\n    x, y = symbols('x y')\n    ten = UnevaluatedExpr(10)\n\n    Bx = 2 * ten**(-4) * cos(ten**5 * x) * sin(ten**(-3) * y)\n    mat = Matrix([[Bx, Bx], [Bx, Bx]])\n\n    mat_str = \"\"\"\\"], "sample_140": ["def test_point_partial_velocity_multiple_gen_speeds():\n    t = dynamicsymbols._t\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    p = Point('p')\n    u1, u2, u3 = dynamicsymbols('u1, u2, u3')\n    p.set_vel(N, u1 * A.x + u2 * N.y + u3 * A.z)\n    assert p.partial_velocity(N, u1, u2, u3) == (A.x, N.y, A.z)\n    assert p.partial_velocity(N, u3, u2, u1) == (A.z, N.y, A.x)\n    assert p.partial_velocity(N, u1) == A.x\n", "def test_point_partial_velocity_with_multiple_generalized_speeds():\n    t = dynamicsymbols._t\n    u1, u2, q1, q2 = dynamicsymbols('u1 u2 q1 q2')\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    p = Point('p')\n    p.set_vel(N, u1 * A.x + u2 * N.y + q1 * N.x + q2 * A.y)\n    assert p.partial_velocity(N, u1, u2) == (A.x, N.y)\n    assert p.partial_velocity(N, q1, q2) == (N.x, A.y)\n    assert p.partial_velocity(N, u1, u2, q1, q2) == (A.x, N.y, N.x, A.y)\n", "def test_auto_point_vel_intermediate_frames():\n    t = dynamicsymbols._t\n    q, q1, q2, u = dynamicsymbols('q q1 q2 u')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    A = ReferenceFrame('A')\n    O = Point('O')\n    O.set_vel(N, u * N.x)\n    P = Point('P')\n    P.set_pos(O, q1 * N.x + q2 * B.y)\n    P1 = Point('P1')\n    P1.set_pos(P, q * A.z)\n    raises(ValueError, lambda: P1.vel(N))\n    N.orient(B, 'Axis', (q, B.x))\n    B.orient(A, 'Axis', (q1, A.y))\n    assert P1.vel(N) == (u + q1.diff(t)) * N.x + q2.diff(t) * B.y - q2 * q.diff(t) * B.z + q.diff(t) * A.z + q1 * q.diff(t) * A.x\n", "def test_set_pos_invalid_input():\n    q = dynamicsymbols('q')\n    N = ReferenceFrame('N')\n    B = N.orientnew('B', 'Axis', [q, N.z])\n    O = Point('O')\n    P = Point('P')\n    raises(TypeError, lambda: P.set_pos(O, 5))  # Test with non-Vector value\n    raises(TypeError, lambda: P.set_pos(5, N.x))  # Test with non-Point otherpoint\n", "def test_auto_point_vel_multiple_connected_frames():\n    t = dynamicsymbols._t\n    q, q1, q2, u, u1 = dynamicsymbols('q q1 q2 u u1')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    C = ReferenceFrame('C')\n    O = Point('O')\n    O.set_vel(N, u * N.x)\n    P = Point('P')\n    P.set_pos(O, q1 * N.x + q2 * B.y)\n    raises(ValueError, lambda: P.vel(N))\n    N.orient(B, 'Axis', (q, B.x))\n    B.orient(C, 'Axis', (q2, C.z))\n    P.vel(N) # To populate P's velocity in frame N\n    assert P.vel(N) == (u + q1.diff(t)) * N.x + (q2.diff(t) - q2 * q.diff(t)) * B.y\n    assert P.vel(B) == (u + q1.diff(t) + q * q2.diff(t)) * B.y\n    P.set_vel(B, u1 * B.z)\n    assert P.vel(B) == u1 * B.z\n    assert P.vel(C) == u1 * C.z\n"], "sample_19": ["    def test_request_accepts_text_html(self):\n        request = self.rf.get('/test_view/', HTTP_ACCEPT='text/html')\n        try:\n            raise ValueError(\"Can't find my keys\")\n        except ValueError:\n            exc_type, exc_value, tb = sys.exc_info()\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/html')\n", "    def test_invalid_request(self):\n        request = object()  # invalid request object\n        exc_type = Exception\n        exc_value = Exception()\n        tb = None\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/plain; charset=utf-8')\n", "    def test_cleansed_multivaluedict(self):\n        filter = SafeExceptionReporterFilter()\n        multivaluedict = MultiValueDict({'sensitive': 'data', 'not_sensitive': 'info'})\n        self.assertEqual(filter.get_cleansed_multivaluedict(None, multivaluedict), multivaluedict)\n\n        request = RequestFactory().get('/')\n        request.sensitive_post_parameters = ['sensitive']\n        self.assertEqual(\n            filter.get_cleansed_multivaluedict(request, multivaluedict),\n            MultiValueDict({'sensitive': '********************', 'not_sensitive': 'info'})\n        )\n\n        request.sensitive_post_parameters = '__ALL__'\n        self.assertEqual(\n            filter.get_cleansed_multivaluedict(request, multivaluedict),\n            MultiValueDict({'sensitive': '********************', 'not_sensitive': '********************'})\n        )\n", "    def test_technical_500_response_html(self):\n        request = self.rf.get('/test_view/')\n        request.user = User()\n        try:\n            raise ValueError(\"Can't find my keys\")\n        except ValueError:\n            exc_type, exc_value, tb = sys.exc_info()\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertContains(response, '<div class=\"context\" id=\"', status_code=500)\n", "    def test_html_response(self):\n        \"A technical 500 error response can be generated\"\n        request = self.rf.get('/test_view/')\n        try:\n            raise ValueError(\"Can't find my keys\")\n        except ValueError:\n            exc_type, exc_value, tb = sys.exc_info()\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/html')\n        self.assertContains(response, '<h1>ValueError at /test_view/</h1>', status_code=500)\n"], "sample_119": ["def test_user_functions():\n    assert mcode(sin(x), user_functions={'sin': 'MySin'}) == \"MySin[x]\"\n    assert mcode(cos(x), user_functions={'cos': 'MyCos'}) == \"MyCos[x]\"\n    assert mcode(sin(x) + cos(x), user_functions={'sin': 'MySin', 'cos': 'MyCos'}) == \"MySin[x] + MyCos[x]\"\n", "def test_UserDefinedFunctions():\n    assert mcode(exp(x), user_functions={'exp': ['Exp']}) == \"Exp[x]\"\n    assert mcode(sin(x), user_functions={'sin': ['Sin']}) == \"Sin[x]\"\n    assert mcode(cos(x), user_functions={'cos': ['Cos']}) == \"Cos[x]\"\n    assert mcode(exp(x) + sin(x) + cos(x), user_functions={'exp': ['Exp'], 'sin': ['Sin'], 'cos': ['Cos']}) == \"Cos[x] + Exp[x] + Sin[x]\"\n", "def test_Decimal_and_Float():\n    from decimal import Decimal\n    assert mcode(Decimal('3.14')) == \"31/10\"\n    assert mcode(3.14) == \"3.14\"\n    assert mcode(1.0*x) == \"1.0*x\"\n    assert mcode(1.5**x) == \"1.5^x\"\n    assert mcode(x**1.5) == \"x^1.5\"\n", "def test_UserFunctions():\n    assert mcode(exp(x), user_functions={'exp': 'my_exp'}) == \"my_exp[x]\"\n    assert mcode(sin(x), user_functions={'sin': 'my_sin'}) == \"my_sin[x]\"\n    assert mcode(sin(x), user_functions={'sin': ['my_sin1', 'my_sin2']}) == \"my_sin1[x]\"\n    assert mcode(sin(x), user_functions={'sin': [(lambda *x: True, 'my_sin1'), (lambda *x: False, 'my_sin2')]}) == \"my_sin1[x]\"\n", "def test_UserFunctions():\n    # test user-defined function\n    assert mcode(f(x), {\"user_functions\": {\"f\": \"myf\"}}) == \"myf[x]\"\n    \n    # test multiple user-defined functions\n    assert mcode(f(x) + g(y), {\"user_functions\": {\"f\": \"myf\", \"g\": \"myg\"}}) == \"myf[x] + myg[y]\"\n\n    # test user-defined function with multiple arguments\n    assert mcode(h(x, y, z), {\"user_functions\": {\"h\": \"myh\"}}) == \"myh[x, y, z]\"\n\n    # test lambda function as a user-defined function\n    assert mcode(f(x), {\"user_functions\": {\"f\": lambda *x: \"myf\"}}) == \"myf[x]\"\n\n    # test condition in user-defined function\n        return x.is_real\n    assert mcode(f(x), {\"user_functions\": {\"f\": [(cond, \"myf\")]}}) == \"f[x]\"\n    assert mcode(f(1), {\"user_functions\": {\"f\": [(cond, \"myf\")]}}) == \"myf[1]\"\n"], "sample_133": ["def test_fcode_cse():\n    a, b, c, d = symbols('a b c d')\n    e = MatrixSymbol('e', 3, 1)\n    name_expr = (\"test\", Matrix([[a*b], [a*b + c*d], [a*b*c*d]]))\n    generator = FCodeGen(cse=True)\n    result = codegen(name_expr, code_gen=generator, header=False, empty=False)\n    source = result[0][1]\n    expected = (\n        \"subroutine test(a, b, c, d, e)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in) :: a\\n\"\n        \"REAL*8, intent(in) :: b\\n\"\n        \"REAL*8, intent(in) :: c\\n\"\n        \"REAL*8, intent(in) :: d\\n\"\n        \"REAL*8, intent(out), dimension(1:3, 1:1) :: e\\n\"\n        \"REAL*8 x0\\n\"\n        \"x0 = a*b\\n\"\n        \"REAL*8 x1\\n\"\n        \"x1 = c*d\\n\"\n        \"e(1, 1) = x0\\n\"\n        \"e(2, 1) = x0 + x1\\n\"\n        \"e(3, 1) = x0*x1\\n\"\n        \"end subroutine\\n\"\n    )\n    assert source == expected\n", "def test_fcode_matrixsymbol_slice_constant():\n    # see issue #8093\n    A = MatrixSymbol('A', 2, 3)\n    name_expr = (\"test\", A[1, 1])\n    result = codegen(name_expr, \"f95\", \"test\", header=False, empty=False)\n    source = result[0][1]\n    expected = (\n        \"subroutine test(A, out_%(hash)s)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in), dimension(1:2, 1:3) :: A\\n\"\n        \"REAL*8, intent(out) :: out_%(hash)s\\n\"\n        \"out_%(hash)s = A(2, 2)\\n\"\n        \"end subroutine\\n\"\n    )\n    # look for the magic number\n    a = source.splitlines()[3]\n    b = a.split('_')\n    out = b[1]\n    expected = expected % {'hash': out}\n    assert source == expected\n", "def test_fcode_matrixsymbol_slice_autoname_real_imag():\n    # see issue #8093\n    A = MatrixSymbol('A', 2, 3)\n    name_expr = (\"test\", A[:, 1].as_real_imag())\n    result = codegen(name_expr, \"f95\", \"test\", header=False, empty=False)\n    source = result[0][1]\n    expected = (\n        \"subroutine test(A, out_%(hash)s, out_%(hash2)s)\\n\"\n        \"implicit none\\n\"\n        \"COMPLEX*16, intent(in), dimension(1:2, 1:3) :: A\\n\"\n        \"REAL*8, intent(out), dimension(1:2, 1:1) :: out_%(hash)s\\n\"\n        \"REAL*8, intent(out), dimension(1:2, 1:1) :: out_%(hash2)s\\n\"\n        \"out_%(hash)s(1, 1) = A(1, 2)\\n\"\n        \"out_%(hash)s(2, 1) = A(2, 2)\\n\"\n        \"out_%(hash2)s(1, 1) = A(1, 2)\\n\"\n        \"out_%(hash2)s(2, 1) = A(2, 2)\\n\"\n        \"end subroutine\\n\"\n    )\n    # look for the magic number\n    a = source.splitlines()[3]\n    b = a.split('_')\n    out = b[1]\n    a = source.splitlines()[4]\n    b = a.split('_')\n    out2 = b[1]\n    expected = expected % {'hash': out, 'hash2': out2}\n    assert source == expected\n", "def test_c_with_custom_dtype():\n    from sympy.printing.ccode import C99CodePrinter\n    class CustomPrinter(C99CodePrinter):\n            return \"myfrac({}, {})\".format(self._print(expr.p), self._print(expr.q))\n\n    x = symbols('x')\n    expr = 2*x/3\n    expected =[\n        (\"file.c\",\n        \"#include \\\"file.h\\\"\\n\"\n        \"#include <math.h>\\n\"\n        \"double test(double x) {\\n\"\n        \"   double test_result;\\n\"\n        \"   test_result = myfrac(2, 3)*x;\\n\"\n        \"   return test_result;\\n\"\n        \"}\\n\"),\n        (\"file.h\",\n        \"#ifndef PROJECT__FILE__H\\n\"\n        \"#define PROJECT__FILE__H\\n\"\n        \"double test(double x);\\n\"\n        \"#endif\\n\")\n    ]\n    result = codegen((\"test\", expr), \"C\",\"file\", header=False, empty=False, printer = CustomPrinter())\n    assert result == expected\n", "def test_fcode_matrixsymbol_slice_autoname_with_matrix_rhs():\n    # see issue #8093\n    A = MatrixSymbol('A', 2, 3)\n    B = MatrixSymbol('B', 2, 1)\n    name_expr = (\"test\", Equality(B, Matrix([[1, 2], [3, 4]])*A[:, 1]))\n    result = codegen(name_expr, \"f95\", \"test\", header=False, empty=False)\n    source = result[0][1]\n    expected = (\n        \"subroutine test(A, B)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in), dimension(1:2, 1:3) :: A\\n\"\n        \"REAL*8, intent(out), dimension(1:2, 1:1) :: B\\n\"\n        \"B(1, 1) = 1*A(1, 2) + 2*A(2, 2)\\n\"\n        \"B(2, 1) = 3*A(1, 2) + 4*A(2, 2)\\n\"\n        \"end subroutine\\n\"\n    )\n    assert source == expected\n"], "sample_148": ["def test_conjugate_and_transpose_matrix():\n    a = Symbol('a', real=True)\n    b = Symbol('b', real=True)\n    A = Matrix([[a + b*I, a + b*I], [b*I, a + b*I]])\n    assert conjugate(A) == Matrix([[a - b*I, a - b*I], [-b*I, a - b*I]])\n    assert transpose(A) == Matrix([[a + b*I, b*I], [a + b*I, a + b*I]])\n    assert adjoint(A) == Matrix([[a - b*I, -b*I], [a - b*I, a - b*I]])\n    assert conjugate(transpose(A)) == Matrix([[a - b*I, -b*I], [a - b*I, a - b*I]])\n    assert transpose(conjugate(A)) == Matrix([[a - b*I, -b*I], [a - b*I, a - b*I]])\n", "def test_principal_branch_polar():\n    from sympy import principal_branch, exp_polar, I, pi\n    x = Symbol('x')\n    p = Symbol('p', positive=True)\n    assert principal_branch(x, 2*pi) == principal_branch(principal_branch(x, 2*pi), 2*pi)\n    assert principal_branch(x + I, p) == principal_branch(x + I, principal_branch(p, 2*pi))\n    assert principal_branch(exp_polar(2*pi*I)*x, p) == principal_branch(exp_polar(0)*x, p)\n    assert principal_branch(exp_polar(pi*I)*x, p) == principal_branch(-x, p)\n    assert principal_branch(principal_branch(exp_polar(pi*I)*x, 2*pi), p) == principal_branch(-x, p)\n", "def test_polar_lift():\n    assert polar_lift(0) == 0\n    assert polar_lift(1) == 1\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(-I*pi/2)\n    assert polar_lift(-I) == exp_polar(I*pi/2)\n    assert polar_lift(2*I) == 2*exp_polar(-I*pi/2)\n    assert polar_lift(-2*I) == 2*exp_polar(I*pi/2)\n    assert polar_lift(2) == 2\n    assert polar_lift(-2) == 2*exp_polar(I*pi)\n    assert polar_lift(2 + I) == polar_lift(2 + I)\n    assert polar_lift(-2 + I) == polar_lift(-2 + I)\n    assert polar_lift(-2 - I) == polar_lift(-2 - I)\n    assert polar_lift(2 - I) == polar_lift(2 - I)\n    assert polar_lift(1 + sqrt(2)) == 1 + sqrt(2)\n    assert polar_lift(sqrt(2) + I) == polar_lift(sqrt(2) + I)\n    assert polar_lift(-sqrt(2) + I) == polar_lift(-sqrt(2) + I)\n    assert polar_lift(-sqrt(2) - I) == polar_lift(-sqrt(2) - I)\n    assert polar_lift(sqrt(2) - I) == polar_lift(sqrt(2) - I)\n\n    #test arguments\n    assert polar_lift(0, evaluate=False) == 0\n    assert polar_lift(1, evaluate=False) == 1\n    assert polar_lift(-1, evaluate=False) == -1\n    assert polar_lift(I, evaluate=False) == I\n    assert polar_lift(-I, evaluate=False) == -I\n    assert polar_lift(2*I, evaluate=False) == 2*I\n    assert polar_lift(-2*I, evaluate=False) == -2*I\n    assert polar_lift(2, evaluate=False) == 2\n    assert polar_lift(-2, evaluate=False) == -2\n    assert polar_lift(2 + I, evaluate=False) == 2 + I\n    assert polar_lift(-2 + I, evaluate=False) == -2 + I\n    assert polar_lift(-2 - I, evaluate=False) == -2 - I\n    assert polar_lift", "def test_polar_lift():\n    from sympy import symbols\n    x, y = symbols('x y')\n\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n\n    assert polar_lift(x) == polar_lift(x)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n\n    assert polar_lift(2*I) == exp_polar(I*pi/2)\n    assert polar_lift(-2*I) == exp_polar(-I*pi/2)\n    assert polar_lift(2 + I) == polar_lift(2 + I)\n\n    assert polar_lift(x*I) == polar_lift(x)*exp_polar(I*pi/2)\n    assert polar_lift(x - I) == polar_lift(x - I)\n\n    assert polar_lift(exp_polar(I*pi)) == exp_polar(I*pi)\n\n    # check that only numbers are lifted\n    assert polar_lift(x + 2).args == (x, 2)\n    assert polar_lift(2 + y*I).args == (2, y)\n", "def test_polar_lift():\n    x, y = symbols('x y')\n    a = Symbol('a', positive=True)\n\n    assert polar_lift(1) == 1*exp_polar(0)\n    assert polar_lift(-1) == 1*exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(-I*pi/2)\n    assert polar_lift(1 + I) == polar_lift(1 + I)\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(3 + 2*I) == polar_lift(3 + 2*I)\n    assert polar_lift(3*a) == 3*polar_lift(a)\n\n    assert polar_lift(x) == polar_lift(x)\n    assert polar_lift(x*I) == polar_lift(x*I)\n    assert polar_lift(y*I) == polar_lift(y*I)\n    assert polar_lift(x + y*I) == polar_lift(x + y*I)\n    assert polar_lift(x + 2*I) == polar_lift(x + 2*I)\n    assert polar_lift(x + I*y) == polar_lift(x + I*y)\n    assert polar_lift(x + 2*I*y) == polar_lift(x + 2*I*y)\n\n    assert polar_lift(S.NegativeOne) == -1\n    assert polar_lift(S.Zero) == 0\n\n    assert polar_lift(I*x) == exp_polar(-I*pi/2)*x\n    assert polar_lift(-I*x) == exp_polar(I*pi/2)*x\n    assert polar_lift(-x) == exp_polar(I*pi)*x\n\n    assert polar_lift(x).as_real_imag() == (x, 0)\n    assert polar_lift(I*x).as_real_imag() == (0, -x)\n    assert polar_lift(-I*x).as_real_imag() == (0, x)\n    assert polar_lift(-x).as_real_imag() == (-x, 0)\n\n    assert polar_lift(a).is_polar\n    assert polar_lift(x).is_polar\n    assert polar_lift(I*x).is_polar\n    assert polar_lift(-I*x).is_polar\n    assert polar_lift(-x).is_polar\n"], "sample_23": ["def test_distinct_with_values(self):\n    ReservedName.objects.create(name='a', order=2)\n    ReservedName.objects.create(name='b', order=2)\n    qs = ReservedName.objects.values('order').distinct().order_by('order')\n    self.assertEqual(list(qs), [{'order': 2}])\n", "def test_union_with_values_and_distinct(self):\n    ReservedName.objects.create(name='a', order=2)\n    ReservedName.objects.create(name='b', order=2)\n    qs1 = ReservedName.objects.values('order')\n    qs2 = ReservedName.objects.values('order')\n    reserved_names = qs1.union(qs2).distinct().order_by('order')\n    self.assertEqual(list(reserved_names), [(2,)])\n", "def test_union_with_deferred_model(self):\n    qs1 = Number.objects.all()\n    qs2 = Number.objects.defer('num')\n    self.assertNumbersEqual(qs1.union(qs2), list(range(10)))\n", "def test_union_with_values_and_order_on_annotated_and_unannotated(self):\n    ReservedName.objects.create(name='rn1', order=1)\n    ReservedName.objects.create(name='rn2', order=2)\n    qs1 = ReservedName.objects.annotate(\n        has_reserved_name=Exists(ReservedName.objects.filter(order=OuterRef('num')))\n    ).filter(has_reserved_name=True).values('id', 'order', 'name')\n    qs2 = Number.objects.filter(num=9).values('num', 'other_num', 'id')\n    self.assertCountEqual(qs1.union(qs2).order_by('-order').values_list('order', flat=True), [9, 2, 1])\n    self.assertCountEqual(qs1.union(qs2).order_by('order').values_list('order', flat=True), [1, 2, 9])\n", "def test_values_list_with_flat_and_named(self):\n    ReservedName.objects.create(name='rn1', order=1)\n    ReservedName.objects.create(name='rn2', order=2)\n    qs = ReservedName.objects.values_list('name', flat=True)\n    msg = \"'flat' and 'named' can't be used together.\"\n    with self.assertRaisesMessage(TypeError, msg):\n        qs.named = True\n    qs = ReservedName.objects.values_list('name', named=True)\n    msg = \"Cannot pass 'flat' and 'named' to values_list() together.\"\n    with self.assertRaisesMessage(ValueError, msg):\n        qs.flat = True\n"], "sample_146": ["def test_ConditionSet():\n    x = symbols('x')\n    assert str(ConditionSet(x, x>0, S.UniversalSet)) == 'ConditionSet(x, x > 0)'\n    assert str(ConditionSet(x, x>0, Interval(0, 1))) == 'ConditionSet(x, x > 0, Interval(0, 1))'\n    assert str(ConditionSet(x, x>0, Interval(1, 2))) == 'ConditionSet(x, x > 0, Interval(1, 2))'\n    assert str(ConditionSet(x, x>0, Interval(-1, 1))) == 'ConditionSet(x, x > 0, Interval(-1, 1))'\n", "def test_UnevaluatedExpr_Mul():\n    from sympy import UnevaluatedExpr\n    assert str(2*UnevaluatedExpr(x+y)) == \"2*(x + y)\"\n    assert str(-2*UnevaluatedExpr(x+y)) == \"-2*(x + y)\"\n    assert str(2*UnevaluatedExpr(x+y)*3) == \"6*(x + y)\"\n    assert str(-2*UnevaluatedExpr(x+y)*3) == \"-6*(x + y)\"\n    assert str(UnevaluatedExpr(x+y)*2*3) == \"6*(x + y)\"\n    assert str(UnevaluatedExpr(x+y)*-2*3) == \"-6*(x + y)\"\n", "def test___print_Subs_on_MatMul():\n    x, y, z = symbols('x y z')\n    A = MatrixSymbol('A', 3, 3)\n    B = MatrixSymbol('B', 3, 3)\n    AB = A*B\n    assert str(Subs(AB, (x, y), (z, z))) == 'Subs(A*B, (x, y), (z, z))'\n", "def test_circular_reference():\n    # Test for circular references.\n    # See issue 12620\n\n    from sympy.printing.str import StrPrinter\n\n    class CircularReference:\n            self.name = name\n            self.a = None\n            self.b = None\n\n            return StrPrinter().doprint(self)\n\n    a = CircularReference('a')\n    b = CircularReference('b')\n\n    a.a = a\n    a.b = b\n\n    b.a = a\n    b.b = b\n\n    sstr(a)\n    sstr(b)\n", "def test_issue_XXXXX():\n    from sympy import Expr, Tuple, sqrt, UnevaluatedExpr\n    from sympy.tensor.array.expressions.array_expressions import ArraySymbol, ArrayElement\n    # Your test code here\n    a, b = symbols(\"a b\")\n    expr1 = UnevaluatedExpr(sqrt(a+b))\n    expr2 = UnevaluatedExpr(Tuple(a,b))\n    expr3 = UnevaluatedExpr(ArraySymbol(\"A\"))\n    expr4 = UnevaluatedExpr(ArrayElement(\"A\", (2,1)))\n    expr5 = UnevaluatedExpr(Expr(1, 2))\n    assert str(expr1) == \"sqrt(a + b)\"\n    assert str(expr2) == \"(a, b)\"\n    assert str(expr3) == \"A\"\n    assert str(expr4) == \"A[2, 1]\"\n    assert str(expr5) == \"Expr(1, 2)\"\n"], "sample_17": ["    def test_create_test_db(self, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            test_db_name = creation.create_test_db(verbosity=0, autoclobber=True, serialize=False, keepdb=False)\n            self.assertEqual(test_db_name, TEST_DATABASE_PREFIX + old_database_name)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n", "    def test_destroy_test_db(self):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        test_database_name = creation._get_test_db_name()\n        with mock.patch.object(creation, '_destroy_test_db') as mocked_destroy_test_db:\n            creation.destroy_test_db(verbosity=1)\n        mocked_destroy_test_db.assert_called_once_with(test_database_name, 1)\n", "    def test_create_clone_destroy_test_db(self, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            test_database_name = creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n            cloned_database_name = creation.clone_test_db(suffix='clone', verbosity=0, autoclobber=True, keepdb=False)\n            self.assertEqual(cloned_database_name, test_connection.settings_dict['NAME'] + '_clone')\n            creation.destroy_test_db(old_database_name, verbosity=0, keepdb=False, suffix='clone')\n        finally:\n            creation.destroy_test_db(old_database_name, verbosity=0)\n", "    def test_serialize_db_to_string(self):\n        # serialize_db_to_string() serializes all data in the database.\n        obj = Object.objects.create()\n        obj_ref = ObjectReference.objects.create(obj=obj)\n        obj.obj_ref = obj_ref\n        obj.save()\n        serialized_data = connection.creation.serialize_db_to_string()\n        # The serialized data should include both objects.\n        self.assertIn('Object', serialized_data)\n        self.assertIn('ObjectReference', serialized_data)\n        self.assertIn(str(obj.id), serialized_data)\n        self.assertIn(str(obj_ref.id), serialized_data)\n", "    def test_clone_test_db(self):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        with mock.patch.object(creation, '_clone_test_db') as mocked_clone:\n            creation.clone_test_db('suffix', verbosity=1, autoclobber=False, keepdb=False)\n            mocked_clone.assert_called_once_with('suffix', 1, False)\n"], "sample_99": ["def test_kneighbors_graph_sparse_dtype():\n    # Test kneighbors_graph to build the k-Nearest Neighbor graph\n    # for sparse input with different dtypes.\n    rng = np.random.RandomState(36)\n    X = rng.randn(10, 10)\n    Xcsr = csr_matrix(X, dtype='float32')\n\n    for n_neighbors in [1, 2, 3]:\n        for mode in [\"connectivity\", \"distance\"]:\n            assert_array_almost_equal(\n                neighbors.kneighbors_graph(X,\n                                           n_neighbors,\n                                           mode=mode).toarray(),\n                neighbors.kneighbors_graph(Xcsr,\n                                           n_neighbors,\n                                           mode=mode).toarray())\n", "def test_kneighbors_regressor_callable_weights():\n    # Test k-neighbors in multi-output regression with callable weights\n    rng = check_random_state(0)\n    n_features = 5\n    n_samples = 40\n    n_output = 4\n\n    X = rng.rand(n_samples, n_features)\n    y = rng.rand(n_samples, n_output)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\n    for algorithm in ALGORITHMS:\n        weights = lambda dist: 1 / dist\n        knn = neighbors.KNeighborsRegressor(weights=weights,\n                                            algorithm=algorithm)\n        knn.fit(X_train, y_train)\n\n        neigh_idx = knn.kneighbors(X_test, return_distance=True)\n        y_pred_idx = np.array([np.average(y_train[idx], axis=0, weights=1.0/dist)\n                               for idx, dist in zip(neigh_idx[1], neigh_idx[0])])\n\n        y_pred = knn.predict(X_test)\n\n        assert_equal(y_pred_idx.shape, y_test.shape)\n        assert_equal(y_pred.shape, y_test.shape)\n        assert_array_almost_equal(y_pred, y_pred_idx)\n", "def test_kneighbors_regressor_sparse_matrix():\n    # Test k-neighbors regression on sparse matrices\n\n    # Create sparse matrix\n    X_sparse = csr_matrix(np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]))\n\n    # Create target variable\n    y = np.array([1, 2, 3])\n\n    # Create a k-neighbors regressor\n    knn = neighbors.KNeighborsRegressor(n_neighbors=2, algorithm='auto')\n\n    # Fit the model\n    knn.fit(X_sparse, y)\n\n    # Predict\n    y_pred = knn.predict(X_sparse)\n\n    # Test the prediction\n    assert_array_almost_equal(y_pred, y)\n", "def test_neighbors_base_init():\n    # Test the base class for nearest neighbors estimators.\n    nn = neighbors.NeighborsBase(n_neighbors=5,\n                                 radius=1.0,\n                                 algorithm='auto',\n                                 leaf_size=10,\n                                 metric='minkowski',\n                                 p=2,\n                                 metric_params=None,\n                                 n_jobs=1)\n    assert_equal(nn.n_neighbors, 5)\n    assert_equal(nn.radius, 1.0)\n    assert_equal(nn.algorithm, 'auto')\n    assert_equal(nn.leaf_size, 10)\n    assert_equal(nn.metric, 'minkowski')\n    assert_equal(nn.metric_params, None)\n    assert_equal(nn.p, 2)\n    assert_equal(nn.n_jobs, 1)\n\n    # Test the check of algorithm and metric\n    assert_raises(ValueError, neighbors.NeighborsBase,\n                  n_neighbors=5, radius=1.0, algorithm='wrong')\n\n    # Test the check of metric when p is not valid\n    assert_raises(ValueError, neighbors.NeighborsBase,\n                  n_neighbors=5, radius=1.0, metric='minkowski', p=0.5)\n", "def test_neighbors_input_validation():\n    # Test input validation for neighbors methods\n    X = np.array([[0, 1], [1, 0]])\n    y = np.array([0, 0])\n\n    # Test for zero-sized training set\n    nbrs = neighbors.KNeighborsClassifier(n_neighbors=1)\n    assert_raises(ValueError, nbrs.fit, np.zeros((0, 2)), y)\n\n    # Test for zero-sized test set\n    nbrs = neighbors.KNeighborsClassifier(n_neighbors=1)\n    nbrs.fit(X, y)\n    assert_raises(ValueError, nbrs.kneighbors, np.zeros((0, 2)))\n\n    # Test for mismatch between n_samples and n_features\n    nbrs = neighbors.KNeighborsClassifier(n_neighbors=1)\n    assert_raises(ValueError, nbrs.fit, np.zeros((2, 3)), np.zeros((3,)))\n\n    # Test for mismatch between n_samples and n_outputs\n    nbrs = neighbors.KNeighborsClassifier(n_neighbors=1)\n    assert_raises(ValueError, nbrs.fit, np.zeros((3, 2)), np.zeros((2,)))\n\n    # Test for mismatch between n_samples and n_targets\n    nbrs = neighbors.KNeighborsRegressor(n_neighbors=1)\n    assert_raises(ValueError, nbrs.fit, np.zeros((3, 2)), np.zeros((2,)))\n"], "sample_34": ["    def test_abstract_model_inheritance(self):\n        class AbstractModel(models.Model):\n            class Meta:\n                abstract = True\n\n        class ChildModel(AbstractModel):\n            pass\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n", "    def test_abstract_model_without_fields(self):\n        class AbstractModel(models.Model):\n            class Meta:\n                abstract = True\n\n        class Model(AbstractModel):\n            pass\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n", "    def test_fields_cache_descriptor(self):\n        class TestModel(models.Model):\n            field1 = models.CharField(max_length=20)\n            field2 = models.CharField(max_length=20)\n\n        test_model = TestModel()\n        self.assertEqual(test_model.fields_cache, {})\n        self.assertNotEqual(id(test_model.fields_cache), id(ModelStateFieldsCacheDescriptor.__get__(None)))\n", "    def test_multiple_m2m_fields_same_intermediary_model(self):\n        class Intermediary(models.Model):\n            pass\n\n        class Model(models.Model):\n            field1 = models.ManyToManyField('self', through=Intermediary)\n            field2 = models.ManyToManyField('self', through=Intermediary)\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"The model has two identical many-to-many relations through \"\n                \"the intermediate model 'check_framework.Intermediary'.\",\n                obj=Model,\n                id='models.E003',\n            ),\n        ])\n", "    def test_abstract_model_inheritance(self):\n        class AbstractModel(models.Model):\n            class Meta:\n                abstract = True\n\n        class ConcreteModel(AbstractModel):\n            pass\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n"], "sample_123": ["def test_issue_4122():\n    x = Symbol('x', nonpositive=True)\n    assert (oo + x).is_Add\n    x = Symbol('x', finite=True)\n    assert (oo + x).is_Add  # x could be imaginary\n    x = Symbol('x', nonnegative=True)\n    assert oo + x == oo\n    x = Symbol('x', finite=True, real=True)\n    assert oo + x == oo\n\n    # similarily for negative infinity\n    x = Symbol('x', nonnegative=True)\n    assert (-oo + x).is_Add\n    x = Symbol('x', finite=True)\n    assert (-oo + x).is_Add\n    x = Symbol('x', nonpositive=True)\n    assert -oo + x == -oo\n    x = Symbol('x', finite=True, real=True)\n    assert -oo + x == -oo\n", "def test_issue_12573():\n    assert igcd(1, 2**1000000) == 1\n", "def test_issue_13749():\n    assert (Integer(0)/Float(1.0))._evalf(15) == Float(0)\n    assert (Float(1.0)/Integer(0))._evalf(15) == Float('inf')\n    assert (Float(0.0)/Integer(0))._evalf(15) == Float('nan')\n", "def test_comparisons():\n    assert (Rational(2, 3) > Rational(1, 3)) is True\n    assert (Rational(2, 3) > Rational(3, 4)) is True\n    assert (Rational(2, 3) < Rational(3, 4)) is False\n    assert (Rational(2, 3) < Rational(3, 5)) is False\n    assert (Rational(2, 3) <= Rational(2, 3)) is True\n    assert (Rational(2, 3) >= Rational(2, 3)) is True\n    assert (Rational(2, 3) <= Rational(3, 4)) is False\n    assert (Rational(2, 3) >= Rational(3, 4)) is True\n", "def test_comp_with_zero():\n    # issue 11732\n    assert comp(0, 0.0, 1e-10)\n    assert comp(0, 0.00001, 1e-10)\n    assert comp(0, -0.00001, 1e-10)\n    assert not comp(0, 0.001, 1e-10)\n    assert comp(0, 0.0000001, 1e-10)\n    assert not comp(0, -0.0000001, 1e-10)\n    assert comp(0, S(0.0), 1e-10)\n    assert comp(0, S(1e-7), 1e-10)\n    assert comp(0, S(-1e-7), 1e-10)\n    assert not comp(0, S(0.001), 1e-10)\n    assert comp(0, Float(1e-7), 1e-10)\n    assert comp(0, Float(-1e-7), 1e-10)\n    assert not comp(0, Float(0.001), 1e-10)\n\n    assert comp(0, Rational('0.00001'), 1e-10)\n    assert comp(0, Rational('-0.00001'), 1e-10)\n    assert not comp(0, Rational('0.001'), 1e-10)\n    assert comp(0, Rational('0.0000001'), 1e-10)\n    assert not comp(0, Rational('-0.0000001'), 1e-10)\n\n    assert not comp(0, 0.0, 1e-15)\n    assert comp(0, 0.00001, 1e-15)\n    assert comp(0, -0.00001, 1e-15)\n    assert not comp(0, 0.0000001, 1e-15)\n    assert comp(0, -0.0000001, 1e-15)\n"], "sample_149": ["def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n", "def test_MonomialOps():\n    u = MonomialOps(2)\n    assert u.mul()((1, 2), (3, 4)) == (4, 6)\n    assert u.pow()( (1, 2), 3) == (3, 6)\n    assert u.mulpow()( (1, 2), (3, 4), 2) == (7, 10)\n    assert u.ldiv()((3, 4), (1, 2)) == (2, 2)\n    assert u.div()((3, 4), (1, 2)) == (2, 2)\n    assert u.gcd()((3, 4), (1, 2)) == (1, 2)\n    assert u.lcm()((3, 4), (1, 2)) == (3, 4)\n", "def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n    assert monomial_ldiv((1, 2, 3), (0, 0, 0)) == (1, 2, 3)\n", "def test_itermonomials_with_non_integer_variables():\n    from sympy import symbols, sqrt, root\n    x, y = symbols('x y')\n    assert set(itermonomials([x**sqrt(2), y**root(3, 2)], 2)) == {1, x**(sqrt(2)*2), y**(2*root(3, 2)), x**sqrt(2)*y**root(3, 2)}\n", "def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n    assert monomial_ldiv((0, 0, 0), (1, 2, 0)) == (-1, -2, 0)\n"], "sample_46": ["    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(),\n            ['suffix1', 'suffix2'], ['opclass1', 'opclass2']\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(), col_suffixes=('ASC', 'DESC'), opclasses=('varchar_pattern_ops', 'text_pattern_ops')\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'],\n            lambda column: column.upper(), col_suffixes=['ASC', 'DESC'],\n            opclasses=['bt_text_pattern_ops', 'bt_text_pattern_ops'],\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['column'], lambda column: column.upper(), \n            col_suffixes=['ASC', 'DESC'], opclasses=['varchar_pattern_ops', 'text_pattern_ops']\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['column'], lambda column: column.upper(), ('ASC',), ('btree',)\n        )\n"], "sample_93": ["def test_tmp_path_factory_basetemp_removes_old(pytester: Pytester) -> None:\n    mytemp = pytester.path.joinpath(\"xyz\")\n    p = pytester.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    pytester.runpytest(p, \"--basetemp=%s\" % mytemp)\n    assert mytemp.exists()\n    mytemp.joinpath(\"hello\").touch()\n\n    pytester.runpytest(p, \"--basetemp=%s\" % mytemp)\n    assert mytemp.exists()\n    assert not mytemp.joinpath(\"hello\").exists()\n", "def test_tmp_path_factory_from_config_with_absolute_path(pytester: Pytester, monkeypatch: MonkeyPatch) -> None:\n    \"\"\"Test that TempPathFactory.from_config() handles absolute paths correctly.\"\"\"\n    mytemp = pytester.path.joinpath(\"xyz\")\n    mytemp.mkdir()\n    monkeypatch.setenv(\"PYTEST_DEBUG_TEMPROOT\", str(mytemp))\n    config = cast(Config, FakeConfig(mytemp))\n    t = TempPathFactory.from_config(config, _ispytest=True)\n    assert t.getbasetemp().resolve() == mytemp.resolve()\n", "def test_mktemp_numbered_false(tmp_path_factory: TempPathFactory) -> None:\n    \"\"\"Test that mktemp with numbered=False creates a directory without a number.\"\"\"\n    basename = \"test_dir\"\n    dir_path = tmp_path_factory.mktemp(basename, numbered=False)\n    assert dir_path.name == basename\n    assert not dir_path.exists()\n\n    # Create the directory\n    dir_path.mkdir()\n\n    # Try to create the same directory again\n    with pytest.raises(FileExistsError):\n        tmp_path_factory.mktemp(basename, numbered=False)\n", "    def test_mktemp_relative_path_with_numbered(self, tmp_path):\n        config = FakeConfig(tmp_path)\n        t = TempPathFactory.from_config(config, _ispytest=True)\n        basename = \"relative/path\"\n        tmp = t.mktemp(basename, numbered=True)\n        assert tmp.resolve().parent == t.getbasetemp().resolve()\n", "def test_getbasetemp_from_config(pytester: Pytester, monkeypatch: MonkeyPatch) -> None:\n    \"\"\"Test that TempPathFactory correctly handles the --basetemp option.\"\"\"\n    mytemp = pytester.path.joinpath(\"xyz\")\n    pytester.runpytest(\"--basetemp=%s\" % mytemp)\n    config = pytest.config.get_config()\n    tmp_path_factory = TempPathFactory.from_config(config, _ispytest=True)\n    assert tmp_path_factory.getbasetemp().resolve() == mytemp.resolve()\n\n    monkeypatch.setattr(\"pytest.config.get_config().option.basetemp\", None)\n    pytester.runpytest()\n    tmp_path_factory = TempPathFactory.from_config(config, _ispytest=True)\n    assert tmp_path_factory.getbasetemp().name.startswith(\"pytest-of-\")\n\n    monkeypatch.setattr(\"pytest.config.get_config().option.basetemp\", \"/invalid/path\")\n    pytester.runpytest()\n    with pytest.raises(ValueError):\n        TempPathFactory.from_config(config, _ispytest=True).getbasetemp()\n"], "sample_16": ["    def test_reverse_field_path(self):\n        model, path = reverse_field_path(Article, \"site\")\n        self.assertEqual(model, Site)\n        self.assertEqual(path, \"article_set\")\n", "def test_get_deleted_objects(self):\n    \"\"\"\n    Tests for get_deleted_objects\n    \"\"\"\n    article = Article.objects.create(title='Test article')\n    event = Event.objects.create(name='Test event')\n\n    to_delete, model_count, perms_needed, protected = get_deleted_objects([article], None, None)\n    self.assertEqual(to_delete, ['article: Test article'])\n    self.assertEqual(model_count, {'articles': 1})\n    self.assertEqual(perms_needed, set())\n    self.assertEqual(protected, [])\n\n    to_delete, model_count, perms_needed, protected = get_deleted_objects([event], None, None)\n    self.assertEqual(to_delete, ['event: Test event'])\n    self.assertEqual(model_count, {'events': 1})\n    self.assertEqual(perms_needed, set())\n    self.assertEqual(protected, [])\n\n    location = Location.objects.create(name='Test location')\n    event.location = location\n    event.save()\n\n    to_delete, model_count, perms_needed, protected = get_deleted_objects([location], None, None)\n    self.assertEqual(to_delete, ['location: Test location', ['event: Test event']])\n    self.assertEqual(model_count, {'locations': 1, 'events': 1})\n    self.assertEqual(perms_needed, set())\n    self.assertEqual(protected, [])\n\n    EventGuide.objects.create(event=event)\n\n    to_delete, model_count, perms_needed, protected = get_deleted_objects([location], None, None)\n    self.assertEqual(to_delete, ['location: Test location', ['event: Test event']])\n    self.assertEqual(model_count, {'locations': 1, 'events': 1})\n    self.assertEqual(perms_needed, set())\n    self.assertEqual(protected, ['eventguide: EventGuide object'])\n\n    article.delete()\n    to_delete, model_count, perms_needed, protected = get_deleted_objects([event], None, None)\n    self.assertEqual(to_delete, ['event: Test event'])\n    self.assertEqual(model_count, {'events': 1})\n    self.assertEqual(perms_needed, set())\n    self.assertEqual(protected, ['eventguide: EventGuide object'])\n", "    def setUp(self):\n        self.opts = Article._meta\n", "    def test_reverse_field_path(self):\n        \"\"\"\n        Test for reverse_field_path\n        \"\"\"\n        self.assertEqual(\n            reverse_field_path(Article, \"site__url\"),\n            (Site, \"article__site\")\n        )\n        self.assertEqual(\n            reverse_field_path(Event, \"location__address__street\"),\n            (Address, \"location__event__location\")\n        )\n", "    def test_lookup_needs_distinct(self):\n        \"\"\"\n        Test lookup_needs_distinct() for m2m and non-m2m relations.\n        \"\"\"\n        class TestModel(models.Model):\n            m2m_field = models.ManyToManyField('self')\n\n        class NonM2MModel(models.Model):\n            fk_field = models.ForeignKey('self', on_delete=models.CASCADE)\n\n        opts = TestModel._meta\n        self.assertTrue(lookup_needs_distinct(opts, 'm2m_field'))\n\n        opts = NonM2MModel._meta\n        self.assertFalse(lookup_needs_distinct(opts, 'fk_field'))\n"], "sample_82": ["def test_groupby_bins_scalar_argument(array):\n    bins = 2\n    with raises_regex(TypeError, \"bins must be array-like\"):\n        array.groupby_bins(\"x\", bins=bins)\n", "def test_da_groupby_inverse_permutation():\n    array = xr.DataArray(\n        data=[1, 2, 3, 4, 5, 6],\n        dims=[\"x\"],\n        coords={\n            \"x\": [1, 1, 2, 2, 2, 3],\n        },\n    )\n    group = array.groupby(\"x\")\n    expected = [0, 0, 1, 2, 2, 2]\n    actual = group._group_indices\n    assert expected == actual\n", "def test_groupby_empty_groups_from_reduce():\n    # regression test for GH2154\n    array = xr.DataArray(\n        [1, 2, 3, 4, 5, 6], [(\"x\", [1, 1, 1, 2, 2, 2])], name=\"foo\"\n    )\n    actual = array.groupby(\"x\").reduce(np.min, dim=\"x\", keep_attrs=True)\n    expected = xr.DataArray(\n        [1, 4], [(\"x\", [1, 2])], name=\"foo\", attrs=array.attrs\n    )\n    assert_identical(expected, actual)\n", "def test_groupby_stack_with_group_dim():\n    # regression test for GH2745\n    times = pd.date_range(\"2000-01-01\", periods=12)\n    x = [1, 2]\n    foo = xr.DataArray(\n        np.arange(12 * 2).reshape(12, 2),\n        coords={\"time\": times, \"x\": x},\n        dims=(\"time\", \"x\"),\n    )\n    g = foo.groupby(foo.time.dt.month)\n\n    stacked = foo.stack({\"space\": (\"time\", \"x\")})\n    actual = stacked.groupby(g).mean()\n    expected = foo.mean(\"time\").stack({\"space\": (\"time\", \"x\")})\n    assert_identical(expected, actual)\n\n    stacked = foo.stack({\"space\": (\"x\", \"time\")})\n    actual = stacked.groupby(g).mean()\n    expected = foo.mean(\"time\").stack({\"space\": (\"x\", \"time\")})\n    assert_identical(expected, actual)\n", "def test_da_groupby_datetime_index():\n    # Test for groupby over a DataArray with a datetime index\n    times = pd.date_range(\"2000-01-01\", periods=4)\n    foo = xr.DataArray([1, 2, 3, 4], coords={\"time\": times}, dims=\"time\")\n\n    # Test for different grouping frequencies\n    for freq in [\"D\", \"2D\", \"M\"]:\n        g = foo.groupby(\"time.\" + freq)\n        actual = g.sum()\n        expected = foo.resample(time=freq).sum()\n        assert_identical(expected, actual)\n\n    # Test for grouping over the month attribute\n    g = foo.groupby(\"time.month\")\n    actual = g.sum()\n    expected = foo.groupby(foo.time.dt.month).sum()\n    assert_identical(expected, actual)\n"], "sample_20": ["    def test_model_field_pk(self):\n        class Model(models.Model):\n            field_pk = models.IntegerField(primary_key=True)\n\n        self.assertEqual(Model.check(), [])\n", "    def test_proxy_model_without_parent_model(self):\n        class Model(models.Model):\n            pass\n\n        class ProxyModel(Model):\n            class Meta:\n                proxy = True\n\n        self.assertEqual(ProxyModel._meta.proxy_for_model, Model)\n", "    def test_unique_constraint_with_model_instance(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                constraints = [models.UniqueConstraint(instance=models.Q(age__gte=18), name='is_adult')]\n\n        error = Error(\n            \"'constraints' must be a list of Constraint instances, \"\n            \"not a list of instances of type 'Q'.\",\n            obj=Model,\n            id='models.E035',\n        )\n        self.assertEqual(Model.check(databases=self.databases), [error])\n", "    def test_model_base_model(self):\n        class ModelBaseSubclass(ModelBase):\n            pass\n\n        class Model(metaclass=ModelBaseSubclass):\n            pass\n\n        self.assertEqual(Model.check(), [])\n", "    def test_model_with_non_string_name(self):\n        class Model(metaclass=ModelBase):\n            pass\n\n        with self.assertRaises(TypeError):\n            type(1, (ModelBase,), {})\n"], "sample_136": ["def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', n, m)\n    X = BlockMatrix([[A, B]])\n\n    X_real, X_imag = X.as_real_imag()\n\n    assert X_real.blocks[0, 0] == re(A)\n    assert X_real.blocks[0, 1] == re(B)\n    assert X_imag.blocks[0, 0] == im(A)\n    assert X_imag.blocks[0, 1] == im(B)\n", "def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', m, m)\n    C = MatrixSymbol('C', n, m)\n    X = BlockMatrix([[A, C], [ZeroMatrix(m, n), B]])\n    r, i = X.as_real_imag()\n    assert isinstance(r, BlockMatrix)\n    assert isinstance(i, BlockMatrix)\n    assert r.blocks[0, 0] == A.as_real_imag()[0]\n    assert r.blocks[1, 1] == B.as_real_imag()[0]\n    assert i.blocks[0, 0] == A.as_real_imag()[1]\n    assert i.blocks[1, 1] == B.as_real_imag()[1]\n", "def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', n, m)\n    X = BlockMatrix([[A, B]])\n    a, b = X.as_real_imag()\n    assert a.blocks[0, 0] == re(A)\n    assert b.blocks[0, 0] == im(A)\n    assert a.blocks[0, 1] == re(B)\n    assert b.blocks[0, 1] == im(B)\n\n    X = BlockMatrix([[A + B*I]])\n    a, b = X.as_real_imag()\n    assert a.blocks[0, 0] == A\n    assert b.blocks[0, 0] == B\n\n    X = BlockMatrix([[A], [B]])\n    a, b = X.as_real_imag()\n    assert a.blocks[0, 0] == re(A)\n    assert b.blocks[0, 0] == im(A)\n    assert a.blocks[1, 0] == re(B)\n    assert b.blocks[1, 0] == im(B)\n", "def test_block_collapse_error_handling():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, m)\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', l, l)\n    \n    with pytest.raises(ValueError):\n        BlockMatrix([[A, B], [C, D]])\n    \n    with pytest.raises(ValueError):\n        BlockMatrix([[A, B, C], [D, A, B]])\n\n    with pytest.raises(ValueError):\n        BlockMatrix([[A], [B, C]])\n", "def test_block_collapse_edge_cases():\n    assert block_collapse(BlockMatrix([])) == BlockMatrix([])\n    assert block_collapse(BlockMatrix([[]])) == BlockMatrix([[]])\n    assert block_collapse(BlockMatrix([[], []])) == BlockMatrix([[], []])\n\n    assert block_collapse(BlockMatrix([[1, 2], [3, 4]])) == BlockMatrix([[1, 2], [3, 4]])\n    assert block_collapse(BlockMatrix([[ImmutableMatrix([1, 2]), ImmutableMatrix([3, 4])],\n                                      [ImmutableMatrix([5, 6]), ImmutableMatrix([7, 8])]])) == BlockMatrix([[1, 2], [3, 4]])\n\n    assert block_collapse(BlockMatrix([MatrixSymbol('A', n, m)])) == BlockMatrix([MatrixSymbol('A', n, m)])\n    assert block_collapse(BlockMatrix([ImmutableMatrix([[1, 2], [3, 4]])])) == ImmutableMatrix([[1, 2], [3, 4]])\n"], "sample_91": ["def test_xfail_strict_skipif(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.skipif(\"True\", reason=\"skip reason\")\n        @pytest.mark.xfail(reason=\"xfail reason\", strict=True)\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rxX\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*SKIP*skip reason*\",\n        ]\n    )\n    assert result.ret == 0\n", "    def test_skipif_invalid_syntax(self, testdir):\n        item = testdir.getitem(\n            \"\"\"\n            import pytest\n            @pytest.mark.skipif(\"invalid syntax\")\n                pass\n        \"\"\"\n        )\n        with pytest.raises(pytest.fail.Exception) as excinfo:\n            pytest_runtest_setup(item)\n        assert excinfo.value.msg is not None\n        assert \"SyntaxError: invalid syntax\" in excinfo.value.msg\n", "def test_xfail_unicode_reason(testdir):\n    testdir.makepyfile(\n        test_one=\"\"\"\n        import pytest\n        @pytest.mark.xfail(reason='\u00e4\u00f6\u00fc')\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rx\")\n    result.stdout.fnmatch_lines([\"*XFAIL*test_one.py::test_func \u00e4\u00f6\u00fc\"])\n", "def test_xfail_run_with_invalid_boolean_condition(testdir):\n    testdir.makepyfile(\n        test_sample=\"\"\"\n            import pytest\n            @pytest.mark.xfail(condition=InvalidBool())\n                assert 0\n\n            class InvalidBool:\n                    raise TypeError(\"INVALID\")\n        \"\"\"\n    )\n    result = testdir.runpytest(\"--runxfail\")\n    result.stdout.fnmatch_lines([\"*1 error*\"])\n", "def test_xfail_dynamically_generated_test(testdir):\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n\n        class MyItem(pytest.Item):\n            nodeid = 'foo'\n                marker = pytest.mark.xfail(\"1 == 1\", reason=\"Expected failure\")\n                self.add_marker(marker)\n                assert False\n\n            if report.failed:\n                report = pytest.Item(\"bar\", report.node)\n                report.add_marker(pytest.mark.xfail(\"1 == 1\", reason=\"Expected failure\"))\n                report.node._nodeid = \"bar\"\n                report.node.parent = report.node\n                report.node._collected = True\n                report.node._report = report\n                report.node.session = report.node\n                return [report]\n\n            return MyItem(\"foo\", parent)\n    \"\"\"\n    )\n    result = testdir.inline_run()\n    passed, skipped, failed = result.listoutcomes()\n    assert not failed\n    xfailed = [r for r in skipped if hasattr(r, \"wasxfail\")]\n    assert len(xfailed) == 1\n    assert xfailed[0].nodeid == \"foo\"\n    assert xfailed[0].wasxfail == \"Expected failure\"\n"], "sample_118": ["def test_ccode_AugmentedAssignment():\n    assert ccode(aug_assign(x, '+', y + z)) == 'x += y + z;'\n    assert ccode(aug_assign(x, '-', y + z)) == 'x -= y + z;'\n    assert ccode(aug_assign(x, '*', y + z)) == 'x *= y + z;'\n    assert ccode(aug_assign(x, '/', y + z)) == 'x /= y + z;'\n    assert ccode(aug_assign(x, '**', y + z)) == 'x **= y + z;'\n", "def test_ccode_AugmentedAssignment_with_MultipleOperands():\n    from sympy import symbols\n    x, y, z = symbols('x y z')\n    expr = aug_assign(x, '+', y + z)\n    assert ccode(expr) == 'x += y + z;'\n", "def test_ccode_MultipleIndexContractions():\n    from sympy.tensor import IndexedBase, Idx\n    from sympy import symbols\n    n, m, o = symbols('n m o', integer=True)\n    a = IndexedBase('a')\n    b = IndexedBase('b')\n    y = IndexedBase('y')\n    i = Idx('i', m)\n    j = Idx('j', n)\n    k = Idx('k', o)\n\n    s = (\n        'for (int i=0; i<m; i++){\\n'\n        '   y[i] = 0;\\n'\n        '}\\n'\n        'for (int i=0; i<m; i++){\\n'\n        '   for (int j=0; j<n; j++){\\n'\n        '      for (int k=0; k<o; k++){\\n'\n        '         y[i] = a[i, j, k]*b[j, k] + y[i];\\n'\n        '      }\\n'\n        '   }\\n'\n        '}'\n    )\n    c = ccode(a[i, j, k]*b[j, k], assign_to=y[i])\n    assert c == s\n", "def test_ccode_Symbol():\n    x = symbols('x')\n    assert ccode(x) == 'x'\n    assert ccode(x, assign_to='z') == 'z = x;'\n\n    # check that reserved words are handled properly\n    x = symbols('auto')\n    assert ccode(x) == 'auto_'\n    assert ccode(x, assign_to='z') == 'z = auto_;'\n    assert ccode(x, reserved_word_suffix='_reserved') == 'auto_reserved'\n    assert ccode(x, assign_to='z', reserved_word_suffix='_reserved') == 'z = auto_reserved;'\n\n    # check that error_on_reserved raises an error\n    raises(ValueError, lambda: ccode(x, error_on_reserved=True))\n", "def test_ccode_Printer_settings():\n    from sympy import Symbol, Matrix, MatrixSymbol\n    from sympy.printing.ccode import CCodePrinter\n    p = CCodePrinter()\n    \n    assert p._default_settings == {\n        'order': None,\n        'full_prec': 'auto',\n        'precision': 15,\n        'user_functions': {},\n        'human': True,\n        'contract': True,\n        'dereference': set(),\n        'error_on_reserved': False,\n        'reserved_word_suffix': '_',\n    }\n    \n    # Set the default settings for the test\n    p.settings = {\n        'precision': 20,\n        'human': False,\n        'contract': False,\n        'error_on_reserved': True,\n        'reserved_word_suffix': '__',\n    }\n    \n    x = Symbol('x')\n    assert p._print(x) == 'x'\n    assert p._print(x, **p.settings) == 'x'\n    \n    x = Symbol('if')\n    assert p._print(x) == 'if_'\n    assert p._print(x, **p.settings) == 'if__'\n    \n    A = MatrixSymbol('A', 2, 2)\n    assert p._print(A) == 'A'\n    assert p._print(A, **p.settings) == 'A'\n    \n    A = Matrix([[1, 2], [3, 4]])\n    assert p._print(A) == 'A'\n    assert p._print(A, **p.settings) == 'A'\n"], "sample_62": ["    def test_delete_non_existent_file(self):\n        self.assertIs(cache.delete(\"non_existent_key\"), False)\n        self.assertIs(cache.delete(\"non_existent_key\"), False)\n", "    def test_create_dir_with_pathlib(self):\n        import pathlib\n        self.dirname = pathlib.Path(self.mkdtemp())\n        # Caches location cannot be modified through override_settings /\n        # modify_settings, hence settings are manipulated directly here and the\n        # setting_changed signal is triggered manually.\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n        cache.set(\"test\", \"value\")\n        self.assertTrue(self.dirname.is_dir())\n", "    def test_filebasedcache_cull_frequency(self):\n        from django.core.cache.backends.filebased import FileBasedCache\n\n        cache = FileBasedCache(\"test_filebasedcache_cull_frequency\", {\"OPTIONS\": {\"MAX_ENTRIES\": 100, \"CULL_FREQUENCY\": 5}})\n        cache.set('key1', 'value1')\n        cache.set('key2', 'value2')\n        cache.set('key3', 'value3')\n        cache.set('key4', 'value4')\n        cache.set('key5', 'value5')\n\n        self.assertEqual(len(cache._list_cache_files()), 5)\n        cache.set('key6', 'value6')\n        self.assertEqual(len(cache._list_cache_files()), 5)\n\n        cache.set('key7', 'value7')\n        self.assertEqual(len(cache._list_cache_files()), 5)\n\n        cache.set('key8', 'value8')\n        self.assertEqual(len(cache._list_cache_files()), 5)\n\n        cache.set('key9', 'value9')\n        self.assertEqual(len(cache._list_cache_files()), 4)\n", "    def setUp(self):\n        super().setUp()\n        self.dirname = self.mkdtemp()\n        # Caches location cannot be modified through override_settings /\n        # modify_settings, hence settings are manipulated directly here and the\n        # setting_changed signal is triggered manually.\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n", "    def setUp(self):\n        super().setUp()\n        self.dirname = \"/tmp/django-cache/\"\n        # Caches location cannot be modified through override_settings /\n        # modify_settings, hence settings are manipulated directly here and the\n        # setting_changed signal is triggered manually.\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n"], "sample_8": ["    def test_callable_setting_wrapper_repr(self):\n        class CallableSettingWrapperTest:\n                return \"repr from the wrapped callable\"\n\n                pass\n\n        actual = repr(CallableSettingWrapper(CallableSettingWrapperTest()))\n        self.assertEqual(actual, \"repr from the wrapped callable\")\n", "    def test_traceback_filtering_with_builtin_functions(self):\n            try:\n                a = [1, 2, 3]\n                a.index(4)\n            except ValueError:\n                raise IndexError('Not in list') from None\n\n        request = self.rf.get('/test_view/')\n        try:\n            test_func()\n        except Exception:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        html = reporter.get_traceback_html()\n        self.assertIn('ValueError: list.index(x): x not in list', html)\n", "    def test_typeerror_in_traceback_frame_variables(self):\n        \"\"\"\n        TypeError exceptions raised by get_traceback_frame_variables()\n        should not break the report generation.\n        \"\"\"\n        class Frame:\n                raise TypeError('Mocked error')\n        tb_frame = Frame()\n\n        reporter = ExceptionReporter(None, None, None, None)\n        with self.assertLogs('django.request', 'ERROR'):\n            reporter.filter.get_traceback_frame_variables(None, tb_frame)\n", "    def test_traceback_frame_variables_with_recursive_data(self):\n        \"\"\"\n        A recursive data structure in a frame's locals should not cause the\n        ExceptionReporter to enter an infinite loop.\n        \"\"\"\n        try:\n            a = []\n            a.append(a)\n            raise ValueError()\n        except Exception:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(None, exc_type, exc_value, tb)\n        html = reporter.get_traceback_html()\n        self.assertIn('ValueError', html)\n", "    def test_sensitivity_annotation_overrides_filter(self):\n        \"\"\"\n        The sensitive_variables decorator can be used to override the\n        settings.DEBUG value. It allows to make sure some variables are\n        hidden, even in DEBUG mode (#14614).\n        \"\"\"\n        request = self.rf.get('/test_view/')\n        try:\n            from functools import wraps\n\n                    @wraps(func)\n                        return func(*args, **kwargs)\n                    wrapper.sensitive_variables = variables\n                    return wrapper\n\n                return decorator\n\n            @sensitive_variables('sensitive')\n                non_sensitive = 'public'\n                sensitive = 'private'\n                raise ValueError('Test')\n\n            decorated_function()\n        except ValueError:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        html = reporter.get_traceback_html()\n        self.assertIn('non_sensitive', html)\n        self.assertIn('public', html)\n        self.assertIn('sensitive', html)\n        self.assertNotIn('private', html)\n"], "sample_101": ["def test_pipeline_set_params_with_tuple():\n    pipe = Pipeline([('transf', Transf()), ('clf', FitParamT())])\n    params = [('transf', {'a': 1}), ('clf', {'should_succeed': True})]\n    pipe.set_params(**dict(params))\n    assert_equal(pipe.named_steps['transf'].a, 1)\n    pipe.fit(None, None)\n    assert pipe.named_steps['clf'].successful\n", "def test_pipeline_feature_union():\n    # Test that the pipeline can take a feature union\n    pipe = Pipeline([('fu', FeatureUnion([(\"mock\", Transf())])), ('clf', FitParamT())])\n    pipe.fit(None, None)\n    # classifier should return True\n    assert pipe.predict(None)\n    # and transformer params should not be changed\n    assert pipe.named_steps['fu'].transformer_list[0][1].a is None\n    assert pipe.named_steps['fu'].transformer_list[0][1].b is None\n    # invalid parameters should raise an error message\n    assert_raise_message(\n        TypeError,\n        \"fit() got an unexpected keyword argument 'bad'\",\n        pipe.fit, None, None, clf__bad=True\n    )\n    # Test pipeline with FeatureUnion as the last step\n    pipe = Pipeline([('fu', FeatureUnion([(\"mock\", Transf())]))])\n    assert pipe.fit(None).transform(None) is not None\n", "def test_feature_union_nested():\n    # test feature union with nested feature union\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    pca = PCA(n_components=2, svd_solver='randomized', random_state=0)\n    select = SelectKBest(k=1)\n    fu = FeatureUnion([(\"pca\", pca), (\"select\", select)])\n    fu2 = FeatureUnion([(\"fu\", fu), (\"select2\", SelectKBest(k=2))])\n    fu2.fit(X, y)\n    X_transformed = fu2.transform(X)\n    assert_equal(X_transformed.shape, (X.shape[0], 5))\n\n    # check if it does the expected thing\n    assert_array_almost_equal(X_transformed[:, :-2], fu.fit_transform(X))\n    assert_array_equal(X_transformed[:, -2:], SelectKBest(k=2).fit_transform(X, y))\n\n    # test if it also works for sparse input\n    # We use a different pca object to control the random_state stream\n    X_sp = sparse.csr_matrix(X)\n    X_sp_transformed = fu2.fit_transform(X_sp, y)\n    assert_array_almost_equal(X_transformed, X_sp_transformed.toarray())\n\n    # test error if some elements do not support transform\n    assert_raises_regex(TypeError,\n                        'All estimators should implement fit and '\n                        'transform.*\\\\bNoTrans\\\\b',\n                        FeatureUnion,\n                        [(\"fu\", FeatureUnion([(\"transform\", Transf()),\n                                              (\"no_transform\", NoTrans())]))])\n\n    # test that init accepts tuples\n    fu2 = FeatureUnion(((\"fu\", fu), (\"select2\", SelectKBest(k=2))))\n    fu2.fit(X, y)\n\n    # test with transformer weights\n    fu = FeatureUnion([(\"pca\", pca), (\"select\", select)],\n                      transformer_weights={\"pca\": 10})\n    fu2 = FeatureUnion([(\"fu\", fu), (\"select2\", SelectKBest(k=2))])\n    fu2.fit(X, y)\n    X_transformed = fu2.transform(X)\n    # check if it does the expected thing\n    assert_array_almost_equal(X_transformed[:, :-2], 10 * fu.fit_transform(X))\n    assert_array_equal(X_transformed[:, -2:], SelectKBest(k=2).fit_transform(X, y))\n", "def test_pipeline_memory_with_callable():\n    # Test the usage of a custom Memory object with a callable.\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n        return Memory(location=mkdtemp(), verbose=0)\n    memory = custom_memory\n    clf = SVC(gamma='scale', probability=True, random_state=0)\n    transf = DummyTransf()\n    cached_pipe = Pipeline([('transf', transf), ('svc', clf)],\n                           memory=memory)\n    cached_pipe.fit(X, y)\n    assert_array_almost_equal(cached_pipe.predict(X),\n                              Pipeline([('transf', transf), ('svc', clf)]).fit(X, y).predict(X))\n", "def test_pipeline_memory_clone():\n    # Test that Pipeline clones estimators before fitting when memory is used.\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        if LooseVersion(joblib_version) < LooseVersion('0.12'):\n            # Deal with change of API in joblib\n            memory = Memory(cachedir=cachedir, verbose=10)\n        else:\n            memory = Memory(location=cachedir, verbose=10)\n        # Test with Transformer + SVC\n        clf = SVC(gamma='scale', probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', transf), ('svc', clf)],\n                        memory=memory)\n\n        # Memoize the transformer at the first fit\n        pipe.fit(X, y)\n\n        # Check that the transformer has been cloned and the clone is stored\n        # in the pipeline\n        assert pipe.named_steps['transf'] is not transf\n        assert pipe.named_steps['transf'].__class__ is transf.__class__\n\n        # Check that modifying the original transformer does not affect\n        # the cloned one\n        transf.means_ = 42\n        assert pipe.named_steps['transf'].means_ is not 42\n    finally:\n        shutil.rmtree(cachedir)\n"], "sample_11": ["def test_serialize_settings_reference(self):\n    setting = SettingsReference('AUTH_USER_MODEL', 'AUTH_USER_MODEL')\n    self.assertSerializedResultEqual(\n        setting,\n        (\"settings.AUTH_USER_MODEL\", {\"from django.conf import settings\"})\n    )\n    setting = SettingsReference('AUTH_USER_MODEL', 'CUSTOM_SETTING')\n    self.assertSerializedResultEqual(\n        setting,\n        (\"settings.CUSTOM_SETTING\", {\"from django.conf import settings\"})\n    )\n    setting = SettingsReference('CUSTOM_SETTING', 'AUTH_USER_MODEL')\n    self.assertSerializedResultEqual(\n        setting,\n        (\"settings.AUTH_USER_MODEL\", {\"from django.conf import settings\"})\n    )\n", "def test_serialize_settings_reference_with_default(self):\n    setting_value = settings.AUTH_USER_MODEL\n    reference = SettingsReference(setting_value, \"AUTH_USER_MODEL\")\n    self.assertSerializedResultEqual(\n        reference,\n        (\"settings.%s\" % setting_value, {\"from django.conf import settings\"})\n    )\n", "def test_serialize_functools_partial_class_method(self):\n    class MyClass:\n            pass\n\n    instance = MyClass()\n    value = functools.partial(instance.method, 1, 2, a=3, b=4)\n    result = self.serialize_round_trip(value)\n    self.assertIsInstance(result, functools.partial)\n    self.assertEqual(result.func, instance.method)\n    self.assertEqual(result.args, (1, 2))\n    self.assertEqual(result.keywords, {'a': 3, 'b': 4})\n", "def test_serialize_regex_flags(self):\n    \"\"\"\n    Make sure regex flags are properly serialized.\n    \"\"\"\n    validator = RegexValidator(r'^\\w+$', flags=re.IGNORECASE)\n    string = MigrationWriter.serialize(validator)[0]\n    self.assertEqual(string, \"django.core.validators.RegexValidator(r'^\\\\\\\\w+$', flags=re.RegexFlag['IGNORECASE'])\")\n    self.serialize_round_trip(validator)\n\n    validator = RegexValidator(r'^\\w+$', flags=re.S)\n    string = MigrationWriter.serialize(validator)[0]\n    self.assertEqual(string, \"django.core.validators.RegexValidator(r'^\\\\\\\\w+$', flags=re.RegexFlag['DOTALL'])\")\n    self.serialize_round_trip(validator)\n\n    validator = RegexValidator(r'^\\w+$', flags=re.I)\n    string = MigrationWriter.serialize(validator)[0]\n    self.assertEqual(string, \"django.core.validators.RegexValidator(r'^\\\\\\\\w+$', flags=re.RegexFlag['IGNORECASE'])\")\n    self.serialize_round_trip(validator)\n\n    validator = RegexValidator(r'^\\w+$', flags=re.M)\n    string = MigrationWriter.serialize(validator)[0]\n    self.assertEqual(string, \"django.core.validators.RegexValidator(r'^\\\\\\\\w+$', flags=re.RegexFlag['MULTILINE'])\")\n    self.serialize_round_trip(validator)\n\n    validator = RegexValidator(r'^\\w+$', flags=re.X)\n    string = MigrationWriter.serialize(validator)[0]\n    self.assertEqual(string, \"django.core.validators.RegexValidator(r'^\\\\\\\\w+$', flags=re.RegexFlag['VERBOSE'])\")\n    self.serialize_round_trip(validator)\n\n    validator = RegexValidator(r'^\\w+$', flags=re.A)\n    string = MigrationWriter.serialize(validator)[0]\n    self.assertEqual(string, \"django.core.validators.RegexValidator(r'^\\\\\\\\w+$', flags=re.RegexFlag['ASCII'])\")\n    self.serialize_round_trip(validator)\n\n    validator = RegexValidator(r'^\\w+$', flags=re.U)\n    string = MigrationWriter.serialize(validator)[0]\n    self.assertEqual(string, \"django.core.validators.RegexValidator(r'^\\\\\\\\w+$', flags=re.RegexFlag['UNICODE'])\")\n    self.serialize_round_trip(validator)\n\n    validator = RegexValidator(r'^\\w+$', flags=re.L)\n    string = MigrationWriter.serialize(validator)[0]\n    self.assertEqual(string, \"django.core.validators.RegexValidator(r'^\\\\\\\\w+$', flags=re.RegexFlag['LOCALE'])\")\n    self", "    def test_serialize_operation(self):\n        \"\"\"\n        Test serialization of an Operation instance.\n        \"\"\"\n        class TestOperation(migrations.operations.base.Operation):\n                self.value = value\n\n                return (\"TestOperation\", (self.value,), {})\n\n        operation = TestOperation(42)\n        string, imports = MigrationWriter.serialize(operation)\n        self.assertEqual(string, \"TestOperation(42)\")\n        self.assertEqual(imports, set())\n\n        class TestOperationWithImports(migrations.operations.base.Operation):\n                self.value = value\n\n                return (\"TestOperationWithImports\", (self.value,), {})\n\n        MigrationWriter.register_serializer(TestOperationWithImports, TestOperationSerializer)\n        operation = TestOperationWithImports(42)\n        string, imports = MigrationWriter.serialize(operation)\n        self.assertEqual(string, \"TestOperationWithImports(42)\")\n        self.assertEqual(imports, set())\n        MigrationWriter.unregister_serializer(TestOperationWithImports)\n\n        class TestOperationWithSerializedValue(migrations.operations.base.Operation):\n                self.value = value\n\n                return (\"TestOperationWithSerializedValue\", (self.value,), {})\n\n        MigrationWriter.register_serializer(TestOperationWithSerializedValue, OperationSerializer)\n        operation = TestOperationWithSerializedValue(datetime.datetime(2022, 1, 1, 1, 1, tzinfo=utc))\n        string, imports = MigrationWriter.serialize(operation)\n        self.assertEqual(string, \"TestOperationWithSerializedValue(datetime.datetime(2022, 1, 1, 1, 1, tzinfo=utc))\")\n        self.assertEqual(imports, {'import datetime', 'from django.utils.timezone import utc'})\n        MigrationWriter.unregister_serializer(TestOperationWithSerializedValue)\n\n        with self.assertRaisesMessage(ValueError, \"Cannot serialize: <class 'TestOperation'>\"):\n            MigrationWriter.serialize(TestOperation)\n"], "sample_122": ["def test_row_structure_symbolic_cholesky():\n    S = SparseMatrix([\n        [1, 0, 3, 2],\n        [0, 0, 1, 0],\n        [4, 0, 0, 5],\n        [0, 6, 7, 0]])\n    assert S.row_structure_symbolic_cholesky() == [[0], [], [0], [1, 2]]\n\n    S = SparseMatrix([\n        [1, 1, 0, 0],\n        [1, 2, 1, 0],\n        [0, 1, 3, 1],\n        [0, 0, 1, 4]])\n    assert S.row_structure_symbolic_cholesky() == [[0], [0], [1, 2], [2, 3]]\n\n    S = SparseMatrix([\n        [1, 1, 1, 0],\n        [1, 2, 2, 1],\n        [1, 2, 3, 2],\n        [0, 1, 2, 4]])\n    assert S.row_structure_symbolic_cholesky() == [[0], [0, 1], [1, 2], [1, 2, 3]]\n", "def test_sparse_matrix_methods():\n    # Test liupc method\n    S = SparseMatrix([\n        [1, 0, 3, 2],\n        [0, 0, 1, 0],\n        [4, 0, 0, 5],\n        [0, 6, 7, 0]])\n    assert S.liupc() == ([[0], [], [0], [1, 2]], [4, 3, 4, 4])\n\n    # Test row_structure_symbolic_cholesky method\n    S = SparseMatrix([\n        [1, 0, 3, 2],\n        [0, 0, 1, 0],\n        [4, 0, 0, 5],\n        [0, 6, 7, 0]])\n    assert S.row_structure_symbolic_cholesky() == [[0], [], [0], [1, 2]]\n\n    # Test _cholesky_sparse method\n    A = SparseMatrix([\n        [25, 15, -5],\n        [15, 18, 0],\n        [-5, 0, 11]])\n    C = A._cholesky_sparse()\n    assert C == SparseMatrix([\n        [5, 0, 0],\n        [3, 3, 0],\n        [-1, 1, 3]])\n\n    # Test _LDL_sparse method\n    A = SparseMatrix([\n        [25, 15, -5],\n        [15, 18, 0],\n        [-5, 0, 11]])\n    L, D = A._LDL_sparse()\n    assert L == SparseMatrix([\n        [1, 0, 0],\n        [3/5, 1, 0],\n        [-1/5, 1/3, 1]])\n    assert D == SparseMatrix([\n        [25, 0, 0],\n        [0, 9, 0],\n        [0, 0, 9]])\n\n    # Test _lower_triangular_solve method\n    A = SparseMatrix([\n        [2, 0, 0],\n        [3, 3, 0],\n        [-1, 1, 3]])\n    rhs = SparseMatrix([[1], [2], [3]])\n    X = A._lower_triangular_solve(rhs)\n    assert X == SparseMatrix([\n", "def test_copy():\n    m = SparseMatrix(5, 5, {(0, 0): 1, (4, 4): 2})\n    n = m.copy()\n    assert m == n\n    m[0, 0] = 3\n    assert m != n\n", "def test_diagonal_solve():\n    # test diagonal solve for zero diagonal\n    M = SparseMatrix(3, 3, {(0, 0): 0, (1, 1): 0, (2, 2): 0})\n    b = SparseMatrix(3, 1, [1, 1, 1])\n    raises(ZeroDivisionError, lambda: M._diagonal_solve(b))\n\n    # test diagonal solve for non-square\n    M = SparseMatrix(2, 3, {(0, 0): 1, (1, 1): 2})\n    b = SparseMatrix(2, 1, [1, 1])\n    raises(ValueError, lambda: M._diagonal_solve(b))\n\n    # test diagonal solve for diagonal matrix\n    M = SparseMatrix(3, 3, {(0, 0): 2, (1, 1): 3, (2, 2): 4})\n    b = SparseMatrix(3, 1, [1, 1, 1])\n    x = M._diagonal_solve(b)\n    assert x == SparseMatrix(3, 1, [S(1)/2, S(1)/3, S(1)/4])\n", "def test_sparse_solve_ill_conditioned():\n    # Test case for issue 20845\n    A = SparseMatrix(((1, 0, 0, 0, 0, 0),\n                      (0, 1, 0, 0, 0, 0),\n                      (0, 0, 0, 0, 0, 0),\n                      (0, 0, 0, 1, 0, 0),\n                      (0, 0, 0, 0, 1, 0),\n                      (0, 0, 0, 0, 0, 0)))\n    b = SparseMatrix(6, 1, (1, 0, 0, 0, 0, 0))\n    solution = A.solve_least_squares(b, 'LDL')\n    assert A * solution - b == SparseMatrix(6, 1, (0, 0, 0, 0, 0, 0))\n"], "sample_54": ["def test_avoid_wrapping(self):\n    self.assertEqual(avoid_wrapping(\"Test phrase\"), \"Test\\xa0phrase\")\n    self.assertEqual(avoid_wrapping(\"Test  phrase\"), \"Test\\xa0\\xa0phrase\")\n    self.assertEqual(avoid_wrapping(\"Test phrase test\"), \"Test\\xa0phrase\\xa0test\")\n    self.assertEqual(avoid_wrapping(\"\"), \"\")\n    self.assertEqual(avoid_wrapping(\" \"), \"\\xa0\")\n", "def test_avoid_wrapping(self):\n    tests = (\n        (\"Test string with spaces\", \"Test\u00a0string\u00a0with\u00a0spaces\"),\n        (\"Test string with multiple spaces   between words\", \"Test\u00a0string\u00a0with\u00a0multiple\u00a0spaces\u00a0\u00a0\u00a0between\u00a0words\"),\n        (\"Test string with leading and trailing spaces   \", \"Test\u00a0string\u00a0with\u00a0leading\u00a0and\u00a0trailing\u00a0spaces\u00a0\u00a0\u00a0\"),\n        (\"\", \"\"),\n    )\n    for value, output in tests:\n        with self.subTest(value=value, output=output):\n            self.assertEqual(avoid_wrapping(value), output)\n            self.assertEqual(avoid_wrapping(lazystr(value)), output)\n", "def test_avoid_wrapping(self):\n    # Test with simple input\n    self.assertEqual(avoid_wrapping(\"Hello World\"), \"Hello\\xA0World\")\n    \n    # Test with punctuation\n    self.assertEqual(avoid_wrapping(\"Hello, World!\"), \"Hello,\\xA0World!\")\n    \n    # Test with multiple spaces\n    self.assertEqual(avoid_wrapping(\"Hello  World\"), \"Hello\\xA0World\")\n    \n    # Test with no spaces\n    self.assertEqual(avoid_wrapping(\"HelloWorld\"), \"HelloWorld\")\n    \n    # Test with lazy string input\n    self.assertEqual(avoid_wrapping(lazystr(\"Hello World\")), \"Hello\\xA0World\")\n", "def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\n            \"Search for google.com/?q=! and see.\",\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>! and '\n            \"see.\",\n        ),\n        (\n            \"Search for google.com/?q=1&lt!, and see.\",\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt'\n            \"</a>, and see.\",\n        ),\n        (\n            \"foo@example.com.\",\n            '<a href=\"mailto:foo@example.com\">foo@example.com</a>.',\n        ),\n        (\n            \"foo@example.com,\",\n            '<a href=\"mailto:foo@example.com\">foo@example.com</a>,',\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n", "def test_urlize_autoescape(self):\n    tests = (\n        (\n            \"<script>alert('XSS')</script> https://www.example.com/\",\n            \"&lt;script&gt;alert(&#x27;XSS&#x27;)&lt;/script&gt; <a href=\\\"https://www.example.com/\\\">https://www.example.com/</a>\",\n        ),\n        (\n            \"<script>alert('XSS')</script> foo@bar.com\",\n            \"&lt;script&gt;alert(&#x27;XSS&#x27;)&lt;/script&gt; <a href=\\\"mailto:foo@bar.com\\\">foo@bar.com</a>\",\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value, autoescape=True), output)\n"], "sample_29": ["def test_outerref_mixed_case_table_name_2(self):\n    inner = Experiment.objects.filter(assigned=OuterRef('result__experiment__assigned'))\n    outer = Experiment.objects.annotate(\n        results=Subquery(\n            Result.objects.filter(pk=OuterRef('pk')).values('experiment').annotate(\n                count=Count('pk')\n            ).values('count').order_by('-count')\n        )\n    )\n    self.assertEqual(outer.get().results, 2)\n", "    def test_base_path(self):\n        path = [('a', [])]\n        with self.assertRaisesMessage(MultiJoin, \"MultiJoin(1, [('a', [])])\"):\n            raise MultiJoin(1, path)\n", "    def test_add_annotation(self):\n        Company.objects.create(name='Example Inc.', num_employees=2300, num_chairs=5, ceo=self.max)\n        self.max.manager = Manager.objects.create(name='Manager')\n        self.max.save()\n\n        query = Query(Company)\n        query.add_annotation(Count('*'), alias='__count', is_summary=True)\n\n        query.add_annotation(Max('num_employees'), alias='max_num_employees', is_summary=True)\n\n        query.add_annotation(Max('ceo__salary'), alias='max_ceo_salary', is_summary=True)\n\n        query.add_annotation(Max('ceo__manager__name'), alias='max_ceo_manager_name', is_summary=True)\n\n        query.add_annotation(Count('ceo__manager__name'), alias='count_ceo_manager_name', is_summary=True)\n\n        results = query.get_aggregation(using=DEFAULT_DB_ALIAS, added_aggregate_names=['__count'])\n\n        self.assertIn('__count', results)\n        self.assertIn('max_num_employees', results)\n        self.assertIn('max_ceo_salary', results)\n        self.assertIn('max_ceo_manager_name', results)\n        self.assertIn('count_ceo_manager_name', results)\n", "    def setUpTestData(cls):\n        cls.e1 = Experiment.objects.create(\n            name='Experiment 1',\n            assigned=datetime.date(2010, 6, 25),\n            start=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000),\n            end=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000),\n            completed=datetime.date(2010, 6, 25),\n            estimated_time=datetime.timedelta(),\n        )\n        cls.r1 = Result.objects.create(experiment=cls.e1, result_time=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000))\n", "    def test_is_empty(self):\n        empty_query = Company.objects.filter(name='')\n        self.assertTrue(empty_query.query.is_empty())\n        self.assertFalse(Company.objects.all().query.is_empty())\n"], "sample_37": ["    def test_pathinfo_namedtuple(self):\n        from_opts = mock.Mock()\n        to_opts = mock.Mock()\n        target_fields = mock.Mock()\n        join_field = mock.Mock()\n        m2m = mock.Mock()\n        direct = mock.Mock()\n        filtered_relation = mock.Mock()\n\n        path_info = PathInfo(\n            from_opts, to_opts, target_fields, join_field, m2m, direct, filtered_relation\n        )\n        self.assertEqual(path_info.from_opts, from_opts)\n        self.assertEqual(path_info.to_opts, to_opts)\n        self.assertEqual(path_info.target_fields, target_fields)\n        self.assertEqual(path_info.join_field, join_field)\n        self.assertEqual(path_info.m2m, m2m)\n        self.assertEqual(path_info.direct, direct)\n        self.assertEqual(path_info.filtered_relation, filtered_relation)\n", "    def test_pathinfo(self):\n        pi = PathInfo(\n            from_opts='from_opts', to_opts='to_opts', target_fields='target_fields',\n            join_field='join_field', m2m=False, direct=True, filtered_relation='filtered_relation'\n        )\n        self.assertEqual(pi.from_opts, 'from_opts')\n        self.assertEqual(pi.to_opts, 'to_opts')\n        self.assertEqual(pi.target_fields, 'target_fields')\n        self.assertEqual(pi.join_field, 'join_field')\n        self.assertEqual(pi.m2m, False)\n        self.assertEqual(pi.direct, True)\n        self.assertEqual(pi.filtered_relation, 'filtered_relation')\n", "    def test_clone(self):\n        fr = FilteredRelation('relation_name', condition=Q())\n        fr.alias = 'alias'\n        fr.path = ['path']\n        cloned = fr.clone()\n        self.assertEqual(cloned.relation_name, fr.relation_name)\n        self.assertEqual(cloned.alias, fr.alias)\n        self.assertEqual(cloned.path, fr.path)\n        self.assertEqual(cloned.condition, fr.condition)\n", "    def test_q_expression_negation(self):\n        self.assertEqual(~Q(num_employees=100), Q(num_employees__isnull=True, num_employees__lt=100, num_employees__gt=100))\n", "    def test_q_pickle(self):\n        q = Q(id=5)\n        self.assertEqual(pickle.loads(pickle.dumps(q)), q)\n"], "sample_56": ["    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n", "    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n", "    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n", "    def test_template_tags_with_empty_libraries(self):\n        with self.settings(\n            TEMPLATES=[\n                {\n                    \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n                    \"OPTIONS\": {\n                        \"libraries\": {},\n                    },\n                },\n            ]\n        ):\n            self.assertEqual(check_for_template_tags_with_the_same_name(None), [])\n", "    def test_template_tags_with_same_name_empty_templates_setting(self):\n        with self.settings(TEMPLATES=[]):\n            self.assertEqual(check_for_template_tags_with_the_same_name(None), [])\n"], "sample_88": ["def test_ellipsize():\n    assert _ellipsize(\"short string\", 100) == \"short string\"\n    assert _ellipsize(\"a\" * 100, 20) == \"aaaaaaaaaa...aaaaaaaaaa\"\n    assert _ellipsize(\"\", 10) == \"\"\n    assert _ellipsize(\"a\", 1) == \"...\"\n    assert _ellipsize(\"ab\", 3) == \"a...\"\n", "def test_saferepr_on_recursive_object():\n    class RecursiveObject:\n            self.parent = parent\n\n            if self.parent is None:\n                return \"RecursiveObject()\"\n            return f\"RecursiveObject(parent={self.parent!r})\"\n\n    obj = RecursiveObject()\n    obj.parent = obj\n\n    assert saferepr(obj) == \"RecursiveObject(parent=...)\"\n", "def test_saferepr_edge_cases():\n    assert saferepr(0) == \"0\"\n    assert saferepr(-1) == \"-1\"\n    assert saferepr(float(\"inf\")) == \"inf\"\n    assert saferepr(float(\"-inf\")) == \"-inf\"\n    assert saferepr(float(\"nan\")) == \"nan\"\n    assert saferepr(complex(1, 2)) == \"(1+2j)\"\n    assert saferepr(complex(0, 0)) == \"0j\"\n    assert saferepr(complex(1, 0)) == \"(1+0j)\"\n    assert saferepr(complex(0, 1)) == \"1j\"\n    assert saferepr(bytearray(b\"hello\")) == \"bytearray(b'hello')\"\n    assert saferepr(memoryview(b\"hello\")) == \"<memory at 0x...>\"\n    assert saferepr(slice(1, 2, 3)) == \"slice(1, 2, 3)\"\n", "def test_ellipsize_edge_cases():\n    assert _ellipsize(\"\", 10) == \"\"\n    assert _ellipsize(\"a\" * 10, 10) == \"a\" * 10\n    assert _ellipsize(\"a\" * 3, 2) == \"a...\"  # maxsize smaller than \"...\".length\n    assert _ellipsize(\"a\" * 5, 3) == \"...a\"  # maxsize smaller than length - \"...\".length\n", "def test_repr_with_depth_limitation():\n    class DeepRepr:\n            self.depth = depth\n            self.value = self\n\n            if self.depth > 0:\n                return repr(self.value)\n            return \"<DeepRepr>\"\n\n    obj = DeepRepr(5)\n    assert saferepr(obj) == \"<DeepRepr>\"\n\n    obj = DeepRepr(10)\n    assert saferepr(obj) == \"<DeepRepr>\"\n\n    deep_repr = SafeRepr(maxsize=1000)\n    assert deep_repr.repr(obj) == \"<DeepRepr>\"\n\n    class CycleRepr:\n            self.value = self\n\n            return repr(self.value)\n\n    obj = CycleRepr()\n    assert \"RecursionError\" in saferepr(obj)\n"], "sample_74": ["def test_colorbar_set_ticks_location():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cbar = fig.colorbar(im, orientation='horizontal')\n    cbar.set_ticks(ticks=[0, 2])\n    cbar.ax.invert_xaxis()\n    assert cbar.get_ticks() == [2, 0]\n    cbar.ax.invert_xaxis()\n    assert cbar.get_ticks() == [0, 2]\n", "def test_colorbar_mappable_alpha():\n    \"\"\"Test that colorbar.mappable still has the original alpha.\"\"\"\n    fig, ax = plt.subplots()\n    im = ax.pcolormesh(np.random.randn(10, 10), alpha=0.7)\n    fig.colorbar(im)\n    fig.draw_without_rendering()\n    assert im.get_alpha() == 0.7\n    assert im.get_alpha() is not None\n", "def test_colorbar_labels_update():\n    # test issue gh-16760\n    fig, ax = plt.subplots()\n    im = ax.pcolormesh([[1, 2], [3, 4]])\n    cb = fig.colorbar(im)\n    labels = ['tick1', 'tick2', 'tick3', 'tick4']\n    cb.set_ticks(cb.get_ticks())\n    cb.set_ticklabels(labels)\n    assert cb.ax.yaxis.get_ticklabels() == labels\n", "def test_colorbar_locator_formatter_scale():\n    # Test that locator, formatter, and scale are updated when\n    # mappable norm changes.\n    fig, ax = plt.subplots()\n    pcm = ax.pcolormesh(np.arange(100).reshape(10, 10),\n                        norm=mcolors.Normalize(vmin=0, vmax=100))\n    cbar = fig.colorbar(pcm, ax=ax)\n    assert cbar.ax.yaxis.get_scale() == 'linear'\n    assert cbar.locator is not None\n    assert cbar.formatter is not None\n    pcm.set_norm(LogNorm(vmin=1, vmax=10))\n    assert cbar.ax.yaxis.get_scale() == 'log'\n    assert cbar.locator is not None\n    assert cbar.formatter is not None\n    pcm.set_norm(Normalize(vmin=0, vmax=10))\n    assert cbar.ax.yaxis.get_scale() == 'linear'\n    assert cbar.locator is not None\n    assert cbar.formatter is not None\n    pcm.set_norm(PowerNorm(gamma=0.5, vmin=0, vmax=10))\n    assert cbar.ax.yaxis.get_scale() == 'function'\n    assert cbar.locator is not None\n    assert cbar.formatter is not None\n", "def test_colorbar_vertical_and_horizontal_spines():\n    \"\"\"\n    Test that spines are correctly drawn and updated in vertical and\n    horizontal colorbars.\n    \"\"\"\n    fig, axs = plt.subplots(2, 2)\n    for ax, location in zip(axs.flat, ['right', 'top', 'left', 'bottom']):\n        pcm = ax.pcolormesh(np.arange(100).reshape(10, 10))\n        cb = fig.colorbar(pcm, ax=ax, location=location)\n        if location in ['left', 'right']:\n            assert not cb.outline.get_visible()\n        else:\n            assert cb.outline.get_visible()\n        cb.outline.set_visible(not cb.outline.get_visible())\n        assert cb.outline.get_visible() != (location in ['left', 'right'])\n    fig.draw_without_rendering()\n"], "sample_111": ["def test_adjusted_mutual_info_score(metric_name, y1, y2, expected_score):\n    metric = SUPERVISED_METRICS[metric_name]\n    assert metric(y1, y2) == pytest.approx(expected_score)\n", "def test_non_symmetry_edge_cases(metric_name, y1, y2):\n    metric = SUPERVISED_METRICS[metric_name]\n    assert metric(y1, y1) == 1.0\n    assert metric(y2, y2) == 1.0\n", "def test_average_method(metric_name, average_method):\n    metric = SUPERVISED_METRICS[metric_name]\n    y1 = [0, 0, 0, 1, 1, 1]\n    y2 = [0, 0, 0, 1, 1, 1]\n    score = metric(y1, y2, average_method=average_method)\n    assert score == 1.0\n\n    y1 = [0, 0, 0, 1, 1, 1]\n    y2 = [1, 1, 1, 0, 0, 0]\n    score = metric(y1, y2, average_method=average_method)\n    assert score == 1.0\n\n    y1 = [0, 0, 1, 1]\n    y2 = [0, 1, 0, 1]\n    score = metric(y1, y2, average_method=average_method)\n    assert score < 1.0\n", "def test_empty_input(metric_name):\n    metric = SUPERVISED_METRICS[metric_name]\n    with pytest.raises(ValueError, match='input arrays must not be empty'):\n        metric([], [])\n", "def test_average_methods(metric_name, average_method):\n    if metric_name == \"homogeneity_completeness_v_measure\":\n        metric = lambda x, y: homogeneity_completeness_v_measure(x, y, beta=average_method)\n    else:\n        metric = SUPERVISED_METRICS[metric_name]\n    y1 = np.array([0, 0, 0, 1, 1, 1])\n    y2 = np.array([0, 1, 1, 0, 1, 1])\n    if average_method in [\"min\", \"geometric\", \"arithmetic\", \"max\"]:\n        score = metric(y1, y2, average_method=average_method)\n        assert score >= 0.0\n        assert score <= 1.0\n    else:\n        with pytest.raises(ValueError):\n            metric(y1, y2, average_method=average_method)\n"], "sample_47": ["    def test_check_replacements(self):\n        \"\"\"\n        Regression test for #24628 - check_replacements() should be called\n        unconditionally on every migrate, rather than just when migrations are\n        applied or unapplied.\n        \"\"\"\n        recorder = MigrationRecorder(connection)\n        # Place the database in a state where the replaced migrations are\n        # partially applied: 0001 is applied, 0002 is not.\n        recorder.record_applied(\"migrations\", \"0001_initial\")\n        executor = MigrationExecutor(connection)\n        # Use fake because we don't actually have the first migration\n        # applied, so the second will fail. And there's no need to actually\n        # create/modify tables here, we're just testing the\n        # MigrationRecord, which works the same with or without fake.\n        executor.migrate([(\"migrations\", \"0001_initial\")])\n        # Because we've now applied 0001 and 0002 both, their squashed\n        # replacement should be marked as applied.\n        self.assertIn(\n            (\"migrations\", \"0001_squashed_0002\"),\n            recorder.applied_migrations(),\n        )\n", "def test_migrate_skips_schema_creation_with_table_exists(self, mocked_has_table):\n    \"\"\"\n    The django_migrations table is not created if it already exists and there\n    are no migrations to record.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # 1 query, to check the migrations.\n    with self.assertNumQueries(1):\n        executor.migrate([], plan=[])\n", "    def test_migration_plan_with_target_none(self):\n        \"\"\"\n        Test that the migration plan is correctly generated when the target is None.\n        \"\"\"\n        executor = MigrationExecutor(connection)\n        # Make the initial plan, check it\n        plan = executor.migration_plan([(\"migrations\", None)])\n        self.assertEqual(\n            plan,\n            [\n                (executor.loader.graph.nodes[\"migrations\", \"0002_second\"], True),\n                (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], True),\n            ],\n        )\n        # Were the tables there before?\n        self.assertTableNotExists(\"migrations_author\")\n        self.assertTableNotExists(\"migrations_tribble\")\n        # Alright, let's try running it\n        executor.migrate([(\"migrations\", \"0002_second\")])\n        # Are the tables there now?\n        self.assertTableExists(\"migrations_author\")\n        self.assertTableExists(\"migrations_tribble\")\n        # Rebuild the graph to reflect the new DB state\n        executor.loader.build_graph()\n        # Alright, let's undo what we did\n        plan = executor.migration_plan([(\"migrations\", None)])\n        self.assertEqual(\n            plan,\n            [\n                (executor.loader.graph.nodes[\"migrations\", \"0002_second\"], True),\n                (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], True),\n            ],\n        )\n        executor.migrate([(\"migrations\", None)])\n        # Are the tables gone?\n        self.assertTableNotExists(\"migrations_author\")\n        self.assertTableNotExists(\"migrations_tribble\")\n", "def test_check_replacements(self):\n    \"\"\"\n    Test that check_replacements marks replacement migrations applied.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Apply the original migration\n    executor.migrate([(\"migrations\", \"0001_initial\")])\n    # Check that the original migration is recorded as applied\n    self.assertIn((\"migrations\", \"0001_initial\"), executor.recorder.applied_migrations())\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Check that the replacement migration is not recorded as applied\n    self.assertNotIn((\"migrations\", \"0002_replacement\"), executor.recorder.applied_migrations())\n    # Apply the replacement migration\n    executor.migrate([(\"migrations\", \"0002_replacement\")])\n    # Check that the replacement migration is recorded as applied\n    self.assertIn((\"migrations\", \"0002_replacement\"), executor.recorder.applied_migrations())\n    # Check that the original migration is not recorded as applied\n    self.assertNotIn((\"migrations\", \"0001_initial\"), executor.recorder.applied_migrations())\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Check that the replacement migration is still recorded as applied\n    self.assertIn((\"migrations\", \"0002_replacement\"), executor.recorder.applied_migrations())\n    # Unapply the replacement migration\n    executor.migrate([(\"migrations\", None)])\n    # Check that the replacement migration is not recorded as applied\n    self.assertNotIn((\"migrations\", \"0002_replacement\"), executor.recorder.applied_migrations())\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Check that the original migration is not recorded as applied\n    self.assertNotIn((\"migrations\", \"0001_initial\"), executor.recorder.applied_migrations())\n", "def test_migrate_marks_replacement_unapplied_after_unapplying_replaced_migrations(self):\n    \"\"\"\n    Replacing a migration that is marked as unapplied still marks the\n    replacement as unapplied after unapplying its replaced migrations.\n    \"\"\"\n    recorder = MigrationRecorder(connection)\n    # Record all replaced migrations as applied\n    recorder.record_applied(\"migrations\", \"0001_initial\")\n    recorder.record_applied(\"migrations\", \"0002_second\")\n    # Record the replacement as applied\n    recorder.record_applied(\"migrations\", \"0001_squashed_0002\")\n    executor = MigrationExecutor(connection)\n    # Unapply the replaced migrations\n    executor.migrate([(\"migrations\", \"0001_initial\")], fake=True)\n    executor.loader.build_graph()\n    # Rebuild the graph to reflect the new DB state\n    self.assertNotIn(\n        ('migrations', '0001_squashed_0002'),\n        recorder.applied_migrations(),\n    )\n"], "sample_75": ["def test_imagegrid_cbar_mode_each():\n    imdata = np.arange(100).reshape((10, 10))\n\n    fig = plt.figure(1, (4, 4))\n    grid = ImageGrid(fig, 111, nrows_ncols=(2, 2), axes_pad=0.1,\n                     cbar_mode=\"each\", cbar_location=\"right\", cbar_size=\"15%\")\n    for ax, cax in zip(grid, grid.cbar_axes):\n        im = ax.imshow(imdata, interpolation='none')\n        cax.colorbar(im)\n", "def test_imagegrid_cbar_set_cax():\n    imdata = np.arange(100).reshape((10, 10))\n\n    fig = plt.figure(1, (3, 3))\n    grid = ImageGrid(fig, (1, 1, 1), nrows_ncols=(3, 2), axes_pad=(0.5, 0.3),\n                     cbar_mode=\"each\", cbar_location=\"left\", cbar_size=\"15%\",\n                     label_mode=\"all\", cbar_set_cax=False)\n    for ax in grid:\n        assert not hasattr(ax, 'cax')\n\n    grid = ImageGrid(fig, (1, 1, 1), nrows_ncols=(3, 2), axes_pad=(0.5, 0.3),\n                     cbar_mode=\"each\", cbar_location=\"left\", cbar_size=\"15%\",\n                     label_mode=\"all\", cbar_set_cax=True)\n    for ax in grid:\n        assert hasattr(ax, 'cax')\n", "def test_grid_cbar_axes_visibility():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (1, 1))\n    assert not grid.cbar_axes[0].get_visible()\n\n    grid = ImageGrid(fig, 111, (1, 1), cbar_mode=\"single\")\n    assert grid.cbar_axes[0].get_visible()\n\n    grid = ImageGrid(fig, 111, (1, 1), cbar_mode=\"each\")\n    assert all(cax.get_visible() for cax in grid.cbar_axes)\n\n    grid = ImageGrid(fig, 111, (1, 1), cbar_mode=\"edge\")\n    assert all(cax.get_visible() for cax in grid.cbar_axes[:2])\n    assert all(not cax.get_visible() for cax in grid.cbar_axes[2:])\n", "def test_grid_init():\n    fig = plt.figure()\n    with pytest.raises(TypeError, match=\"Incorrect rect format\"):\n        Grid(fig, (1, 1), (2, 3))\n\n    with pytest.raises(ValueError, match=\"ngrids must be positive\"):\n        Grid(fig, 111, (2, 3), ngrids=-1)\n\n    with pytest.raises(ValueError, match=\"ngrids must be positive\"):\n        Grid(fig, 111, (2, 3), ngrids=7)\n\n    grid = Grid(fig, 111, (2, 3))\n    assert grid.nrows == 2\n    assert grid.ncols == 3\n    assert grid.ngrids == 6\n    assert grid.axes_pad == (0.02, 0.02)\n    assert grid.direction == \"row\"\n    assert grid.share_all is False\n    assert grid.share_x is True\n    assert grid.share_y is True\n    assert grid.label_mode == \"L\"\n    assert grid.aspect is False\n\n    grid = Grid(fig, 111, (2, 3), direction=\"column\")\n    assert grid.direction == \"column\"\n", "def test_imagegrid_cbar_location_edge():\n    imdata = np.arange(100).reshape((10, 10))\n\n    fig = plt.figure(1, (3, 3))\n    grid = ImageGrid(fig, (1, 1, 1), nrows_ncols=(2, 2), axes_pad=(0.5, 0.3),\n                     cbar_mode=\"edge\", cbar_location=\"right\", cbar_size=\"15%\",\n                     label_mode=\"all\")\n    for ax, cax in zip(grid, grid.cbar_axes):\n        im = ax.imshow(imdata, interpolation='none')\n        cax.colorbar(im)\n    # check cbar_axes for the edge location\n    assert len(grid.cbar_axes) == grid._nrows\n    assert all(ax.get_visible() for ax in grid.cbar_axes)\n"], "sample_147": ["def test_Function_kind():\n    f = S.Function('f')\n    assert f.kind is UndefinedKind\n    assert f(comm_x).kind is UndefinedKind\n    assert f(noncomm_x).kind is UndefinedKind\n", "def test_Lambda_kind():\n    f = Lambda(comm_x, 2*comm_x)\n    assert f.kind is NumberKind\n    f = Lambda(noncomm_x, 2*noncomm_x)\n    assert f.kind is UndefinedKind\n", "def test_Lambda_kind():\n    x = Symbol('x')\n    y = Symbol('y')\n    assert Lambda(x, x).kind is NumberKind\n    assert Lambda(x, x + y).kind is NumberKind\n    assert Lambda((x, y), x + y).kind is NumberKind\n", "def test_FunctionClass_kind():\n    class f(Function):\n        pass\n    assert f.kind is NumberKind\n    class g(Function, commutative=False):\n        pass\n    assert g.kind is UndefinedKind\n", "def test_Derivative_nargs():\n    assert Derivative(S(1)).nargs == (0,)\n    assert Derivative(S(1), S(1)).nargs == (1,)\n    assert Derivative(S(1), (S(1), 2)).nargs == (2,)\n"], "sample_115": ["def test__wrap_in_pandas_container_sparse_input():\n    \"\"\"Check that _wrap_in_pandas_container raises an error with sparse input.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    X_csr = csr_matrix(X)\n\n    match = \"Pandas output does not support sparse data.\"\n    with pytest.raises(ValueError, match=match):\n        _wrap_in_pandas_container(X_csr, columns=[\"a\", \"b\", \"c\"])\n", "def test__wrap_method_output():\n    \"\"\"Check that _wrap_method_output correctly wraps a method.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n        return X\n\n    wrapped_transform = _wrap_method_output(transform, \"transform\")\n    est = EstimatorWithSetOutput().set_output(transform=\"pandas\")\n    est.transform = wrapped_transform.__get__(est, type(est))\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    X_trans = est.transform(X)\n    assert isinstance(X_trans, pd.DataFrame)\n    assert_array_equal(X_trans.columns, est.get_feature_names_out())\n", "def test__wrap_method_output():\n    \"\"\"Check that _wrap_method_output is correctly wrapping methods.\"\"\"\n    class EstimatorWithSetOutput(_SetOutputMixin):\n            self.n_features_in_ = X.shape[1]\n            return self\n\n            return X\n\n            return np.asarray([f\"X{i}\" for i in range(self.n_features_in_)], dtype=object)\n\n    est = EstimatorWithSetOutput()\n    original_method = est.transform\n    wrapped_method = _wrap_method_output(original_method, \"transform\")\n    assert wrapped_method.__name__ == original_method.__name__\n    assert wrapped_method.__doc__ == original_method.__doc__\n\n    pd = pytest.importorskip(\"pandas\")\n    X = pd.DataFrame([[1, 2, 3], [4, 5, 6]])\n    est.fit(X)\n    result = wrapped_method(est, X)\n    assert isinstance(result, pd.DataFrame)\n", "def test__wrap_data_with_container():\n    \"\"\"Check that _wrap_data_with_container returns data unchanged if output config is default.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    class Estimator(_SetOutputMixin):\n            self.n_features_in_ = X.shape[1]\n            return self\n\n            return X\n\n            return np.asarray([f\"X{i}\" for i in range(self.n_features_in_)], dtype=object)\n\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    est = Estimator().fit(X)\n    est._sklearn_output_config = {\"transform\": \"default\"}\n\n    data_to_wrap = np.asarray([[1, 0, 3], [0, 0, 1]])\n    wrapped_data = _wrap_data_with_container(\"transform\", data_to_wrap, X, est)\n\n    assert isinstance(wrapped_data, np.ndarray)\n    assert_array_equal(wrapped_data, data_to_wrap)\n", "def test_wrap_method_output():\n    \"\"\"Check _wrap_method_output wrapper.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    class EstimatorWithSetOutput(_SetOutputMixin):\n            self.n_features_in_ = X.shape[1]\n            return self\n\n            return X\n\n            return np.asarray([f\"X{i}\" for i in range(self.n_features_in_)], dtype=object)\n\n    est = EstimatorWithSetOutput().fit(np.asarray([[1, 2, 3]]))\n\n    wrapped_method = _wrap_method_output(est.transform, \"transform\")\n    X = np.asarray([[1, 2, 3]])\n    X_wrapped = wrapped_method(est, X)\n    assert isinstance(X_wrapped, pd.DataFrame)\n\n    est.set_output(transform=\"default\")\n    wrapped_method = _wrap_method_output(est.transform, \"transform\")\n    X = np.asarray([[1, 2, 3]])\n    X_wrapped = wrapped_method(est, X)\n    assert isinstance(X_wrapped, np.ndarray)\n\n    # Check that the wrapped method does not change the input\n    X = np.asarray([[1, 2, 3]])\n    wrapped_method = _wrap_method_output(est.transform, \"transform\")\n    X_wrapped = wrapped_method(est, X)\n    assert X_wrapped is not X\n    assert_array_equal(X_wrapped, X)\n\n    # Check that the wrapped method works with tuple outputs\n    class EstimatorWithSetOutputCrossDecomposition(_SetOutputMixin):\n            self.n_features_in_ = X.shape[1]\n            return self\n\n            return X, X\n\n            return np.asarray([f\"X{i}\" for i in range(self.n_features_in_)], dtype=object)\n\n    est = EstimatorWithSetOutputCrossDecomposition().fit(np.asarray([[1, 2, 3]]))\n\n    wrapped_method = _wrap_method_output(est.fit_transform, \"transform\")\n    X = np.asarray([[1, 2, 3]])\n    X_wrapped = wrapped_method(est, X)\n    assert isinstance(X_wrapped[0], pd.DataFrame)\n    assert isinstance(X_wrapped[1], np.ndarray"], "sample_126": ["def test_Float_Rational():\n    assert Float(Rational(1, 2)) == Rational(1, 2)\n    assert Float(Rational(1, 2), precision=10) == Rational(1, 2)\n    assert Float(Rational(1, 2), dps=10) == Rational(1, 2)\n    raises(ValueError, lambda: Float(Rational(1, 2), precision=10, dps=10))\n    raises(ValueError, lambda: Float(Rational(1, 2), precision=\"\", dps=10))\n    raises(ValueError, lambda: Float(Rational(1, 2), precision=10, dps=\"\"))\n    raises(ValueError, lambda: Float(Rational(1, 2), precision=\"\", dps=\"\"))\n", "def test_issue_10973():\n    assert Catalan.approximation(Integer) == (Integer(0), Integer(1))\n    assert Catalan.approximation(Rational) == (Rational(9, 10), Rational(1, 1))\n    assert pi.approximation(Integer) == (Integer(3), Integer(4))\n    assert pi.approximation(Rational) == (Rational(223, 71), Rational(22, 7))\n    assert EulerGamma.approximation(Integer) == (Integer(0), Integer(1))\n    assert EulerGamma.approximation(Rational) == (Rational(1, 2), Rational(3, 5))\n    assert Exp1.approximation(Integer) == (Integer(2), Integer(3))\n    assert Exp1.approximation(Rational) == (Rational(8, 3), Rational(11, 4))\n    assert GoldenRatio.approximation(Integer) == (Integer(1), Integer(2))\n    assert GoldenRatio.approximation(Rational) == (Rational(1, 1), Rational(2, 1))\n\n    assert Catalan.approximation(Number) is None\n    assert pi.approximation(Number) is None\n    assert EulerGamma.approximation(Number) is None\n    assert Exp1.approximation(Number) is None\n    assert GoldenRatio.approximation(Number) is None\n", "def test_mod_inverse_finite():\n    assert mod_inverse(2, 5) == 3\n    assert mod_inverse(3, 5) == 2\n    assert mod_inverse(4, 5) == 4\n    assert mod_inverse(5, 5) == 0\n    assert mod_inverse(1, 5) == 1\n    assert mod_inverse(2, 7) == 4\n    assert mod_inverse(3, 7) == 5\n    assert mod_inverse(4, 7) == 2\n    assert mod_inverse(5, 7) == 3\n    assert mod_inverse(6, 7) == 6\n    assert mod_inverse(0, 7) == 0\n    assert mod_inverse(2, 8) == 5\n    assert mod_inverse(3, 8) == 3\n    assert mod_inverse(5, 8) == 5\n    assert mod_inverse(7, 8) == 7\n    assert mod_inverse(1, 8) == 1\n    assert mod_inverse(2, 9) == 5\n    assert mod_inverse(4, 9) == 7\n    assert mod_inverse(5, 9) == 2\n    assert mod_inverse(7, 9) == 4\n    assert mod_inverse(8, 9) == 8\n    assert mod_inverse(1, 9) == 1\n    assert mod_inverse(2, 10) == 8\n    assert mod_inverse(3, 10) == 7\n    assert mod_inverse(7, 10) == 3\n    assert mod_inverse(9, 10) == 9\n    assert mod_inverse(1, 10) == 1\n    assert mod_inverse(2, 11) == 6\n    assert mod_inverse(3, 11) == 4\n    assert mod_inverse(4, 11) == 3\n    assert mod_inverse(5, 11) == 9\n    assert mod_inverse(6, 11) == 2\n    assert mod_inverse(7, 11) == 8\n    assert mod_inverse(8, 11) == 7\n    assert mod_inverse(9, 11) == 5\n    assert mod_inverse(10, 11) == ", "def test_latex_names():\n    from sympy.printing.latex import latex\n\n    # Issue 10541: LaTeX names for mathematical constants\n    assert latex(S.Pi, mode=\"inline\") == r\"\\pi\"\n    assert latex(S.Pi, mode=\"equation\") == r\"\\pi\"\n    assert latex(S.Pi, mode=\"equation*\", r\"\\pi\")\n\n    assert latex(S.E, mode=\"inline\") == r\"\\mathrm{E}\"\n    assert latex(S.E, mode=\"equation\") == r\"\\mathrm{E}\"\n    assert latex(S.E, mode=\"equation*\", r\"\\mathrm{E}\")\n\n    assert latex(S.GoldenRatio, mode=\"inline\") == r\"\\phi\"\n    assert latex(S.GoldenRatio, mode=\"equation\") == r\"\\phi\"\n    assert latex(S.GoldenRatio, mode=\"equation*\", r\"\\phi\")\n\n    assert latex(S.EulerGamma, mode=\"inline\") == r\"\\gamma\"\n    assert latex(S.EulerGamma, mode=\"equation\") == r\"\\gamma\"\n    assert latex(S.EulerGamma, mode=\"equation*\", r\"\\gamma\")\n\n    assert latex(S.Catalan, mode=\"inline\") == r\"\\mathrm{Catalan}\"\n    assert latex(S.Catalan, mode=\"equation\") == r\"\\mathrm{Catalan}\"\n    assert latex(S.Catalan, mode=\"equation*\", r\"\\mathrm{Catalan}\")\n", "def test_issue_9311():\n    # Check Rational cannot be instantiated with non-integer\n    raises(ValueError, lambda: Rational(1.1, 2))\n    raises(ValueError, lambda: Rational(1, 2.2))\n\n    # Check Rational cannot be instantiated with Rational\n    raises(TypeError, lambda: Rational(Rational(1, 2), 2))\n\n    # Check Rational cannot be instantiated with non-Rational\n    raises(TypeError, lambda: Rational(1, Rational(1, 2)))\n\n    # Check Rational cannot be instantiated with invalid literal\n    raises(ValueError, lambda: Rational('1.1/2'))\n    raises(ValueError, lambda: Rational('1/2.2'))\n    raises(ValueError, lambda: Rational('1/2.2/3.3'))\n    raises(ValueError, lambda: Rational('1.1/2.2/3.3'))\n"], "sample_138": ["def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n\n    real_matrices, imag_matrices = X.as_real_imag()\n    assert real_matrices.blocks == X.blocks\n    assert imag_matrices.blocks == BlockMatrix([[ZeroMatrix(n, n), ZeroMatrix(n, m)],\n                                               [ZeroMatrix(m, n), ZeroMatrix(m, m)]])\n", "def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n    real_part, imag_part = X.as_real_imag()\n    assert real_part.is_real and imag_part.is_real\n    assert real_part + imag_part*I == X\n", "def test_BlockMatrix_inverse():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n\n    assert X.inverse().__class__ == Inverse\n\n    # Check that inverse is correctly applied\n    from sympy import eye\n    assert block_collapse(X * X.I) == BlockDiagMatrix(eye(n), eye(m))\n    assert block_collapse(X.I * X) == BlockDiagMatrix(eye(n), eye(m))\n", "def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', m, m)\n    X = BlockMatrix([[A, B]])\n    a, b = symbols('a b', real=True)\n    A_val = Matrix([[a + b*I, 2], [3, a - b*I]])\n    B_val = Matrix([[a + b*I, 2], [3, a + b*I]])\n    Y = BlockMatrix([[A_val, B_val]])\n    \n    real_part, imag_part = X.as_real_imag()\n    real_part_val, imag_part_val = Y.as_real_imag()\n    \n    assert block_collapse(real_part * real_part_val) == block_collapse(X * Y).as_real_imag()[0]\n    assert block_collapse(imag_part * imag_part_val) == block_collapse(X * Y).as_real_imag()[1]\n", "def test_block_collapse_edges():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, n)\n    C = MatrixSymbol('C', p, p)\n    D = MatrixSymbol('D', p, p)\n\n    # Edge case: block_collapse with single element tuple\n    assert block_collapse((A,)) == (A,)\n\n    # Edge case: block_collapse with empty tuple\n    assert block_collapse(()) == ()\n\n    # Edge case: block_collapse with MatrixSymbol\n    assert block_collapse(A) == A\n\n    # Edge case: block_collapse with non-matrix expressions\n    assert block_collapse(n + m) == n + m\n\n    # Edge case: block_collapse with BlockMatrix and non-block elements\n    X = BlockMatrix([[A, B]])\n    assert block_collapse((X, C)) == (X, C)\n\n    # Edge case: block_collapse with nested BlockMatrices\n    Y = BlockMatrix([[X, C]])\n    assert block_collapse(Y) == BlockMatrix([[A, B], [C, D]])\n"], "sample_117": ["def test_stringify_ForwardRef():\n    from typing import ForwardRef  # type: ignore\n    assert stringify(ForwardRef(\"myint\")) == \"myint\"\n", "def test_is_system_TypeVar():\n    from typing import TypeVar\n    T = TypeVar('T')\n    assert is_system_TypeVar(T)\n    class MyTypeVar(TypeVar):\n        pass\n    assert not is_system_TypeVar(MyTypeVar)\n", "def test_restify_type_hints_NewType():\n    assert restify(MyInt) == \":class:`MyInt`\"\n    NewInt = NewType('NewInt', int, dict(a=1))\n    assert restify(NewInt) == \":class:`NewInt`\"\n    assert restify(List[NewInt]) == \":class:`List`\\\\ [:class:`NewInt`]\"\n    assert restify(Dict[str, NewInt]) == \":class:`Dict`\\\\ [:class:`str`, :class:`NewInt`]\"  # type: ignore\n", "def test_stringify_type_hints_NewType():\n    assert stringify(MyInt) == \"MyInt\"\n    assert stringify(NewType(\"MyNewType\", int)) == \"MyNewType\"\n    assert stringify(NewType(\"MyNewType\", int, {'a': 1})) == \"MyNewType\"\n", "def test_restify_and_stringify_forwardref():\n    from typing import ForwardRef\n\n    if sys.version_info > (3, 7):\n        forward_ref = ForwardRef('tests.test_util_typing.MyClass1')\n    else:\n        forward_ref = ForwardRef('MyClass1', is_argument=False)\n\n    assert restify(forward_ref) == \":class:`tests.test_util_typing.MyClass1`\"\n    assert stringify(forward_ref) == \"tests.test_util_typing.MyClass1\"\n\n"], "sample_63": ["    def test_render(self):\n        field = ReadOnlyPasswordHashField()\n        value = (\n            \"pbkdf2_sha256$100000$a6Pucb1qSFcD$WmCkn9Hqidj48NVe5x0FEM6A9YiOqQcl/83m2Z5u\"\n            \"dm0=\"\n        )\n        widget = field.widget\n        html = widget.render(\"name\", value, {})\n        self.assertHTMLEqual(\n            html,\n            '<div>'\n            \"    <strong>algorithm</strong>: <bdi>pbkdf2_sha256</bdi>\"\n            \"    <strong>iterations</strong>: <bdi>100000</bdi>\"\n            \"    <strong>salt</strong>: <bdi>a6Pucb******</bdi>\"\n            \"    <strong>hash</strong>: \"\n            \"       <bdi>WmCkn9**************************************</bdi>\"\n            \"</div>\",\n        )\n", "    def test_required(self):\n        field = ReadOnlyPasswordHashField(required=True)\n        self.assertIs(field.required, False)\n", "    def test_integer_username_reset_password(self):\n        user = IntegerUsernameUser.objects.create_user(username=123456, password=\"test123\")\n        data = {\"email\": user.email}\n        form = PasswordResetForm(data)\n        self.assertTrue(form.is_valid())\n        form.save()\n        self.assertEqual(len(mail.outbox), 1)\n        self.assertEqual(mail.outbox[0].to, [user.email])\n", "    def test_get_users(self):\n        \"\"\"\n        Test the get_users method of the PasswordResetForm class.\n        \"\"\"\n        user1 = User.objects.create_user(\"test1\", \"test1@example.com\", \"password\")\n        user2 = User.objects.create_user(\"test2\", \"test2@example.com\", \"password\")\n        user2.is_active = False\n        user2.save()\n\n        form = PasswordResetForm({\"email\": \"test1@example.com\"})\n        self.assertTrue(form.is_valid())\n        users = form.get_users(form.cleaned_data[\"email\"])\n        self.assertEqual(list(users), [user1])\n\n        form = PasswordResetForm({\"email\": \"test2@example.com\"})\n        self.assertTrue(form.is_valid())\n        users = form.get_users(form.cleaned_data[\"email\"])\n        self.assertEqual(list(users), [])\n\n        form = PasswordResetForm({\"email\": \"nonexistent@example.com\"})\n        self.assertTrue(form.is_valid())\n        users = form.get_users(form.cleaned_data[\"email\"])\n        self.assertEqual(list(users), [])\n", "    def test_empty_string_value(self):\n        # Rendering the widget with an empty string value mustn't raise an exception.\n        widget = ReadOnlyPasswordHashWidget()\n        html = widget.render(name=\"password\", value=\"\", attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_31": ["def test_shell_with_interface_not_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import python interface.\"):\n        call_command('shell', interface='nonexistent')\n", "    def test_shell_with_no_interface_available(self, select):\n        select.return_value = ([], [], [])\n        with mock.patch.dict('sys.modules', {'IPython': None, 'bpython': None}):\n            with self.assertRaisesMessage(CommandError, \"Couldn't import python interface.\"):\n                call_command('shell')\n", "    def test_shell_with_interface_option(self, select):\n        select.return_value = ([], [], [])\n        with self.assertLogs('test', 'INFO') as cm:\n            call_command(\n                'shell',\n                interface='ipython',\n                command=(\n                    'import django; from logging import getLogger; '\n                    'getLogger(\"test\").info(django.__version__)'\n                ),\n            )\n        self.assertEqual(cm.records[0].getMessage(), __version__)\n", "    def test_shell_with_no_interface_available(self, select):\n        select.return_value = ([], [], [])\n        with self.assertRaisesMessage(CommandError, \"Couldn't import python interface.\"):\n            call_command('shell')\n", "    def test_shell_no_startup(self):\n        with captured_stdout() as stdout:\n            call_command('shell', no_startup=True)\n        self.assertNotIn('PYTHONSTARTUP', stdout.getvalue())\n"], "sample_81": ["def test_encoding_declaration(self) -> None:\n    code = \"\"\"# -*- coding: utf-8 -*-\n                a = 1\n                \"\"\"\n    with open(\"test_encoding_declaration.py\", \"w\", encoding=\"utf-8\") as f:\n        f.write(code)\n    with self.assertNoMessages():\n        self.checker.process_module(self.get_ast_module(\"test_encoding_declaration.py\"))\n    import os\n    os.remove(\"test_encoding_declaration.py\")\n", "def test_check_encoding(self) -> None:\n    code = b\"\"\"# -*- coding: utf-8 -*-\n                a = 1\n                \"\"\"\n    with self.assertNoMessages():\n        with open(\"test.py\", \"wb\") as f:\n            f.write(code)\n        with open(\"test.py\", \"rb\") as f:\n            node = astroid.parse(f.read())\n        self.checker.process_module(node)\n\n    code = b\"\"\"# -*- coding: utf-16 -*-\n                a = 1\n                \"\"\"\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"syntax-error\", line=1, args=\"Cannot decode using encoding 'utf-16', bad encoding\")\n    ):\n        with open(\"test.py\", \"wb\") as f:\n            f.write(code)\n        with open(\"test.py\", \"rb\") as f:\n            node = astroid.parse(f.read())\n        self.checker.process_module(node)\n", "    def test_notes_rgx(self) -> None:\n        code = \"\"\"a = 1\n                # NOTAG\n                # TODO\n                \"\"\"\n        with self.assertNoMessages():\n            self.checker.process_tokens(_tokenize_str(code))\n", "def test_notes_rgx(self) -> None:\n    code = \"\"\"a = 1\n            # Issue #1234\n            #FIXME\n            \"\"\"\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"fixme\", line=2, args=\"FIXME\", col_offset=17)\n    ):\n        with set_config(notes_rgx=r\"Issue #\\d+\"):\n            self.checker.open()\n            self.checker.process_tokens(_tokenize_str(code))\n            self.checker.close()\n", "    def test_non_ascii_encoding(self) -> None:\n        code = b\"\"\"# -*- coding: utf-8 -*-\n                a = 1\n                # \\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\n                \"\"\"\n        with self.assertNoMessages():\n            self.checker.process_module(nodes.Module(None, code, \"test.py\"))\n"], "sample_114": ["def test_check_partial_fit_first_call():\n    class TestClassifier:\n            self.classes_ = None\n\n    clf = TestClassifier()\n\n    # Test with classes provided\n    _check_partial_fit_first_call(clf, classes=[1, 2, 3])\n    assert clf.classes_.tolist() == [1, 2, 3]\n\n    # Test with classes already set\n    clf.classes_ = [1, 2, 3]\n    _check_partial_fit_first_call(clf, classes=[1, 2, 3])\n    assert clf.classes_.tolist() == [1, 2, 3]\n\n    # Test with classes not provided and not set\n    clf.classes_ = None\n    with pytest.raises(ValueError):\n        _check_partial_fit_first_call(clf)\n\n    # Test with different classes provided\n    clf.classes_ = [1, 2, 3]\n    with pytest.raises(ValueError):\n        _check_partial_fit_first_call(clf, classes=[1, 2, 4])\n", "def test_check_partial_fit_first_call():\n    # Test check_partial_fit_first_call for first call with classes provided\n    class Classifier:\n        pass\n\n    clf = Classifier()\n    classes = np.array([1, 2, 3])\n    assert _check_partial_fit_first_call(clf, classes)\n    assert_array_equal(clf.classes_, unique_labels(classes))\n\n    # Test check_partial_fit_first_call for subsequent calls with classes provided\n    assert not _check_partial_fit_first_call(clf, classes)\n    assert_array_equal(clf.classes_, unique_labels(classes))\n\n    # Test check_partial_fit_first_call for first call without classes provided\n    clf = Classifier()\n    with pytest.raises(ValueError):\n        _check_partial_fit_first_call(clf)\n\n    # Test check_partial_fit_first_call for subsequent calls without classes provided\n    clf.classes_ = np.array([1, 2, 3])\n    assert not _check_partial_fit_first_call(clf)\n\n    # Test check_partial_fit_first_call for subsequent calls with different classes\n    with pytest.raises(ValueError):\n        _check_partial_fit_first_call(clf, np.array([1, 2, 4]))\n", "def test_check_partial_fit_first_call():\n    # Test that an error is raised when classes is None on the first call\n    clf = MockEstimator()\n    with pytest.raises(ValueError):\n        _check_partial_fit_first_call(clf)\n\n    # Test that classes is set correctly on the first call\n    classes = [0, 1, 2]\n    assert _check_partial_fit_first_call(clf, classes=classes)\n    assert_array_equal(clf.classes_, unique_labels(classes))\n\n    # Test that an error is raised when classes is not None on the second call\n    # and is different from clf.classes_\n    with pytest.raises(ValueError):\n        _check_partial_fit_first_call(clf, classes=[0, 1])\n\n    # Test that no error is raised when classes is None on the second call\n    assert not _check_partial_fit_first_call(clf)\n", "def test_type_of_target_corner_cases():\n    # Test corner cases for type_of_target\n\n    # Test 2D array with only one row\n    assert type_of_target(np.array([[1, 2]])) == \"multiclass-multioutput\"\n\n    # Test 2D array with only one column\n    assert type_of_target(np.array([[1], [2]])) == \"multiclass\"\n\n    # Test 2D array with one row and one column\n    assert type_of_target(np.array([[1]])) == \"binary\"\n\n    # Test array with only one element\n    assert type_of_target(np.array([1])) == \"binary\"\n\n    # Test array with only one element and a float dtype\n    assert type_of_target(np.array([1.0])) == \"continuous\"\n\n    # Test 2D array with one row and one column and a float dtype\n    assert type_of_target(np.array([[1.0]])) == \"continuous\"\n", "def test_type_of_target_empty_list():\n    # Test type_of_target with an empty list\n    assert type_of_target([]) == \"unknown\"\n\n"], "sample_130": ["def test_issue_14941_with_numpy():\n    x, y = Dummy(), Dummy()\n\n    # test dict\n    f1 = lambdify([x, y], {x: 3, y: 3}, 'numpy')\n    assert f1(2, 3) == {2: 3, 3: 3}\n\n    # test tuple\n    f2 = lambdify([x, y], (y, x), 'numpy')\n    assert f2(2, 3) == (3, 2)\n\n    # test list\n    f3 = lambdify([x, y], [y, x], 'numpy')\n    assert f3(2, 3) == [3, 2]\n", "def test_lambdify_dict_arg():\n    # Test for issue #14941 (dict)\n    d1, d2 = Dummy('d1'), Dummy('d2')\n    f1 = lambdify([d1, d2], {d1: d2, d2: d1}, 'sympy')\n    assert f1(2, 3) == {2: 3, 3: 2}\n    f2 = lambdify([d1], {d1: d1}, 'sympy')\n    assert f2(3) == {3: 3}\n", "def test_lambdify_expr_too_complex():\n    # Test for issue 11312\n    f = lambdify(x, Piecewise((x, Eq(x, 0)), (1, True), (2, True)))\n    raises(ValueError, lambda: f(1))\n", "def test_tensorflow_nonzero_args():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n\n    f = lambdify(x, x**2, 'tensorflow')\n\n    # Test that nonzero args are correctly passed as tensorflow constants\n    s = tensorflow.Session()\n    assert s.run(f(tensorflow.constant(2))) == 4\n    assert s.run(f(tensorflow.constant(2.5))) == 6.25\n    assert s.run(f(tensorflow.constant(2+3j))) == 13.0\n", "def test_mpmath_matrix():\n    # Test for issue 15027\n    if not mpmath:\n        skip(\"mpmath not installed.\")\n\n    mpmath.mp.dps = 50\n    A = Matrix([[x, x*y], [sin(z) + 4, x**z]])\n    sol_arr = mpmath.nmatrix([[1, 2], [mpmath.sin(3) + 4, 1]])\n    f = lambdify((x, y, z), A, 'mpmath')\n    numpy.testing.assert_allclose(f(1, 2, 3), sol_arr)\n    assert isinstance(f(1, 2, 3), mpmath.nmatrix)\n"], "sample_131": ["def test_user_functions():\n    assert mcode(sin(x), user_functions={\"sin\": \"MySin\"}) == \"MySin[x]\"\n    assert mcode(cos(x), user_functions={\"cos\": lambda *x: \"MyCos\"}) == \"MyCos[x]\"\n    assert mcode(f(x, y, z), user_functions={\"f\": \"MyF\"}) == \"MyF[x, y, z]\"\n    assert mcode(Max(x,y,z), user_functions={\"Max\": \"MyMax\"}) == \"MyMax[x, y, z]\"\n    assert mcode(Min(x,y,z), user_functions={\"Min\": \"MyMin\"}) == \"MyMin[x, y, z]\"\n", "def test_NegativeOne():\n    assert mcode(-1) == \"-1\"\n    assert mcode(-S.One) == \"-1\"\n\n", "def test_Parenthesis():\n    assert mcode((x + y)*z) == \"z*(x + y)\"\n    assert mcode(x + (y + z)) == \"x + (y + z)\"\n    assert mcode(x*(y + z)) == \"x*(y + z)\"\n    assert mcode((x + y)/(z + 1)) == \"(x + y)/(z + 1)\"\n    assert mcode(x**((y + 1)/(z - 1))) == \"x^((y + 1)/(z - 1))\"\n", "def test_unsupported_functions():\n    assert mcode(log(x)) == \"log[x]\"  # default function name when not in known_functions\n    class CustomFunction(Function):\n        pass\n    assert mcode(CustomFunction(x)) == \"CustomFunction[x]\"  # custom function name\n    f = Function('f')\n    assert mcode(f(x, y, z, evaluate=False)) == \"f[x, y, z]\"  # function name with evaluate=False\n", "def test_user_defined_functions():\n    assert mcode(f(x, y), user_functions={'f': 'myf'}) == \"myf[x, y]\"\n    assert mcode(g(x, y), user_functions={'g': lambda *x: 'myg'}) == \"myg[x, y]\"\n    assert mcode(h(x, y, z), user_functions={'h': ['h1', 'h2']}) == \"h1[x, y, z]\"\n    assert mcode(h(x, y, z), user_functions={'h': [(lambda a, b, c: b > c, 'h1'), \n                                                   (lambda a, b, c: b <= c, 'h2')]}) == \"h1[x, y, z]\"\n\n        return x > y\n    assert mcode(g(x, y), user_functions={'g': [(g_func, 'myg1'), \n                                                (lambda a, b: a <= b, 'myg2')]}) == \"myg1[x, y]\"\n"], "sample_32": ["    def test_key_transform_iexact(self):\n        self.assertIs(NullableJSONModel.objects.filter(value__foo__iexact='BaR').exists(), True)\n        self.assertIs(NullableJSONModel.objects.filter(value__foo__iexact='\"BaR\"').exists(), False)\n        self.assertIs(NullableJSONModel.objects.filter(value__foo__iexact='bar').exists(), True)\n        self.assertIs(NullableJSONModel.objects.filter(value__foo__iexact='\"bar\"').exists(), False)\n", "def test_key_transform_oracle_json_query(self):\n    value = {'d': {'f': 'g'}}\n    obj = NullableJSONModel.objects.create(value=value)\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__d__f__exact='g'),\n        [obj],\n    )\n", "    def test_nested_key_transform_with_custom_encoder_decoder(self):\n        value = {\n            'name': 'John',\n            'age': 20,\n            'pets': [\n                {'name': 'Kit', 'type': 'cat', 'age': 2},\n                {'name': 'Max', 'type': 'dog', 'age': 1},\n            ],\n        }\n        obj = NullableJSONModel.objects.create(value_custom=value)\n        self.assertEqual(\n            NullableJSONModel.objects.filter(value_custom__name='John').get(),\n            obj,\n        )\n        self.assertEqual(\n            NullableJSONModel.objects.filter(value_custom__pets__0__name='Kit').get(),\n            obj,\n        )\n        self.assertEqual(\n            NullableJSONModel.objects.filter(value_custom__pets__has_key=0).get(),\n            obj,\n        )\n", "    def test_key_transform_lookups(self):\n        obj = NullableJSONModel.objects.create(value={'d': ['e', {'f': 'g'}, {'f': 'h'}]})\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__d__1__f__startswith='g'),\n            [obj],\n        )\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__d__1__f__istartswith='G'),\n            [obj],\n        )\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__d__1__f__endswith='h'),\n            [obj],\n        )\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__d__1__f__iendswith='H'),\n            [obj],\n        )\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__d__1__f__regex=r'^g$'),\n            [obj],\n        )\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__d__1__f__iregex=r'^G$'),\n            [obj],\n        )\n", "    def setUpTestData(cls):\n        cls.objs = [\n            NullableJSONModel.objects.create(value={'a': [1, {'b': [2, 3, {'c': 4}]}]}),\n            NullableJSONModel.objects.create(value={'a': [{'b': [2, 3, {'c': 4}]}]}),\n            NullableJSONModel.objects.create(value={'a': [1, {'b': [{'c': 4}]}]}),\n        ]\n"], "sample_128": ["def test_Options_init():\n    opt = Options((x, y), {'domain': 'ZZ', 'order': 'lex'})\n    assert opt['gens'] == (x, y)\n    assert opt['domain'] == ZZ\n    assert opt['order'] == lex\n\n    raises(OptionError, lambda: Options((x, y), {'domain': 'ZZ', 'order': 'invalid'}))\n    raises(OptionError, lambda: Options((x, y), {'domain': 'invalid', 'order': 'lex'}))\n\n    raises(GeneratorsError, lambda: Options((x, x), {'domain': 'ZZ', 'order': 'lex'}))\n\n    raises(GeneratorsError, lambda: Options((x, y, z), {'domain': ZZ[x], 'order': 'lex'}))\n    raises(GeneratorsError, lambda: Options((), {'domain': EX, 'order': 'lex'}))\n", "def test_Options_init():\n    opt = Options((x, y), {'domain': 'ZZ', 'auto': False})\n\n    assert opt.domain == ZZ\n    assert opt.auto == False\n    assert opt.gens == (x, y)\n\n    raises(OptionError, lambda: Options((x, y), {'domain': 'ZZ', 'auto': 'abc'}))\n    raises(OptionError, lambda: Options((x, y), {'gens': (x, y, y), 'domain': 'ZZ'}))\n    raises(GeneratorsError, lambda: Options((x, y), {'gens': (x, x**2), 'domain': 'ZZ[x]'}))\n", "def test_Options_init():\n    opt = Options((x, y), {'domain': 'ZZ', 'order': 'lex'})\n\n    assert opt.gens == (x, y)\n    assert opt.domain == ZZ\n    assert opt.order == lex\n\n    raises(OptionError, lambda: Options((x, y), {'domain': 'abc'}))\n    raises(OptionError, lambda: Options((x, y), {'order': 'abc'}))\n\n    raises(GeneratorsError, lambda: Options((x, x), {'domain': 'ZZ'}))\n    raises(GeneratorsError, lambda: Options((x, y, Symbol('a', commutative=False)), {'domain': 'ZZ'}))\n\n    opt = Options((x, y), {'domain': 'ZZ', 'field': True})\n    assert opt.auto is False\n\n    opt = Options((x, y), {'domain': 'ZZ', 'gaussian': True})\n    assert opt.auto is False\n    assert opt.extension == {I}\n    assert opt.domain == QQ.algebraic_field(I)\n\n    opt = Options((x, y), {'domain': 'ZZ', 'gaussian': True, 'symmetric': False})\n    assert opt.auto is False\n    assert opt.extension == {I}\n    assert opt.domain == QQ.algebraic_field(I)\n\n    raises(NotImplementedError, lambda: Options((x, y), {'split': True}))\n", "def test_Options_init():\n    opt = Options((x, y, z), {'domain': 'ZZ', 'gens': (x, y, z)})\n    raises(OptionError, lambda: opt)\n\n    opt = Options((x, y, z), {'domain': 'ZZ', 'auto': True})\n    raises(OptionError, lambda: opt)\n\n    opt = Options((x, y, z), {'domain': 'ZZ', 'frac': True}, ['frac'])\n    raises(OptionError, lambda: opt)\n\n    opt = Options((x, y, z), {'domain': 'ZZ'})\n    assert opt.domain == ZZ\n    assert opt.gens == (x, y, z)\n\n    opt = Options((), {'domain': 'ZZ'})\n    assert opt.domain == ZZ\n    assert opt.gens == ()\n\n    opt = Options((x, y, z), {'gens': (x, y, z)})\n    assert opt.domain == None\n    assert opt.gens == (x, y, z)\n\n    opt = Options((), {})\n    assert opt.domain == None\n    assert opt.gens == ()\n", "def test_Options_init():\n    opt1 = Options((x, y), {'domain': 'ZZ', 'gens': (x, y)})\n\n    raises(OptionError, lambda: opt1)\n\n    opt2 = Options((x, y), {'domain': 'ZZ'})\n\n    assert opt2['gens'] == (x, y)\n    assert opt2['domain'] == ZZ\n\n    opt3 = Options((x, y, z), {'domain': 'ZZ', 'gens': (x, y)})\n\n    raises(OptionError, lambda: opt3)\n\n    opt4 = Options({}, {'domain': 'ZZ', 'gens': (x, y)})\n\n    assert opt4['gens'] == (x, y)\n    assert opt4['domain'] == ZZ\n\n    opt5 = Options({}, {'domain': 'ZZ', 'gens': ((x, y),)})\n\n    assert opt5['gens'] == (x, y)\n    assert opt5['domain'] == ZZ\n\n    raises(GeneratorsError, lambda: Options({}, {'domain': 'ZZ', 'gens': (x, x)}))\n\n    raises(GeneratorsError, lambda: Options({}, {'domain': 'ZZ', 'gens': (x, y, z)}))\n\n    opt6 = Options({}, {'domain': 'EX'})\n\n    raises(GeneratorsError, lambda: opt6)\n"], "sample_144": ["def test_refine_nested_abs():\n    assert refine(Abs(Abs(x)), Q.real(x)) == Abs(x)\n    assert refine(Abs(Abs(x)), Q.positive(x)) == x\n    assert refine(Abs(Abs(x)), Q.negative(x)) == -x\n    assert refine(Abs(Abs(Abs(x))), Q.real(x)) == Abs(x)\n    assert refine(Abs(Abs(Abs(x))), Q.positive(x)) == x\n    assert refine(Abs(Abs(Abs(x))), Q.negative(x)) == -x\n", "def test_refine_handler_coverage():\n    assert refine(Abs(x), Q.positive(x)) == x\n    assert refine(Abs(x), Q.negative(x)) == -x\n    assert refine((-1)**x, Q.even(x)) == 1\n    assert refine((-1)**x, Q.odd(x)) == -1\n    assert refine(atan2(y, x), Q.real(y) & Q.positive(x)) == atan(y/x)\n    assert refine(re(x), Q.real(x)) == x\n    assert refine(im(x), Q.imaginary(x)) == -I*x\n    assert refine(arg(x), Q.positive(x)) == 0\n    assert refine(sign(x), Q.positive(x)) == 1\n    assert refine(x[1, 0], Q.symmetric(x)) == x[0, 1]\n", "def test_refine_with_nested_abs():\n    assert refine(Abs(Abs(x)), Q.real(x)) == Abs(x)\n    assert refine(Abs(Abs(x)), Q.positive(x)) == x\n    assert refine(Abs(Abs(x)), Q.negative(x)) == -x\n", "def test_refine_repeated_application():\n    assert refine(refine(Abs(x), Q.positive(x)), Q.positive(x)) == x\n    assert refine(refine(Abs(x), Q.negative(x)), Q.negative(x)) == -x\n    assert refine(refine((-1)**x, Q.even(x)), Q.even(x)) == 1\n    assert refine(refine((-1)**x, Q.odd(x)), Q.odd(x)) == -1\n    assert refine(refine(sqrt(x**2), Q.real(x)), Q.real(x)) == Abs(x)\n    assert refine(refine(sqrt(x**2), Q.positive(x)), Q.positive(x)) == x\n\n    # Test repeated application on complex expression\n    expr = Abs(x) * (-1)**x\n    refined_expr = refine(expr, Q.positive(x) & Q.even(x))\n    assert refine(refined_expr, Q.positive(x) & Q.even(x)) == x\n", "def test_refine_with_nested_expressions():\n    x = Symbol('x', real=True)\n    y = Symbol('y', real=True)\n    assert refine(sqrt(x**2 + y**2), Q.positive(x) & Q.positive(y)) == sqrt(x**2 + y**2)\n    assert refine(Abs(x + y), Q.positive(x) & Q.positive(y)) == x + y\n    assert refine(Abs(x - y), Q.positive(x) & Q.positive(y)) == Abs(x - y)\n    assert refine(sign(x + y), Q.positive(x) & Q.positive(y)) == 1\n    assert refine(arg(x + y), Q.positive(x) & Q.positive(y)) == 0\n"], "sample_35": ["    def test_model_form_metaclass(self):\n        class TestModel:\n            class Meta:\n                pass\n\n        class TestForm(ModelForm):\n            class Meta:\n                model = TestModel\n                fields = ['field1', 'field2']\n\n        self.assertEqual(TestForm._meta.model, TestModel)\n        self.assertEqual(TestForm._meta.fields, ['field1', 'field2'])\n", "    def test_model_to_dict(self):\n        from ..models import ChoiceModel\n        obj = ChoiceModel.objects.create(name='Test')\n        expected_dict = {'name': 'Test'}\n        self.assertEqual(model_to_dict(obj), expected_dict)\n", "    def test_model_form_save_with_invalid_data(self):\n        class TestModel(models.Model):\n            name = models.CharField(max_length=10)\n            age = models.IntegerField()\n\n        class TestForm(ModelForm):\n            class Meta:\n                model = TestModel\n                fields = ('name', 'age')\n\n        form = TestForm({'name': 'test_name', 'age': 'invalid_age'})\n        self.assertFalse(form.is_valid())\n\n        with self.assertRaises(ValueError):\n            form.save()\n", "    def test_save_model_with_unique_fields(self):\n        # Create a model with unique fields\n        from django.db import models\n        class UniqueModel(models.Model):\n            unique_field = models.CharField(max_length=10, unique=True)\n            another_field = models.CharField(max_length=10)\n\n        # Create a form for the model\n        class UniqueForm(forms.ModelForm):\n            class Meta:\n                model = UniqueModel\n                fields = ['unique_field', 'another_field']\n\n        # Create a unique model instance\n        unique_instance = UniqueModel(unique_field='unique', another_field='another')\n        unique_instance.save()\n\n        # Create a new form with a duplicate unique field\n        form = UniqueForm({'unique_field': 'unique', 'another_field': 'another'})\n\n        # Check that the form is invalid\n        self.assertFalse(form.is_valid())\n\n        # Check that the error message is correct\n        self.assertEqual(form.errors['unique_field'], ['This field must be unique.'])\n", "    def test_model_form_save(self):\n        class Book(models.Model):\n            title = models.CharField(max_length=100)\n            author = models.CharField(max_length=100)\n\n        class BookForm(forms.ModelForm):\n            class Meta:\n                model = Book\n                fields = ('title', 'author')\n\n        # Test saving a new instance\n        form_data = {'title': 'Book title', 'author': 'John Doe'}\n        form = BookForm(data=form_data)\n        self.assertTrue(form.is_valid())\n        book = form.save()\n        self.assertEqual(book.title, 'Book title')\n        self.assertEqual(book.author, 'John Doe')\n\n        # Test updating an existing instance\n        book.title = 'New title'\n        form_data = {'title': 'Book title updated', 'author': 'Jane Doe'}\n        form = BookForm(data=form_data, instance=book)\n        self.assertTrue(form.is_valid())\n        form.save()\n        book.refresh_from_db()\n        self.assertEqual(book.title, 'Book title updated')\n        self.assertEqual(book.author, 'Jane Doe')\n"], "sample_61": ["def test_invalid_inputs(self):\n    with self.assertRaises(TypeError):\n        nformat(object(), \".\", decimal_pos=2)\n\n    with self.assertRaises(ValueError):\n        nformat(1234, \".\", decimal_pos=-1)\n\n    with self.assertRaises(ValueError):\n        nformat(1234, \".\", decimal_pos=\"two\")\n\n    with self.assertRaises(ValueError):\n        nformat(1234, \".\", grouping=-1)\n\n    with self.assertRaises(ValueError):\n        nformat(1234, \".\", grouping=\"three\")\n\n    with self.assertRaises(ValueError):\n        nformat(1234, \".\", thousand_sep=1234)\n\n    with self.assertRaises(ValueError):\n        nformat(1234, \".\", use_l10n=1234)\n", "def test_invalid_input(self):\n    with self.assertRaises(TypeError):\n        nformat(None, None)\n    with self.assertRaises(TypeError):\n        nformat(object(), \".\")\n    with self.assertRaises(ValueError):\n        nformat(1234, \".\")\n    with self.assertRaises(ValueError):\n        nformat(1234, \".\")\n    with self.assertRaises(TypeError):\n        nformat(1234, \".\", decimal_pos=\"two\")\n    with self.assertRaises(TypeError):\n        nformat(1234, \".\", grouping=\"three\")\n    with self.assertRaises(TypeError):\n        nformat(1234, \".\", thousand_sep=123)\n    with self.assertRaises(TypeError):\n        nformat(1234, \".\", force_grouping=\"always\")\n    with self.assertRaises(TypeError):\n        nformat(1234, \".\", use_l10n=\"always\")\n", "def test_edge_cases(self):\n    # Test with non-string decimal separator\n    self.assertEqual(nformat(1234, \",\"), \"1234\")\n    self.assertEqual(nformat(1234.2, \",\"), \"1234,2\")\n    # Test with non-string thousand separator\n    self.assertEqual(nformat(1234, \".\", thousand_sep=\",\"), \"1234\")\n    self.assertEqual(nformat(1234, \".\", grouping=3, thousand_sep=\",\"), \"1,234\")\n    # Test with invalid grouping value\n    with self.assertRaises(TypeError):\n        nformat(1234, \".\", grouping=\"three\", thousand_sep=\",\")\n    # Test with invalid decimal_pos value\n    with self.assertRaises(TypeError):\n        nformat(1234, \".\", decimal_pos=\"two\", thousand_sep=\",\")\n", "def test_edge_cases(self):\n    # Test handling of special values like NaN and Infinity\n    self.assertEqual(nformat(float(\"nan\"), \".\"), \"nan\")\n    self.assertEqual(nformat(float(\"inf\"), \".\"), \"inf\")\n    self.assertEqual(nformat(float(\"-inf\"), \".\"), \"-inf\")\n\n    # Test handling of very small numbers close to zero\n    self.assertEqual(nformat(1e-323, \".\"), \"0.0\")\n    self.assertEqual(nformat(-1e-323, \".\"), \"-0.0\")\n\n    # Test handling of numbers with a large number of decimal places\n    self.assertEqual(nformat(Decimal(\"0.\" + \"1\" * 100), \".\"), \"0.\" + \"1\" * 100)\n\n    # Test handling of numbers with a large number of digits before the decimal point\n    self.assertEqual(nformat(Decimal(\"1\" * 100 + \".0\"), \".\"), \"1\" * 100 + \".0\")\n", "def test_edge_cases(self):\n    # Test with very large decimal positions\n    self.assertEqual(nformat(1234, \".\", decimal_pos=1000), \"1234.000...\")  # truncated for brevity\n    self.assertEqual(nformat(Decimal(\"1234\"), \".\", decimal_pos=1000), \"1234.000...\")  # truncated for brevity\n\n    # Test with negative decimal positions\n    self.assertEqual(nformat(1234, \".\", decimal_pos=-1), \"1234\")\n    self.assertEqual(nformat(Decimal(\"1234\"), \".\", decimal_pos=-1), \"1234\")\n\n    # Test with decimal positions that are not integers\n    self.assertEqual(nformat(1234, \".\", decimal_pos=1.5), \"1234.00\")\n    self.assertEqual(nformat(Decimal(\"1234\"), \".\", decimal_pos=1.5), \"1234.00\")\n\n    # Test with non-string decimal separators\n    self.assertEqual(nformat(1234, 1), \"1234\")\n    self.assertEqual(nformat(Decimal(\"1234\"), 1), \"1234\")\n\n    # Test with non-string thousand separators\n    self.assertEqual(nformat(1234, \".\", thousand_sep=1), \"1234\")\n    self.assertEqual(nformat(Decimal(\"1234\"), \".\", thousand_sep=1), \"1234\")\n\n    # Test with grouping that is not an integer or a sequence\n    self.assertEqual(nformat(1234, \".\", grouping=\"test\"), \"1234\")\n    self.assertEqual(nformat(Decimal(\"1234\"), \".\", grouping=\"test\"), \"1234\")\n"], "sample_108": ["def test_sparse_linear_kernel():\n    # Test that sparse linear kernel works correctly\n    X = sparse.csr_matrix(np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]))\n    y = np.array([0, 1, 2])\n\n    clf = svm.SVC(kernel='linear')\n    clf.fit(X, y)\n    assert clf.score(X, y) == 1.0\n\n    # Test that sparse linear kernel works correctly with sample weights\n    sample_weight = np.array([1.0, 2.0, 3.0])\n    clf.fit(X, y, sample_weight=sample_weight)\n    assert clf.score(X, y) == 1.0\n", "def test_base_libsvmGammaAutoScale():\n    X = [[0.], [1.]]\n    y = [0, 1]\n\n    # test with auto\n    clf = svm.SVC(gamma='auto')\n    clf.fit(X, y)\n    assert clf._gamma == 1.0 / X[0].__len__()\n\n    # test with scale\n    clf = svm.SVC(gamma='scale')\n    clf.fit(X, y)\n    assert clf._gamma == 1.0 / (X[0].__len__() * np.var(X))\n", "def test_base_libsvm_attributes():\n    # Test BaseLibSVM attributes\n    class TestBaseLibSVM(BaseLibSVM):\n            pass\n\n    test_clf = TestBaseLibSVM()\n    assert hasattr(test_clf, 'shape_fit_')\n    assert hasattr(test_clf, 'coef_')\n    assert hasattr(test_clf, 'n_support_')\n\n    with pytest.raises(NotImplementedError):\n        test_clf.fit(X, Y)\n    with pytest.raises(NotImplementedError):\n        test_clf._validate_targets(Y)\n    with pytest.raises(NotImplementedError):\n        test_clf._get_coef()\n", "def test_sparse_precomputed_kernel():\n    # Test that a sparse precomputed kernel is not supported\n    X_train = sparse.csr_matrix(np.random.rand(10, 10))\n    y_train = np.random.randint(0, 2, 10)\n    clf = svm.SVC(kernel='precomputed')\n    with pytest.raises(TypeError, match='Sparse precomputed kernels are not supported'):\n        clf.fit(X_train, y_train)\n\n    X_train = sparse.csr_matrix(np.random.rand(10, 10))\n    X_test = sparse.csr_matrix(np.random.rand(5, 10))\n    clf = svm.SVC(kernel='precomputed').fit(X_train, y_train)\n    with pytest.raises(ValueError, match='X.shape[1] should be equal to %d, the number of samples at training time'):\n        clf.predict(X_test.T)\n", "def test_base_libsvm_fit_input_validation():\n    # test that fit input validation works correctly\n    clf = BaseLibSVM(kernel='linear', degree=3, gamma='auto', coef0=0.0,\n                     tol=1e-3, C=1.0, nu=0.5, epsilon=1e-3, shrinking=True,\n                     probability=True, cache_size=200, class_weight=None,\n                     verbose=0, max_iter=-1000, random_state=None)\n    \n    X = np.array([[1, 2], [1, 4], [2, 4], [2, 3]])\n    y = np.array([0, 0, 1, 1])\n    \n    with pytest.raises(ValueError):\n        clf.fit(X, y)\n\n    clf = BaseLibSVM(kernel='linear', degree=3, gamma='auto', coef0=0.0,\n                     tol=1e-3, C=1.0, nu=0.5, epsilon=1e-3, shrinking=True,\n                     probability=True, cache_size=200, class_weight=None,\n                     verbose=0, max_iter=1000, random_state=None)\n    \n    X = np.array([[1, 2], [1, 4], [2, 4], [2, 3]])\n    y = np.array([0, 0, 1, 1, 2])\n    \n    with pytest.raises(ValueError):\n        clf.fit(X, y)\n\n    X = np.array([[1, 2], [1, 4], [2, 4]])\n    y = np.array([0, 0, 1, 1])\n    \n    with pytest.raises(ValueError):\n        clf.fit(X, y)\n"], "sample_141": ["def test_quantity_simplify():\n    v_w1 = Quantity('v_w1')\n    v_w2 = Quantity('v_w2')\n    v_w1.set_global_relative_scale_factor(S(1), meter/second)\n    v_w2.set_global_relative_scale_factor(S(1), meter/second)\n    assert quantity_simplify(kilo*foot*inch) == 250*foot**2/3\n    assert quantity_simplify(foot - 6*inch) == foot/2\n    assert quantity_simplify(v_w1) == v_w1\n    assert quantity_simplify(v_w1/v_w2) == 1\n    assert quantity_simplify(v_w1 + v_w2) == 2*v_w1\n", "def test_check_dimensions():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n    w = Quantity(\"w\")\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    w.set_global_relative_scale_factor(S(2), second)\n\n    # Test no ValueError is raised when addends have the same dimension\n    check_dimensions(u + v)\n\n    # Test ValueError is raised when addends have different dimensions\n    raises(ValueError, lambda: check_dimensions(u + w))\n\n    # Test ValueError is raised when addends have different dimensions\n    raises(ValueError, lambda: check_dimensions(v + 1))\n\n    # Test ValueError is raised when addends have different dimensions\n    raises(ValueError, lambda: check_dimensions(u - w))\n\n    # Test ValueError is raised when addends have different dimensions\n    raises(ValueError, lambda: check_dimensions(u - 1))\n\n    # Test ValueError is raised when addends have different dimensions\n    raises(ValueError, lambda: check_dimensions(1 - exp(u / w)))\n", "def test_convert_to_dimensionless_quantity():\n    q = Quantity(\"q\")\n    q.set_global_relative_scale_factor(10, 1/meter**2)\n    assert convert_to(q, meter**2) == 10\n    assert convert_to(2 * q, meter**2) == 20\n    assert convert_to(q**2, meter**4) == 100\n", "def test_quantity_simplify():\n    v_w1 = Quantity('v_w1')\n    v_w2 = Quantity('v_w2')\n    v_w3 = Quantity('v_w3')\n\n    v_w1.set_global_relative_scale_factor(1, meter/second)\n    v_w2.set_global_relative_scale_factor(1, meter/second)\n    v_w3.set_global_relative_scale_factor(1, meter/second)\n\n    assert quantity_simplify(v_w1*v_w2) == v_w1*v_w2\n    assert quantity_simplify(v_w1 + v_w2) == v_w1 + v_w2\n    assert quantity_simplify(v_w1*v_w2/v_w3) == v_w1*v_w2/v_w3\n    assert quantity_simplify(v_w1/v_w2) == v_w1/v_w2\n\n    # Testing with prefixes\n    assert quantity_simplify(kilo*v_w1) == 1000*v_w1\n    assert quantity_simplify(milli*v_w2) == v_w2/1000\n    assert quantity_simplify(v_w3*kilo) == 1000*v_w3\n\n    # Testing with quantities of the same dimension\n    v_w4 = Quantity('v_w4')\n    v_w4.set_global_relative_scale_factor(2, meter/second)\n    assert quantity_simplify(v_w1 + v_w4) == (v_w1 + 2*v_w1)\n\n    # Testing with quantities of different dimensions\n    v_w5 = Quantity('v_w5')\n    v_w5.set_global_relative_scale_factor(2, meter/second**2)\n    assert quantity_simplify(v_w1 + v_w5) == v_w1 + v_w5\n", "def test_quantity_simplify():\n    # Test that quantity_simplify correctly replaces prefixes with numerical values\n    assert quantity_simplify(kilo*foot*inch) == 250*foot**2/3\n\n    # Test that quantity_simplify correctly unifies units of a given dimension\n    assert quantity_simplify(foot - 6*inch) == foot/2\n\n    # Test that quantity_simplify does not affect quantities without prefixes or units\n    u = Quantity(\"u\")\n    u.set_global_relative_scale_factor(S.One, meter)\n    assert quantity_simplify(u) == u\n\n    # Test that quantity_simplify works with more complex expressions\n    assert quantity_simplify(kilo*foot**2 + 3*inch**2) == 250*foot**2/3 + 9*foot**2/25\n\n    # Test that quantity_simplify works with expressions containing multiple units\n    assert quantity_simplify(kilo*foot**2 * joule) == 250*foot**2/3 * joule\n\n    # Test that quantity_simplify works with expressions containing prefixes\n    assert quantity_simplify(kilo*foot**2 + mega*joule) == 250*foot**2/3 + 1000000*joule\n\n    # Test that quantity_simplify works with expressions containing quantities\n    v = Quantity(\"v\")\n    v.set_global_relative_scale_factor(S(2), meter)\n    assert quantity_simplify(kilo*foot**2 + v**2) == 250*foot**2/3 + 4*meter**2\n"], "sample_142": ["def test_generate_bell_large_n():\n    \"\"\"Test generate_bell for larger n.\"\"\"\n    assert len(list(generate_bell(7))) == factorial(7)\n", "def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [\n        (0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((0, 1))) == [(0, 1), (0, -1)]\n    assert list(permute_signs((0, 0))) == [(0, 0)]\n    assert list(permute_signs([1, 1])) == [(1, 1), (-1, 1), (1, -1), (-1, -1)]\n    assert list(permute_signs((1, 2, 3, 4))) == [\n        (1, 2, 3, 4), (-1, 2, 3, 4), (1, -2, 3, 4), (1, 2, -3, 4), (1, 2, 3, -4),\n        (-1, -2, 3, 4), (-1, 2, -3, 4), (-1, 2, 3, -4), (1, -2, -3, 4),\n        (1, -2, 3, -4), (1, 2, -3, -4), (-1, -2, -3, 4), (-1, -2, 3, -4),\n        (-1, 2, -3, -4), (-1, -2, -3, -4), (1, -2, -3, -4)]\n", "def test_permute_signs():\n    assert list(permute_signs((0, 1, 2, 3))) == [\n        (0, 1, 2, 3), (0, -1, 2, 3), (0, 1, -2, 3), (0, -1, -2, 3),\n        (0, 1, 2, -3), (0, -1, 2, -3), (0, 1, -2, -3), (0, -1, -2, -3),\n    ]\n    assert list(permute_signs((0, 1, 1))) == [\n        (0, 1, 1), (0, -1, 1), (0, 1, -1), (0, -1, -1),\n    ]\n    assert list(permute_signs((0, 0, 0))) == [\n        (0, 0, 0),\n    ]\n    assert list(permute_signs((-1, 1))) == [\n        (-1, 1), (1, 1), (-1, -1), (1, -1),\n    ]\n", "def test_reshape_with_tuples():\n    # Test reshaping when the input is a tuple.\n    assert reshape(tuple(range(9)), [3, 3]) == [(0, 1, 2), (3, 4, 5), (6, 7, 8)]\n    assert reshape(tuple(range(8)), (2, 4)) == [(0, 1, 2, 3), (4, 5, 6, 7)]\n    assert reshape(tuple(range(6)), (2, [3])) == [(0, 1, 2), (3, 4, 5)]\n", "def test_least_rotation():\n    assert least_rotation([3, 1, 5, 1, 2]) == 3\n    assert rotate_left([3, 1, 5, 1, 2], 3) == [1, 2, 3, 1, 5]\n    assert least_rotation([1, 2, 3]) == 0\n    assert least_rotation([3, 2, 1]) == 0\n    assert least_rotation([3, 1, 1, 3, 2, 1]) == 1\n    assert least_rotation([1, 1, 1, 1, 1, 1]) == 0\n    assert least_rotation([5, 5, 5, 5, 5, 5]) == 0\n    assert least_rotation([1, 2, 3, 2, 1]) == 2\n    assert least_rotation([1, 2, 3, 1, 2]) == 0\n    assert least_rotation([1, 2, 2, 1, 3]) == 2\n    assert least_rotation([1, 3, 2, 2, 1]) == 0\n"], "sample_105": ["def test_voting_regressor_sample_weight():\n    \"\"\"Test VotingRegressor with sample weights.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(n_estimators=5)\n    ereg = VotingRegressor([('lr', reg1), ('rf', reg2)])\n\n    X_r_train, X_r_test, y_r_train, y_r_test = \\\n        train_test_split(X_r, y_r, test_size=.25)\n\n    ereg.fit(X_r_train, y_r_train, sample_weight=np.ones((len(y_r_train),)))\n    ereg.fit(X_r_train, y_r_train)\n\n    assert_array_almost_equal(ereg.predict(X_r_test),\n                              ereg.predict(X_r_test))\n\n    sample_weight = np.random.RandomState(123).uniform(size=(len(y_r_train),))\n    ereg.fit(X_r_train, y_r_train, sample_weight)\n    reg1.fit(X_r_train, y_r_train, sample_weight)\n    assert_array_almost_equal(ereg.predict(X_r_test),\n                              reg1.predict(X_r_test))\n", "def test_voting_regressor_with_sample_weight():\n    \"\"\"Tests sample_weight parameter of VotingRegressor\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(random_state=123)\n    reg3 = DummyRegressor(strategy='quantile', quantile=.2)\n    ereg1 = VotingRegressor([('lr', reg1), ('rf', reg2), ('dr', reg3)]).fit(X_r, y_r, sample_weight=np.ones((len(y_r),)))\n    ereg2 = VotingRegressor([('lr', reg1), ('rf', reg2), ('dr', reg3)]).fit(X_r, y_r)\n    assert_array_almost_equal(ereg1.predict(X_r), ereg2.predict(X_r))\n\n    sample_weight = np.random.RandomState(123).uniform(size=(len(y_r),))\n    ereg3 = VotingRegressor([('lr', reg1)]).fit(X_r, y_r, sample_weight)\n    reg1.fit(X_r, y_r, sample_weight)\n    assert_array_almost_equal(ereg3.predict(X_r), reg1.predict(X_r))\n\n    reg4 = DummyRegressor(strategy='constant', constant=5.0)\n    ereg3 = VotingRegressor([('lr', reg1), ('dr', reg4)]).fit(X_r, y_r, sample_weight)\n    msg = ('Underlying estimator \\'dr\\' does not support sample weights.')\n    assert_raise_message(ValueError, msg, ereg3.fit, X_r, y_r, sample_weight)\n", "def test_voting_classifier_with_sample_weight_and_varying_estimators():\n    \"\"\"Test VotingClassifier with sample weights and varying estimators.\"\"\"\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    clf3 = GaussianNB()\n    eclf1 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft').fit(X, y, sample_weight=np.ones((len(y),)))\n    eclf2 = VotingClassifier(estimators=[\n        ('lr', clf1), ('gnb', clf3)],\n        voting='soft').fit(X, y, sample_weight=np.ones((len(y),)))\n\n    assert_array_almost_equal(eclf1.predict_proba(X), eclf2.predict_proba(X),\n                              decimal=2)\n\n    eclf3 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2)],\n        voting='soft').fit(X, y, sample_weight=np.random.RandomState(123).uniform(size=(len(y),)))\n\n    assert_array_almost_equal(eclf1.predict_proba(X), eclf3.predict_proba(X),\n                              decimal=2)\n", "def test_voting_classifier_with_none_estimator():\n    # Test VotingClassifier with a None estimator\n    eclf = VotingClassifier(estimators=[('lr', LogisticRegression()),\n                                        ('rf', RandomForestClassifier()),\n                                        ('gnb', None)],\n                            voting='soft', weights=[1, 1, 1])\n    eclf.fit(X, y)\n    assert_array_equal(eclf.predict(X).shape, y.shape)\n    assert_array_almost_equal(eclf.predict_proba(X).shape, (len(y), 3))\n\n    # Test VotingClassifier with multiple None estimators\n    eclf = VotingClassifier(estimators=[('lr', LogisticRegression()),\n                                        ('rf', None),\n                                        ('gnb', None)],\n                            voting='soft', weights=[1, 1, 1])\n    eclf.fit(X, y)\n    assert_array_equal(eclf.predict(X).shape, y.shape)\n    assert_array_almost_equal(eclf.predict_proba(X).shape, (len(y), 3))\n\n    # Test VotingClassifier with only None estimators\n    eclf = VotingClassifier(estimators=[('lr', None),\n                                        ('rf', None),\n                                        ('gnb', None)],\n                            voting='soft', weights=[1, 1, 1])\n    msg = 'All estimators are None. At least one is required!'\n    assert_raise_message(ValueError, msg, eclf.fit, X, y)\n", "def test_get_params():\n    \"\"\"Check that get_params() returns the correct parameters\"\"\"\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    eclf1 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2)],\n        voting='soft')\n\n    params = eclf1.get_params()\n    assert set(params.keys()) == {'estimators', 'voting', 'weights', 'n_jobs', 'flatten_transform'}\n    assert params['estimators'] == [('lr', clf1), ('rf', clf2)]\n    assert params['voting'] == 'soft'\n    assert params['weights'] is None\n    assert params['n_jobs'] is None\n    assert params['flatten_transform'] is True\n\n    eclf1.set_params(voting='hard', weights=[1, 2])\n    params = eclf1.get_params()\n    assert params['voting'] == 'hard'\n    assert params['weights'] == [1, 2]\n\n    # Test that get_params(deep=True) returns the parameters of the estimators\n    params = eclf1.get_params(deep=True)\n    assert 'lr__C' in params\n    assert params['lr__C'] == 1.0\n    assert 'rf__n_estimators' in params\n    assert params['rf__n_estimators'] == 100\n"], "sample_53": ["def test_alter_model_table_case(self):\n    \"\"\"\n    Renaming the db_table case-insensitive doesn't lead to any autodetected operations.\n    \"\"\"\n    author_renamed_table = ModelState(\n        \"testapp\",\n        \"Author\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n        ],\n        {\"db_table\": \"auThOr\"},\n    )\n    changes = self.get_changes(\n        [self.author_with_db_table_options], [author_renamed_table]\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 0)\n", "def test_check_dependency_on_self(self):\n    changes = self.get_changes(\n        [],\n        [\n            ModelState(\n                \"app\",\n                \"Model\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\n                        \"parent\",\n                        models.ForeignKey(\"app.Model\", models.CASCADE),\n                    ),\n                ],\n            ),\n        ],\n    )\n    self.assertNumberMigrations(changes, \"app\", 1)\n    self.assertOperationTypes(changes, \"app\", 0, [\"CreateModel\"])\n    self.assertMigrationDependencies(changes, \"app\", 0, [])\n", "def test_alter_field_to_many_to_many_with_through(self):\n    \"\"\"\n    #26595 - Changing a concrete field into a ManyToManyField with\n    through model first removes the concrete field and then adds the m2m field.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_with_former_m2m], [self.author_with_m2m_through, self.publisher, self.contract]\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(\n        changes,\n        \"testapp\",\n        0,\n        [\n            \"CreateModel\",\n            \"CreateModel\",\n            \"CreateModel\",\n            \"RemoveField\",\n            \"AddField\",\n        ],\n    )\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Publisher\")\n    self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"Contract\")\n    self.assertOperationAttributes(changes, \"testapp\", 0, 2, name=\"Author\")\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 3, model_name=\"author\", name=\"publishers\"\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 4, model_name=\"author\", name=\"publishers\"\n    )\n", "    def test_detect_add_unique_together_and_indexes_with_renamed_model(self):\n        \"\"\"\n        Tests detection of added unique_together and indexes with renamed model.\n        \"\"\"\n        changes = self.get_changes(\n            [self.author_with_book],\n            [\n                self.author_renamed_with_book,\n                self.book_indexes,\n            ],\n            questioner=MigrationQuestioner({\"ask_rename_model\": True}),\n        )\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, \"testapp\", 1)\n        self.assertNumberMigrations(changes, \"otherapp\", 1)\n        self.assertOperationTypes(changes, \"testapp\", 0, [\"RenameModel\"])\n        self.assertOperationAttributes(\n            changes, \"testapp\", 0, 0, old_name=\"Author\", new_name=\"Writer\"\n        )\n        # Right number/type of migrations for related field rename?\n        # Alter is already taken care of.\n        self.assertOperationTypes(\n            changes, \"otherapp\", 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\"]\n        )\n        self.assertOperationAttributes(\n            changes, \"otherapp\", 0, 0, name=\"book\", unique_together={(\"author\", \"title\")}\n        )\n        self.assertOperationAttributes(\n            changes, \"otherapp\", 0, 1, name=\"book\", index_together={(\"author\", \"title\")}\n        )\n", "def test_indexed_together_model_deletion(self):\n    \"\"\"\n    A migration that removes a model which is referenced in an index_together\n    constraint should run after the migration that removes that index_together.\n    \"\"\"\n    book_with_index_together = ModelState(\n        \"otherapp\",\n        \"Book\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n            (\"title\", models.CharField(max_length=200)),\n        ],\n        {\n            \"index_together\": {(\"author\", \"title\")},\n        },\n    )\n    changes = self.get_changes(\n        [self.author_empty, book_with_index_together],\n        [self.author_empty, self.book],\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(\n        changes, \"otherapp\", 0, [\"AlterIndexTogether\", \"RemoveField\"]\n    )\n    self.assertOperationAttributes(\n        changes, \"otherapp\", 0, 0, name=\"book\", index_together=set()\n    )\n    self.assertOperationAttributes(\n        changes, \"otherapp\", 0, 1, name=\"author\", model_name=\"book\"\n    )\n"], "sample_137": ["def test_least_rotation():\n    assert least_rotation([3, 1, 5, 1, 2]) == 3\n    assert least_rotation([1, 2, 3, 4, 5]) == 0\n    assert least_rotation([5, 4, 3, 2, 1]) == 0\n    assert least_rotation([1, 2, 3, 4, 5, 1, 2, 3, 4, 5]) == 0\n    assert least_rotation([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]) == 0\n", "def test_permute_signs():\n    assert list(permute_signs((1, 2))) == [(1, 2), (-1, 2), (1, -2), (-1, -2)]\n    assert list(permute_signs((-1, -2))) == [(-1, -2), (1, -2), (-1, 2), (1, 2)]\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((1, 2, 3))) == [\n        (1, 2, 3), (-1, 2, 3), (1, -2, 3), (-1, -2, 3),\n        (1, 2, -3), (-1, 2, -3), (1, -2, -3), (-1, -2, -3)]\n    assert list(permute_signs((1, 1, 3))) == [\n        (1, 1, 3), (-1, 1, 3), (1, -1, 3), (-1, -1, 3),\n        (1, 1, -3), (-1, 1, -3), (1, -1, -3), (-1, -1, -3)]\n    assert list(permute_signs((0, 0))) == [(0, 0)]\n", "def test_multiset():\n    assert multiset('') == {}\n    assert multiset([]) == {}\n    assert multiset('a') == {'a': 1}\n    assert multiset(['a']) == {'a': 1}\n    assert multiset('aa') == {'a': 2}\n    assert multiset(['a', 'a']) == {'a': 2}\n    assert multiset('ab') == {'a': 1, 'b': 1}\n    assert multiset(['a', 'b']) == {'a': 1, 'b': 1}\n    assert multiset('aab') == {'a': 2, 'b': 1}\n    assert multiset(['a', 'a', 'b']) == {'a': 2, 'b': 1}\n    assert multiset('abc') == {'a': 1, 'b': 1, 'c': 1}\n    assert multiset(['a', 'b', 'c']) == {'a': 1, 'b': 1, 'c': 1}\n    assert multiset('aaa') == {'a': 3}\n    assert multiset(['a', 'a', 'a']) == {'a': 3}\n    assert multiset([1, 2, 2]) == {1: 1, 2: 2}\n", "def test_generate_bell():\n    # Check that the number of generated permutations is factorial\n    for n in range(7):\n        assert len(list(generate_bell(n))) == factorial(n)\n\n    # Check that the first and last permutations are the identity and reverse\n    for n in range(1, 7):\n        b = list(generate_bell(n))\n        assert b[0] == tuple(range(n))\n        assert b[-1] == tuple(range(n - 1, -1, -1))\n", "def test_flatten():\n    # Test that flatten works with a list of Basic instances\n    class BasicWrapper(Basic):\n        pass\n\n    data = [BasicWrapper(1), BasicWrapper(2), [3, BasicWrapper(4)], 5]\n    expected = [1, 2, 3, 4, 5]\n    assert flatten(data) == expected\n\n    # Test that flatten works with a list of iterables\n    data = [(1, 2), (3, (4, 5)), 6]\n    expected = [1, 2, 3, 4, 5, 6]\n    assert flatten(data) == expected\n\n    # Test that flatten works with a list of iterables that contain lists\n    data = [[1, 2], [3, (4, [5, 6])], 7]\n    expected = [1, 2, 3, 4, 5, 6, 7]\n    assert flatten(data) == expected\n\n    # Test that flatten works with a list that contains a single element\n    data = [1]\n    expected = [1]\n    assert flatten(data) == expected\n\n    # Test that flatten works with an empty list\n    data = []\n    expected = []\n    assert flatten(data) == expected\n\n    # Test that flatten works with a string\n    data = \"123\"\n    expected = ['1', '2', '3']\n    assert flatten(data) == expected\n\n    # Test that flatten works with a tuple\n    data = (1, 2, (3, 4))\n    expected = [1, 2, 3, 4]\n    assert flatten(data) == expected\n\n    # Test that flatten works with a dictionary\n    data = {1: 2, 3: (4, 5)}\n    expected = [1, 2, 3, 4, 5]\n    assert flatten(data) == expected\n\n    # Test that flatten works with a set\n    data = {1, 2, (3, 4)}\n    expected = [1, 2, 3, 4]\n    assert flatten(data) == expected\n\n    # Test that flatten works with a frozenset\n    data = frozenset({1, 2, (3, 4)})\n    expected = [1, 2, 3, 4]\n   "], "sample_86": ["def test_record_testsuite_property_with_non_string_value(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", {\"a\": 1, \"b\": 2})\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p1_node.assert_attr(name=\"stats\", value='{\"a\": 1, \"b\": 2}')\n", "def test_record_testsuite_property_multiple_values(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", \"all good\")\n\n            record_testsuite_property(\"stats\", \"more good\")\n            record_testsuite_property(\"stats\", \"even more good\")\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p2_node = properties_node.find_nth_by_tag(\"property\", 1)\n    p3_node = properties_node.find_nth_by_tag(\"property\", 2)\n    p1_node.assert_attr(name=\"stats\", value=\"all good\")\n    p2_node.assert_attr(name=\"stats\", value=\"more good\")\n    p3_node.assert_attr(name=\"stats\", value=\"even more good\")\n", "def test_record_testsuite_property_xml_escaping(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats <&'\", 10)\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p1_node.assert_attr(name=\"stats <&'\", value=\"10\")\n", "def test_record_testsuite_property_multi_value(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", \"all good\")\n            record_testsuite_property(\"stats\", 10)\n            record_testsuite_property(\"stats\", [1, 2])\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    properties = properties_node.find_by_tag(\"property\")\n    assert len(properties) == 3\n    for prop in properties:\n        assert prop[\"name\"] == \"stats\"\n        assert prop[\"value\"] in (\"all good\", \"10\", \"[1, 2]\")\n", "def test_junit_prefixing_with_absolute_paths(testdir, prefix):\n    testdir.makepyfile(\n        \"\"\"\n            assert 0\n        class TestHello(object):\n                pass\n    \"\"\"\n    )\n    result, dom = runandparse(testdir, \"--junitprefix=%s\" % prefix)\n    assert result.ret\n    node = dom.find_first_by_tag(\"testsuite\")\n    node.assert_attr(failures=1, tests=2)\n    tnode = node.find_first_by_tag(\"testcase\")\n    tnode.assert_attr(classname=(\"%s.test_junit_prefixing_with_absolute_paths\" % prefix).strip(\".\"), \n                      name=\"test_func\")\n    tnode = node.find_nth_by_tag(\"testcase\", 1)\n    tnode.assert_attr(classname=(\"%s.test_junit_prefixing_with_absolute_paths.TestHello\" % prefix).strip(\".\"),\n                      name=\"test_hello\")\n"], "sample_83": ["def test_colorized_reporter(linter: PyLinter) -> None:\n    \"\"\"Test the colorized reporter.\"\"\"\n    output = StringIO()\n    linter.reporter = ColorizedTextReporter(output)\n    linter.open()\n    linter.set_current_module(\"my_module\")\n\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n    linter.add_message(\n        \"line-too-long\", line=2, end_lineno=2, end_col_offset=4, args=(3, 4)\n    )\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert out_lines[1].startswith(\"\\033[31m************* Module my_module\")\n    assert \"\\033[0m\" in out_lines[1]\n    assert out_lines[2].startswith(\"\\033[31mmy_module:1:0: \\033[1mC0301\")\n    assert \"\\033[0m\" in out_lines[2]\n    assert out_lines[3].startswith(\"\\033[31mmy_module:2:0: \\033[1mC0301\")\n    assert \"\\033[0m\" in out_lines[3]\n", "def test_colorized_reporter_color_mapping(linter):\n    \"\"\"Test the color mapping of the ColorizedTextReporter.\"\"\"\n    output = StringIO()\n    reporter = ColorizedTextReporter(output)\n    linter.reporter = reporter\n    linter.config.msg_template = \"{msg_id}: {msg} ({symbol})\"\n    linter.open()\n    linter.set_current_module(\"my_module\")\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n    linter.add_message(\"line-too-long\", line=2, args=(3, 4))\n    linter.add_message(\"R0914\", line=3, args=(5, 6))\n    linter.add_message(\"too-many-boolean-expressions\", line=4, args=(7, 8))\n    linter.add_message(\"W0613\", line=5, args=(9, 10))\n    linter.add_message(\"unused-argument\", line=6, args=(11, 12))\n    linter.add_message(\"E0001\", line=7, args=(13, 14))\n    linter.add_message(\"syntax-error\", line=8, args=(15, 16))\n    linter.add_message(\"F0001\", line=9, args=(17, 18))\n    linter.add_message(\"fatal-error\", line=10, args=(19, 20))\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert out_lines[1].startswith(\"\\x1b[31mC0301: \")\n    assert out_lines[2].startswith(\"\\x1b[31mC0301: \")\n    assert out_lines[3].startswith(\"\\x1b[35m\\x1b[1m\\x1b[3mR0914: \")\n    assert out_lines[4].startswith(\"\\x1b[35m\\x1b[1m\\x1b[3mR0914: \")\n    assert out_lines[5].startswith(\"\\x1b[35mW0613: \")\n    assert out_lines[6].startswith(\"\\x1b[35mW0613: \")\n    assert out_lines[7].startswith(\"\\x1b[31m\\x1b[1mE0001: \")\n    assert out_lines[8].startswith(\"\\x1b[31m\\x1b[1mE0001: \")\n    assert out_lines[9].startswith(\"\\x1b[", "def test_colorized_text_reporter(linter):\n    output = StringIO()\n    linter.reporter = ColorizedTextReporter(output)\n    linter.reporter.out = output\n    linter.set_current_module(\"my_module\")\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n    linter.add_message(\n        \"line-too-long\", line=2, end_lineno=2, end_col_offset=4, args=(3, 4)\n    )\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert len(out_lines) == 3\n    assert out_lines[0].startswith(\"\\033[\")\n    assert out_lines[1].startswith(\"\\033[\")\n    assert out_lines[2] == \"\"\n\n", "def test_colorized_text_reporter_handle_message(tmp_path):\n    \"\"\"Test the handle_message method of the ColorizedTextReporter class.\"\"\"\n    output = StringIO()\n    linter = PyLinter(reporter=ColorizedTextReporter(output))\n    linter.set_current_module(\"my_module\")\n    message = Message(\n        symbol=\"missing-docstring\",\n        msg_id=\"C0123\",\n        location=(\"abspath\", \"path\", \"module\", \"obj\", 1, 2, 1, 3),\n        msg=\"This is a message\",\n        confidence=HIGH,\n    )\n    linter.reporter.handle_message(message)\n    assert \"my_module\" in output.getvalue()\n    assert \"C0123\" in output.getvalue()\n    assert \"This is a message\" in output.getvalue()\n    assert \"\\033[\" in output.getvalue()  # ANSI escape code\n    assert \"m\" in output.getvalue()  # ANSI reset code\n\n    # Test colorized output for different message types\n    color_mapping = {\n        \"I\": MessageStyle(\"green\"),\n        \"C\": MessageStyle(None, (\"bold\",)),\n        \"R\": MessageStyle(\"magenta\", (\"bold\", \"italic\")),\n        \"W\": MessageStyle(\"magenta\"),\n        \"E\": MessageStyle(\"red\", (\"bold\",)),\n        \"F\": MessageStyle(\"red\", (\"bold\", \"underline\")),\n        \"S\": MessageStyle(\"yellow\", (\"inverse\",)),  # S stands for module Separator\n    }\n    linter.reporter.color_mapping = color_mapping\n\n    message = Message(\n        symbol=\"info\",\n        msg_id=\"I0123\",\n        location=(\"abspath\", \"path\", \"module\", \"obj\", 1, 2, 1, 3),\n        msg=\"This is an info message\",\n        confidence=HIGH,\n    )\n    linter.reporter.handle_message(message)\n    assert \"\\033[32m\" in output.getvalue()  # Green color code\n\n    message = Message(\n        symbol=\"convention\",\n        msg_id=\"C0123\",\n        location=(\"abspath\", \"path\", \"module\", \"obj\", 1, 2, 1, 3),\n        msg=\"This is a convention message\",\n        confidence=HIGH,\n    )\n    linter.reporter.handle_message(message)\n    assert \"\\033[1m\" in output.getvalue()  # Bold style code\n\n    message = Message(\n        symbol=\"refactor\",\n        msg_id=\"", "def test_colorized_text_reporter(linter):\n    output = StringIO()\n    linter.reporter = ColorizedTextReporter(output)\n    linter.config.msg_template = \"{msg_id}:{line:03d}:{msg}\"\n    linter.open()\n    linter.set_current_module(\"0123\")\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n    linter.add_message(\"line-too-long\", line=2, args=(3, 4))\n    assert linter.reporter.color_mapping[\"C\"] == MessageStyle(None, (\"bold\",))\n\n    linter.config.msg_template = \"{msg}\"\n    linter.reporter.color_mapping = {\n        \"I\": MessageStyle(\"green\"),\n        \"C\": MessageStyle(\"magenta\", (\"bold\",)),\n    }\n    linter.set_current_module(\"0123\")\n    linter.add_message(\"I0001\", line=1, args=(1, 2))\n    linter.add_message(\"line-too-long\", line=2, args=(3, 4))\n    linter.add_message(\"C0301\", line=3, args=(5, 6))\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert \"\\033[32mLine too long (1/2)\\033[0m\" in out_lines[1]\n    assert \"\\033[35;1mLine too long (3/4)\\033[0m\" in out_lines[2]\n    assert \"\\033[35;1mLine too long (5/6)\\033[0m\" in out_lines[3]\n"], "sample_7": ["    def test_common_roots_with_hfs(self):\n        paths = (\n            Path('/first/second'),\n            Path('/first/second/third'),\n            Path('/first/'),\n            Path('/root/first/'),\n        )\n        results = autoreload.common_roots(paths)\n        self.assertCountEqual(results, [Path('/first/'), Path('/root/first/')])\n", "    def setUp(self):\n        self.reloader = autoreload.WatchmanReloader()\n        self.reloader.client_timeout = 0.01  # Shorten the timeout to speed up tests.\n", "    def test_nested_exceptions(self):\n        try:\n            try:\n                raise Exception('Inner exception')\n            except Exception as e:\n                try:\n                    raise Exception('Outer exception') from e\n                except Exception:\n                    raise\n        except Exception as e:\n            exc_info = sys.exc_info()\n            with mock.patch('django.utils.autoreload._exception', exc_info):\n                with self.assertRaisesMessage(Exception, 'Inner exception'):\n                    autoreload.raise_last_exception()\n", "    def test_zip_imports_included(self):\n        \"\"\"Tests that the zipimporter is included when using iter_all_python_module_files.\"\"\"\n        zip_file = self.temporary_file('test_import_zip.zip')\n        with zipfile.ZipFile(str(zip_file), 'w', zipfile.ZIP_DEFLATED) as zipf:\n            zipf.writestr('test_zipped_file.py', '')\n\n        with extend_sys_path(str(zip_file)):\n            self.import_and_cleanup('test_zipped_file')\n            self.assertFileFound(zip_file)\n            # Now check that the cached result still includes the zip file\n            self.clear_autoreload_caches()\n            self.assertFileFound(zip_file)\n", "    def test_no_exception(self):\n        # Should raise no exception if _exception is None\n        autoreload.raise_last_exception()\n"], "sample_22": ["def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('HelloWorldClass'), 'hello world class')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('hello'), 'hello')\n    self.assertEqual(text.camel_case_to_spaces(''), '')\n    self.assertEqual(text.camel_case_to_spaces(lazystr('HelloWorld')), 'hello world')\n", "    def test_camel_case_to_spaces(self):\n        self.assertEqual(text.camel_case_to_spaces('HelloWorld'), 'hello world')\n        self.assertEqual(text.camel_case_to_spaces('HelloXMLWorld'), 'hello xml world')\n        self.assertEqual(text.camel_case_to_spaces('helloWorld'), 'hello world')\n        self.assertEqual(text.camel_case_to_spaces('helloXMLWorld'), 'hello xml world')\n        self.assertEqual(text.camel_case_to_spaces('HelloWORLD'), 'hello world')\n        self.assertEqual(text.camel_case_to_spaces('helloWORLD'), 'hello world')\n        self.assertEqual(text.camel_case_to_spaces(''), '')\n        self.assertEqual(text.camel_case_to_spaces(lazystr('HelloWorld')), 'hello world')\n", "def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('helloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloXMLWorld'), 'hello xml world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorldHello'), 'hello world hello')\n    self.assertEqual(text.camel_case_to_spaces('hello'), 'hello')\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces(''), '')\n    self.assertEqual(text.camel_case_to_spaces(lazystr('helloWorld')), 'hello world')\n", "def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('helloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWORLD'), 'hello w o r l d')\n    self.assertEqual(text.camel_case_to_spaces('hello-World'), 'hello- world')\n    self.assertEqual(text.camel_case_to_spaces('hello_World'), 'hello_ world')\n    self.assertEqual(text.camel_case_to_spaces('hello world'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorldFooBar'), 'hello world foo bar')\n", "    def test_camel_case_to_spaces(self):\n        items = [\n            ('HelloWorld', 'hello world'),\n            ('helloWorld', 'hello world'),\n            ('helloWORLD', 'hello world'),\n            ('HelloWORLD', 'hello world'),\n            ('hello', 'hello'),\n            ('Hello', 'hello'),\n            ('helloWorld123', 'hello world 123'),\n            ('', ''),\n            ('   ', ''),\n            ('\\n', '\\n'),\n            ('\\t', '\\t'),\n        ]\n        for value, output in items:\n            self.assertEqual(text.camel_case_to_spaces(value), output)\n            self.assertEqual(text.camel_case_to_spaces(lazystr(value)), output)\n"], "sample_72": ["def test_figure_add_artist():\n    fig, ax = plt.subplots()\n    artist = ax.plot([1, 2, 3])[0]\n    fig.add_artist(artist)\n    assert artist in fig.artists\n    fig.clear()\n    assert artist not in fig.artists\n", "def test_figure_subfigures():\n    fig = plt.figure()\n    subfigs = fig.subfigures(1, 2)\n    assert len(subfigs) == 2\n\n    axs1 = subfigs[0].subplots(2, 1)\n    axs2 = subfigs[1].subplots(1, 2)\n\n    assert len(axs1) == 2\n    assert len(axs2) == 2\n\n    assert subfigs[0].get_axes() == axs1\n    assert subfigs[1].get_axes() == axs2\n", "def test_add_subfigure():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    subfig = fig.add_subfigure(gs[0, 1])\n    assert subfig._parent == fig\n    assert subfig.figure == fig\n    assert subfig._subplotspec == gs[0, 1]\n    assert subfig.subplotpars == fig.subplotpars\n    assert subfig.dpi_scale_trans == fig.dpi_scale_trans\n    assert subfig._axstack == fig._axstack\n    assert subfig.canvas == fig.canvas\n    assert subfig.transFigure == fig.transFigure\n    assert subfig.figbbox == fig.figbbox\n    assert subfig.bbox == subfig.transSubfigure.transformed(fig.bbox)\n", "def test_figure_suptitle():\n    fig, ax = plt.subplots()\n    title = \"This is a title\"\n    fig.suptitle(title)\n    assert fig._suptitle.get_text() == title\n    fig.suptitle(title, fontsize=20)\n    assert fig._suptitle.get_fontsize() == 20\n    fig.suptitle(title, fontweight=\"bold\")\n    assert fig._suptitle.get_fontweight() == \"bold\"\n    with pytest.raises(ValueError):\n        fig.suptitle(title, x=2)\n", "def test_subfigure():\n    fig = plt.figure()\n    subfigs = fig.subfigures(1, 2, width_ratios=[1, 2])\n    axsL = subfigs[0].subplots(1, 2)\n    axsR = subfigs[1].subplots(2, 1)\n\n    assert axsL[0].get_figure() is subfigs[0]\n    assert axsR[0].get_figure() is subfigs[1]\n\n    fig.canvas.draw()\n    assert subfigs[0].get_size_inches() == subfigs[0].get_renderer().get_canvas_width_height()\n\n    # test that we cannot change the subfigure's dpi, but we can change\n    # the figure's dpi\n    with pytest.raises(AttributeError):\n        subfigs[0].dpi = 200\n    fig.dpi = 200\n    assert fig.dpi == 200\n    assert subfigs[0].get_dpi() == 200\n\n    assert subfigs[0].get_tight_layout() is False\n    assert subfigs[0].get_constrained_layout() is True\n    assert subfigs[0].get_constrained_layout_pads() == fig.get_constrained_layout_pads()\n\n    # Test adding a subfigure to itself\n    with pytest.raises(ValueError):\n        subfigs[0].add_subfigure(subfigs[1].get_subplotspec())\n"], "sample_150": ["def test_solve_generic():\n    assert solve_generic([Poly(x - 1, x, domain='ZZ')], 'x') == [(S.One,)]\n\n    assert solve_generic([Poly(y - x, x, y, domain='ZZ'), Poly(y - x - 1, x, y, domain='ZZ')], (x, y)) is None\n\n    assert solve_generic([Poly(y - x**2, x, y, domain='ZZ'), Poly(y + x**2, x, y, domain='ZZ')], (x, y)) == [(S.Zero, S.Zero)]\n\n    assert solve_generic([Poly(2*x - 3, x, y, z, domain='ZZ'), Poly(3*y/2 - 2*x, x, y, z, domain='ZZ'), Poly(z - 5*y, x, y, z, domain='ZZ')], (x, y, z)) == \\\n        [(Rational(3, 2), Integer(2), Integer(10))]\n\n    assert solve_generic([Poly(x*y - 2*y, x, y, domain='ZZ'), Poly(2*y**2 - x**2, x, y, domain='ZZ')], (x, y)) == \\\n        [(0, 0), (2, -sqrt(2)), (2, sqrt(2))]\n\n    f_1 = Poly(x**2 + y + z - 1, x, y, z, domain='ZZ')\n    f_2 = Poly(x + y**2 + z - 1, x, y, z, domain='ZZ')\n    f_3 = Poly(x + y + z**2 - 1, x, y, z, domain='ZZ')\n\n    a, b = sqrt(2) - 1, -sqrt(2) - 1\n\n    assert solve_generic([f_1, f_2, f_3], (x, y, z)) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0), (a, a, a), (b, b, b)]\n\n    solution = [(1, -1), (1, 1)]\n\n    assert solve_generic([Poly(x**2 - y**2, x, y, domain='ZZ'), Poly(x - 1, x, y, domain='ZZ')], (", "def test_solve_generic():\n    x, y, z = symbols('x y z')\n\n    f_1 = x - y + 5\n    f_2 = x + y - 3\n\n    assert solve_generic([Poly(f_1, x, y, domain='ZZ'), Poly(f_2, x, y, domain='ZZ')],\n        {'gens': (x, y), 'domain': 'ZZ'}) == [(-1, 4)]\n\n    f_1 = x - 2*y + 5\n    f_2 = 2*x - y - 3\n\n    assert solve_generic([Poly(f_1, x, y, domain='ZZ'), Poly(f_2, x, y, domain='ZZ')],\n        {'gens': (x, y), 'domain': 'ZZ'}) == [(11/3, 13/3)]\n\n    f_1 = x**2 + y\n    f_2 = x + y*4\n\n    assert solve_generic([Poly(f_1, x, y, domain='ZZ'), Poly(f_2, x, y, domain='ZZ')],\n        {'gens': (x, y), 'domain': 'ZZ'}) == [(0, 0), (1/4, -1/16)]\n\n    raises(NotImplementedError, lambda: solve_generic([x**3 - y**3], {'gens': (x, y)}))\n    raises(NotImplementedError, lambda: solve_generic([z, -2*x*y**2 + x + y**2*z, y**2*(-z - 4) + 2],\n        {'gens': (x, y, z)}))\n\n    raises(PolynomialError, lambda: solve_generic([1/x], {'gens': (x,)}))\n", "def test_solve_generic():\n    x_1, x_2, x_3 = symbols('x_1 x_2 x_3')\n\n    polys = [Poly(x_1**2 + x_2**2 + x_3**2 - 1, x_1, x_2, x_3)]\n    opt = {\"domain\": \"ZZ\", \"gens\": (x_1, x_2, x_3)}\n\n    raises(NotImplementedError, lambda: solve_generic(polys, opt))\n\n    polys = [Poly(x_1 - x_2, x_1, x_2, x_3), Poly(x_2 - x_3, x_1, x_2, x_3)]\n    opt = {\"domain\": \"ZZ\", \"gens\": (x_1, x_2, x_3)}\n\n    raises(NotImplementedError, lambda: solve_generic(polys, opt))\n\n    polys = [Poly(x_1 - x_2, x_1, x_2), Poly(x_2 - x_3, x_1, x_2, x_3)]\n    opt = {\"domain\": \"ZZ\", \"gens\": (x_1, x_2, x_3)}\n\n    raises(PolynomialError, lambda: solve_generic(polys, opt))\n", "def test_solve_generic():\n    f_1 = x**2 - 3*x + 2\n    f_2 = x - 2*y + 1\n    f_3 = x - 2*y + 2\n\n    assert solve_generic([Poly(f_1, x, y), Poly(f_2, x, y)], parallel_poly_from_expr([f_1, f_2], x, y)[1]) == \\\n        [(1, 0), (2, S.Half)]\n\n    assert solve_generic([Poly(f_1, x, y), Poly(f_3, x, y)], parallel_poly_from_expr([f_1, f_3], x, y)[1]) == \\\n        [(1, S.Half), (2, S.Half)]\n\n    f_1 = x**2 + y\n    f_2 = x + y*4\n\n    assert solve_generic([Poly(f_1, x, y), Poly(f_2, x, y)], parallel_poly_from_expr([f_1, f_2], x, y)[1]) == \\\n        [(0, 0), (1/4, -1/16)]\n\n    raises(NotImplementedError, lambda: solve_generic([Poly(x**3 - y**3, x, y)], parallel_poly_from_expr([x**3 - y**3], x, y)[1]))\n    raises(NotImplementedError, lambda: solve_generic([Poly(x**2 + y**2, x, y), Poly(x**2 - y**2, x, y)], parallel_poly_from_expr([x**2 + y**2, x**2 - y**2], x, y)[1]))\n", "def test_solve_generic():\n    x_1, y_1, x_2, y_2 = symbols('x_1 y_1 x_2 y_2')\n\n    # Test for a zero-dimensional system\n    polys = [x_1**2 + y_1**2 - 4, x_1 + y_1 - 2]\n    opt = Poly._construct_ufuncs(polys, (x_1, y_1), domain='ZZ')\n    result = solve_generic(polys, opt)\n    assert sorted(result, key=default_sort_key) == [(0, 2), (2, 0)]\n\n    # Test for a one-dimensional system\n    polys = [x_1 - 2*y_1, y_1 - 2]\n    opt = Poly._construct_ufuncs(polys, (x_1, y_1), domain='ZZ')\n    raises(NotImplementedError, lambda: solve_generic(polys, opt))\n\n    # Test for a non-zero-dimensional system\n    polys = [x_1**2 + y_1**2, x_1 + y_1]\n    opt = Poly._construct_ufuncs(polys, (x_1, y_1), domain='ZZ')\n    raises(NotImplementedError, lambda: solve_generic(polys, opt))\n\n    # Test for a system with more than two variables\n    polys = [x_1 - x_2, x_2 - y_1, y_1 - y_2]\n    opt = Poly._construct_ufuncs(polys, (x_1, x_2, y_1, y_2), domain='ZZ')\n    raises(NotImplementedError, lambda: solve_generic(polys, opt))\n"], "sample_40": ["def test_boundfield_subwidget_attributes(self):\n    class SomeForm(Form):\n        field = MultipleChoiceField(\n            choices=[('a', 'A'), ('b', 'B')],\n            widget=CheckboxSelectMultiple,\n            attrs={'class': 'pretty'},\n        )\n\n    form = SomeForm()\n    subwidgets = form['field'].subwidgets\n    self.assertEqual(subwidgets[0].data['attrs']['class'], 'pretty')\n    self.assertEqual(subwidgets[1].data['attrs']['class'], 'pretty')\n", "def test_boundfield_subwidget_label_tag(self):\n    class SomeForm(Form):\n        field = MultipleChoiceField(\n            choices=[('a', 'A'), ('b', 'B')],\n            widget=CheckboxSelectMultiple,\n        )\n\n    form = SomeForm()\n    subwidget = form['field'].subwidgets[0]\n    self.assertEqual(subwidget.id_for_label, 'id_field_0')\n    self.assertEqual(subwidget.choice_label, 'A')\n    self.assertHTMLEqual(\n        subwidget.tag(),\n        '<input type=\"checkbox\" name=\"field\" value=\"a\" id=\"id_field_0\" required>',\n    )\n    self.assertHTMLEqual(\n        str(subwidget),\n        '<label for=\"id_field_0\"><input type=\"checkbox\" name=\"field\" value=\"a\" id=\"id_field_0\" required> A</label>',\n    )\n", "def test_boundfield_subwidgets_with_disability(self):\n    class MyForm(Form):\n        name = ChoiceField(choices=[('a', 'A'), ('b', 'B')], widget=CheckboxSelectMultiple, disabled=True)\n\n    form = MyForm()\n    subwidgets = form['name'].subwidgets\n    for subwidget in subwidgets:\n        self.assertTrue(subwidget.data['attrs']['disabled'])\n", "def test_boundfield_with_custom_name(self):\n    class CustomBoundField(BoundField):\n            super().__init__(form, field, name)\n            self.html_name = 'custom_name'\n\n    class CustomCharField(CharField):\n            return CustomBoundField(form, self, name)\n\n    class SomeForm(Form):\n        field = CustomCharField()\n\n    form = SomeForm()\n    self.assertEqual(form['field'].html_name, 'custom_name')\n", "def test_hidden_id_for_label(self):\n    class MyWidget(TextInput):\n            return None\n\n    class MyForm(Form):\n        name = CharField(widget=MyWidget)\n        hidden = CharField(widget=HiddenInput)\n\n    form = MyForm(auto_id='id_%s')\n    self.assertIsNone(form['name'].id_for_label)\n    self.assertIsNone(form['hidden'].id_for_label)\n"], "sample_155": ["def test_get_units_non_prefixed():\n    assert set([meter, second, ampere, kelvin, mole, candela, gram]) == set(SI.get_units_non_prefixed())\n", "def test_UnitSystem():\n    us = UnitSystem((meter, kilogram, second), name=\"SI\", descr=\"International System of Units\")\n    assert us.name == \"SI\"\n    assert us.descr == \"International System of Units\"\n    assert us._base_units == (meter, kilogram, second)\n    assert us._units == (meter, kilogram, second)\n    assert us._dimension_system is not None\n    assert us._derived_units == {}\n\n    us2 = UnitSystem.extend(us, (ampere,), name=\"SI2\", descr=\"Extended International System of Units\")\n    assert us2.name == \"SI2\"\n    assert us2.descr == \"Extended International System of Units\"\n    assert us2._base_units == (meter, kilogram, second, ampere)\n    assert us2._units == (meter, kilogram, second, ampere)\n    assert us2._dimension_system is not None\n    assert us2._derived_units == {}\n\n    assert us.get_dimension_system() is not None\n    assert us.get_quantity_dimension(meter) == length\n    assert us.get_quantity_scale_factor(meter) == 1\n\n    assert UnitSystem.get_unit_system(\"SI\") == us\n    assert UnitSystem.get_default_unit_system() == us\n\n    assert us.dim == 3\n    assert us.is_consistent\n\n    us3 = UnitSystem((meter, kilogram, second), derived_units={length: meter})\n    assert us3.derived_units == {length: meter}\n\n    assert us.get_units_non_prefixed() == {meter, kilogram, second}\n", "def test_extend():\n    new_system = SI.extend((inch,), name=\"New System\", description=\"A new unit system\")\n    assert new_system.name == \"New System\"\n    assert new_system.descr == \"A new unit system\"\n    assert new_system.dim == 2\n    assert new_system.get_units_non_prefixed() == {inch, meter, second, kilogram, kelvin, ampere, mole, candela}\n\n    derived_units = {Dimension(length/time): Quantity(\"speed\")}\n    new_system = SI.extend((inch,), name=\"New System\", description=\"A new unit system\", derived_units=derived_units)\n    assert new_system.derived_units == derived_units\n", "def test_unit_system():\n    # Create a new unit system\n    us = UnitSystem((meter, second, kilogram), name=\"SI\")\n\n    # Test the name and description\n    assert str(us) == \"SI\"\n    assert repr(us) == '<UnitSystem: (meter, second, kilogram)>'\n\n    # Test the base and derived units\n    assert us._base_units == (meter, second, kilogram)\n    assert us._derived_units == {}\n\n    # Test extending the unit system\n    new_us = us.extend((kelvin,))\n    assert new_us._base_units == (meter, second, kilogram, kelvin)\n    assert new_us._units == (meter, second, kilogram, kelvin)\n\n    # Test getting the dimension system\n    assert isinstance(us.get_dimension_system(), Dimension)\n\n    # Test getting the quantity dimension\n    assert us.get_quantity_dimension(meter) == length\n\n    # Test getting the quantity scale factor\n    assert us.get_quantity_scale_factor(meter) == 1\n\n    # Test the is_consistent property\n    assert us.is_consistent\n\n    # Test the dim property\n    assert us.dim == 3\n\n    # Test the derived_units property\n    assert us.derived_units == {}\n", "def test_derived_units():\n    derived_unit_system = SI.extend(\n        base=(Quantity(\"decimeter\"), ),\n        units=(Quantity(\"decimeter\"), ),\n        name=\"Derived SI\",\n        description=\"SI system with base units plus decimeter\",\n        dimension_system=None,\n        derived_units={Dimension(length): Quantity(\"decimeter\")}\n    )\n    \n    assert derived_unit_system.dim == 2\n    assert derived_unit_system._derived_units == {Dimension(length): Quantity(\"decimeter\")}\n    assert derived_unit_system.get_units_non_prefixed() == {meter, Quantity(\"decimeter\")}\n    assert derived_unit_system._base_units == (meter, Quantity(\"decimeter\"))\n    assert derived_unit_system._units == (meter, Quantity(\"decimeter\"))\n"], "sample_21": ["    def test_restrict_through_model(self):\n        a = create_a('restrict')\n        m = M.objects.create()\n        m.m2m.add(a.restrict)\n        msg = (\n            \"Cannot delete some instances of model 'R' because they are \"\n            \"referenced through restricted foreign keys: 'A.restrict', \"\n            \"'M.m2m'.\"\n        )\n        with self.assertRaisesMessage(RestrictedError, msg):\n            a.restrict.delete()\n", "def test_delete_with_fail_on_restricted(self):\n    a = create_a('restrict')\n    msg = (\n        \"Cannot delete some instances of model 'R' because they are \"\n        \"referenced through restricted foreign keys: 'A.restrict'.\"\n    )\n    with self.assertRaisesMessage(RestrictedError, msg):\n        a.restrict.delete()\n    # Test that setting fail_on_restricted=False doesn't raise an error.\n    collector = Collector(using='default')\n    collector.collect([a.restrict], source=None, nullable=False, fail_on_restricted=False)\n", "    def test_setvalue_from_child(self):\n        a = create_a('child')\n        a.child.delete()\n        a = A.objects.get(pk=a.pk)\n        self.assertEqual(self.DEFAULT, a.child)\n", "    def test_add_dependency(self):\n        collector = Collector(using='default')\n        model_a = A._meta.concrete_model\n        model_b = B._meta.concrete_model\n        collector.add_dependency(model_a, model_b)\n        self.assertIn(model_b, collector.dependencies[model_a])\n", "    def test_cascade_to_generic_foreign_key(self):\n        generic_b1 = GenericB1.objects.create()\n        generic_b2 = GenericB2.objects.create()\n        GenericDeleteBottom.objects.create(generic_b1=generic_b1, generic_b2=generic_b2)\n        generic_b1.delete()\n        self.assertFalse(GenericDeleteBottom.objects.exists())\n        self.assertFalse(GenericB2.objects.exists())\n"], "sample_71": ["def test_use_invalid_path():\n    with pytest.raises(IOError):\n        style.use('/non/existent/path/to/style')\n", "def test_blacklist_params():\n    original_value = 'gray'\n    bad_value = 'pink'\n    bad_param = 'interactive'\n    mpl.rcParams[PARAM] = original_value\n    with pytest.warns(mpl._api.MatplotlibDeprecationWarning):\n        with style.context({PARAM: bad_value, bad_param: 'foo'}):\n            assert mpl.rcParams[PARAM] == bad_value\n            assert mpl.rcParams[bad_param] != 'foo'\n    assert mpl.rcParams[PARAM] == original_value\n", "def test_remove_blacklisted_style_params():\n    style_params = {'backend': 'agg', 'axes.facecolor': 'adeade'}\n    expected = {'axes.facecolor': 'adeade'}\n    result = style.core._remove_blacklisted_style_params(style_params, warn=False)\n    assert result == expected\n", "def test_use_deprecated_seaborn_style(caplog):\n    with pytest.warns(mpl._api.MatplotlibDeprecationWarning):\n        mpl.style.use(\"seaborn\")\n    assert len(caplog.records) == 1\n    assert \"seaborn\" in caplog.records[0].getMessage()\n    assert \"seaborn-v0_8\" in caplog.records[0].getMessage()\n\n", "def test_use_default():\n    original_value = 'gray'\n    mpl.rcParams[PARAM] = original_value\n    with style.context('default'):\n        assert mpl.rcParams[PARAM] == rcParamsDefault[PARAM]\n    assert mpl.rcParams[PARAM] == original_value\n\n"], "sample_10": ["def test_lookup_year_exact(self):\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 4>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 7>',\n            '<Article: Article 1>',\n        ]\n    )\n", "def test_exact_exists_with_bilateral_transforms(self):\n    qs = Article.objects.filter(pub_date__year=OuterRef('year'))\n    seasons = Season.objects.annotate(\n        year_exists=Exists(qs),\n    ).filter(\n        year_exists=Exists(qs),\n    )\n    self.assertCountEqual(seasons, Season.objects.all())\n", "def test_exact_lookup_with_function_expression_rhs(self):\n    from django.db.models.functions import Coalesce, Upper\n    season = Season.objects.create(year=2012, nulled_text_field='test')\n    self.assertEqual(\n        Season.objects.filter(nulled_text_field__exact=Upper(Coalesce('nulled_text_field', Value('')))).get(),\n        season\n    )\n", "def test_year_lookup_bounds(self):\n    # year lookups should return the correct bounds for different field types\n    output_field = self.a1._meta.get_field('pub_date')\n    self.assertEqual(\n        connection.ops.year_lookup_bounds_for_datetime_field(2005),\n        (datetime(2005, 1, 1, 0, 0), datetime(2006, 1, 1, 0, 0))\n    )\n    self.assertEqual(\n        connection.ops.year_lookup_bounds_for_date_field(2005),\n        (datetime.date(2005, 1, 1), datetime.date(2006, 1, 1))\n    )\n    self.assertEqual(\n        connection.ops.year_lookup_bounds_for_datetime_field(2005, output_field=output_field),\n        (datetime(2005, 1, 1, 0, 0), datetime(2006, 1, 1, 0, 0))\n    )\n    self.assertEqual(\n        connection.ops.year_lookup_bounds_for_date_field(2005, output_field=output_field),\n        (datetime.date(2005, 1, 1), datetime.date(2006, 1, 1))\n    )\n", "def test_exact_lookup_value_conversion(self):\n    self.assertEqual(\n        list(Article.objects.filter(pub_date__exact=datetime(2005, 7, 27))),\n        [self.a2, self.a3, self.a7]\n    )\n    self.assertEqual(\n        list(Article.objects.filter(pub_date__exact=datetime(2005, 7, 27).date())),\n        [self.a2, self.a3, self.a7]\n    )\n    self.assertEqual(\n        list(Article.objects.filter(pub_date__exact='2005-07-27 00:00:00')),\n        [self.a2, self.a3, self.a7]\n    )\n    self.assertEqual(\n        list(Article.objects.filter(pub_date__exact='2005-07-27')),\n        [self.a2, self.a3, self.a7]\n    )\n    self.assertEqual(\n        list(Article.objects.filter(pub_date__exact='20050727')),\n        [self.a2, self.a3, self.a7]\n    )\n"], "sample_25": ["def test_create_model_with_unique_constraint(self):\n    \"\"\"Test creation of new model with unique constraint already defined.\"\"\"\n    author = ModelState(\"otherapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200)),\n    ], {\n        \"constraints\": [models.UniqueConstraint(fields=['name'], name='name_unique')]\n    })\n    changes = self.get_changes([], [author])\n    added_constraint = models.UniqueConstraint(fields=['name'], name='name_unique')\n    # Right number of migrations?\n    self.assertEqual(len(changes['otherapp']), 1)\n    # Right number of actions?\n    migration = changes['otherapp'][0]\n    self.assertEqual(len(migration.operations), 2)\n    # Right actions order?\n    self.assertOperationTypes(changes, 'otherapp', 0, ['CreateModel', 'AddConstraint'])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='Author')\n    self.assertOperationAttributes(changes, 'otherapp', 0, 1, model_name='author', constraint=added_constraint)\n", "def test_alter_field_to_m2m(self):\n    \"\"\"\n    #23938 - Changing a concrete field into a ManyToManyField first removes\n    the concrete field and then adds the m2m field.\n    \"\"\"\n    changes = self.get_changes([self.author_with_former_m2m, self.publisher], [self.author_with_m2m, self.publisher])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"RemoveField\", \"AddField\", \"CreateModel\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"publishers\", model_name='author')\n    self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"publishers\", model_name='author')\n    self.assertOperationAttributes(changes, 'testapp', 0, 2, name='Publisher')\n", "    def test_rename_model_with_renamed_field_and_fks(self):\n        \"\"\"\n        #27581 -- Tests autodetection of renamed models while simultaneously\n        renaming one of the fields that relate to the renamed model and\n        another field.\n        \"\"\"\n        changes = self.get_changes(\n            [self.author_with_book, self.book],\n            [self.author_renamed_with_book, self.book_with_field_and_author_renamed],\n            MigrationQuestioner({\"ask_rename\": True, \"ask_rename_model\": True}),\n        )\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, [\"RenameModel\"])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name=\"Author\", new_name=\"Writer\")\n        # Right number/type of migrations for related field rename?\n        # Alter is already taken care of.\n        self.assertNumberMigrations(changes, 'otherapp', 1)\n        self.assertOperationTypes(changes, 'otherapp', 0, [\"RenameField\"])\n        self.assertOperationAttributes(changes, 'otherapp', 0, 0, old_name=\"author\", new_name=\"writer\")\n", "def test_deconstructible_object_in_field_kwargs(self):\n    author_deconstructible = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, validators=[DeconstructibleObject()]))\n    ])\n    author_deconstructible_2 = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, validators=[DeconstructibleObject()]))\n    ])\n    changes = self.get_changes([author_deconstructible], [author_deconstructible_2])\n    # Right number of migrations?\n    self.assertEqual(len(changes), 0)\n\n    author_deconstructible_changed = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, validators=[DeconstructibleObject(x=1)])\n    ])\n    changes = self.get_changes([author_deconstructible], [author_deconstructible_changed])\n    # Right number of migrations?\n    self.assertEqual(len(changes), 1)\n\n    author_deconstructible_list = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, validators=[DeconstructibleObject(), 1]))\n    ])\n    changes = self.get_changes([author_deconstructible], [author_deconstructible_list])\n    # Right number of migrations?\n    self.assertEqual(len(changes), 1)\n\n    author_deconstructible_tuple = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, validators=[(DeconstructibleObject(), 1)])\n    ])\n    changes = self.get_changes([author_deconstructible], [author_deconstructible_tuple])\n    # Right number of migrations?\n    self.assertEqual(len(changes), 1)\n\n    author_deconstructible_dict = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, validators=[{\"item\": DeconstructibleObject()}])\n    ])\n    changes = self.get_changes([author_deconstructible], [author_deconstructible_dict])\n    # Right number of migrations?\n    self.assertEqual(len(changes), 1)\n", "def test_deconstruct_list_of_strings(self):\n    \"\"\"\n    Test that deconstructing a list of strings does not remove whitespace.\n    \"\"\"\n    before = ModelState(\n        \"testapp\", \"Author\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"bio\", models.CharField(max_length=200, default=[\"Line 1\", \"Line 2\"])),\n        ]\n    )\n    after = ModelState(\n        \"testapp\", \"Author\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"bio\", models.CharField(max_length=200, default=[\"Line 1\", \"Line 2\"])),\n        ]\n    )\n    changes = self.get_changes([before], [after])\n    # Right number of migrations?\n    self.assertEqual(len(changes), 0)\n\n    after = ModelState(\n        \"testapp\", \"Author\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"bio\", models.CharField(max_length=200, default=[\"Line 1\", \"Line 3\"])),\n        ]\n    )\n    changes = self.get_changes([before], [after])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"bio\")\n    self.assertOperationFieldAttributes(changes, 'testapp', 0, 0, default=[\"Line 1\", \"Line 3\"])\n"], "sample_9": ["    def test_nested_exception_with_context(self):\n        try:\n            raise Exception(2)\n        except Exception as e:\n            try:\n                raise Exception(1) from e\n            except Exception as nested_e:\n                try:\n                    raise Exception(3) from nested_e\n                except Exception:\n                    exc_info = sys.exc_info()\n\n        with mock.patch('django.utils.autoreload._exception', exc_info):\n            with self.assertRaises(Exception) as cm:\n                autoreload.raise_last_exception()\n            self.assertEqual(cm.exception.args[0], 3)\n            self.assertEqual(cm.exception.__cause__.args[0], 1)\n            self.assertEqual(cm.exception.__cause__.__cause__.args[0], 2)\n", "    def test_common_roots_with_multiple_common_prefixes(self):\n        paths = (\n            Path('/first/second/third'),\n            Path('/first/second/fourth'),\n            Path('/first/third'),\n            Path('/first/fourth'),\n            Path('/root/first/second/third'),\n        )\n        results = autoreload.common_roots(paths)\n        self.assertCountEqual(results, [Path('/first/second'), Path('/first/'), Path('/root/first/second/third')])\n", "    def test_signal_sent_and_trigger_reload_called(self, mocked_file_changed, mocked_trigger_reload):\n        reloader = autoreload.BaseReloader()\n        reloader.notify_file_changed('file_path')\n        mocked_file_changed.assert_called_once_with(sender=reloader, file_path='file_path')\n        mocked_trigger_reload.assert_called_once_with('file_path')\n", "    def test_nothing_is_done_if_not_tty(self, mock_isatty):\n        mock_isatty.return_value = False\n        autoreload.ensure_echo_on()\n        self.assertEqual(mock_isatty.call_count, 1)\n", "    def test_common_roots_multiple_parents(self):\n        paths = (\n            Path('/first/second/third'),\n            Path('/first/second/third/fourth'),\n            Path('/first/second/fifth'),\n            Path('/root/first/'),\n        )\n        results = autoreload.common_roots(paths)\n        self.assertCountEqual(results, [Path('/first/second/'), Path('/root/first/')])\n"], "sample_96": ["def test_ridge_regression_return_n_iter():\n    rng = np.random.RandomState(0)\n    X = rng.randn(10, 5)\n    y = rng.randn(10)\n\n    # Test that n_iter is returned correctly when return_n_iter=True\n    for solver in ('sparse_cg', 'lsqr', 'sag', 'saga'):\n        coefs, n_iter = ridge_regression(X, y, alpha=1.0, solver=solver,\n                                         return_n_iter=True)\n        assert n_iter is not None\n\n    # Test that n_iter is None when return_n_iter=False\n    for solver in ('sparse_cg', 'lsqr', 'sag', 'saga'):\n        coefs = ridge_regression(X, y, alpha=1.0, solver=solver,\n                                 return_n_iter=False)\n        assert 'n_iter' not in coefs\n\n    # Test that n_iter is None for solvers that don't support it\n    for solver in ('svd', 'cholesky'):\n        coefs = ridge_regression(X, y, alpha=1.0, solver=solver,\n                                 return_n_iter=True)\n        assert coefs[1] is None\n", "def test_ridge_regression_solver_saga():\n    # Test ridge regression saga solver\n\n    rng = np.random.RandomState(42)\n\n    n_samples, n_features, n_target = 20, 10, 2\n    X = rng.randn(n_samples, n_features)\n    y = rng.randn(n_samples, n_target)\n\n    ridge_saga = Ridge(alpha=1.0, solver='saga', random_state=42).fit(X, y)\n    ridge_cholesky = Ridge(alpha=1.0, solver='cholesky').fit(X, y)\n\n    assert_array_almost_equal(ridge_saga.coef_, ridge_cholesky.coef_)\n    assert_array_almost_equal(ridge_saga.intercept_, ridge_cholesky.intercept_)\n", "def test_ridge_regression_random_state():\n    # Test that the random state is correctly used in Ridge regression.\n\n    n_samples = 100\n    n_features = 20\n    X = np.random.rand(n_samples, n_features)\n    y = np.random.rand(n_samples)\n\n    ridge = Ridge(random_state=0, solver='sag')\n    ridge.fit(X, y)\n    y_pred_1 = ridge.predict(X)\n\n    ridge = Ridge(random_state=0, solver='sag')\n    ridge.fit(X, y)\n    y_pred_2 = ridge.predict(X)\n\n    assert_array_almost_equal(y_pred_1, y_pred_2, decimal=10)\n\n    ridge = Ridge(random_state=1, solver='sag')\n    ridge.fit(X, y)\n    y_pred_3 = ridge.predict(X)\n\n    assert_array_not_almost_equal(y_pred_1, y_pred_3, decimal=10)\n", "def test_ridge_multi_class_sparse():\n    # Test RidgeClassifier with multi-class sparse matrix\n    X, y = make_multilabel_classification(n_samples=100, n_features=10, random_state=42)\n    y = np.argmax(y.toarray(), axis=1)\n\n    for solver in ('sag', 'saga'):\n        ridge = RidgeClassifier(solver=solver)\n        ridge.fit(X, y)\n        assert_array_almost_equal(ridge.predict(X), y)\n\n    # Test with sparse matrix\n    X_sparse = sp.csr_matrix(X)\n    for solver in ('sag', 'saga'):\n        ridge = RidgeClassifier(solver=solver)\n        ridge.fit(X_sparse, y)\n        assert_array_almost_equal(ridge.predict(X_sparse), y)\n", "def test_ridge_regression_solver_edge_cases():\n    X = np.array([[1]])\n    y = np.array([1])\n\n    # Test the edge case of empty alphas\n    assert_raises(ValueError, ridge_regression, X, y, alpha=[], solver=\"auto\")\n\n    # Test the edge case of empty X\n    assert_raises(ValueError, ridge_regression, X=np.array([]), y=y, alpha=1.0, solver=\"auto\")\n\n    # Test the edge case of empty y\n    assert_raises(ValueError, ridge_regression, X=X, y=np.array([]), alpha=1.0, solver=\"auto\")\n\n    # Test the edge case of a single sample\n    assert_almost_equal(ridge_regression(X, y, alpha=1.0, solver=\"auto\"), np.array([[1.0]]))\n\n    # Test the edge case of a single feature\n    assert_almost_equal(ridge_regression(X, y, alpha=1.0, solver=\"auto\"), np.array([[1.0]]))\n\n    # Test the edge case of a single target\n    assert_almost_equal(ridge_regression(X, y, alpha=1.0, solver=\"auto\"), np.array([[1.0]]))\n\n    # Test the edge case of multiple targets\n    y = np.array([[1], [2]])\n    assert_almost_equal(ridge_regression(X, y, alpha=1.0, solver=\"auto\"), np.array([[1.0], [2.0]]))\n"], "sample_94": ["def test_getstatementrange_with_f_string() -> None:\n    source = Source(\n        \"\"\"\\", "def test_getstatementrange_ast_issue59():\n    source = Source(\n        \"\"\"\\", "def test_source_indented_trailing_newline() -> None:\n    source = Source(\n        \"\"\"\\\n            if True:\n                return\n\n        \"\"\"\n    )\n    assert len(source) == 4\n    assert source[1].strip() == \"if True:\"\n    assert source[2].strip() == \"    return\"\n    assert source[3] == \"\"\n", "    def test_deindent_multiple_levels(self):\n        source = Source(\n            \"\"\"\\\n                if True:\n                    if False:\n                        pass\n        \"\"\"\n        )\n        deindented_source = source.deindent()\n        assert str(deindented_source) == \"\"\"\\", "def test_source_indentation_preservation():\n    source = Source(\n        \"\"\"\\\n            return 1\n\n            return 2\n    \"\"\"\n    )\n    indented_source = source.indent(\"    \")\n    assert str(indented_source) == textwrap.indent(str(source), \"    \") + \"\\n\"\n"], "sample_0": ["def test_widget_rendering(self):\n    form = forms.Form()\n    form.fields['text'] = forms.CharField()\n    form.fields['number'] = forms.IntegerField()\n    form.fields['email'] = forms.EmailField()\n    form.fields['url'] = forms.URLField()\n    form.fields['password'] = forms.CharField(widget=forms.PasswordInput)\n    form.fields['hidden'] = forms.CharField(widget=forms.HiddenInput)\n    form.fields['multiple_hidden'] = forms.MultipleChoiceField(\n        choices=[('1', '1'), ('2', '2')], widget=forms.MultipleHiddenInput)\n    form.fields['file'] = forms.FileField()\n    form.fields['clearable_file'] = forms.FileField(widget=forms.ClearableFileInput)\n    form.fields['textarea'] = forms.CharField(widget=forms.Textarea)\n    form.fields['date'] = forms.DateField()\n    form.fields['datetime'] = forms.DateTimeField()\n    form.fields['time'] = forms.TimeField()\n    form.fields['checkbox'] = forms.BooleanField()\n    form.fields['choice'] = forms.ChoiceField(choices=[('1', '1'), ('2', '2')])\n    form.fields['multiple_choice'] = forms.MultipleChoiceField(\n        choices=[('1', '1'), ('2', '2')])\n    form.fields['radio'] = forms.ChoiceField(\n        choices=[('1', '1'), ('2', '2')], widget=forms.RadioSelect)\n    form.fields['checkbox_multiple'] = forms.MultipleChoiceField(\n        choices=[('1', '1'), ('2', '2')], widget=forms.CheckboxSelectMultiple)\n\n    rendered_form = form.as_table()\n    for field_name in form.fields:\n        self.assertIn(field_name, rendered_form)\n", "def test_select_date_widget(self):\n    widget = SelectDateWidget()\n    date = datetime.date(2022, 7, 25)\n    context = widget.get_context('date', date, {})\n    self.assertEqual(context['widget']['subwidgets'][0]['value'], '2022')\n    self.assertEqual(context['widget']['subwidgets'][1]['value'], '7')\n    self.assertEqual(context['widget']['subwidgets'][2]['value'], '25')\n", "def test_select_date_widget(self):\n    # Create a test widget\n    widget = SelectDateWidget()\n\n    # Test the format_value method with a datetime object\n    dt = datetime.date(2022, 1, 1)\n    formatted_value = widget.format_value(dt)\n    self.assertEqual(formatted_value, {'year': 2022, 'month': 1, 'day': 1})\n\n    # Test the format_value method with a string in a specific format\n    formatted_value = widget.format_value('2022-01-01')\n    self.assertEqual(formatted_value, {'year': 2022, 'month': 1, 'day': 1})\n\n    # Test the format_value method with a string in a different format\n    with override_settings(USE_L10N=True):\n        formatted_value = widget.format_value('01/01/2022')\n        self.assertEqual(formatted_value, {'year': 2022, 'month': 1, 'day': 1})\n\n    # Test the value_from_datadict method\n    data = {'year': '2022', 'month': '1', 'day': '1'}\n    value = widget.value_from_datadict(data, {}, 'date')\n    self.assertEqual(value, '2022-01-01')\n\n    # Test the value_omitted_from_data method\n    data = {}\n    self.assertTrue(widget.value_omitted_from_data(data, {}, 'date'))\n\n    # Test the id_for_label method\n    id_ = 'date'\n    self.assertEqual(widget.id_for_label(id_), 'date_year')\n\n    # Test the get_context method\n    context = widget.get_context('date', dt, {})\n    self.assertIn('widget', context)\n    self.assertIn('subwidgets', context['widget'])\n    self.assertEqual(len(context['widget']['subwidgets']), 3)\n", "def test_widgets_media_definition(self):\n    widgets_with_media = [\n        'ClearableFileInput',\n        'PasswordInput',\n        'SelectDateWidget',\n        'SplitDateTimeWidget',\n        'SplitHiddenDateTimeWidget',\n    ]\n\n    for widget_name in widgets_with_media:\n        widget = getattr(self, f'test_{widget_name}_media_definition', None)\n        if widget is None:\n            widget = globals()[widget_name]()\n        self.assertIsNotNone(widget.media)\n", "    def test_select_date_widget_render(self):\n        widget = SelectDateWidget()\n        html = widget.render('date', '2022-01-01')\n        self.assertIn('id=\"id_date_year\"', html)\n        self.assertIn('id=\"id_date_month\"', html)\n        self.assertIn('id=\"id_date_day\"', html)\n        self.assertIn('selected value=\"2022\"', html)\n        self.assertIn('selected value=\"1\"', html)\n        self.assertIn('selected value=\"1\"', html)\n"], "sample_27": ["def test_token_with_unsaved_user(self):\n    \"\"\"A token for an unsaved user can be created and checked.\"\"\"\n    user = User(username='unsaveduser', email='test5@example.com')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk1), True)\n", "def test_make_token_with_timestamp(self):\n    \"\"\"\n    Ensure that _make_token_with_timestamp generates the correct token.\n    \"\"\"\n    user = User.objects.create_user('testuser', 'test@example.com', 'testpw')\n    generator = PasswordResetTokenGenerator()\n    timestamp = 1000  # arbitrary timestamp\n    token = generator._make_token_with_timestamp(user, timestamp)\n    ts_b36, hash_string = token.split(\"-\")\n    self.assertEqual(base36_to_int(ts_b36), timestamp)\n    expected_hash_string = salted_hmac(\n        generator.key_salt,\n        generator._make_hash_value(user, timestamp),\n        secret=generator.secret,\n        algorithm=generator.algorithm,\n    ).hexdigest()[::2]\n    self.assertEqual(hash_string, expected_hash_string)\n", "def test_make_hash_value(self):\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    ts = p0._num_seconds(datetime.now())\n    hash_value = p0._make_hash_value(user, ts)\n    self.assertIsInstance(hash_value, str)\n\n    # Test with last_login as None\n    user.last_login = None\n    hash_value_none_last_login = p0._make_hash_value(user, ts)\n    self.assertIsInstance(hash_value_none_last_login, str)\n    self.assertNotEqual(hash_value, hash_value_none_last_login)\n\n    # Test with email field\n    user.email = 'newemail@example.com'\n    hash_value_new_email = p0._make_hash_value(user, ts)\n    self.assertIsInstance(hash_value_new_email, str)\n    self.assertNotEqual(hash_value, hash_value_new_email)\n", "def test_make_hash_value(self):\n    \"\"\"\n    Test that _make_hash_value returns the expected string.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    timestamp = 1000  # Some arbitrary timestamp\n    expected = f\"{user.pk}{user.password}{user.last_login}{timestamp}{user.email}\"\n    p0 = PasswordResetTokenGenerator()\n    actual = p0._make_hash_value(user, timestamp)\n    self.assertEqual(actual, expected)\n    # Test with a user that has last_login set to None\n    user.last_login = None\n    user.save()\n    expected = f\"{user.pk}{user.password}None{timestamp}{user.email}\"\n    actual = p0._make_hash_value(user, timestamp)\n    self.assertEqual(actual, expected)\n", "def test_make_token_with_timestamp(self):\n    \"\"\"The _make_token_with_timestamp method generates the correct token.\"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    timestamp = 1000\n    token = p0._make_token_with_timestamp(user, timestamp)\n    ts_b36, _ = token.split(\"-\")\n    self.assertEqual(base36_to_int(ts_b36), timestamp)\n"], "sample_145": ["def test_latex_tilde():\n    assert latex(~x) == r\"\\neg x\"\n    assert latex(~(x > y)) == r\"\\neg \\left(x > y\\right)\"\n    assert latex(~(x >= y)) == r\"\\neg \\left(x \\geq y\\right)\"\n    assert latex(~(x < y)) == r\"\\neg \\left(x < y\\right)\"\n    assert latex(~(x <= y)) == r\"\\neg \\left(x \\leq y\\right)\"\n    assert latex(~(x == y)) == r\"\\neg \\left(x = y\\right)\"\n    assert latex(~(x != y)) == r\"\\neg \\left(x \\neq y\\right)\"\n    assert latex(~(x**2 > 1)) == r\"\\neg \\left(x^{2} > 1\\right)\"\n    assert latex(~(x**2 < 1)) == r\"\\neg \\left(x^{2} < 1\\right)\"\n", "def test_latex_fancy_names():\n    x = Symbol(r'\\frac{a_1}{b_1}')\n    assert latex(x) == r'\\frac{a_1}{b_1}'\n    assert latex(cos(x)) == r'\\cos{\\left(\\frac{a_1}{b_1} \\right)}'\n    assert latex(x**2) == r'{\\left(\\frac{a_1}{b_1} \\right)}^{2}'\n    y = Symbol(r'\\frac{\\frac{a_1}{b_1}}{b_2}')\n    assert latex(y) == r'\\frac{\\frac{a_1}{b_1}}{b_2}'\n    assert latex(cos(y)) == r'\\cos{\\left(\\frac{\\frac{a_1}{b_1}}{b_2} \\right)}'\n    assert latex(y**2) == r'{\\left(\\frac{\\frac{a_1}{b_1}}{b_2} \\right)}^{2}'\n    z = Symbol(r'\\left(\\frac{a_1}{b_1}\\right)^2')\n    assert latex(z) == r'{\\left(\\frac{a_1}{b_1} \\right)}^{2}'\n    assert latex(cos(z)) == r'\\cos{\\left({\\left(\\frac{a_1}{b_1} \\right)}^{2} \\right)}'\n    assert latex(z**2) == r'{\\left({\\left(\\frac{a_1}{b_1} \\right)}^{2} \\right)}^{2}'\n", "def test_latex_tensor_indices():\n    from sympy.tensor.tensor import TensorIndexType, TensorHead\n\n    i, j, k, l = symbols('i:j, k:l')\n\n    L = TensorIndexType(\"L\")\n    L1 = TensorIndexType(\"L1\")\n    i1 = tensor_indices(\"i1\", L)\n    i2 = tensor_indices(\"i2\", L1)\n\n    A, B, C = tensor_heads(\"A B C\", [L])\n\n    assert latex(A(i1)) == r\"A{}^{i_{1}}\"\n\n    assert latex(B(i, j)) == r\"B{}^{ij}\"\n\n    assert latex(C(i, j, k, l)) == r\"C{}^{ijkl}\"\n\n    assert latex(A(i, j)) == r\"A{}^{ij}\"\n\n    assert latex(A(i1, i2)) == r\"A{}^{i_{1}i_{2}}\"\n\n    assert latex(A(-i, i1)) == r\"A{}_{i}{}^{i_{1}}\"\n\n    assert latex(A(i, -j)) == r\"A{}^{i}{}_{j}\"\n", "def test_mat_expr_latex():\n    from sympy import MatrixSymbol, Eq\n    from sympy.physics.control.lti import TransferFunction\n\n    # test TransferFunction\n    A, B, C, D = MatrixSymbol('A', 1, 1), MatrixSymbol('B', 1, 1), MatrixSymbol('C', 1, 1), MatrixSymbol('D', 1, 1)\n    s = symbols('s')\n    tf = TransferFunction(A, (s**2 + 1), (s + 1))\n    assert latex(tf) == r\"\\frac{\\frac{1}{s^{2} + 1} A}{\\frac{1}{s + 1} A}\"\n\n    # test Eq\n    x, y = symbols('x y')\n    eq = Eq(x + y, 3)\n    assert latex(eq) == r\"x + y = 3\"\n    eq = Eq(x + y, 0)\n    assert latex(eq) == r\"x + y = 0\"\n    eq = Eq(x + y, x)\n    assert latex(eq) == r\"x + y = x\"\n    eq = Eq(x + y, y)\n    assert latex(eq) == r\"x + y = y\"\n", "def test_latex_custom_numbers():\n    from sympy import symbols\n    from sympy.abc import mu, tau\n\n    # test that we can add custom numbers\n    custom_numbers = {\n        3: r'\\3',\n        4: r'\\4',\n        5: r'\\5',\n        6: r'\\6',\n        7: r'\\7',\n        8: r'\\8',\n        9: r'\\9',\n        0: r'\\0',\n    }\n\n    x, y, z = symbols('x y z')\n    p = symbols('p', integer=True, positive=True)\n\n    assert latex(3*x, custom_numbers=custom_numbers) == r'\\3 x'\n    assert latex(-3*x, custom_numbers=custom_numbers) == r'- \\3 x'\n    assert latex(3*x + 2*y - 3*z, custom_numbers=custom_numbers) == r'\\3 x + 2 y - \\3 z'\n\n    assert latex(3*mu, custom_numbers=custom_numbers) == r'\\3 \\mu'\n    assert latex(3*tau, custom_numbers=custom_numbers) == r'\\3 \\tau'\n\n    assert latex(3*p, custom_numbers=custom_numbers) == r'\\3 p'\n"], "sample_1": ["def test_understand_err_col():\n    colnames = ['a', 'a_err', 'b', 'b_perr', 'b_nerr', 'c']\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [1])\n    assert np.allclose(terr, [2])\n\n    colnames = ['a', 'a_perr', 'a_nerr', 'b', 'b_err']\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [3])\n    assert np.allclose(terr, [0])\n\n    colnames = ['a']\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [])\n    assert np.allclose(terr, [])\n\n    colnames = ['a', 'a_perr']\n    with pytest.raises(ValueError, match=\"Missing negative error\"):\n        _understand_err_col(colnames)\n\n    colnames = ['a', 'a_nerr']\n    with pytest.raises(ValueError, match=\"Missing positive error\"):\n        _understand_err_col(colnames)\n", "def test_write_read_error_specs(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3]))\n    t1.add_column(Column(name=\"a_err\", data=[0.1, 0.2, 0.3]))\n    t1.add_column(Column(name=\"b\", data=[4, 5, 6]))\n    t1.add_column(Column(name=\"b_perr\", data=[0.1, 0.2, 0.3]))\n    t1.add_column(Column(name=\"b_nerr\", data=[-0.1, -0.2, -0.3]))\n    t1.write(test_file, format=\"ascii.qdp\", err_specs={\"serr\": [1], \"terr\": [2]})\n    t2 = Table.read(test_file, format=\"ascii.qdp\", table_id=0, names=[\"a\", \"b\"])\n    assert np.allclose(t2[\"a_err\"], t1[\"a_err\"])\n    assert np.allclose(t2[\"b_perr\"], t1[\"b_perr\"])\n    assert np.allclose(t2[\"b_nerr\"], t1[\"b_nerr\"])\n", "def test_interpret_err_lines():\n    # Test with symmetric error\n    colnames = [\"a\", \"b\", \"c_err\", \"d\"]\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [2])\n    assert np.allclose(terr, [])\n\n    # Test with two-sided error\n    colnames = [\"a\", \"b_err1\", \"b_err2\", \"c\", \"d\"]\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [])\n    assert np.allclose(terr, [1])\n\n    # Test with both\n    colnames = [\"a\", \"b_err1\", \"b_err2\", \"c\", \"c_err\", \"d\"]\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [4])\n    assert np.allclose(terr, [1])\n\n    # Test with error in first column\n    colnames = [\"a_err1\", \"a_err2\", \"b\", \"c\", \"d\"]\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [])\n    assert np.allclose(terr, [0])\n\n    # Test missing positive error\n    colnames = [\"a\", \"a_nerr\", \"b\", \"c\", \"d\"]\n    with pytest.raises(ValueError):\n        _understand_err_col(colnames)\n\n    # Test missing negative error\n    colnames = [\"a\", \"a_perr\", \"b\", \"c\", \"d\"]\n    with pytest.raises(ValueError):\n        _understand_err_col(colnames)\n", "def test_interpret_err_lines():\n    # Test with symmetric error\n    colnames = ['a', 'a_err', 'b', 'c']\n    cols = _interpret_err_lines({'serr': [1]}, 4, names=colnames)\n    assert cols[0] == 'a'\n    assert cols[1] == 'a_err'\n    assert cols[2] == 'b'\n    assert cols[3] == 'c'\n\n    # Test with two-sided error\n    colnames = ['a', 'a_perr', 'a_nerr', 'b', 'c']\n    cols = _interpret_err_lines({'terr': [1]}, 5, names=colnames)\n    assert cols[0] == 'a'\n    assert cols[1] == 'a_perr'\n    assert cols[2] == 'a_nerr'\n    assert cols[3] == 'b'\n    assert cols[4] == 'c'\n\n    # Test with both symmetric and two-sided error\n    colnames = ['a', 'a_perr', 'a_nerr', 'b', 'b_err', 'c']\n    cols = _interpret_err_lines({'terr': [1], 'serr': [2]}, 6, names=colnames)\n    assert cols[0] == 'a'\n    assert cols[1] == 'a_perr'\n    assert cols[2] == 'a_nerr'\n    assert cols[3] == 'b'\n    assert cols[4] == 'b_err'\n    assert cols[5] == 'c'\n\n    # Test with incorrect column names\n    colnames = ['a', 'a_nerr', 'b', 'c']\n    with pytest.raises(ValueError):\n        _interpret_err_lines(None, 4, names=colnames)\n\n    # Test with incorrect column names\n    colnames = ['a', 'a_perr', 'b', 'c']\n    with pytest.raises(ValueError):\n        _interpret_err_lines(None, 4, names=colnames)\n", "def test_understand_err_col():\n    colnames = ['a', 'a_err', 'b', 'b_perr', 'b_nerr']\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [1])\n    assert np.allclose(terr, [2])\n\n    colnames = ['a', 'a_nerr']\n    with pytest.raises(ValueError) as excinfo:\n        _understand_err_col(colnames)\n    assert \"Missing positive error\" in str(excinfo.value)\n\n    colnames = ['a', 'a_perr']\n    with pytest.raises(ValueError) as excinfo:\n        _understand_err_col(colnames)\n    assert \"Missing negative error\" in str(excinfo.value)\n\n    colnames = ['a', 'b', 'b_err']\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [2])\n    assert np.allclose(terr, [])\n\n    colnames = ['a', 'b', 'b_nerr', 'b_perr']\n    with pytest.raises(ValueError) as excinfo:\n        _understand_err_col(colnames)\n    assert \"Negative before positive error\" in str(excinfo.value)\n\n    colnames = ['a', 'a_err', 'b_err', 'b']\n    with pytest.raises(ValueError) as excinfo:\n        _understand_err_col(colnames)\n    assert \"Data column after error column\" in str(excinfo.value)\n\n    colnames = ['a', 'a_perr', 'a_nerr', 'b', 'b_err']\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [4])\n    assert np.allclose(terr, [0])\n\n    colnames = ['a', 'a_err', 'b', 'b_err', 'c', 'c_perr', 'c_nerr']\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [1, 3])\n    assert np.allclose(terr, [5])\n"], "sample_156": ["def test_parser_mathematica_function_handling():\n    parser = MathematicaParser()\n\n    convert_chain = lambda expr: parser.parse(expr)\n\n    x, y = symbols('x y')\n\n    assert convert_chain(\"Function[x, x^3]\") == Lambda(x, x**3)\n    assert convert_chain(\"Function[{x, y}, x^2 + y^2]\") == Lambda((x, y), x**2 + y**2)\n    assert convert_chain(\"Function[x, x^3] &[y]\") == y**3\n    assert convert_chain(\"Function[{x, y}, x^2 + y^2] &[3, 4]\") == 3**2 + 4**2\n\n    # Issue 21827\n    assert convert_chain(\"Function[x, x]\") == Lambda(x, x)\n    assert convert_chain(\"Function[x, x]&\") == Lambda(x, x)\n    assert convert_chain(\"Function[x, x]&[y]\") == y\n", "def test_mathematica_parser_edge_cases():\n    parser = MathematicaParser()\n\n    # Test parsing of Mathematica's CompoundExpression\n    compound_expr = \"a;b;c\"\n    sympy_expr = [\"CompoundExpression\", \"a\", \"b\", \"c\"]\n    assert parser.parse(compound_expr) == sympy_expr\n\n    # Test parsing of Mathematica's Apply\n    apply_expr = \"f@@{a, b, c}\"\n    sympy_expr = [\"Apply\", \"f\", [\"List\", \"a\", \"b\", \"c\"]]\n    assert parser.parse(apply_expr) == sympy_expr\n\n    # Test parsing of Mathematica's Condition\n    condition_expr = \"x_/; x>0\"\n    sympy_expr = [\"Condition\", \"x\", \"x > 0\"]\n    assert parser.parse(condition_expr) == sympy_expr\n\n    # Test parsing of Mathematica's RuleDelayed\n    rule_delayed_expr = \"f[x_, 3] := x^3\"\n    sympy_expr = [\"SetDelayed\", [\"f\", [\"Pattern\", \"x\", [\"Blank\"]], \"3\"], [\"Power\", \"x\", \"3\"]]\n    assert parser.parse(rule_delayed_expr) == sympy_expr\n\n    # Test parsing of Mathematica's Alternatives\n    alternatives_expr = \"a|b|c\"\n    sympy_expr = [\"Alternatives\", \"a\", \"b\", \"c\"]\n    assert parser.parse(alternatives_expr) == sympy_expr\n\n    # Test parsing of Mathematica's PatternTest\n    pattern_test_expr = \"x_?IntegerQ\"\n    sympy_expr = [\"PatternTest\", \"x\", \"IntegerQ\"]\n    assert parser.parse(pattern_test_expr) == sympy_expr\n\n    # Test parsing of Mathematica's Repeated and RepeatedNull\n    repeated_expr = \"x..\"\n    sympy_expr = [\"Repeated\", \"x\"]\n    assert parser.parse(repeated_expr) == sympy_expr\n\n    repeated_null_expr = \"x...\"\n    sympy_expr = [\"RepeatedNull\", \"x\"]\n    assert parser.parse(repeated_null_expr) == sympy_expr\n", "def test_mathematica_setdelayed():\n    parser = MathematicaParser()\n\n    chain = lambda expr: parser.parse(expr)\n\n    # Test SetDelayed:\n    assert chain(\"f[x_] := x^2\") == Lambda(Dummy(\"x\"), Dummy(\"x\")**2)\n    assert chain(\"f[x_, y_] := x^2 + y\") == Lambda((Dummy(\"x\"), Dummy(\"y\")), Dummy(\"x\")**2 + Dummy(\"y\"))\n    assert chain(\"f[x_, 2] := x^3 /; x > 0\") == Lambda(Dummy(\"x\"), Conditional(Dummy(\"x\")**3, Dummy(\"x\") > 0))\n\n    # Test Set:\n    assert chain(\"f[x_] = x^2\") == Eq(Lambda(Dummy(\"x\"), Dummy(\"x\")**2), Dummy(\"x\")**2)\n\n    # Test Set with more than one definition:\n    assert chain(\"f[x_, y_] = x^2 + y\\nf[z_] = z^3\") == [\"CompoundExpression\", Eq(Lambda((Dummy(\"x\"), Dummy(\"y\")), Dummy(\"x\")**2 + Dummy(\"y\")), Dummy(\"x\")**2 + Dummy(\"y\")), Eq(Lambda(Dummy(\"z\"), Dummy(\"z\")**3), Dummy(\"z\")**3)]\n\n    # Test SetDelayed with more than one definition:\n    assert chain(\"f[x_, y_] := x^2 + y\\nf[z_] := z^3\") == [\"CompoundExpression\", Lambda((Dummy(\"x\"), Dummy(\"y\")), Conditional(Dummy(\"x\")**2 + Dummy(\"y\"), True)), Lambda(Dummy(\"z\"), Conditional(Dummy(\"z\")**3, True))]\n", "def test_parser_mathematica_complex_expressions():\n    parser = MathematicaParser()\n\n    convert_chain = lambda expr: parser.parse(expr)\n\n    # Complex expressions\n    complex_expr1 = \"Sin[x]^2 + Cos[y]^2\"\n    complex_expr2 = \"Exp[Log[4]] + ArcSin[Cos[0]]\"\n    complex_expr3 = \"x (y + z)^2 - 3 (x - y)\"\n    complex_expr4 = \"(x + y) / (z - w)\"\n    complex_expr5 = \"x^2 + y^2 + z^2\"\n\n    assert convert_chain(complex_expr1) == sin(x)**2 + cos(y)**2\n    assert convert_chain(complex_expr2) == exp(log(4)) + asin(cos(0))\n    assert convert_chain(complex_expr3) == x*(y + z)**2 - 3*(x - y)\n    assert convert_chain(complex_expr4) == (x + y) / (z - w)\n    assert convert_chain(complex_expr5) == x**2 + y**2 + z**2\n\n    # Test parsing of expressions with multiple layers of parentheses\n    nested_expr1 = \"(x + (y + z)) * (a + (b + c))\"\n    nested_expr2 = \"((x + y) * (z + w)) / (a + (b + c))\"\n\n    assert convert_chain(nested_expr1) == (x + (y + z)) * (a + (b + c))\n    assert convert_chain(nested_expr2) == ((x + y) * (z + w)) / (a + (b + c))\n\n    # Test parsing of expressions with multiple layers of parentheses and other operators\n    mixed_expr1 = \"(x + (y + z)) * (a + (b + c)) / (d - (e - f))\"\n    mixed_expr2 = \"((x + y) * (z + w)) / (a + (b + c)) + (d - (e - f))\"\n\n    assert convert_chain(mixed_expr1) == (x + (y + z)) * (a + (b + c)) / (d - (e - f))\n    assert convert_chain(mixed_expr2) == ((x + y) * (z + w)) / (a + (b + c)) + (d - (e - f", "def test_mathematica_translations():\n    parser = MathematicaParser()\n\n    assert parser.parse(\"f[x, y]\") == Function(\"f\")(x, y)\n\n    parser = MathematicaParser({'f[x, y]': 'f(x, y)'})\n\n    assert parser.parse(\"f[x, y]\") == f(x, y)\n\n    parser = MathematicaParser({'f[x_, y_]': 'f(x, y)'})\n\n    assert parser.parse(\"f[x, y]\") == f(x, y)\n\n    # Test the deprecation warning\n    import warnings\n    with warnings.catch_warnings(record=True) as w:\n        mathematica(\"f[x, y]\", additional_translations={'f[x_, y_]': 'f(x, y)'})\n        assert len(w) == 1\n        assert \"deprecated\" in str(w[0].message)\n\n    # Test that a bad translation raises an error\n    raises(ValueError, lambda: MathematicaParser({'f[x_, y_': 'f(x, y)'}))\n\n    # Test that a bad translation raises an error\n    raises(ValueError, lambda: MathematicaParser({1: 'f(x, y)'}))\n\n    # Test that a bad translation raises an error\n    raises(ValueError, lambda: MathematicaParser({'f[x_, y_]': 1}))\n\n    # Test that a bad translation raises an error\n    raises(ValueError, lambda: MathematicaParser({'f[x_, y_': 'f(x, y)'}))\n\n    # Test that a bad translation raises an error\n    raises(ValueError, lambda: MathematicaParser({'f[x_, y_]': 'f(x, '}))\n"], "sample_143": ["def test_pretty_NDimArray():\n    x, y, z, w = symbols(\"x y z w\")\n\n    for ArrayType in (ImmutableDenseNDimArray, ImmutableSparseNDimArray, MutableDenseNDimArray, MutableSparseNDimArray):\n        M = ArrayType([[[x, y], [z, w]])\n\n        ascii_str = \\", "def test_pretty_grassmann():\n    from sympy import WedgeProduct\n    e1 = Symbol(\"e1\")\n    e2 = Symbol(\"e2\")\n    e3 = Symbol(\"e3\")\n    e4 = Symbol(\"e4\")\n\n    assert upretty(WedgeProduct(e1,e2)) == 'e\u2081\u2227e\u2082'\n    assert upretty(WedgeProduct(e1,e1)) == '0'\n    assert upretty(WedgeProduct(e1,e2,e3)) == 'e\u2081\u2227e\u2082\u2227e\u2083'\n    assert upretty(WedgeProduct(e1,e2,e1,e3)) == '0'\n    assert upretty(WedgeProduct(e1,e2,e3,e4)) == 'e\u2081\u2227e\u2082\u2227e\u2083\u2227e\u2084'\n", "def test_pretty_issue_18390():\n    from sympy import Point\n    assert pretty(Point(0, 0)) == 'Point(0, 0)'\n    assert upretty(Point(0, 0)) == 'Point(0, 0)'\n    p = Point(0, 0)\n    assert pretty(p) == 'Point(0, 0)'\n    assert upretty(p) == 'Point(0, 0)'\n    assert pretty(Point(0, 0).x) == '0'\n    assert upretty(Point(0, 0).x) == '0'\n    assert pretty(Point(0, 0).y) == '0'\n    assert upretty(Point(0, 0).y) == '0'\n    assert pretty(p.x) == '0'\n    assert upretty(p.x) == '0'\n    assert pretty(p.y) == '0'\n    assert upretty(p.y) == '0'\n", "def test_pretty_ITE_with_Piecewise():\n    from sympy import ITE, Piecewise\n    expr = ITE(x, y, z)\n    pw_expr = Piecewise((0, x > 0), (y, x == 0), (z, True))\n    assert upretty(ITE(x, pw_expr, z)) == \"\"\"\\", "def test_pretty_bitwise():\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z')\n    n = Symbol('n')\n\n    assert pretty(x & y) == \"x & y\"\n    assert upretty(x & y) == \"x \u2227 y\"\n    assert pretty(x | y) == \"x | y\"\n    assert upretty(x | y) == \"x \u2228 y\"\n    assert pretty(x ^ y) == \"x ^ y\"\n    assert upretty(x ^ y) == \"x \u2295 y\"\n\n    assert pretty(And(x, y, z)) == \"And(x, y, z)\"\n    assert upretty(And(x, y, z)) == \"x \u2227 y \u2227 z\"\n\n    assert pretty(Or(x, y, z)) == \"Or(x, y, z)\"\n    assert upretty(Or(x, y, z)) == \"x \u2228 y \u2228 z\"\n\n    assert pretty(Xor(x, y, z)) == \"Xor(x, y, z)\"\n    assert upretty(Xor(x, y, z)) == \"x \u2295 y \u2295 z\"\n    assert pretty(Not(x)) == \"Not(x)\"\n    assert upretty(Not(x)) == \"\u00acx\"\n    assert pretty(Nor(x, y, z)) == \"Nor(x, y, z)\"\n    assert upretty(Nor(x, y, z)) == \"x \u22bd y \u22bd z\"\n    assert pretty(Nand(x, y, z)) == \"Nand(x, y, z)\"\n    assert upretty(Nand(x, y, z)) == \"x \u22bc y \u22bc z\"\n\n    assert pretty(Lsh(x, n)) == \"Lsh(x, n)\"\n    assert upretty(Lsh(x, n)) == \"x \u226a n\"\n\n    assert pretty(Rsh(x, n)) == \"Rsh(x, n)\"\n    assert upretty(Rsh(x, n)) == \"x \u226b n\"\n\n    assert pretty(Xor(x, y, z)) == \"Xor(x, y, z)\"\n    assert upretty(Xor(x, y, z)) == \"x \u2295 y \u2295 z\"\n    assert pretty(Implies(x, y)) == \"Implies(x, y)\"\n    assert upretty(Implies(x, y)) == \"x \u2192 y\"\n    assert pretty(Equivalent(x, y)) == \"Equivalent"], "sample_106": ["def test_transformer_rank():\n    X = iris_data\n    y = iris_target\n\n    # Check that the rank of the transformation is correct for different\n    # number of components\n    for n_components in [1, 2, 3, 4]:\n        nca = NeighborhoodComponentsAnalysis(n_components=n_components)\n        nca.fit(X, y)\n        rank = np.linalg.matrix_rank(nca.components_)\n        assert rank == min(n_components, X.shape[1]), (\n            \"The rank of the transformation matrix is not correct.\")\n", "def test_transform_input_validation():\n    nca = NeighborhoodComponentsAnalysis()\n    nca.fit(iris_data, iris_target)\n\n    # test non-numeric input\n    assert_raise_message(ValueError,\n                         'Input X should be an array or other '\n                         'similarily array-like object',\n                         nca.transform, 'not an array')\n\n    # test non-2D input\n    assert_raise_message(ValueError,\n                         'Reshape your data either using array.reshape(-1, 1) '\n                         'if your data has a single feature or array.reshape(1, -1) '\n                         'if it contains a single sample',\n                         nca.transform, np.array([1, 2, 3]))\n\n    # test input with NaN\n    X_nan = iris_data.copy()\n    X_nan[0, 0] = np.nan\n    assert_raise_message(ValueError,\n                         'Input X contains NaN, infinity or a value too large '\n                         'for dtype(',\n                         nca.transform, X_nan)\n\n    # test input with inf\n    X_inf = iris_data.copy()\n    X_inf[0, 0] = np.inf\n    assert_raise_message(ValueError,\n                         'Input X contains NaN, infinity or a value too large '\n                         'for dtype(',\n                         nca.transform, X_inf)\n", "def test_random_state_reproducibility():\n    \"\"\"Test that the random state is properly set and provides reproducibility.\"\"\"\n    X = iris_data\n    y = iris_target\n\n    # Test that NeighborhoodComponentsAnalysis is reproducible with\n    # a RandomState\n    nca1 = NeighborhoodComponentsAnalysis(random_state=42)\n    nca1.fit(X, y)\n    transformation1 = nca1.components_\n\n    nca2 = NeighborhoodComponentsAnalysis(random_state=42)\n    nca2.fit(X, y)\n    transformation2 = nca2.components_\n\n    assert_array_equal(transformation1, transformation2)\n\n    # Test that NeighborhoodComponentsAnalysis is not reproducible with\n    # different random states\n    nca3 = NeighborhoodComponentsAnalysis(random_state=0)\n    nca3.fit(X, y)\n    transformation3 = nca3.components_\n\n    assert_array_equal(transformation1, transformation3) is False\n", "def test_transform_after_init_fits_expected_shape():\n    \"\"\"Test that transform method fits the expected shape after initialization\n    by different methods.\n\n    \"\"\"\n    X = iris_data\n    y = iris_target\n\n    # initialization methods\n    init_methods = ['auto', 'pca', 'lda', 'identity', 'random']\n\n    for init in init_methods:\n        nca = NeighborhoodComponentsAnalysis(init=init)\n        nca.fit(X, y)\n        X_t = nca.transform(X)\n        assert_equal(X_t.shape, (X.shape[0], nca.components_.shape[0]))\n", "def test_transform_X_zero_features():\n    X = np.zeros((10, 0))\n    y = [1, 1, 2, 2, 1, 1, 2, 2, 1, 2]\n\n    # Test that an error is raised when transform is called on an NCA\n    # that has not been fitted.\n    nca = NeighborhoodComponentsAnalysis()\n    assert_raises_regex(ValueError,\n                        'has not been fitted',\n                        nca.transform, X)\n\n    nca = NeighborhoodComponentsAnalysis(n_components=1)\n    nca.fit(X, y)\n    assert nca.components_.shape == (1, 0)\n\n    # assert that transform does not fail\n    X_t = nca.transform(X)\n    assert_array_equal(X_t, np.zeros((10, 0)))\n"], "sample_103": ["def test_mutual_info_classif_discrete_sparse():\n    X = np.array([[0, 0, 0],\n                  [1, 1, 0],\n                  [2, 0, 1],\n                  [2, 0, 1],\n                  [2, 0, 1]])\n    X_csr = csr_matrix(X)\n    y = np.array([0, 1, 2, 2, 1])\n\n    # Here X[:, 0] is the most informative feature, and X[:, 1] is weakly\n    # informative.\n    mi_dense = mutual_info_classif(X, y, discrete_features=True)\n    mi_sparse = mutual_info_classif(X_csr, y, discrete_features=True)\n    assert_array_equal(np.argsort(-mi_dense), np.array([0, 2, 1]))\n    assert_array_equal(mi_dense, mi_sparse)\n", "def test_mutual_info_classif_sparse():\n    # We generate sample from multivariate normal distribution, using\n    # transformation from initially uncorrelated variables. The zero\n    # variables after transformation is selected as the target vector,\n    # it has the strongest correlation with the variable 2, and\n    # the weakest correlation with the variable 1.\n    T = np.array([\n        [1, 0.5, 2, 1],\n        [0, 1, 0.1, 0.0],\n        [0, 0.1, 1, 0.1],\n        [0, 0.1, 0.1, 1]\n    ])\n    cov = T.dot(T.T)\n    mean = np.zeros(4)\n\n    rng = check_random_state(0)\n    Z = rng.multivariate_normal(mean, cov, size=1000)\n    X = Z[:, 1:]\n    y = (Z[:, 0] > 0).astype(int)\n\n    X_sparse = csr_matrix(X)\n    mi_dense = mutual_info_classif(X, y, random_state=0)\n    mi_sparse = mutual_info_classif(X_sparse, y, random_state=0)\n\n    assert_array_equal(mi_dense, mi_sparse)\n\n    # Test with mixed features\n    X[:, 2] = (X[:, 2] > 0.5).astype(int)\n    X_sparse = csr_matrix(X)\n    mi_dense = mutual_info_classif(X, y, discrete_features=[2], random_state=0)\n    mi_sparse = mutual_info_classif(X_sparse, y, discrete_features=[2], random_state=0)\n\n    assert_array_equal(mi_dense, mi_sparse)\n", "def test_mutual_info_copy():\n    # Test that a copy is made when copy=True and the original data is not\n    # modified when copy=False.\n    X = np.array([[0, 0, 0],\n                  [1, 1, 0],\n                  [2, 0, 1],\n                  [2, 0, 1],\n                  [2, 0, 1]])\n    y = np.array([0, 1, 2, 2, 1])\n\n    X_copy = X.copy()\n    mutual_info_classif(X_copy, y, copy=True, random_state=0)\n    assert_array_equal(X, X_copy)\n\n    X_no_copy = X.copy()\n    mutual_info_classif(X_no_copy, y, copy=False, random_state=0)\n    assert_array_equal(X, X_no_copy)\n\n    X_no_copy = X.copy()\n    mutual_info_regression(X_no_copy, y, copy=False, random_state=0)\n    assert_array_equal(X, X_no_copy)\n", "def test_estimate_mi_copy():\n    X = np.array([[0, 0, 0],\n                  [1, 1, 0],\n                  [2, 0, 1],\n                  [2, 0, 1],\n                  [2, 0, 1]], dtype=float)\n    y = np.array([0, 1, 2, 2, 1], dtype=float)\n\n    # Test that the input data is not modified when copy=True.\n    X_copy = X.copy()\n    y_copy = y.copy()\n    mi_1 = mutual_info_regression(X_copy, y_copy, copy=True, random_state=0)\n    assert_array_equal(X, X_copy)\n    assert_array_equal(y, y_copy)\n\n    # Test that the input data is modified when copy=False.\n    X_no_copy = X.copy()\n    y_no_copy = y.copy()\n    mi_2 = mutual_info_regression(X_no_copy, y_no_copy, copy=False, random_state=0)\n    assert_array_not_equal(X, X_no_copy)\n    assert_array_not_equal(y, y_no_copy)\n\n    # Test that the results are the same whether or not the data is copied.\n    assert_array_equal(mi_1, mi_2)\n", "def test_estimate_mi_continuous():\n    # Test that _estimate_mi function works as expected for continuous features\n    # and target.\n    rng = check_random_state(0)\n    X = rng.rand(1000, 3)\n    y = rng.rand(1000)\n\n    mi = _estimate_mi(X, y, discrete_features=False, discrete_target=False,\n                      n_neighbors=3, copy=True, random_state=0)\n    assert_array_equal(mi.shape, (3,))\n\n    # Check that the function returns the same result for a copy of the data\n    mi_copy = _estimate_mi(X, y, discrete_features=False, discrete_target=False,\n                           n_neighbors=3, copy=True, random_state=0)\n    assert_array_equal(mi, mi_copy)\n\n    # Check that the function returns a different result for a different random\n    # state\n    mi_different_state = _estimate_mi(X, y, discrete_features=False,\n                                      discrete_target=False, n_neighbors=3,\n                                      copy=True, random_state=42)\n    assert_array_not_equal(mi, mi_different_state)\n\n    # Check that the function raises an error for sparse data with continuous\n    # features\n    X_sparse = csr_matrix(X)\n    assert_raises(ValueError, _estimate_mi, X_sparse, y, discrete_features=False,\n                 discrete_target=False, n_neighbors=3, copy=True, random_state=0)\n"], "sample_113": ["def test_verbose_feature_names_out_unique(transformers, remainder, expected_names):\n    \"\"\"Check feature_names_out for verbose_feature_names_out=True with duplicate names\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame([[1, 2, 3, 4, 5]], columns=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n    ct = ColumnTransformer(\n        transformers,\n        remainder=remainder,\n    )\n    ct.fit(df)\n\n   ", "def test_column_transformer_set_output_empty_transformers():\n    \"\"\"Check that ColumnTransformer can set output after fitting with no transformers.\"\"\"\n    ct = ColumnTransformer([], remainder=StandardScaler())\n    ct.fit(np.array([1, 2, 3]))\n    ct.set_output(transform=\"pandas\")\n    X = np.array([4, 5, 6])\n    X_trans = ct.transform(X)\n    assert isinstance(X_trans, np.ndarray)\n", "def test_column_transformer_output_indices_with_callable_selector():\n    # Checks for the output_indices_ attribute with data frames\n    pd = pytest.importorskip(\"pandas\")\n\n    X_df = pd.DataFrame(np.arange(6).reshape(3, 2), columns=[\"first\", \"second\"])\n\n        return X.columns[0]\n\n    ct = ColumnTransformer([(\"trans1\", Trans(), select_first), (\"trans2\", Trans(), \"second\")])\n    X_trans = ct.fit_transform(X_df)\n    assert ct.output_indices_ == {\n        \"trans1\": slice(0, 1),\n        \"trans2\": slice(1, 2),\n        \"remainder\": slice(0, 0),\n    }\n    assert_array_equal(X_trans[:, [0]], X_trans[:, ct.output_indices_[\"trans1\"]])\n    assert_array_equal(X_trans[:, [1]], X_trans[:, ct.output_indices_[\"trans2\"]])\n    assert_array_equal(X_trans[:, []], X_trans[:, ct.output_indices_[\"remainder\"]])\n\n        return X.columns[:]\n\n    ct = ColumnTransformer(\n        [(\"trans1\", Trans(), select_first_and_second), (\"trans2\", Trans(), \"second\")]\n    )\n    with pytest.raises(ValueError, match=\"No valid specification\"):\n        ct.fit_transform(X_df)\n", "def test_column_transformer_dataframe_transformer():\n    # Functional test for column transformer + column selector\n    pd = pytest.importorskip(\"pandas\")\n    X_df = pd.DataFrame(\n        {\n            \"col_int\": np.array([0, 1, 2], dtype=int),\n            \"col_float\": np.array([0.0, 1.0, 2.0], dtype=float),\n            \"col_cat\": [\"one\", \"two\", \"one\"],\n            \"col_str\": [\"low\", \"middle\", \"high\"],\n        },\n        columns=[\"col_int\", \"col_float\", \"col_cat\", \"col_str\"],\n    )\n    X_df[\"col_str\"] = X_df[\"col_str\"].astype(\"category\")\n\n    cat_selector = make_column_selector(dtype_include=[\"category\", object])\n    num_selector = make_column_selector(dtype_include=np.number)\n\n    ohe = OneHotEncoder()\n    scaler = StandardScaler()\n    df_trans = FunctionTransformer(validate=False)\n\n    ct_selector = make_column_transformer(\n        (ohe, cat_selector), (scaler, num_selector), (df_trans, [\"col_str\"])\n    )\n    X_selector = ct_selector.fit_transform(X_df)\n    assert isinstance(X_selector, pd.DataFrame)\n\n    assert_array_equal(X_selector[\"col_str\"], X_df[\"col_str\"])\n", "def test_feature_names_out_with_pandas_input(transformer_weights):\n    \"\"\"Check get_feature_names_out with pandas input\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n\n    ct = ColumnTransformer([(\"trans\", TransWithNames([\"a_transformed\"]), [\"a\"])], transformer_weights=transformer_weights)\n\n    expected_names = [\"trans__a_transformed\", \"b\"]\n    if transformer_weights is None:\n        expected_names = np.array(expected_names, dtype=object)\n    else:\n        expected_names = np.array(expected_names, dtype=object)\n    assert_array_equal(ct.fit(df).get_feature_names_out(), expected_names)\n"], "sample_97": ["def test_label_binarize_empty_classes():\n    y = [1, 2, 3]\n    classes = []\n    assert_raises(ValueError, label_binarize, y, classes)\n", "def test_label_binarize_multiclass_with_unseen_labels():\n    y = [0, 1, 2, 3]\n    classes = [0, 1, 2]\n    pos_label = 1\n    neg_label = 0\n    expected = np.array([[1, 0, 0],\n                         [0, 1, 0],\n                         [0, 0, 1],\n                         [0, 0, 0]])\n\n    yield check_binarized_results, y, classes, pos_label, neg_label, expected\n\n    assert_raises(ValueError, label_binarize, y, classes, neg_label=0,\n                  pos_label=pos_label, sparse_output=False)\n\n    y = [0, 1, 2, 3]\n    classes = [0, 1, 2]\n    pos_label = 1\n    neg_label = 0\n    expected = np.array([[1, 0, 0],\n                         [0, 1, 0],\n                         [0, 0, 1],\n                         [0, 0, 0]])\n\n    assert_raises(ValueError, label_binarize, y, classes, neg_label=0,\n                  pos_label=pos_label, sparse_output=True)\n", "def test_label_encoder_on_string_labels():\n    le = LabelEncoder()\n    y = ['class1', 'class2', 'class1', 'class2', 'class3']\n    le.fit(y)\n    assert_array_equal(le.classes_, ['class1', 'class2', 'class3'])\n    assert_array_equal(le.transform(y), [0, 1, 0, 1, 2])\n    assert_array_equal(le.inverse_transform([0, 1, 0, 1, 2]), y)\n\n    le.fit_transform(y)\n    assert_array_equal(le.classes_, ['class1', 'class2', 'class3'])\n    assert_array_equal(le.transform(y), [0, 1, 0, 1, 2])\n    assert_array_equal(le.inverse_transform([0, 1, 0, 1, 2]), y)\n\n    assert_raises(ValueError, le.transform, ['class4'])\n    assert_raises(ValueError, le.inverse_transform, [3])\n", "def test_multilabel_binarizer_input_types():\n    mlb = MultiLabelBinarizer()\n    y = [[1, 2], (1,), {1, 2}, np.array([1, 2])]\n\n    assert_array_equal(mlb.fit_transform(y),\n                       np.array([[0, 1, 1],\n                                 [1, 0, 0],\n                                 [1, 1, 0],\n                                 [0, 1, 1]]))\n    assert_array_equal(mlb.classes_, [1, 2])\n\n    mlb.fit(y)\n    assert_array_equal(mlb.transform(y),\n                       np.array([[0, 1, 1],\n                                 [1, 0, 0],\n                                 [1, 1, 0],\n                                 [0, 1, 1]]))\n    assert_array_equal(mlb.classes_, [1, 2])\n", "def test_label_binarizer_sparse_thresholding():\n    # Check that thresholding works for sparse matrices\n    X = np.array([[0.4, 0.7], [0.1, 0.3]])\n    X_sparse = csr_matrix(X)\n    y = np.array([0, 1])\n    classes = np.array([0, 1])\n\n    for threshold in [0.5, 0]:\n        binarized = label_binarize(y, classes, pos_label=1, neg_label=0,\n                                   sparse_output=True)\n        assert_equal(binarized.shape, (2, 2))\n        assert_true(issparse(binarized))\n        assert_array_equal(binarized.toarray(), np.array([[1, 0], [0, 1]]))\n\n        binarized_sparse = label_binarize(X_sparse, classes, pos_label=1,\n                                          neg_label=0, sparse_output=True,\n                                          threshold=threshold)\n        assert_equal(binarized_sparse.shape, (2, 2))\n        assert_true(issparse(binarized_sparse))\n        assert_array_equal(binarized_sparse.toarray(), np.array([[0, 1], [0, 0]]))\n\n        binarized_dense = label_binarize(X, classes, pos_label=1, neg_label=0,\n                                         sparse_output=False,\n                                         threshold=threshold)\n        assert_equal(binarized_dense.shape, (2, 2))\n        assert_array_equal(binarized_dense, np.array([[0, 1], [0, 0]]))\n\n    lb = LabelBinarizer(pos_label=1, neg_label=0, sparse_output=True)\n    lb.fit(y)\n    binarized_sparse = lb.transform(X_sparse, threshold=threshold)\n    assert_equal(binarized_sparse.shape, (2, 2))\n    assert_true(issparse(binarized_sparse))\n    assert_array_equal(binarized_sparse.toarray(), np.array([[0, 1], [0, 0]]))\n"], "sample_26": ["    def test_create_test_db(self, mocked_create_test_db):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        creation.create_test_db(verbosity=1, autoclobber=False, serialize=True, keepdb=False)\n        mocked_create_test_db.assert_called_once_with(1, False, False)\n        self.assertEqual(test_connection.settings_dict['NAME'], 'test_database')\n", "    def test_test_db_name_setting(self):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        test_db_name = creation._get_test_db_name()\n        self.assertEqual(test_db_name, 'test_testdb')\n", "    def test_clone_test_db(self):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        with mock.patch.object(creation, '_clone_test_db'):\n            creation.clone_test_db(suffix='clone', verbosity=0, autoclobber=True, keepdb=False)\n        # Test that the correct method was called\n        creation._clone_test_db.assert_called_once_with('clone', 0, False)\n", "    def test_destroy_database(self):\n        # destroy_test_db() destroys the test database.\n        connection.creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n        self.assertIsNotNone(connection.settings_dict['NAME'])\n        connection.creation.destroy_test_db(verbosity=0)\n        self.assertIsNotNone(connection.settings_dict['NAME'])\n", "    def test_serialize_db_to_string(self):\n        # serialize_db_to_string() serializes all data in the database.\n        obj = Object.objects.create()\n        data = connection.creation.serialize_db_to_string()\n        self.assertIn('\"model\": \"backends.object\"', data)\n        self.assertIn('\"pk\": %s' % obj.pk, data)\n"], "sample_50": ["def test_encode_empty(self):\n    \"\"\"\n    Test the encode_empty parameter of the _encode method.\n    \"\"\"\n    storage = self.get_storage()\n    encoded_data = storage._encode([], encode_empty=True)\n    self.assertNotEqual(encoded_data, b'')\n    self.assertIsNotNone(storage._decode(encoded_data))\n", "def test_update_with_empty_messages_list(self):\n    \"\"\"\n    Update with an empty messages list should result in the cookie being deleted.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n    storage.update(response)\n    self.assertEqual(response.cookies.get(CookieStorage.cookie_name), None)\n", "def test_process_messages_recursive(self):\n    \"\"\"\n    Verify that MessageDecoder.process_messages recursively processes\n    nested lists and dictionaries.\n    \"\"\"\n    data = [\n        {\n            MessageEncoder.message_key: [0, 0, constants.INFO, 'message', 'extra tags'],\n            'nested_list': [\n                [MessageEncoder.message_key, 0, constants.INFO, 'nested message'],\n            ],\n            'nested_dict': {\n                MessageEncoder.message_key: [0, 0, constants.INFO, 'nested message'],\n            },\n        },\n        MessageEncoder.message_key,\n        0,\n        constants.INFO,\n        'message',\n    ]\n    expected_result = [\n        {\n            'nested_list': [Message(constants.INFO, 'nested message')],\n            'nested_dict': Message(constants.INFO, 'nested message'),\n            MessageEncoder.message_key: Message(constants.INFO, 'message', extra_tags='extra tags'),\n        },\n        Message(constants.INFO, MessageEncoder.message_key),\n        0,\n        constants.INFO,\n        'message',\n    ]\n    decoder = MessageDecoder()\n    result = decoder.process_messages(data)\n    self.assertEqual(result, expected_result)\n", "    def test_empty_cookie(self):\n        \"\"\"\n        When the cookie is empty, the storage should return an empty list.\n        \"\"\"\n        storage = self.storage_class(self.get_request())\n        storage.request.COOKIES = {CookieStorage.cookie_name: ''}\n        self.assertEqual(list(storage), [])\n", "def test_remove_oldest_message(self):\n    \"\"\"\n    When the data exceeds the maximum allowed cookie size and remove_oldest=True,\n    the oldest messages are removed.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # Generate a list of 5 messages to be added to the storage.\n    messages = ['message1', 'message2', 'message3', 'message4', 'message5']\n    for message in messages:\n        storage.add(constants.INFO, message)\n\n    # Simulate the max_cookie_size being exceeded, by setting it to a small value.\n    original_max_cookie_size = CookieStorage.max_cookie_size\n    CookieStorage.max_cookie_size = 50\n\n    # Update the storage and check the messages that were not stored.\n    unstored_messages = storage.update(response)\n\n    # Restore the original max_cookie_size value.\n    CookieStorage.max_cookie_size = original_max_cookie_size\n\n    self.assertEqual(len(unstored_messages), 1)\n    self.assertEqual(unstored_messages[0].message, messages[0])\n\n    # Check the messages that were stored.\n    cookie_storing = self.stored_messages_count(storage, response)\n    self.assertEqual(cookie_storing, 4)\n"], "sample_90": ["def test_mark_evaluator_invalidraise(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.raises(Exception)\n            raise Exception('Test exception')\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    passed, skipped, failed = reprec.listoutcomes()\n    assert len(passed) == 1\n    assert len(skipped) == 0\n    assert len(failed) == 0\n\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.raises(ValueError)\n            raise Exception('Test exception')\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    passed, skipped, failed = reprec.listoutcomes()\n    assert len(passed) == 0\n    assert len(skipped) == 0\n    assert len(failed) == 1\n", "def test_mark_evaluator_invalidraise(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.eval(\"1/0\")\n            pass\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    failed = reprec.getfailedcollections()\n    assert len(failed) == 1\n    assert \"ZeroDivisionError\" in str(failed[0].longrepr)\n\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.eval(\"1/0\", raises=ZeroDivisionError)\n            pass\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    assert reprec.countoutcomes(passed=1)\n", "def test_invalid_raising(self):\n    mark_eval = MarkEvaluator(mock.Mock(), \"invalidraises\")\n    with pytest.raises(TEST_OUTCOME):\n        mark_eval.invalidraise(Exception(\"Test exception\"))\n\n    mark_eval = MarkEvaluator(mock.Mock(), \"raises\")\n    mark_eval._mark = Mark(\"raises\", (\"ValueError\",), {})\n    assert mark_eval.invalidraise(ValueError(\"Test exception\")) is False\n    assert mark_eval.invalidraise(Exception(\"Test exception\")) is True\n", "def test_MarkEvaluator_invalidraise(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.raises()\n            assert True\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    reprec.assertoutcome(passed=1)\n\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.raises()\n            raise ValueError()\n            assert True\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    reprec.assertoutcome(passed=1)\n\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.raises(ValueError)\n            raise TypeError()\n            assert True\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    reprec.assertoutcome(failed=1)\n\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.raises()\n            assert True\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    reprec.assertoutcome(passed=1)\n\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.raises()\n            assert True\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    reprec.assertoutcome(passed=1)\n", "def test_mark_evaluator_istrue(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n            assert 1\n\n        @pytest.mark.eval(\"1 == 1\")\n            assert 1\n\n        @pytest.mark.eval(\"1 != 1\")\n            assert 1\n\n        @pytest.mark.eval(\"test_1\")\n            assert 1\n    \"\"\"\n    )\n\n    from ..outcomes import fail\n    from .structures import Mark\n    from _pytest.nodes import Item\n\n    class MockItem(Item):\n            self.config = mock.Mock()\n            self.keywords = {\"test_1\": True}\n            self.iter_markers = mock.Mock(return_value=[Mark(\"eval\", (1 == 1,))])\n\n    evaluator = MarkEvaluator(MockItem(), \"eval\")\n    assert evaluator.istrue()\n    assert evaluator.getexplanation() == \"\"\n\n    evaluator = MarkEvaluator(MockItem(), \"eval\")\n    evaluator._mark = Mark(\"eval\", (\"test_1\",))\n    assert evaluator.istrue()\n    assert evaluator.getexplanation() == \"\"\n\n    evaluator = MarkEvaluator(MockItem(), \"eval\")\n    evaluator._mark = Mark(\"eval\", (\"1 != 1\",))\n    assert not evaluator.istrue()\n    assert evaluator.getexplanation() == \"condition: 1 != 1\"\n\n    evaluator = MarkEvaluator(MockItem(), \"eval\")\n    evaluator._mark = Mark(\"eval\", (\"test_1\",))\n    del evaluator.item.keywords[\"test_1\"]\n    assert not evaluator.istrue()\n    assert evaluator.getexplanation() == \"condition: test_1\"\n\n    evaluator = MarkEvaluator(MockItem(), \"eval\")\n    evaluator._mark = Mark(\"eval\", (\"1 / 0\",))\n    try:\n        assert evaluator.istrue()\n    except Exception as e:\n        assert isinstance(e, fail.Exception) and \"SyntaxError\" in str(e)\n    else:\n        assert False, \"Expected fail.Exception\"\n"], "sample_125": ["def test_issue_5325():\n    assert 0**oo is S.NaN\n    assert 0**-oo is S.NaN\n    assert (S(2) - pi)**S.Infinity is S.NaN\n    assert (S(2) - pi)**-S.Infinity is S.NaN\n    assert (S(2) - pi)**S.NegativeInfinity is S.NaN\n    assert (S(2) - pi)**oo is S.NaN\n", "def test_Float_string_creation_with_empty_precision():\n    # Test Float string creation with empty precision\n    s = str(pi.evalf(128))\n    assert Float(s)._prec == 53\n    assert Float(s, '')._prec == 128\n    assert Float('123.456', '') == Float('123.456', 53)\n    assert Float('123.45678901234567890', '')._prec == 53\n    assert Float('123.45678901234567890', 50)._prec == 50\n", "def test_latex():\n    assert latex(Float('1.2')) == r'1.2'\n    assert latex(Float('1.2', 3)) == r'1.200'\n    assert latex(Float('1.2e-3', 3)) == r'1.200e-3'\n    assert latex(Float('-1.2e-3')) == r'-1.2e-3'\n    assert latex(Float('nan')) == r'\\mathrm{NaN}'\n    assert latex(Float('inf')) == r'\\infty'\n    assert latex(Float('-inf')) == r'-\\infty'\n    assert latex(Rational(1, 2)) == r'\\frac{1}{2}'\n    assert latex(Rational(1, 3)) == r'\\frac{1}{3}'\n    assert latex(Integer(-1)) == r'-1'\n    assert latex(Integer(0)) == r'0'\n    assert latex(Integer(1)) == r'1'\n    assert latex(S.Infinity) == r'\\infty'\n    assert latex(S.NegativeInfinity) == r'-\\infty'\n    assert latex(S.ComplexInfinity) == r'\\tilde{\\infty}'\n    assert latex(S.ImaginaryUnit) == r'i'\n    assert latex(S.NaN) == r'\\mathrm{NaN}'\n    assert latex(S.Exp1) == r'e'\n    assert latex(S.Pi) == r'\\pi'\n    assert latex(S.EulerGamma) == r'\\gamma'\n    assert latex(S.GoldenRatio) == r'\\phi'\n    assert latex(S.Catalan) == r'C'\n", "def test_mod_inverse_modulo_Rational():\n    # Check the case where 'a' is a Rational and 'm' is a Rational.\n    assert mod_inverse(Rational(2, 3), Rational(5, 7)) == Rational(3, 2)\n    assert mod_inverse(Rational(4, 5), Rational(11, 7)) == Rational(2, 7)\n    # Check the case where 'a' is a Rational and 'm' is an Integer.\n    assert mod_inverse(Rational(2, 3), Integer(7)) == Rational(5, 3)\n    assert mod_inverse(Rational(3, 5), Integer(7)) == Rational(2, 1)\n    # Check the case where 'a' is an Integer and 'm' is a Rational.\n    assert mod_inverse(Integer(2), Rational(5, 7)) == Rational(3, 5)\n    assert mod_inverse(Integer(4), Rational(11, 7)) == Rational(8, 11)\n    # Check the case where both 'a' and 'm' are Rational but not Integers.\n    assert mod_inverse(Rational(2, 7), Rational(3, 11)) == Rational(2, 7)\n    assert mod_inverse(Rational(2, 11), Rational(3, 7)) == Rational(8, 3)\n", "def test_issue_10247():\n    assert mod_inverse(1, 1) == 1\n    assert mod_inverse(0, 3) == 0\n    assert mod_inverse(1, 3) == 1\n    assert mod_inverse(2, 3) == 2\n    assert mod_inverse(1, 4) == 1\n    assert mod_inverse(3, 4) == 3\n    assert mod_inverse(7, 8) == 7\n    assert mod_inverse(7, 9) == 4\n    assert mod_inverse(14, 17) == 5\n    assert mod_inverse(25, 29) == 20\n    assert mod_inverse(41, 45) == 14\n    assert mod_inverse(62, 67) == 33\n    assert mod_inverse(73, 81) == 55\n    assert mod_inverse(91, 103) == 14\n    assert mod_inverse(106, 117) == 16\n    assert mod_inverse(130, 151) == 16\n    assert mod_inverse(142, 157) == 112\n    assert mod_inverse(143, 167) == 24\n    assert mod_inverse(165, 179) == 165\n    assert mod_inverse(171, 199) == 88\n    assert mod_inverse(172, 197) == 173\n    assert mod_inverse(181, 193) == 104\n    assert mod_inverse(182, 223) == 139\n    assert mod_inverse(191, 197) == 191\n    assert mod_inverse(198, 223) == 111\n    assert mod_inverse(202, 211) == 202\n    assert mod_inverse(206, 229) == 206\n    assert mod_inverse(208, 233) == 208\n    assert mod_inverse(214, 251) == 214\n    assert mod_inverse(218, 239) == 218\n    assert mod_inverse(225, 229) == 225\n    assert mod_inverse(227, 251) == 227\n    assert mod_inverse(230, 241) == 230\n    assert mod_inverse(232, 257) == 232\n    assert mod_inverse(237, 271) == 237\n    assert mod_inverse(245, 277) == "], "sample_129": ["def test_latex_Subs_list():\n    subs = Subs((x+y+z)**2, (x, y, z), [1, 2, 3])\n    assert latex(subs) == r'\\left. \\left(x + y + z\\right)^{2} \\right|_{\\substack{ x=1\\\\ y=2\\\\ z=3 }}'\n    subs = Subs(x+y+z, (x, y, z), [1, 2, 3])\n    assert latex(subs) == r'\\left. x + y + z \\right|_{\\substack{ x=1\\\\ y=2\\\\ z=3 }}'\n    subs = Subs(x+y+z, (x, y, z), (1, 2, 3))\n    assert latex(subs) == r'\\left. x + y + z \\right|_{\\substack{ x=1\\\\ y=2\\\\ z=3 }}'\n", "def test_latexprinting_objects_with_custom_latexnames():\n    obj = Object(\"MyObject\")\n    obj._latex_form = \"MyLaTeXName\"\n    assert latex(obj) == \"MyLaTeXName\"\n", "def test_latex_Quaternion():\n    from sympy.physics.quantum import TensorProduct\n    from sympy import Symbol\n    x, y, z, t = symbols('x y z t')\n    q1 = Quaternion(x, y, z, t)\n    q2 = Quaternion(x, y, z, t)\n\n    assert latex(q1) == \"x + y i + z j + t k\"\n    assert latex(q2) == \"x + y i + z j + t k\"\n    assert latex(-q1) == \"- x - y i - z j - t k\"\n    assert latex(q1*q2) == r\"\\left(- t^{2} - z^{2} - y^{2} - x^{2}\\right) + \\left(- t y + z x\\right) i + \\left(t x + z y\\right) j + \\left(t z - y x\\right) k\"\n    assert latex(q1+q2) == r\"2 x + 2 y i + 2 z j + 2 t k\"\n    assert latex(q1-q2) == \"0\"\n    assert latex(q1**2) == r\"- t^{2} - z^{2} - y^{2} - x^{2} + 0 i + 0 j + 0 k\"\n    assert latex(2*q1) == \"2 x + 2 y i + 2 z j + 2 t k\"\n    assert latex(q1/2) == r\"\\frac{x}{2} + \\frac{y}{2} i + \\frac{z}{2} j + \\frac{t}{2} k\"\n    assert latex(TensorProduct(q1, q1)) == r\"\\left( x + y i + z j + t k \\right) \\otimes \\left( x + y i + z j + t k \\right)\"\n", "def test_issue_14626():\n    # Test that latex converts Rational objects correctly\n    assert latex(Rational(1)) == \"1\"\n    assert latex(Rational(-1)) == \"-1\"\n    assert latex(Rational(1, 2)) == r\"\\frac{1}{2}\"\n    assert latex(Rational(1, -2)) == r\"- \\frac{1}{2}\"\n    assert latex(Rational(-1, -2)) == r\"\\frac{1}{2}\"\n    assert latex(Rational(0)) == \"0\"\n    assert latex(Rational(3, 4)) == r\"\\frac{3}{4}\"\n    assert latex(-Rational(3, 4)) == r\"- \\frac{3}{4}\"\n    assert latex(Rational(-3, 4)) == r\"- \\frac{3}{4}\"\n    assert latex(Rational(3, -4)) == r\"- \\frac{3}{4}\"\n    assert latex(Rational(-3, -4)) == r\"\\frac{3}{4}\"\n", "def test_latex_AccentDecorator():\n    from sympy.printing.latex import translate, tex_greek_dictionary\n    greek_letters_set = frozenset(tex_greek_dictionary.keys())\n    for letter in greek_letters_set:\n        for accent in ('dot', 'ddot', 'vec', 'hat', 'bar', 'tilde', 'breve', 'check', 'acute', 'grave', 'prime', 'Mathring', 'bm'):\n            s = letter + accent\n            assert latex(Symbol(s)) == translate(s)\n            assert latex(Symbol(s) + 1) == translate(s) + ' + 1'\n"], "sample_70": ["def test_legend_draggable_mode_expand():\n    fig, ax = plt.subplots()\n    ax.plot(range(10), label='shabnams')\n    leg = ax.legend(draggable=True, mode=\"expand\")\n    assert leg.get_draggable()\n    assert leg._mode == \"expand\"\n", "def test_legend_draggable_set_state():\n    # Test that setting draggable to False and back to True works.\n    fig, ax = plt.subplots()\n    ax.plot(range(10), label='shabnams')\n    leg = ax.legend(draggable=True)\n    assert leg.get_draggable()\n    leg.set_draggable(False)\n    assert not leg.get_draggable()\n    leg.set_draggable(True)\n    assert leg.get_draggable()\n", "def test_legend_multiple_columns():\n    fig, ax = plt.subplots()\n    x = np.linspace(0, 1, 11)\n    for i in range(10):\n        ax.plot(x, np.sin(x + i * np.pi / 10), label=f\"line {i}\")\n    ax.legend(ncols=3)\n    assert len(ax.get_legend().get_children()[1].get_children()) == 3\n", "def test_title_fontproperties():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [3, 4], label='line')\n    title_fontproperties = FontProperties(family='fantasy', size=12)\n    leg = ax.legend(title='Legend Title', title_fontproperties=title_fontproperties)\n    assert leg.get_title().get_fontname() == 'Computer Modern Sans Serif'\n    assert leg.get_title().get_size() == 12\n", "def test_legend_set_framealpha():\n    # Test that framealpha is settable\n    fig, ax = plt.subplots()\n    ax.plot(range(10), label=\"test\")\n    leg = ax.legend(facecolor='w')\n    assert leg.get_frame().get_alpha() == 1\n    leg.set_frame_on(True)\n    assert leg.get_frame().get_alpha() == 1\n    leg.set_frame_on(False)\n    assert leg.get_frame().get_alpha() == 0\n    leg.set_frame_on(True)\n    leg.set_framealpha(0.7)\n    assert leg.get_frame().get_alpha() == 0.7\n"], "sample_3": ["def test_coord_matrix_mapping():\n    c = _coord_matrix(Mapping((0, 1)), 'left', 2)\n    assert_allclose(np.array([[1, 0], [0, 1]]), c)\n    c = _coord_matrix(Mapping((0, 0, 1)), 'left', 3)\n    assert_allclose(np.array([[1, 0], [1, 0], [0, 1]]), c)\n    c = _coord_matrix(Mapping((0, 1, 0, 1)), 'left', 4)\n    assert_allclose(np.array([[1, 0], [0, 1], [1, 0], [0, 1]]), c)\n    c = _coord_matrix(Mapping((0, 1, 0, 1)), 'right', 4)\n    assert_allclose(np.array([[0, 0], [0, 0], [1, 0], [0, 1]]), c)\n", "def test_separable_matrix():\n    # Test case for separability_matrix with a single input and multiple outputs\n    model = sh1 & sh2 | scl1 & scl2\n    expected_matrix = np.array([[True, False], [False, True], [True, False], [False, True]])\n    assert_allclose(separability_matrix(model), expected_matrix)\n\n    # Test case for separability_matrix with multiple inputs and a single output\n    model = rot & sh1 & sh2\n    expected_matrix = np.array([[True, True]])\n    assert_allclose(separability_matrix(model), expected_matrix)\n\n    # Test case for separability_matrix with a model that has a single input and a single output\n    model = sh1\n    expected_matrix = np.array([[True]])\n    assert_allclose(separability_matrix(model), expected_matrix)\n", "def test_separable_matrix():\n    # Test separability_matrix for a single model\n    result = separability_matrix(sh1)\n    assert_allclose(result, np.array([[True]]))\n\n    result = separability_matrix(p2)\n    assert_allclose(result, np.array([[True, True]]))\n\n    # Test separability_matrix for a compound model with a single input\n    compound_model = sh1 & sh2 | sh1\n    result = separability_matrix(compound_model)\n    assert_allclose(result, np.array([[True, False], [False, True], [True, False]]))\n\n    # Test separability_matrix for a compound model with a single output\n    compound_model = sh1 | sh2\n    result = separability_matrix(compound_model)\n    assert_allclose(result, np.array([[True, True]]))\n\n    # Test separability_matrix for a compound model with a single input and output\n    compound_model = sh1\n    result = separability_matrix(compound_model)\n    assert_allclose(result, np.array([[True]]))\n", "def test_is_separable_special_cases():\n    # Test that models with 1 input and > 1 output are correctly identified as non-separable\n    model = models.Polynomial1D(2)\n    assert_allclose(is_separable(model), np.array([False, False]))\n\n    # Test that models with 1 input and 1 output are correctly identified as separable\n    model = models.Shift(1)\n    assert_allclose(is_separable(model), np.array([True]))\n\n    # Test that a model with a single output that is not separable is correctly identified\n    @custom_model\n        return x + y\n    assert_allclose(is_separable(model()), np.array([False]))\n", "def test_is_separable_special_cases():\n    model = sh1 & sh2 | scl1 & scl2\n    assert_allclose(is_separable(model), np.array([False, False]))\n    assert_allclose(separability_matrix(model), np.array([[True, False], [False, True]]))\n\n    model = sh1 & sh2 | map1 | scl1 & scl2\n    assert_allclose(is_separable(model), np.array([True, True, True, True]))\n    assert_allclose(separability_matrix(model), np.array([[True, False], [False, True], [True, False], [False, True]]))\n\n    model = sh1 & sh2 | rot & scl1 & scl2\n    assert_allclose(is_separable(model), np.array([False, False, False, False, False]))\n    assert_allclose(separability_matrix(model), np.array([[True, True, False, False, False], [True, True, False, False, False],\n                                                         [False, False, True, False, False], [False, False, False, True, False],\n                                                         [False, False, False, False, True]]))\n\n    model = sh1 & sh2 | map1 | rot & scl1 & scl2\n    assert_allclose(is_separable(model), np.array([False, False, False, False, False, False]))\n    assert_allclose(separability_matrix(model), np.array([[True, True, False, False, False, False], [True, True, False, False, False, False],\n                                                         [False, False, True, True, False, False], [False, False, True, True, False, False],\n                                                         [False, False, False, False, True, False], [False, False, False, False, False, True]]))\n"], "sample_157": ["def test_tensor_product_simp_Mul():\n    assert tensor_product_simp_Mul(TensorProduct(A, B)*TensorProduct(C, D)) == \\\n        TensorProduct(A*C, B*D)\n    assert tensor_product_simp_Mul(TensorProduct(A, B)*TensorProduct(C, D)*2) == \\\n        2*TensorProduct(A*C, B*D)\n    assert tensor_product_simp_Mul(2*TensorProduct(A, B)*TensorProduct(C, D)) == \\\n        2*TensorProduct(A*C, B*D)\n", "def test_tensor_product_simp_Mul():\n    A, B, C, D, E, F = symbols('A B C D E F', commutative=False)\n    assert tensor_product_simp_Mul(TensorProduct(A, B)*TensorProduct(C, D)) == \\\n        TensorProduct(A*C, B*D)\n    assert tensor_product_simp_Mul(TensorProduct(A, B)*TensorProduct(C, D)*E) == \\\n        E*TensorProduct(A*C, B*D)\n    assert tensor_product_simp_Mul(TensorProduct(A, B)*TensorProduct(C, D)*E*F) == \\\n        E*F*TensorProduct(A*C, B*D)\n    assert tensor_product_simp_Mul(TensorProduct(A, B)*TensorProduct(C, D)**2) == \\\n        TensorProduct(A*C**2, B*D**2)\n    assert tensor_product_simp_Mul(TensorProduct(A, B)**2*TensorProduct(C, D)) == \\\n        TensorProduct(A**2*C, B**2*D)\n    assert tensor_product_simp_Mul(TensorProduct(A, B)*TensorProduct(C, D)*TensorProduct(E, F)) == \\\n        TensorProduct(A*C*E, B*D*F)\n", "def test_tensor_product_simp_commutator():\n    assert tensor_product_simp(Comm(TP(A, B), TP(C, D))) == \\\n        TP(A*C, B*D) - TP(A*D, B*C)\n    assert tensor_product_simp(Comm(TP(A, B), TP(C, D)**x)) == \\\n        TP(A*C**x, B*D**x) - TP(A*D**x, B*C**x)\n    assert tensor_product_simp(Comm(TP(A, B)**x, TP(C, D))) == \\\n        TP(A**x*C, B**x*D) - TP(A**x*D, B**x*C)\n", "def test_tensor_product_simp_Mul():\n    # test tensor_product_simp_Mul on a complex expression\n    assert tensor_product_simp_Mul(TensorProduct(A, B)*TensorProduct(B, C)*TensorProduct(D, E)) == \\\n        TensorProduct(A*B*D, B*C*E)\n    # test tensor_product_simp_Mul on a complex expression with scalars\n    assert tensor_product_simp_Mul(2*TensorProduct(A, B)*3*TensorProduct(B, C)) == \\\n        6*TensorProduct(A*B, B*C)\n", "def test_tensor_product_simp_with_anticommutator():\n    # tests for AntiCommutator-expressions\n    assert tensor_product_simp(TP(A, B)*TP(B, C) + TP(B, C)*TP(A, B)) == \\\n        TP(A*B, B*C) + TP(B*C, A*B)\n    assert tensor_product_simp(TP(A, B)*TP(B, C)**2 + TP(B, C)**2*TP(A, B)) == \\\n        TP(A*B, B**2*C**2) + TP(B**2*C**2, A*B)\n    assert tensor_product_simp(x*(TP(A, B)*TP(B, C) + TP(B, C)*TP(A, B))) == \\\n        x*(TP(A*B, B*C) + TP(B*C, A*B))\n    assert tensor_product_simp(TP(A, B) - TP(C, D)**x + TP(B, C)*TP(A, B)) == \\\n        TP(A, B) - TP(C**x, D**x) + TP(A*B, B*C)\n"], "sample_139": ["def test_conjugate_transpose_properties():\n    M = Matrix([[1, 2], [3, 4]])\n    assert transpose(conjugate(M)) == adjoint(M)\n    assert conjugate(transpose(M)) == adjoint(M)\n    assert adjoint(transpose(M)) == conjugate(M)\n    assert transpose(adjoint(M)) == conjugate(M)\n", "def test_unbranched_argument():\n    from sympy import unbranched_argument, exp_polar, oo, pi\n    x = Symbol('x')\n    i = Symbol('i', imaginary=True)\n    r = Symbol('r', real=True)\n\n    assert unbranched_argument(0) is nan\n    assert unbranched_argument(1) == 0\n    assert unbranched_argument(-1) == pi\n    assert unbranched_argument(I) == pi/2\n    assert unbranched_argument(-I) == -pi/2\n    assert unbranched_argument(1 + I) == pi/4\n    assert unbranched_argument(-1 + I) == pi*Rational(3, 4)\n    assert unbranched_argument(1 - I) == -pi/4\n    assert unbranched_argument(exp_polar(4*pi*I)) == 4*pi\n    assert unbranched_argument(exp_polar(-7*pi*I)) == -7*pi\n    assert unbranched_argument(exp_polar(5 - 3*pi*I/4)) == pi*Rational(-3, 4)\n    assert unbranched_argument(x) == arg(x)\n    assert unbranched_argument(i) == arg(i)\n    assert unbranched_argument(r) == arg(r)\n    assert unbranched_argument(r*I) == pi/2\n    assert unbranched_argument(r*x) == arg(r*x)\n    assert unbranched_argument(r*I*x) == arg(r*I*x)\n", "def test_polar_lift():\n    from sympy import polar_lift, pi, I, exp_polar\n\n    assert polar_lift(0) == 0\n    assert polar_lift(1) == 1\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(I*pi/2)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n\n    assert polar_lift(pi) == pi * exp_polar(0)\n    assert polar_lift(-pi) == pi * exp_polar(I*pi)\n    assert polar_lift(I*pi) == pi * exp_polar(I*pi/2)\n    assert polar_lift(-I*pi) == pi * exp_polar(-I*pi/2)\n\n    assert polar_lift(polar_lift(1)) == 1\n    assert polar_lift(polar_lift(-1)) == exp_polar(I*pi)\n    assert polar_lift(polar_lift(I)) == exp_polar(I*pi/2)\n    assert polar_lift(polar_lift(-I)) == exp_polar(-I*pi/2)\n\n    x = Symbol('x', real=True)\n    assert polar_lift(x) == x\n    assert polar_lift(-x) == x * exp_polar(I*pi)\n\n    y = Symbol('y', imaginary=True)\n    assert polar_lift(y) == exp_polar(I*pi/2)*y\n    assert polar_lift(-y) == exp_polar(-I*pi/2)*y\n\n    z = Symbol('z', complex=True)\n    assert polar_lift(z) == polar_lift(z)\n\n    assert polar_lift(Abs(1 + I)) == Abs(1 + I) * exp_polar(0)\n    assert polar_lift(Abs(-1 - I)) == Abs(-1 - I) * exp_polar(I*pi)\n\n    assert polar_lift(arg(1 + I)) == arg(1 + I)\n    assert polar_lift(arg(-1 - I)) == arg(-1 - I)\n", "def test_polar_lift():\n    x = Symbol('x')\n    a = Symbol('a', real=True)\n    b = Symbol('b', real=True)\n\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(I + 2) == polar_lift(2 + I)\n\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*polar_lift(x)) == 4*polar_lift(x)\n\n    assert polar_lift(a + b*I) == Abs(a + b*I)*exp_polar(I*arg(a + b*I))\n    assert polar_lift(a - b*I) == Abs(a - b*I)*exp_polar(I*arg(a - b*I))\n\n    assert polar_lift(2 + I) == (sqrt(5)*exp_polar(I*atan(1/2)))\n    assert polar_lift(-2 - I) == (sqrt(5)*exp_polar(I*(pi + atan(1/2))))\n\n    # Check that this works with complex numbers\n    assert polar_lift(1 + I).evalf() == polar_lift(1 + I).evalf()\n    assert polar_lift(I + 1).evalf() == polar_lift(I + 1).evalf()\n", "def test_polar_lift():\n    from sympy import Symbol, I, pi, exp_polar, exp\n    from sympy.abc import x\n\n    assert polar_lift(1) == 1*exp_polar(0)\n    assert polar_lift(-1) == 1*exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(-I*pi/2)\n    assert polar_lift(1 + I) == polar_lift(1 + I)\n\n    z = Symbol('z', polar=True)\n    assert polar_lift(z) == z\n\n    x = Symbol('x', real=True)\n    assert polar_lift(x) == x*exp_polar(0)\n\n    # coverage\n    assert unchanged(polar_lift, x)\n    assert polar_lift(x*I).func == polar_lift\n\n    assert polar_lift(4).as_real_imag() == (4, 0)\n    assert polar_lift(-4).as_real_imag() == (4, 0)\n    assert polar_lift(-I).as_real_imag() == (1, 0)\n    assert polar_lift(I + 2).as_real_imag() == (2, 1)\n\n    # derivatives\n    assert polar_lift(x).diff(x) == 1\n    assert polar_lift(x*I).diff(x) == I\n\n    # expand\n    assert polar_lift(2*I).expand(complex=True) == I*2\n    assert polar_lift(x + I).expand(complex=True) == x + I\n\n    assert polar_lift(1 + x*I).as_real_imag() == (1, x)\n\n    assert polar_lift(exp(0)).as_real_imag() == (1, 0)\n    assert polar_lift(exp(I*pi)).as_real_imag() == (-1, 0)\n    assert polar_lift(exp(-I*pi)).as_real_imag() == (-1, 0)\n\n    assert polar_lift(1 + I).as_real_imag() == (1, 1)\n\n    assert polar_lift(x).evalf() == x\n"], "sample_95": ["def test_xfail_and_skip_on_same_test(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail\n        @pytest.mark.skip\n            pass\n        @pytest.mark.skip\n        @pytest.mark.xfail\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-rsxX\")\n    result.stdout.fnmatch_lines_random(\n        [\n            \"*SKIP*unconditional skip*\",\n            \"*SKIP*unconditional skip*\",\n            \"*2 skipped*\",\n        ]\n    )\n", "def test_xfail_strict_with_parametrize(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        test_one=\"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"x\", [1, 2])\n        @pytest.mark.xfail(strict=True)\n            assert x == 1\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-rxX\")\n    result.stdout.fnmatch_lines([\"*XFAIL*test_foo[2]*\", \"*2 failed*\"])\n    assert result.ret == 2\n", "def test_custom_xfail_reason(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n            if item.node.name == \"test_foo\":\n                item.add_marker(pytest.mark.xfail(reason=\"my custom reason\"))\n        \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n            assert 0\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-rx\")\n    result.stdout.fnmatch_lines([\"*XFAIL*my custom reason*\"])\n", "def test_skipif_markeval_namespace_override(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n            return {\"color\": \"blue\"}\n        \"\"\"\n    )\n    pytester.makepyfile(\n        test_foo=\"\"\"\n        import pytest\n\n        @pytest.mark.skipif(\"color == 'red'\")\n            assert False\n\n        @pytest.mark.skipif(\"color == 'blue'\")\n            assert False\n\n            return {\"color\": \"green\"}\n\n        class TestClass:\n            pytestmark = pytest.mark.skipif(\"color == 'blue'\")\n\n                assert False\n        \"\"\"\n    )\n    reprec = pytester.inline_run(\"-rs\")\n    reprec.assertoutcome(skipped=3)\n    reprec.stdout.fnmatch_lines(\n        [\n            \"SKIPPED [[]1[]] test_foo.py::TestClass::test_3: condition: color == 'blue'\",\n            \"SKIPPED [[]2[]] test_foo.py::test_2: condition: color == 'blue'\",\n            \"SKIPPED [[]3[]] test_foo.py::test_1: condition: color == 'blue'\",\n        ]\n    )\n", "def test_parametrize_scope_selection(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        test_foo=\"\"\"\n            import pytest\n            @pytest.fixture(scope=\"session\")\n                return 1\n            @pytest.fixture(scope=\"package\")\n                return 2\n            @pytest.fixture(scope=\"module\")\n                return 3\n            @pytest.fixture(scope=\"class\")\n                return 4\n            @pytest.fixture(scope=\"function\")\n                return 5\n\n            @pytest.mark.parametrize(\"arg\", [\"session\", \"package\", \"module\", \"class\", \"function\"])\n                fixture = request.getfixturevalue(arg + \"_scope_fixture\")\n                assert fixture == {\"session\": 1, \"package\": 2, \"module\": 3, \"class\": 4, \"function\": 5}[arg]\n        \"\"\"\n    )\n    result = pytester.runpytest(test_foo)\n    result.assert_outcomes(passed=5)\n"], "sample_44": ["def test_modelchoicefield_widgets(self):\n    # Test that ModelChoiceField works with various widgets\n    for widget in [\n        forms.Select,\n        forms.RadioSelect,\n        forms.CheckboxSelectMultiple,\n        forms.SelectMultiple,\n    ]:\n        field = forms.ModelChoiceField(Category.objects.all(), widget=widget)\n        if hasattr(widget, 'allow_multiple_selected'):\n            self.assertEqual(field.widget.allow_multiple_selected, widget.allow_multiple_selected)\n", "def test_modelchoicefield_to_field_name_with_non_pk_unique_field(self):\n    class AuthorForm(forms.Form):\n        author = forms.ModelChoiceField(\n            Author.objects.all(),\n            to_field_name='name',\n        )\n\n    a1 = Author.objects.create(name='Author1', bio='Bio1')\n    a2 = Author.objects.create(name='Author2', bio='Bio2')\n\n    form = AuthorForm(data={'author': 'Author1'})\n    self.assertEqual(form.is_valid(), True)\n    self.assertEqual(form.cleaned_data['author'], a1)\n\n    form = AuthorForm(data={'author': 'Author3'})\n    self.assertEqual(form.is_valid(), False)\n", "def test_modelchoicefield_formfield_callback(self):\n    # Test a custom formfield_callback on ModelChoiceField\n        return forms.ModelChoiceField(\n            queryset=field.remote_field.model._default_manager.get_queryset(),\n            **kwargs\n        )\n\n    class TestForm(forms.ModelForm):\n        class Meta:\n            model = Book\n            fields = ('author',)\n            formfield_callback = custom_formfield_callback\n\n    book = Book.objects.create(author=Writer.objects.create(name='Test writer'))\n    form = TestForm(instance=book)\n    self.assertIsInstance(form.fields['author'], forms.ModelChoiceField)\n\n    # Test a custom formfield_callback on ModelMultipleChoiceField\n    class TestForm(forms.ModelForm):\n        class Meta:\n            model = Article\n            fields = ('categories',)\n            formfield_callback = custom_formfield_callback\n\n    article = Article.objects.create(\n        pub_date=datetime.date(1988, 1, 4),\n        writer=Writer.objects.create(name='Test writer'),\n    )\n    article.categories.set([self.c1.pk])\n    form = TestForm(instance=article)\n    self.assertIsInstance(form.fields['categories'], forms.ModelMultipleChoiceField)\n", "def test_model_form_save(self):\n    class AuthorForm(forms.ModelForm):\n        class Meta:\n            model = Author\n            fields = ('name',)\n\n    author = Writer.objects.create(name='Test writer')\n    form = AuthorForm(data={'name': 'New name'}, instance=author)\n    self.assertTrue(form.is_valid())\n    self.assertEqual(Author.objects.count(), 1)\n    author = form.save()\n    self.assertEqual(author.name, 'New name')\n\n    class ArticleForm(forms.ModelForm):\n        categories = forms.ModelMultipleChoiceField(Category.objects.all())\n\n        class Meta:\n            model = Article\n            fields = ('pub_date', 'writer', 'categories')\n\n    article = Article.objects.create(\n        pub_date=datetime.date(1988, 1, 4),\n        writer=Writer.objects.create(name='Test writer'),\n    )\n    form = ArticleForm(data={\n        'pub_date': '2020-01-01',\n        'writer': article.writer.pk,\n        'categories': [self.c1.pk, self.c2.pk],\n    }, instance=article)\n    self.assertTrue(form.is_valid())\n    self.assertEqual(article.categories.count(), 0)\n    article = form.save()\n    self.assertEqual(article.pub_date, datetime.date(2020, 1, 1))\n    self.assertEqual(article.writer.name, 'Test writer')\n    self.assertEqual([x.pk for x in article.categories.all()], [self.c1.pk, self.c2.pk])\n\n    form = ArticleForm(data={\n        'pub_date': '2020-01-01',\n        'writer': article.writer.pk,\n        'categories': [self.c1.pk, self.c3.pk],\n    }, instance=article)\n    self.assertTrue(form.is_valid())\n    article = form.save(commit=False)\n    self.assertEqual(article.pub_date, datetime.date(2020, 1, 1))\n    self.assertEqual(article.writer.name, 'Test writer')\n    self.assertEqual([x.pk for x in article.categories.all()], [self.c1.pk, self.c2.pk])\n    article.save()\n    article.refresh_from_db()\n    self.assertEqual([x.pk for x in article.categories.all()], [self.c1.pk, self.c3.pk])\n", "def test_modelchoicefield_with_invalid_queryset(self):\n    with self.assertRaisesMessage(TypeError, \"'NoneType' object is not iterable\"):\n        forms.ModelChoiceField(queryset=None)\n\n    with self.assertRaisesMessage(TypeError, \"'NoneType' object is not iterable\"):\n        forms.ModelMultipleChoiceField(queryset=None)\n\n    with self.assertRaisesMessage(ValueError, \"Invalid model field: 'fail'\"):\n        forms.ModelChoiceField(queryset=Category.objects.all(), to_field_name='fail')\n\n    class InvalidQueryset:\n            return 1\n\n    with self.assertRaisesMessage(TypeError, \"'InvalidQueryset' object is not iterable\"):\n        forms.ModelChoiceField(queryset=InvalidQueryset())\n\n    class InvalidQuerysetIterator:\n            yield 'test'\n\n            return 1\n\n    with self.assertRaisesMessage(AttributeError, \"object has no attribute 'get'\"):\n        forms.ModelChoiceField(queryset=InvalidQuerysetIterator())\n"], "sample_76": ["def test_low_unique_x(self, df):\n\n    groupby = GroupBy([\"group\"])\n    df[\"x\"] = np.repeat([1, 2, 3], 33)\n    res = PolyFit(order=2, gridsize=100)(df, groupby, \"x\", {})\n\n    assert res.columns.to_list() == [\"x\", \"y\", \"group\"]\n\n    ngroups = df[\"group\"].nunique()\n    assert_array_equal(res.index, np.arange(ngroups * 3))\n\n    for _, part in res.groupby(\"group\"):\n        assert_array_equal(part[\"x\"], [1, 2, 3])\n        assert_array_equal(part[\"y\"], part[\"y\"])\n", "def test_unique_x(self, df):\n\n    df.loc[:, \"x\"] = 0  # Make all x values unique\n    groupby = GroupBy([\"group\"])\n    res = PolyFit(order=2, gridsize=100)(df, groupby, \"x\", {})\n\n    assert res.columns.to_list() == [\"x\", \"y\", \"group\"]\n    assert res.empty\n", "def test_insufficient_unique_x(self, df):\n\n    df[\"x\"] = np.repeat(np.arange(3), 33)  # Just 3 unique values\n    groupby = GroupBy([\"group\"])\n    res = PolyFit(order=3, gridsize=100)(df, groupby, \"x\", {})\n\n    assert res.empty\n", "    def test_unique_x(self, df):\n        \"\"\"\n        Test the case when there are not enough unique x values for the fit.\n        \"\"\"\n\n        df[\"x\"] = [1, 1, 1, 2, 2, 2]\n        groupby = GroupBy([\"group\"])\n        res = PolyFit(order=3)(df, groupby, \"x\", {})\n\n        assert res.columns.to_list() == [\"x\", \"y\", \"group\"]\n\n        for _, part in res.groupby(\"group\"):\n            assert part[\"x\"].empty\n            assert part[\"y\"].empty\n", "def test_polyfit_order_zero(df):\n    \"\"\"Test that the order zero case works properly.\"\"\"\n\n    groupby = GroupBy([\"group\"])\n    polyfit = PolyFit(order=0)\n    res = polyfit(df, groupby, \"x\", {})\n    assert res.columns.to_list() == [\"x\", \"y\", \"group\"]\n\n    ngroups = df[\"group\"].nunique()\n    assert_array_equal(res.index, np.arange(ngroups))\n\n    for _, part in res.groupby(\"group\"):\n        mean_y = df[df[\"group\"] == part[\"group\"].iloc[0]][\"y\"].mean()\n        assert_array_equal(part[\"x\"], part[\"x\"].unique())\n        assert_array_equal(part[\"y\"], [mean_y] * len(part))\n"], "sample_24": ["def test_iter(self):\n    error_dict = {'field1': ['error1', 'error2'], 'field2': ['error3']}\n    error = ValidationError(error_dict)\n    self.assertEqual(\n        list(error),\n        [('field1', ['error1', 'error2']), ('field2', ['error3'])],\n    )\n    error = ValidationError(['error1', 'error2'])\n    self.assertEqual(list(error), ['error1', 'error2'])\n    error = ValidationError('error message')\n    self.assertEqual(list(error), ['error message'])\n", "def test_update_error_dict(self):\n    error1 = ValidationError({'field1': 'message'})\n    error2 = ValidationError({'field2': 'other'})\n    error_dict = {}\n    error1.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['message']})\n    error2.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['message'], 'field2': ['other']})\n    error3 = ValidationError('message')\n    error3.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['message'], 'field2': ['other'], '__all__': ['message']})\n", "def test_iter(self):\n    exception = ValidationError('error')\n    self.assertEqual(list(exception), ['error'])\n\n    error_dict = {'field1': ['error1', 'error2'], 'field2': 'error3'}\n    exception = ValidationError(error_dict)\n    self.assertEqual(list(exception), [('field1', ['error1', 'error2']), ('field2', ['error3'])])\n\n    error_list = [ValidationError({'field1': 'error1', 'field2': 'error2'}), 'error3']\n    exception = ValidationError(error_list)\n    self.assertEqual(list(exception), [('field1', ['error1']), ('field2', ['error2']), ('__all__', ['error3'])])\n", "def test_update_error_dict(self):\n    error_dict = {\n        'field1': ['error1'],\n        'field2': ['error2'],\n    }\n    exception = ValidationError(error_dict)\n    updated_error_dict = {}\n    exception.update_error_dict(updated_error_dict)\n    self.assertEqual(updated_error_dict, error_dict)\n\n    updated_error_dict = {\n        'field1': ['error3'],\n    }\n    exception.update_error_dict(updated_error_dict)\n    self.assertEqual(updated_error_dict, {\n        'field1': ['error3', 'error1'],\n        'field2': ['error2'],\n    })\n\n    exception = ValidationError('error')\n    updated_error_dict = {}\n    exception.update_error_dict(updated_error_dict)\n    self.assertEqual(updated_error_dict, {\n        '__all__': ['error'],\n    })\n", "def test_update_error_dict(self):\n    error_dict = {\n        'field1': ValidationError(['error1', 'error2']),\n        'field2': ValidationError('error3'),\n    }\n    error = ValidationError(error_dict)\n    target_dict = {}\n    error.update_error_dict(target_dict)\n    expected_dict = {\n        'field1': ['error1', 'error2'],\n        'field2': ['error3'],\n    }\n    self.assertEqual(target_dict, expected_dict)\n\n    error = ValidationError('error')\n    target_dict = {}\n    error.update_error_dict(target_dict)\n    expected_dict = {'__all__': ['error']}\n    self.assertEqual(target_dict, expected_dict)\n\n    error_list = [\n        ValidationError('error1'),\n        ValidationError('error2'),\n        ValidationError({\n            'field1': 'error3',\n            'field2': 'error4',\n        }),\n    ]\n    error = ValidationError(error_list)\n    target_dict = {}\n    error.update_error_dict(target_dict)\n    expected_dict = {\n        '__all__': ['error1', 'error2'],\n        'field1': ['error3'],\n        'field2': ['error4'],\n    }\n    self.assertEqual(target_dict, expected_dict)\n\n    error = ValidationError({\n        'field1': ValidationError('error1'),\n        'field2': ValidationError('error2'),\n    })\n    target_dict = {\n        'field3': ['error3'],\n    }\n    error.update_error_dict(target_dict)\n    expected_dict = {\n        'field1': ['error1'],\n        'field2': ['error2'],\n        'field3': ['error3'],\n    }\n    self.assertEqual(target_dict, expected_dict)\n"], "sample_36": ["def test_combine_not_q_object_with_or(self):\n    obj = object()\n    q = Q(x=1)\n    with self.assertRaisesMessage(TypeError, str(obj)):\n        q | ~obj\n    with self.assertRaisesMessage(TypeError, str(obj)):\n        ~obj | q\n", "    def test_combine_or(self):\n        q1 = Q(price__gt=F('discounted_price'))\n        q2 = ~Q(price=F('discounted_price'))\n        q = q1 | q2\n        path, args, kwargs = q.deconstruct()\n        self.assertEqual(args, (\n            ('price__gt', F('discounted_price')),\n            ('price', F('discounted_price')),\n            ('_negated', True),\n        ))\n        self.assertEqual(kwargs, {'_connector': 'OR'})\n", "def test_filtered_relation(self):\n    fr = FilteredRelation('relation_name', condition=Q(x=1))\n    self.assertEqual(fr.relation_name, 'relation_name')\n    self.assertIsNone(fr.alias)\n    self.assertEqual(fr.condition, Q(x=1))\n    self.assertEqual(fr.path, [])\n\n    fr.alias = 'alias'\n    fr.path = ['path1', 'path2']\n    cloned_fr = fr.clone()\n    self.assertEqual(cloned_fr.relation_name, 'relation_name')\n    self.assertEqual(cloned_fr.alias, 'alias')\n    self.assertEqual(cloned_fr.condition, Q(x=1))\n    self.assertEqual(cloned_fr.path, ['path1', 'path2'])\n\n    self.assertEqual(fr, cloned_fr)\n\n    with self.assertRaises(ValueError):\n        FilteredRelation('')\n\n    with self.assertRaises(ValueError):\n        FilteredRelation('relation_name', condition='condition')\n", "def test_resolve_expression(self):\n    q = Q(x=1)\n    with self.assertRaisesMessage(NotImplementedError, 'QuerySet.annotate() only accepts expression-like arguments'):\n        q.resolve_expression()\n\n    q = Q(x=1)\n    query = object()\n    with self.assertRaisesMessage(NotImplementedError, 'QuerySet.annotate() only accepts expression-like arguments'):\n        q.resolve_expression(query=query)\n\n    q = Q(x=1)\n    query = object()\n    allow_joins = False\n    reuse = set()\n    summarize = True\n    for_save = True\n    with self.assertRaisesMessage(NotImplementedError, 'QuerySet.annotate() only accepts expression-like arguments'):\n        q.resolve_expression(query=query, allow_joins=allow_joins, reuse=reuse, summarize=summarize, for_save=for_save)\n", "def test_invert(self):\n    q = Q(price__gt=F('discounted_price'))\n    path, args, kwargs = (~q).deconstruct()\n    self.assertEqual(args, ())\n    self.assertEqual(kwargs, {\n        'price__gt': F('discounted_price'),\n        '_negated': True,\n    })\n"], "sample_67": ["def test_serialize_settings_reference(self):\n    class TestSettings:\n        TEST_SETTING = \"test_value\"\n\n    with self.settings(TEST_SETTING=\"test_value\"):\n        self.assertSerializedResultEqual(\n            SettingsReference(\"TEST_SETTING\", \"TEST_SETTING\"),\n            (\"settings.TEST_SETTING\", {\"from django.conf import settings\"}),\n        )\n        self.assertSerializedResultEqual(\n            SettingsReference(TestSettings.TEST_SETTING, \"TEST_SETTING\"),\n            (\"settings.TEST_SETTING\", {\"from django.conf import settings\"}),\n        )\n", "def test_serialize_lazy_setting(self):\n    lazy_setting = SimpleLazyObject(lambda: settings.SECRET_KEY)\n    self.assertSerializedEqual(lazy_setting)\n    string, imports = MigrationWriter.serialize(lazy_setting)\n    self.assertEqual(string, \"settings.SECRET_KEY\")\n    self.assertIn(\"from django.conf import settings\", imports)\n", "def test_serialize_function_type_with_module_name_none(self):\n        pass\n\n    func.__module__ = None\n    func.__qualname__ = \"test_func\"\n    with self.assertRaisesMessage(\n        ValueError, \"Cannot serialize function %r: No module\" % func\n    ):\n        self.assertSerializedEqual(func)\n", "def test_serialize_operation(self):\n    \"\"\"\n    Test serialization of Operation instances.\n    \"\"\"\n    operation = migrations.CreateModel(\n        \"MyModel\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=255)),\n        ],\n    )\n    string, imports = MigrationWriter.serialize(operation)\n    self.assertEqual(\n        string,\n        \"migrations.CreateModel(\"\n        \"    name='MyModel', \"\n        \"    fields=[\"\n        \"        ('id', models.AutoField(auto_created=True, primary_key=True, \"\n        \"serialize=False, verbose_name='ID')), \"\n        \"        ('name', models.CharField(max_length=255)), \"\n        \"    ], \"\n        \"    options={\"\n        \"    }, \"\n        \"    bases=(models.Model,), \"\n        \")\",\n    )\n    self.assertEqual(imports, {\"from django.db import models\", \"import django.db.migrations\"})\n\n    operation = migrations.DeleteModel(\"MyModel\")\n    string, imports = MigrationWriter.serialize(operation)\n    self.assertEqual(\n        string,\n        \"migrations.DeleteModel(name='MyModel')\",\n    )\n    self.assertEqual(imports, {\"import django.db.migrations\"})\n\n    operation = migrations.AddField(\n        \"MyModel\", \"new_field\", models.CharField(max_length=255)\n    )\n    string, imports = MigrationWriter.serialize(operation)\n    self.assertEqual(\n        string,\n        \"migrations.AddField(\"\n        \"    model_name='MyModel', \"\n        \"    name='new_field', \"\n        \"    field=models.CharField(max_length=255), \"\n        \")\",\n    )\n    self.assertEqual(imports, {\"from django.db import models\", \"import django.db.migrations\"})\n\n    operation = migrations.AlterField(\n        \"MyModel\", \"name\", models.CharField(max_length=255)\n    )\n    string, imports = MigrationWriter.serialize(operation)\n    self.assertEqual(\n        string,\n        \"migrations.AlterField(\"\n        \"    model_name='MyModel', \"\n        \"    name='name', \"\n        \"    field=models.CharField(max_length=255), \"\n        \")\",\n    )\n    self.assertEqual(imports, {\"from django.db import models\", \"import django.db.migrations\"})\n\n    operation = migrations.RemoveField(\"MyModel\", \"name\")\n    string, imports = MigrationWriter.serialize(operation)\n    self.assertEqual(\n        string,\n        \"migrations.RemoveField(\"\n        \"    model_name='MyModel', \"\n        \"    name='name', \"\n        \")\",\n", "def test_serialize_lazy_objects_with_nested_lazy_objects(self):\n    \"\"\"\n    Serialize lazy objects with nested lazy objects.\n    \"\"\"\n    lazy_value = SimpleLazyObject(lambda: SimpleLazyObject(lambda: \"value\"))\n    expected_string = \"'value'\"\n    expected_imports = set()\n    string, imports = MigrationWriter.serialize(lazy_value)\n    self.assertEqual(string, expected_string)\n    self.assertEqual(imports, expected_imports)\n"], "sample_5": ["def test_set_on_delete_callable(self):\n        return R.objects.get_or_create(name='default_r')[0]\n\n    a = A.objects.create(setvalue_callable=get_default_r())\n    a.setvalue_callable.delete()\n    a = A.objects.get(pk=a.pk)\n    self.assertEqual(a.setvalue_callable_id, get_default_r().pk)\n\n        collector.add_field_update(field, R.objects.get_or_create(name='callable')[0], sub_objs)\n\n    a = A.objects.create(set_on_delete_callable=R.objects.create())\n    a.set_on_delete_callable.delete()\n    a = A.objects.get(pk=a.pk)\n    self.assertEqual(a.set_on_delete_callable_id, R.objects.get(name='callable').pk)\n", "    def test_add_field_update(self):\n        collector = Collector(using='default')\n        field = A._meta.get_field('auto')\n        obj = A.objects.create(name='test')\n        collector.add_field_update(field, None, [obj])\n        self.assertIn((field, None), collector.field_updates[A])\n        self.assertIn(obj, collector.field_updates[A][(field, None)])\n", "def test_collector_add_field_update(self):\n    collector = Collector(using='default')\n    field = models.ForeignKey(A, models.CASCADE, related_name='test_related')\n    objs = [R.objects.create(), R.objects.create()]\n    collector.add_field_update(field, None, objs)\n    self.assertEqual(len(collector.field_updates[R]), 1)\n    self.assertEqual(collector.field_updates[R][(field, None)], set(objs))\n", "    def test_delete_collector_add_field_update(self):\n        r = R.objects.create()\n        a = A.objects.create(protect=r)\n        collector = Collector(using='default')\n        field = A._meta.get_field('protect')\n        collector.add_field_update(field, None, [a])\n        self.assertEqual(collector.field_updates[A][ (field, None) ], {a})\n", "def test_cascade_on_delete_with_select_related(self):\n    a = create_a('cascade')\n    r = a.cascade\n    # This will load related objects for 'r' which will be used later\n    # in the collector during deletion.\n    r.select_related('m_set').get()\n    # Now try to delete 'a' which should cascade to 'r'.\n    a.delete()\n    self.assertFalse(A.objects.filter(name='cascade').exists())\n    self.assertFalse(R.objects.filter(pk=r.pk).exists())\n"], "sample_98": ["def test_check_X_y_unsupported_y_dtype():\n    X = np.array([1, 2, 3])\n    y = np.array([1, 2, 3], dtype=object)\n    assert_warns_message(DataConversionWarning,\n                         \"Data with input dtype object were all converted to \"\n                         \"float64.\",\n                         check_X_y, X, y, estimator='SomeEstimator')\n", "def test_check_X_y_force_all_finite_valid():\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([1, 2])\n    X[0, 0] = np.nan\n    y[1] = np.nan\n    X_checked, y_checked = check_X_y(X, y, force_all_finite='allow-nan',\n                                      accept_sparse=False, dtype=None)\n    assert_allclose_dense_sparse(X_checked, X)\n    assert_allclose_dense_sparse(y_checked, y)\n\n", "def test_check_X_y_dtype_warning(dtype, target_dtype):\n    X = np.ones((10, 10), dtype=dtype)\n    y = np.ones(10, dtype=dtype)\n    assert_warns_message(DataConversionWarning,\n                         \"Data with input dtype {} were all converted to {}.\"\n                         .format(dtype, target_dtype),\n                         check_X_y, X, y, dtype=target_dtype, warn_on_dtype=True)\n", "def test_check_X_y_numeric():\n    X = np.array([1, 2, 3])\n    y = np.array([1, 2, 'a'])\n\n    # Test y_numeric=True\n    assert_raises_regex(\n        ValueError, \"A column-vector y was passed when a 1d array was expected\",\n        check_X_y, X, y, y_numeric=True)\n    assert_raises_regex(\n        ValueError, \"A column-vector y was passed when a 1d array was expected\",\n        check_X_y, X, y, y_numeric=True, multi_output=False)\n\n    # Test y_numeric=False\n    X_checked, y_checked = check_X_y(X, y, y_numeric=False)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, np.array([1, 2, 'a']))\n\n    # Test y_numeric=True with correct y\n    y = np.array([1, 2, 3])\n    X_checked, y_checked = check_X_y(X, y, y_numeric=True)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, np.array([1, 2, 3], dtype=np.float64))\n", "def test_check_X_y_data_conversion_warnings():\n    X = np.arange(4).reshape(2, 2)\n    y = np.arange(2)\n\n    # No warning for numeric X and y\n    X_checked, y_checked = assert_no_warnings(check_X_y, X, y)\n\n    # Warning for object dtype\n    X_obj = np.array([[1, 2], [3, 4]], dtype=object)\n    y_obj = np.array([1, 2], dtype=object)\n    assert_warns(DataConversionWarning, check_X_y, X_obj, y_obj)\n\n    # Warning for mixed dtypes\n    X_mixed = np.array([[1, 2], [3, '4']], dtype=object)\n    y_mixed = np.array([1, 2], dtype=object)\n    assert_warns(DataConversionWarning, check_X_y, X_mixed, y_mixed)\n\n    # No warning for numeric X and y with estimator name\n    X_checked, y_checked = assert_no_warnings(check_X_y, X, y, estimator='MyEstimator')\n\n    # Warning for object dtype with estimator name\n    assert_warns_message(DataConversionWarning,\n                         'SomeEstimator',\n                         check_X_y, X_obj, y_obj, estimator='SomeEstimator')\n\n    # Warning for mixed dtypes with estimator name\n    assert_warns_message(DataConversionWarning,\n                         'MyEstimator',\n                         check_X_y, X_mixed, y_mixed, estimator='MyEstimator')\n"], "sample_120": ["def test_as_explicit():\n    A = MatrixSymbol('A', 3, 3)\n    assert A.as_explicit().shape == A.shape\n    assert isinstance(A.as_explicit(), ImmutableDenseMatrix)\n\n    B = MatrixSymbol('B', n, m)\n    raises(ShapeError, lambda: B.as_explicit())\n", "def test_MatrixSymbol_as_explicit():\n    A = MatrixSymbol('A', 2, 3)\n    explicit_A = A.as_explicit()\n    assert explicit_A.shape == A.shape\n    for i in range(A.rows):\n        for j in range(A.cols):\n            assert explicit_A[i, j] == A[i, j]\n\n    A = MatrixSymbol('A', n, m)\n    with raises(ShapeError):\n        A.as_explicit()\n", "def test_adjoint():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    C = MatrixSymbol('C', n, n)\n    assert A.adjoint().shape == (m, n)\n    assert (A.adjoint()*A).is_square\n    assert (A*B).adjoint() == B.adjoint()*A.adjoint()\n    assert A.adjoint().adjoint() == A\n    assert C.adjoint().is_square\n    assert Identity(n).adjoint() == Identity(n)\n    assert ZeroMatrix(n, m).adjoint() == ZeroMatrix(m, n)\n", "def test_equality():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 3)\n    Z = ZeroMatrix(2, 2)\n    I = Identity(2)\n\n    assert (A == A) is True\n    assert (A == B) is False\n    assert (A == C) is False\n    assert (A == Z) is False\n    assert (A == I) is False\n    assert (Z == Z) is True\n    assert (I == I) is True\n    assert (Z == I) is False\n    assert (A == 0) is False\n    raises(TypeError, lambda: A != 0)\n", "def test_MatrixExpr_as_explicit_and_mutable():\n    A = MatrixSymbol('A', 3, 3)\n    B = MatrixSymbol('B', 3, 3)\n\n    # Test that explicit and mutable conversions work for MatrixExpr\n    explicit_A = A.as_explicit()\n    explicit_B = B.as_explicit()\n    assert isinstance(explicit_A, ImmutableDenseMatrix)\n    assert isinstance(explicit_B, ImmutableDenseMatrix)\n\n    mutable_A = A.as_mutable()\n    mutable_B = B.as_mutable()\n    assert isinstance(mutable_A, Matrix)\n    assert isinstance(mutable_B, Matrix)\n\n    # Test that explicit and mutable conversions work for complex MatrixExpr\n    AB = A*B\n    explicit_AB = AB.as_explicit()\n    assert isinstance(explicit_AB, ImmutableDenseMatrix)\n\n    mutable_AB = AB.as_mutable()\n    assert isinstance(mutable_AB, Matrix)\n\n    A_add_B = A + B\n    explicit_A_add_B = A_add_B.as_explicit()\n    assert isinstance(explicit_A_add_B, ImmutableDenseMatrix)\n\n    mutable_A_add_B = A_add_B.as_mutable()\n    assert isinstance(mutable_A_add_B, Matrix)\n"], "sample_104": ["def test_custom_n_max_elements_to_show():\n    # Test the n_max_elements_to_show parameter in _EstimatorPrettyPrinter\n    n_max_elements_to_show = 5\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=n_max_elements_to_show\n    )\n\n    # No ellipsis\n    vocabulary = {i: i for i in range(n_max_elements_to_show)}\n    vectorizer = CountVectorizer(vocabulary=vocabulary)\n\n    expected = r\"\"\"", "def test_n_max_elements_to_show_with_tuple():\n    # Test that n_max_elements_to_show is respected for tuples\n    n_max_elements_to_show = 30\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=n_max_elements_to_show\n    )\n\n    # No ellipsis\n    tuple_ = tuple(range(n_max_elements_to_show))\n    expected = f\"\"\"", "def test_n_max_elements_to_show_with_tuples():\n    n_max_elements_to_show = 30\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=n_max_elements_to_show\n    )\n\n    # No ellipsis\n    pipeline = Pipeline([\n        ('reduce_dim', PCA()),\n        ('classify', SVC())\n    ] * n_max_elements_to_show)\n    expected = \"\"\"", "def test_non_ascii_repr():\n    # Test that the repr of an estimator with non-ASCII characters doesn't crash\n    # (e.g. when the estimator has a parameter with a non-ASCII name).\n    from sklearn.base import BaseEstimator\n    class Estimator(BaseEstimator):\n            self.caf\u00e9 = caf\u00e9\n    estimator = Estimator('caf\u00e9')\n    estimator.__repr__()\n", "def test_n_max_elements_to_show_nested():\n    # Test that n_max_elements_to_show is also applied to nested estimators\n    n_max_elements_to_show = 2\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=n_max_elements_to_show\n    )\n\n    # Create a pipeline with a large number of features\n    vocabulary = {i: i for i in range(n_max_elements_to_show + 1)}\n    vectorizer = CountVectorizer(vocabulary=vocabulary)\n    pipeline = make_pipeline(vectorizer, LogisticRegression())\n\n    # Check that the pipeline's repr has ellipsis\n    expected = r\"\"\""], "sample_87": ["def test_collect_in_virtualenv_subdir(testdir):\n    bindir = \"Scripts\" if sys.platform.startswith(\"win\") else \"bin\"\n    testdir.tmpdir.ensure(\"virtual\", bindir, \"activate\")\n    testdir.tmpdir.mkdir(\"virtual\", \"subdir\")\n    testfile = testdir.tmpdir.ensure(\"virtual\", \"subdir\", \"test_invenv.py\")\n    testfile.write(\"def test_hello(): pass\")\n\n    # by default, ignore tests inside a virtualenv\n    result = testdir.runpytest()\n    result.stdout.no_fnmatch_line(\"*test_invenv*\")\n    # allow test collection if user insists\n    result = testdir.runpytest(\"--collect-in-virtualenv\")\n    assert \"test_invenv\" in result.stdout.str()\n    # allow test collection if user directly passes in the directory\n    result = testdir.runpytest(\"virtual/subdir\")\n    assert \"test_invenv\" in result.stdout.str()\n", "def test_custom_norecursedirs_with_virtualenvs(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        norecursedirs = venv\n    \"\"\"\n    )\n    testdir.tmpdir.ensure(\"venv\", \"bin\", \"activate\")\n    testfile = testdir.tmpdir.ensure(\"venv\", \"test_invenv.py\")\n    testfile.write(\"def test_hello(): pass\")\n\n    # by default, ignore tests inside a virtualenv\n    result = testdir.runpytest()\n    result.stdout.no_fnmatch_line(\"*test_invenv*\")\n\n    # allow test collection if user insists\n    result = testdir.runpytest(\"--collect-in-virtualenv\")\n    assert \"test_invenv\" in result.stdout.str()\n", "def test_maxfail_zero_does_not_exit(testdir):\n    \"\"\"\n    Verify that setting maxfail=0 does not cause pytest to exit during collection.\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n            assert False\n            assert False\n            assert True\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--maxfail=0\")\n    result.stdout.fnmatch_lines(\n        [\"collected 3 items\", \"*2 failed, 1 passed in*\"]\n    )\n    assert result.ret == 1\n", "def test_ignore_collect_conftest(testdir):\n    testdir.makeconftest(\n        \"\"\"\n            return path.basename.startswith(\"x\") or path.basename == \"test_one.py\"\n    \"\"\"\n    )\n    testdir.makeconftest(\n        \"\"\"\n            return path.basename == \"test_two.py\"\n    \"\"\",\n        dir=\"subdir\",\n    )\n    testdir.makepyfile(\"def test_hello(): pass\")\n    testdir.makepyfile(\"test_one\", \"def test_hello(): pass\")\n    testdir.makepyfile(\"test_two\", \"def test_hello(): pass\")\n    result = testdir.runpytest(\"--collect-only\")\n    result.stdout.fnmatch_lines([\"collected 1 item\", \"*test_hello.py*\"])\n    result = testdir.runpytest(\"subdir\", \"--collect-only\")\n    result.stdout.fnmatch_lines([\"collected 0 items\"])\n", "    def test_deselect_prefix_single_item(self, testdir):\n        p = testdir.makepyfile(\"def test_foo(): pass\")\n        testdir.makeconftest(\n            \"\"\"\n            import pytest\n                assert len(items) == 1\n                assert items[0].nodeid.startswith(\"test_foo\")\n                items.clear()\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\"collected 0 items\"])\n"], "sample_78": ["def test_flaskgroup_shell_command(runner):\n        return Flask(\"flaskgroup\")\n\n    @click.group(cls=FlaskGroup, create_app=create_app)\n        pass\n\n    @cli.command()\n        click.echo(current_app.name)\n\n    result = runner.invoke(cli, [\"shell\"])\n    assert result.exit_code == 0\n    assert \"flaskgroup\" in result.output\n    assert \"App: flaskgroup\" in result.output\n    assert \"Instance: \" in result.output\n", "def test_flaskgroup_load_dotenv(runner, monkeypatch):\n        return Flask(\"flaskgroup\")\n\n    @click.group(cls=FlaskGroup, create_app=create_app, load_dotenv=True)\n        pass\n\n    @cli.command()\n        assert os.environ[\"FOO\"] == \"1\"\n        assert os.environ[\"BAR\"] == \"2\"\n\n    with monkeypatch.context() as m:\n        m.setenv(\"FLASK_SKIP_DOTENV\", \"\")\n        m.chdir(test_path)\n        result = runner.invoke(cli, [\"test\"])\n        assert result.exit_code == 0\n", "def test_load_dotenv_pathsep(monkeypatch, runner):\n    for item in (\"FOO\", \"BAR\", \"EGGS\"):\n        monkeypatch._setitem.append((os.environ, item, notset))\n\n    os.environ[\"FLASK_APP\"] = \"cliapp.app\"\n    load_dotenv(test_path / \".flaskenv\")\n\n        assert value == str(test_path / \".flaskenv\")\n\n    monkeypatch.setattr(runner, \"handle_env_file_callback\", mock_env_file_callback)\n\n    runner.invoke(FlaskGroup())\n    assert Path.cwd() == cwd\n    assert \"FOO\" in os.environ\n", "def test_flaskgroup_plugin_commands(runner):\n    group = FlaskGroup()\n\n    @click.group(\"custom\")\n        pass\n\n    @custom.command()\n        click.echo(\"Custom command\")\n\n    entry_point = types.SimpleNamespace(\n        load=lambda: custom,\n        name=\"custom\",\n    )\n\n    with monkeypatch.context() as m:\n        m.setattr(\"sys.modules\", {\"importlib\": types.ModuleType(\"importlib\")})\n        if sys.version_info >= (3, 10):\n            m.setattr(\"importlib.metadata\", types.ModuleType(\"metadata\"))\n            m.setattr(\n                \"importlib.metadata.entry_points\",\n                lambda: [entry_point],\n            )\n        else:\n            import importlib_metadata as metadata\n            m.setattr(\"importlib_metadata\", types.ModuleType(\"metadata\"))\n            m.setattr(\n                \"importlib_metadata.entry_points\",\n                lambda: [entry_point],\n            )\n\n        result = runner.invoke(group, [\"custom\", \"command\"])\n        assert result.exit_code == 0\n        assert result.output == \"Custom command\\n\"\n", "def test_run_command_with_app_import_path(runner):\n    app = Flask(__name__)\n    obj = ScriptInfo(app_import_path=\":testapp\")\n\n    result = runner.invoke(run_command, [\"--host\", \"0.0.0.0\", \"--port\", \"5000\"], obj=obj)\n    assert result.exit_code == 0\n    assert \" * Serving Flask app ':testapp'\" in result.output\n\n"], "sample_92": ["def test_evaluate_condition_invalid_type(testdir):\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.skipif(object())\n            pass\n    \"\"\"\n    )\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_condition(item, item.iter_markers(name=\"skipif\").__next__(), object())\n    assert excinfo.value.msg is not None\n    assert \"Error evaluating 'skipif' condition as a boolean\" in excinfo.value.msg\n", "def test_xfail_imperative_with_custom_reason(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n            pytest.xfail(\"Hello, world!\")\n    \"\"\"\n    )\n    result = testdir.runpytest(p)\n    result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n    result = testdir.runpytest(p, \"-rx\")\n    result.stdout.fnmatch_lines([\"*XFAIL*test_this*\", \"*reason: Hello, world!*\"])\n", "def test_xfail_empty_reason(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(reason='')\n            assert 1\n        @pytest.mark.xfail(reason='')\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rxX\")\n    result.stdout.fnmatch_lines([\"*XPASS test_foo.py::test_foo ''\", \"*XFAIL test_bar.py::test_bar ''\"])\n    assert result.ret == 0\n", "def test_xfail_eval_condition_with_multi_line_string(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.xfail(condition=\"\"\" + \"'hello' in 'hello world'\")\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rsx\")\n    result.stdout.fnmatch_lines([\"*XFAIL*test_func*\"])\n", "    def test_xfail_reason_unicode(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(reason='\u2202\u00fc')\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        result.stdout.fnmatch_lines(\n            [\n                \"*XPASS*test_func*\u2202\u00fc\",\n            ]\n        )\n        assert result.ret == 0\n"], "sample_107": ["def test_logistic_regression_cv_intercept_scaling(solver):\n    # Test that LogisticRegressionCV ignores intercept_scaling when fit_intercept\n    # is False\n    X, y = make_classification(n_samples=100, n_features=20, random_state=0)\n    Cs = np.logspace(-4, 4, 10)\n    lrcv = LogisticRegressionCV(Cs=Cs, solver=solver, fit_intercept=False,\n                                random_state=0, cv=2, multi_class='ovr',\n                                intercept_scaling=1000)\n    lrcv.fit(X, y)\n    assert_array_almost_equal(lrcv.intercept_, np.zeros_like(lrcv.intercept_))\n", "def test_logistic_regression_elasticnet_attributes():\n    # Test that the attributes of LogisticRegression with elasticnet\n    # penalty are correctly set\n    n_samples = 50\n    X, y = make_classification(n_samples=n_samples, n_features=20,\n                               random_state=0)\n\n    # Test for LogisticRegression\n    lr_enet = LogisticRegression(penalty='elasticnet', solver='saga',\n                                 random_state=0, l1_ratio=.5)\n    lr_enet.fit(X, y)\n\n    assert hasattr(lr_enet, 'coef_')\n    assert hasattr(lr_enet, 'intercept_')\n    assert hasattr(lr_enet, 'n_iter_')\n\n    # Test for LogisticRegressionCV\n    lrcv_enet = LogisticRegressionCV(penalty='elasticnet', solver='saga',\n                                      random_state=0, l1_ratios=[.5])\n    lrcv_enet.fit(X, y)\n\n    assert hasattr(lrcv_enet, 'coef_')\n    assert hasattr(lrcv_enet, 'intercept_')\n    assert hasattr(lrcv_enet, 'n_iter_')\n    assert hasattr(lrcv_enet, 'Cs_')\n    assert hasattr(lrcv_enet, 'l1_ratios_')\n    assert hasattr(lrcv_enet, 'coefs_paths_')\n    assert hasattr(lrcv_enet, 'scores_')\n", "def test_logistic_regression_path_n_features():\n    # Test logistic_regression_path when n_features is zero\n    X, y = make_classification(n_samples=100, n_features=0, n_informative=0,\n                               n_classes=2, random_state=0)\n    msg = \"X has 0 features, but LogisticRegression needs at least 1.\"\n    assert_raise_message(ValueError, msg,\n                         _logistic_regression_path, X, y, Cs=[1.],\n                         fit_intercept=False, solver='lbfgs',\n                         multi_class='ovr', random_state=0, tol=1e-4,\n                         verbose=0, penalty='l2', dual=False,\n                         max_iter=100)\n", "def test_logistic_regressionCV_elastic_net():\n    # Test that elastic net regularization in LogisticRegressionCV is\n    # equivalent to using GridSearchCV with LogisticRegression\n    n_samples, n_features = 100, 20\n    X, y = make_classification(n_samples=n_samples, n_features=n_features,\n                               n_informative=10, n_redundant=0, n_repeated=0,\n                               n_classes=2, random_state=0)\n    Cs = [1.]\n    l1_ratios = np.linspace(0, 1, 5)\n    cv = StratifiedKFold(5, random_state=0)\n    logrcv = LogisticRegressionCV(Cs=Cs, l1_ratios=l1_ratios, penalty='elasticnet',\n                                  solver='saga', cv=cv, random_state=0)\n    logrcv.fit(X, y)\n    param_grid = {'C': Cs, 'l1_ratio': l1_ratios}\n    logr = LogisticRegression(penalty='elasticnet', solver='saga',\n                              random_state=0)\n    gs = GridSearchCV(logr, param_grid, cv=cv)\n    gs.fit(X, y)\n    assert_array_equal(logrcv.coef_, gs.best_estimator_.coef_)\n    assert_array_equal(logrcv.intercept_, gs.best_estimator_.intercept_)\n    assert_equal(logrcv.C_[0], gs.best_params_['C'])\n    assert_equal(logrcv.l1_ratio_[0], gs.best_params_['l1_ratio'])\n", "def test_logistic_regression_elasticnet_model_selection():\n    # Test that the model selection in LogisticRegressionCV is done properly\n    # when the elasticnet solver is used.\n    X, y = make_classification(n_samples=100, n_features=20, random_state=0)\n    Cs = np.logspace(-4, 4, 10)\n    l1_ratios = np.linspace(0, 1, 5)\n    cv = 3\n\n    # Test that the shapes are correct\n    lr_cv = LogisticRegressionCV(penalty='elasticnet', solver='saga',\n                                 Cs=Cs, cv=cv, l1_ratios=l1_ratios)\n    lr_cv.fit(X, y)\n    assert lr_cv.C_.shape == (1,)\n    assert lr_cv.l1_ratio_.shape == (1,)\n\n    # Test the model selection when there is one best model\n    np.random.seed(0)\n    X, y = make_classification(n_samples=100, n_features=20, random_state=0)\n    Cs = np.logspace(-4, 4, 10)\n    l1_ratios = np.linspace(0, 1, 5)\n    cv = 3\n\n    # The best model is the one with C=1. and l1_ratio=0.5\n    lr_cv = LogisticRegressionCV(penalty='elasticnet', solver='saga',\n                                 Cs=Cs, cv=cv, l1_ratios=l1_ratios)\n    lr_cv.fit(X, y)\n    assert lr_cv.C_ == [1.]\n    assert lr_cv.l1_ratio_ == [0.5]\n\n    # Test the model selection when there are multiple best models\n    X, y = make_classification(n_samples=100, n_features=20, random_state=42)\n    Cs = [1., 1.]\n    l1_ratios = [0.5, 0.5]\n    cv = 3\n\n    lr_cv = LogisticRegressionCV(penalty='elasticnet', solver='saga',\n                                 Cs=Cs, cv=cv, l1_ratios=l1_ratios)\n    lr_cv.fit(X, y)\n    assert lr_cv.C_ == [1.]\n    assert lr_cv.l1_ratio_ == [0.5]\n"], "sample_45": ["    def test_sync_and_async_middleware(self):\n        @sync_and_async_middleware\n            return lambda request: HttpResponse()\n\n        self.assertTrue(middleware_factory.sync_capable)\n        self.assertTrue(middleware_factory.async_capable)\n", "    def test_decorator_from_middleware(self):\n        \"\"\"\n        Ensure decorator_from_middleware returns a decorator.\n        \"\"\"\n        decorator = decorator_from_middleware(XFrameOptionsMiddleware)\n        self.assertTrue(callable(decorator))\n", "    def test_middleware_decorator_with_args(self):\n                request.middleware_called = True\n                return get_response(request)\n            return middleware\n        my_decorator = decorator_from_middleware_with_args(my_middleware)\n        @my_decorator()\n            return HttpResponse()\n        request = HttpRequest()\n        response = my_view(request)\n        self.assertTrue(hasattr(request, 'middleware_called'))\n", "    def test_sync_and_async_middleware(self):\n        @sync_and_async_middleware\n            pass\n\n        self.assertTrue(middleware_factory.sync_capable)\n        self.assertTrue(middleware_factory.async_capable)\n\n", "    def test_sync_and_async_middleware(self):\n        \"\"\"\n        The sync_and_async_middleware decorator sets both sync_capable and\n        async_capable to True.\n        \"\"\"\n        @sync_and_async_middleware\n            return HttpResponse()\n\n        self.assertTrue(my_middleware.sync_capable)\n        self.assertTrue(my_middleware.async_capable)\n"], "sample_100": ["def test_ordinal_encoder_set_params():\n    X = np.array([[1, 2]]).T\n    oe = OrdinalEncoder()\n    # set params on not yet fitted object\n    oe.set_params(categories=[[0, 1, 2, 3]])\n    assert oe.get_params()['categories'] == [[0, 1, 2, 3]]\n    assert oe.fit_transform(X).shape == (2, 1)\n    # set params on already fitted object\n    oe.set_params(categories=[[0, 1, 2, 3, 4]])\n    assert oe.fit_transform(X).shape == (2, 1)\n", "def test_ordinal_encoder_get_feature_names():\n    enc = OrdinalEncoder()\n    X = [['Male', 1, 'girl', 2, 3],\n         ['Female', 41, 'girl', 1, 10],\n         ['Male', 51, 'boy', 12, 3],\n         ['Male', 91, 'girl', 21, 30]]\n\n    enc.fit(X)\n    feature_names = enc.get_feature_names()\n    assert isinstance(feature_names, np.ndarray)\n\n    assert_array_equal(feature_names, ['x0', 'x1', 'x2', 'x3', 'x4'])\n\n    feature_names2 = enc.get_feature_names(['one', 'two',\n                                            'three', 'four', 'five'])\n\n    assert_array_equal(feature_names2, ['one', 'two', 'three', 'four', 'five'])\n\n    with pytest.raises(ValueError, match=\"input_features should have length\"):\n        enc.get_feature_names(['one', 'two'])\n", "def test_ordinal_encoder_handle_unknown():\n    X = np.array([['a', 'b'], ['c', 'b'], ['a', 'a']], dtype=object).T\n    X2 = np.array([['a', 'd']], dtype=object).T\n\n    # Test that ordinal encoder raises error for unknown features\n    # present during transform.\n    oh = OrdinalEncoder(handle_unknown='error')\n    oh.fit(X)\n    with pytest.raises(ValueError, match=\"Found unknown categories\"):\n        oh.transform(X2)\n\n    # Test the ignore option, ignores unknown features (giving them a code)\n    oh = OrdinalEncoder(handle_unknown='ignore')\n    oh.fit(X)\n    assert_array_equal(oh.transform(X2), [[0], [np.nan]])\n\n    # Raise error if handle_unknown is neither ignore or error.\n    oh = OrdinalEncoder(handle_unknown='42')\n    assert_raises(ValueError, oh.fit, X)\n", "def test_one_hot_encoder_warning_handle_unknown():\n    enc = OneHotEncoder(handle_unknown='error')\n    X = [['a', 2], ['b', 2], ['a', 3]]\n    with pytest.warns(FutureWarning, match=\"Input X contains unknown categories\"):\n        enc.fit_transform(X)\n", "def test_ordinal_encoder_handle_unknown():\n    X = np.array([['a', 2, 'cat'], ['b', 1, 'cat'], ['b', 2, 'dog']], dtype=object)\n    X2 = np.array([['b', 1, 'cat'], ['c', 3, 'cat']], dtype=object)\n\n    # Test that ordinal encoder raises error for unknown features\n    # present during transform.\n    oe = OrdinalEncoder()\n    assert_warns(FutureWarning, oe.fit, X)\n    assert_raises(ValueError, oe.transform, X2)\n\n    # Test the ignore option, ignores unknown features (giving them\n    # a value one larger than the largest category value)\n    oe = OrdinalEncoder(handle_unknown='use_encoded_value')\n    oe.fit(X)\n    X2_passed = X2.copy()\n    exp = np.array([[1., 0., 1.], [2., 2., 1.]])\n    assert_array_equal(oe.transform(X2_passed), exp)\n    # ensure transformed data was not modified in place\n    assert_array_equal(X2, X2_passed)\n\n    # Raise error if handle_unknown is neither 'error' or 'use_encoded_value'.\n    oe = OrdinalEncoder(handle_unknown='42')\n    assert_raises(ValueError, oe.fit, X)\n"], "sample_77": ["    def test_convert_units_with_number(self):\n\n        s = Continuous()._setup(pd.Series([1, 2, 3]), Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.update_units([1, 2, 3])\n        assert_array_equal(a.convert_units([1, 2, 3]), [1, 2, 3])\n", "    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n", "    def x(self):\n        return pd.Series([1, 3, 5, 3, 1], name=\"x\", dtype=int)\n", "    def s(self):\n        return Continuous()\n", "    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n"], "sample_68": ["    def test_update_conflicts_unique_fields_update_fields_db_column_with_target(self):\n        FieldsWithDbColumns.objects.bulk_create(\n            [\n                FieldsWithDbColumns(rank=1, name=\"a\"),\n                FieldsWithDbColumns(rank=2, name=\"b\"),\n            ]\n        )\n        self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n\n        conflicting_objects = [\n            FieldsWithDbColumns(rank=1, name=\"c\"),\n            FieldsWithDbColumns(rank=2, name=\"d\"),\n        ]\n        results = FieldsWithDbColumns.objects.bulk_create(\n            conflicting_objects,\n            update_conflicts=True,\n            unique_fields=[\"rank\"],\n            update_fields=[\"db_column_name\"],\n        )\n        self.assertEqual(len(results), len(conflicting_objects))\n        if connection.features.can_return_rows_from_bulk_insert:\n            for instance in results:\n                self.assertIsNotNone(instance.pk)\n        self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n        self.assertCountEqual(\n            FieldsWithDbColumns.objects.values(\"rank\", \"name\"),\n            [\n                {\"rank\": 1, \"name\": \"c\"},\n                {\"rank\": 2, \"name\": \"d\"},\n            ],\n        )\n", "    def test_update_conflicts_unique_fields_update_fields_db_column_pk(self):\n        FieldsWithDbColumns.objects.bulk_create(\n            [\n                FieldsWithDbColumns(rank=1, name=\"a\"),\n                FieldsWithDbColumns(rank=2, name=\"b\"),\n            ]\n        )\n        self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n\n        conflicting_objects = [\n            FieldsWithDbColumns(rank=1, name=\"c\"),\n            FieldsWithDbColumns(rank=2, name=\"d\"),\n        ]\n        results = FieldsWithDbColumns.objects.bulk_create(\n            conflicting_objects,\n            update_conflicts=True,\n            unique_fields=[\"id\"],\n            update_fields=[\"name\"],\n        )\n        self.assertEqual(len(results), len(conflicting_objects))\n        if connection.features.can_return_rows_from_bulk_insert:\n            for instance in results:\n                self.assertIsNotNone(instance.pk)\n        self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n        self.assertCountEqual(\n            FieldsWithDbColumns.objects.values(\"rank\", \"name\"),\n            [\n                {\"rank\": 1, \"name\": \"c\"},\n                {\"rank\": 2, \"name\": \"d\"},\n            ],\n        )\n", "def test_update_conflicts_unique_fields_update_fields_db_column_different_model(self):\n    FieldsWithDbColumns.objects.bulk_create(\n        [\n            FieldsWithDbColumns(rank=1, name=\"a\"),\n            FieldsWithDbColumns(rank=2, name=\"b\"),\n        ]\n    )\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n\n    conflicting_objects = [\n        FieldsWithDbColumns(rank=1, name=\"c\", name_db_column=\"c_db\"),\n        FieldsWithDbColumns(rank=2, name=\"d\", name_db_column=\"d_db\"),\n    ]\n    results = FieldsWithDbColumns.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        unique_fields=[\"rank\"],\n        update_fields=[\"name_db_column\"],\n    )\n    self.assertEqual(len(results), len(conflicting_objects))\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n    self.assertCountEqual(\n        FieldsWithDbColumns.objects.values(\"rank\", \"name_db_column\"),\n        [\n            {\"rank\": 1, \"name_db_column\": \"c_db\"},\n            {\"rank\": 2, \"name_db_column\": \"d_db\"},\n        ],\n    )\n", "def test_update_conflicts_unique_fields_update_fields_db_column_other_order(self):\n    FieldsWithDbColumns.objects.bulk_create(\n        [\n            FieldsWithDbColumns(rank=1, name=\"a\"),\n            FieldsWithDbColumns(rank=2, name=\"b\"),\n        ]\n    )\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n\n    conflicting_objects = [\n        FieldsWithDbColumns(rank=1, name=\"c\"),\n        FieldsWithDbColumns(rank=2, name=\"d\"),\n    ]\n    results = FieldsWithDbColumns.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        unique_fields=[\"column_1\"],\n        update_fields=[\"db_column_name\"],\n    )\n    self.assertEqual(len(results), len(conflicting_objects))\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n    self.assertCountEqual(\n        FieldsWithDbColumns.objects.values(\"rank\", \"db_column_name\"),\n        [\n            {\"rank\": 1, \"db_column_name\": \"c\"},\n            {\"rank\": 2, \"db_column_name\": \"d\"},\n        ],\n    )\n", "def test_bulk_create_no_save_on_related_fields(self):\n    \"\"\"\n    Test that bulk_create doesn't call save() on fields of the related objects.\n\n    Regression test for #24441.\n    \"\"\"\n    related_model = RelatedModel.objects.create()\n    related_model.save()  # This should be the last save call on related_model.\n\n    # related_model is not a new object, so save() should not be called on it.\n    NullableFields.objects.bulk_create(\n        [\n            NullableFields(auto_field=related_model),\n        ]\n    )\n    self.assertEqual(NullableFields.objects.count(), 1)\n\n    # related_model.save() should not have been called again.\n    self.assertEqual(related_model.save.call_count, 1)\n"], "sample_14": ["def test_serialize_lazy_object_instance(self):\n    \"\"\"A lazy object instance can be serialized.\"\"\"\n    lazy_object = SimpleLazyObject(lambda: datetime.datetime.utcnow)\n    self.serialize_round_trip(lazy_object)\n", "def test_serialize_regex_flags(self):\n    \"\"\"\n    Test serialization of regex flags.\n    \"\"\"\n    self.assertSerializedEqual(re.RegexFlag.A)\n    self.assertSerializedResultEqual(\n        re.RegexFlag.IGNORECASE,\n        (\"re.RegexFlag['IGNORECASE']\", {'import re'})\n    )\n    self.assertSerializedResultEqual(\n        re.RegexFlag.MULTILINE | re.RegexFlag.IGNORECASE,\n        (\"re.RegexFlag['MULTILINE'] | re.RegexFlag['IGNORECASE']\", {'import re'})\n    )\n    self.assertSerializedResultEqual(\n        re.RegexFlag.VERBOSE,\n        (\"re.RegexFlag['VERBOSE']\", {'import re'})\n    )\n", "    def test_serialize_lazy_object_from_module_function(self):\n        \"\"\"\n        A lazy object created from a module-level function can be serialized.\n        \"\"\"\n            return \"example\"\n\n        lazy_object = SimpleLazyObject(lambda: example_function)\n        self.assertEqual(self.serialize_round_trip(lazy_object), \"example\")\n", "    def test_serialize_function_types(self):\n            pass\n\n        class TestClass:\n            @staticmethod\n                pass\n\n            @classmethod\n                pass\n\n        self.assertSerializedResultEqual(\n            test_function,\n            (\n                'migrations.test_writer.test_function',\n                {'import migrations.test_writer'},\n            ),\n        )\n        self.assertSerializedResultEqual(\n            TestClass.static_method,\n            (\n                'migrations.test_writer.TestClass.static_method',\n                {'import migrations.test_writer'},\n            ),\n        )\n        self.assertSerializedResultEqual(\n            TestClass.class_method,\n            (\n                'migrations.test_writer.TestClass.class_method',\n                {'import migrations.test_writer'},\n            ),\n        )\n\n        with self.assertRaisesMessage(ValueError, 'Could not find function test_function in migrations.test_writer'):\n            self.assertSerializedEqual(lambda: test_function)\n\n        with self.assertRaisesMessage(ValueError, 'Could not find object test_function in migrations.test_writer'):\n            self.assertSerializedEqual(deconstructible(path=\"migrations.test_writer.test_function\")(test_function))\n\n        with self.assertRaisesMessage(ValueError, 'Could not find object test_function in migrations.test_writer'):\n            self.assertSerializedEqual(deconstructible(path=\"migrations.test_writer.NonExistentFunction\")(test_function))\n", "def test_serialize_lazy_object_with_lazy_import(self):\n    \"\"\"\n    Make sure LazyObject with lazy import can be serialized.\n    \"\"\"\n    lazy_pattern = SimpleLazyObject(lambda: re.compile(r'^foo$'))\n    self.serialize_round_trip(lazy_pattern)\n"], "sample_57": ["def test_can_order_and_can_delete_extra_formset_forms(self):\n    ChoiceFormFormset = formset_factory(\n        form=Choice,\n        can_order=True,\n        can_delete=True,\n        extra=2,\n    )\n    formset = ChoiceFormFormset()\n    self.assertEqual(len(formset), 2)\n    self.assertIn(\"ORDER\", formset.forms[0].fields)\n    self.assertIn(\"DELETE\", formset.forms[0].fields)\n    self.assertIn(\"ORDER\", formset.forms[1].fields)\n    self.assertIn(\"DELETE\", formset.forms[1].fields)\n\n    formset = ChoiceFormFormset(initial=[{\"choice\": \"Zero\", \"votes\": \"1\"}])\n    self.assertEqual(len(formset), 3)\n    self.assertIn(\"ORDER\", formset.forms[0].fields)\n    self.assertIn(\"DELETE\", formset.forms[0].fields)\n    self.assertIn(\"ORDER\", formset.forms[1].fields)\n    self.assertNotIn(\"DELETE\", formset.forms[1].fields)\n    self.assertIn(\"ORDER\", formset.forms[2].fields)\n    self.assertNotIn(\"DELETE\", formset.forms[2].fields)\n\n    formset = ChoiceFormFormset(\n        data={\n            \"form-0-choice\": \"Zero\",\n            \"form-0-votes\": \"0\",\n            \"form-0-ORDER\": \"1\",\n            \"form-0-DELETE\": \"on\",\n            \"form-1-choice\": \"One\",\n            \"form-1-votes\": \"1\",\n            \"form-1-ORDER\": \"2\",\n            \"form-2-choice\": \"\",\n            \"form-2-votes\": \"\",\n            \"form-2-ORDER\": \"\",\n            \"form-TOTAL_FORMS\": \"3\",\n            \"form-INITIAL_FORMS\": \"1\",\n        },\n        initial=[{\"choice\": \"Zero\", \"votes\": \"1\"}],\n    )\n    self.assertEqual(\n        formset.cleaned_data,\n        [\n            {\"choice\": \"Zero\", \"votes\": 0, \"ORDER\": 1, \"DELETE\": True},\n            {\"choice\": \"One\", \"votes\": 1, \"ORDER\": 2},\n            {},\n        ],\n    )\n    self.assertIs(formset._should_delete_form(formset.forms[0]), True)\n    self.assertIs(formset._should_delete_form(formset.forms[1]), False)\n    self.assertIs(formset._should_delete_form(formset.forms[2]), False)\n", "def test_absolute_max_with_zero_initial_and_extra(self):\n    data = {\n        \"form-TOTAL_FORMS\": \"4\",\n        \"form-INITIAL_FORMS\": \"0\",\n    }\n    LimitedFavoriteDrinkFormSet = formset_factory(\n        FavoriteDrinkForm, extra=3, max_num=2, absolute_max=3\n    )\n    formset = LimitedFavoriteDrinkFormSet(data=data)\n    self.assertIs(formset.is_valid(), False)\n    self.assertEqual(len(formset.forms), 3)\n    self.assertEqual(\n        formset.non_form_errors(),\n        [\"Please submit at most 2 forms.\"],\n    )\n", "def test_management_form_with_custom_renderer(self):\n    class CustomRenderer:\n            return f\"Custom {template_name}\"\n\n    renderer = CustomRenderer()\n    management_form = ManagementForm(renderer=renderer)\n    self.assertEqual(management_form.template_name, \"django/forms/div.html\")\n    self.assertEqual(\n        management_form.get_context().get(\"form\"),\n        \"Custom django/forms/fieldset.html\",\n    )\n", "def test_add_prefix(self):\n    \"\"\"The prefix is added to the form fields.\"\"\"\n    ChoiceFormSet = formset_factory(Choice)\n    data = {\n        \"choices-TOTAL_FORMS\": \"2\",\n        \"choices-INITIAL_FORMS\": \"0\",\n        \"choices-MIN_NUM_FORMS\": \"0\",\n        \"choices-MAX_NUM_FORMS\": \"0\",\n        \"choices-0-choice\": \"Zero\",\n        \"choices-0-votes\": \"0\",\n        \"choices-1-choice\": \"One\",\n        \"choices-1-votes\": \"1\",\n    }\n    formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n    self.assertEqual(formset.management_form.cleaned_data[\"TOTAL_FORMS\"], 2)\n    self.assertEqual(formset.forms[0].fields[\"choice\"].widget.attrs[\"name\"], \"choices-0-choice\")\n", "def test_formset_management_form_rendered_with_custom_template(self):\n    \"\"\"\n    Formsets are rendered with a custom template.\n    \"\"\"\n    template_name = \"custom_formset_template.html\"\n    ChoiceFormSet = formset_factory(Choice)\n    formset = ChoiceFormSet(auto_id=False, prefix=\"choices\", template_name=template_name)\n    rendered_formset = str(formset)\n    self.assertIn(template_name, rendered_formset)\n"], "sample_151": ["def test_orthogonal_direction():\n    p1 = Point(0, 1)\n    p2 = Point(1, 0)\n    p3 = Point(1, 1)\n    p4 = Point(1, 1, 1)\n    p5 = Point(1, 2, 3)\n\n    assert p1.orthogonal_direction == p2\n    assert p2.orthogonal_direction == Point(0, -1)\n    assert p3.orthogonal_direction == Point(-1, 0)\n    assert p4.orthogonal_direction == Point(-1, 0, 0)\n    assert p5.orthogonal_direction == Point(-2, 1, 0)\n", "def test_ambient_dimension():\n    assert Point2D(1, 2).ambient_dimension == 2\n    assert Point3D(1, 2, 3).ambient_dimension == 3\n    assert Point(1, 2, 3, 4).ambient_dimension == 4\n\n    p1 = Point(1, 2)\n    p2 = Point(3, 4, 5)\n\n    with warns(UserWarning):\n        Point._normalize_dimension(p1, p2)\n\n    assert p1.ambient_dimension == 2\n    assert p2.ambient_dimension == 3\n", "def test_unit_vector_edge_cases():\n    assert Point(0, 0, 0).unit == Point(0, 0, 0)\n    assert Point(0, 0).unit == Point(0, 0)\n    assert Point(1, 1).unit == Point(sqrt(2)/2, sqrt(2)/2)\n    assert Point(1, 0).unit == Point(1, 0)\n    assert Point(0, 1).unit == Point(0, 1)\n    assert Point(1, 1, 1).unit == Point(sqrt(3)/3, sqrt(3)/3, sqrt(3)/3)\n", "def test_orthogonal_direction():\n    # test that the orthogonal direction is orthogonal to the vector from the origin\n    p = Point(1, 2, 3)\n    o = p.origin\n    d = p.orthogonal_direction\n    assert p.dot(d) == 0\n\n    # test that the orthogonal direction is not the zero vector\n    assert d != o\n\n    # test 2D points\n    p = Point2D(1, 2)\n    o = p.origin\n    d = p.orthogonal_direction\n    assert p.dot(d) == 0\n    assert d != o\n", "def test_orthogonal_direction():\n    # Test the orthogonal direction method in Point2D\n    assert Point2D(1, 0).orthogonal_direction == Point2D(0, 1)\n    assert Point2D(0, 1).orthogonal_direction == Point2D(-1, 0)\n    assert Point2D(1, 1).orthogonal_direction == Point2D(-1, 1)\n\n    # Test the orthogonal direction method in Point3D\n    assert Point3D(1, 0, 0).orthogonal_direction == Point3D(0, 1, 0)\n    assert Point3D(0, 1, 0).orthogonal_direction == Point3D(-1, 0, 0)\n    assert Point3D(0, 0, 1).orthogonal_direction == Point3D(1, 0, 0)\n    assert Point3D(1, 1, 0).orthogonal_direction == Point3D(-1, 1, 0)\n    assert Point3D(1, 0, 1).orthogonal_direction == Point3D(0, 1, 0)\n    assert Point3D(0, 1, 1).orthogonal_direction == Point3D(1, 0, 0)\n\n    # Test with points having two zero coordinates\n    assert Point3D(1, 0, 0).orthogonal_direction == Point3D(0, 1, 0)\n    assert Point3D(0, 1, 0).orthogonal_direction == Point3D(-1, 0, 0)\n    assert Point3D(0, 0, 1).orthogonal_direction == Point3D(1, 0, 0)\n    assert Point3D(0, 0, 0).orthogonal_direction == Point3D(1, 0, 0)\n"], "sample_43": ["def test_process_request_with_invalid_model(self):\n    request = self.factory.get(self.url, {'term': 'is', **self.opts, 'model_name': 'InvalidModel'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n", "    def test_process_request_invalid_request_parameters(self):\n        request = self.factory.get(self.url, {'term': 'is'})\n        request.user = self.superuser\n        with self.assertRaises(PermissionDenied):\n            AutocompleteJsonView.as_view(**self.as_view_args)(request)\n\n        request = self.factory.get(self.url, {'term': 'is', 'app_label': 'invalid'})\n        request.user = self.superuser\n        with self.assertRaises(PermissionDenied):\n            AutocompleteJsonView.as_view(**self.as_view_args)(request)\n\n        request = self.factory.get(self.url, {'term': 'is', 'app_label': Answer._meta.app_label})\n        request.user = self.superuser\n        with self.assertRaises(PermissionDenied):\n            AutocompleteJsonView.as_view(**self.as_view_args)(request)\n\n        request = self.factory.get(self.url, {'term': 'is', 'app_label': Answer._meta.app_label, 'model_name': 'invalid'})\n        request.user = self.superuser\n        with self.assertRaises(PermissionDenied):\n            AutocompleteJsonView.as_view(**self.as_view_args)(request)\n\n        request = self.factory.get(self.url, {'term': 'is', 'app_label': Answer._meta.app_label, 'model_name': Answer._meta.model_name})\n        request.user = self.superuser\n        with self.assertRaises(PermissionDenied):\n            AutocompleteJsonView.as_view(**self.as_view_args)(request)\n", "def test_process_request_malformed_app_label(self):\n    \"\"\"Test that process_request raises PermissionDenied for malformed app_label.\"\"\"\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': 'malformed', 'model_name': 'answer', 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n", "def test_process_request_with_invalid_app_label(self):\n    \"\"\"process_request should raise PermissionDenied for an invalid app_label.\"\"\"\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': 'invalid', 'model_name': Answer._meta.model_name, 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n", "def test_process_request_invalid_app_label(self):\n    \"\"\"\n    process_request() should raise PermissionDenied if the app_label is invalid.\n    \"\"\"\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': 'non-existent-app', **self.opts})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n"], "sample_38": ["    def test_normalize_username(self):\n        # The normalization happens in the field's to_python method.\n        ohm_username = 'test\u2126'  # U+2126 OHM SIGN\n        field = UsernameField()\n        normalized_username = field.to_python(ohm_username)\n        self.assertNotEqual(normalized_username, ohm_username)\n        self.assertEqual(normalized_username, 'test\u03a9')  # U+03A9 GREEK CAPITAL LETTER OMEGA\n", "    def test_normalize_username(self):\n        field = UsernameField()\n        # The normalization happens in AbstractBaseUser.clean() and ModelForm\n        # validation calls Model.clean().\n        ohm_username = 'test\u2126'  # U+2126 OHM SIGN\n        self.assertEqual(field.to_python(ohm_username), 'test\u03a9')  # U+03A9 GREEK CAPITAL LETTER OMEGA\n", "    def test_normalize_username(self):\n        field = UsernameField()\n        username = 'test\u2126'  # U+2126 OHM SIGN\n        normalized_username = field.to_python(username)\n        self.assertEqual(normalized_username, 'test\u03a9')  # U+03A9 GREEK CAPITAL LETTER OMEGA\n", "    def test_render(self):\n        # Test the password hash is displayed correctly\n        user = User.objects.get(username='testclient')\n        widget = ReadOnlyPasswordHashWidget()\n        html = widget.render('name', user.password, {'id': 'id_password'})\n        self.assertHTMLEqual(\n            html,\n            \"\"\"\n            <div id=\"id_password\">\n                <strong>algorithm</strong>: %(algorithm)s\n                <strong>iterations</strong>: %(iterations)s\n                <strong>salt</strong>: %(salt)s\n                <strong>hash</strong>: %(hash)s\n            </div>\n            \"\"\" % user.password.split('$')\n        )\n", "    def test_autocapitalize_none(self):\n        field = UsernameField()\n        self.assertEqual(field.widget.attrs.get('autocapitalize'), 'none')\n"], "sample_79": ["def test_concat_compat_override():\n    ds1 = Dataset(\n        {\n            \"has_x_y\": ((\"y\", \"x\"), [[1, 2]]),\n            \"has_x\": (\"x\", [1, 2]),\n            \"no_x_y\": (\"z\", [1, 2]),\n        },\n        coords={\"x\": [0, 1], \"y\": [0], \"z\": [-1, -2]},\n    )\n    ds2 = Dataset(\n        {\n            \"has_x_y\": ((\"y\", \"x\"), [[3, 4]]),\n            \"has_x\": (\"x\", [1, 2]),\n            \"no_x_y\": ((\"q\", \"z\"), [[1, 2]]),\n        },\n        coords={\"x\": [0, 1], \"y\": [1], \"z\": [-1, -2], \"q\": [0]},\n    )\n\n    result = concat([ds1, ds2], dim=\"y\", data_vars=\"all\", compat=\"override\")\n    assert_equal(ds1.no_x_y, result.no_x_y.transpose())\n\n    for var in [\"has_x\", \"no_x_y\"]:\n        assert \"y\" not in result[var]\n\n    result = concat([ds1, ds2], dim=\"y\", data_vars=\"all\", compat=\"override\")\n    assert result.has_x_y.dims == ('y', 'x')\n    assert result.has_x_y.shape == (2, 2)\n", "    def test_concat_positions(self):\n        ds1 = Dataset({\"a\": (\"x\", [1, 2])}, {\"x\": [0, 1]})\n        ds2 = Dataset({\"a\": (\"x\", [3, 4])}, {\"x\": [0, 1]})\n        expected = Dataset({\"a\": ((\"y\", \"x\"), [[1, 2], [3, 4]])}, {\"x\": [0, 1]})\n        actual = concat([ds1, ds2], dim=\"y\", positions=[0, 1])\n        assert_identical(actual, expected)\n\n        with raises_regex(ValueError, \"positions must have the same length\"):\n            concat([ds1, ds2], dim=\"y\", positions=[0, 1, 2])\n\n        with raises_regex(ValueError, \"out of bounds\"):\n            concat([ds1, ds2], dim=\"y\", positions=[2, 3])\n\n        with raises_regex(ValueError, \"positions must be in strictly increasing order\"):\n            concat([ds1, ds2], dim=\"y\", positions=[1, 0])\n", "    def test_concat_dim_precedence(self):\n        # verify that the dim argument takes precedence over\n        # concatenating dataset variables of the same name\n        data = Dataset({\"a\": ((\"x\", \"y\"), [[1, 2]])}, {\"x\": [0, 1]})\n        dim = (2 * data[\"x\"]).rename(\"x\")\n        datasets = [g for _, g in data.groupby(\"x\", squeeze=False)]\n        expected = data.copy()\n        expected[\"x\"] = dim\n        actual = concat(datasets, dim)\n        assert_identical(expected, actual)\n        ", "    def data(self):\n        return create_test_data().drop_dims(\"dim3\")\n", "    def test_concat_errors_dataset_dim_exists_but_not_in_data(self):\n        data = Dataset({\"a\": (\"x\", [1])}, {\"y\": [2]})\n        with raises_regex(ValueError, \"is a coordinate in some datasets but not others\"):\n            concat([data, data], dim=\"z\")\n"], "sample_135": ["def test_compare():\n    x, y, z = symbols('x y z')\n    assert x.compare(x) == 0\n    assert x.compare(y) == -1\n    assert y.compare(x) == 1\n\n    assert (x + y).compare(x) == 1\n    assert (x + y).compare(x + z) == -1\n    assert (x + z).compare(x + y) == 1\n\n    assert (x**2).compare(x) == 1\n    assert (x**2).compare(y**2) == -1\n    assert (y**2).compare(x**2) == 1\n\n    assert sin(x).compare(cos(x)) == -1\n    assert cos(x).compare(sin(x)) == 1\n", "def test_count():\n    x, y, z = symbols('x y z')\n    assert b21.count(Basic) == 5\n    assert b21.count(Basic, x) == 5\n    assert b21.count(x) == 2\n    assert b21.count(y) == 0\n    assert b21.count(z) == 0\n    assert b21.count(Basic([])) == 1\n    assert b21.count(Basic()) == 1\n", "def test_find():\n    x, y = symbols('x y')\n    e = (x + y)*y + sin(x)\n    assert e.find(sin(x)) == {sin(x)}\n    assert e.find(sin(x), group=True) == {sin(x): 1}\n    assert e.find(sin(y)) == set()\n    assert e.find(S.Pi) == set()\n    assert e.find(S.Pi, group=True) == {}\n    assert e.find(Basic) == set()\n    assert e.find(Basic, group=True) == {}\n    assert e.find(sin(x) + y) == set()\n    assert e.find(sin(x) + y, group=True) == {}\n    assert e.find(Basic(x, y)) == set()\n    assert e.find(Basic(x, y), group=True) == {}\n", "def test_replace_no_default_sort_key():\n    from sympy import Wild\n    x, y, z = symbols('x y z')\n    e = (z + x + y)\n    p, q = Wild('p'), Wild('q')\n    assert e.replace(p + q, q) == z + x + y\n    assert e.replace(p + q, q, exact=False) == z + x + y\n    assert e.replace(p + q, q, exact=True) == z + x + y\n    assert e.replace(p + q, q, old=True) == z + x + y\n", "def test_compare():\n    # Test that compare() is consistent with the sort_key() ordering.\n    x, y, z = symbols('x y z')\n    exprs = [x + y, y + x, x + x, x + z, z + x, 2*x, x + 2, x**2, x**x]\n    expected_order = [-1, 1, -1, -1, 1, -1, -1, -1, -1,\n                      0,  # x + y vs x + y\n                      -1, 1, -1, 1, -1, 1,\n                      -1, 1, -1, 1, -1,\n                      1, -1, -1, 1, -1,\n                      1, 1, -1, -1,\n                      1, -1, 1,\n                      1, 1,\n                      -1]  # ... vs x**x\n    results = []\n    for i in range(len(exprs)):\n        for j in range(i, len(exprs)):\n            c = exprs[i].compare(exprs[j])\n            results.append(c)\n    assert results == expected_order\n"], "sample_159": ["def test_prefix_latex():\n    assert kilo._latex(None) == r'\\text{k}'\n    assert micro._latex(None) == r'\\mu'\n", "def test_prefix_latex():\n    assert kilo._latex(None) == r\"\\text{k}\"\n    assert micro._latex(None) == r\"\\mu\"\n    assert Prefix('custom', 'c', 1)._latex(None) == r\"\\text{c}\"\n", "def test_prefix_latex():\n    assert kilo._latex(None) == r'\\text{k}'\n    assert micro._latex(None) == r'\\mu'\n    assert micro._latex_repr is not None\n    assert kilo._latex_repr is None\n\n    class TestPrefix(Prefix):\n            return super().__new__(cls, *args, **kwargs)\n\n    test_prefix = TestPrefix('test', 't', 1, latex_repr=r'\\text{t}')\n    assert test_prefix._latex(None) == r'\\text{t}'\n", "def test_prefix_division():\n    assert kilo / kilo is S.One\n    assert kilo / mega is S.One / 1000\n    assert mega / kilo == 1000\n\n    assert kibi / kibi is S.One\n    assert kibi / mebi is S.One / 1024\n    assert mebi / kibi == 1024\n\n    assert yocto / yocto is S.One\n    assert yocto / yotta is S.One / 1000000000000000000000000\n    assert yotta / yocto == 1000000000000000000000000\n\n    assert yocto / kilo == yocto.scale_factor / kilo.scale_factor\n    assert kilo / yocto == kilo.scale_factor / yocto.scale_factor\n", "def test_prefix_latex_repr():\n    assert kibi._latex(None) == r'\\text{Y}'\n    assert micro._latex(None) == r\"\\mu\"\n\n"], "sample_30": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n", "    def setUp(self):\n        self.client.force_login(self.superuser)\n", "    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', email='super@example.com', password='secret')\n        cls.holder = Holder.objects.create(dummy=13)\n", "    def test_inline_media(self):\n        class InnerInlineWithCustomMedia(InlineModelAdmin):\n            model = Inner\n            classes = ['extra-media']\n\n        modeladmin = ModelAdmin(Holder, admin_site)\n        modeladmin.inlines = [InnerInlineWithCustomMedia]\n\n        holder = Holder.objects.create(dummy=1)\n        request = self.factory.get(reverse('admin:admin_inlines_holder_change', args=(holder.id,)))\n        request.user = self.superuser\n\n        response = modeladmin.changeform_view(request, object_id=holder.id)\n\n        # my_awesome_admin_scripts.js is provided by HolderAdmin's media\n        # custom.js is provided by the extra-media class\n        self.assertContains(response, 'my_awesome_admin_scripts.js')\n        self.assertContains(response, 'custom.js')\n", "    def test_get_view_on_site_url(self):\n        novel = Novel.objects.create(name=\"Lord of the rings\")\n        novel_admin = ModelAdmin(Novel, admin_site)\n        self.assertIsNotNone(novel_admin.get_view_on_site_url(novel))\n        self.assertIsNone(novel_admin.get_view_on_site_url())\n\n        class ModelAdminWithCallable(ModelAdmin):\n                return reverse('some_view', kwargs={'pk': obj.pk})\n\n        model_admin = ModelAdminWithCallable(Novel, admin_site)\n        self.assertIsNotNone(model_admin.get_view_on_site_url(novel))\n        self.assertIsNone(model_admin.get_view_on_site_url())\n"], "sample_154": ["def test_lambdify_kwargs():\n    f = lambdify((x, y), x + y, 'numpy')\n    raises(TypeError, lambda: f(a=1, b=2))\n    raises(TypeError, lambda: f(1, a=2))\n    raises(TypeError, lambda: f(a=1, 2))\n", "def test_issue_15071():\n    if not numpy:\n        skip(\"numpy not installed\")\n    f = lambdify(x, Matrix((x, 2, 3)).T)\n    numpy.testing.assert_array_equal(f(1), numpy.array([[1], [2], [3]]))\n", "def test_issue_17526():\n    if not numpy:\n        skip(\"numpy not installed\")\n    f = lambdify([x, y], x**y, 'numpy')\n    assert f(2, numpy.array([2, 3])) == [4, 8]\n    assert f(numpy.array([2, 3]), 2) == [4, 9]\n    assert f(numpy.array([2, 3]), numpy.array([2, 3])) == [4, 27]\n", "def test_no_dummification():\n    # Issue 15583\n    f = lambdify('x', 'x', dummify=False)\n    assert f(1) == 'x'\n    assert f(2) == 'x'\n    assert f('x') == 'x'\n", "def test_issue_24075():\n    if not numpy:\n        skip(\"numpy not installed\")\n    if not scipy:\n        skip(\"scipy not installed\")\n    x = symbols(\"x\")\n    f = lambdify(x, Array(2*x, 3*x, 4*x), 'numpy')\n    numpy.testing.assert_array_equal(f(1), numpy.array([2, 3, 4]))\n"], "sample_18": ["    def test_on_delete_set_null_with_default_value(self):\n        class Person(models.Model):\n            pass\n\n        class Model(models.Model):\n            foreign_key = models.ForeignKey('Person', models.SET_NULL, default=1)\n\n        field = Model._meta.get_field('foreign_key')\n        self.assertEqual(field.check(), [\n            Error(\n                'Field specifies on_delete=SET_NULL, but cannot be null.',\n                hint='Set null=True argument on the field, or change the on_delete rule.',\n                obj=field,\n                id='fields.E320',\n            ),\n        ])\n", "    def test_reverse_query_name_ending_with_underscore(self):\n        class Target(models.Model):\n            pass\n\n        class Model(models.Model):\n            field = models.ForeignKey(Target, models.CASCADE, related_query_name='ends_with_underscore_')\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"Reverse query name 'ends_with_underscore_' must not end with an underscore.\",\n                hint=(\"Add or change a related_name or related_query_name \"\n                      \"argument for this field.\"),\n                obj=Model._meta.get_field('field'),\n                id='fields.E308',\n            ),\n        ])\n", "    def test_clash_between_symmetrical_m2m_and_fk(self):\n        class Model(models.Model):\n            symmetrical_m2m = models.ManyToManyField('self', symmetrical=True)\n            fk = models.ForeignKey('self', models.CASCADE)\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"Reverse accessor for 'Model.fk' clashes with reverse accessor for 'Model.symmetrical_m2m'.\",\n                hint=(\n                    \"Add or change a related_name argument to the definition \"\n                    \"for 'Model.fk' or 'Model.symmetrical_m2m'.\"\n                ),\n                obj=Model._meta.get_field('fk'),\n                id='fields.E304',\n            ),\n            Error(\n                \"Reverse query name for 'Model.fk' clashes with reverse query name for 'Model.symmetrical_m2m'.\",\n                hint=(\n                    \"Add or change a related_name argument to the definition \"\n                    \"for 'Model.fk' or 'Model.symmetrical_m2m'.\"\n                ),\n                obj=Model._meta.get_field('fk'),\n                id='fields.E305',\n            ),\n        ])\n", "    def test_reverse_accessor_clash_with_parent_link(self):\n        class Parent(models.Model):\n            pass\n\n        class Child(Parent):\n            child = models.OneToOneField(Parent, models.CASCADE)\n\n        self.assertEqual(Child.check(), [\n            Error(\n                \"Reverse accessor for 'Child.child' clashes with field name 'Parent.parent_ptr'.\",\n                hint=(\"Rename field 'Parent.parent_ptr', or add/change a related_name \"\n                      \"argument to the definition for field 'Child.child'.\"),\n                obj=Child._meta.get_field('child'),\n                id='fields.E302',\n            ),\n        ])\n", "    def test_related_field_non_string(self):\n        with self.assertRaisesMessage(ValueError, 'Related field must be a string, a model class, or a reference to a swappable model'):\n            models.Field(remote_field=models.Field())\n"], "sample_58": ["    def test_default_dbname(self):\n        self.assertEqual(\n            self.settings_to_cmd_args_env(\n                {\n                    \"USER\": \"someuser\",\n                    \"HOST\": \"somehost\",\n                    \"PORT\": \"444\",\n                }\n            ),\n            (\n                [\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"postgres\"],\n                None,\n            ),\n        )\n", "def test_default_database(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env(\n            {\n                \"USER\": \"someuser\",\n                \"HOST\": \"somehost\",\n                \"PORT\": \"444\",\n            }\n        ),\n        (\n            [\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"postgres\"],\n            None,\n        ),\n    )\n", "    def test_default_database(self):\n        self.assertEqual(\n            self.settings_to_cmd_args_env({}),\n            ([\"psql\", \"postgres\"], None),\n        )\n        self.assertEqual(\n            self.settings_to_cmd_args_env({\"USER\": \"someuser\"}),\n            ([\"psql\", \"-U\", \"someuser\", \"postgres\"], None),\n        )\n", "    def test_default_database(self):\n        self.assertEqual(\n            self.settings_to_cmd_args_env(\n                {\n                    \"USER\": \"someuser\",\n                    \"PASSWORD\": \"somepassword\",\n                    \"HOST\": \"somehost\",\n                    \"PORT\": \"444\",\n                }\n            ),\n            (\n                [\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"postgres\"],\n                {\"PGPASSWORD\": \"somepassword\"},\n            ),\n        )\n", "def test_default_database_name(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env({}),\n        ([\"psql\", \"postgres\"], None),\n    )\n"], "sample_73": ["def test_aux_transform_box():\n    fig, ax = plt.subplots()\n    aux_transform = mtransforms.Affine2D().rotate_deg(45)\n    aux_box = AuxTransformBox(aux_transform)\n    child = DrawingArea(20, 20)\n    aux_box.add_artist(child)\n    ax.add_artist(aux_box)\n    ax.set_xlim(0, 100)\n    ax.set_ylim(0, 100)\n    fig.canvas.draw()\n", "def test_auxtransformbox(fig_test, fig_ref):\n    ax_ref = fig_ref.add_subplot()\n    text0 = TextArea(\"Foo\")\n    atb = AuxTransformBox(ax_ref.transData)\n    atb.add_artist(text0)\n    ax_ref.add_artist(atb)\n\n    ax_test = fig_test.add_subplot()\n    text1 = TextArea(\"Bar\")\n    atb = AuxTransformBox(ax_test.transData)\n    atb.add_artist(text1)\n    ax_test.add_artist(atb)\n    atb.set_offset((1, 1))\n    text1.set_text(\"Foo\")\n    atb.set_offset((0, 0))\n", "def test_auxtransformbox():\n    # Test the basic functionality of AuxTransformBox\n    fig, ax = plt.subplots()\n    aux_transform = mtransforms.Affine2D().rotate_deg(30)\n    aux_box = AuxTransformBox(aux_transform)\n    at = TextArea(\"foo\")\n    aux_box.add_artist(at)\n    ax.add_artist(aux_box)\n    ab = AnchoredOffsetbox('upper right', child=aux_box)\n    ax.add_artist(ab)\n    fig.canvas.draw()\n\n    # Test that the aux_transform is applied\n    xy = aux_box.get_window_extent().p0\n    assert_allclose(xy, ab.get_window_extent().p0, atol=1)\n\n    # Test that the offset_transform is also applied\n    aux_box.set_offset((10, 20))\n    fig.canvas.draw()\n    xy = aux_box.get_window_extent().p0\n    assert_allclose(xy, (10, 20), atol=1)\n", "def test_drawing_area_add_artist(align):\n    # Test adding artists to a DrawingArea with different alignments.\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100, xdescent=0, ydescent=0, clip=False)\n\n    # Add a rectangle with alignment.\n    rect = mpatches.Rectangle((0, 0), 50, 50, facecolor='red')\n    rect.set_transform(da.get_transform())\n    da.add_artist(rect)\n\n    # Add another rectangle without alignment.\n    rect2 = mpatches.Rectangle((50, 50), 50, 50, facecolor='blue')\n    da.add_artist(rect2)\n\n    ax.add_artist(da)\n    ax.set_xlim(0, 100)\n    ax.set_ylim(0, 100)\n    ax.set_aspect('equal')\n    fig.canvas.draw()\n\n    # Check that both rectangles are visible and in the correct position.\n    assert rect.get_visible()\n    assert rect2.get_visible()\n    if align in [\"left\", \"bottom\"]:\n        assert_allclose(rect.get_xy(), (0, 0))\n        assert_allclose(rect2.get_xy(), (50, 50))\n    elif align in [\"right\", \"top\"]:\n        assert_allclose(rect.get_xy(), (50, 0))\n        assert_allclose(rect2.get_xy(), (0, 50))\n    elif align == \"center\":\n        assert_allclose(rect.get_xy(), (25, 25))\n        assert_allclose(rect2.get_xy(), (75, 75))\n", "def test_draggable_offsetbox():\n    fig, ax = plt.subplots()\n    ab = AnnotationBbox(DrawingArea(20, 20), (.5, .5),\n                        xybox=(0, 0), xycoords='axes fraction',\n                        boxcoords=\"offset points\", pad=0.3,\n                        arrowprops=dict(arrowstyle=\"->\"))\n    ax.add_artist(ab)\n    ax.set_xlim([0, 10])\n    ax.set_ylim([0, 10])\n\n    drag = DraggableOffsetBox(ab, ab.offsetbox, use_blit=False)\n\n    fig.canvas.draw()\n    calls = []\n    fig.canvas.mpl_connect('motion_notify_event',\n                           lambda event: calls.append(event))\n    event = MouseEvent(\"motion_notify_event\", fig.canvas, 5, 5,\n                       MouseButton.LEFT, button_dblclick=False, key=\"\")\n    event.processed = False\n    event.xdata = 5\n    event.ydata = 5\n    fig.canvas.callbacks.process(event.name, event)\n    assert len(calls) == 1\n\n    drag.update_offset(10, 10)\n    fig.canvas.draw()\n\n    assert ab.offsetbox.get_offset() == (10, 10)\n\n    drag.finalize_offset()\n    fig.canvas.draw()\n"], "sample_121": ["def test_inverse():\n    p = Permutation([[1, 2, 3], [0, 4, 5]])\n    assert ~p == Permutation([4, 0, 1, 2, 3, 5])\n    assert p**-1 == ~p\n    assert p*~p == ~p*p == Permutation([0, 1, 2, 3, 4, 5])\n    assert ~(~p) == p\n", "def test_power():\n    p = Permutation([0, 2, 3, 1])\n    assert p**-1 == Permutation([3, 1, 0, 2])\n    assert p**(p.order()) == Permutation([0, 1, 2, 3])\n    assert p**1 == p\n    assert p**0 == Permutation([0, 1, 2, 3])\n    assert p**-2 == Permutation([2, 0, 3, 1])**2\n    assert p**(3) == p**2*p\n    assert p**(-3) == ~p**3\n    raises(NotImplementedError, lambda: p**p)\n    raises(TypeError, lambda: p**a)\n", "def test_transpositions():\n    # Test with a permutation that has a single cycle\n    p = Permutation([0, 3, 2, 1])\n    assert p.transpositions() == [(0, 3), (0, 1), (0, 2)]\n    \n    # Test with a permutation that has multiple cycles\n    p = Permutation([[1, 2, 3], [0, 4]])\n    assert p.transpositions() == [(1, 3), (1, 2), (0, 4)]\n    \n    # Test with the identity permutation\n    p = Permutation([0, 1, 2, 3])\n    assert p.transpositions() == []\n    \n    # Test with a permutation that has a single transposition\n    p = Permutation([0, 2, 1, 3])\n    assert p.transpositions() == [(0, 2)]\n    \n    # Test with a permutation that has a cycle of length 1\n    p = Permutation([[0], [1, 2, 3]])\n    assert p.transpositions() == [(1, 3), (1, 2)]\n    \n    # Test with a permutation that has multiple cycles of length 1\n    p = Permutation([[0], [1], [2], [3]])\n    assert p.transpositions() == []\n", "def test_cycle_structure():\n    # Test singletons\n    p = Permutation([0, 1, 2, 3, 4])\n    assert p.cycle_structure == {1: 5}\n    assert p.cycles == 5\n\n    # Test two 2-cycles\n    p = Permutation([[1, 3], [2, 4]], size=5)\n    assert p.cycle_structure == {2: 2, 1: 1}\n    assert p.cycles == 3\n\n    # Test one 3-cycle\n    p = Permutation([1, 2, 0, 3, 4])\n    assert p.cycle_structure == {3: 1, 1: 2}\n    assert p.cycles == 3\n\n    # Test one 4-cycle\n    p = Permutation([[1, 2, 3, 4]])\n    assert p.cycle_structure == {4: 1}\n    assert p.cycles == 1\n\n    # Test 2 cycles of lengths 3 and 2\n    p = Permutation([[1, 2, 3], [4, 5]], size=6)\n    assert p.cycle_structure == {2: 1, 3: 1, 1: 1}\n    assert p.cycles == 3\n", "def test_exceptions():\n    raises(ValueError, lambda: Permutation([0, 1, 3], size=3))\n    raises(ValueError, lambda: Permutation([0, 1, 3], size=4))\n    raises(ValueError, lambda: Permutation([0, 1, 2, 4], size=3))\n    raises(ValueError, lambda: Permutation([1, 0, 2, 3]))\n    raises(ValueError, lambda: Permutation([1, 0, 2, 4]))\n    raises(ValueError, lambda: Permutation([[1, 2], [0, 1]]))\n    raises(ValueError, lambda: Permutation([[1, 2], [3, 4]]))\n    raises(ValueError, lambda: Permutation([[1, 2], [2, 3]]))\n    raises(ValueError, lambda: Permutation([[1, 2], [0, 1, 1]]))\n    raises(ValueError, lambda: Permutation([[0, 1, 2], [0, 1, 2]]))\n    raises(ValueError, lambda: Permutation(1, 0, 2, 0))\n    raises(ValueError, lambda: Permutation([[0, 1, 2], [2, 0, 1]]))\n    raises(ValueError, lambda: Permutation([[0, 1, 2], [1, 2, 0]]))\n    raises(ValueError, lambda: Permutation(0, 1, 2, 0))\n    raises(ValueError, lambda: Permutation([[0, 2, 1], [2, 1, 0]]))\n    raises(ValueError, lambda: Permutation([0, 1, 2], size=3))\n    raises(ValueError, lambda: Permutation([1, 2, 0], size=1))\n    raises(ValueError, lambda: Permutation(1, 2, 1))\n    raises(ValueError, lambda: Permutation(1, 2, size=3))\n    raises(ValueError, lambda: Permutation([0, 1, 3], size=5))\n    raises(ValueError, lambda: Permutation(1, 2)(3, 4, 3))\n    raises(ValueError, lambda: Permutation(0, 1, 2)(3, 4, 5, 3))\n    raises(ValueError, lambda: Permutation(1, 2)(1,"], "sample_158": ["def test_get_units_non_prefixed():\n    assert len(SI.get_units_non_prefixed()) == 9\n    assert all(isinstance(u, Quantity) for u in SI.get_units_non_prefixed())\n    assert all(not u.is_prefixed for u in SI.get_units_non_prefixed())\n    assert all(not u.is_physical_constant for u in SI.get_units_non_prefixed())\n\n    new_unit_system = SI.extend([], name=\"NewUnitSystem\")\n    assert len(new_unit_system.get_units_non_prefixed()) == 0\n\n    new_unit = Quantity('new_unit')\n    new_unit.set_global_relative_scale_factor(1, meter)\n    new_unit_system = SI.extend([], units=(new_unit,), name=\"NewUnitSystem\")\n    assert len(new_unit_system.get_units_non_prefixed()) == 1\n    assert new_unit in new_unit_system.get_units_non_prefixed()\n", "def test_extend_unit_system():\n    SI = UnitSystem.get_unit_system(\"SI\")\n    new_system = SI.extend(base=(Quantity(\"new_unit\"),), units=(Quantity(\"new_unit2\"),))\n    assert new_system._base_units == (meter, kilogram, second, ampere, kelvin, mole, candela, Quantity(\"new_unit\"))\n    assert new_system._units == (meter, kilogram, second, ampere, kelvin, mole, candela, Quantity(\"new_unit\"), Quantity(\"new_unit2\"))\n    assert new_system.name == \"\"\n    assert new_system.descr == \"\"\n    assert new_system.is_consistent\n    assert len(new_system._base_units) == 8\n", "def test_unit_system_extend():\n    base_units = (meter, second)\n    units = (kilogram, joule)\n    name = \"SI\"\n    description = \"International System of Units\"\n    dimension_system = None\n    derived_units = {energy: joule}\n\n    us = UnitSystem(base_units, units, name, description, dimension_system, derived_units)\n    extended_us = us.extend(base=(), units=(volt,), name=\"SI_extended\", description=\"Extended International System of Units\")\n\n    assert extended_us.name == \"SI_extended\"\n    assert extended_us.descr == \"Extended International System of Units\"\n    assert extended_us._base_units == (meter, second)\n    assert extended_us._units == (meter, second, kilogram, joule, volt)\n    assert extended_us._derived_units == {energy: joule}\n", "def test_unit_system():\n    u1 = Quantity('u1')\n    u1.set_global_relative_scale_factor(1, meter)\n    u2 = Quantity('u2')\n    u2.set_global_relative_scale_factor(1, second)\n    us = UnitSystem([u1, u2], name='my_unit_system')\n\n    assert us.name == 'my_unit_system'\n    assert us.descr == ''\n    assert us._base_units == (u1, u2)\n    assert us._dimension_system.is_consistent\n\n    us2 = us.extend([Quantity('u3')], name='my_unit_system2')\n    assert us2._base_units == (u1, u2, Quantity('u3'))\n    assert us2._dimension_system.is_consistent\n    assert us2.name == 'my_unit_system2'\n    assert us2.descr == ''\n\n    assert us.get_dimension_system() == us._dimension_system\n    assert us.get_quantity_dimension(u1) == length\n    assert us.get_quantity_scale_factor(u1) == 1\n\n    assert UnitSystem.get_unit_system('my_unit_system') == us\n    with raises(ValueError):\n        UnitSystem.get_unit_system('unknown_unit_system')\n    assert UnitSystem.get_default_unit_system().name == 'SI'\n\n    assert us.dim == 2\n    assert us.is_consistent\n\n    assert us.derived_units == {}\n\n    assert us.get_units_non_prefixed() == {u1, u2}\n", "def test_get_unit_system():\n    assert SI.get_unit_system(\"SI\") == SI\n    with raises(ValueError):\n        SI.get_unit_system(\"NonExistingUnitSystem\")\n    with raises(ValueError):\n        SI.get_unit_system(123)\n"], "sample_59": ["def test_formset_add_fields(self):\n    class FormWithExtraFields(Form):\n        field1 = CharField()\n        field2 = CharField()\n\n    class FormSetWithExtraFields(BaseFormSet):\n            form.fields[\"field3\"] = CharField()\n            form.fields[\"field4\"] = CharField()\n\n    FormSet = formset_factory(FormWithExtraFields, formset=FormSetWithExtraFields)\n    formset = FormSet()\n    form = formset.empty_form\n    self.assertIn(\"field1\", form.fields)\n    self.assertIn(\"field2\", form.fields)\n    self.assertIn(\"field3\", form.fields)\n    self.assertIn(\"field4\", form.fields)\n", "def test_formset_with_renderers(self):\n    from django.forms.renderers import TemplatesSetting\n\n    class CustomRenderer(TemplatesSetting):\n        formset_template_name = \"a/custom/formset/template.html\"\n\n    ChoiceFormSet = formset_factory(Choice, renderer=CustomRenderer)\n\n    formset = ChoiceFormSet()\n    self.assertEqual(\n        formset.template_name, \"a/custom/formset/template.html\"\n    )\n\n    data = {\n        \"choices-TOTAL_FORMS\": \"2\",\n        \"choices-INITIAL_FORMS\": \"0\",\n        \"choices-MIN_NUM_FORMS\": \"0\",\n        \"choices-0-choice\": \"Zero\",\n        \"choices-0-votes\": \"0\",\n        \"choices-1-choice\": \"One\",\n        \"choices-1-votes\": \"1\",\n    }\n    formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n    self.assertEqual(formset.management_form.renderer, CustomRenderer())\n    self.assertEqual(formset.forms[0].renderer, CustomRenderer())\n    self.assertEqual(formset.non_form_errors().renderer, CustomRenderer())\n    self.assertEqual(formset.empty_form.renderer, CustomRenderer())\n", "def test_empty_form_with_extra_fields(self):\n    class ExtraFieldsFormSet(BaseFormSet):\n            form.fields[\"extra_field\"] = CharField(label=\"Extra\")\n\n    class ExtraFieldsForm(Form):\n        pass\n\n    ExtraFieldsFormSet = formset_factory(ExtraFieldsForm, formset=ExtraFieldsFormSet)\n\n    formset = ExtraFieldsFormSet()\n    self.assertIn(\"extra_field\", formset.forms[0].fields)\n    self.assertIn(\"extra_field\", formset.empty_form.fields)\n", "def test_formset_absolute_max_with_validate_max_and_min_num(self):\n    \"\"\"absolute_max and validate_max with min_num.\"\"\"\n    data = {\n        \"form-TOTAL_FORMS\": \"1001\",\n        \"form-INITIAL_FORMS\": \"0\",\n        \"form-MIN_NUM_FORMS\": \"0\",\n        \"form-MAX_NUM_FORMS\": \"0\",\n    }\n    LimitedFavoriteDrinksFormSet = formset_factory(\n        FavoriteDrinkForm,\n        min_num=1000,\n        absolute_max=1000,\n        validate_min=True,\n        validate_max=True,\n    )\n    formset = LimitedFavoriteDrinksFormSet(data=data)\n    self.assertIs(formset.is_valid(), False)\n    self.assertEqual(len(formset.forms), 1000)\n    self.assertEqual(\n        formset.non_form_errors(),\n        [\"Please submit at most 1000 forms.\"],\n    )\n", "def test_absolute_max_prevents_instantiation(self):\n    \"\"\"\n    absolute_max prevents instantiation of forms beyond its limit.\n    \"\"\"\n    data = {\n        \"form-TOTAL_FORMS\": \"2001\",\n        \"form-INITIAL_FORMS\": \"0\",\n        \"form-MAX_NUM_FORMS\": \"0\",\n    }\n    FormSet = formset_factory(FavoriteDrinkForm, absolute_max=3)\n    formset = FormSet(data)\n    self.assertEqual(len(formset.forms), 3)\n    # Only 3 forms are instantiated despite a higher TOTAL_FORMS value.\n    with self.assertRaises(IndexError):\n        formset.forms[3]\n"], "sample_60": ["def test_serialize_enum_subclass(self):\n    class MyEnum(TextEnum):\n        pass\n\n    self.assertSerializedResultEqual(\n        MyEnum.A,\n        (\"migrations.test_writer.WriterTests.test_serialize_enum_subclass.<locals>.MyEnum['A']\", {\"import migrations.test_writer\"}),\n    )\n\n    field = models.CharField(\n        default=MyEnum.B, choices=[(m.value, m) for m in MyEnum]\n    )\n    string = MigrationWriter.serialize(field)[0]\n    self.assertEqual(\n        string,\n        \"models.CharField(choices=[\"\n        \"('a-value', migrations.test_writer.WriterTests.test_serialize_enum_subclass.<locals>.MyEnum['A']), \"\n        \"('value-b', migrations.test_writer.WriterTests.test_serialize_enum_subclass.<locals>.MyEnum['B'])], \"\n        \"default=migrations.test_writer.WriterTests.test_serialize_enum_subclass.<locals>.MyEnum['B'])\",\n    )\n", "def test_serialize_timezone_aware_datetime_object(self):\n    dt = datetime.datetime(2022, 1, 1, 12, 0, tzinfo=datetime.timezone.utc)\n    dt_aware = datetime.datetime(2022, 1, 1, 12, 0, tzinfo=get_default_timezone())\n    self.assertSerializedResultEqual(\n        dt,\n        (\n            \"datetime.datetime(2022, 1, 1, 12, 0, tzinfo=datetime.timezone.utc)\",\n            {\"import datetime\"},\n        ),\n    )\n    self.assertSerializedResultEqual(\n        dt_aware,\n        (\n            \"datetime.datetime(2022, 1, 1, 12, 0, tzinfo=datetime.timezone.utc)\",\n            {\"import datetime\"},\n        ),\n    )\n", "def test_serialize_custom_serializer(self):\n    class CustomSerializer(BaseSerializer):\n            return repr(self.value), {\"import custom_module\"}\n\n    Serializer.register(enum.Enum, CustomSerializer)\n    self.assertSerializedResultEqual(\n        TextEnum.A,\n        (\"migrations.test_writer.TextEnum['A']\", {\"import custom_module\"}),\n    )\n    Serializer.unregister(enum.Enum)\n    with self.assertRaisesMessage(ValueError, \"Cannot serialize: <TextEnum.A: 'a-value'>\"):\n        self.assertSerializedEqual(TextEnum.A)\n", "    def test_serialize_settings_reference(self):\n        \"\"\"\n        Ticket #32230: Test serialization of SettingsReference.\n        \"\"\"\n        class MySettings(models.Model):\n            value = models.CharField(max_length=10)\n\n        class MyModel(models.Model):\n            value = models.CharField(max_length=10, default=SettingsReference(MySettings, \"value\"))\n\n        string, imports = MigrationWriter.serialize(MyModel._meta.get_field(\"value\"))\n        self.assertEqual(\n            string,\n            \"models.CharField(default=settings.value, max_length=10)\",\n        )\n        self.assertEqual(imports, {\"from django.conf import settings\"})\n", "def test_serialize_enum_members(self):\n    \"\"\"Ensure that enum members are serialized as themselves.\"\"\"\n    class Color(models.TextChoices):\n        RED = 'red', 'Red'\n        GREEN = 'green', 'Green'\n        BLUE = 'blue', 'Blue'\n\n    color = Color.RED\n    string, imports = MigrationWriter.serialize(color)\n    self.assertEqual(string, \"migrations.test_writer.WriterTests.Color['RED']\")\n    self.assertEqual(imports, {\"import migrations.test_writer\"})\n\n    class Shape(models.IntegerChoices):\n        SQUARE = 1, 'Square'\n        CIRCLE = 2, 'Circle'\n        TRIANGLE = 3, 'Triangle'\n\n    shape = Shape.CIRCLE\n    string, imports = MigrationWriter.serialize(shape)\n    self.assertEqual(string, \"migrations.test_writer.WriterTests.Shape['CIRCLE']\")\n    self.assertEqual(imports, {\"import migrations.test_writer\"})\n\n    class Size(models.Choices):\n        SMALL = 'small', 'Small'\n        MEDIUM = 'medium', 'Medium'\n        LARGE = 'large', 'Large'\n\n    size = Size.MEDIUM\n    string, imports = MigrationWriter.serialize(size)\n    self.assertEqual(string, \"migrations.test_writer.WriterTests.Size['MEDIUM']\")\n    self.assertEqual(imports, {\"import migrations.test_writer\"})\n"], "sample_102": ["def test_iforest_oob_score():\n    \"\"\"Test that oob_score is not supported.\"\"\"\n    clf = IsolationForest()\n    assert_raises_message(\n        NotImplementedError,\n        \"OOB score not supported by iforest\",\n        clf._set_oob_score,\n        np.array([[0, 1], [1, 2]]),\n        np.array([0, 1])\n    )\n", "def test_iforest_predict_large_input():\n    \"\"\"Test that IsolationForest can predict on large input.\"\"\"\n    rng = check_random_state(0)\n    X_train, X_test, y_train, y_test = train_test_split(boston.data,\n                                                        boston.target,\n                                                        random_state=rng)\n    clf = IsolationForest(n_estimators=10, random_state=rng).fit(X_train)\n    large_X_test = np.vstack([X_test] * 1000)  # create a large test set\n    clf.predict(large_X_test)\n", "def test_compute_score_samples():\n    X_train = [[1, 1], [1, 2], [2, 1]]\n    clf = IsolationForest(contamination=0.1).fit(X_train)\n    X_test = [[2., 2.]]\n    scores = clf._compute_score_samples(X_test, subsample_features=False)\n    expected_scores = np.array([0.006737946999085459])\n    assert_allclose(scores, expected_scores)\n", "def test_iforest_empty_input():\n    \"\"\"Test that Isolation Forest raises error on empty input.\"\"\"\n    X = np.array([])\n\n    assert_raises_regex(\n        ValueError, \n        \"zero-size samples\",\n        IsolationForest().fit, X\n    )\n\n    assert_raises_regex(\n        ValueError, \n        \"zero-size samples\",\n        IsolationForest().fit, X, None\n    )\n\n    X = np.array([[]])\n\n    assert_raises_regex(\n        ValueError, \n        \"zero-size samples\",\n        IsolationForest().fit, X\n    )\n\n    assert_raises_regex(\n        ValueError, \n        \"zero-size samples\",\n        IsolationForest().fit, X, None\n    )\n", "def test_iforest_edge_cases():\n    # test max_depth=1\n    X_train = [[1], [2], [3]]\n    clf = IsolationForest(max_samples=2).fit(X_train)\n    assert_equal(clf.max_depth_, 1)\n\n    # test max_depth=2\n    X_train = [[1], [2], [3], [4]]\n    clf = IsolationForest(max_samples=4).fit(X_train)\n    assert_equal(clf.max_depth_, 2)\n\n    # test zero variance features\n    X_train = [[1, 2], [1, 2], [1, 2]]\n    clf = IsolationForest().fit(X_train)\n    assert_array_equal(clf.predict(X_train), [1, 1, 1])\n\n    # test a single sample\n    X_train = [[1]]\n    clf = IsolationForest().fit(X_train)\n    assert_array_equal(clf.predict(X_train), [1])\n"], "sample_109": ["def test_time_series_split_random_state():\n    # Test the randomness in TimeSeriesSplit\n    X = np.arange(10).reshape((10, 1))\n    tscv1 = TimeSeriesSplit(n_splits=5)\n    tscv2 = TimeSeriesSplit(n_splits=5, random_state=0)\n    tscv3 = TimeSeriesSplit(n_splits=5, random_state=0)\n    tscv4 = TimeSeriesSplit(n_splits=5, random_state=np.random.RandomState(0))\n\n    for train1, test1 in tscv1.split(X):\n        for train2, test2 in tscv2.split(X):\n            assert_array_equal(train1, train2)\n            assert_array_equal(test1, test2)\n\n    for train1, test1 in tscv2.split(X):\n        for train3, test3 in tscv3.split(X):\n            assert_array_equal(train1, train3)\n            assert_array_equal(test1, test3)\n\n    for train1, test1 in tscv2.split(X):\n        for train4, test4 in tscv4.split(X):\n            assert_array_equal(train1, train4)\n            assert_array_equal(test1, test4)\n\n    with pytest.raises(AssertionError):\n        for train1, test1 in tscv1.split(X):\n            for train2, test2 in tscv2.split(X):\n                assert_array_equal(train1, train2)\n                assert_array_equal(test1, test2)\n", "def test_predefined_split():\n    # Test predefined split with multiple groups\n    X = np.ones((6, 3))\n    y = np.array([1, 1, 2, 2, 3, 3])\n    test_fold = np.array([0, 0, 1, 1, 2, -1])\n    ps = PredefinedSplit(test_fold)\n    expected_splits = [([1, 2, 3, 4, 5], [0, 1]),\n                       ([0, 1, 3, 4, 5], [2, 3]),\n                       ([0, 1, 2, 3, 4], [5])]\n    splits = list(ps.split(X, y))\n    np.testing.assert_array_equal(splits, expected_splits)\n", "def test_split_class_repr(SplitClass):\n    # Test repr when all parameters are set\n    split = SplitClass(2, shuffle=True, random_state=42)\n    if SplitClass in [KFold, StratifiedKFold]:\n        expected_repr = \"{}(n_splits=2, shuffle=True, random_state=42)\"\n    else:\n        expected_repr = \"{}(n_splits=2, n_repeats=10, random_state=42)\"\n    assert repr(split) == expected_repr.format(SplitClass.__name__)\n\n    # Test repr when shuffle is False\n    split = SplitClass(2, shuffle=False, random_state=42)\n    if SplitClass in [KFold, StratifiedKFold]:\n        expected_repr = \"{}(n_splits=2, shuffle=False, random_state=42)\"\n    else:\n        expected_repr = \"{}(n_splits=2, n_repeats=10, random_state=42)\"\n    assert repr(split) == expected_repr.format(SplitClass.__name__)\n\n    # Test repr when random_state is None\n    split = SplitClass(2, shuffle=True, random_state=None)\n    if SplitClass in [KFold, StratifiedKFold]:\n        expected_repr = \"{}(n_splits=2, shuffle=True, random_state=None)\"\n    else:\n        expected_repr = \"{}(n_splits=2, n_repeats=10, random_state=None)\"\n    assert repr(split) == expected_repr.format(SplitClass.__name__)\n", "def test_stratified_kfold_y_type():\n    # Check that StratifiedKFold works with 1d y\n    X = np.arange(5)\n    y_int = np.array([0, 0, 0, 1, 1])\n    y_float = np.array([0., 0., 0., 1., 1.])\n    y_str = np.array(['a', 'a', 'a', 'b', 'b'])\n\n    cv = StratifiedKFold(n_splits=2)\n\n    for y in (y_int, y_float, y_str):\n        splits = list(cv.split(X, y))\n        assert len(splits) == 2\n        for train, test in splits:\n            assert_array_equal(y[train], [0, 0, 0, 1])\n            assert_array_equal(y[test], [1, 1])\n\n    # Check that StratifiedKFold works with 2d y\n    y_int_2d = y_int.reshape(-1, 1)\n    y_float_2d = y_float.reshape(-1, 1)\n    y_str_2d = y_str.reshape(-1, 1)\n\n    for y in (y_int_2d, y_float_2d, y_str_2d):\n        splits = list(cv.split(X, y))\n        assert len(splits) == 2\n        for train, test in splits:\n            assert_array_equal(y[train], [[0], [0], [0], [1]])\n            assert_array_equal(y[test], [[1], [1]])\n", "def test_stratified_shuffle_split_sample_weights():\n    y = np.array([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2])\n    test_size = 5\n    train_size = 10\n    sss = StratifiedShuffleSplit(6, test_size=test_size, train_size=train_size,\n                                 random_state=0).split(np.ones(len(y)), y)\n\n    # Check that the weights are consistent with the stratification\n    sample_weights = [0.2, 0.2, 0.2, 0.2, 0.2]\n    y_train = [y[i] for i, w in enumerate(sample_weights) if w == 0.2]\n    y_test = [y[i] for i, w in enumerate(sample_weights) if w == 0.1]\n\n    for train, test in sss:\n        train_weights = np.asarray([sample_weights[i] for i in train])\n        test_weights = np.asarray([sample_weights[i] for i in test])\n\n        # Check that the weights are consistent with the stratification\n        assert_allclose(np.bincount(y_train) / len(train_weights),\n                        np.bincount(y) / len(sample_weights))\n        assert_allclose(np.bincount(y_test) / len(test_weights),\n                        np.bincount(y) / len(sample_weights))\n"], "sample_110": ["def test_affinity_propagation_sparse_input():\n    # Test that AffinityPropagation accepts sparse input\n    X_sparse = csr_matrix(X)\n    af = AffinityPropagation()\n    labels_sparse = af.fit_predict(X_sparse)\n    labels_dense = af.fit_predict(X)\n    assert_array_equal(labels_sparse, labels_dense)\n", "def test_affinity_propagation_sparse_affinity_matrix():\n    # Test Affinity Propagation with sparse affinity matrix\n    S = csr_matrix(np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]]))\n    preference = np.median(S.data)\n    cluster_centers_indices, labels = affinity_propagation(\n        S, preference=preference, copy=False)\n\n    af = AffinityPropagation(preference=preference, affinity=\"precomputed\")\n    labels_precomputed = af.fit(S).labels_\n\n    assert_array_equal(labels, labels_precomputed)\n\n    cluster_centers_indices = af.cluster_centers_indices_\n\n    n_clusters_ = len(cluster_centers_indices)\n    assert np.unique(labels).size == n_clusters_\n", "def test_affinity_propagation_affinity_matrix_symmetry():\n    # Test that affinity matrix must be symmetric.\n    X = np.array([[0, 0], [1, 1]])\n    S = np.array([[0, 2], [1, 0]])\n    with pytest.raises(ValueError):\n        affinity_propagation(S)\n    \n    af = AffinityPropagation(affinity=\"precomputed\")\n    with pytest.raises(ValueError):\n        af.fit(S)\n", "def test_affinity_propagation_input_validation():\n    # Test input validation\n    with pytest.raises(ValueError):\n        affinity_propagation(np.array([[1, 2], [3, 4]]), damping=1.5)\n    with pytest.raises(ValueError):\n        AffinityPropagation(damping=1.5).fit(X)\n    with pytest.raises(ValueError):\n        AffinityPropagation(max_iter=0).fit(X)\n    with pytest.raises(ValueError):\n        AffinityPropagation(convergence_iter=0).fit(X)\n    with pytest.raises(ValueError):\n        AffinityPropagation(convergence_iter=20, max_iter=10).fit(X)\n    with pytest.raises(ValueError):\n        affinity_propagation(np.array([[1, 2], [3, 4]]), preference='abc')\n", "def test_affinity_propagation_edge_cases():\n    # Test edge cases for input validation\n    S = np.array([[0, 1], [1, 0]])\n    with pytest.raises(ValueError):\n        affinity_propagation(S, preference='invalid')\n    with pytest.raises(ValueError):\n        affinity_propagation(S, damping=0.4)\n    with pytest.raises(ValueError):\n        affinity_propagation(S, max_iter=-1)\n    with pytest.raises(ValueError):\n        affinity_propagation(S, convergence_iter=-1)\n\n    # Test case where S is a 1x1 matrix\n    S = np.array([[1]])\n    cluster_centers_indices, labels = affinity_propagation(S)\n    assert_array_equal(cluster_centers_indices, np.array([0]))\n    assert_array_equal(labels, np.array([0]))\n\n    # Test case where S is a symmetric matrix\n    S = np.array([[1, 0], [0, 1]])\n    cluster_centers_indices, labels = affinity_propagation(S)\n    assert_array_equal(cluster_centers_indices, np.array([0, 1]))\n    assert_array_equal(labels, np.array([0, 1]))\n"], "sample_39": ["    def test_lazy_translation(self):\n        from django.utils.translation import gettext_lazy\n        descriptor = LocaleRegexDescriptor('pattern')\n        descriptor.pattern = gettext_lazy('hello')\n        self.assertEqual(descriptor.regex.pattern, '^hello$')\n", "    def test_regex_pattern_repr(self):\n        pattern = RegexPattern(r'^/test/$', name='test-name')\n        self.assertEqual(repr(pattern), \"<RegexPattern '^/test/$' [name='test-name']>\")\n", "    def test_check_pattern_startswith_slash(self):\n        # test that CheckURLMixin._check_pattern_startswith_slash returns a warning\n        # when the pattern starts with a slash\n        pattern = RegexPattern(r'^/test/')\n        self.assertEqual(len(pattern.check()), 1)\n", "    def setUp(self):\n        from django.utils.translation import activate\n        self._original_lang = activate('en')\n", "    def test_empty_language_prefix(self):\n        \"\"\"\n        LocalePrefixPattern's regex property should return an empty string when\n        the current language is the LANGUAGE_CODE and prefix_default_language is\n        False.\n        \"\"\"\n        with override_settings(LANGUAGE_CODE='en'):\n            locale_prefix_pattern = LocalePrefixPattern(prefix_default_language=False)\n            with self.settings(LANGUAGE_CODE='en'):\n                self.assertEqual(locale_prefix_pattern.regex.pattern, '')\n            with self.settings(LANGUAGE_CODE='fr'):\n                self.assertEqual(locale_prefix_pattern.regex.pattern, '^fr/')\n"]}, "raw_scored_generations": {"sample_3": [false, false, false, false, false], "sample_2": [true, true, false, false, false], "sample_1": [false, true, false, false, false], "sample_0": [true, true, true, true, false], "sample_6": [false, false, false, true, false], "sample_4": [false, false, false, false, false], "sample_5": [false, false, true, false, true], "sample_7": [true, false, false, false, false], "sample_9": [true, false, false, false, false], "sample_8": [false, false, false, true, false], "sample_10": [true, true, true, true, true], "sample_11": [true, true, true, true, false], "sample_13": [false, false, false, false, false], "sample_12": [true, true, true, true, true], "sample_14": [false, true, false, false, false], "sample_15": [true, true, true, false, true], "sample_16": [false, true, false, false, false], "sample_17": [false, true, false, false, true], "sample_18": [true, true, false, false, false], "sample_19": [false, false, false, false, false], "sample_21": [false, true, false, true, false], "sample_20": [true, true, false, false, false], "sample_23": [true, true, true, true, true], "sample_22": [true, false, true, true, false], "sample_24": [true, true, true, true, true], "sample_25": [true, true, false, false, true], "sample_28": [false, false, false, false, false], "sample_26": [false, false, false, true, false], "sample_27": [true, true, true, true, true], "sample_29": [true, false, false, false, false], "sample_31": [true, false, false, false, true], "sample_30": [false, false, false, true, false], "sample_32": [true, true, true, false, false], "sample_33": [true, false, false, false, false], "sample_34": [false, false, false, false, false], "sample_35": [false, false, false, false, false], "sample_36": [true, false, true, true, true], "sample_37": [false, false, false, false, true], "sample_39": [false, false, false, false, false], "sample_38": [false, false, false, false, false], "sample_40": [true, true, true, false, false], "sample_42": [true, true, true, false, true], "sample_41": [true, true, true, false, true], "sample_43": [true, true, true, true, true], "sample_45": [false, false, false, false, false], "sample_44": [true, true, false, true, false], "sample_46": [false, false, false, false, false], "sample_48": [true, true, true, true, false], "sample_47": [false, true, false, true, true], "sample_50": [true, true, true, true, true], "sample_49": [true, true, true, true, true], "sample_51": [true, true, true, true, true], "sample_52": [true, true, true, true, false], "sample_53": [true, true, true, false, true], "sample_55": [true, false, false, true, true], "sample_54": [true, true, true, true, true], "sample_56": [false, false, false, true, true], "sample_58": [true, true, true, true, true], "sample_57": [true, true, false, true, true], "sample_60": [true, true, false, false, true], "sample_59": [true, true, true, true, true], "sample_61": [true, true, true, true, true], "sample_63": [false, false, false, true, true], "sample_62": [true, false, false, false, false], "sample_64": [true, true, true, true, false], "sample_66": [true, true, true, true, true], "sample_65": [false, false, false, false, false], "sample_68": [false, false, true, true, true], "sample_67": [true, true, false, false, true], "sample_69": [false, true, false, false, false], "sample_70": [false, true, false, false, false], "sample_71": [true, false, true, false, false], "sample_72": [true, false, false, false, false], "sample_73": [false, false, false, false, false], "sample_74": [false, true, false, true, false], "sample_75": [false, true, false, false, false], "sample_76": [false, false, false, false, false], "sample_77": [true, false, false, false, false], "sample_78": [false, false, false, false, false], "sample_79": [false, false, false, false, false], "sample_80": [false, true, true, false, false], "sample_82": [false, false, true, false, false], "sample_81": [false, false, false, false, false], "sample_83": [false, false, false, false, false], "sample_84": [false, false, true, true, true], "sample_85": [false, false, false, false, false], "sample_86": [false, false, false, false, false], "sample_87": [true, false, false, false, true], "sample_88": [false, false, false, false, false], "sample_89": [false, false, false, false, false], "sample_90": [false, false, false, false, false], "sample_91": [false, true, false, true, false], "sample_92": [false, false, false, false, true], "sample_93": [false, true, false, true, false], "sample_95": [false, false, false, false, false], "sample_94": [false, false, false, false, false], "sample_96": [false, false, false, false, false], "sample_97": [false, true, true, false, false], "sample_98": [false, false, false, false, false], "sample_99": [true, true, false, false, true], "sample_100": [true, false, false, false, false], "sample_101": [false, false, false, false, true], "sample_102": [false, false, false, false, false], "sample_103": [true, false, false, false, false], "sample_104": [false, false, false, false, false], "sample_105": [false, false, false, true, false], "sample_107": [false, true, false, false, false], "sample_106": [true, false, true, true, false], "sample_108": [true, true, false, false, false], "sample_109": [false, false, false, false, false], "sample_110": [true, false, false, false, false], "sample_111": [false, false, false, false, false], "sample_112": [true, false, true, true, false], "sample_113": [false, false, false, false, false], "sample_114": [false, false, false, false, false], "sample_115": [true, false, false, false, false], "sample_116": [false, false, false, false, false], "sample_117": [true, false, false, false, false], "sample_118": [false, true, false, true, false], "sample_119": [true, false, false, false, false], "sample_120": [false, false, false, false, false], "sample_121": [false, false, false, false, false], "sample_122": [false, false, true, false, true], "sample_123": [true, true, false, false, false], "sample_124": [false, false, false, false, false], "sample_125": [false, false, false, false, false], "sample_126": [true, false, false, false, false], "sample_127": [true, true, false, false, false], "sample_128": [false, false, false, false, false], "sample_129": [true, false, false, true, true], "sample_130": [false, true, false, true, false], "sample_131": [false, true, false, false, false], "sample_132": [false, false, false, false, false], "sample_133": [false, false, false, false, false], "sample_134": [true, true, true, true, true], "sample_135": [false, false, false, false, false], "sample_136": [false, false, false, false, false], "sample_137": [false, false, true, false, false], "sample_138": [false, false, false, false, false], "sample_139": [true, false, false, false, false], "sample_140": [true, true, false, true, false], "sample_142": [true, false, false, false, false], "sample_141": [false, false, false, false, false], "sample_143": [false, false, false, false, false], "sample_144": [true, false, true, true, true], "sample_145": [false, false, false, false, false], "sample_146": [false, true, true, false, true], "sample_147": [false, false, false, false, false], "sample_148": [true, false, false, false, false], "sample_149": [false, false, false, false, false], "sample_150": [false, false, false, false, false], "sample_151": [false, true, false, true, false], "sample_152": [false, false, false, false, false], "sample_153": [true, true, true, false, false], "sample_154": [false, true, true, false, true], "sample_155": [false, false, false, false, false], "sample_156": [false, false, false, false, false], "sample_157": [false, false, false, false, false], "sample_158": [false, false, false, false, true], "sample_159": [false, false, false, false, false]}}