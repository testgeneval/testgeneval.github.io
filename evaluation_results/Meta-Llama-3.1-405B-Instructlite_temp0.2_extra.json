{"raw_generations": {"sample_97": ["def test_label_binarize_empty_input():\n    y = []\n    classes = [0, 1, 2]\n    pos_label = 1\n    neg_label = 0\n\n    lb = LabelBinarizer(neg_label=neg_label, pos_label=pos_label)\n    binarized = lb.fit_transform(y)\n    assert_array_equal(binarized, np.array([]))\n    assert_array_equal(lb.classes_, classes)\n\n    binarized = label_binarize(y, classes, neg_label=neg_label,\n                               pos_label=pos_label)\n    assert_array_equal(binarized, np.array([]))\n"], "sample_37": ["    def test_combine(self):\n        q1 = Q(x=1)\n        q2 = Q(y=2)\n        combined = q1 & q2\n        self.assertEqual(combined.children, [q1, q2])\n        self.assertEqual(combined.connector, Q.AND)\n\n        combined = q1 | q2\n        self.assertEqual(combined.children, [q1, q2])\n        self.assertEqual(combined.connector, Q.OR)\n"], "sample_7": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertTrue(mocked_termios.tcgetattr.called)\n        self.assertTrue(mocked_termios.tcsetattr.called)\n"], "sample_150": ["def test_solve_generic():\n    assert solve_generic([Poly(x - 1, x)], Options((x,), {'domain': 'ZZ'})) == [(1,)]\n\n    assert solve_generic([Poly(y - x, x, y), Poly(y - x - 1, x, y)], Options((x, y), {'domain': 'ZZ'})) is None\n\n    assert solve_generic([Poly(y - x**2, x, y), Poly(y + x**2, x, y)], Options((x, y), {'domain': 'ZZ'})) == [(0, 0)]\n\n    assert solve_generic([Poly(2*x - 3, x), Poly(y*Rational(3, 2) - 2*x, x, y), Poly(z - 5*y, x, y, z)], Options((x, y, z), {'domain': 'QQ'})) == \\\n        [(Rational(3, 2), Integer(2), Integer(10))]\n"], "sample_84": ["def test_fixture_function_with_yield_and_return(testdir):\n    \"\"\"Check if a fixture function with both yield and return statements raises an error (#4545)\"\"\"\n\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            yield 1\n            return 2\n\n            pass\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\"*Fixture functions cannot use 'yield' and 'return' simultaneously*\"]\n    )\n"], "sample_47": ["def test_migration_plan_with_replaced_migrations(self):\n    \"\"\"\n    Tests that replaced migrations are properly handled in the migration plan.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Create a graph with a replaced migration\n    graph = MigrationGraph()\n    graph.add_node((\"migrations\", \"0001_initial\"), FakeMigration(\"0001_initial\"))\n    graph.add_node((\"migrations\", \"0002_second\"), FakeMigration(\"0002_second\"))\n    graph.add_node((\"migrations\", \"0003_third\"), FakeMigration(\"0003_third\"))\n    graph.add_dependency(None, (\"migrations\", \"0002_second\"), (\"migrations\", \"0001_initial\"))\n    graph.add_dependency(None, (\"migrations\", \"0003_third\"), (\"migrations\", \"0002_second\"))\n    graph.add_replacement((\"migrations\", \"0002_second\"), [(\"migrations\", \"0002.5_replace_second\")])\n    executor.loader.graph = graph\n\n    # Test that the replaced migration is not included in the plan\n    plan = executor.migration_plan([(\"migrations\", \"0003_third\")])\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n            (executor.loader.graph.nodes[\"migrations\", \"0002.5_replace_second\"], False),\n            (executor.loader.graph.nodes[\"migrations\", \"0003_third\"], False),\n        ],\n    )\n"], "sample_61": ["def test_non_uniform_grouping(self):\n    self.assertEqual(\n        nformat(123456789, \".\", grouping=(3, 2, 0), thousand_sep=\",\", force_grouping=True),\n        \"12,34,56,789\"\n    )\n    self.assertEqual(\n        nformat(123456789, \".\", grouping=(3, 2), thousand_sep=\",\", force_grouping=True),\n        \"123,45,6789\"\n    )\n    self.assertEqual(\n        nformat(123456789, \".\", grouping=(2, 3), thousand_sep=\",\", force_grouping=True),\n        \"12,345,6789\"\n    )\n"], "sample_9": ["    def test_ensure_echo_on_calls_tcsetattr(self, mocked_termios):\n        with mock.patch('sys.stdin.isatty', return_value=True):\n            autoreload.ensure_echo_on()\n        self.assertEqual(mocked_termios.tcsetattr.call_count, 1)\n"], "sample_146": ["def test_printing_str_elementwiseapplyfunction():\n    from sympy.tensor.array.expressions import ArraySymbol, ElementwiseApplyFunction\n    X = ArraySymbol(\"X\", (2, 3))\n    func = Lambda(x, x**2)\n    expr = ElementwiseApplyFunction(func, X)\n    assert sstr(expr) == \"Lambda(x, x**2).(X)\"\n"], "sample_3": ["def test_separable_single_input_multi_output():\n    model = models.Polynomial1D(1, n_outputs=2)\n    assert not np.any(is_separable(model))\n    assert np.all(separability_matrix(model) == np.ones((2, 1)))\n"], "sample_8": ["    def test_cleanse_setting_callable(self):\n            return \"This should not be displayed\"\n        cleansed = cleanse_setting('SETTING_NAME', callable_setting)\n        self.assertIsInstance(cleansed, CallableSettingWrapper)\n        self.assertEqual(repr(cleansed), repr(callable_setting))\n"], "sample_133": ["def test_julia_codegen():\n    x, y, z = symbols('x,y,z')\n    expr = (x + y)*z\n    result = codegen((\"test\", expr), \"julia\", \"file\", header=False, empty=False)\n    expected = [\n        (\"file.jl\",\n        \"function test(x, y, z)\\n\"\n        \"   return z*(x + y)\\n\"\n        \"end\\n\"),\n    ]\n    assert result == expected\n"], "sample_105": ["def test_voting_regressor_get_params():\n    \"\"\"Check get_params method of VotingRegressor.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor()\n    ereg = VotingRegressor(estimators=[('lr', reg1), ('rf', reg2)])\n    params = ereg.get_params()\n    assert 'estimators' in params\n    assert 'lr' in params\n    assert 'rf' in params\n    assert params['lr'] is reg1\n    assert params['rf'] is reg2\n    assert params['lr__n_jobs'] is None\n    assert params['rf__n_estimators'] == 100\n"], "sample_59": ["def test_formset_template_name(self):\n    \"\"\"Formset's template_name is set to the renderer's formset_template_name.\"\"\"\n    ChoiceFormSet = formset_factory(Choice)\n    self.assertEqual(\n        ChoiceFormSet().template_name, get_default_renderer().formset_template_name\n    )\n"], "sample_141": ["def test_check_dimensions():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n    w = Quantity(\"w\")\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    w.set_global_relative_scale_factor(S(2), second)\n\n    assert check_dimensions(u + v) == u + v\n    assert check_dimensions(u - v) == u - v\n    raises(ValueError, lambda: check_dimensions(u + w))\n    raises(ValueError, lambda: check_dimensions(u - w))\n    raises(ValueError, lambda: check_dimensions(u + 1))\n    raises(ValueError, lambda: check_dimensions(u - 1))\n    raises(ValueError, lambda: check_dimensions(1 - exp(u / w)))\n"], "sample_140": ["def test_point_vel_with_intermediate_frame():\n    t = dynamicsymbols._t\n    q, q1, u = dynamicsymbols('q q1 u')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    O = Point('O')\n    O.set_vel(N, u * N.x)\n    P = Point('P')\n    P.set_pos(O, q1 * B.x)\n    raises(ValueError, lambda: P.vel(N))\n    B.set_ang_vel(N, q * B.z)\n    assert P.vel(N) == u * N.x + q1.diff(t) * B.x + q * q1 * B.y\n"], "sample_38": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = '!'\n        html = widget.render(name='password', value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_20": ["    def test_model_attribute(self):\n        class Model(models.Model):\n            pass\n\n        self.assertEqual(Model.check(), [])\n"], "sample_98": ["def test_check_X_y():\n    # Test that X and y are checked consistently\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_csr = sp.csr_matrix(X)\n    y_csr = sp.csr_matrix(y.reshape(-1, 1))\n\n    # check X and y as arrays\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    # check X as csr and y as array\n    X_checked, y_checked = check_X_y(X_csr, y)\n    assert_array_equal(X_checked.toarray(), X)\n    assert_array_equal(y_checked, y)\n\n    # check X as array and y as csr\n    X_checked, y_checked = check_X_y(X, y_csr)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked.toarray().ravel(), y)\n\n    # check X and y as csr\n    X_checked, y_checked = check_X_y(X_csr, y_csr)\n    assert_array_equal(X_checked.toarray(), X)\n    assert_array_equal(y_checked.toarray().ravel(), y)\n"], "sample_45": ["    def test_sync_and_async_middleware(self):\n        @sync_and_async_middleware\n            return get_response\n\n        self.assertTrue(my_middleware.sync_capable)\n        self.assertTrue(my_middleware.async_capable)\n"], "sample_49": ["def test_get_template_directories_with_loader_without_get_dirs(self):\n    self.assertSetEqual(\n        autoreload.get_template_directories(),\n        {\n            EXTRA_TEMPLATES_DIR,\n            ROOT / 'templates',\n        }\n    )\n"], "sample_5": ["def test_collector_sort(self):\n    # Create some objects with dependencies between them.\n    r = R.objects.create()\n    s1 = S.objects.create(r=r)\n    s2 = S.objects.create(r=r)\n    t1 = T.objects.create(s=s1)\n    t2 = T.objects.create(s=s2)\n\n    collector = Collector(using='default')\n    collector.add([t1, t2])\n    collector.add([s1, s2])\n    collector.add([r])\n\n    # Before sorting, the order is arbitrary.\n    self.assertEqual(set(collector.data.keys()), {T, S, R})\n\n    collector.sort()\n\n    # After sorting, the order should respect dependencies.\n    self.assertEqual(list(collector.data.keys()), [T, S, R])\n"], "sample_156": ["def test_parser_mathematica_function():\n    parser = MathematicaParser()\n\n    convert_chain = lambda expr: parser._from_tokens_to_fullformlist(parser._from_mathematica_to_tokens(expr))\n\n    # Test function with multiple arguments\n    assert convert_chain(\"f[x, y, z]\") == [\"f\", \"x\", \"y\", \"z\"]\n\n    # Test function with no arguments\n    assert convert_chain(\"f[]\") == [\"f\"]\n\n    # Test function with nested functions\n    assert convert_chain(\"f[g[x], h[y]]\") == [\"f\", [\"g\", \"x\"], [\"h\", \"y\"]]\n\n    # Test function with prefix operator\n    assert convert_chain(\"!f[x]\") == [\"Not\", [\"f\", \"x\"]]\n\n    # Test function with postfix operator\n    assert convert_chain(\"f[x]'\") == [\"Derivative\", [\"f\", \"x\"]]\n\n    # Test function with infix operator\n    assert convert_chain(\"f[x] + g[y]\") == [\"Plus\", [\"f\", \"x\"], [\"g\", \"y\"]]\n"], "sample_158": ["def test_get_units_non_prefixed():\n    assert set(SI.get_units_non_prefixed()) == {\n        meter, second, joule, kilogram, coulomb, volt, ohm, farad, henry,\n        siemens, weber, tesla, newton, pascal, hertz, radian, steradian,\n        lux, watt, gray, sievert, katal, kelvin, mole, ampere\n    }\n"], "sample_55": ["def test_command_error_returncode(self):\n    \"\"\"Test that CommandError takes an optional returncode parameter.\"\"\"\n    e = CommandError(\"An error occurred\", returncode=42)\n    self.assertEqual(e.returncode, 42)\n    e = CommandError(\"An error occurred\")\n    self.assertEqual(e.returncode, 1)\n"], "sample_95": ["def test_xfail_strict_with_condition(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(condition=True, reason=\"expected failure\", strict=True)\n            assert True\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-rxX\")\n    result.stdout.fnmatch_lines([\"*XPASS(strict)*expected failure*\"])\n    assert result.ret == 1\n"], "sample_106": ["def test_components_shape():\n    \"\"\"Test that the learned components have the expected shape.\"\"\"\n    X = iris_data\n    y = iris_target\n\n    nca = NeighborhoodComponentsAnalysis(n_components=2)\n    nca.fit(X, y)\n\n    assert nca.components_.shape == (2, X.shape[1])\n"], "sample_90": ["def test_mark_evaluator_get_closest_marker(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parent\n        class TestParent(object):\n            @pytest.mark.child\n                pass\n\n                pass\n        \"\"\"\n    )\n    items, _ = testdir.inline_genitems()\n    child_item, parent_item = items\n    assert child_item.get_closest_marker(\"child\").name == \"child\"\n    assert child_item.get_closest_marker(\"parent\").name == \"parent\"\n    assert parent_item.get_closest_marker(\"parent\").name == \"parent\"\n    assert parent_item.get_closest_marker(\"child\") is None\n"], "sample_85": ["def test_log_file_format(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = INFO\n        log_file_format = %(asctime)s %(levelname)s %(message)s\n        log_file_date_format = %Y-%m-%d %H:%M:%S\n        \"\"\".format(\n            log_file\n        )\n    )\n\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logging.getLogger().info(\"Normal message\")\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file, encoding=\"utf-8\") as rfh:\n        contents = rfh.read()\n        assert re.match(r\"\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} INFO Normal message\", contents)\n"], "sample_132": ["def test_are_coplanar():\n    from sympy.geometry import Point3D, Line3D, Plane\n\n    # All points are coplanar\n    p1 = Point3D(0, 0, 0)\n    p2 = Point3D(1, 1, 1)\n    p3 = Point3D(2, 2, 2)\n    assert are_coplanar(p1, p2, p3) == True\n\n    # Not all points are coplanar\n    p4 = Point3D(1, 2, 3)\n    assert are_coplanar(p1, p2, p4) == False\n\n    # All lines are coplanar\n    l1 = Line3D(p1, p2)\n    l2 = Line3D(p2, p3)\n    assert are_coplanar(l1, l2) == True\n\n    # Not all lines are coplanar\n    l3 = Line3D(p1, p4)\n    assert are_coplanar(l1, l3) == False\n\n    # All entities are coplanar (Plane and points)\n    plane = Plane(p1, p2, p3)\n    assert are_coplanar(plane, p1, p2, p3) == True\n\n    # Not all entities are coplanar (Plane and point)\n    assert are_coplanar(plane, p4) == False\n"], "sample_27": ["def test_token_with_invalid_timestamp(self):\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    ts_b36, _ = tk1.split(\"-\")\n    # Try to parse a token with an invalid timestamp\n    try:\n        base36_to_int(' invalid' + ts_b36[7:])\n    except ValueError:\n        pass\n    else:\n        self.fail(\"base36_to_int should have raised a ValueError\")\n    # Try to check a token with an invalid timestamp\n    self.assertIs(p0.check_token(user, ' invalid' + tk1[7:]), False)\n"], "sample_144": ["def test_refine_Pow_non_integer():\n    x = Symbol('x', real=True)\n    assert refine((-1)**(x/2), Q.even(x)) == 1\n    assert refine((-1)**(x/2), Q.odd(x)) == -I\n    assert refine((-1)**(x/3), Q.integer(x)) == (-1)**(x/3)\n"], "sample_31": ["def test_shell_with_no_interfaces_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import python interface.\"):\n        call_command('shell')\n"], "sample_64": ["def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should create a list of\n    prepopulated fields for the admin form and inlines.\n    \"\"\"\n    request = self.request_factory.get(\n        reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n    )\n    request.user = self.superuser\n    admin = UserAdmin(User, site)\n    response = admin.change_view(request, str(self.superuser.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIn(\"prepopulated_fields\", template_context)\n    self.assertIn(\"prepopulated_fields_json\", template_context)\n    self.assertIsInstance(template_context[\"prepopulated_fields\"], list)\n    self.assertIsInstance(template_context[\"prepopulated_fields_json\"], str)\n"], "sample_86": ["def test_xfail_strict_with_custom_reason(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(strict=True, reason=\"Custom reason\")\n            pass\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    node = dom.find_first_by_tag(\"testsuite\")\n    tnode = node.find_first_by_tag(\"testcase\")\n    fnode = tnode.find_first_by_tag(\"failure\")\n    fnode.assert_attr(message=\"[XPASS(strict)] Custom reason\")\n"], "sample_76": ["def test_insufficient_unique_x(self, df):\n\n    groupby = GroupBy([\"group\"])\n    df[\"x\"] = np.repeat([1, 2], len(df) // 2)\n    res = PolyFit(order=2)(df, groupby, \"x\", {})\n\n    assert res.columns.to_list() == [\"x\", \"y\", \"group\"]\n\n    for _, part in res.groupby(\"group\"):\n        assert_array_equal(part[\"x\"], [])\n        assert_array_equal(part[\"y\"], [])\n"], "sample_19": ["    def test_get_traceback_data(self):\n        try:\n            request = self.rf.get('/test_view/')\n            raise ValueError(\"Can't find my keys\")\n        except ValueError:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIn('request', data)\n        self.assertIn('request_meta', data)\n        self.assertIn('filtered_POST_items', data)\n        self.assertIn('settings', data)\n        self.assertIn('sys_executable', data)\n        self.assertIn('sys_version_info', data)\n        self.assertIn('server_time', data)\n        self.assertIn('django_version_info', data)\n        self.assertIn('sys_path', data)\n        self.assertIn('template_info', data)\n        self.assertIn('template_does_not_exist', data)\n        self.assertIn('postmortem', data)\n"], "sample_118": ["def test_ccode_For_nested():\n    f = For(x, Range(0, 10, 2), [For(y, Range(1, 5), [aug_assign(z, '+', x + y)])])\n    sol = ccode(f)\n    assert sol == (\"for (x = 0; x < 10; x += 2) {\\n\"\n                   \"   for (y = 1; y < 5; y++) {\\n\"\n                   \"      z += x + y;\\n\"\n                   \"   }\\n\"\n                   \"}\")\n"], "sample_152": ["def test_array_rank():\n    for ArrayType in array_types:\n        test_array = ArrayType([1, 2, 3])\n        assert test_array.rank() == 1\n\n        test_array = ArrayType([[1, 2], [3, 4]])\n        assert test_array.rank() == 2\n\n        test_array = ArrayType([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n        assert test_array.rank() == 3\n"], "sample_154": ["def test_lambdify_with_cse():\n    f = lambdify(x, sin(x) + cos(x), cse=True)\n    assert abs(f(1) - (sin(1) + cos(1)).evalf()) < 1e-15\n"], "sample_51": ["def test_was_modified_since_overflow(self):\n    \"\"\"\n    was_modified_since handles an overflow when parsing the If-Modified-Since header (#32553).\n    \"\"\"\n    mtime = 1643723900\n    header = \"Mon, 31 Jan 2038 23:59:00 GMT\"\n    self.assertTrue(was_modified_since(header, mtime))\n"], "sample_17": ["    def test_clone_test_db(self, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        with mock.patch.object(creation, '_clone_test_db') as mocked_clone:\n            creation.clone_test_db(suffix='test_suffix', verbosity=0, autoclobber=True, keepdb=False)\n            mocked_clone.assert_called_once_with('test_suffix', 0, False)\n"], "sample_130": ["def test_lambdify_with_integer_types():\n    f = lambdify(x, x**2)\n    assert f(2) == 4\n    assert f(2.0) == 4.0\n    assert f(int(2)) == 4\n    assert f(float(2)) == 4.0\n"], "sample_116": ["def test_create_index_with_group_entries(app):\n    text = (\".. index:: docutils\\n\"\n            \".. index:: Python\\n\"\n            \".. index:: pip; install\\n\"\n            \".. index:: pip; upgrade\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder, group_entries=False)\n    assert len(index) == 4\n    assert index[0] == ('D', [('docutils', [[('', '#index-0')], [], None])])\n    assert index[1] == ('P', [('pip', [[], [('install', [('', '#index-2')])], None]),\n                              ('pip', [[], [('upgrade', [('', '#index-3')])], None]),\n                              ('Python', [[('', '#index-1')], [], None])])\n"], "sample_40": ["def test_boundfield_widget_type(self):\n    class MyForm(Form):\n        field1 = CharField()\n        field2 = IntegerField()\n        field3 = DateField()\n\n    form = MyForm()\n    self.assertEqual(form['field1'].widget_type, 'text')\n    self.assertEqual(form['field2'].widget_type, 'number')\n    self.assertEqual(form['field3'].widget_type, 'date')\n"], "sample_73": ["def test_auxtransformbox():\n    fig, ax = plt.subplots()\n    aux_transform = mtransforms.Affine2D().translate(10, 20)\n    box = AuxTransformBox(aux_transform)\n    child = TextArea(\"Hello\")\n    box.add_artist(child)\n    ax.add_artist(box)\n    fig.canvas.draw()\n    assert not fig.stale\n    box.remove()\n    assert not fig.stale\n"], "sample_54": ["def test_urlize_trailing_punctuation(self):\n    tests = (\n        (\"Check out www.google.com.\", 'Check out <a href=\"http://www.google.com\">www.google.com</a>.'),\n        (\"Check out www.google.com!\", 'Check out <a href=\"http://www.google.com\">www.google.com</a>!'),\n        (\"Check out www.google.com?\", 'Check out <a href=\"http://www.google.com\">www.google.com</a>?'),\n        (\"Check out www.google.com:\", 'Check out <a href=\"http://www.google.com\">www.google.com</a>:'),\n        (\"Check out www.google.com;\", 'Check out <a href=\"http://www.google.com\">www.google.com</a>;'),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_155": ["def test_unit_system_get_default():\n    assert UnitSystem.get_default_unit_system() == UnitSystem._unit_systems[\"SI\"]\n    assert UnitSystem.get_unit_system(\"SI\") == UnitSystem._unit_systems[\"SI\"]\n\n    with raises(ValueError):\n        UnitSystem.get_unit_system(\"NonExistentUnitSystem\")\n"], "sample_83": ["def test_colorized_text_reporter_color_mapping_deprecation() -> None:\n    \"\"\"Test that a deprecation warning is raised when passing a deprecated color mapping.\"\"\"\n    with warnings.catch_warnings(record=True) as cm:\n        warnings.simplefilter(\"always\")\n        ColorizedTextReporter(color_mapping={\"I\": (\"green\", \"bold\")})\n\n    assert len(cm) == 1\n    assert isinstance(cm[0].message, DeprecationWarning)\n"], "sample_43": ["def test_process_request_invalid_app_label(self):\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': 'invalid', 'model_name': Answer._meta.model_name, 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n"], "sample_119": ["def test_user_functions():\n    assert mcode(sin(x), user_functions={'sin': 'MySin'}) == \"MySin[x]\"\n    assert mcode(cos(x), user_functions={'cos': 'MyCos'}) == \"MyCos[x]\"\n    assert mcode(exp(x), user_functions={'exp': 'MyExp'}) == \"MyExp[x]\"\n"], "sample_88": ["def test_saferepr_recursive():\n    \"\"\"Test saferepr() with recursive objects.\"\"\"\n\n    class Recursive:\n            self.attr = None\n\n            return \"Recursive({})\".format(self.attr)\n\n    obj1 = Recursive()\n    obj2 = Recursive()\n    obj1.attr = obj2\n    obj2.attr = obj1\n\n    assert saferepr(obj1).startswith(\"Recursive(\")\n    assert saferepr(obj2).startswith(\"Recursive(\")\n"], "sample_21": ["def test_collector_sort(self):\n    # Create some objects to delete\n    r1 = R.objects.create()\n    r2 = R.objects.create()\n    s1 = S.objects.create(r=r1)\n    s2 = S.objects.create(r=r2)\n\n    # Create a collector and add the objects\n    collector = Collector(using='default')\n    collector.add([r1, r2])\n    collector.add([s1, s2])\n\n    # Sort the collector\n    collector.sort()\n\n    # Check that the objects are in the correct order for deletion\n    self.assertEqual(collector.data, {R: [r1, r2], S: [s1, s2]})\n\n    # Check that the dependencies are correct\n    self.assertEqual(collector.dependencies, {R: {S}})\n"], "sample_69": ["def test_artist_stale_callback():\n    class TestArtist(martist.Artist):\n            super().__init__()\n            self.stale_called = False\n\n            self.stale_called = True\n\n    art = TestArtist()\n    art.stale_callback = art.stale_callback\n    art.stale = True\n    assert art.stale_called\n"], "sample_58": ["def test_default_database(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env({}),\n        ([\"psql\", \"postgres\"], None),\n    )\n"], "sample_41": ["def test_formset_with_disabled_fields(self):\n    \"\"\"Formsets can handle disabled fields.\"\"\"\n    class DisabledForm(Form):\n        field = IntegerField(disabled=True)\n\n    DisabledFormSet = formset_factory(DisabledForm)\n    data = {\n        'form-TOTAL_FORMS': '1',\n        'form-INITIAL_FORMS': '0',\n        'form-0-field': '42',\n    }\n    formset = DisabledFormSet(data, prefix='form')\n    self.assertTrue(formset.is_valid())\n    self.assertEqual([{'field': 42}], formset.cleaned_data)\n"], "sample_94": ["def test_getstatementrange_ast_with_nested_functions() -> None:\n    source = Source(\n        \"\"\"\\"], "sample_91": ["def test_xfail_strict_ini(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        xfail_strict = True\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail\n            assert 1\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n    assert result.ret == 1\n"], "sample_115": ["def test__wrap_in_pandas_container_columns_none():\n    \"\"\"Check _wrap_in_pandas_container with columns=None.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    X_df = pd.DataFrame(X)\n\n    # If input is a DataFrame and columns=None, then the column names are not changed.\n    wrapped_df = _wrap_in_pandas_container(X_df, columns=None)\n    assert_array_equal(wrapped_df.columns, X_df.columns)\n\n    # If input is not a DataFrame and columns=None, then the column names are range(n_features).\n    wrapped_df = _wrap_in_pandas_container(X, columns=None)\n    assert_array_equal(wrapped_df.columns, range(X.shape[1]))\n"], "sample_15": ["def test_invalid_variant_consistent_language_settings(self):\n    tests = [\n        # language + region (region not in LANGUAGES).\n        'fr-US',\n        'es-UK',\n        'de-CN',\n        # language + script.\n        'zh-Hans',\n        # language + region + variant (variant not in LANGUAGES).\n        'ca-ES-barcelona',\n    ]\n    msg = (\n        'You have provided a value for the LANGUAGE_CODE setting that is '\n        'not in the LANGUAGES setting.'\n    )\n    for tag in tests:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [\n                Error(msg, id='translation.E004'),\n            ])\n"], "sample_12": ["def test_mti_inheritance_model_removal_with_fk(self):\n    Animal = ModelState('app', 'Animal', [\n        (\"id\", models.AutoField(primary_key=True)),\n    ])\n    Dog = ModelState('app', 'Dog', [\n        (\"owner\", models.ForeignKey(\"app.Owner\", models.CASCADE)),\n    ], bases=('app.Animal',))\n    Owner = ModelState('app', 'Owner', [\n        (\"id\", models.AutoField(primary_key=True)),\n    ])\n    changes = self.get_changes([Animal, Dog, Owner], [Animal, Owner])\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'DeleteModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, model_name='dog', name='owner')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='Dog')\n"], "sample_100": ["def test_ordinal_encoder_set_params():\n    X = np.array([[1, 2]]).T\n    enc = OrdinalEncoder()\n    # set params on not yet fitted object\n    enc.set_params(categories=[[0, 1, 2, 3]])\n    assert enc.get_params()['categories'] == [[0, 1, 2, 3]]\n    assert enc.fit_transform(X).shape == (2, 1)\n    # set params on already fitted object\n    enc.set_params(categories=[[0, 1, 2, 3, 4]])\n    assert enc.fit_transform(X).shape == (2, 1)\n"], "sample_81": ["def test_fixme_pattern_with_custom_notes_rgx(self) -> None:\n    code = \"\"\"a = 1\n            # BUG123\n            \"\"\"\n    set_config(notes_rgx=\"BUG\\\\d+\")\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"fixme\", line=2, args=\"BUG123\", col_offset=17)\n    ):\n        self.checker.open()\n        self.checker.process_tokens(_tokenize_str(code))\n"], "sample_4": ["    def test_file_response(self):\n        response = FileResponse(open(__file__, 'rb'))\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response['Content-Type'], 'text/x-python')\n        self.assertGreater(int(response['Content-Length']), 0)\n"], "sample_1": ["def test_line_type():\n    assert _line_type(\"READ SERR 3\") == \"command\"\n    assert _line_type(\" \\\\n    !some gibberish\") == \"comment\"\n    assert _line_type(\"   \") == \"comment\"\n    assert _line_type(\" 21345.45\") == \"data,1\"\n    assert _line_type(\" 21345.45 1.53e-3 1e-3 .04 NO nan\") == \"data,6\"\n    assert _line_type(\" 21345.45,1.53e-3,1e-3,.04,NO,nan\", delimiter=',') == \"data,6\"\n    assert _line_type(\" 21345.45 ! a comment to disturb\") == \"data,1\"\n    assert _line_type(\"NO NO NO NO NO\") == \"new\"\n    assert _line_type(\"NO,NO,NO,NO,NO\", delimiter=',') == \"new\"\n    with pytest.raises(ValueError):\n        _line_type(\"N O N NOON OON O\")\n    with pytest.raises(ValueError):\n        _line_type(\" some non-comment gibberish\")\n"], "sample_139": ["def test_issue_16353():\n    from sympy import symbols, I\n    x = symbols('x', real=True)\n    assert re((1 + I)*x) == x\n    assert im((1 + I)*x) == x\n"], "sample_131": ["def test_user_functions():\n    assert mcode(sin(x), user_functions={'sin': 'MySin'}) == \"MySin[x]\"\n    assert mcode(cos(x), user_functions={'cos': 'MyCos'}) == \"MyCos[x]\"\n    assert mcode(exp(x), user_functions={'exp': 'MyExp'}) == \"MyExp[x]\"\n    assert mcode(sin(x) + cos(x), user_functions={'sin': 'MySin', 'cos': 'MyCos'}) == \"MySin[x] + MyCos[x]\"\n"], "sample_29": ["    def test_combine(self):\n        q1 = Query(Employee)\n        q2 = Query(Employee)\n        combined = q1.combine(q2, 'AND')\n        self.assertEqual(combined.where.connector, 'AND')\n        self.assertEqual(len(combined.where.children), 0)\n"], "sample_62": ["    def test_path_traversal(self):\n        # Ensure that the cache backend prevents path traversal attacks.\n        cache_key = \"../test\"\n        cache.set(cache_key, \"value\")\n        self.assertIsNone(cache.get(cache_key))\n"], "sample_33": ["def test_receiver_weakref(self):\n    class WeakReceiver:\n            self.state = val\n\n    receiver = WeakReceiver()\n    weak_receiver = weakref.ref(receiver)\n    a_signal.connect(weak_receiver())\n    del receiver\n    garbage_collect()\n    result = a_signal.send(sender=self, val=\"test\")\n    self.assertEqual(result, [])\n    self.assertTestIsClean(a_signal)\n"], "sample_93": ["def test_tmp_path_factory_uses_given_basetemp(tmp_path_factory: TempPathFactory, tmp_path: Path) -> None:\n    given_basetemp = tmp_path / \"given-basetemp\"\n    given_basetemp.mkdir()\n    tmp_path_factory = TempPathFactory(given_basetemp, trace=None)\n    assert tmp_path_factory.getbasetemp() == given_basetemp\n"], "sample_120": ["def test_MatrixElement_as_coeff_Mul():\n    A = MatrixSymbol('A', 2, 2)\n    expr = A[0, 0]*A[1, 1]\n    coeff, matmul = expr.as_coeff_Mul()\n    assert coeff == 1\n    assert matmul == MatMul(A[0, 0], A[1, 1])\n"], "sample_157": ["def test_tensor_product_simp_Mul_with_Add():\n    assert tensor_product_simp(TP(A + B, C)*TP(D, E)) == TP((A + B)*D, C*E)\n    assert tensor_product_simp(TP(A, B)*TP(C + D, E)) == TP(A*(C + D), B*E)\n    assert tensor_product_simp(TP(A + B, C + D)*TP(E, F)) == TP((A + B)*E, (C + D)*F)\n"], "sample_110": ["def test_affinity_propagation_verbose():\n    # Test AffinityPropagation with verbose output\n    af = AffinityPropagation(affinity=\"euclidean\", verbose=True)\n    with pytest.raises(io.UnsupportedOperation):\n        with redirect_stdout(io.StringIO()) as f:\n            af.fit(X)\n            assert \"Converged after\" in f.getvalue()\n"], "sample_99": ["def test_kneighbors_graph_mode_distance_include_self():\n    # Test kneighbors_graph with mode='distance' and include_self=True\n    X = np.array([[0, 1], [1.01, 1.], [2, 0]])\n\n    A = neighbors.kneighbors_graph(X, 2, mode='distance', include_self=True)\n    assert_array_almost_equal(\n        A.toarray(),\n        [[0., 1.01, 2.23606798],\n         [1.01, 0., 1.40716026],\n         [2.23606798, 1.40716026, 0.]])\n"], "sample_6": ["    def test_custom_validator(self):\n        class CustomUsernameValidator(validators.RegexValidator):\n            regex = r'^[a-z0-9]+$'\n            message = 'Enter a valid username. This value may contain only lowercase letters and numbers.'\n            flags = re.ASCII\n\n        valid_usernames = ['hello', 'world123']\n        invalid_usernames = ['Hello', 'World!', 'hello world']\n\n        v = CustomUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n"], "sample_63": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = \"unusable password\"\n        html = widget.render(name=\"password\", value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_96": ["def test_ridgecv_scorer():\n    # Test that RidgeCV works with a custom scorer.\n    X, y = make_regression(n_samples=10, n_features=5, random_state=0)\n    scorer = make_scorer(mean_squared_error, greater_is_better=False)\n    ridgecv = RidgeCV(scorer=scorer)\n    ridgecv.fit(X, y)\n    assert hasattr(ridgecv, 'best_score_')\n    assert hasattr(ridgecv, 'alpha_')\n"], "sample_36": ["def test_register_lookup(self):\n    class MyLookup:\n        lookup_name = 'mylookup'\n\n    class MyModel:\n        pass\n\n    RegisterLookupMixin.register_lookup(MyLookup, MyModel)\n    self.assertIn('mylookup', RegisterLookupMixin.get_lookups())\n    self.assertEqual(RegisterLookupMixin._get_lookup('mylookup'), MyLookup)\n\n    # Test unregistering a lookup\n    RegisterLookupMixin._unregister_lookup(MyLookup)\n    self.assertNotIn('mylookup', RegisterLookupMixin.get_lookups())\n    self.assertIsNone(RegisterLookupMixin._get_lookup('mylookup'))\n"], "sample_78": ["def test_cli_group_name_collision(app):\n    \"\"\"Test that blueprints with the same CLI group name do not collide.\"\"\"\n    bp1 = Blueprint(\"bp1\", __name__, cli_group=\"group\")\n    bp2 = Blueprint(\"bp2\", __name__, cli_group=\"group\")\n\n    @bp1.cli.command(\"cmd\")\n        click.echo(\"cmd1\")\n\n    @bp2.cli.command(\"cmd\")\n        click.echo(\"cmd2\")\n\n    app.register_blueprint(bp1)\n    app.register_blueprint(bp2)\n\n    result = app.test_cli_runner().invoke(args=[\"group\", \"--help\"])\n    assert \"cmd  cmd1\" in result.output\n    assert \"cmd  cmd2\" in result.output\n"], "sample_71": ["def test_reload_library():\n    original_library = style.library.copy()\n    with temp_style('test', DUMMY_SETTINGS):\n        assert 'test' in style.library\n    style.reload_library()\n    assert style.library == original_library\n"], "sample_26": ["    def test_create_test_db_with_keepdb(self):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        with mock.patch.object(creation, '_create_test_db') as mocked_create:\n            creation.create_test_db(verbosity=0, autoclobber=True, keepdb=True)\n            mocked_create.assert_called_once_with(verbosity=0, autoclobber=True, keepdb=True)\n"], "sample_117": ["def test_stringify_type_hints_Ellipsis():\n    assert stringify(Ellipsis) == '...'\n"], "sample_87": ["def test_collect_ignore_with_absolute_path(testdir):\n    \"\"\"Test that collect_ignore works with absolute paths.\"\"\"\n    tests = testdir.mkpydir(\"tests\")\n    ignore_me = tests.mkdir(\"ignore_me\")\n    ignore_me.ensure(\"__init__.py\")\n    ignore_me.ensure(\"test_ignore.py\").write(\"def test_ignore(): pass\")\n\n    tests.ensure(\"conftest.py\").write(\n        \"import os\\n\"\n        \"collect_ignore = [os.path.abspath('ignore_me')]\\n\"\n    )\n\n    result = testdir.runpytest()\n    assert result.ret == ExitCode.NO_TESTS_COLLECTED\n"], "sample_153": ["def test_pretty_printing_mod():\n    from sympy import symbols, Mod\n    x = symbols('x')\n    assert pretty(Mod(x, 2)) == 'x mod 2'\n"], "sample_82": ["def test_groupby_fillna():\n    # Test filling NaN values in grouped DataArray\n    da = xr.DataArray(\n        [[1, 2, np.nan], [4, np.nan, 6], [np.nan, 8, 9]],\n        dims=[\"x\", \"y\"],\n        coords={\"x\": [1, 2, 3], \"y\": [1, 2, 3]},\n    )\n    filled_da = da.groupby(\"x\").fillna(0)\n    expected_da = xr.DataArray(\n        [[1, 2, 0], [4, 0, 6], [0, 8, 9]],\n        dims=[\"x\", \"y\"],\n        coords={\"x\": [1, 2, 3], \"y\": [1, 2, 3]},\n    )\n    assert_identical(filled_da, expected_da)\n\n    # Test filling NaN values in grouped Dataset\n    ds = xr.Dataset()\n    ds[\"a\"] = da\n    filled_ds = ds.groupby(\"x\").fillna(0)\n    expected_ds = xr.Dataset()\n    expected_ds[\"a\"] = expected_da\n    assert_identical(filled_ds, expected_ds)\n"], "sample_70": ["def test_legend_set_title():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [3, 4], label='line')\n    leg = ax.legend()\n    leg.set_title('New title')\n    assert leg.get_title().get_text() == 'New title'\n"], "sample_75": ["def test_grid_with_ngrids():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 3), ngrids=4)\n    assert len(grid.axes_all) == 4\n    assert len(grid.axes_row) == 2\n    assert len(grid.axes_column) == 3\n    for ax in grid.axes_all[4:]:\n        assert ax is None\n"], "sample_114": ["def test_type_of_target_sparse_multiclass():\n    # Test type_of_target with sparse multiclass data\n    y = csr_matrix(np.array([[1], [2], [3]]))\n    assert type_of_target(y) == \"multiclass\"\n\n    y = csc_matrix(np.array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]))\n    assert type_of_target(y) == \"multiclass-multioutput\"\n"], "sample_16": ["def test_unquote(self):\n    self.assertEqual(unquote('something_0Aor_0Aother'), 'something\\nor\\nother')\n    self.assertEqual(unquote('nothing'), 'nothing')\n    self.assertEqual(unquote('something_3Aor_3Aother'), 'something:or:other')\n    self.assertEqual(unquote('something_2For_2Fother'), 'something/or/other')\n"], "sample_89": ["def test_node_repr():\n    node = nodes.Node.from_parent(None, name=\"test_node\")\n    assert repr(node) == \"<Node test_node>\"\n"], "sample_13": ["    def test_fields_limit(self):\n        qs = 'a=1&b=2&c=3'\n        self.assertEqual(limited_parse_qsl(qs, fields_limit=2), [('a', '1'), ('b', '2')])\n        with self.assertRaises(TooManyFieldsSent):\n            limited_parse_qsl(qs, fields_limit=1)\n"], "sample_50": ["def test_update_cookie(self):\n    \"\"\"\n    The _update_cookie method correctly sets or deletes the cookie.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # Test setting the cookie with data\n    encoded_data = storage._encode(['message'])\n    storage._update_cookie(encoded_data, response)\n    self.assertIn(storage.cookie_name, response.cookies)\n    self.assertEqual(response.cookies[storage.cookie_name].value, encoded_data)\n\n    # Test deleting the cookie when there is no data\n    storage._update_cookie(None, response)\n    self.assertIn(storage.cookie_name, response.cookies)\n    self.assertEqual(response.cookies[storage.cookie_name]['max-age'], 0)\n"], "sample_92": ["def test_xfail_strict_with_multiple_conditions(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(strict=True, condition=\"True or False\")\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rxX\")\n    result.stdout.fnmatch_lines([\"*XPASS(strict)*\"])\n"], "sample_46": ["    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(),\n            col_suffixes=('', 'DESC'), opclasses=('int4_ops', 'text_ops')\n        )\n"], "sample_159": ["def test_prefix_properties():\n    m = PREFIXES['m']\n    k = PREFIXES['k']\n\n    assert m.name == 'milli'\n    assert m.abbrev == 'm'\n    assert m.scale_factor == S.One / 1000\n    assert m.base == 10\n\n    assert k.name == 'kilo'\n    assert k.abbrev == 'k'\n    assert k.scale_factor == S(1000)\n    assert k.base == 10\n\n    assert str(m) == 'm'\n    assert repr(m) == \"Prefix('milli', 'm', -3)\"\n"], "sample_24": ["def test_update_error_dict(self):\n    error_dict = {}\n    exception = ValidationError('message')\n    exception.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['message']})\n\n    error_dict = {}\n    exception = ValidationError({'field1': 'message'})\n    exception.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['message']})\n\n    error_dict = {'field1': ['existing message']}\n    exception = ValidationError({'field1': 'message', 'field2': 'other'})\n    exception.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['existing message', 'message'], 'field2': ['other']})\n\n    error_dict = {}\n    exception = ValidationError([\n        ValidationError({'field1': 'field error', 'field2': 'other'}),\n        'message',\n    ])\n    exception.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['field error'], 'field2': ['other'], '__all__': ['message']})\n"], "sample_147": ["def test_Function_kind():\n    from sympy.core.function import Function\n    f = Function('f')\n    assert f(comm_x).kind is NumberKind\n    assert f(noncomm_x).kind is UndefinedKind\n"], "sample_57": ["def test_formset_with_disabled_fields(self):\n    \"\"\"\n    Formsets with disabled fields should still be able to be validated.\n    \"\"\"\n\n    class DisabledForm(Form):\n        field = IntegerField(disabled=True)\n\n    data = {\n        \"form-TOTAL_FORMS\": \"1\",\n        \"form-INITIAL_FORMS\": \"0\",\n        \"form-MIN_NUM_FORMS\": \"0\",\n        \"form-MAX_NUM_FORMS\": \"0\",\n        \"form-0-field\": \"123\",\n    }\n    DisabledFormSet = formset_factory(DisabledForm)\n    formset = DisabledFormSet(data, prefix=\"form\")\n    self.assertTrue(formset.is_valid())\n    self.assertEqual([form.cleaned_data for form in formset.forms], [{\"field\": 123}])\n"], "sample_103": ["def test_mutual_info_classif_sparse():\n    # Test that sparse and dense inputs give the same results for mutual_info_classif.\n    X = np.array([[0, 0, 0],\n                  [1, 1, 0],\n                  [2, 0, 1],\n                  [2, 0, 1],\n                  [2, 0, 1]])\n    y = np.array([0, 1, 2, 2, 1])\n\n    X_sparse = csr_matrix(X)\n\n    mi_dense = mutual_info_classif(X, y, discrete_features='auto', random_state=0)\n    mi_sparse = mutual_info_classif(X_sparse, y, discrete_features='auto', random_state=0)\n\n    assert_array_equal(mi_dense, mi_sparse)\n"], "sample_101": ["def test_pipeline_get_params():\n    # Test that get_params returns all the parameters of the pipeline\n    mult2 = Mult(mult=2)\n    mult3 = Mult(mult=3)\n    pipeline = Pipeline([('m1', mult2), ('m2', mult3)])\n\n    params = pipeline.get_params()\n    assert 'm1' in params\n    assert 'm2' in params\n    assert 'm1__mult' in params\n    assert 'm2__mult' in params\n\n    # Check that parameter values are correct\n    assert params['m1'] is mult2\n    assert params['m2'] is mult3\n    assert params['m1__mult'] == 2\n    assert params['m2__mult'] == 3\n"], "sample_108": ["def test_libsvm_sparse_predict():\n    # Test that sparse predict gives the same result as dense predict\n    X, y = make_classification(n_samples=20, n_features=10, random_state=0)\n    clf = svm.SVC(kernel='linear', probability=True, random_state=0)\n    clf.fit(X, y)\n\n    X_sparse = sparse.csr_matrix(X)\n    assert_array_almost_equal(clf.predict(X), clf.predict(X_sparse))\n    assert_array_almost_equal(clf.decision_function(X), clf.decision_function(X_sparse))\n    assert_array_almost_equal(clf.predict_proba(X), clf.predict_proba(X_sparse))\n"], "sample_22": ["def test_camel_case_to_spaces(self):\n    items = [\n        ('camelCase', 'camel case'),\n        ('CamelCase', 'camel case'),\n        ('CAMELCase', 'camel case'),\n        ('_camelCase', '_camel case'),\n        ('Camel_Case', 'camel _case'),\n        ('__camel_Case__', '__camel _case__'),\n    ]\n    for value, output in items:\n        self.assertEqual(text.camel_case_to_spaces(value), output)\n        self.assertEqual(text.camel_case_to_spaces(lazystr(value)), output)\n"], "sample_44": ["def test_model_choice_iterator_value_equality(self):\n    value_1 = ModelChoiceIteratorValue(self.c1.pk, self.c1)\n    value_2 = ModelChoiceIteratorValue(self.c1.pk, None)\n    value_3 = ModelChoiceIteratorValue(self.c2.pk, self.c2)\n\n    self.assertEqual(value_1, value_2)\n    self.assertEqual(value_1, self.c1.pk)\n    self.assertNotEqual(value_1, value_3)\n    self.assertNotEqual(value_1, self.c2.pk)\n"], "sample_28": ["    def setUpTestData(cls):\n        cls.u1 = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n"], "sample_104": ["def test_indent_at_name():\n    # Test that the indent_at_name parameter is correctly used\n\n    pp = _EstimatorPrettyPrinter(compact=True, indent=1, indent_at_name=False)\n    lr = LogisticRegression()\n    expected = \"\"\""], "sample_107": ["def test_logistic_regression_path_multiclass():\n    # Test that logistic_regression_path returns the correct coefs for\n    # multiclass problems.\n    X, y = make_classification(n_samples=200, n_classes=3, n_informative=2,\n                               n_redundant=0, n_clusters_per_class=1,\n                               random_state=0, n_features=2)\n    Cs = [.00001, 1, 10000]\n    coefs, _, _ = _logistic_regression_path(X, y, penalty='l1', Cs=Cs,\n                                            solver='saga', random_state=0,\n                                            multi_class='multinomial')\n\n    # Check that the returned coefs are of the correct shape.\n    assert coefs.shape == (len(Cs), 3, 2)\n\n    # Check that the coefs for each class are not identical.\n    for i in range(len(Cs)):\n        with pytest.raises(AssertionError):\n            assert_array_almost_equal(coefs[i, 0], coefs[i, 1], decimal=1)\n        with pytest.raises(AssertionError):\n            assert_array_almost_equal(coefs[i, 0], coefs[i, 2], decimal=1)\n        with pytest.raises(AssertionError):\n            assert_array_almost_equal(coefs[i, 1], coefs[i, 2], decimal=1)\n"], "sample_34": ["    def test_model_str(self):\n        class MyModel(models.Model):\n            name = models.CharField(max_length=10)\n\n                return self.name\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n"], "sample_39": ["    def test_warning_on_unnamed_pattern(self):\n        msg = (\n            \"URL route 'unnamed-pattern' has a name including a ':'. Remove the colon, to \"\n            \"avoid ambiguous namespace references.\"\n        )\n        with self.assertWarnsMessage(Warning, msg):\n            check_resolver(get_resolver())\n"], "sample_35": ["    def test_modelform_unique_error_messages(self):\n        # Create a model form with unique and unique_together constraints.\n        from .models import UniqueModel\n\n        class UniqueForm(forms.ModelForm):\n            class Meta:\n                model = UniqueModel\n                fields = '__all__'\n                error_messages = {\n                    'name': {'unique': 'Custom name unique message'},\n                    'UNIQUE_CONSTRAINT': {'unique': 'Custom unique constraint message'},\n                }\n\n        # Test unique constraint error messages.\n        f = UniqueForm({'name': 'Taken'})\n        self.assertFormErrors(['Custom name unique message'], f.clean)\n\n        # Test unique_together constraint error messages.\n        f = UniqueForm({'name': 'Taken', 'no': '1'})\n        self.assertFormErrors(['Custom unique constraint message'], f.clean)\n"], "sample_149": ["def test_MonomialOps():\n    ops = MonomialOps(3)\n\n    assert ops.mul()( (1, 2, 3), (4, 5, 6) ) == (5, 7, 9)\n    assert ops.pow()( (1, 2, 3), 2 ) == (2, 4, 6)\n    assert ops.mulpow()( (1, 2, 3), (4, 5, 6), 2 ) == (9, 12, 15)\n    assert ops.ldiv()( (4, 5, 6), (1, 2, 3) ) == (3, 3, 3)\n    assert ops.div()( (4, 5, 6), (1, 2, 3) ) == (3, 3, 3)\n    assert ops.lcm()( (1, 2, 3), (4, 5, 6) ) == (4, 5, 6)\n    assert ops.gcd()( (1, 2, 3), (4, 5, 6) ) == (1, 2, 3)\n"], "sample_79": ["def test_concat_positions(self):\n    # Test that the positions argument works as expected\n    data = create_test_data()\n    split_data = [data.isel(dim1=slice(3)), data.isel(dim1=slice(3, None))]\n    positions = [[0, 1, 2], [3, 4, 5]]\n    actual = concat(split_data, dim=\"dim1\", positions=positions)\n    assert_identical(data, actual)\n\n    # Test that incorrect positions raise an error\n    with raises_regex(ValueError, \"Length of positions does not match\"):\n        concat(split_data, dim=\"dim1\", positions=[[0, 1], [3, 4, 5]])\n"], "sample_77": ["    def test_identity(self):\n\n        s = Scale._identity()\n        x = pd.Series([1, 2, 3], name=\"x\")\n        assert_series_equal(s(x), x)\n"], "sample_102": ["def test_iforest_fit_predict_sparse():\n    \"\"\"Test fit and predict methods with sparse data\"\"\"\n    X_train = csr_matrix(np.array([[0, 1], [1, 2]]))\n    X_test = csr_matrix(np.array([[2, 1], [1, 1]]))\n\n    clf = IsolationForest(random_state=rng)\n    clf.fit(X_train)\n    y_pred = clf.predict(X_test)\n\n    assert_array_equal(y_pred, [-1, -1])\n"], "sample_25": ["def test_alter_model_table_with_inheritance(self):\n    \"\"\"\n    AlterModelTable should be generated when a model's db_table is changed,\n    even if the model has inheritance.\n    \"\"\"\n    before = [\n        ModelState('app', 'Parent', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'Child', [], bases=('app.Parent',)),\n    ]\n    after = [\n        ModelState('app', 'Parent', [\n            ('id', models.AutoField(primary_key=True)),\n        ], options={'db_table': 'new_parent'}),\n        ModelState('app', 'Child', [], bases=('app.Parent',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['AlterModelTable'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='parent', table='new_parent')\n"], "sample_56": ["    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n"], "sample_135": ["def test_replace_issue_10237():\n    from sympy import Wild\n    x, y = symbols('x y')\n    e = (x**2 + x*y)\n    a = Wild('a')\n    b = Wild('b')\n    c = Wild('c')\n    assert e.replace(a*b, c) == e\n    assert e.replace(a*b, c, exact=False) == c\n"], "sample_74": ["def test_colorbar_set_label():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cb = fig.colorbar(im)\n    cb.set_label('Test Label')\n    assert cb.ax.get_ylabel() == 'Test Label'\n    cb.set_label(None)\n    assert cb.ax.get_ylabel() == ''\n"], "sample_48": ["def test_reduce_references_model(self):\n    operation = FieldOperation('MoDel', 'field', models.ForeignKey('Other', models.CASCADE))\n    other_operation = FieldOperation('Other', 'other_field', models.BooleanField(default=False))\n    self.assertEqual(operation.reduce(other_operation, 'migrations'), [operation, other_operation])\n    self.assertEqual(other_operation.reduce(operation, 'migrations'), [other_operation])\n"], "sample_113": ["def test_column_transformer_feature_names_out_with_callable_specifier():\n    \"\"\"Check feature names out when using a callable specifier.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X_df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\n\n        return [\"A\"]\n\n    ct = ColumnTransformer([(\"trans\", TransWithNames([\"x\", \"y\"]), selector)])\n    ct.fit(X_df)\n\n    assert_array_equal(ct.get_feature_names_out(), [\"trans__x\", \"trans__y\"])\n"], "sample_128": ["def test_build_options():\n    assert build_options((x, y, z), {'domain': 'ZZ'}) == Options((x, y, z), {'domain': 'ZZ'})\n    assert build_options({'opt': Options((x, y, z), {'domain': 'ZZ'})}) == Options((x, y, z), {'domain': 'ZZ'})\n\n    raises(OptionError, lambda: build_options((x, y, z), {'opt': Options((x, y, z), {'domain': 'ZZ'})}))\n"], "sample_68": ["def test_update_conflicts_unique_fields_update_fields_non_unique(self):\n    FieldsWithDbColumns.objects.bulk_create(\n        [\n            FieldsWithDbColumns(rank=1, name=\"a\"),\n            FieldsWithDbColumns(rank=2, name=\"b\"),\n        ]\n    )\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n\n    conflicting_objects = [\n        FieldsWithDbColumns(rank=1, name=\"c\", non_unique_field=\"x\"),\n        FieldsWithDbColumns(rank=2, name=\"d\", non_unique_field=\"y\"),\n    ]\n    results = FieldsWithDbColumns.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        unique_fields=[\"rank\"],\n        update_fields=[\"name\", \"non_unique_field\"],\n    )\n    self.assertEqual(len(results), len(conflicting_objects))\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n    self.assertCountEqual(\n        FieldsWithDbColumns.objects.values(\"rank\", \"name\", \"non_unique_field\"),\n        [\n            {\"rank\": 1, \"name\": \"c\", \"non_unique_field\": \"x\"},\n            {\"rank\": 2, \"name\": \"d\", \"non_unique_field\": \"y\"},\n        ],\n    )\n"], "sample_72": ["def test_figure_repr():\n    fig = Figure()\n    assert repr(fig) == \"<Figure size 640x480 with 0 Axes>\"\n    ax = fig.add_subplot(111)\n    assert repr(fig) == \"<Figure size 640x480 with 1 Axes>\"\n"], "sample_80": ["def test_short_data_repr(self):\n    array = np.random.randn(100, 5, 1)\n    data_array = xr.DataArray(array)\n\n    # Test with numpy array\n    result = formatting.short_data_repr(array)\n    assert len(result.splitlines()) < 50\n\n    # Test with xarray DataArray\n    result = formatting.short_data_repr(data_array)\n    assert len(result.splitlines()) < 50\n\n    # Test with dask array\n    if IS_NEP18_ACTIVE:\n        import dask.array as da\n\n        dask_array = da.from_array(array, chunks=(10, 5, 1))\n        result = formatting.short_data_repr(dask_array)\n        assert len(result.splitlines()) < 50\n"], "sample_0": ["def test_split_datetime_widget_render(self):\n    widget = SplitDateTimeWidget()\n    output = widget.render('date_time', datetime.datetime(2022, 12, 25, 10, 30))\n    self.assertIn('value=\"2022\"', output)\n    self.assertIn('value=\"12\"', output)\n    self.assertIn('value=\"25\"', output)\n    self.assertIn('value=\"10\"', output)\n    self.assertIn('value=\"30\"', output)\n"], "sample_134": ["def test_cbrt():\n    if not np:\n        skip(\"NumPy not installed\")\n    assert abs(lambdify((a,), cbrt(a), 'numpy')(27) - 3) < 1e-16\n    assert abs(lambdify((a,), Cbrt(a), 'numpy')(27) - 3) < 1e-16\n"], "sample_67": ["def test_serialize_type_with_module(self):\n    class TestType:\n        pass\n\n    self.assertSerializedResultEqual(\n        type(TestType),\n        (\"type\", set()),\n    )\n    self.assertSerializedResultEqual(\n        type,\n        (\"type\", set()),\n    )\n    self.assertSerializedResultEqual(\n        TestType.__class__,\n        (\"type\", set()),\n    )\n"], "sample_60": ["def test_serialize_type_with_module(self):\n    class TestType:\n        pass\n\n    self.assertSerializedEqual(TestType)\n    string, imports = MigrationWriter.serialize(TestType)\n    self.assertEqual(string, \"migrations.test_writer.WriterTests.test_serialize_type_with_module.<locals>.TestType\")\n    self.assertEqual(imports, {\"import migrations.test_writer\"})\n"], "sample_10": ["def test_in_bulk_with_large_input(self):\n    # Create a large number of authors\n    Author.objects.bulk_create([Author(name=f'Author {i}') for i in range(1000)])\n\n    # Test that in_bulk() works with a large input\n    authors = list(Author.objects.all())\n    author_ids = [author.id for author in authors]\n    retrieved_authors = Author.objects.in_bulk(author_ids)\n    self.assertEqual(len(retrieved_authors), len(authors))\n    for author in authors:\n        self.assertIn(author.id, retrieved_authors)\n        self.assertEqual(retrieved_authors[author.id], author)\n"], "sample_11": ["def test_serialize_type_with_module(self):\n    class TestType:\n        pass\n\n    self.assertSerializedResultEqual(\n        type(TestType()),\n        (\"migrations.test_writer.TestType\", {'import migrations.test_writer'})\n    )\n"], "sample_30": ["    def test_get_extra(self):\n        class MyInline(TabularInline):\n            model = Inner\n\n                return 1\n\n        modeladmin = ModelAdmin(Holder, admin_site)\n        modeladmin.inlines = [MyInline]\n        request = self.factory.get(reverse('admin:admin_inlines_holder_add'))\n        request.user = self.superuser\n        response = modeladmin.changeform_view(request)\n        self.assertContains(response, 'id=\"id_inner_set-TOTAL_FORMS\" value=\"1\"')\n"], "sample_124": ["def test_hyperbolic_is_real():\n    x = Symbol('x', real=True)\n    assert sinh(x).is_real is True\n    assert cosh(x).is_real is True\n    assert tanh(x).is_real is True\n    assert coth(x).is_real is True\n    assert sech(x).is_real is True\n    assert csch(x).is_real is True\n\n    x = Symbol('x', real=False)\n    assert sinh(x).is_real is None\n    assert cosh(x).is_real is None\n    assert tanh(x).is_real is None\n    assert coth(x).is_real is None\n    assert sech(x).is_real is None\n    assert csch(x).is_real is None\n\n    x = Symbol('x')\n    assert sinh(x).is_real is None\n    assert cosh(x).is_real is None\n    assert tanh(x).is_real is None\n    assert coth(x).is_real is None\n    assert sech(x).is_real is None\n    assert csch(x).is_real is None\n"], "sample_109": ["def test_validate_shuffle_split():\n    # Test _validate_shuffle_split function\n    n_samples = 10\n\n    # Test when both train_size and test_size are None\n    train_size, test_size = _validate_shuffle_split(n_samples, None, None)\n    assert train_size + test_size == n_samples\n\n    # Test when only train_size is specified\n    train_size, test_size = _validate_shuffle_split(n_samples, None, 0.5)\n    assert train_size + test_size == n_samples\n\n    # Test when only test_size is specified\n    train_size, test_size = _validate_shuffle_split(n_samples, 0.5, None)\n    assert train_size + test_size == n_samples\n\n    # Test when both train_size and test_size are specified\n    train_size, test_size = _validate_shuffle_split(n_samples, 0.4, 0.6)\n    assert train_size + test_size == n_samples\n\n    # Test when train_size and test_size do not add up to 1\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, 0.7, 0.7)\n\n    # Test when train_size is larger than n_samples\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, 11, None)\n\n    # Test when test_size is larger than n_samples\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, None, 11)\n"], "sample_111": ["def test_empty_input(metric_name, metric_func):\n    # Test that all supervised metrics handle empty input correctly\n    assert metric_func([], []) == 1.0\n    with pytest.raises(ValueError, match='labels_true and labels_pred must be 1D'):\n        metric_func([[]], [[]])\n    with pytest.raises(ValueError, match='labels_true and labels_pred must be 1D'):\n        metric_func([[1]], [[1]])\n"], "sample_151": ["def test_direction_ratio():\n    p1 = Point3D(0, 0, 0)\n    p2 = Point3D(1, 1, 1)\n\n    assert p1.direction_ratio(Point3D(1, 0, 0)) == [1, 0, 0]\n    assert p1.direction_ratio(Point3D(0, 1, 0)) == [0, 1, 0]\n    assert p1.direction_ratio(Point3D(0, 0, pi)) == [0, 0, pi]\n\n    assert p1.direction_ratio(Point3D(5, 0, 0)) == [5, 0, 0]\n    assert p1.direction_ratio(Point3D(0, sqrt(3), 0)) == [0, sqrt(3), 0]\n    assert p1.direction_ratio(Point3D(0, 0, 5)) == [0, 0, 5]\n\n    assert p1.direction_ratio(Point3D(2.4, 2.4, 0)) == [2.4, 2.4, 0]\n    assert p1.direction_ratio(Point3D(1, 1, 1)) == [1, 1, 1]\n    assert p1.direction_ratio(Point3D(-12, 0 -15)) == [-12, -15, 0]\n\n    assert p2.direction_ratio(Point3D(0, 0, 0)) == [-1, -1, -1]\n    assert p2.direction_ratio(Point3D(1, 1, 12)) == [0, 0, 11]\n    assert p2.direction_ratio(Point3D(12, 1, 12)) == [11, 0, 11]\n"], "sample_148": ["def test_issue_19627():\n    from sympy import Function, Symbol, Abs\n    x = Symbol('x')\n    f = Function('f', positive=True)\n    assert Abs(f(x)) == f(x)\n    assert Abs(f(x)**2) == f(x)**2\n    assert Abs(f(x)**3) == f(x)**3\n    assert Abs(f(x)**4) == f(x)**4\n    assert Abs(f(x)**5) == f(x)**5\n    assert Abs(f(x)**6) == f(x)**6\n"], "sample_121": ["def test_cycle_structure():\n    p = Permutation([0, 1, 2])\n    assert p.cycle_structure == {1: 3}\n    p = Permutation([0, 2, 1])\n    assert p.cycle_structure == {1: 1, 2: 1}\n    p = Permutation([1, 2, 0])\n    assert p.cycle_structure == {3: 1}\n    p = Permutation([0, 1, 2, 3])\n    assert p.cycle_structure == {1: 4}\n    p = Permutation([0, 3, 2, 1])\n    assert p.cycle_structure == {1: 2, 2: 1}\n"], "sample_65": ["    def test_add01(self):\n        output = self.engine.render_to_string(\"add01\", {\"a\": 1, \"b\": 2})\n        self.assertEqual(output, \"3\")\n"], "sample_122": ["def test_row_structure_symbolic_cholesky():\n    S = SparseMatrix([\n        [1, 0, 3, 2],\n        [0, 0, 1, 0],\n        [4, 0, 0, 5],\n        [0, 6, 7, 0]])\n    assert S.row_structure_symbolic_cholesky() == [[0], [], [0], [1, 2]]\n"], "sample_32": ["def test_key_transform_with_invalid_input(self):\n    msg = 'Value must be valid JSON.'\n    with self.assertRaisesMessage(ValidationError, msg):\n        KeyTransform('test', 'value').process_rhs(\n            compiler=None,\n            connection=None,\n            value='invalid json',\n        )\n"], "sample_42": ["def test_serialize_lazy_object(self):\n    lazy_object = SimpleLazyObject(lambda: \"lazy_value\")\n    self.assertSerializedEqual(lazy_object)\n    string, imports = MigrationWriter.serialize(lazy_object)\n    self.assertEqual(string, \"'lazy_value'\")\n    self.assertEqual(imports, set())\n"], "sample_142": ["def test_roundrobin():\n    assert list(roundrobin('ABC', 'D', 'EF')) == [\n        'A', 'D', 'E', 'B', 'F', 'C']\n    assert list(roundrobin([1, 2], [3, 4, 5])) == [1, 3, 2, 4, 5]\n"], "sample_14": ["def test_serialize_type_with_module(self):\n    class TestType:\n        pass\n\n    self.assertSerializedResultEqual(\n        type(TestType),\n        (\"type(migrations.test_writer.WriterTests.test_serialize_type_with_module.<locals>.TestType)\", set())\n    )\n"], "sample_136": ["def test_block_collapse_inverse():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', m, m)\n    X = BlockDiagMatrix(A, B)\n\n    assert block_collapse(X.I) == BlockDiagMatrix(A.I, B.I)\n    assert block_collapse(Inverse(X)) == BlockDiagMatrix(A.I, B.I)\n    assert bc_inverse(X.I) == BlockDiagMatrix(A.I, B.I)\n    assert bc_inverse(Inverse(X)) == BlockDiagMatrix(A.I, B.I)\n"], "sample_66": ["    def test_not_callable_or_boolean(self):\n        class TestModelAdmin(ModelAdmin):\n            view_on_site = \"hello\"\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'view_on_site' must be a callable or a boolean value.\",\n            \"admin.E025\",\n        )\n"], "sample_2": ["def test_axis_type_names():\n    w = wcs.WCS(naxis=2)\n    w.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\"]\n    w.wcs.cname = [\"Longitude\", \"\"]\n    assert w.axis_type_names == [\"Longitude\", \"DEC--TAN\"]\n"], "sample_23": ["def test_union_with_subqueries(self):\n    qs1 = Number.objects.filter(num__lte=1)\n    qs2 = Number.objects.filter(num__gte=8).filter(num__in=Number.objects.values('num'))\n    self.assertNumbersEqual(qs1.union(qs2), [0, 1, 8, 9], ordered=False)\n"], "sample_18": ["    def test_table_clash(self):\n        class Person(models.Model):\n            pass\n\n        class Group(models.Model):\n            members = models.ManyToManyField('Person', through='GroupMember')\n\n        class GroupMember(models.Model):\n            person = models.ForeignKey(Person, models.CASCADE)\n            group = models.ForeignKey(Group, models.CASCADE)\n\n        class OtherModel(models.Model):\n            pass\n\n        # Create a model with the same table name as the through model.\n        class ClashingModel(models.Model):\n            class Meta:\n                db_table = 'invalid_models_tests_groupmember'\n\n        field = Group._meta.get_field('members')\n        self.assertEqual(field.check(from_model=Group), [\n            Error(\n                \"The field's intermediary table 'invalid_models_tests_groupmember' \"\n                \"clashes with the table name of 'invalid_models_tests.ClashingModel'.\",\n                obj=field,\n                id='fields.E340',\n            ),\n        ])\n"], "sample_112": ["def test_isotonic_regression_output_transform():\n    \"\"\"Check that `transform` does return the expected output type.\n\n    We need to check that `transform` will output a DataFrame and a NumPy array\n    when we set `transform_output` to `pandas`.\n\n    Non-regression test for:\n    https://github.com/scikit-learn/scikit-learn/issues/25499\n    \"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    X, y = make_regression(n_samples=10, n_features=1, random_state=42)\n    regressor = IsotonicRegression()\n    with sklearn.config_context(transform_output=\"pandas\"):\n        regressor.fit(X, y)\n        X_trans_pandas = regressor.transform(X)\n\n    with sklearn.config_context(transform_output=\"default\"):\n        regressor.fit(X, y)\n        X_trans_default = regressor.transform(X)\n\n    assert isinstance(X_trans_pandas, pd.DataFrame)\n    assert isinstance(X_trans_default, np.ndarray)\n"], "sample_137": ["def test_roundrobin():\n    assert list(roundrobin('ABC', 'D', 'EF')) == [\n        'A', 'D', 'E', 'B', 'F', 'C']\n    assert list(roundrobin([1, 2], [3, 4, 5])) == [1, 3, 2, 4]\n    assert list(roundrobin([1, 2, 3], [4, 5], [6, 7, 8, 9])) == [\n        1, 4, 6, 2, 5, 7, 3, 8, 9]\n"], "sample_138": ["def test_block_collapse_inverse():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', m, m)\n    C = MatrixSymbol('C', l, l)\n    X = BlockDiagMatrix(A, B, C)\n\n    assert block_collapse(X.I) == BlockDiagMatrix(A.I, B.I, C.I)\n    assert block_collapse(Inverse(X)) == BlockDiagMatrix(A.I, B.I, C.I)\n"], "sample_129": ["def test_issue_15141():\n    from sympy import limit, sin, cos, oo\n    x = Symbol(\"x\")\n    assert latex(limit(sin(x)/x, x, oo)) == r\"\\lim_{x \\to \\infty} \\frac{\\sin{\\left (x \\right )}}{x}\"\n"], "sample_145": ["def test_latex_fully_qualified_names():\n    x = Symbol('x')\n    assert latex(x, symbol_names={x: \"x_i\"}) == r\"x_i\"\n    assert latex(x, symbol_names={x: \"x_i\"}, fully_qualified_names=True) == r\"x\"\n    assert latex(x + 1, symbol_names={x: \"x_i\"}) == r\"x_i + 1\"\n    assert latex(x + 1, symbol_names={x: \"x_i\"}, fully_qualified_names=True) == r\"x + 1\"\n"], "sample_53": ["def test_alter_field_with_f_expression(self):\n    \"\"\"Tests autodetection of altered fields with F expressions.\"\"\"\n    before = [\n        ModelState(\n            \"testapp\",\n            \"Author\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=200)),\n                (\"counter\", models.IntegerField(default=0)),\n            ],\n        ),\n    ]\n    after = [\n        ModelState(\n            \"testapp\",\n            \"Author\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=200)),\n                (\n                    \"counter\",\n                    models.IntegerField(\n                        default=models.F(\"counter\") + 1,\n                    ),\n                ),\n            ],\n        ),\n    ]\n    changes = self.get_changes(before, after)\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, name=\"counter\", preserve_default=True\n    )\n"], "sample_123": ["def test_as_integer_ratio():\n    f = Float(0.5)\n    assert f.as_integer_ratio() == (1, 2)\n\n    f = Float(3.14159)\n    n, d = f.as_integer_ratio()\n    assert f == n/d\n    assert n/d == f\n    assert n/d - f == 0\n"], "sample_143": ["def test_pretty_print_PartialDerivative():\n    from sympy.tensor.toperators import PartialDerivative\n    from sympy.tensor.tensor import TensorIndexType, tensor_indices, TensorHead, tensor_heads\n\n    L = TensorIndexType(\"L\")\n    i, j, k = tensor_indices(\"i j k\", L)\n\n    A, B, C, D = tensor_heads(\"A B C D\", [L])\n\n    H = TensorHead(\"H\", [L, L])\n\n    expr = PartialDerivative(A(i), A(j))\n    ascii_str = \\"], "sample_52": ["def test_rename_table_with_m2m_to_self(self):\n    app_label = \"test_rename_table_with_m2m_to_self\"\n    project_state = self.apply_operations(\n        app_label,\n        ProjectState(),\n        operations=[\n            migrations.CreateModel(\n                \"Tag\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                ],\n            ),\n            migrations.CreateModel(\n                \"Obj\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\n                        \"tags\",\n                        models.ManyToManyField(\n                            \"Tag\",\n                            related_name=\"related_objs\",\n                        ),\n                    ),\n                ],\n            ),\n        ],\n    )\n    new_state = project_state.clone()\n    operation = migrations.AlterModelTable(name=\"obj\", table=None)\n    operation.state_forwards(app_label, new_state)\n    atomic_rename = connection.features.supports_atomic_references_rename\n    with connection.schema_editor(atomic=atomic_rename) as editor:\n        operation.database_forwards(app_label, editor, project_state, new_state)\n    self.assertTableExists(f\"{app_label}_obj\")\n    self.assertTableExists(f\"{app_label}_obj_tags\")\n    self.assertForeignKeyExists(\n        f\"{app_label}_obj_tags\",\n        \"obj_id\",\n        (app_label, \"obj\"),\n    )\n"], "sample_126": ["def test_mod_inverse_fractions():\n    assert mod_inverse(Rational(3, 5), 11) == 4\n    assert mod_inverse(Rational(3, 5), 7) == 3\n    assert mod_inverse(Rational(5, 3), 11) == 9\n    assert mod_inverse(Rational(5, 3), 7) == 5\n    assert mod_inverse(Rational(7, 11), 5) == 3\n    assert mod_inverse(Rational(7, 11), 3) == 2\n"], "sample_125": ["def test_Float_precision_too_high():\n    raises(ValueError, lambda: Float(1.0, precision=1000000))\n"], "sample_127": ["def test_latex_radian():\n    expr1 = pi*radian\n    assert latex(expr1) == r\"\\pi \\detokenize {radian}\"\n    expr2 = x*radian\n    assert latex(expr2) == r\"x \\detokenize {radian}\"\n    expr3 = sin(x*radian + pi*radian)\n    assert latex(expr3) == r'\\sin{\\left (x \\detokenize {radian} + \\pi \\detokenize {radian} \\right )}'\n"]}, "raw_scored_generations": {"sample_3": [false], "sample_2": [false], "sample_0": [true], "sample_1": [false], "sample_6": [false], "sample_4": [false], "sample_5": [true], "sample_7": [false], "sample_9": [false], "sample_8": [false], "sample_10": [true], "sample_11": [true], "sample_13": [false], "sample_12": [true], "sample_14": [true], "sample_15": [true], "sample_16": [true], "sample_17": [false], "sample_18": [true], "sample_19": [false], "sample_21": [true], "sample_20": [true], "sample_23": [true], "sample_22": [true], "sample_24": [true], "sample_25": [true], "sample_28": [false], "sample_26": [false], "sample_27": [true], "sample_29": [false], "sample_31": [true], "sample_30": [false], "sample_32": [true], "sample_33": [true], "sample_34": [false], "sample_35": [false], "sample_36": [true], "sample_37": [false], "sample_39": [false], "sample_38": [true], "sample_40": [true], "sample_42": [true], "sample_41": [true], "sample_43": [true], "sample_45": [false], "sample_44": [true], "sample_46": [false], "sample_48": [true], "sample_47": [true], "sample_50": [true], "sample_49": [true], "sample_51": [true], "sample_52": [true], "sample_53": [true], "sample_55": [true], "sample_54": [true], "sample_56": [false], "sample_58": [true], "sample_57": [true], "sample_60": [true], "sample_59": [true], "sample_61": [true], "sample_63": [false], "sample_62": [false], "sample_64": [true], "sample_66": [true], "sample_65": [false], "sample_68": [true], "sample_67": [true], "sample_69": [false], "sample_70": [true], "sample_71": [true], "sample_72": [true], "sample_73": [false], "sample_74": [true], "sample_75": [false], "sample_76": [false], "sample_77": [false], "sample_78": [false], "sample_79": [false], "sample_80": [false], "sample_82": [true], "sample_81": [false], "sample_83": [false], "sample_84": [false], "sample_85": [false], "sample_86": [false], "sample_87": [false], "sample_88": [false], "sample_89": [false], "sample_90": [false], "sample_91": [false], "sample_92": [false], "sample_93": [false], "sample_95": [false], "sample_94": [false], "sample_96": [false], "sample_97": [false], "sample_98": [false], "sample_99": [false], "sample_100": [true], "sample_101": [true], "sample_102": [false], "sample_103": [false], "sample_104": [false], "sample_105": [false], "sample_107": [false], "sample_106": [true], "sample_108": [false], "sample_109": [false], "sample_110": [false], "sample_111": [false], "sample_112": [true], "sample_113": [false], "sample_114": [false], "sample_115": [true], "sample_116": [false], "sample_117": [true], "sample_118": [false], "sample_119": [true], "sample_120": [true], "sample_121": [true], "sample_122": [true], "sample_123": [false], "sample_124": [false], "sample_125": [false], "sample_126": [false], "sample_127": [true], "sample_128": [false], "sample_129": [false], "sample_130": [true], "sample_131": [true], "sample_132": [false], "sample_133": [false], "sample_134": [true], "sample_135": [false], "sample_136": [false], "sample_137": [false], "sample_138": [false], "sample_139": [true], "sample_140": [false], "sample_142": [false], "sample_141": [false], "sample_143": [false], "sample_144": [false], "sample_145": [false], "sample_146": [false], "sample_147": [false], "sample_148": [true], "sample_149": [false], "sample_150": [false], "sample_151": [false], "sample_152": [true], "sample_153": [true], "sample_154": [true], "sample_155": [false], "sample_156": [false], "sample_157": [false], "sample_158": [false], "sample_159": [false]}}