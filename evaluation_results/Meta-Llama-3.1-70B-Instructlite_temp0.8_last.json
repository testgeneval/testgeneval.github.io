{"raw_generations": {"sample_33": ["def test_send_robust_sender_filtering(self):\n        return sender\n\n    a_signal.connect(receiver)\n    result = a_signal.send_robust(sender=self, val='test')\n    self.assertEqual(len(result), 1)\n    self.assertEqual(result[0][0], receiver)\n    self.assertEqual(result[0][1], self)\n\n    a_signal.connect(receiver, sender='other')\n    result = a_signal.send_robust(sender=self, val='test')\n    self.assertEqual(len(result), 1)\n    self.assertEqual(result[0][0], receiver)\n    self.assertEqual(result[0][1], self)\n\n    result = a_signal.send_robust(sender='other', val='test')\n    self.assertEqual(len(result), 2)\n    self.assertEqual(result[0][0], receiver)\n    self.assertEqual(result[0][1], 'other')\n    self.assertEqual(result[1][0], receiver)\n    self.assertEqual(result[1][1], 'other')\n\n    a_signal.disconnect(receiver)\n    a_signal.disconnect(receiver, sender='other')\n    self.assertTestIsClean(a_signal)\n", "def test_receiver_multiple_signal_multiple_sender(self):\n    self.state = []\n    @receiver([a_signal, b_signal], sender=self)\n        self.state.append((val, kwargs.get('sender')))\n    @receiver([a_signal, b_signal], sender=object())\n        self.state.append((val, kwargs.get('sender')))\n    a_signal.send(sender=self, val=True)\n    b_signal.send(sender=self, val=True)\n    a_signal.send(sender=object(), val=True)\n    b_signal.send(sender=object(), val=True)\n    self.assertEqual(len(self.state), 8)\n    self.assertIn((True, self), self.state)\n    self.assertIn((True, object()), self.state)\n", "    def test_connect_weak_false(self):\n        \"\"\"\n        Test that using weak=False in signal connection still works.\n        \"\"\"\n        a_signal.connect(receiver_1_arg, weak=False)\n        result = a_signal.send(sender=self, val='test')\n        self.assertEqual(result, [(receiver_1_arg, 'test')])\n        a_signal.disconnect(receiver_1_arg)\n        self.assertTestIsClean(a_signal)\n", "    def test_signal_caching(self):\n        # Create a sender that will be garbage collected\n        class Sender:\n            pass\n        sender = Sender()\n        d_signal.send(sender=sender, val='test')\n\n        # Check that the cache contains the sender\n        self.assertIn(sender, d_signal.sender_receivers_cache)\n\n        # Delete the sender and force garbage collection\n        del sender\n        garbage_collect()\n\n        # Check that the cache no longer contains the sender\n        self.assertNotIn(sender, d_signal.sender_receivers_cache)\n", "    def test_weakref_removal(self):\n        \"\"\"Test removal of weakrefs\"\"\"\n        class Callable:\n                return val\n\n        a = Callable()\n        a_signal.connect(a)\n        a_signal.send(sender=self, val='test')\n        a_signal.send(sender=self, val='test')  # Make sure cache is populated.\n        del a\n        garbage_collect()\n        self.assertFalse(a_signal.has_listeners())\n        self.assertEqual(len(a_signal.receivers), 0)\n        self.assertEqual(len(a_signal.sender_receivers_cache), 0)\n"], "sample_42": ["    def test_serialize_operation(self):\n        \"\"\"\n        Test serialization of Operation instances.\n        \"\"\"\n        operation = Operation()\n        string, imports = MigrationWriter.serialize(operation)\n        self.assertEqual(string, \"django.db.migrations.operations.base.Operation\")\n        self.assertEqual(imports, {'from django.db.migrations.operations.base import Operation'})\n", "def test_serialize_model_managers(self):\n    self.assertSerializedResultEqual(\n        FoodManager('a', 'b', c=3, d=4),\n        ('migrations.models.FoodManager(\"a\", \"b\", c=3, d=4)', {'import migrations.models'})\n    )\n    self.assertSerializedResultEqual(\n        FoodQuerySet.as_manager(),\n        ('migrations.models.FoodQuerySet.as_manager()', {'import migrations.models'})\n    )\n    self.assertSerializedResultEqual(\n        FoodManager(models.QuerySet, 'b', c=3, d=4),\n        ('migrations.models.FoodManager(models.QuerySet, \"b\", c=3, d=4)', {'from django.db import models', 'import migrations.models'})\n    )\n", "def test_serialize_regex(self):\n    regex = re.compile(r'^[0-9]+$')\n    self.assertSerializedEqual(regex)\n    self.assertSerializedResultEqual(\n        regex,\n        (\"re.compile('^[0-9]+$')\", {'import re'})\n    )\n    regex = re.compile(r'^[0-9]+$', re.IGNORECASE)\n    self.assertSerializedEqual(regex)\n    self.assertSerializedResultEqual(\n        regex,\n        (\"re.compile('^[0-9]+$', re.IGNORECASE)\", {'import re'})\n    )\n    self.assertSerializedResultEqual(\n        re.compile(r'^[0-9]+$', flags=re.S),\n        (\"re.compile('^[0-9]+$', flags=re.RegexFlag['DOTALL'])\", {'import re'})\n    )\n    self.assertSerializedResultEqual(\n        re.compile(r'^[0-9]+$', flags=re.IGNORECASE | re.MULTILINE),\n        (\"re.compile('^[0-9]+$', flags=re.RegexFlag['IGNORECASE'] | re.RegexFlag['MULTILINE'])\", {'import re'})\n    )\n    self.assertSerializedResultEqual(\n        re.compile(r'^[0-9]+$', flags=re.IGNORECASE | re.MULTILINE | re.DOTALL),\n        (\"re.compile('^[0-9]+$', flags=re.RegexFlag['IGNORECASE'] | re.RegexFlag['MULTILINE'] | re.RegexFlag['DOTALL'])\", {'import re'})\n    )\n", "    def test_unregister_serializer(self):\n        # Register a new serializer\n        original_registry = Serializer._registry.copy()\n        class CustomSerializer(BaseSerializer):\n                return 'custom(%r)' % self.value, {}\n        Serializer.register(type(self), CustomSerializer)\n\n        # Check the new serializer is being used\n        string, imports = serializer_factory(self)\n        self.assertEqual(string, 'custom(%r)' % self)\n        self.assertEqual(imports, set())\n\n        # Unregister the serializer\n        Serializer.unregister(type(self))\n\n        # Check the original serializer is being used again\n        string, imports = serializer_factory(self)\n        self.assertNotEqual(string, 'custom(%r)' % self)\n        self.assertEqual(imports, set())\n\n        # Restore the original registry\n        Serializer._registry = original_registry\n", "    def test_serialize_nested_path_like(self):\n        \"\"\"\n        Test serialization of nested path-like objects\n        \"\"\"\n        path_like = os.PathLike()\n        path_like.path = os.path.dirname(__file__)\n\n        class NestedPathLike:\n                self.path_like = path_like\n\n        nested_path_like = NestedPathLike(path_like)\n\n        self.assertSerializedResultEqual(\n            nested_path_like,\n            (\"migrations.test_writer.NestedPathLike(%r)\" % path_like, {'import migrations.test_writer'})\n        )\n"], "sample_112": ["def test_isotonic_regression_ymin_ymax_decreasing():\n    # Test from @NelleV's issue:\n    # https://github.com/scikit-learn/scikit-learn/issues/6921\n    x = np.array(\n        [\n            1.263,\n            1.318,\n            -0.572,\n            0.307,\n            -0.707,\n            -0.176,\n            -1.599,\n            1.059,\n            1.396,\n            1.906,\n            0.210,\n            0.028,\n            -0.081,\n            0.444,\n            0.018,\n            -0.377,\n            -0.896,\n            -0.377,\n            -1.327,\n            0.180,\n        ]\n    )\n    y = isotonic_regression(x, y_min=0.0, y_max=0.1, increasing=False)\n\n    assert np.all(y >= 0)\n    assert np.all(y <= 0.1)\n\n    # Also test with only one bound\n    y = isotonic_regression(x, y_max=0.1, increasing=False)\n\n    assert np.all(y <= 0.1)\n", "def test_isotonic_regression_pickling_fitted_model():\n    # Test that the pickled model can be used for predictions\n    y = np.array([3, 7, 5, 9, 8, 7, 10])\n    x = np.arange(len(y))\n\n    # Create model and fit\n    ir = IsotonicRegression(increasing=\"auto\", out_of_bounds=\"clip\")\n    ir.fit(x, y)\n\n    # Pickle the model\n    pickled_ir = pickle.dumps(ir)\n\n    # Unpickle the model\n    unpickled_ir = pickle.loads(pickled_ir)\n\n    # Use the unpickled model for predictions\n    y_pred = unpickled_ir.predict(x)\n\n    # Check that the predictions are correct\n    assert_array_equal(y_pred, ir.predict(x))\n", "def test_isotonic_regression_with_y_max_as_nan():\n    # Test from #16957\n    # Check that IsotonicRegression handles y_max as np.nan\n    X = np.array([1, 2, 3, 4, 5])\n    y = np.array([1, 2, 3, 4, 5])\n    iso_reg = IsotonicRegression(y_max=np.nan)\n    with pytest.raises(ValueError, match=\"y_max must be a real number\"):\n        iso_reg.fit(X, y)\n", "def test_isotonic_regression_non_monotonic_input():\n    # Check that IsotonicRegression correctly handles non-monotonic inputs\n    x = np.arange(10)\n    y = np.array([0, 2, 4, 6, 8, 7, 6, 4, 2, 0])\n\n    iso_reg = IsotonicRegression(increasing=True)\n    y_pred = iso_reg.fit_transform(x, y)\n\n    # Check that the predicted values are monotonic\n    assert all(np.diff(y_pred) >= 0)\n\n    iso_reg = IsotonicRegression(increasing=False)\n    y_pred = iso_reg.fit_transform(x, y)\n\n    # Check that the predicted values are anti-monotonic\n    assert all(np.diff(y_pred) <= 0)\n", "def test_isotonic_regression_unbounded_out_of_bounds_warning():\n    # Set y and x\n    y = np.array([3, 7, 5, 9, 8, 7, 10])\n    x = np.arange(len(y))\n\n    # Create model and fit\n    ir = IsotonicRegression(out_of_bounds=\"raise\")\n    ir.fit(x, y)\n\n    # Check that an exception is thrown for unbounded case\n    msg = \"out_of_bounds must be in ('nan', 'clip', 'raise')\"\n    with pytest.warns(FutureWarning, match=msg):\n        ir = IsotonicRegression(out_of_bounds=\"bounded\")\n        ir.fit(x, y)\n\n    # Check that a ValueError is thrown for incorrect value\n    msg = \"out_of_bounds must be in ('nan', 'clip', 'raise')\"\n    with pytest.raises(ValueError, match=msg):\n        ir = IsotonicRegression(out_of_bounds=\"wrong\")\n        ir.fit(x, y)\n"], "sample_84": ["    def test_parametrize_overwrites_class_scope(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            class TestClass(object):\n                @pytest.fixture(scope=\"class\")\n                    return request.param\n\n                @pytest.mark.parametrize(\"arg1\", [1, 2])\n                    pass\n            \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\"*1 error*\"])\n        result.stdout.fnmatch_lines([\"*ScopeMismatch*involved factories*\"])\n", "    def test_conftest_ordering(self, testdir):\n        testdir.makepyfile(\n            test_a=\"\"\"\n            import pytest\n            pytest_plugins = ['test_plugin_a']\n                pass\n        \"\"\",\n            test_plugin_a=\"\"\"\n            import pytest\n            pytest_plugins = ['test_plugin_b']\n            @pytest.fixture\n                return \"fix_a\"\n        \"\"\",\n            test_plugin_b=\"\"\"\n            import pytest\n            @pytest.fixture\n                return \"fix_b\"\n        \"\"\",\n        )\n        testdir.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n                return \"fix_c\"\n        \"\"\"\n        )\n        items, _ = testdir.inline_genitems()\n        request = FixtureRequest(items[0])\n        assert request.fixturenames == \"fix_b fix_a fix_c\".split()\n", "    def test_function_scope(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(scope=\"function\", params=[1, 2])\n                return request.param\n            values = []\n                values.append(arg)\n                assert values == [1, 2]\n        \"\"\"\n        )\n        reprec = testdir.inline_run()\n        reprec.assertoutcome(passed=3)\n", "    def test_autouse_finalizer_ordering(self, testdir):\n        \"\"\"Ensure that finalizers from autouse fixtures are called in the correct order (#3843).\"\"\"\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(scope='session', autouse=True)\n                request.addfinalizer(lambda: print('s1'))\n                pass\n\n            @pytest.fixture(scope='package', autouse=True)\n                request.addfinalizer(lambda: print('p1'))\n                pass\n\n            @pytest.fixture(scope='module', autouse=True)\n                request.addfinalizer(lambda: print('m1'))\n                pass\n\n            @pytest.fixture(scope='class', autouse=True)\n                request.addfinalizer(lambda: print('c1'))\n                pass\n\n            @pytest.fixture(scope='function', autouse=True)\n                request.addfinalizer(lambda: print('f1'))\n                pass\n\n            class TestClass(object):\n                    pass\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-v\")\n        result.stdout.fnmatch_lines(\n            [\n                \"s1\",\n                \"p1\",\n                \"m1\",\n                \"c1\",\n                \"f1\",\n            ]\n        )\n", "    def test_autouse_ordering(self, testdir):\n        testdir.makeconftest(\n            \"\"\"\n            import pytest\n            @pytest.fixture(autouse=True)\n                pass\n            @pytest.fixture(autouse=True)\n                pass\n            @pytest.fixture(autouse=True)\n                pass\n            @pytest.fixture(autouse=True)\n                pass\n            \"\"\"\n        )\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(autouse=True)\n                pass\n            @pytest.fixture(autouse=True)\n                pass\n                assert len(pytest.FIXTURE_ORDER) == 0\n            \"\"\"\n        )\n        testdir.runpytest()\n        assert pytest.FIXTURE_ORDER == [\n            \"s1\", \"s2\", \"p1\", \"p2\", \"m1\", \"m2\", \"tmpdir_factory\", \"tmpdir\"\n        ]\n"], "sample_85": ["def test_set_log_path(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            plugin.set_log_path('pytest.log')\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n\n    result = testdir.runpytest(\"-s\", \"--log-file-level=INFO\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines([\"test_set_log_path.py PASSED\"])\n\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert \"This log message will be shown\" in contents\n", "def test_log_in_runtest_logstart(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = INFO\n        log_cli=true\n        \"\"\".format(\n            log_file\n        )\n    )\n    testdir.makeconftest(\n        \"\"\"\n        import logging\n        logger = logging.getLogger(__name__)\n\n            logger.info(\"logstart\")\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n                assert True\n        \"\"\"\n    )\n    testdir.runpytest()\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert contents.count(\"logstart\") == 1\n", "def test_log_capture_fixture(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        import pytest\n\n            logger = logging.getLogger(__name__)\n            logger.info('info message')\n            logger.warning('warning message')\n            assert len(caplog.records) == 2\n            assert caplog.record_tuples == [\n                (__name__, logging.INFO, 'info message'),\n                (__name__, logging.WARNING, 'warning message')\n            ]\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"* 1 passed in *\"])\n", "def test_live_logging_with_newlines(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logging.getLogger('catchlog').info(\"Line1\\nLine2\")\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_live_logging_with_newlines.py::test_log_1 \",\n            \"*-- live log call --*\",\n            \"*INFO*Line1\",\n            \"*Line2*\",\n            \"PASSED *100%*\",\n            \"=* 1 passed in *=\",\n        ]\n    )\n", "def test_catching_logs_context_manager(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        import pytest\n\n            with pytest.raises(SystemExit) as exc_info:\n                with catching_logs(LogCaptureHandler()):\n                    logging.getLogger('catchlog').critical('test message')\n                    pytest.exit('test exit')\n\n            assert exc_info.type == SystemExit\n            assert exc_info.value.code == 'test exit'\n            assert 'test message' in caplog.text\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*= 1 passed in *=\"])\n"], "sample_4": ["    def test_set_cookie_with_expires(self):\n        r = HttpResponseBase()\n        expires = datetime.datetime(2018, 1, 1, tzinfo=timezone.utc)\n        r.set_cookie('key', 'value', expires=expires)\n        self.assertEqual(r.cookies['key']['expires'], 'Mon, 01 Jan 2018 00:00:00 GMT')\n", "    def test_status_code_range(self):\n        with self.assertRaises(ValueError):\n            HttpResponseBase(status=1000)\n        with self.assertRaises(ValueError):\n            HttpResponseBase(status=-1)\n", "    def test_charset(self):\n        r = HttpResponseBase(content_type='text/html; charset=latin1')\n        self.assertEqual(r.charset, 'latin1')\n        r.charset = 'utf-8'\n        self.assertEqual(r.charset, 'utf-8')\n        r['Content-Type'] = 'text/html'\n        self.assertEqual(r.charset, settings.DEFAULT_CHARSET)\n        r['Content-Type'] = 'text/html; charset=iso-8859-1'\n        self.assertEqual(r.charset, 'iso-8859-1')\n", "    def test_set_signed_cookie(self):\n        # Regression test for #23593: HttpResponse.set_signed_cookie.\n        r = HttpResponse()\n        r.set_signed_cookie('my_cookie', 'my_value')\n        self.assertEqual(r.cookies['my_cookie']['httponly'], False)\n        self.assertIn('my_value', r.cookies['my_cookie'].value)\n        ", "    def test_set_headers(self):\n        # Create a file and get its size.\n        filename = 'file_response_test.txt'\n        content = b'Hello, world!'\n        with open(filename, 'wb') as f:\n            f.write(content)\n        size = os.path.getsize(filename)\n\n        # Test the response with a file object.\n        file_object = open(filename, 'rb')\n        response = FileResponse(file_object)\n        self.assertEqual(response['Content-Type'], 'text/plain')\n        self.assertEqual(response['Content-Length'], str(size))\n\n        # Test the response with a file object that doesn't have a name.\n        file_object = open(filename, 'rb')\n        file_object.name = None\n        response = FileResponse(file_object)\n        self.assertEqual(response['Content-Type'], 'application/octet-stream')\n        self.assertNotIn('Content-Length', response)\n\n        # Test the response with a file object that has a name but not a size.\n        file_object = open(filename, 'rb')\n        file_object.name = filename\n        file_object.getbuffer = None\n        response = FileResponse(file_object)\n        self.assertEqual(response['Content-Type'], 'text/plain')\n        self.assertNotIn('Content-Length', response)\n\n        # Test the response with a filename but not a file object.\n        response = FileResponse(filename=filename)\n        self.assertEqual(response['Content-Type'], 'text/plain')\n        self.assertEqual(response['Content-Length'], str(size))\n\n        # Clean up the test file.\n        os.remove(filename)\n"], "sample_66": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n", "    def test_invalid_ordering_with_f_expression(self):\n        class TestModelAdmin(ModelAdmin):\n            ordering = (F(\"non_existent_field\").desc(),)\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'ordering[0]' refers to 'non_existent_field', \"\n            \"which is not a field of 'modeladmin.ValidationTestModel'.\",\n            \"admin.E033\",\n        )\n", "    def test_ordering_item_expression_and_lookup(self):\n        class TestModelAdmin(ModelAdmin):\n            ordering = (\"name__upper\",)\n\n        self.assertIsValid(TestModelAdmin, ValidationTestModel)\n", "    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n", "    def test_ordering_with_orderby(self):\n        class TestModelAdmin(ModelAdmin):\n            ordering = (models.OrderBy(F(\"name\"), descending=True),)\n\n        self.assertIsValid(TestModelAdmin, ValidationTestModel)\n"], "sample_116": ["def test_create_index_with_category_key(app):\n    text = (\".. index:: single: docutils\\n\"\n            \"   :category: Letter D\\n\"\n            \".. index:: single: Python\\n\"\n            \"   :category: Letter P\\n\"\n            \".. index:: Sphinx\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n\n    # check index is created correctly\n    assert len(index) == 3\n    assert index[0] == ('Letter D', [('docutils', [[('', '#index-0')], [], None])])\n    assert index[1] == ('Letter P', [('Python', [[('', '#index-1')], [], None])])\n    assert index[2] == ('S', [('Sphinx', [[('', '#index-2')], [], None])])\n", "def test_create_index_with_group_entries_false(app):\n    text = (\".. index:: single: docutils\\n\"\n            \".. index:: single: Python\\n\"\n            \".. index:: Sphinx\\n\"\n            \".. index:: pip; install\\n\"\n            \".. index:: pip; upgrade\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder, group_entries=False)\n    assert len(index) == 4\n    assert index[0] == ('D', [('docutils', [[('', '#index-0')], [], None])])\n    assert index[1] == ('P', [('pip', [[], [('install', [('', '#index-3')]),\n                                            ('upgrade', [('', '#index-4')])], None]),\n                              ('Python', [[('', '#index-1')], [], None])])\n    assert index[2] == ('S', [('Sphinx', [[('', '#index-2')], [], None])])\n    assert index[3] == ('Symbols', [('pip (in module )', [[], [], None])])\n", "def test_create_index_with_fixre(app):\n    text = (\".. index:: func() (in module foo)\\n\"\n            \".. index:: func() (in module bar)\\n\"\n            \".. index:: other() (in module baz)\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder, _fixre=re.compile(r'(.*) \\(.*\\)'))\n\n    assert len(index) == 2\n    assert index[0] == ('F', [('func()', [[], [('in module bar', [('', '#index-1')]),\n                                             ('in module foo', [('', '#index-0')])], None])])\n    assert index[1] == ('O', [('other()', [[('', '#index-2')], [], None])])\n", "def test_create_index_with_group_entries_false(app):\n    text = (\".. index:: docutils\\n\"\n            \".. index:: Python\\n\"\n            \".. index:: pip; install\\n\"\n            \".. index:: pip; upgrade\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder, group_entries=False)\n    assert len(index) == 5\n    assert index[0] == ('Symbols', [])\n    assert index[1] == ('D', [('docutils', [[('', '#index-0')], {}, None])])\n    assert index[2] == ('P', [('pip', [[], {'install': [('', '#index-2')], 'upgrade': [('', '#index-3')]}, None]),\n                              ('Python', [[('', '#index-1')], {}, None])])\n    assert index[3] == ('U', [('upgrade', [[], {}, 'pip'])])\n    assert index[4] == ('I', [('install', [[], {}, 'pip'])])\n", "def test_create_index_with_empty_subentry(app):\n    text = (\".. index:: single: docutils\\n\"\n            \".. index:: single: Python\\n\"\n            \".. index:: pip; \\n\"\n            \".. index:: Sphinx\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n\n    # check index is created correctly\n    assert len(index) == 3\n    assert index[0] == ('D', [('docutils', [[('', '#index-0')], [], None])])\n    assert index[1] == ('P', [('Python', [[('', '#index-1')], [], None])])\n    assert index[2] == ('S', [('Sphinx', [[('', '#index-3')], [], None])])\n\n    # check the empty subentry is handled correctly\n    assert len(index[1][1][0][1]) == 0\n"], "sample_52": ["def test_alter_model_managers_to_custom_manager(self):\n    \"\"\"\n    The managers on a model are set to a custom manager.\n    \"\"\"\n    project_state = self.set_up_test_model(\"test_almomacm\")\n    # Test the state alteration\n    class CustomManager(models.Manager):\n            return self.filter(pink=True)\n\n    operation = migrations.AlterModelManagers(\n        \"Pony\",\n        managers=[\n            (\"custom_manager\", CustomManager()),\n        ],\n    )\n    self.assertEqual(operation.describe(), \"Change managers on Pony\")\n    self.assertEqual(operation.migration_name_fragment, \"alter_pony_managers\")\n    managers = project_state.models[\"test_almomacm\", \"pony\"].managers\n    self.assertEqual(managers, [])\n\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_almomacm\", new_state)\n    self.assertIn((\"test_almomacm\", \"pony\"), new_state.models)\n    managers = new_state.models[\"test_almomacm\", \"pony\"].managers\n    self.assertEqual(managers[0][0], \"custom_manager\")\n    self.assertIsInstance(managers[0][1], CustomManager)\n", "def test_add_index_with_covering(self):\n    app_label = \"test_add_index_with_covering\"\n    project_state = self.set_up_test_model(app_label)\n    covering_index = models.Index(\n        fields=[\"pink\"], include=[\"weight\"], name=\"test_add_index_with_covering\"\n    )\n    operation = migrations.AddIndex(\"Pony\", covering_index)\n    self.assertEqual(\n        operation.describe(),\n        \"Create index test_add_index_with_covering on field(s) pink of model Pony\",\n    )\n    self.assertEqual(\n        operation.migration_name_fragment,\n        \"pony_test_add_index_with_covering\",\n    )\n    new_state = project_state.clone()\n    operation.state_forwards(app_label, new_state)\n    self.assertEqual(\n        len(new_state.models[app_label, \"pony\"].options[\"indexes\"]), 1\n    )\n    self.assertIndexNameNotExists(\n        f\"{app_label}_pony\", \"test_add_index_with_covering\"\n    )\n    with connection.schema_editor() as editor:\n        operation.database_forwards(app_label, editor, project_state, new_state)\n    self.assertIndexNameExists(f\"{app_label}_pony\", \"test_add_index_with_covering\")\n    Pony = new_state.apps.get_model(app_label, \"Pony\")\n    Pony.objects.create(pink=1, weight=4.0)\n    if connection.features.supports_covering_indexes:\n        with self.assertRaises(IntegrityError):\n            Pony.objects.create(pink=1, weight=7.0)\n    else:\n        Pony.objects.create(pink=1, weight=7.0)\n    with connection.schema_editor() as editor:\n        operation.database_backwards(app_label, editor, new_state, project_state)\n    self.assertIndexNameNotExists(f\"{app_label}_pony\", \"test_add_index_with_covering\")\n    Pony.objects.create(pink=1, weight=7.0)\n    definition = operation.deconstruct()\n    self.assertEqual(definition[0], \"AddIndex\")\n    self.assertEqual(definition[1], [])\n    self.assertEqual(definition[2], {\"model_name\": \"Pony\", \"index\": covering_index})\n", "def test_rename_model_with_unmanaged_m2m(self):\n    app_label = \"test_rename_model_with_unmanaged_m2m\"\n    project_state = self.set_up_test_model(app_label, second_model=True)\n    Pony = project_state.apps.get_model(app_label, \"Pony\")\n    Stable = project_state.apps.get_model(app_label, \"Stable\")\n    Pony.objects.create(pink=False, weight=4.55)\n    Stable.objects.create()\n    Pony.stables.add(Stable)\n\n    project_state = self.apply_operations(\n        app_label,\n        project_state,\n        operations=[\n            migrations.RenameModel(\"Pony\", \"Pony2\"),\n        ],\n        atomic=connection.features.supports_atomic_references_rename,\n    )\n    Pony = project_state.apps.get_model(app_label, \"Pony2\")\n    Stable = project_state.apps.get_model(app_label, \"Stable\")\n    self.assertEqual(Pony.objects.count(), 1)\n    self.assertEqual(Stable.objects.count(), 1)\n    self.assertEqual(Pony.stables.count(), 1)\n    self.assertEqual(Stable.ponies.count(), 1)\n", "    def test_alter_field_with_deferrable_unique_constraint(self):\n        \"\"\"\n        Tests the AlterField operation on a field that is part of a unique constraint\n        that has a deferrable constraint.\n        \"\"\"\n        app_label = \"test_alflwithduc\"\n        deferrable_unique_constraint = models.UniqueConstraint(\n            fields=[\"pink\"],\n            name=\"deferrable_pink_constraint\",\n            deferrable=models.Deferrable.DEFERRED,\n        )\n        operations = [\n            migrations.CreateModel(\n                \"Pony\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\"pink\", models.IntegerField(default=3)),\n                ],\n                options={\"constraints\": [deferrable_unique_constraint]},\n            ),\n        ]\n        project_state = self.apply_operations(app_label, ProjectState(), operations)\n        operation = migrations.AlterField(\n            \"Pony\",\n            \"pink\",\n            models.IntegerField(null=True),\n        )\n        self.apply_operations(app_label, project_state, operations=[operation])\n        Pony = project_state.apps.get_model(app_label, \"Pony\")\n        Pony.objects.create(pink=1)\n        if connection.features.supports_deferrable_unique_constraints:\n            with transaction.atomic():\n                obj = Pony.objects.create(pink=1)\n                obj.pink = 2\n                obj.save()\n            with self.assertRaises(IntegrityError):\n                with transaction.atomic(), connection.cursor() as cursor:\n                    quoted_name = connection.ops.quote_name(\n                        deferrable_unique_constraint.name\n                    )\n                    cursor.execute(\"SET CONSTRAINTS %s IMMEDIATE\" % quoted_name)\n                    obj = Pony.objects.create(pink=1)\n                    obj.pink = 3\n                    obj.save()\n        else:\n            Pony.objects.create(pink=1)\n", "def test_alter_model_options_preserves_equality(self):\n    project_state = self.set_up_test_model(\"test_almoopp\")\n    # Test the state alteration (no DB alteration to test)\n    options = {\n        \"permissions\": [(\"can_groom\", \"Can groom\")],\n        \"verbose_name\": \"Pony\",\n        \"verbose_name_plural\": \"Ponies\",\n    }\n    operation = migrations.AlterModelOptions(\"Pony\", options)\n    self.assertEqual(operation.describe(), \"Change Meta options on Pony\")\n    self.assertEqual(operation.migration_name_fragment, \"alter_pony_options\")\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_almoopp\", new_state)\n    self.assertEqual(\n        new_state.models[\"test_almoopp\", \"pony\"].options.get(\"permissions\", []),\n        options[\"permissions\"],\n    )\n    self.assertEqual(\n        new_state.models[\"test_almoopp\", \"pony\"].options.get(\"verbose_name\", None),\n        options[\"verbose_name\"],\n    )\n    self.assertEqual(\n        new_state.models[\"test_almoopp\", \"pony\"].options.get(\n            \"verbose_name_plural\", None\n        ),\n        options[\"verbose_name_plural\"],\n    )\n    # And deconstruction\n    definition = operation.deconstruct()\n    self.assertEqual(definition[0], \"AlterModelOptions\")\n    self.assertEqual(definition[1], [])\n    self.assertEqual(\n        definition[2],\n        {\"name\": \"Pony\", \"options\": options},\n    )\n    # The operation should be idempotent.\n    new_state = project_state.clone()\n    new_state.models[\"test_almoopp\", \"pony\"].options = options\n    operation.state_forwards(\"test_almoopp\", new_state)\n    self.assertEqual(\n        new_state.models[\"test_almoopp\", \"pony\"].options.get(\"permissions\", []),\n        options[\"permissions\"],\n    )\n    self.assertEqual(\n        new_state.models[\"test_almoopp\", \"pony\"].options.get(\"verbose_name\", None),\n        options[\"verbose_name\"],\n    )\n    self.assertEqual(\n        new_state.models[\"test_almoopp\", \"pony\"].options.get(\n            \"verbose_name_plural\", None\n        ),\n        options[\"verbose_name_plural\"],\n    )\n"], "sample_69": ["def test_stale_callback():\n    class TestArtist(martist.Artist):\n            super().__init__()\n            self.axes = axes\n            self.stale_called = False\n\n            self.stale_called = True\n\n    fig, ax = plt.subplots()\n    art = TestArtist(ax)\n    assert not art.stale_called\n    art.stale = True\n    assert art.stale_called\n", "def test_artist_invalidate():\n    \"\"\"Test the behavior of Artist's stale attribute.\"\"\"\n    art = martist.Artist()\n    assert art.stale\n    art.stale = False\n    assert not art.stale\n    art.pchanged()\n    assert art.stale\n    art.stale = False\n    art.set_visible(True)\n    assert art.stale\n", "def test_artist_inspector_properties():\n    # test that properties() returns the correct dictionary\n    art = martist.Artist()\n    art.set_alpha(0.5)\n    art.set_visible(False)\n    art.set_zorder(5)\n    props = art.properties()\n    assert props['alpha'] == 0.5\n    assert props['visible'] is False\n    assert props['zorder'] == 5\n", "def test_get_tightbbox():\n    fig, ax = plt.subplots()\n    ax.set_xlim([1, 3])\n    ax.set_ylim([1, 3])\n\n    # Test get_window_extent() for an invisible artist\n    e = mpatches.Ellipse((2, 2), width=1, height=1, visible=False)\n    ax.add_patch(e)\n    assert e.get_window_extent(fig.canvas.get_renderer()).extents == (0, 0, 0, 0)\n\n    # Test get_window_extent() and get_tightbbox() for an artist\n    e = mpatches.Ellipse((2, 2), width=1, height=1)\n    ax.add_patch(e)\n    bbox1 = e.get_window_extent(fig.canvas.get_renderer())\n    bbox2 = e.get_tightbbox(fig.canvas.get_renderer())\n    assert bbox1.extents == bbox2.extents\n\n    # Test get_window_extent() and get_tightbbox() for an artist with clipbox\n    e = mpatches.Ellipse((2, 2), width=1, height=1, clipbox=ax.bbox)\n    ax.add_patch(e)\n    bbox1 = e.get_window_extent(fig.canvas.get_renderer())\n    bbox2 = e.get_tightbbox(fig.canvas.get_renderer())\n    assert bbox1.extents == bbox2.extents\n\n    # Test get_window_extent() and get_tightbbox() for an artist with clippath\n    clip_path = mpatches.Circle((2, 2), radius=1)\n    e = mpatches.Ellipse((2, 2), width=1, height=1, clip_path=clip_path)\n    ax.add_patch(e)\n    bbox1 = e.get_window_extent(fig.canvas.get_renderer())\n    bbox2 = e.get_tightbbox(fig.canvas.get_renderer())\n    assert bbox1.extents == bbox2.extents\n", "def test_artist_setters():\n    # Test that all artist setter methods are accounted for in the\n    # auto-generated set() method.\n\n    class TestArtist(martist.Artist):\n            pass\n\n            pass\n\n    ai = martist.ArtistInspector(TestArtist)\n    assert ai.get_setters() == ['alpha', 'animated', 'clip_box', 'clip_on',\n                                'clip_path', 'gid', 'in_layout', 'label',\n                                'path_effects', 'picker', 'rasterized',\n                                'sketch_params', 'snap', 'transform', 'url',\n                                'visible', 'zorder', 'foo', 'bar']\n\n    assert len(ai.get_aliases()) == 0\n\n    assert TestArtist.set.__doc__.startswith('Set multiple properties at once.\\n\\n')\n    assert 'foo : unknown' in TestArtist.set.__doc__\n    assert 'bar : unknown' in TestArtist.set.__doc__\n    assert 'alpha : scalar or None' in TestArtist.set.__doc__\n    assert 'animated : bool' in TestArtist.set.__doc__\n"], "sample_127": ["def test_latex_degree():\n    assert latex(degree) == r\"^{\\circ}\"\n    assert latex(degree * x) == r\"x^{\\circ}\"\n    assert latex(2 * degree) == r\"2^{\\circ}\"\n    assert latex(radian) == r\"\\mathrm{rad}\"\n    assert latex(radian * x) == r\"x \\mathrm{rad}\"\n    assert latex(2 * radian) == r\"2 \\mathrm{rad}\"\n", "def test_latex_PolyElement_power():\n    Ruv, u,v = ring(\"u,v\", ZZ)\n    Rxyz, x,y,z = ring(\"x,y,z\", Ruv)\n    p = Poly(u**2 + 3*u*v + 1, x, Rxyz)\n    assert latex(p**2) == r\"\\left({u}^{2} + 3 u v + 1\\right)^{2}\"\n    p = Poly(u**2 + 3*u*v + 1, x, Rxyz, domain='QQ')\n    assert latex(p**2) == r\"\\left({u}^{2} + 3 u v + 1\\right)^{2}\"\n", "def test_latex_BasisDependent():\n    C = CoordSys3D('C', 'cartesian')\n    x, y, z = C.base_scalars()\n    xhat, yhat, zhat = C.base_vectors()\n    v = 2*xhat + yhat\n    assert latex(v) == '2\\\\mathbf{\\hat{i}_{C}} + \\\\mathbf{\\hat{j}_{C}}'\n", "def test_latex_styling():\n    expr = 2*x**2 + 3*x + 1\n    assert latex(expr, ln_notation=True) == r\"2 x^{2} + 3 x + 1\"\n    assert latex(expr, mul_symbol='ldot') == r\"2 \\,.\\, x^{2} + 3 \\,.\\, x + 1\"\n    assert latex(expr, inv_trig_style=\"power\") == r\"2 x^{2} + 3 x + 1\"\n    assert latex(expr, order=\"lex\") == r\"2 x^{2} + 3 x + 1\"\n    assert latex(expr, mode=\"equation*\") == r\"\\begin{equation*}2 x^{2} + 3 x + 1\\end{equation*}\"\n", "def test_super_subscript_symbol_names():\n    x = Symbol('x', real=True)\n    y = Symbol('y', real=True)\n    assert latex(x) == \"x\"\n    assert latex(x, symbol_names={x: \"x_{sub}^{super}\"}) == \"x_{sub}^{super}\"\n    assert latex(x**2, symbol_names={x: \"x_{sub}^{super}\"}) == r\"x_{sub}^{super}^{2}\"\n    assert latex(x*y, symbol_names={x: \"x_{sub}^{super}\", y: \"y_{sub}^{super}\"}) == \\\n        r\"x_{sub}^{super} y_{sub}^{super}\"\n    assert latex(x**2, symbol_names={x: \"x^super_sub\"}) == r\"x^{super}_{sub}^{2}\"\n    assert latex(x*y, symbol_names={x: \"x^super_sub\", y: \"y^super_sub\"}) == \\\n        r\"x^{super}_{sub} y^{super}_{sub}\"\n"], "sample_65": ["    def test_floatformat01(self):\n        output = self.engine.render_to_string(\"floatformat01\", {\"a\": 34.23234})\n        self.assertEqual(output, \"34.2\")\n", "    def test_capfirst(self):\n        output = self.engine.render_to_string(\"stringfilter01\", {\"a\": \"hello world\"})\n        self.assertEqual(output, \"Hello world\")\n", "    def test_trunc01(self):\n        output = self.engine.render_to_string(\"trunc01\", {\"a\": \"abcdefghij\"})\n        self.assertEqual(output, \"abcdefghij\")\n", "    def test_stringfilter01(self):\n        output = self.engine.render_to_string(\"stringfilter01\", {\"a\": 'Hello \"World\"!'})\n        self.assertEqual(output, 'Hello \\\\\"World\\\"!')\n", "    def test_join09(self):\n        output = self.engine.render_to_string(\n            \"join09\", {\"a\": [\"alpha\", \"beta & me\"], \"var\": [\"&\"]}\n        )\n        self.assertEqual(output, \"alpha, beta &amp; me\")\n"], "sample_28": ["    def setUp(self):\n        self.site = admin.AdminSite()\n", "    def setUp(self):\n        self.site = admin.AdminSite()\n", "    def setUp(self):\n        self.site = admin.AdminSite()\n", "    def setUpTestData(cls):\n        cls.u1 = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n", "    def setUp(self):\n        self.site = admin.AdminSite(name=\"test_adminsite\")\n        self.site.register(User)\n"], "sample_89": ["def test_get_fslocation_from_item(testdir):\n    test_file = testdir.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    item = testdir.getitems(test_file)[0]\n    location = nodes.get_fslocation_from_item(item)\n    assert location == (test_file, 1)\n\n    test_module = testdir.makepyfile(\n        \"\"\"\n        class TestClass:\n                pass\n    \"\"\"\n    )\n    item = testdir.getitems(test_module)[0]\n    location = nodes.get_fslocation_from_item(item)\n    assert location == (test_module, 3)\n\n    # Test with fslocation attribute\n    item.location = (test_file, 10, \"test_func\")\n    location = nodes.get_fslocation_from_item(item)\n    assert location == (test_file, 10)\n", "def test_get_fslocation_from_item():\n    class FakeItem:\n        location = (\"path\", 1, \"lineno\")\n\n    assert nodes.get_fslocation_from_item(FakeItem()) == (\"path\", 1)\n\n    class FakeItem:\n        obj = object()\n\n    class FakeNode:\n        fspath = \"node_path\"\n\n    FakeItem.parent = FakeNode()\n    assert nodes.get_fslocation_from_item(FakeItem()) == (\"node_path\", -1)\n\n    class FakeItem:\n        pass\n\n    assert nodes.get_fslocation_from_item(FakeItem()) == (\"unknown location\", -1)\n", "def test_get_fslocation_from_item():\n    class FakeItem:\n            self.location = location\n            self.obj = obj\n            self.fspath = fspath\n\n    # Test location from attribute\n    item = FakeItem((\"file\", 10, \"name\"))\n    assert nodes.get_fslocation_from_item(item) == (\"file\", 10)\n\n    # Test location from obj\n    item = FakeItem(None, obj=\"function\")\n    assert nodes.get_fslocation_from_item(item) == getfslineno(\"function\")\n\n    # Test location from fspath\n    item = FakeItem(None, fspath=\"path\")\n    assert nodes.get_fslocation_from_item(item) == (\"path\", -1)\n\n    # Test default\n    item = FakeItem(None)\n    assert nodes.get_fslocation_from_item(item) == (\"unknown location\", -1)\n", "def test_FSCollector_from_parent(testdir):\n    class FakeSession:\n        config = object()\n\n    parent = nodes.Node(\"parent\", config=FakeSession.config, session=FakeSession())\n    fspath = testdir.makefile(\".py\")\n    collector = nodes.FSCollector.from_parent(parent, fspath=fspath)\n\n    assert collector.fspath == fspath\n    assert collector.parent == parent\n    assert collector.session == FakeSession()\n    assert collector._nodeid == str(fspath.relto(testdir))\n    assert collector._norecursepatterns == []  # empty by default\n", "def test_node_repr_failure_item_repr(testdir):\n    \"\"\"Ensure repr_failure returns the expected error message for an item.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n            assert 1 == 0\n    \"\"\"\n    )\n    item = testdir.getitems()[0]\n    excinfo = pytest.raises(AssertionError, item.runtest)\n    error_message = item.repr_failure(excinfo, style=\"long\")\n    assert \"assert 1 == 0\" in error_message\n    assert \"def test()\" in error_message\n"], "sample_80": ["def test_diff_dataset_repr_dims_only(self):\n    ds_a = xr.Dataset(coords={\"x\": [1, 2, 3]})\n    ds_b = xr.Dataset(coords={\"x\": [1, 2]})\n\n    expected = dedent(\n        \"\"\"\\\n    Left and right Dataset objects are not identical\n    Differing dimensions:\n        (x: 3) != (x: 2)\n    \"\"\"\n    )\n\n    actual = formatting.diff_dataset_repr(ds_a, ds_b, \"identical\")\n    assert actual == expected\n", "def test_format_array_flat_dask(self):\n    import dask.array as da\n\n    x = da.from_array(np.arange(100), chunks=10)\n\n    actual = formatting.format_array_flat(x, 2)\n    expected = \"...\"\n    assert expected == actual\n\n    actual = formatting.format_array_flat(x, 9)\n    expected = \"0 ... 99\"\n    assert expected == actual\n\n    actual = formatting.format_array_flat(x, 10)\n    expected = \"0 1 ... 99\"\n    assert expected == actual\n\n    actual = formatting.format_array_flat(x, 13)\n    expected = \"0 1 ... 98 99\"\n    assert expected == actual\n\n    actual = formatting.format_array_flat(x, 15)\n    expected = \"0 1 2 ... 98 99\"\n    assert expected == actual\n\n    actual = formatting.format_array_flat(x, 5)\n    expected = \"0 1\"\n    assert expected == actual\n\n    actual = formatting.format_array_flat(x, 7)\n    expected = \"0 1 2\"\n    assert expected == actual\n\n    actual = formatting.format_array_flat(x, 11)\n    expected = \"0 1 2 3\"\n    assert expected == actual\n\n    actual = formatting.format_array_flat(x, 12)\n    expected = \"0 1 2 3 4\"\n    assert expected == actual\n", "def test_summarize_coord(self):\n    coord = xr.IndexVariable(\"x\", np.array([1, 2, 3]), dims=\"x\")\n    actual = formatting.summarize_coord(\"x\", coord, 20)\n    expected = dedent(\n        \"\"\"\\\n      * x        (x) int64 1 2 3\"\"\"\n    )\n    assert actual == expected\n\n    multi_index = xr.IndexVariable(\n        (\"x\", \"y\"), \n        np.array([(1, 2), (3, 4), (5, 6)]),\n        dims=(\"x\", \"y\"), \n        attrs={\"a\": 1}\n    )\n    actual = formatting.summarize_coord(\"x\", multi_index, 20)\n    expected = dedent(\n        \"\"\"\\\n      * x        (x, y) MultiIndex\n      a          int64 1 2\n      b          int64 3 4\"\"\"\n    )\n    assert actual == expected\n", "def test_diff_dataset_repr_with_multiindex(self):\n    ds_a = xr.Dataset(\n        data_vars={\n            \"var1\": ((\"x\", \"y\"), np.array([[1, 2, 3], [4, 5, 6]], dtype=\"int64\")),\n        },\n        coords={\n            \"x\": xr.IndexVariable(\"x\", np.array([\"a\", \"b\"], dtype=\"U1\")),\n            \"y\": xr.IndexVariable(\n                \"y\",\n                np.array([1, 2, 3], dtype=\"int64\"),\n                dims=\"y\",\n                attrs={\"units\": \"m\"},\n            ),\n        },\n    )\n    ds_a[\"x\"].set_levels(\n        [xr.IndexVariable(\"x1\", np.array([1, 2], dtype=\"int64\"))],\n        level_names=\"x\",\n        inplace=True,\n    )\n\n    ds_b = xr.Dataset(\n        data_vars={\"var1\": ((\"x\", \"y\"), np.array([[1, 2, 3], [4, 5, 6]], dtype=\"int64\"))},\n        coords={\n            \"x\": xr.IndexVariable(\"x\", np.array([\"a\", \"c\"], dtype=\"U1\")),\n            \"y\": xr.IndexVariable(\n                \"y\",\n                np.array([1, 2, 3], dtype=\"int64\"),\n                dims=\"y\",\n                attrs={\"units\": \"kg\"},\n            ),\n        },\n    )\n    ds_b[\"x\"].set_levels(\n        [xr.IndexVariable(\"x1\", np.array([1, 2], dtype=\"int64\"))],\n        level_names=\"x\",\n        inplace=True,\n    )\n\n    expected = dedent(\n        \"\"\"\\\n        Left and right Dataset objects are not identical\n        Differing coordinates:\n        L * x1      (x) int64 1 2\n          * x        (x) MultiIndex\n        R * x1      (x) int64 1 2\n          * x        (x) MultiIndex\n        Coordinates only on the left object:\n          * y        (y) int64 1 2 3\n        Coordinates only on the right object:\n          * y        (y) int64 1 2 3\n        \"\"\"\n    )\n\n    actual = formatting.diff_dataset_repr(ds_a, ds_b, \"identical\")\n    assert actual == expected\n", "    def test_short_data_repr(self):\n        data_array = xr.DataArray(np.arange(100).reshape(10, 10))\n        data_array_large = xr.DataArray(np.arange(100000).reshape(100, 1000))\n        actual = formatting.short_data_repr(data_array)\n        expected = formatting.short_numpy_repr(data_array.data)\n        assert actual == expected\n\n        actual = formatting.short_data_repr(data_array_large)\n        assert actual.startswith(\"[100000 values with dtype=int64]\")\n\n        # test dask array\n        import dask.array as da\n        data_array_dask = xr.DataArray(da.from_array(data_array))\n        actual = formatting.short_data_repr(data_array_dask)\n        assert actual.startswith(\"dask.array<chunksize=(10, 10)>\")\n\n        # test custom __array_function__\n        class CustomArray:\n                self.value = value\n\n                return NotImplemented\n\n            @property\n                return self.value.shape\n\n            @property\n                return self.value.dtype\n\n            @property\n                return self.value.ndim\n\n        data_array_custom = xr.DataArray(CustomArray(np.arange(100).reshape(10, 10)))\n        actual = formatting.short_data_repr(data_array_custom)\n        expected = formatting.short_numpy_repr(data_array_custom.data.value)\n        assert actual == expected\n"], "sample_124": ["def test_inverse_derivatives():\n    x = Symbol('x')\n    assert asinh(x).fdiff() == 1/sqrt(x**2 + 1)\n    assert acosh(x).fdiff() == 1/sqrt(x**2 - 1)\n    assert atanh(x).fdiff() == 1/(1 - x**2)\n    assert acoth(x).fdiff() == 1/(1 - x**2)\n    assert asech(x).fdiff() == -1/(x*sqrt(1 - x**2))\n    assert acsch(x).fdiff() == -1/(x**2*sqrt(1 + x**(-2)))\n", "def test_peeloff_ipi():\n    from sympy import symbols, pi, I\n    x, y = symbols('x y')\n\n    assert _peeloff_ipi(x + I*pi/2) == (x, I*pi/2)\n    assert _peeloff_ipi(x + I*2*pi/3 + I*pi*y) == (x + I*pi*y + I*pi/6, I*pi/2)\n    assert _peeloff_ipi(2*x) == (2*x, 0)\n    assert _peeloff_ipi(I*pi) == (0, I*pi)\n    assert _peeloff_ipi(I*pi/3) == (0, I*pi/3)\n", "def test_issue_sinh_hyperbolics_as_exp():\n    x = Symbol('x')\n    expr = sinh(x) + cosh(x)\n    result = _rewrite_hyperbolics_as_exp(expr)\n    expected = (exp(x) + exp(-x))/2 + (exp(x) + exp(-x))/2\n    assert result == expected\n", "def test_hyperbolic_functions_with_complex_numbers():\n    x = Symbol('x')\n    y = Symbol('y')\n    for func in [sinh, cosh, tanh, coth, csch, sech]:\n        z = x + I*y\n        result = func(z)\n        assert result.conjugate() == func(z.conjugate())\n        assert result.conjugate().conjugate() == result\n", "def test_edge_cases():\n    from sympy import symbols\n    x = symbols('x')\n\n    # Test sinh for large numbers\n    large_number = 10**100\n    assert sinh(large_number).evalf() == large_number / 2\n\n    # Test cosh for large numbers\n    large_number = 10**100\n    assert cosh(large_number).evalf() == large_number / 2\n\n    # Test tanh for large numbers\n    large_number = 10**100\n    assert tanh(large_number).evalf() == 1\n\n    # Test coth for large numbers\n    large_number = 10**100\n    assert coth(large_number).evalf() == 1\n\n    # Test csch for small numbers\n    small_number = 10**-100\n    assert csch(small_number).evalf() == 1/small_number\n\n    # Test sech for small numbers\n    small_number = 10**-100\n    assert sech(small_number).evalf() == 1\n"], "sample_64": ["def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should render prepopulated fields.\n    \"\"\"\n    article = Article.objects.all()[0]\n    request = self.request_factory.get(\n        reverse(\"admin:admin_views_article_change\", args=[article.pk])\n    )\n    request.user = self.superuser\n    admin = ArticleAdmin(Article, site)\n    response = admin.change_view(request, str(article.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIn(\"prepopulated_fields\", template_context)\n    self.assertIn(\"prepopulated_fields_json\", template_context)\n    self.assertIsInstance(template_context[\"prepopulated_fields\"], list)\n    self.assertIsInstance(template_context[\"prepopulated_fields_json\"], str)\n    self.assertJSONSerializable(template_context[\"prepopulated_fields_json\"])\n\n    # Test with a prepopulated field\n    article_admin = ArticleAdmin(Article, site)\n    article_admin.prepopulated_fields = {\"slug\": (\"title\",)}\n    response = article_admin.change_view(request, str(article.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertEqual(len(template_context[\"prepopulated_fields\"]), 1)\n    self.assertEqual(len(template_context[\"prepopulated_fields_json\"]), 1)\n", "def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should render JavaScript for prepopulated fields.\n    \"\"\"\n    article = Article.objects.all()[0]\n    request = self.request_factory.get(\n        reverse(\"admin:admin_views_article_change\", args=[article.pk])\n    )\n    request.user = self.superuser\n    admin = ArticleAdmin(Article, site)\n    response = admin.change_view(request, str(article.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIn(\"prepopulated_fields_json\", template_context)\n    prepopulated_fields_json = json.loads(template_context[\"prepopulated_fields_json\"])\n    self.assertIsInstance(prepopulated_fields_json, list)\n    self.assertGreater(len(prepopulated_fields_json), 0)\n    for field in prepopulated_fields_json:\n        self.assertIn(\"id\", field)\n        self.assertIn(\"name\", field)\n        self.assertIn(\"dependency_ids\", field)\n        self.assertIn(\"dependency_list\", field)\n        self.assertIn(\"maxLength\", field)\n        self.assertIn(\"allowUnicode\", field)\n", "def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should generate the correct JavaScript\n    for the prepopulated fields.\n    \"\"\"\n    article = Article.objects.all()[0]\n    request = self.request_factory.get(\n        reverse(\"admin:admin_views_article_change\", args=[article.pk])\n    )\n    request.user = self.superuser\n    admin = ArticleAdmin(Article, site)\n    response = admin.change_view(request, str(article.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIn(\"prepopulated_fields\", template_context)\n    self.assertIn(\"prepopulated_fields_json\", template_context)\n    prepopulated_fields_json = json.loads(template_context[\"prepopulated_fields_json\"])\n    self.assertEqual(len(prepopulated_fields_json), 1)\n    self.assertEqual(prepopulated_fields_json[0][\"id\"], \"#id_title\")\n    self.assertEqual(prepopulated_fields_json[0][\"name\"], \"title\")\n    self.assertEqual(prepopulated_fields_json[0][\"dependency_ids\"], [\"#id_slug\"])\n    self.assertEqual(prepopulated_fields_json[0][\"dependency_list\"], [\"slug\"])\n    self.assertEqual(prepopulated_fields_json[0][\"maxLength\"], 50)\n    self.assertEqual(prepopulated_fields_json[0][\"allowUnicode\"], False)\n", "    def test_cell_count(self):\n        \"\"\"\n        Test the cell_count filter.\n        \"\"\"\n        admin = ArticleAdmin(Article, site)\n        formset = admin.get_inline_formsets(request=None, obj=None)[0]\n        inline_admin_form = formset.formset[0]\n        inline_admin_form.fields[\"field1\"].is_hidden = True\n        inline_admin_form.fields[\"field2\"].is_hidden = False\n        self.assertEqual(cell_count(inline_admin_form), 2)\n        self.assertEqual(cell_count(formset.formset[1]), 2)\n\n        admin = ArticleAdmin(Article, site)\n        formset = admin.get_inline_formsets(request=None, obj=None)[0]\n        inline_admin_form = formset.formset[0]\n        inline_admin_form.fields[\"field1\"].is_hidden = False\n        inline_admin_form.fields[\"field2\"].is_hidden = False\n        self.assertEqual(cell_count(inline_admin_form), 3)\n        self.assertEqual(cell_count(formset.formset[1]), 3)\n\n        admin = ArticleAdmin(Article, site)\n        formset = admin.get_inline_formsets(request=None, obj=None)[0]\n        inline_admin_form = formset.formset[0]\n        inline_admin_form.fields[\"field1\"].is_hidden = True\n        inline_admin_form.fields[\"field2\"].is_hidden = True\n        formset.can_delete = True\n        self.assertEqual(cell_count(inline_admin_form), 2)\n        self.assertEqual(cell_count(formset.formset[1]), 2)\n\n        admin = ArticleAdmin(Article, site)\n        formset = admin.get_inline_formsets(request=None, obj=None)[0]\n        inline_admin_form = formset.formset[0]\n        inline_admin_form.fields[\"field1\"].is_hidden = False\n        inline_admin_form.fields[\"field2\"].is_hidden = False\n        formset.can_delete = True\n        self.assertEqual(cell_count(inline_admin_form), 4)\n        self.assertEqual(cell_count(formset.formset[1]), 4)\n\n        admin = ArticleAdmin(Article, site)\n        formset = admin.get_inline_formsets(request=None, obj=None)[0]\n        inline_admin_form = formset.formset[0]\n        inline_admin_form.fields[\"field1\"].is_hidden = True\n        inline_admin_form.fields[\"field2\"].is_hidden = True\n        formset.can_delete = False\n        self.assertEqual(cell_count(inline_admin_form), 1)\n        self.assertEqual(cell_count(formset", "def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should pass prepopulated fields.\n    \"\"\"\n    request = self.request_factory.get(\n        reverse(\"admin:admin_views_article_change\", args=[self.article.pk])\n    )\n    request.user = self.superuser\n    admin = ArticleAdmin(Article, site)\n    response = admin.change_view(request, str(self.article.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIsInstance(template_context[\"prepopulated_fields\"], list)\n    self.assertIsInstance(template_context[\"prepopulated_fields_json\"], str)\n\n    # Test the structure of the prepopulated_fields_json\n    prepopulated_fields_json = json.loads(template_context[\"prepopulated_fields_json\"])\n    for field in prepopulated_fields_json:\n        self.assertIn(\"id\", field)\n        self.assertIn(\"name\", field)\n        self.assertIn(\"dependency_ids\", field)\n        self.assertIn(\"dependency_list\", field)\n        self.assertIn(\"maxLength\", field)\n        self.assertIn(\"allowUnicode\", field)\n\n    # Test cell_count filter\n    inline_admin_form = admin.get_inline_instances(request, self.article)\n    template_context = {\"inline_admin_form\": inline_admin_form[0]}\n    cell_count_result = self.render_template_string(\n        \"{% load admin_list %}{{ inline_admin_form|cell_count }}\", template_context\n    ).strip()\n    self.assertIsInstance(cell_count_result, str)\n    self.assertRegex(cell_count_result, r\"^\\d+$\")\n"], "sample_15": ["def test_consistent_language_settings(self):\n    for tag in ['en', 'fr']:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [])\n\n    with self.subTest('get_supported_language_variant raises LookupError'), self.settings(LANGUAGE_CODE='fr-CA'):\n        try:\n            get_supported_language_variant.cache_clear()\n        except AttributeError:\n            pass  # Python < 3.9\n        self.assertEqual(check_language_settings_consistent(None), [\n            Error('You have provided a value for the LANGUAGE_CODE setting that is not in the LANGUAGES setting.', id='translation.E004'),\n        ])\n", "def test_language_settings_consistent(self):\n    with self.settings(LANGUAGE_CODE='en', LANGUAGES=[('en', 'English')]):\n        self.assertEqual(check_language_settings_consistent(None), [])\n\n    with self.settings(LANGUAGE_CODE='es', LANGUAGES=[('en', 'English'), ('es', 'Spanish')]):\n        self.assertEqual(check_language_settings_consistent(None), [])\n\n    with self.settings(LANGUAGE_CODE='invalid', LANGUAGES=[('en', 'English'), ('es', 'Spanish')]):\n        self.assertEqual(check_language_settings_consistent(None), [\n            Error('You have provided a value for the LANGUAGE_CODE setting that is not in the LANGUAGES setting.', id='translation.E004'),\n        ])\n\n    with self.settings(LANGUAGE_CODE='en', LANGUAGES=[]):\n        self.assertEqual(check_language_settings_consistent(None), [\n            Error('You have provided a value for the LANGUAGE_CODE setting that is not in the LANGUAGES setting.', id='translation.E004'),\n        ])\n\n    with self.settings(LANGUAGE_CODE=None, LANGUAGES=[('en', 'English')]):\n        self.assertEqual(check_language_settings_consistent(None), [\n            Error('You have provided an invalid value for the LANGUAGE_CODE setting: None.', id='translation.E001'),\n        ])\n", "    def test_consistent_language_settings(self):\n        self.assertEqual(check_language_settings_consistent(None), [])\n", "def test_inconsistent_language_settings_with_valid_language_code(self):\n    msg = (\n        'You have provided a value for the LANGUAGE_CODE setting that is '\n        'not in the LANGUAGES setting.'\n    )\n    with self.subTest('same language code as LANGUAGES'), self.settings(LANGUAGE_CODE='en'):\n        self.assertEqual(check_language_settings_consistent(None), [])\n\n    with self.subTest('language code with variant'), self.settings(LANGUAGE_CODE='en-gb'):\n        self.assertEqual(check_language_settings_consistent(None), [])\n\n    with self.subTest('language code with script'), self.settings(LANGUAGE_CODE='zh-hans'):\n        self.assertEqual(check_language_settings_consistent(None), [])\n\n    with self.subTest('language code with region'), self.settings(LANGUAGE_CODE='fr-ca'):\n        self.assertEqual(check_language_settings_consistent(None), [])\n", "def test_consistent_language_settings(self):\n    self.assertEqual(check_language_settings_consistent(None), [])\n"], "sample_2": ["def test_sip_with_altkey2():\n    \"\"\"\n    Test that when creating a WCS object using a key, CTYPE with\n    that key is looked at and not the primary CTYPE.\n    fix for #5443.\n    \"\"\"\n    with fits.open(get_pkg_data_filename('data/sip.fits')) as f:\n        w = wcs.WCS(f[0].header)\n    # create a header with two WCSs.\n    h1 = w.to_header(relax=True, key='A')\n    h2 = w.to_header(relax=False)\n    h1['CTYPE1A'] = \"RA---SIN-SIP\"\n    h1['CTYPE2A'] = \"DEC--SIN-SIP\"\n    h1.update(h2)\n    w = wcs.WCS(h1, key=' ')\n    assert (w.wcs.ctype == np.array(['RA---SIN', 'DEC--SIN'])).all()\n", "def test_to_fits_2():\n    \"\"\"\n    Test to_fits() with D2IMDIS distortion.\n    \"\"\"\n    fits_name = get_pkg_data_filename('data/hst_0001.fits')\n    w = wcs.WCS(fits_name)\n    wfits = w.to_fits()\n    assert isinstance(wfits, fits.HDUList)\n    assert isinstance(wfits[0], fits.PrimaryHDU)\n    assert isinstance(wfits[1], fits.ImageHDU)\n", "def test_copy_sip():\n    \"\"\"\n    Test that WCS object copying preserves SIP coefficients\n    \"\"\"\n    header = get_pkg_data_contents('data/sip.fits', encoding='binary')\n    w1 = wcs.WCS(header)\n    w2 = w1.copy()\n    assert np.all(w1.sip.a == w2.sip.a)\n    assert np.all(w1.sip.b == w2.sip.b)\n    assert np.all(w1.sip.ap == w2.sip.ap)\n    assert np.all(w1.sip.bp == w2.sip.bp)\n    assert w1.sip.crpix == w2.sip.crpix\n    assert w1.sip.a_order == w2.sip.a_order\n    assert w1.sip.b_order == w2.sip.b_order\n    assert w1.sip.ap_order == w2.sip.ap_order\n    assert w1.sip.bp_order == w2.sip.bp_order\n", "def test_radesys():\n    \"\"\"\n    Test handling of the RADESYS keyword.\n    \"\"\"\n    w = wcs.WCS()\n    w.wcs.radesys = 'FK4'\n    assert w.wcs.radesys == 'FK4'\n\n    w.wcs.radesys = 'FK5'\n    assert w.wcs.radesys == 'FK5'\n\n    with pytest.raises(ValueError):\n        w.wcs.radesys = 'invalid'\n", "def test_nonstandard_wcsaxes():\n    \"\"\"\n    Test for nonstandard WCSAXES (fix #5511).\n    \"\"\"\n    hdr = fits.Header()\n    hdr['WCSAXES'] = 2.5\n    with pytest.raises(wcs.wcs.InvalidTransformError):\n        wcs.WCS(hdr)\n"], "sample_41": ["def test_formset_absolute_max_zero(self):\n    \"\"\"If absolute_max is 0 then no form is rendered at all, unless initial data is present.\"\"\"\n    AbsoluteMaxFavoriteDrinkFormSet = formset_factory(\n        FavoriteDrinkForm,\n        absolute_max=0,\n    )\n    formset = AbsoluteMaxFavoriteDrinkFormSet()\n    self.assertEqual(formset.forms, [])\n\n    # initial trumps absolute_max\n    initial = [\n        {'name': 'Fernet and Coke'},\n        {'name': 'Bloody Mary'},\n    ]\n    formset = AbsoluteMaxFavoriteDrinkFormSet(initial=initial)\n    self.assertHTMLEqual(\n        '\\n'.join(str(form) for form in formset.forms),\n        \"\"\"<tr><th><label for=\"id_form-0-name\">Name:</label></th>", "def test_can_delete_extra_with_initial(self):\n    ChoiceFormFormset = formset_factory(form=Choice, can_delete=True, can_delete_extra=False, extra=2)\n    formset = ChoiceFormFormset(initial=[{'choice': 'Zero', 'votes': '1'}])\n    self.assertEqual(len(formset.forms), 3)\n    self.assertIn('DELETE', formset.forms[0].fields)\n    self.assertNotIn('DELETE', formset.forms[1].fields)\n    self.assertNotIn('DELETE', formset.forms[2].fields)\n\n    formset = ChoiceFormFormset(data={\n        'form-0-choice': 'Zero',\n        'form-0-votes': '0',\n        'form-0-DELETE': 'on',\n        'form-1-choice': 'One',\n        'form-1-votes': '1',\n        'form-2-choice': '',\n        'form-2-votes': '',\n        'form-TOTAL_FORMS': '3',\n        'form-INITIAL_FORMS': '1',\n    }, initial=[{'choice': 'Zero', 'votes': '1'}])\n    self.assertEqual(formset.cleaned_data, [\n        {'choice': 'Zero', 'votes': 0, 'DELETE': True},\n        {'choice': 'One', 'votes': 1},\n        {},\n    ])\n    self.assertIs(formset._should_delete_form(formset.forms[0]), True)\n    self.assertIs(formset._should_delete_form(formset.forms[1]), False)\n    self.assertIs(formset._should_delete_form(formset.forms[2]), False)\n", "def test_empty_form_with_initial_data(self):\n    \"\"\"The empty form is correctly created when initial data is passed.\"\"\"\n    ChoiceFormSet = formset_factory(Choice, extra=1)\n    initial = [{'choice': 'Calexico', 'votes': 100}]\n    formset = ChoiceFormSet(auto_id=False, prefix='choices', initial=initial)\n    self.assertEqual(formset.empty_form.fields['choice'].initial, '')\n    self.assertEqual(formset.empty_form.fields['votes'].initial, '')\n    ChoiceFormSet = formset_factory(Choice, extra=1, initial={'choice': 'default'})\n    formset = ChoiceFormSet(auto_id=False, prefix='choices')\n    self.assertEqual(formset.empty_form.fields['choice'].initial, 'default')\n    self.assertEqual(formset.empty_form.fields['votes'].initial, '')\n", "def test_empty_permitted(self):\n    \"\"\"empty_permitted is set correctly on forms.\"\"\"\n    LimitedFavoriteDrinkFormSet = formset_factory(FavoriteDrinkForm, extra=3)\n    formset = LimitedFavoriteDrinkFormSet()\n    self.assertFalse(formset.forms[0].empty_permitted)\n    self.assertTrue(formset.forms[1].empty_permitted)\n    self.assertTrue(formset.forms[2].empty_permitted)\n    self.assertTrue(formset.empty_form.empty_permitted)\n\n    LimitedFavoriteDrinkFormSet = formset_factory(FavoriteDrinkForm, extra=3, min_num=2)\n    formset = LimitedFavoriteDrinkFormSet()\n    self.assertFalse(formset.forms[0].empty_permitted)\n    self.assertFalse(formset.forms[1].empty_permitted)\n    self.assertTrue(formset.forms[2].empty_permitted)\n\n    LimitedFavoriteDrinkFormSet = formset_factory(FavoriteDrinkForm, extra=3, min_num=4)\n    formset = LimitedFavoriteDrinkFormSet()\n    self.assertFalse(formset.forms[0].empty_permitted)\n    self.assertFalse(formset.forms[1].empty_permitted)\n    self.assertFalse(formset.forms[2].empty_permitted)\n    self.assertFalse(formset.forms[3].empty_permitted)\n    self.assertTrue(formset.forms[4].empty_permitted)\n\n    LimitedFavoriteDrinkFormSet = formset_factory(FavoriteDrinkForm, extra=3)\n    initial = [{'name': 'Fernet and Coke'}, {'name': 'Bloody Mary'}, {'name': 'Gin Tonic'}]\n    formset = LimitedFavoriteDrinkFormSet(initial=initial)\n    self.assertFalse(formset.forms[0].empty_permitted)\n    self.assertFalse(formset.forms[1].empty_permitted)\n    self.assertFalse(formset.forms[2].empty_permitted)\n    self.assertTrue(formset.forms[3].empty_permitted)\n\n    LimitedFavoriteDrinkFormSet = formset_factory(FavoriteDrinkForm, extra=3, can_delete=True)\n    formset = LimitedFavoriteDrinkFormSet()\n    self.assertFalse(formset.forms[0].empty_permitted)\n    self.assertTrue(formset.forms[1].empty_permitted)\n    self.assertTrue(formset.forms[2].empty_permitted)\n\n    LimitedFavoriteDrinkFormSet = formset_factory(FavoriteDrinkForm, extra=3, can_delete=True)\n    initial = [{'name': 'Fernet and Coke'}]\n    formset = LimitedFavoriteDrinkFormSet(initial=initial)\n    self.assertFalse(formset", "def test_management_form_prefix_collision(self):\n    \"\"\"\n    Formset management form's prefix collision with form field name.\n    \"\"\"\n    class CustomForm(Form):\n        total_forms = IntegerField(label='Custom TOTAL_FORMS field')\n        initial_forms = IntegerField(label='Custom INITIAL_FORMS field')\n\n    data = {\n        'form-TOTAL_FORMS': '2',  # the number of forms rendered\n        'form-INITIAL_FORMS': '0',  # the number of forms with initial data\n        'form-MIN_NUM_FORMS': '0',  # min number of forms\n        'form-MAX_NUM_FORMS': '0',  # max number of forms\n        'form-0-total_forms': '1',\n        'form-0-initial_forms': '0',\n        'form-0-total_forms_1': '2',\n        'form-0-initial_forms_1': '1',\n    }\n    CustomFormset = formset_factory(CustomForm)\n    formset = CustomFormset(data, prefix='form')\n    self.assertTrue(formset.is_valid())\n    self.assertEqual(formset.management_form.cleaned_data, {'TOTAL_FORMS': 2, 'INITIAL_FORMS': 0, 'MIN_NUM_FORMS': 0, 'MAX_NUM_FORMS': 0})\n"], "sample_132": ["def test_closest_points():\n    p1, p2, p3, p4 = Point2D(1, 1), Point2D(3, 1), Point2D(3, 3), Point2D(1, 3)\n    assert closest_points(p1, p2, p3, p4) == {(p1, p2), (p2, p3), (p3, p4), (p4, p1)}\n    assert closest_points(p1, p2, p3, p4, p1, p2, p3, p4) == {(p1, p2), (p2, p3), (p3, p4), (p4, p1)}\n", "def test_are_coplanar():\n    p1 = Point3D(1, 2, 3)\n    p2 = Point3D(4, 5, 6)\n    p3 = Point3D(7, 8, 9)\n    p4 = Point3D(10, 11, 12)\n    assert are_coplanar(p1, p2, p3, p4) == True\n    assert are_coplanar(p1, p2, p3, p4, p3) == True\n    assert are_coplanar(p1, p2, p3, p4, p1) == True\n    p5 = Point3D(1, 2, 3.1)\n    assert are_coplanar(p1, p2, p3, p4, p5) == False\n    l1 = Line3D(p1, p2)\n    l2 = Line3D(p3, p4)\n    l3 = Line3D(p1, p5)\n    assert are_coplanar(l1, l2, l3) == False\n    p6 = Point3D(0, 0, 0)\n    p7 = Point3D(1, 0, 0)\n    p8 = Point3D(0, 1, 0)\n    pl = Plane(p6, p7, p8)\n    assert are_coplanar(pl, p6, p7, p8) == True\n    assert are_coplanar(pl, p6, p7, p8, p5) == False\n", "def test_closest_points():\n    p1 = Point2D(0, 0)\n    p2 = Point2D(3, 0)\n    p3 = Point2D(3, 4)\n    assert closest_points(p1, p2, p3) == {(p1, p2)}\n    p4 = Point2D(2, 0)\n    assert closest_points(p1, p2, p3, p4) == {(p1, p2), (p2, p3), (p3, p4), (p4, p1)}\n\n", "def test_closest_points():\n    p = Point2D(0, 0)\n    q = Point2D(1, 0)\n    r = Point2D(1, 1)\n    s = Point2D(0, 1)\n    assert closest_points(p, q, r, s) == {(p, q), (q, s), (r, s), (p, r)}\n\n", "def test_closest_and_farthest_points():\n    assert closest_points(Point(0, 0), Point(3, 0), Point(0, 4)) == {(Point2D(0, 0), Point2D(3, 0))}\n    assert farthest_points(Point(0, 0), Point(3, 0), Point(0, 4)) == {(Point2D(3, 0), Point2D(0, 4))}\n    assert closest_points(Point(0, 0), Point(2, 0), Point(1, 1), Point(2, 2), Point(0, 2)) == {(Point2D(1, 1), Point2D(2, 2))}\n    assert farthest_points(Point(0, 0), Point(2, 0), Point(1, 1), Point(2, 2), Point(0, 2)) == {(Point2D(0, 0), Point2D(2, 2))}\n    raises(ValueError, lambda: closest_points(Point(0, 0)))\n    raises(ValueError, lambda: farthest_points(Point(0, 0)))\n    raises(ValueError, lambda: closest_points(Point(0, 0), Point(0, 0)))\n    raises(ValueError, lambda: farthest_points(Point(0, 0), Point(0, 0)))\n"], "sample_152": ["def test_array_diff():\n    x, y = symbols('x y')\n    A = ImmutableDenseNDimArray([[x, y], [1, x*y]])\n    assert A.diff(x) == ImmutableDenseNDimArray([[1, 0], [0, y]])\n    assert A.diff(y) == ImmutableDenseNDimArray([[0, 1], [0, x]])\n", "def test_immutable_ndim_array_hash():\n    A = ImmutableDenseNDimArray([[1, 2], [3, 4]])\n    B = ImmutableDenseNDimArray([[1, 2], [3, 4]])\n    assert hash(A) == hash(B)\n\n    C = ImmutableDenseNDimArray([[1, 2], [3, 5]])\n    assert hash(A) != hash(C)\n\n    D = ImmutableSparseNDimArray([[1, 2], [3, 4]])\n    assert hash(A) == hash(D)\n\n    E = ImmutableSparseNDimArray([[1, 2], [3, 5]])\n    assert hash(A) != hash(E)\n", "def test_ndim_array_properties():\n    for ArrayType in array_types:\n        test_array = ArrayType([[1, 2], [3, 4]])\n        assert test_array.shape == (2, 2)\n        assert len(test_array) == 4\n        assert test_array.rank() == 2\n        assert test_array.tolist() == [[1, 2], [3, 4]]\n\n        test_array = ArrayType([1, 2, 3, 4], shape=(2, 2))\n        assert test_array.shape == (2, 2)\n        assert len(test_array) == 4\n        assert test_array.rank() == 2\n        assert test_array.tolist() == [[1, 2], [3, 4]]\n\n        test_array = ArrayType([[1, 2], [3, 4], [5, 6]])\n        assert test_array.shape == (3, 2)\n        assert len(test_array) == 6\n        assert test_array.rank() == 2\n        assert test_array.tolist() == [[1, 2], [3, 4], [5, 6]]\n\n        test_array = ArrayType([1, 2, 3, 4, 5, 6], shape=(3, 2))\n        assert test_array.shape == (3, 2)\n        assert len(test_array) == 6\n        assert test_array.rank() == 2\n        assert test_array.tolist() == [[1, 2], [3, 4], [5, 6]]\n\n        test_array = ArrayType([])\n        assert test_array.shape == (0,)\n        assert len(test_array) == 0\n        assert test_array.rank() == 1\n        assert test_array.tolist() == []\n", "def test_ndim_array_rank():\n    for ArrayType in array_types:\n        # Test rank method with different ranks\n        test_array = ArrayType([[1, 2, 3], [4, 5, 6]])\n        assert test_array.rank() == 2\n\n        test_array = ArrayType([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n        assert test_array.rank() == 3\n\n        test_array = ArrayType([[[[1, 2], [3, 4]], [[5, 6], [7, 8]]], [[[9, 10], [11, 12]], [[13, 14], [15, 16]]]])\n        assert test_array.rank() == 4\n\n        # Test rank method with a single element\n        test_array = ArrayType([1])\n        assert test_array.rank() == 1\n\n        # Test rank method with an empty array\n        test_array = ArrayType([])\n        assert test_array.rank() == 1\n", "def test_issue_ndimarray_iter():\n    for ArrayType in array_types:\n        a = ArrayType([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n        assert list(a) == [1, 2, 3, 4, 5, 6, 7, 8]\n\n        a = ArrayType([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n        assert len(a) == 8\n        assert a.tolist() == [[1, 2], [3, 4], [5, 6], [7, 8]]\n\n        a = ArrayType([[1, 2], [3, 4]])\n        assert list(a) == [1, 2, 3, 4]\n        assert a.tolist() == [[1, 2], [3, 4]]\n\n        a = ArrayType([1, 2, 3, 4], (2, 2))\n        assert list(a) == [1, 2, 3, 4]\n        assert a.tolist() == [[1, 2], [3, 4]]\n\n        a = ArrayType([[1, 2, 3, 4], [5, 6, 7, 8]])\n        assert list(a) == [1, 2, 3, 4, 5, 6, 7, 8]\n        assert a.tolist() == [[1, 2, 3, 4], [5, 6, 7, 8]]\n\n        a = ArrayType([1, 2, 3, 4, 5, 6], (2, 3))\n        assert list(a) == [1, 2, 3, 4, 5, 6]\n        assert a.tolist() == [[1, 2, 3], [4, 5, 6]]\n\n        a = ArrayType([1, 2, 3, 4, 5, 6, 7, 8], (2, 2, 2))\n        assert list(a) == [1, 2, 3, 4, 5, 6, 7, 8]\n        assert a.tolist() == [[[1, 2], [3, "], "sample_51": ["def test_directory_index_with_subdirectory(self):\n    response = self.client.get(\"/%s/subdir/subdir/\" % self.prefix)\n    self.assertContains(response, \"Index of subdir/subdir/\")\n    # File with a leading dot (e.g. .hidden) aren't displayed.\n    self.assertEqual(response.context[\"file_list\"], [])\n", "def test_directory_index_non_ascii(self):\n    \"\"\"Test directory index with non-ASCII characters in directory name.\"\"\"\n    response = self.client.get(\"/%s/subdir_with_accents/\" % self.prefix)\n    self.assertContains(response, \"Index of subdir_with_accents/\")\n    # File with a leading dot (e.g. .hidden) aren't displayed.\n    self.assertEqual(response.context[\"file_list\"], [\"visible\"])\n", "def test_was_modified_since_with_length(self):\n    \"\"\"\n    Test was_modified_since() with length in If-Modified-Since header\n    \"\"\"\n    mtime = 1343416141\n    size = 1024\n    header = f\"Thu, 1 Jan 1970 00:00:00 GMT; length={size}\"\n    self.assertFalse(was_modified_since(header, mtime, size))\n    # Test with different length\n    header = f\"Thu, 1 Jan 1970 00:00:00 GMT; length=2048\"\n    self.assertTrue(was_modified_since(header, mtime, size))\n", "def test_directory_index_with_directory_names_starting_with_dot(self):\n    \"\"\"\n    Directories whose names start with a dot shouldn't be displayed in the index.\n    \"\"\"\n    # Create a hidden directory\n    hidden_dir_path = path.join(media_dir, \".hidden\")\n    Path(hidden_dir_path).mkdir(exist_ok=True)\n    \n    response = self.client.get(\"/%s/\" % self.prefix)\n    self.assertNotIn(\".hidden/\", response.context[\"file_list\"])\n", "def test_serve_directory(self):\n    \"The static view raises a 404 when show_indexes is False and path is a directory\"\n    urlconf = [\n        self.prefix + r\"^/(?P<path>.*)$\",\n        \"django.views.static.serve\",\n        {\"document_root\": media_dir, \"show_indexes\": False},\n    ]\n    with self.settings(ROOT_URLCONF=urlconf):\n        response = self.client.get(\"/%s/\" % self.prefix)\n        self.assertEqual(404, response.status_code)\n"], "sample_134": ["def test_MatrixBase():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    A = MatrixSymbol(\"A\", 2, 2)\n    f = lambdify((A,), A, 'numpy')\n\n    A_ = np.array([[1, 2], [3, 4]])\n    assert np.array_equal(f(A_), A_)\n\n    B = Identity(2)\n    f = lambdify((), B, 'numpy')\n\n    assert np.array_equal(f(), np.eye(2))\n", "def test_MatrixBase():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    M = MatrixSymbol(\"M\", 3, 3)\n    N = MatrixSymbol(\"N\", 3, 3)\n    expr = M + N\n    printer = NumPyPrinter()\n    assert printer.doprint(expr) == 'numpy.add(M, N)'\n\n    M = MatrixSymbol(\"M\", 3, 3)\n    expr = M + 2\n    printer = NumPyPrinter()\n    assert printer.doprint(expr) == 'numpy.add(M, 2)'\n\n    M = MatrixSymbol(\"M\", 3, 3)\n    expr = 2 + M\n    printer = NumPyPrinter()\n    assert printer.doprint(expr) == 'numpy.add(2, M)'\n", "compilation error", "def test_numpyprinter_functions():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    printer = NumPyPrinter()\n\n    # Test _print_Arg\n    expr = x.as_real_imag()[1]\n    assert printer.doprint(expr) == \"numpy.angle(x)\"\n\n    # Test _print_Im\n    expr = x.as_real_imag()[1]\n    assert printer.doprint(expr) == \"numpy.imag(x)\"\n\n    # Test _print_Re\n    expr = x.as_real_imag()[0]\n    assert printer.doprint(expr) == \"numpy.real(x)\"\n\n    # Test _print_Sinc\n    from sympy.functions.elementary.trigonometric import sinc\n    expr = sinc(x)\n    assert printer.doprint(expr) == \"numpy.sinc(x / pi)\"\n\n    # Test _print_BlockMatrix\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    expr = BlockMatrix([[A, B]])\n    assert printer.doprint(expr) == \"numpy.block([[A, B]])\"\n\n    # Test _print_Identity\n    expr = Identity(3)\n    assert printer.doprint(expr) == \"numpy.eye(3)\"\n\n    # Test _print_CodegenArrayContraction\n    M = MatrixSymbol('M', 2, 2)\n    N = MatrixSymbol('N', 2, 2)\n    expr = CodegenArrayContraction.from_MatMul(M*N)\n    assert printer.doprint(expr) == \"numpy.einsum(M, [0, 1], N, [1, 2])\"\n\n    # Test _print_CodegenArrayDiagonal\n    M = MatrixSymbol('M', 2, 2)\n    expr = CodegenArrayDiagonal(M, (0, 1))\n    assert printer.doprint(expr) == \"numpy.diagonal(M, 0, axis1=0, axis2=1)\"\n\n    # Test _print_CodegenArrayPermuteDims\n    M = MatrixSymbol('M', 2, 2)\n    expr = CodegenArrayPermuteDims(M, [1, 0])\n    assert printer.doprint(expr) == \"numpy.transpose(M, (1, 0))\"\n\n    # Test _print_CodegenArrayElementwiseAdd\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B", "def test_MatPow():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    A = MatrixSymbol(\"A\", 3, 3)\n    expr = A ** 2\n    f = lambdify((A,), expr, \"numpy\")\n\n    a_ = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    assert np.array_equal(f(a_), np.linalg.matrix_power(a_, 2))\n\n"], "sample_55": ["def test_base_command_init_invalid_requires_system_checks(self):\n    class Command(BaseCommand):\n        requires_system_checks = \"x\"\n\n    msg = \"requires_system_checks must be a list or tuple.\"\n    with self.assertRaisesMessage(TypeError, msg):\n        Command()\n", "def test_base_command_output_transaction_wrapper(self):\n    class Command(BaseCommand):\n        output_transaction = True\n\n            return \"SELECT * FROM table;\"\n\n    out = StringIO()\n    management.call_command(\"test\", stdout=out)\n    output = out.getvalue()\n    self.assertTrue(output.strip().startswith(connection.ops.start_transaction_sql()))\n    self.assertTrue(output.strip().endswith(connection.ops.end_transaction_sql()))\n    self.assertIn(\"SELECT * FROM table;\", output)\n", "    def test_base_command_output_transaction_with_color(self):\n        output = management.call_command(\n            \"transaction\", stdout=StringIO(), no_color=False\n        )\n        self.assertTrue(\n            output.strip().startswith(connection.ops.start_transaction_sql())\n        )\n        self.assertTrue(output.strip().endswith(connection.ops.end_transaction_sql()))\n        self.assertIn(\"BEGIN;\", output)\n        self.assertIn(\"COMMIT;\", output)\n        self.assertIn(\"\\033[1;33m\", output)  # ANSI color code for yellow\n", "def test_command_output_transaction_without_database(self):\n    \"\"\"\n    Test that the output_transaction option is disabled if no database is\n    configured.\n    \"\"\"\n    with self.settings(DATABASES={}):\n        output = management.call_command(\"transaction\", stdout=StringIO(), no_color=True)\n        self.assertFalse(output.startswith(connection.ops.start_transaction_sql()))\n        self.assertFalse(output.endswith(connection.ops.end_transaction_sql()))\n", "    def test_add_base_argument_suppressed(self):\n        \"\"\"add_base_argument() suppresses help text for specified arguments.\"\"\"\n        command = BaseCommand()\n        parser = ArgumentParser()\n        command.suppressed_base_arguments.add(\"--version\")\n        command.add_base_argument(parser, \"--version\")\n        action = next(a for a in parser._actions if a.dest == \"version\")\n        self.assertIs(action.help, argparse.SUPPRESS)\n"], "sample_49": ["def test_get_template_directories_to_path_called(self, mock_to_path):\n    autoreload.get_template_directories()\n    self.assertEqual(mock_to_path.call_count, 2)\n", "def test_reset_loaders_with_cached_loader(self, mock_reset):\n    autoreload.reset_loaders()\n    self.assertEqual(mock_reset.call_count, 2)\n", "    def test_reset_nested_loaders(self, mock_reset):\n        autoreload.reset_loaders()\n        self.assertEqual(mock_reset.call_count, 2)\n", "    def test_template_changed_in_nested_template_directory(self, mock_reset):\n        template_path = Path(__file__).parent / 'templates' / 'subdir' / 'index.html'\n        self.assertTrue(autoreload.template_changed(None, template_path))\n        mock_reset.assert_called_once()\n", "def test_reset_nested_loaders(self, mock_reset):\n    autoreload.reset_loaders()\n    self.assertEqual(mock_reset.call_count, 1)\n    self.assertEqual(mock_reset.call_args[0][0][0].__class__.__name__, 'Loader')\n    self.assertEqual(mock_reset.call_args[0][0][1].__class__.__name__, 'Loader')\n"], "sample_13": ["    def test_safe_parsing_rfc1123(self):\n        parsed = parse_http_date_safe('Sun, 06 Nov 1994 08:49:37 GMT')\n        self.assertEqual(datetime.utcfromtimestamp(parsed), datetime(1994, 11, 6, 8, 49, 37))\n", "    def test_valid_date(self):\n        self.assertEqual(parse_http_date_safe('Mon, 01 Jan 2007 01:54:21 GMT'), 1167616461)\n", "    def test_fields_limit_exceeded(self):\n        qs = '&'.join(['a=%s' % i for i in range(1024)])\n        with self.assertRaisesMessage(TooManyFieldsSent, 'The number of GET/POST parameters exceeded settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'):\n            limited_parse_qsl(qs, fields_limit=1000)\n", "    def test_limited_fields(self):\n        self.assertEqual(limited_parse_qsl('a=1&b=2&c=3', keep_blank_values=False, encoding='utf-8', errors='replace', fields_limit=5), \n                         [('a', '1'), ('b', '2'), ('c', '3')])\n        with self.assertRaisesMessage(TooManyFieldsSent, \"The number of GET/POST parameters exceeded settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.\"):\n            limited_parse_qsl('a=1&b=2&c=3', keep_blank_values=False, encoding='utf-8', errors='replace', fields_limit=2)\n", "    def test_fields_limit(self):\n        with self.assertRaisesMessage(TooManyFieldsSent, \"The number of GET/POST parameters exceeded settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.\"):\n            limited_parse_qsl('a=1&a=2&a=3', fields_limit=2)\n"], "sample_48": ["def test_alter_order_with_respect_to_remove(self):\n    \"\"\"\n    Tests the AlterOrderWithRespectTo operation on removing order_with_respect_to option.\n    \"\"\"\n    project_state = self.set_up_test_model(\"test_alorwrttor\", related_model=True)\n    # Test the state alteration\n    operation = migrations.AlterOrderWithRespectTo(\"Rider\", None)\n    self.assertEqual(operation.describe(), \"Set order_with_respect_to on Rider to None\")\n    self.assertEqual(\n        operation.migration_name_fragment,\n        'alter_rider_order_with_respect_to',\n    )\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_alorwrttor\", new_state)\n    self.assertEqual(\n        project_state.models[\"test_alorwrttor\", \"rider\"].options.get(\"order_with_respect_to\", None),\n        \"pony\"\n    )\n    self.assertIsNone(\n        new_state.models[\"test_alorwrttor\", \"rider\"].options.get(\"order_with_respect_to\", None)\n    )\n    # Make sure there's a matching index\n    self.assertColumnExists(\"test_alorwrttor_rider\", \"_order\")\n    # Test the database alteration\n    with connection.schema_editor() as editor:\n        operation.database_forwards(\"test_alorwrttor\", editor, project_state, new_state)\n    self.assertColumnNotExists(\"test_alorwrttor_rider\", \"_order\")\n    # And test reversal\n    with connection.schema_editor() as editor:\n        operation.database_backwards(\"test_alorwrttor\", editor, new_state, project_state)\n    self.assertColumnExists(\"test_alorwrttor_rider\", \"_order\")\n    # And deconstruction\n    definition = operation.deconstruct()\n    self.assertEqual(definition[0], \"AlterOrderWithRespectTo\")\n    self.assertEqual(definition[1], [])\n    self.assertEqual(definition[2], {'name': \"Rider\", 'order_with_respect_to': None})\n", "def test_rename_model_with_through(self):\n    \"\"\"\n    Tests the RenameModel operation with a model used as a through model.\n    \"\"\"\n    app_label = \"test_rename_model_with_through\"\n    project_state = self.apply_operations(app_label, ProjectState(), operations=[\n        migrations.CreateModel(\"Rider\", fields=[\n            (\"id\", models.AutoField(primary_key=True)),\n        ]),\n        migrations.CreateModel(\"Pony\", fields=[\n            (\"id\", models.AutoField(primary_key=True)),\n        ]),\n        migrations.CreateModel(\"PonyRider\", fields=[\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"rider\", models.ForeignKey(\"Rider\", models.CASCADE)),\n            (\"pony\", models.ForeignKey(\"Pony\", models.CASCADE)),\n        ]),\n        migrations.AddField(\n            \"Pony\",\n            \"riders\",\n            models.ManyToManyField(\"Rider\", through=\"PonyRider\"),\n        ),\n    ])\n    Pony = project_state.apps.get_model(app_label, \"Pony\")\n    Rider = project_state.apps.get_model(app_label, \"Rider\")\n    PonyRider = project_state.apps.get_model(app_label, \"PonyRider\")\n    pony = Pony.objects.create()\n    rider = Rider.objects.create()\n    PonyRider.objects.create(pony=pony, rider=rider)\n\n    project_state = self.apply_operations(app_label, project_state, operations=[\n        migrations.RenameModel(\"PonyRider\", \"PonyRider2\"),\n    ])\n    Pony = project_state.apps.get_model(app_label, \"Pony\")\n    Rider = project_state.apps.get_model(app_label, \"Rider\")\n    PonyRider = project_state.apps.get_model(app_label, \"PonyRider2\")\n    pony = Pony.objects.first()\n    rider = Rider.objects.create()\n    PonyRider.objects.create(pony=pony, rider=rider)\n    self.assertEqual(Pony.objects.count(), 1)\n    self.assertEqual(Rider.objects.count(), 2)\n    self.assertEqual(PonyRider.objects.count(), 2)\n    self.assertEqual(pony.riders.count(), 2)\n", "def test_rename_model_preserve_order_with_respect_to(self):\n    \"\"\"\n    RenameModel preserves order_with_respect_to.\n    \"\"\"\n    project_state = self.set_up_test_model(\"test_rnmoopwrt\", related_model=True)\n    # Test the state alteration\n    operation = migrations.RenameModel(\"Rider\", \"HorseRider\")\n    self.assertEqual(operation.describe(), \"Rename model Rider to HorseRider\")\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_rnmoopwrt\", new_state)\n    self.assertNotIn((\"test_rnmoopwrt\", \"rider\"), new_state.models)\n    self.assertIn((\"test_rnmoopwrt\", \"horserider\"), new_state.models)\n    # RenameModel also repoints all incoming FKs and M2Ms\n    self.assertEqual(\n        new_state.models[\"test_rnmoopwrt\", \"horserider\"].options['order_with_respect_to'],\n        'pony',\n    )\n    # Test the database alteration\n    self.assertTableExists(\"test_rnmoopwrt_rider\")\n    self.assertTableNotExists(\"test_rnmoopwrt_horserider\")\n    if connection.features.supports_foreign_keys:\n        self.assertFKExists(\"test_rnmoopwrt_rider\", [\"pony_id\"], (\"test_rnmoopwrt_pony\", \"id\"))\n        self.assertFKNotExists(\"test_rnmoopwrt_rider\", [\"pony_id\"], (\"test_rnmoopwrt_horserider\", \"id\"))\n    atomic_rename = connection.features.supports_atomic_references_rename\n    with connection.schema_editor(atomic=atomic_rename) as editor:\n        operation.database_forwards(\"test_rnmoopwrt\", editor, project_state, new_state)\n    self.assertTableNotExists(\"test_rnmoopwrt_rider\")\n    self.assertTableExists(\"test_rnmoopwrt_horserider\")\n    if connection.features.supports_foreign_keys:\n        self.assertFKNotExists(\"test_rnmoopwrt_horserider\", [\"pony_id\"], (\"test_rnmoopwrt_rider\", \"id\"))\n        self.assertFKExists(\"test_rnmoopwrt_horserider\", [\"pony_id\"], (\"test_rnmoopwrt_pony\", \"id\"))\n    # And test reversal\n    with connection.schema_editor(atomic", "def test_rename_field_model_through(self):\n    app_label = 'test_rename_field_model_through'\n    table_name = '%s_pony' % app_label\n    project_state = self.set_up_test_model(app_label, second_model=True)\n\n    # Add M2M field with through model.\n    project_state = self.apply_operations(app_label, project_state, [\n        migrations.CreateModel(\n            'PonyRider',\n            fields=[\n                ('id', models.AutoField(primary_key=True)),\n                ('pony', models.ForeignKey('test_rename_field_model_through.Pony', models.CASCADE)),\n                ('rider', models.ForeignKey('test_rename_field_model_through.Rider', models.CASCADE)),\n            ],\n        ),\n        migrations.AddField(\n            'Pony', 'riders',\n            models.ManyToManyField(\n                'test_rename_field_model_through.Rider',\n                related_name='ponies',\n                through='test_rename_field_model_through.PonyRider',\n            )\n        )\n    ])\n    Pony = project_state.apps.get_model(app_label, 'Pony')\n    PonyRider = project_state.apps.get_model(app_label, 'PonyRider')\n    self.assertEqual(Pony._meta.get_field('riders').remote_field.through, PonyRider)\n    self.assertEqual(Pony._meta.get_field('riders').remote_field.through._meta.db_table, 'test_rename_field_model_through_ponyrider')\n    self.assertTableExists('test_rename_field_model_through_ponyrider')\n\n    # Rename Pony model.\n    project_state = self.apply_operations(app_label, project_state, [\n        migrations.RenameModel('Pony', 'Pony2')\n    ], atomic=connection.features.supports_atomic_references_rename)\n    Pony = project_state.apps.get_model(app_label, 'Pony2')\n    PonyRider = project_state.apps.get_model(app_label, 'PonyRider')\n    self.assertEqual(Pony._meta.get_field('riders').remote_field.through, PonyRider)\n    self.assertEqual(Pony._meta.get_field('riders').remote_field.through._meta.db_table, 'test_rename_field_model_through_ponyrider')\n    self.assertTableExists('test_rename_field_model_through_ponyrider')\n\n    # Rename PonyRider model.\n    project_state = self.apply_operations(app_label, project_state, [\n        migrations.RenameModel('PonyRider', 'PonyRider2')\n    ])\n    Pony = project_state.apps.get_model(app_label, 'Pony2')\n", "    def test_alter_field_to_non_defaultable(self):\n        \"\"\"\n        Tests the AlterField operation on setting null=False to a non-defaultable field.\n        \"\"\"\n        project_state = self.set_up_test_model(\"test_alflnond\")\n        # Test the state alteration\n        operation = migrations.AddField(\"Pony\", \"height\", models.IntegerField(null=True, default=1))\n        project_state = self.apply_operations(\"test_alflnond\", project_state, operations=[operation])\n        operation = migrations.AlterField(\"Pony\", \"height\", models.IntegerField(null=False))\n        new_state = project_state.clone()\n        operation.state_forwards(\"test_alflnond\", new_state)\n        self.assertIs(new_state.models['test_alflnond', 'pony'].fields['height'].null, False)\n        Pony = new_state.apps.get_model(\"test_alflnond\", \"Pony\")\n        Pony.objects.create(weight=42, height=1)\n        Pony.objects.create(weight=43, height=0)\n        Pony.objects.create(weight=44)\n        with self.assertRaises(IntegrityError):\n            Pony.objects.create(weight=42)\n        # Test the database alteration\n        self.assertColumnNull(\"test_alflnond_pony\", \"height\")\n        with connection.schema_editor() as editor:\n            operation.database_forwards(\"test_alflnond\", editor, project_state, new_state)\n        self.assertColumnNotNull(\"test_alflnond_pony\", \"height\")\n        # And test reversal\n        with connection.schema_editor() as editor:\n            operation.database_backwards(\"test_alflnond\", editor, new_state, project_state)\n        self.assertColumnNull(\"test_alflnond_pony\", \"height\")\n        Pony.objects.create(weight=42)\n"], "sample_12": ["def test_deconstruct_nested_list_with_tuple(self):\n    \"\"\"\n    Nested deconstruction should also be applied to tuples within lists.\n    \"\"\"\n    before = [\n        ModelState('app', 'Model', [\n            ('id', models.AutoField(primary_key=True)),\n            ('field', models.CharField(max_length=200, default=[\n                (1, DeconstructibleObject(1)),\n                (2, DeconstructibleObject(2)),\n                (3, DeconstructibleObject(3)),\n            ])),\n        ])\n    ]\n    after = [\n        ModelState('app', 'Model', [\n            ('id', models.AutoField(primary_key=True)),\n            ('field', models.CharField(max_length=200, default=[\n                (1, DeconstructibleObject(1)),\n                (2, DeconstructibleObject(2)),\n                (3, DeconstructibleObject(3)),\n            ])),\n        ])\n    ]\n    changes = self.get_changes(before, after)\n    # Right number of migrations?\n    self.assertEqual(changes, {})\n", "def test_rename_model_with_field_rename_and_order_with_respect_to(self):\n    \"\"\"\n    RenameModel should handle fields with order_with_respect_to.\n    \"\"\"\n    before = [\n        ModelState(\"testapp\", \"Entity\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=255)),\n        ], options={\"order_with_respect_to\": \"name\"}),\n        ModelState(\"otherapp\", \"Related\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"entity\", models.ForeignKey(\"testapp.Entity\", models.CASCADE)),\n        ])\n    ]\n    after = [\n        ModelState(\"testapp\", \"RenamedEntity\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"new_name\", models.CharField(max_length=255)),\n        ], options={\"order_with_respect_to\": \"new_name\"}),\n        ModelState(\"otherapp\", \"Related\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"entity\", models.ForeignKey(\"testapp.RenamedEntity\", models.CASCADE)),\n        ])\n    ]\n    changes = self.get_changes(before, after, MigrationQuestioner({\"ask_rename\": True, \"ask_rename_model\": True}))\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"RenameField\", \"RenameModel\", \"AlterOrderWithRespectTo\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name=\"name\", new_name=\"new_name\")\n    self.assertOperationAttributes(changes, 'testapp', 0, 1, old_name=\"Entity\", new_name=\"RenamedEntity\")\n    self.assertOperationAttributes(changes, 'testapp', 0, 2, name=\"renamedentity\", order_with_respect_to=\"new_name\")\n", "def test_alter_model_options_through_model(self):\n    \"\"\"\n    Changing a model's options, which includes a through model for a\n    ManyToManyField, should only make a change if the through model's options\n    actually changed.\n    \"\"\"\n    changes = self.get_changes(\n        [self.contract, self.author_empty, self.publisher],\n        [self.contract, self.author_empty, self.publisher],\n    )\n    # Right number/type of migrations?\n    self.assertEqual(len(changes), 0)\n\n    changes = self.get_changes(\n        [self.contract, self.author_empty, self.publisher],\n        [\n            ModelState(\"testapp\", \"Contract\", [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"author\", models.ForeignKey(\"testapp.Author\", models.CASCADE)),\n                (\"publisher\", models.ForeignKey(\"testapp.Publisher\", models.CASCADE)),\n            ], options={\"verbose_name\": \"Deal\"}),\n            self.author_empty,\n            self.publisher,\n        ],\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelOptions\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"contract\", options={\"verbose_name\": \"Deal\"})\n", "def test_alter_fk_to_same_model(self):\n    \"\"\"\n    AlterField operation is created when changing ForeignKey's 'to' argument to\n    the same model it was referencing previously.\n    \"\"\"\n    author1 = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"book\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n    ])\n    author2 = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"book\", models.ForeignKey(\"otherapp.Book\", models.CASCADE, to_field='book_id')),\n    ])\n    changes = self.get_changes([author1], [author2])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"book\")\n", "def test_alter_foreign_key_to_mti(self):\n    \"\"\"\n    #23415 - Altering a ForeignKey to an MTI model should correctly\n    resolve the field name.\n    \"\"\"\n    # First, test the default pk field name\n    changes = self.get_changes(\n        [],\n        [self.author_empty, self.book],\n    )\n    # The field name the FK on the book model points to\n    self.assertEqual(\n        changes['otherapp'][0].operations[0].fields[2][1].remote_field.field_name,\n        'id'\n    )\n\n    # Now, test the custom pk field name\n    changes = self.get_changes(\n        [],\n        [self.aardvark_pk_fk_author, self.book],\n    )\n    # The field name the FK on the book model points to\n    self.assertEqual(\n        changes['otherapp'][0].operations[0].fields[2][1].remote_field.field_name,\n        'author_ptr'\n    )\n\n    # Now test the custom pk field name on the MTI model\n    changes = self.get_changes(\n        [self.aardvark_pk_fk_author, self.book],\n        [self.aardvark_based_on_author, self.book],\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, ['AlterField'])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name='author')\n    fk_field = changes['otherapp'][0].operations[0].field\n    to_model = '%s.%s' % (\n        fk_field.remote_field.model._meta.app_label,\n        fk_field.remote_field.model._meta.object_name,\n    )\n    self.assertEqual(to_model, 'testapp.Aardvark')\n    self.assertEqual(changes['otherapp'][0].operations[0].field.remote_field.field_name, 'author_ptr')\n"], "sample_6": ["    def test_ascii_validator(self):\n        valid_usernames = ['joe', 'joe123', 'joe@example']\n        invalid_usernames = [\n            \"Ren\u00e9\", '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f',\n            \"o'connell\", \"\u0639\u0628\u062f \u0627\u0644\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A',\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n", "    def test_ascii_validator(self):\n        valid_usernames = ['joe', 'Ren\u00e9'.encode('ascii', 'ignore').decode(), 'BIGBIRD', 'AHMED']\n        invalid_usernames = [\n            \"o'connell\", \"\u0639\u0628\u062f \u0627\u0644\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A', 'Ren\u00e9',\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n", "    def test_ascii_validator(self):\n        valid_usernames = ['joe', 'hello123', 'user@domain']\n        invalid_usernames = [\n            'Ren\u00e9', '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f',\n            \"o'connell\", \"\u0639\u0628\u062f \u0627\u0644\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A',\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n", "    def test_ascii_validator(self):\n        valid_usernames = ['joe', 'JohnDoe', 'abc123']\n        invalid_usernames = [\n            'Ren\u00e9', '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f',\n            \"o'connell\", \"\u0639\u0628\u062f \u0627\u0644\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A',\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n", "    def test_ascii_validator(self):\n        valid_usernames = ['joe', 'JohnDoe', 'abc123', 'a.b-c+d']\n        invalid_usernames = [\n            \"o'connell\", \"Ren\u00e9\", \"\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30\", \"\u0623\u062d\u0645\u062f\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A',\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n"], "sample_153": ["def test_pretty_print_unicode_d():\n    assert upretty(d[0]) == '(0|0)'\n    assert upretty(d[5]) == '(a) (i_N|k_N) + (-b) (j_N|k_N)'\n    assert upretty(d[7]) == upretty_d_7\n    assert upretty(d[10]) == '(cos(a)) (i_C|k_N) + (-sin(a)) (j_C|k_N)'\n", "def test_pretty_print_unicode_d():\n    assert upretty(d[0]) == '0'\n    assert upretty(d[1]) == '(i_N|k_N)'\n    assert upretty(d[2]) == '(-1) (i_N|k_N)'\n    assert upretty(d[3]) == '(i_N|k_N) + (j_N|k_N)'\n    assert upretty(d[4]) == '(a) (i_N|k_N)'\n    assert upretty(d[5]) == '(a) (i_N|k_N) + (-b) (j_N|k_N)'\n    assert upretty(d[7]) == upretty_d_7\n    assert upretty(d[8]) == ('(N.j|N.k) + (C.x**2 - \u222b(f(b), b))*' +\n                             '(N.k|N.k)')\n    assert upretty(d[9]) == '(C.k|N.k) + (N.i|N.k)'\n    assert upretty(d[10]) == ('(cos(a)) (i_C|k_N) + (-sin(a)) (j_C|k_N)')\n    assert upretty(d[11]) == upretty_v_11\n", "def test_vector_functions():\n    from sympy.vector import CoordSys3D, express\n    R = CoordSys3D('R')\n    v = R.i + R.j + R.k\n    assert upretty(v) == '(i_R + j_R + k_R)'\n    assert pretty(v) == '(i_R + j_R + k_R)'\n    assert upretty(v.cross(R.i)) == 'j_R - k_R'\n    assert pretty(v.cross(R.i)) == 'j_R - k_R'\n    assert upretty(v.dot(R.j)) == '1'\n    assert pretty(v.dot(R.j)) == '1'\n\n    v2 = v.cross(R.k)\n    assert upretty(v2) == 'j_R - i_R'\n    assert pretty(v2) == 'j_R - i_R'\n    assert upretty(v2proj = v2.proj(R.i)) == '(-1)'\n    assert pretty(v2proj) == '(-1)'\n    v2proj2 = v2.proj(R.j)\n    assert upretty(v2proj2) == '1'\n    assert pretty(v2proj2) == '1'\n\n    assert upretty(v2proj2 - v2proj) == '2'\n    assert pretty(v2proj2 - v2proj) == '2'\n    assert upretty(v2proj2 + v2proj) == '0'\n    assert pretty(v2proj2 + v2proj) == '0'\n    assert upretty(v2proj2 - v2proj2) == '0'\n    assert pretty(v2proj2 - v2proj2) == '0'\n    assert upretty(v2proj2 + v2proj2) == '2'\n    assert pretty(v2proj2 + v2proj2) == '2'\n", "def test_tensor_indices():\n    from sympy.tensor.indexed import IndexedBase, Idx\n    from sympy.abc import mu\n    i = Idx('i')\n    j = Idx('j')\n    ij = IndexedBase('T')(i, j)\n    ijmap = {i: 'm', j: 'n'}\n    upretty_ij = \"\"\"\\", "def test_printing_issues():\n    from sympy import symbols, sqrt, log, sin, cos, oo, Interval, S\n    from sympy.abc import x, y\n\n    # test pretty printing of Intervals\n    i1 = Interval(1, 2, False, True)\n    i2 = Interval(1, 2, True, False)\n    i3 = Interval(1, 2, True, True)\n    i4 = Interval(1, 2, False, False)\n\n    assert pretty(i1) == \"]1,2[\"\n    assert pretty(i2) == \"[1,2[\"\n    assert pretty(i3) == \"[1,2]\"\n    assert pretty(i4) == \"]1,2[\"\n\n    # test pretty printing of oo and -oo\n    assert pretty(oo) == \"oo\"\n    assert pretty(-oo) == \"-oo\"\n\n    # test pretty printing of sqrt\n    assert pretty(sqrt(x)) == \"sqrt(x)\"\n    assert pretty(sqrt(x**3)) == \"x*sqrt(x)\"\n    assert pretty(sqrt(x**2)) == \"x\"\n\n    # test pretty printing of Rational\n    from sympy import Rational\n    assert pretty(Rational(1, 2)) == \"1/2\"\n\n    # test pretty printing of log\n    from sympy import log\n    assert pretty(log(x)) == \"log(x)\"\n    assert pretty(log(x, 10)) == \"log(x,10)\"\n\n    # test pretty printing of Derivative\n    from sympy import diff\n    assert pretty(diff(x**2 + 2*x, x)) == \"d(2*x + x**2)/dx\"\n\n    # test pretty printing of Piecewise\n    from sympy import Piecewise\n    f = Piecewise((1, x > 0), (0, x <= 0))\n    assert pretty(f) == \"{1    for x > 0\\n0    otherwise}\"\n\n    # test pretty printing of S\n    from sympy import sin, cos\n    from sympy.abc import x, y\n    assert pretty(sin(x)) == \"sin(x)\"\n    assert pretty(cos(x)) == \"cos(x)\"\n\n    # test pretty printing of symbols\n    assert pretty(x) == \"x\"\n    assert pretty(y) == \"y\"\n\n    # test pretty printing of symbols with unicode\n    from sympy.abc import alpha, beta\n    assert up"], "sample_140": ["def test_set_acc():\n    N = ReferenceFrame('N')\n    p1 = Point('p1')\n    p1.set_acc(N, 10 * N.x)\n    assert p1.acc(N) == 10 * N.x\n    p1.set_acc(N, 20 * N.y)\n    assert p1.acc(N) == 20 * N.y\n", "def test_point_partial_velocity_multiple():\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    p = Point('p')\n\n    u1, u2, u3, u4 = dynamicsymbols('u1, u2, u3, u4')\n\n    p.set_vel(N, u1 * A.x + u2 * N.y + u3 * A.z + u4 * N.z)\n\n    assert p.partial_velocity(N, u1) == A.x\n    assert p.partial_velocity(N, u1, u2) == (A.x, N.y)\n    assert p.partial_velocity(N, u1, u2, u3) == (A.x, N.y, A.z)\n    assert p.partial_velocity(N, u1, u2, u3, u4) == (A.x, N.y, A.z, N.z)\n    assert p.partial_velocity(N, u4, u3, u2, u1) == (N.z, A.z, N.y, A.x)\n", "def test_point_partial_velocity_independent_gen_speeds():\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    B = ReferenceFrame('B')\n    p = Point('p')\n    u1, u2, u3 = dynamicsymbols('u1, u2, u3')\n    p.set_vel(N, u1 * A.x + u2 * N.y + u3 * B.z)\n    assert p.partial_velocity(N, u1) == A.x\n    assert p.partial_velocity(N, u1, u2) == (A.x, N.y)\n    assert p.partial_velocity(N, u1, u2, u3) == (A.x, N.y, B.z)\n    raises(ValueError, lambda: p.partial_velocity(A, u1))\n", "def test_auto_point_vel_multiple_paths():\n    t = dynamicsymbols._t\n    q1, q2, q3, u1 = dynamicsymbols('q1 q2 q3 u1')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    O = Point('O')\n    O.set_vel(N, u1 * N.x)\n    P1 = Point('P1')\n    P1.set_pos(O, q1 * N.y)\n    P2 = Point('P2')\n    P2.set_pos(O, q2 * B.y)\n    P3 = Point('P3')\n    P3.set_pos(P1, q3 * N.z)\n    P3.set_pos(P2, q3 * B.z)\n    P3.set_vel(N, 0)\n    assert P3.vel(N) == 0\n    assert P3.vel(B) == 0\n", "def test_auto_point_vel_multiple_path():\n    t = dynamicsymbols._t\n    q1, q2, q3 = dynamicsymbols('q1 q2 q3')\n    B = ReferenceFrame('B')\n    N = ReferenceFrame('N')\n    P = Point('P')\n    P1 = Point('P1')\n    P2 = Point('P2')\n    P3 = Point('P3')\n    P.set_vel(B, q1 * B.x)\n    P1.set_pos(P, q2 * B.y)\n    P1.set_vel(B, q1 * B.z)\n    P2.set_pos(P, q3 * B.z)\n    P2.set_vel(B, q2 * B.x)\n    P3.set_pos(P1, q1 * B.z)\n    P3.set_pos(P2, q3 * B.y)\n    assert P3.vel(B) == q1.diff(t) * B.z + q1 * B.z + q2.diff(t) * B.y\n"], "sample_19": ["    def test_cleansed_multivaluedict(self):\n        reporter_filter = SafeExceptionReporterFilter()\n        multivaluedict = MultiValueDict({'sensitive': 'value', 'non-sensitive': 'value'})\n        request = RequestFactory().post('/', {'sensitive': 'value'})\n        request.sensitive_post_parameters = ['sensitive']\n        cleansed_multivaluedict = reporter_filter.get_cleansed_multivaluedict(request, multivaluedict)\n        self.assertEqual(cleansed_multivaluedict['sensitive'], reporter_filter.cleansed_substitute)\n        self.assertEqual(cleansed_multivaluedict['non-sensitive'], 'value')\n", "    def setUp(self):\n        self.rf = RequestFactory()\n        self.exc = Http404({'path': '/some/path'})\n", "    def test_technical_500_response_with_empty_request(self):\n        try:\n            raise ValueError(\"Can't find my keys\")\n        except ValueError:\n            exc_type, exc_value, tb = sys.exc_info()\n        response = technical_500_response(None, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/plain; charset=utf-8')\n", "    def test_technical_500_response(self):\n        \"\"\"\n        Ensure technical_500_response returns a HttpResponse with correct\n        content type.\n        \"\"\"\n        exc_type, exc_value, tb = sys.exc_info()\n        request = RequestFactory().get('/')\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/html')\n", "    def test_non_utf8_path(self):\n        try:\n            # Create a path with non-UTF-8 characters.\n            with tempfile.NamedTemporaryFile(prefix=b'\\xffnon_utf8', delete=False) as tmp:\n                path = tmp.name\n            # Raise an exception with the non-UTF-8 path.\n            raise Exception(path)\n        except Exception:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(None, exc_type, exc_value, tb)\n        html = reporter.get_traceback_html()\n        self.assertIn('filename', html)\n"], "sample_119": ["def test_Sum():\n    assert mcode(Sum(sin(x), (x, 0, 10))) == \"Hold[Sum[Sin[x], {x, 0, 10}]]\"\n    assert mcode(Sum(x**2, (x, 0, 10))) == \"Hold[Sum[x^2, {x, 0, 10}]]\"\n    assert mcode(Sum(x*y, (x, 0, 10), (y, 0, 10))) == \\\n        \"Hold[Sum[x*y, {x, 0, 10}, {y, 0, 10}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**2, (x, 0, 10))) == \"Hold[Sum[x^2, {x, 0, 10}]]\"\n    assert mcode(Sum(exp(x), (x, 0, oo))) == \"Hold[Sum[Exp[x], {x, 0, Infinity}]]\"\n    assert mcode(Sum(sin(x), (x, 0, 10, 2))) == \"Hold[Sum[Sin[x], {x, 0, 10, 2}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**2, (x, 0, 10))) == \"Hold[Sum[x^2, {x, 0, 10}]]\"\n    assert mcode(Sum(x*y, (x, 0, 10), (y, 0, 10))) == \\\n        \"Hold[Sum[x*y, {x, 0, 10}, {y, 0, 10}]]\"\n    assert mcode(Sum(x*y, (x, 0, 10), (y, x, 10))) == \\\n        \"Hold[Sum[x*y, {x, 0, 10}, {y, x, 10}]]\"\n    assert mcode(Sum(x*y, (x, 0, 10), (y, 0, x))) == \\\n        \"Hold[Sum[x*y, {x, 0, 10}, {y, 0, x}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**2, (x, 0, 10))) == \"Hold[Sum[x^2, {x, 0, 10}]]\"\n    assert mcode(Sum(x**2, (x, 0, oo))) == \"Hold[Sum[x^2, {x, 0, Infinity}]]\"\n    assert mcode(Sum(x**2, (x, -oo, oo))) == \"Hold[Sum[x^2, {x, -Infinity, Infinity}]]\"\n    assert mcode(Sum(x**2, (x, 0, 10), (y, 0, 5))) == \"Hold[Sum[x^2, {x, 0, 10}, {y, 0, 5}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**2, (x, 1, 3))) == \"Hold[Sum[x^2, {x, 1, 3}]]\"\n    assert mcode(Sum(exp(-x), (x, 0, oo))) == \"Hold[Sum[Exp[-x], {x, 0, Infinity}]]\"\n    assert mcode(Sum(sin(x), (x, 1, 5, 2))) == \"Hold[Sum[Sin[x], {x, 1, 5, 2}]]\"\n"], "sample_133": ["def test_octave_code_argument_order():\n    x, y, z = symbols('x,y,z')\n    expr = x + y\n    routine = make_routine(\"test\", expr, argument_sequence=[z, x, y])\n    code_gen = OctaveCodeGen()\n    source = get_string(code_gen.dump_m, [routine], header=False, empty=False)\n    expected = (\n        \"function [out1, out2] = test(z, x, y)\\n\"\n        \"  out1 = x + y;\\n\"\n        \"end\\n\"\n    )\n    assert source == expected\n", "def test_fortran_90_codegen():\n    x, y, z = symbols('x,y,z')\n    expr1 = (x + y)*z\n    expr2 = (x - y)*z\n    name_expr = [\n        (\"test1\", expr1),\n        (\"test2\", expr2)\n    ]\n    result = codegen(name_expr, \"F90\", \"file\", header=False, empty=False)\n    expected = [\n        (\"file.f90\",\n        \"module file\\ncontains\\n\"\n        \"real*8 function test1(x, y, z)\\n\"\n        \"implicit none\\n\"\n        \"real*8, intent(in) :: x\\n\"\n        \"real*8, intent(in) :: y\\n\"\n        \"real*8, intent(in) :: z\\n\"\n        \"test1 = z*(x + y)\\n\"\n        \"end function\\n\"\n        \"real*8 function test2(x, y, z)\\n\"\n        \"implicit none\\n\"\n        \"real*8, intent(in) :: x\\n\"\n        \"real*8, intent(in) :: y\\n\"\n        \"real*8, intent(in) :: z\\n\"\n        \"test2 = z*(x - y)\\n\"\n        \"end function\\n\"\n        \"end module\\n\"),\n        (\"file.h\",\n        \"interface\\n\"\n        \"module procedure test1\\n\"\n        \"real*8 function test1(x, y, z)\\n\"\n        \"implicit none\\n\"\n        \"real*8, intent(in) :: x\\n\"\n        \"real*8, intent(in) :: y\\n\"\n        \"real*8, intent(in) :: z\\n\"\n        \"end function\\n\"\n        \"end interface\\n\"\n        \"interface\\n\"\n        \"module procedure test2\\n\"\n        \"real*8 function test2(x, y, z)\\n\"\n        \"implicit none\\n\"\n        \"real*8, intent(in) :: x\\n\"\n        \"real*8, intent(in) :: y\\n\"\n        \"real*8, intent(in) :: z\\n\"\n        \"end function\\n\"\n        \"end interface\\n\")\n    ]\n    assert result == expected\n", "def test_octave_loops():\n    from sympy.tensor import IndexedBase, Idx\n    from sympy import symbols\n\n    n, m = symbols('n,m', integer=True)\n    A, x, y = map(IndexedBase, 'Axy')\n    i = Idx('i', m)\n    j = Idx('j', n)\n\n    (f1, code), = codegen(\n        ('matrix_vector', Eq(y[i], A[i, j]*x[j])), \"octave\", \"file\", header=False, empty=False)\n\n    assert f1 == 'file.m'\n    expected = (\n        'function [%s] = matrix_vector(A, m, n, x)\\n'\n        'global n m\\n'\n        '  y = zeros(m, 1);\\n'\n        '  for i = 1:m\\n'\n        '    for j = 1:n\\n'\n        '      y(i) = %(rhs)s + y(i);\\n'\n        '    end\\n'\n        '  end\\n'\n    )\n\n    assert (code == expected % {'rhs': 'A(i, j)*x(j)'} or\n            code == expected % {'rhs': 'x(j)*A(i, j)'})\n", "def test_output_arg_dereference_c():\n    x, y = symbols(\"x,y\")\n    r = make_routine(\"foo\", [Equality(y, x*x)], argument_sequence=(x, y))\n    c = C89CodeGen()\n    result = c.write([r], \"test\", header=False, empty=False)\n    assert result[0][0] == \"test.c\"\n    expected = (\n        '#include \"test.h\"\\n'\n        '#include <math.h>\\n'\n        'void foo(double x, double *y) {\\n'\n        '   (*y) = x*x;\\n'\n        '}\\n'\n    )\n    assert result[0][1] == expected\n\n    # check the header\n    assert result[1][0] == \"test.h\"\n    assert result[1][1] == (\n        '#ifndef PROJECT__TEST__H\\n'\n        '#define PROJECT__TEST__H\\n'\n        'void foo(double x, double *y);\\n'\n        '#endif\\n'\n    )\n", "def test_fcode_indexed_expr():\n    x, y, z = symbols('x,y,z')\n    i, j, k = symbols('i,j,k', integer=True)\n    a = Symbol('a')\n    expr = (x + y)*z\n    routine = make_routine(\"test\", Eq(a, expr))\n    indexed_expr = IndexedBase('indexed_expr', shape=(3,))\n    indexed_expr = indexed_expr[i, j, k]\n    code_gen = FCodeGen()\n    raises(CodeGenError, lambda: code_gen.dump_f95([routine, indexed_expr]))\n"], "sample_148": ["def test_principal_branch_derivative():\n    from sympy import principal_branch, symbols, diff\n    x = symbols('x')\n    p = symbols('p', positive=True)\n    f = Function('f')\n\n    assert diff(principal_branch(f(x), p), x) == diff(f(x), x)\n    assert diff(principal_branch(f(x)*p, p), x) == diff(f(x)*p, x)\n    assert diff(principal_branch(p*f(x), p), x) == diff(p*f(x), x)\n    assert diff(principal_branch(polar_lift(f(x)), p), x) == diff(polar_lift(f(x)), x)\n    assert diff(principal_branch(x*p, p), x) == diff(x*p, x)\n    assert diff(principal_branch(p*x, p), x) == diff(p*x, x)\n", "def test_periodic_argument_branches():\n    from sympy import (periodic_argument, exp_polar, pi, I, oo)\n\n    assert periodic_argument(exp_polar(I*pi/2), 2*pi) == pi/2\n    assert periodic_argument(exp_polar(3*I*pi/2), 2*pi) == -pi/2\n    assert periodic_argument(exp_polar(I*pi/2), pi) == pi/2\n    assert periodic_argument(exp_polar(3*I*pi/2), pi) == pi/2\n    assert periodic_argument(exp_polar(-I*pi/2), 2*pi) == -pi/2\n    assert periodic_argument(exp_polar(-3*I*pi/2), 2*pi) == pi/2\n    assert periodic_argument(exp_polar(-I*pi/2), pi) == -pi/2\n    assert periodic_argument(exp_polar(-3*I*pi/2), pi) == pi/2\n\n    assert periodic_argument(exp_polar(5*I*pi), 2*pi) == 0\n    assert periodic_argument(exp_polar(7*I*pi), 2*pi) == 0\n    assert periodic_argument(exp_polar(5*I*pi), pi) == 0\n    assert periodic_argument(exp_polar(7*I*pi), pi) == pi\n", "def test_unpolarify_polar_lift():\n    from sympy import (exp_polar, polar_lift, unpolarify,\n                       principal_branch, symbols)\n    x, y = symbols('x y')\n    z = polar_lift(x)\n    assert unpolarify(z) == x\n    assert unpolarify(z, exponents_only=True) == x\n    assert unpolarify(principal_branch(z, 2*pi)) == z\n    assert unpolarify(principal_branch(z, 2*pi), exponents_only=True) == z\n    assert unpolarify(polar_lift(x)**2) == x**2\n    assert unpolarify(polar_lift(x)**2, exponents_only=True) == x**polar_lift(2)\n    assert unpolarify(polar_lift(x)**polar_lift(y)) == x**y\n    assert unpolarify(polar_lift(x)**polar_lift(y), exponents_only=True) == x**polar_lift(y)\n", "def test_periodic_argument_edge_cases():\n    from sympy import periodic_argument, oo, pi, exp_polar, principal_branch\n\n    # Test that the periodic argument of the principal branch is the principal branch\n    x = Symbol('x')\n    p = Symbol('p', positive=True)\n    assert periodic_argument(principal_branch(x, p), p) == principal_branch(x, p)\n\n    # Test the periodic argument of exp_polar with a symbolic period\n    assert periodic_argument(exp_polar(I*pi), p) == periodic_argument(exp_polar(I*pi), 2*pi)\n\n    # Test the periodic argument with a period of oo\n    assert periodic_argument(x, oo) == periodic_argument(x, 2*pi)\n\n    # Test the periodic argument with a period of 0\n    assert periodic_argument(x, 0) is None\n", "def test_polar_lift():\n    from sympy import polar_lift\n    x, y = symbols('x,y')\n    a, b = symbols('a,b', real=True)\n    assert polar_lift(0) == 0\n    assert polar_lift(-0) == 0\n    assert polar_lift(1) == 1\n    assert polar_lift(-1) == exp_polar(pi*I)\n    assert polar_lift(2) == 2\n    assert polar_lift(-2) == 2*exp_polar(pi*I)\n    assert polar_lift(I) == exp_polar(-I*pi/2)\n    assert polar_lift(-I) == exp_polar(I*pi/2)\n    assert polar_lift(x).func is polar_lift\n    assert polar_lift(a).func is polar_lift\n    assert polar_lift(b).func is polar_lift\n    assert polar_lift(a + b*I).func is polar_lift\n    assert polar_lift(2*x).func is polar_lift\n    assert polar_lift(-2*x).func is polar_lift\n    assert polar_lift(-2*x).func is polar_lift\n    assert polar_lift(x + I).func is polar_lift\n    assert polar_lift(I*y).func is polar_lift\n    assert polar_lift(2 + I) == polar_lift(2 + I)\n    assert polar_lift(-2 - I) == polar_lift(-2 - I)\n    assert polar_lift(sqrt(a + b*I)) == polar_lift(sqrt(a + b*I))\n    assert polar_lift(a + b*I).args[0] == a + b*I\n    assert polar_lift(2*a + 2*I*b).args[0] == a + I*b\n    assert polar_lift(a + I*b).args[0] == a + I*b\n    assert polar_lift(-a + I*b).args[0] == -a + I*b\n    assert polar_lift(-a - I*b).args[0] == -a - I*b\n"], "sample_23": ["def test_union_with_deferred_models(self):\n    qs1 = Number.objects.defer('num').filter(num__lte=1)\n    qs2 = Number.objects.defer('num').filter(num__gte=8)\n    qs3 = Number.objects.defer('num').filter(num=5)\n    self.assertNumbersEqual(qs1.union(qs2, qs3), [0, 1, 5, 8, 9], ordered=False)\n", "    def test_union_with_distinct_and_empty_qs(self):\n        qs1 = Number.objects.all()\n        qs2 = Number.objects.none()\n        self.assertEqual(len(list(qs1.union(qs2, all=True))), 10)\n        self.assertEqual(len(list(qs2.union(qs1, all=True))), 10)\n", "def test_union_with_values_list_and_distinct(self):\n    ReservedName.objects.bulk_create([\n        ReservedName(name='rn1', order=7),\n        ReservedName(name='rn2', order=5),\n        ReservedName(name='rn0', order=6),\n        ReservedName(name='rn9', order=-1),\n    ])\n    qs1 = ReservedName.objects.filter(order__gte=6).values_list('order', flat=True).distinct()\n    qs2 = ReservedName.objects.filter(order__lte=5).values_list('order', flat=True).distinct()\n    union_qs = qs1.union(qs2)\n    self.assertEqual(len(union_qs), 4)\n    self.assertCountEqual(union_qs, [-1, 5, 6, 7])\n", "def test_defer(self):\n    qs1 = Number.objects.defer('num').filter(num__lte=1)\n    qs2 = Number.objects.filter(num__gte=2, num__lte=3)\n    qs1_union_qs2 = qs1.union(qs2).order_by('num')\n    self.assertNumbersEqual(qs1_union_qs2, [0, 1, 2, 3])\n\n    qs1_only = qs1.union(qs2).values_list('num', flat=True).order_by('num')\n    self.assertEqual(list(qs1_only), [0, 1, 2, 3])\n\n    qs2_defer = qs2.defer('num')\n    qs1_union_qs2_defer = qs1.union(qs2_defer).order_by('num')\n    self.assertNumbersEqual(qs1_union_qs2_defer, [0, 1, 2, 3])\n\n    qs1_union_qs2_defer_only = qs1.union(qs2_defer).values_list('num', flat=True).order_by('num')\n    self.assertEqual(list(qs1_union_qs2_defer_only), [0, 1, 2, 3])\n", "def test_union_with_extra_and_values(self):\n    Number.objects.create(num=3, other_num=4)\n    qs1 = Number.objects.filter(num=1).extra(\n        select={'count': 0},\n    ).values_list('num', 'count')\n    qs2 = Number.objects.filter(num=2).extra(select={'count': 1})\n    qs3 = Number.objects.filter(num=3).extra(select={'count': 2})\n    self.assertCountEqual(qs1.union(qs2, qs3), [(1, 0), (2, 1), (3, 2)])\n"], "sample_146": ["def test_Quaternion_methods():\n    q = Quaternion(x, y, z, t)\n    assert str(q.conjugate()) == \"x - y*i - z*j - t*k\"\n    assert str(q.norm()) == \"sqrt(x**2 + y**2 + z**2 + t**2)\"\n    assert str(q.norm_squared()) == \"x**2 + y**2 + z**2 + t**2\"\n", "def test_Tensor():\n    from sympy.tensor.array.expressions.array_expressions import ArraySymbol, ArrayElement\n    from sympy.tensor.tensor import TensorHead\n\n    n = Symbol('n', integer=True)\n    X = ArraySymbol('X', n, n)\n    assert str(X) == \"X\"\n\n    a = TensorHead('a', [X, X])\n    assert str(a) == \"a\"\n\n    b = TensorHead('b', [X])\n    assert str(b) == \"b\"\n", "def test_StrPrinter_settings():\n    # Ensure that a StrPrinter instance can be created with valid settings\n    settings = {\n        'order': None,\n        'full_prec': 'auto',\n        'sympy_integers': False,\n        'abbrev': False,\n        'perm_cyclic': True,\n        'min': None,\n        'max': None\n    }\n    StrPrinter(settings)\n\n    # Ensure that invalid settings raise a TypeError\n    raises(TypeError, lambda: StrPrinter({'method': 'garbage'}))\n    raises(TypeError, lambda: StrPrinter({'order': 'invalid'}))\n    raises(TypeError, lambda: StrPrinter({'full_prec': 'invalid'}))\n    raises(TypeError, lambda: StrPrinter({'sympy_integers': 'invalid'}))\n    raises(TypeError, lambda: StrPrinter({'abbrev': 'invalid'}))\n    raises(TypeError, lambda: StrPrinter({'perm_cyclic': 'invalid'}))\n    raises(TypeError, lambda: StrPrinter({'min': 'invalid'}))\n    raises(TypeError, lambda: StrPrinter({'max': 'invalid'}))\n", "def test_Relationals_and_Operators():\n    assert str(Eq(x, y)) == \"Eq(x, y)\"\n    assert str(Ne(x, y)) == \"Ne(x, y)\"\n    assert str(Lt(x, y)) == \"Lt(x, y)\"\n    assert str(Le(x, y)) == \"Le(x, y)\"\n    assert str(Gt(x, y)) == \"Gt(x, y)\"\n    assert str(Ge(x, y)) == \"Ge(x, y)\"\n    assert str(x < y) == \"x < y\"\n    assert str(x > y) == \"x > y\"\n    assert str(x <= y) == \"x <= y\"\n    assert str(x >= y) == \"x >= y\"\n    assert str(x != y) == \"x != y\"\n    assert str(x == y) == \"x == y\"\n    assert str(x | y) == \"x | y\"\n    assert str(x & y) == \"x & y\"\n    assert str(x ^ y) == \"x ^ y\"\n    assert str(~x) == \"~x\"\n    assert str(x + y) == \"x + y\"\n    assert str(x - y) == \"x - y\"\n    assert str(x * y) == \"x*y\"\n    assert str(x / y) == \"x/y\"\n    assert str(x**y) == \"x**y\"\n    assert str(x << y) == \"x << y\"\n    assert str(x >> y) == \"x >> y\"\n    assert str(x**S.Half) == \"sqrt(x)\"\n", "def test_Dummy_in_Mul():\n    from sympy.abc import a, b, c\n    assert sstr(a * b * c) == \"a*b*c\"\n    assert sstr(c * a * b) == \"a*b*c\"\n    assert sstr(a * Dummy(\"foo\") * b) == \"_foo*a*b\"\n"], "sample_17": ["    def test_destroy_test_db(self, mocked_migrate, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n            creation.destroy_test_db(old_database_name, verbosity=0, keepdb=False)\n        finally:\n            test_connection.close()\n", "    def test_autoclobber_false(self, mocked_execute_create_test_db, mocked_migrate, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            mocked_execute_create_test_db.side_effect = Exception('Database already exists')\n            with self.assertRaises(SystemExit) as cm:\n                creation.create_test_db(verbosity=0, autoclobber=False, serialize=False)\n            self.assertEqual(cm.exception.code, 1)\n            mocked_migrate.assert_not_called()\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n", "    def test_serialize_db_to_string(self, mocked_log):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        data = creation.serialize_db_to_string()\n        self.assertIsInstance(data, str)\n        mocked_log.assert_called_once()\n", "    def test_serialization(self, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST_NON_SERIALIZED_APPS'] = []\n        creation = test_connection.creation_class(test_connection)\n        # Create some objects to test serialization\n        obj1 = Object.objects.create(name='Object 1')\n        obj2 = Object.objects.create(name='Object 2')\n        ObjectReference.objects.create(object=obj1)\n        ObjectReference.objects.create(object=obj2)\n\n        # Serialize the database\n        serialized_data = creation.serialize_db_to_string()\n\n        # Check that the serialized data is not empty\n        self.assertGreater(len(serialized_data), 0)\n\n        # Deserialize the data\n        creation.deserialize_db_from_string(serialized_data)\n\n        # Check that the objects are still present after deserialization\n        self.assertEqual(Object.objects.count(), 2)\n        self.assertEqual(ObjectReference.objects.count(), 2)\n", "    def setUp(self):\n        self.test_connection = get_connection_copy()\n        self.creation = self.test_connection.creation_class(self.test_connection)\n"], "sample_99": ["def test_supervised_mixin():\n    # Test SupervisedMixin for float and int labels\n\n    # float labels\n    X = np.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n    y = np.array([1.0, 2.0, 3.0])\n    s = SupervisedFloatMixin()\n    s.fit(X, y)\n    assert_array_equal(s._y, y)\n\n    # int labels\n    X = np.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n    y = np.array([1, 2, 3])\n    s = SupervisedIntegerMixin()\n    s.fit(X, y)\n    assert_array_equal(s._y, y)\n", "compilation error", "def test_radius_neighbors_regressor_with_all_zero_distances():\n    # Test radius-based regression when all distances are zero\n    # in this case, the output should be the mean of all target values\n    X = np.zeros((10, 3))\n    y = np.arange(10)\n    radius = 1.0\n    for algorithm in ALGORITHMS:\n        for weights in ['uniform', 'distance']:\n            rnn = neighbors.RadiusNeighborsRegressor(radius=radius,\n                                                     weights=weights,\n                                                     algorithm=algorithm)\n            rnn.fit(X, y)\n            assert_array_almost_equal(rnn.predict(X), np.mean(y) * np.ones(10))\n", "def test_neighbors_base():\n    # Test the base NeighborsBase class\n\n    class TestNeighborsBase(neighbors.NeighborsBase):\n                     algorithm='auto', leaf_size=30, metric='minkowski',\n                     p=2, metric_params=None, n_jobs=1):\n            super(TestNeighborsBase, self).__init__(\n                n_neighbors=n_neighbors, radius=radius,\n                algorithm=algorithm, leaf_size=leaf_size,\n                metric=metric, p=p, metric_params=metric_params,\n                n_jobs=n_jobs)\n\n    X = rng.rand(10, 5)\n    y = rng.randint(0, 2, 10)\n\n    for n_neighbors in [3, 5]:\n        for algorithm in ALGORITHMS:\n            for weights in ['uniform', 'distance']:\n                for metric in ['minkowski', 'euclidean', 'manhattan']:\n                    for p in [1, 2, 3]:\n                        for leaf_size in [10, 30]:\n                            test_nb = TestNeighborsBase(\n                                n_neighbors=n_neighbors, radius=1.0,\n                                algorithm=algorithm, leaf_size=leaf_size,\n                                metric=metric, p=p, metric_params=None,\n                                n_jobs=1)\n                            test_nb.fit(X)\n\n                            assert_equal(test_nb.effective_metric_, metric)\n                            assert_equal(test_nb.effective_metric_params_, {})\n                            assert_equal(test_nb.n_neighbors, n_neighbors)\n                            assert_equal(test_nb.radius, 1.0)\n                            assert_equal(test_nb.algorithm, algorithm)\n                            assert_equal(test_nb.leaf_size, leaf_size)\n                            assert_equal(test_nb.metric, metric)\n                            assert_equal(test_nb.p, p)\n                            assert_equal(test_nb.n_jobs, 1)\n", "def test_supervised_integer_mixin():\n    # Test SupervisedIntegerMixin\n    rng = np.random.RandomState(0)\n    n_samples = 10\n    X = rng.rand(n_samples, 2)\n    y = rng.randint(0, 2, n_samples)\n\n    with assert_raises_regex(ValueError, \"Target is < 0 and is not -1\"):\n        neighbors.KNeighborsClassifier().fit(X, y - 2)\n\n    with assert_warns(DataConversionWarning,\n                      \"A column-vector y was passed when a 1d array \"\n                      \"was expected\"):\n        neighbors.KNeighborsClassifier().fit(X, y[:, np.newaxis])\n\n    neighbors.KNeighborsClassifier().fit(X, y)\n\n    y_multi = np.c_[y, y]\n    neighbors.KNeighborsClassifier().fit(X, y_multi)\n\n    # Test that n_neighbors is validated\n    nn = neighbors.KNeighborsClassifier(n_neighbors=-1)\n    with assert_raises_regex(ValueError, \"Expected n_neighbors > 0. Got -1\"):\n        nn.fit(X, y)\n\n    nn = neighbors.KNeighborsClassifier(n_neighbors=1.5)\n    with assert_raises_regex(TypeError, \"n_neighbors does not take float\"):\n        nn.fit(X, y)\n"], "sample_34": ["    def test_model_name_db_lookup_clashes(self):\n        class Model(models.Model):\n            class Meta:\n                app_label = 'check_framework'\n\n        with self.assertRaisesMessage(ValueError, \"The model name 'Model_' cannot start or end with an underscore as it collides with the query lookup syntax.\"):\n            type('Model_', (models.Model,), {'__name__': 'Model_', 'Meta': Model.Meta})\n\n        with self.assertRaisesMessage(ValueError, \"The model name 'Model__test' cannot contain double underscores as it collides with the query lookup syntax.\"):\n            type('Model__test', (models.Model,), {'__name__': 'Model__test', 'Meta': Model.Meta})\n", "    def test_model_name_starts_with_double_underscore(self):\n        class Model(models.Model):\n            class Meta:\n                app_label = 'check_framework'\n                verbose_name = \"Test Model\"\n\n        with self.assertRaisesMessage(RuntimeError, \"Model class check_framework.__Model doesn't declare an explicit app_label and isn't in an application in INSTALLED_APPS.\"):\n            apps.get_model('check_framework', '__Model')\n\n        class Model(models.Model):\n            class Meta:\n                app_label = 'check_framework'\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"The model name '__Model' cannot start with an underscore as it \"\n                \"collides with the query lookup syntax.\",\n                obj=Model,\n                id='models.E023',\n            ),\n        ])\n", "    def test_proxy_model_multiple_inheritance(self):\n        class Parent1(models.Model):\n            pass\n\n        class Parent2(models.Model):\n            pass\n\n        class Child(Parent1, Parent2):\n            class Meta:\n                proxy = True\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"Proxy model 'check_framework.Child' has more than one non-abstract model base class.\",\n                obj=Child,\n                id='models.E017',\n            ),\n        ])\n", "    def test_meta_model_name_too_long(self):\n        class Model(models.Model):\n            class Meta:\n                verbose_name = 'x' * 256\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"The model name '%s' (model '%s') must of less than or equal to 255 characters.\" % ('x' * 256, 'Model'),\n                obj='Model',\n                id='models.E027',\n            ),\n        ])\n", "    def test_deferred_field(self):\n        class Model(models.Model):\n            field1 = models.CharField(max_length=10)\n            field2 = models.CharField(max_length=10)\n\n        obj = Model(field1='value1', field2=DEFERRED)\n        self.assertEqual(obj.__repr__(), '<Model: Model object (None)>')\n        self.assertEqual(obj.__str__(), 'Model object (None)')\n\n        with self.assertRaises(ValidationError) as e:\n            obj.full_clean()\n        self.assertEqual(e.exception.error_dict, {\n            'field2': ['This field cannot be blank.'],\n        })\n"], "sample_123": ["def test_as_numer_denom():\n    assert Integer(5).as_numer_denom() == (Integer(5), Integer(1))\n    assert Rational(5, 3).as_numer_denom() == (Integer(5), Integer(3))\n    assert Float(5.0).as_numer_denom() == (Integer(5), Integer(1))\n", "def test_issue_12820():\n    x = Float(2, 10)\n    y = Float(2, prec=10)\n    assert x == y\n    assert x._prec == y._prec\n", "def test_float_comparison():\n    # Test that Float instances with equal values but different precision compare\n    # equal.\n    assert Float(1, 1) == Float(1, 2)\n    assert Float(1, 1) == Float(1, 3)\n    assert Float(1, 1) == Float(1, 10)\n    assert Float(1, 10) == Float(1, 1)\n    assert Float(1, 10) == Float(1, 2)\n    assert Float(1, 10) == Float(1, 3)\n", "def test_issue_6664():\n    # Test Integer(NaN) and Integer(oo)\n    assert Integer(S.NaN) == S.NaN\n    assert Integer(S.Infinity) == S.Infinity\n    assert Integer(S.NegativeInfinity) == S.NegativeInfinity\n\n    # Test Rational(NaN) and Rational(oo)\n    raises(TypeError, lambda: Rational(S.NaN))\n    raises(TypeError, lambda: Rational(S.Infinity))\n    raises(TypeError, lambda: Rational(S.NegativeInfinity))\n\n    # Test Float(NaN) and Float(oo)\n    assert Float(S.NaN) == S.NaN\n    assert Float(S.Infinity) == S.Infinity\n    assert Float(S.NegativeInfinity) == S.NegativeInfinity\n\n    # Test Number(NaN) and Number(oo)\n    assert Number(S.NaN) == S.NaN\n    assert Number(S.Infinity) == S.Infinity\n    assert Number(S.NegativeInfinity) == S.NegativeInfinity\n\n    # Test Integer(Rational(NaN)) and Integer(Rational(oo))\n    raises(TypeError, lambda: Integer(Rational(S.NaN)))\n    raises(TypeError, lambda: Integer(Rational(S.Infinity)))\n    raises(TypeError, lambda: Integer(Rational(S.NegativeInfinity)))\n\n    # Test Integer(Float(NaN)) and Integer(Float(oo))\n    raises(TypeError, lambda: Integer(Float(S.NaN)))\n    raises(TypeError, lambda: Integer(Float(S.Infinity)))\n    raises(TypeError, lambda: Integer(Float(S.NegativeInfinity)))\n\n    # Test Integer(Number(NaN)) and Integer(Number(oo))\n    raises(TypeError, lambda: Integer(Number(S.NaN)))\n    raises(TypeError, lambda: Integer(Number(S.Infinity)))\n    raises(TypeError, lambda: Integer(Number(S.NegativeInfinity)))\n\n    # Test Rational(Rational(NaN)) and Rational(Rational(oo))\n    raises(TypeError, lambda: Rational(Rational(S.NaN)))\n    raises(TypeError, lambda: Rational(Rational(S.Infinity)))\n    raises(TypeError, lambda: Rational(Rational(S.NegativeInfinity)))\n\n    # Test Rational(Float(NaN)) and Rational(Float(oo))\n    raises(TypeError, lambda: Rational(Float(S.NaN)))\n    raises(TypeError, lambda: Rational(Float(S.Infinity)))\n    raises(TypeError, lambda: Rational(Float(S.NegativeInfinity)))\n\n    # Test Rational(Number(NaN)) and Rational(Number(oo))\n    raises(TypeError, lambda: Rational(Number(S.NaN)))\n    raises(TypeError, lambda: Rational(Number(S.Infinity)))\n    raises(TypeError, lambda: Rational(Number(S.NegativeInfinity)))\n", "def test_issue_19151():\n    from mpmath import mpf\n    mpf_1 = mpf('1.0')\n    mpf_2 = mpf('2.0')\n    assert (mpf_1 + mpf_2)._mpf_ == (0, long(400000000000000000000), -55, 56)\n    assert Float(mpf_1 + mpf_2)._mpf_ == (0, long(400000000000000000000), -55, 56)\n    assert Float(mpf_1)._mpf_ + Float(mpf_2)._mpf_ == (0, long(400000000000000000000), -55, 56)\n    assert (Float(mpf_1) + Float(mpf_2))._mpf_ == (0, long(400000000000000000000), -55, 56)\n    assert (Float(mpf_1) + Float(mpf_2))._mpf_ == (Float(mpf_1) + Float(mpf_2))._mpf_\n"], "sample_149": ["def test_monomial_divides_boundary_conditions():\n    assert monomial_divides((0, 0, 0), (0, 0, 0)) is True\n    assert monomial_divides((0, 0, 0), (1, 0, 0)) is True\n    assert monomial_divides((1, 0, 0), (0, 0, 0)) is False\n    assert monomial_divides((1, 1, 1), (1, 1, 1)) is True\n    assert monomial_divides((1, 1, 1), (0, 0, 0)) is False\n    assert monomial_divides((0, 0, 0), (1, 1, 1)) is True\n    assert monomial_divides((10, 10, 10), (5, 5, 5)) is True\n    assert monomial_divides((10, 10, 10), (15, 15, 15)) is False\n", "def test_monomial_divides():\n    assert monomial_divides((1, 2), (2, 3)) is True\n    assert monomial_divides((1, 2), (0, 2)) is False\n    assert monomial_divides((1, 2), (1, 2)) is True\n", "def test_monomial_class():\n    assert Monomial((1, 2, 3)) == Monomial((1, 2, 3))\n    assert Monomial((1, 2, 3)) != Monomial((1, 2, 4))\n    assert Monomial((1, 2, 3)).as_expr(x, y, z) == x*y**2*z**3\n    assert Monomial((1, 2, 3)).as_expr(z, y, x) == z*y**2*x**3\n\n    m = Monomial((1, 2, 3))\n    assert m * Monomial((2, 3, 4)) == Monomial((3, 5, 7))\n    assert m / Monomial((0, 1, 1)) == Monomial((1, 1, 2))\n    assert m ** 2 == Monomial((2, 4, 6))\n    assert m.gcd(Monomial((2, 2, 3))) == Monomial((1, 2, 3))\n    assert m.lcm(Monomial((2, 2, 3))) == Monomial((2, 2, 3))\n\n    assert Monomial((1, 2, 3)) == (1, 2, 3)\n    assert Monomial((1, 2, 3)) != (1, 2, 4)\n\n    assert Monomial((1, 2, 3)).__len__() == 3\n    assert list(Monomial((1, 2, 3))) == [1, 2, 3]\n    assert Monomial((1, 2, 3))[0] == 1\n    assert Monomial((1, 2, 3)).__hash__() == hash((Monomial.__name__, (1, 2, 3), None))\n\n    raises(ExactQuotientFailed, lambda: Monomial((1, 2, 3)) / Monomial((2, 2, 2)))\n    raises(NotImplementedError, lambda: Monomial((1, 2, 3)) * 'a')\n    raises(NotImplementedError, lambda: Monomial((1, 2, 3)) / 'a')\n    raises(NotImplementedError, lambda: Monomial((1, 2, 3)) **", "def test_monomial_ops():\n    ops = MonomialOps(3)\n    assert ops.mul()((1, 2, 3), (4, 5, 6)) == ((5, 7, 9),)\n    assert ops.pow()(1, 2) == ((2, 4, 6),)\n    assert ops.mulpow()((1, 2, 3), (4, 5, 6), 2) == ((13, 17, 21),)\n    assert ops.ldiv()((3, 4, 5), (1, 2, 3)) == ((2, 2, 2),)\n    assert ops.div()(ops.ldiv()((3, 4, 5), (1, 2, 3))) == ((2, 2, 2),)\n    assert ops.lcm()((1, 2, 3), (4, 5, 6)) == ((4, 5, 6),)\n    assert ops.gcd()((6, 8, 10), (3, 4, 5)) == ((3, 4, 5),)\n", "def test_Monomial():\n    # Test Monomial class initialization\n    m1 = Monomial((1, 2, 3))\n    assert m1.exponents == (1, 2, 3)\n    assert m1.gens is None\n\n    m2 = Monomial((1, 2, 3), [x, y, z])\n    assert m2.exponents == (1, 2, 3)\n    assert m2.gens == [x, y, z]\n\n    # Test Monomial methods\n    assert m1.rebuild((4, 5, 6)).exponents == (4, 5, 6)\n\n    assert len(m1) == 3\n    assert list(m1) == [1, 2, 3]\n    assert m1[0] == 1\n\n    assert hash(m1) == hash((Monomial.__name__, m1.exponents, m1.gens))\n\n    assert str(m1) == \"Monomial((1, 2, 3))\"\n\n    assert m2.as_expr() == x*y**2*z**3\n\n    # Test Monomial comparison operators\n    m3 = Monomial((1, 2, 3))\n    assert m1 == m3\n    assert m1 != Monomial((4, 5, 6))\n\n    # Test Monomial arithmetic operators\n    m4 = Monomial((4, 5, 6))\n    assert m1 * m4 == Monomial((5, 7, 9))\n    with raises(NotImplementedError):\n        m1 * (1, 2, 3)\n\n    assert m1 / m4 == Monomial((0, 0, 0))\n    assert m1 / m3 is None\n\n    with raises(ExactQuotientFailed):\n        m1 / Monomial((0, 0, 0))\n\n    assert m1 ** 2 == Monomial((2, 4, 6))\n    with raises(ValueError):\n        m1 ** -1\n\n    # Test Monomial gcd and lcm methods\n    assert m1.gcd(m4) == Monomial((1, 2, 3))\n    assert m1.lcm(m4) == Monomial((4, 5, 6))\n\n    # Test MonomialOps class\n    ops = MonomialOps(3)\n    assert ops.mul()((1,"], "sample_46": ["    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(), \n            col_suffixes=('ASC', 'DESC'), opclasses=('varchar_pattern_ops', 'text_pattern_ops')\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(),\n            col_suffixes=['ASC', 'DESC'], opclasses=['text_pattern_ops', 'varchar_pattern_ops']\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(), ['asc', 'desc'], ['opclass1', 'opclass2']\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(),\n            ['ASC', 'DESC'], ['btree', 'gin']\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(),\n            ('DESC',), ('', 'NULLS LAST')\n        )\n"], "sample_93": ["def test_getbasetemp_custom_with_numbered_dir(pytester: Pytester) -> None:\n    mytemp = pytester.path.joinpath(\"xyz\")\n    p = pytester.makepyfile(\n        \"\"\"\n            tmp_path_factory.mktemp('hello-', numbered=False)\n    \"\"\"\n    )\n    pytester.runpytest(p, \"--basetemp=%s\" % mytemp)\n    assert mytemp.exists()\n    assert mytemp.joinpath(\"hello-0\").exists()\n\n    pytester.runpytest(p, \"--basetemp=%s\" % mytemp)\n    assert mytemp.exists()\n    assert not mytemp.joinpath(\"hello-0\").exists()\n    assert mytemp.joinpath(\"hello-1\").exists()\n", "def test_getbasetemp_with_custom_basetemp(tmp_path, monkeypatch):\n    \"\"\"Test that getbasetemp uses the custom basetemp if provided.\"\"\"\n    custom_basetemp = tmp_path / \"custom_basetemp\"\n    config = cast(Config, FakeConfig(custom_basetemp))\n    t = TempPathFactory.from_config(config, _ispytest=True)\n    assert t.getbasetemp().resolve() == custom_basetemp.resolve()\n\n    # Test that the custom basetemp is reset if it already exists\n    custom_basetemp.mkdir()\n    assert t.getbasetemp().resolve() == custom_basetemp.resolve()\n", "def test_tmp_path_factory_invalid_input(monkeypatch, tmp_path):\n    config = cast(Config, FakeConfig(tmp_path))\n    with monkeypatch.context() as m:\n        m.setattr(Path, \"is_absolute\", lambda self: False)\n        with pytest.raises(ValueError):\n            TempPathFactory.from_config(config, _ispytest=True)\n", "def test_tmppath_factory_from_config(monkeypatch: MonkeyPatch) -> None:\n    \"\"\"Test that TempPathFactory.from_config uses the correct configuration.\"\"\"\n    config = cast(Config, FakeConfig(basetemp=\"my_basetemp\"))\n    monkeypatch.setattr(config, \"option\", FakeConfig(basetemp=\"my_basetemp\"))\n    tmppath_factory = TempPathFactory.from_config(config, _ispytest=True)\n    assert tmppath_factory._given_basetemp == Path(\"my_basetemp\")\n", "def test_tmppath_factory_from_config_with_basetemp(pytester: Pytester) -> None:\n    config = pytester.config\n    tmppath_factory = TempPathFactory.from_config(config, _ispytest=True)\n    assert tmppath_factory.getbasetemp().exists()\n\n    # Test that a custom basetemp is used\n    config.option.basetemp = pytester.mkdir(\"custom_basetemp\")\n    tmppath_factory = TempPathFactory.from_config(config, _ispytest=True)\n    assert tmppath_factory.getbasetemp() == config.option.basetemp\n\n    # Test that a non-existent basetemp is created\n    config.option.basetemp = pytester.path.joinpath(\"non_existent_basetemp\")\n    tmppath_factory = TempPathFactory.from_config(config, _ispytest=True)\n    assert tmppath_factory.getbasetemp().exists()\n"], "sample_16": ["    def test_reverse_field_path(self):\n        self.assertEqual(\n            reverse_field_path(Event, 'location__event'),\n            (Event, 'location__event')\n        )\n        self.assertEqual(\n            reverse_field_path(Location, 'event__location'),\n            (Event, 'location__event')\n        )\n        self.assertEqual(\n            reverse_field_path(Event, 'location__event__guest'),\n            (Guest, 'event__location__event')\n        )\n        self.assertEqual(\n            reverse_field_path(EventGuide, 'event__location__event'),\n            (Event, 'location__event')\n        )\n", "    def setUp(self):\n        self.site = Site.objects.create()\n        self.article = Article.objects.create(site=self.site)\n        self.event = Event.objects.create()\n", "    def test_quote(self):\n        for value in ['/', '_', ':', '\"', '#', '?', ';', '@', '&', '=', '+', '$', ',', '[', ']', '<', '>', '%', '\\n', '\\\\']:\n            quoted = quote(value)\n            self.assertIn(f'_{value.encode(\"utf-8\").hex()}', quoted)\n            self.assertEqual(unquote(quoted), value)\n", "def test_get_fields_from_path(self):\n    \"\"\"\n    Test get_fields_from_path function\n    \"\"\"\n    article = Article.objects.create()\n    site = Site.objects.create(domain='example.com')\n    event = Event.objects.create()\n    event_guide = EventGuide.objects.create(event=event)\n\n    # Test normal lookup\n    path = 'site__domain'\n    expected_fields = [Article._meta.get_field('site'), Site._meta.get_field('domain')]\n    self.assertEqual(get_fields_from_path(Article, path), expected_fields)\n\n    # Test many-to-many lookup\n    path = 'sites__domain'\n    expected_fields = [Article._meta.get_field('sites'), Site._meta.get_field('domain')]\n    self.assertEqual(get_fields_from_path(Article, path), expected_fields)\n\n    # Test many-to-one lookup\n    path = 'event__location__name'\n    expected_fields = [EventGuide._meta.get_field('event'), Event._meta.get_field('location'), Location._meta.get_field('name')]\n    self.assertEqual(get_fields_from_path(EventGuide, path), expected_fields)\n\n    # Test lookup with reverse relation\n    path = 'article_set__site__domain'\n    expected_fields = [Site._meta.get_field('article_set'), Article._meta.get_field('site'), Site._meta.get_field('domain')]\n    self.assertEqual(get_fields_from_path(Site, path), expected_fields)\n", "    def test_fieldDoesNotExist(self):\n        \"\"\"\n        If the field does not exist in the lookup path,\n        it should raise a FieldDoesNotExist and ignore it.\n        \"\"\"\n        lookup_fields = ['test', 'pk']\n        opts = Article._meta\n        self.assertFalse(lookup_needs_distinct(opts, LOOKUP_SEP.join(lookup_fields)))\n"], "sample_82": ["def test_da_groupby_reduce_with_kwargs():\n    array = xr.DataArray(\n        data=[1, 2, 3, 4, 5, 6], coords={\"x\": [1, 1, 1, 2, 2, 2]}, dims=\"x\"\n    )\n    actual = array.groupby(\"x\").reduce(np.mean, dim=..., skipna=True)\n    expected = xr.DataArray(\n        data=[2, 5], coords={\"x\": [1, 2]}, dims=\"x\"\n    )\n    assert_identical(actual, expected)\n", "def test_groupby_map_changing_group_dimension():\n    array = xr.DataArray(\n        data=[1, 2, 3, 4, 5, 6],\n        coords={\"x\": [1, 1, 1, 2, 2, 2]},\n        dims=\"x\",\n    )\n\n        return group.isel(x=0).expand_dims(\"y\")\n\n    expected = xr.DataArray(\n        data=[[1, 2, 3], [4, 5, 6]], coords={\"x\": [1, 2], \"y\": [0, 1, 2]}, dims=(\"x\", \"y\")\n    )\n\n    actual = array.groupby(\"x\").map(func)\n    assert_identical(expected, actual)\n", "def test_groupby_where():\n    array = xr.DataArray([1, 2, 3], [(\"x\", [1, 2, 3])])\n    expected = xr.DataArray([1, 4, 3], [(\"x\", [1, 2, 3])])\n    actual = array.groupby(\"x\").where(xr.DataArray([True, False, True], [(\"x\", [1, 2, 3])]), 4)\n    assert_identical(expected, actual)\n\n    dataset = xr.Dataset({\"foo\": (\"x\", [1, 2, 3])}, {\"x\": [1, 2, 3]})\n    expected = xr.Dataset({\"foo\": (\"x\", [1, 4, 3])}, {\"x\": [1, 2, 3]})\n    actual = dataset.groupby(\"x\").where(xr.DataArray([True, False, True], [(\"x\", [1, 2, 3])]), 4)\n    assert_identical(expected, actual)\n\n    array = xr.DataArray([1, 2, 3], [(\"x\", [1, 1, 1])])\n    expected = xr.DataArray([1, 1, 1], [(\"x\", [1, 1, 1])])\n    actual = array.groupby(\"x\").where(xr.DataArray([True, False, True], [(\"x\", [1, 1, 1])]), 4)\n    assert_identical(expected, actual)\n", "def test_groupby_empty_bins():\n    # test for empty bins (GH2665)\n    da = xr.DataArray([1, 2, 3, 4, 5], dims=\"x\")\n    da[\"x\"] = [1, 2, 3, 4, 5]\n    with raises_regex(ValueError, \"None of the data falls within bins with edges\"):\n        da.groupby_bins(\"x\", bins=[2.5, 3.5, 4.5])\n", "def test_groupby_bins_datetime():\n    # GH1132: test groupby_bins with a DataArray of dtype datetime64\n    # create test data\n    times = pd.date_range(\"2000-01-01\", periods=4)\n    foo = xr.DataArray([1, 2, 3, 4], coords=dict(time=times), dims=\"time\")\n    # create test bins\n    bins = pd.date_range(\"1999-12-31\", \"2000-01-05\", freq=\"D\")\n    # create expected result\n    expected = xr.DataArray(\n        [3, 7], coords=dict(time_bins=pd.cut(bins, bins).categories), dims=\"time_bins\"\n    )\n    # create actual result\n    g = foo.groupby_bins(\"time\", bins)\n    actual = g.sum()\n    # assert identical\n    assert_identical(expected, actual)\n"], "sample_20": ["    def test_proxy_model_with_fields(self):\n        class Model(models.Model):\n            field = models.CharField(max_length=100)\n\n        class ProxyModel(Model):\n            class Meta:\n                proxy = True\n                fields = ['field']\n\n        self.assertEqual(ProxyModel.check(), [\n            Error(\n                \"Proxy model 'ProxyModel' contains model fields.\",\n                obj=ProxyModel,\n                id='models.E017',\n            ),\n        ])\n", "    def test_abstract_base_model_without_fields(self):\n        class Abstract(models.Model):\n            class Meta:\n                abstract = True\n\n        class Child(Abstract):\n            pass\n\n        self.assertEqual(Child.check(), [])\n", "    def test_model_base_validates_app_label(self):\n        class Model(metaclass=ModelBase):\n            _meta = Options()\n            _meta.app_label = 'app_label'\n\n        with self.assertRaisesMessage(RuntimeError, \"Model class Model doesn't declare an explicit app_label and isn't in an application in INSTALLED_APPS.\"):\n            ModelBase.__new__(ModelBase, 'Model', (), {})\n", "    def test_model_with_deferred_fields(self):\n        class ModelWithDeferred(models.Model):\n            deferred_field = models.CharField(max_length=100, null=True)\n            normal_field = models.CharField(max_length=100)\n\n        obj = ModelWithDeferred(deferred_field='deferred', normal_field='normal')\n\n        # Save the object and retrieve it from the database.\n        obj.save()\n        obj = ModelWithDeferred.objects.get(pk=obj.pk)\n\n        # Check that deferred fields are deferred.\n        self.assertNotIn('deferred_field', obj.__dict__)\n\n        # Check that non-deferred fields are loaded.\n        self.assertIn('normal_field', obj.__dict__)\n\n        # Test that refresh_from_db() loads the deferred field.\n        obj.refresh_from_db(fields=['deferred_field'])\n        self.assertIn('deferred_field', obj.__dict__)\n", "    def test_check_model_inheritance(self):\n        # Check inheritance from a model defined in another app.\n        class Book(models.Model):\n            pass\n\n        class Magazine(Book):\n            pass\n\n        self.assertEqual(Magazine.check(databases=self.databases), [])\n"], "sample_136": ["def test_BlockMatrix_as_real_imag():\n    A, B, C, D = [MatrixSymbol(s, 3, 3) for s in 'ABCD']\n    X = BlockMatrix([[A, B], [C, D]])\n    real, imag = X.as_real_imag()\n    assert real.is_BlockMatrix\n    assert imag.is_BlockMatrix\n    assert real.shape == X.shape\n    assert imag.shape == X.shape\n    assert block_collapse(real) == block_collapse(X).as_real_imag()[0]\n    assert block_collapse(imag) == block_collapse(X).as_real_imag()[1]\n", "def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', n, k)\n    C = MatrixSymbol('C', l, m)\n    D = MatrixSymbol('D', l, k)\n    X = BlockMatrix([[A, B], [C, D]])\n\n    real_matrices, im_matrices = X.as_real_imag()\n    assert real_matrices.is_BlockMatrix\n    assert im_matrices.is_BlockMatrix\n    assert real_matrices.blockshape == im_matrices.blockshape\n    assert real_matrices.blockshape == X.blockshape\n    assert real_matrices.rowblocksizes == im_matrices.rowblocksizes\n    assert real_matrices.rowblocksizes == X.rowblocksizes\n    assert real_matrices.colblocksizes == im_matrices.colblocksizes\n    assert real_matrices.colblocksizes == X.colblocksizes\n\n    for i in range(X.blockshape[0]):\n        for j in range(X.blockshape[1]):\n            assert real_matrices.blocks[i, j] == X.blocks[i, j].as_real_imag()[0]\n            assert im_matrices.blocks[i, j] == X.blocks[i, j].as_real_imag()[1]\n", "def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', n, m)\n    X = BlockMatrix([[A, B]])\n    Y = BlockMatrix([[A, B]])\n    assert block_collapse(X + Y).as_real_imag() == \\\n        block_collapse(X).as_real_imag()[0] + block_collapse(Y).as_real_imag()[0], \\\n        block_collapse(X).as_real_imag()[1] + block_collapse(Y).as_real_imag()[1]\n\n    assert X.as_real_imag() == (BlockMatrix([[re(A), re(B)]]), \n                                BlockMatrix([[im(A), im(B)]]))\n", "def test_block_collapse_inverse():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n    \n    assert isinstance(block_collapse(X.I), BlockMatrix)\n    assert block_collapse(X.I).blockshape == (2, 2)\n\n    # test the structure of the inverse\n    assert block_collapse(X.I).blocks[0, 0].shape == (n, n)\n    assert block_collapse(X.I).blocks[0, 1].shape == (n, m)\n    assert block_collapse(X.I).blocks[1, 0].shape == (m, n)\n    assert block_collapse(X.I).blocks[1, 1].shape == (m, m)\n\n    # test that the inverse is actually correct\n    assert block_collapse(X * X.I) == Identity(n + m)\n    assert block_collapse(X.I * X) == Identity(n + m)\n", "def test_BlockMatrix_inverse():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n\n    from sympy import assuming, Q\n    with assuming(Q.invertible(A)):\n        inv_X = BlockMatrix([\n            [(A - B*D.I*C).I, -A.I*B*(D - C*A.I*B).I],\n            [-(D - C*A.I*B).I*C*A.I,     (D - C*A.I*B).I]])\n        assert block_collapse(X.I) == inv_X\n        assert block_collapse(X.I*X) == Identity(n + m)\n\n    assert isinstance(X.I, Inverse)\n\n    # Test that inverse works with Identity\n    I = BlockDiagMatrix(Identity(n), Identity(m))\n    assert block_collapse(I.I) == I\n\n    # Test that inverse works with square MatrixSymbol\n    M = MatrixSymbol('M', n, n)\n    assert block_collapse(BlockMatrix([[M]]).I) == BlockMatrix([[M.I]])\n"], "sample_91": ["def test_invalid_xfail_keyword_parameter(testdir):\n    \"\"\"\n    Verify that using pytest.xfail() with unknown parameter raises an error\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n            pytest.xfail(\"skip_module_level\", unknown=1)\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*TypeError:*['unknown']*\"])\n", "def test_xfail_imperative_with_runxfail(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n            pytest.xfail(\"hello\")\n    \"\"\"\n    )\n    result = testdir.runpytest(p, \"--runxfail\")\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n    assert result.ret == 0\n", "def test_evaluate_condition_failure_with_multiple_lines(testdir):\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.skipif('''\n            a = 1\n            b = 2\n            a > b\n        ''')\n            pass\n    \"\"\"\n    )\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_condition(item, item.iter_markers(name=\"skipif\").__next__(), item.iter_markers(name=\"skipif\").__next__().args[0])\n    assert excinfo.value.msg is not None\n    assert \"Error evaluating 'skipif' condition\" in excinfo.value.msg\n", "    def test_dynamic_xfail_in_class(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            class TestClass(object):\n                    pytest.mark.xfail(self.test_method)\n\n                    assert 0\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        result.stdout.fnmatch_lines([\"*XFAIL*test_method*\"])\n", "def test_xfail_string_condition_unexpected_success(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(\"sys.version_info < (3, 0)\")\n            assert 1\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rX\")\n    result.stdout.fnmatch_lines(\n        [\"*XPASS*test_func*\", \"*Unexpected success: condition: sys.version_info < (3, 0)*\"]\n    )\n"], "sample_118": ["def test_ccode_For():\n    x, y = symbols('x y')\n    n = symbols('n', integer=True)\n    expr = For(x, Range(n, n+10), (y, x**2))\n    expected = (\n        'for (int x=n; x<n + 10; x++){'\n        '\\n   y = pow(x, 2);\\n'\n        '}'\n    )\n    assert ccode(expr) == expected\n", "def test_ccode_For():\n    from sympy import symbols\n    n = symbols('n', integer=True)\n    x = symbols('x')\n    e = For(x, Range(0, n), (x + 1))\n    assert ccode(e) == (\n        \"for (int x=0; x<n; x++){\\n\"\n        \"   x = x + 1;\\n\"\n        \"}\"\n    )\n", "def test_ccode_IndexedBase_with_shape():\n    from sympy.tensor import IndexedBase, Idx\n    from sympy import symbols\n    len_y = 5\n    y = IndexedBase('y', shape=(len_y,))\n    t = IndexedBase('t', shape=(len_y,))\n    Dy = IndexedBase('Dy', shape=(len_y-1,))\n    i = Idx('i', len_y-1)\n    e=Eq(Dy[i], (y[i+1]-y[i])/(t[i+1]-t[i]))\n    code0 = ccode(e.lhs)\n    assert code0 == 'Dy[i]'\n    code1 = ccode(e.lhs, assign_to=e.rhs)\n    assert code1 == 'Dy[i] = (y[i + 1] - y[i])/(t[i + 1] - t[i]);'\n", "def test_ccode_For():\n    from sympy import symbols\n    i, m = symbols('i m')\n    x = symbols('x')\n    expr = For(i, Range(0, m, 1), (aug_assign(x, '+', i)))\n    assert ccode(expr) == (\n            'for (int i=0; i<m; i++){\\n'\n            '   x += i;\\n'\n            '}'\n            )\n", "def test_ccode_For():\n    from sympy.codegen import For, aug_assign, Assignment\n    x = symbols('x')\n    expr = For(Assignment(x, 0), (x < 10, x < 20), aug_assign(x, '+', 1))\n    assert ccode(expr) == (\n        \"for (x = 0; x < 10; x += 1){\\n\"\n        \"   if (x < 20){\\n\"\n        \"      break;\\n\"\n        \"   }\\n\"\n        \"}\"\n    )\n    expr = For(Assignment(x, 0), (x < 10, x < 20), aug_assign(x, '+', 1),\n               (Assignment(x, x + 1),))\n    assert ccode(expr) == (\n        \"for (x = 0; x < 10; x += 1){\\n\"\n        \"   if (x < 20){\\n\"\n        \"      break;\\n\"\n        \"   }\\n\"\n        \"   x = x + 1;\\n\"\n        \"}\"\n    )\n"], "sample_62": ["    def setUp(self):\n        super().setUp()\n        self.dirname = self.mkdtemp()\n        # Caches location cannot be modified through override_settings /\n        # modify_settings, hence settings are manipulated directly here and the\n        # setting_changed signal is triggered manually.\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n", "    def setUp(self):\n        super().setUp()\n        self.dirname = self.mkdtemp()\n        # Caches location cannot be modified through override_settings /\n        # modify_settings, hence settings are manipulated directly here and the\n        # setting_changed signal is triggered manually.\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n", "    def test_pickle_protocol(self):\n        # Test the protocol number used for pickling\n        with self.settings(CACHES={\n            \"default\": {\n                \"BACKEND\": \"django.core.cache.backends.filebased.FileBasedCache\",\n                \"OPTIONS\": {\"pickle_protocol\": 2},\n            },\n        }):\n            cache = caches[\"default\"]\n            cache.set(\"key\", \"value\")\n            cache_file = cache._key_to_file(\"key\")\n            with open(cache_file, \"rb\") as f:\n                self.assertEqual(pickle.loads(f.read())[:2], (2, b'\\x80\\x02'))\n\n        with self.settings(CACHES={\n            \"default\": {\n                \"BACKEND\": \"django.core.cache.backends.filebased.FileBasedCache\",\n                \"OPTIONS\": {\"pickle_protocol\": 4},\n            },\n        }):\n            cache = caches[\"default\"]\n            cache.set(\"key\", \"value\")\n            cache_file = cache._key_to_file(\"key\")\n            with open(cache_file, \"rb\") as f:\n                self.assertEqual(pickle.loads(f.read())[:2], (4, b'\\x80\\x04'))\n", "    def setUp(self):\n        super().setUp()\n        self.dirname = self.mkdtemp()\n        # Caches location cannot be modified through override_settings /\n        # modify_settings, hence settings are manipulated directly here and the\n        # setting_changed signal is triggered manually.\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n", "    def setUp(self):\n        super().setUp()\n        self.dirname = self.mkdtemp()\n        # Caches location cannot be modified through override_settings /\n        # modify_settings, hence settings are manipulated directly here and the\n        # setting_changed signal is triggered manually.\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n"], "sample_8": ["    def test_technical_500_response(self):\n        request = RequestFactory().get('/')\n        exc_type = ValueError\n        exc_value = ValueError('Test exception')\n        tb = sys.exc_info()[2]\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response.content_type, 'text/html')\n        self.assertTemplateUsed(response, 'technical_500.html')\n        self.assertEqual(response.reason_phrase, 'Internal Server Error')\n", "    def test_sensitive_variables_exception(self):\n        with self.settings(DEBUG=True):\n            try:\n                sensitive_view(self.rf.post('/some_url/'))\n            except Exception:\n                exc_type, exc_value, tb = sys.exc_info()\n            reporter = ExceptionReporter(self.rf.post('/some_url/'), exc_type, exc_value, tb)\n            html = reporter.get_traceback_html()\n            self.assertIn('sauce', html)\n            self.assertNotIn('worcestershire', html)\n            self.assertIn('sauce', html)\n            self.assertNotIn('worcestershire', html)\n\n            text = reporter.get_traceback_text()\n            self.assertIn('sauce', text)\n            self.assertNotIn('worcestershire', text)\n", "    def test_get_traceback_frames_from_string(self):\n        \"\"\"\n        Frames can be extracted from a traceback generated from a string.\n        \"\"\"\n        source = \"\"\"", "    def test_sensitive_cleansed_multivaluedict(self):\n        \"\"\"\n        The cleanse_special_types method cleanses the keys of MultiValueDicts\n        marked as sensitive.\n        \"\"\"\n        class Request:\n            pass\n\n        request = Request()\n        request.sensitive_post_parameters = ['sensitive_key']\n\n        multivaluedict = MultiValueDict({'sensitive_key': ['value'], 'public_key': ['value']})\n        filter = SafeExceptionReporterFilter()\n        cleansed_multivaluedict = filter.get_cleansed_multivaluedict(request, multivaluedict)\n\n        self.assertIn('sensitive_key', cleansed_multivaluedict)\n        self.assertEqual(cleansed_multivaluedict['sensitive_key'], [CLEANSED_SUBSTITUTE])\n        self.assertIn('public_key', cleansed_multivaluedict)\n        self.assertEqual(cleansed_multivaluedict['public_key'], ['value'])\n", "    def test_recursive_dicts(self):\n        \"\"\"\n        Recursively cleanse settings in dictionaries.\n        \"\"\"\n        settings_dict = {\n            'SECRET_KEY': 'super_secret',\n            'PASSWORD': 'another_secret',\n            'OTHER': 'public',\n            'NESTED': {\n                'SECRET_KEY': 'nested_secret',\n                'PASSWORD': 'another_nested_secret',\n                'OTHER': 'nested_public',\n            },\n            'NESTED_DICT_KEY': {\n                'SECRET_KEY': 'nested_dict_key_secret',\n                'OTHER': 'nested_dict_key_public',\n            },\n        }\n        with self.settings(**settings_dict):\n            safe_settings = get_safe_settings()\n            self.assertEqual(safe_settings['SECRET_KEY'], CLEANSED_SUBSTITUTE)\n            self.assertEqual(safe_settings['PASSWORD'], CLEANSED_SUBSTITUTE)\n            self.assertEqual(safe_settings['OTHER'], 'public')\n            self.assertEqual(safe_settings['NESTED']['SECRET_KEY'], CLEANSED_SUBSTITUTE)\n            self.assertEqual(safe_settings['NESTED']['PASSWORD'], CLEANSED_SUBSTITUTE)\n            self.assertEqual(safe_settings['NESTED']['OTHER'], 'nested_public')\n            self.assertEqual(safe_settings['NESTED_DICT_KEY']['SECRET_KEY'], CLEANSED_SUBSTITUTE)\n            self.assertEqual(safe_settings['NESTED_DICT_KEY']['OTHER'], 'nested_dict_key_public')\n"], "sample_101": ["def test_feature_union_caching():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    pca = PCA(n_components=2, svd_solver='randomized', random_state=0)\n    select = SelectKBest(k=1)\n    # test using fit followed by transform\n    fs = FeatureUnion([(\"pca\", pca), (\"select\", select)],\n                      transformer_weights={\"pca\": 10},\n                      n_jobs=2)\n    fs.fit(X, y)\n    X_transformed = fs.transform(X)\n    # test using fit_transform\n    fs = FeatureUnion([(\"pca\", pca), (\"select\", select)],\n                      transformer_weights={\"pca\": 10},\n                      n_jobs=2)\n    X_fit_transformed = fs.fit_transform(X, y)\n    # check against expected result\n\n    # We use a different pca object to control the random_state stream\n    assert_array_almost_equal(X_transformed[:, :-1], 10 * pca.fit_transform(X))\n    assert_array_equal(X_transformed[:, -1],\n                       select.fit_transform(X, y).ravel())\n    assert_array_almost_equal(X_fit_transformed[:, :-1],\n                              10 * pca.fit_transform(X))\n    assert_array_equal(X_fit_transformed[:, -1],\n                       select.fit_transform(X, y).ravel())\n", "def test_pipeline_predict_with_sample_weight():\n    # Test that the pipeline passes sample_weight to the final estimator\n    # when predict is invoked\n    pipe = Pipeline([('transf', Transf()), ('clf', FitParamT())])\n    pipe.fit(None, None)\n    pipe.predict(X=None, sample_weight=np.array([1, 2]))\n    assert_array_equal(pipe.named_steps['clf'].successful, np.array([1, 2]))\n", "def test_pipeline_set_params_replace_estimator():\n    # Test set_params to replace estimator with another estimator type.\n    pipe = Pipeline([('estimator', LogisticRegression())])\n    pipe.set_params(estimator=LinearRegression())\n    assert isinstance(pipe.named_steps['estimator'], LinearRegression)\n", "def test_pipeline_set_memory():\n    # Test that setting 'memory' parameter correctly changes the cache\n    X = np.array([[1, 2]])\n    pipe = Pipeline([('transf', Transf()), ('clf', Mult())],\n                    memory=DummyMemory())\n    pipe.fit(X, y=None)\n    assert isinstance(pipe.memory, DummyMemory)\n\n    pipe.set_params(memory=None)\n    assert pipe.memory is None\n\n    pipe.set_params(memory=DummyMemory())\n    assert isinstance(pipe.memory, DummyMemory)\n\n    assert_raise_message(\n        TypeError,\n        \"'memory' should be None, a string or have the same interface as \"\n        \"joblib.Memory. Got 'abc' instead.\",\n        pipe.set_params, memory='abc'\n    )\n", "def test_pipeline_memory_clone():\n    # Test that when memory is used with a Pipeline, the transformers are\n    # cloned before being fitted. This ensures that the user cannot directly\n    # inspect the transformers in the pipeline.\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        memory = Memory(location=cachedir, verbose=10)\n        # Test with Transformer + SVC\n        clf = SVC(gamma='scale', probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', transf), ('svc', clf)], memory=memory)\n        pipe.fit(X, y)\n        # Check that the transformer in the pipeline was not fitted\n        assert not hasattr(transf, 'means_')\n        # Check that we are reading the cache while fitting a second time\n        pipe.fit(X, y)\n        # Check that the transformer in the pipeline was not fitted\n        assert not hasattr(transf, 'means_')\n    finally:\n        shutil.rmtree(cachedir)\n"], "sample_11": ["def test_serialize_settings_reference(self):\n    setting_name = 'AUTH_USER_MODEL'\n    setting_value = 'auth.User'\n    setting_reference = SettingsReference(setting_name, setting_value)\n    string, imports = MigrationWriter.serialize(setting_reference)\n    self.assertEqual(string, \"settings.AUTH_USER_MODEL\")\n    self.assertEqual(imports, {\"from django.conf import settings\"})\n    self.serialize_round_trip(setting_reference)\n", "def test_register_serializer(self):\n    Serializer.register(datetime.timedelta, ComplexSerializer)\n    try:\n        self.assertSerializedResultEqual(\n            datetime.timedelta(days=1, hours=2),\n            (\"complex(datetime.timedelta(days=1, hours=2))\", set()),\n        )\n    finally:\n        Serializer.unregister(datetime.timedelta)\n", "def test_register_serializer(self):\n    class MyType:\n            self.value = value\n\n    class MySerializer(BaseSerializer):\n            return repr(self.value), {}\n\n    Serializer.register(MyType, MySerializer)\n\n    my_value = MyType(\"Test value\")\n    string, imports = serializer_factory(my_value).serialize()\n    self.assertEqual(string, repr(my_value.value))\n    self.assertEqual(imports, set())\n\n    Serializer.unregister(MyType)\n\n    with self.assertRaises(ValueError):\n        serializer_factory(my_value).serialize()\n", "def test_serializer_registration(self):\n    # Test that a custom serializer can be registered and used\n    Serializer.register(Complex, ComplexSerializer)\n    complex_value = Complex(1, 2)\n    string, imports = MigrationWriter.serialize(complex_value)\n    self.assertEqual(string, 'complex(%r)' % complex_value)\n    self.assertEqual(imports, set())\n\n    # Test that unregistering a serializer returns it to its original state\n    Serializer.unregister(Complex)\n    with self.assertRaises(ValueError):\n        MigrationWriter.serialize(complex_value)\n\n    # Test that registering a serializer that doesn't inherit from BaseSerializer raises an error\n    with self.assertRaises(ValueError):\n        Serializer.register(Complex, object)\n", "def test_serialize_function_type(self):\n        pass\n\n    self.serialize_round_trip(local_function)\n\n    @functools.wraps(local_function)\n        pass\n\n    self.serialize_round_trip(wrapped_function)\n\n    class Class:\n            pass\n\n    instance = Class()\n    self.serialize_round_trip(instance.method)\n\n    class Class:\n        @staticmethod\n            pass\n\n    self.serialize_round_trip(Class.static_method)\n\n    class Class:\n        @classmethod\n            pass\n\n    self.serialize_round_trip(Class.class_method)\n\n    self.serialize_round_trip(MathTypeSerializer)\n\n        return str(value)\n\n    self.serialize_round_trip(MathTypeSerializer)\n\n    with self.assertRaisesMessage(ValueError, 'Could not find function <lambda> in migrations.test_writer'):\n        self.serialize_round_trip(lambda x: x)\n"], "sample_122": ["def test_scalar_multiply():\n    M = SparseMatrix.eye(3)\n    s = 2\n    N = M.scalar_multiply(s)\n    assert N == M.applyfunc(lambda x: x * s)\n    M = SparseMatrix.zeros(3, 3)\n    s = 0\n    N = M.scalar_multiply(s)\n    assert N == M\n", "def test_sparse_matrix_methods():\n    s = SparseMatrix(3, 3, lambda i, j: 1 if i == j else 0)\n\n    # Test fill method\n    s.fill(5)\n    assert s[0, 0] == 5\n    assert s[1, 1] == 5\n    assert s[2, 2] == 5\n    s.fill(0)\n\n    # Test row_op and col_op methods\n    s[1, 1] = 2\n    s.row_op(1, lambda v, j: v + 1)\n    assert s[1, 0] == 1\n    assert s[1, 1] == 3\n    assert s[1, 2] == 1\n    s.col_op(1, lambda v, i: v * 2)\n    assert s[0, 1] == 0\n    assert s[1, 1] == 6\n    assert s[2, 1] == 0\n\n    # Test row_swap and col_swap methods\n    s.row_swap(0, 1)\n    assert s[0, 0] == 0\n    assert s[0, 1] == 6\n    assert s[0, 2] == 0\n    assert s[1, 0] == 0\n    assert s[1, 1] == 0\n    assert s[1, 2] == 0\n    s.col_swap(0, 1)\n    assert s[0, 0] == 6\n    assert s[0, 1] == 0\n    assert s[0, 2] == 0\n    assert s[1, 0] == 0\n    assert s[1, 1] == 0\n    assert s[1, 2] == 0\n\n    # Test copyin_list and copyin_matrix methods\n    s.copyin_list((1, 0), [1, 2, 3])\n    assert s[1, 0] == 1\n    assert s[2, 0] == 3\n    s.copyin_matrix((1, 0), SparseMatrix(1, 3, [4, 5, 6]))\n    assert s[1, 0] == 4\n   ", "def test_sparsetranspose_and_mutation():\n    A = SparseMatrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    B = A.transpose()\n    A[0, 1] = 100\n    assert B[1, 0] != 100\n    assert B[1, 0] == 2\n    assert A[0, 1] == 100\n\n    A = SparseMatrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    B = A.copy().transpose()\n    A[0, 1] = 100\n    assert B[1, 0] != 100\n    assert B[1, 0] == 2\n    assert A[0, 1] == 100\n", "def test_sparse_fill():\n    m = SparseMatrix(2, 2, {})\n    assert len(m._smat) == 0\n    m.fill(1)\n    assert len(m._smat) == 4\n    m.fill(0)\n    assert len(m._smat) == 0\n    m.fill(1)\n    m.fill(2)\n    assert len(m._smat) == 4\n    for v in m._smat.values():\n        assert v == 2\n", "def test_sliced_sparse_matrix_methods():\n    m = SparseMatrix(5, 5, lambda i, j: i + j)\n\n    # test applyfunc\n    assert m[1:3, :].applyfunc(lambda x: 2*x) == SparseMatrix(2, 5, lambda i, j: 2*(i+1 + j))\n\n    # test row_list\n    assert m[1:3, :].row_list() == [(0, 0, 1), (0, 1, 2), (0, 2, 3), (0, 3, 4), (0, 4, 5),\n                                    (1, 0, 2), (1, 1, 3), (1, 2, 4), (1, 3, 5), (1, 4, 6)]\n\n    # test col_list\n    assert m[:, 1:3].col_list() == [(0, 1, 1), (1, 1, 2), (2, 1, 3), (3, 1, 4), (4, 1, 5),\n                                    (0, 2, 2), (1, 2, 3), (2, 2, 4), (3, 2, 5), (4, 2, 6)]\n\n    # test nnz\n    assert m[1:3, :].nnz() == 10\n\n    # test _LDL_sparse\n    L, D = m[1:3, :]._LDL_sparse()\n    assert L == SparseMatrix(2, 2, lambda i, j: 1 if i == j else 0)\n    assert D == SparseMatrix(2, 2, lambda i, j: 2*i + 1 if i == j else 0)\n\n    # test LDLdecomposition\n    L, D = m[1:3, :].LDLdecomposition()\n    assert L == SparseMatrix(2, 2, lambda i, j: 1 if i == j else 0)\n    assert D == SparseMatrix(2, 2, lambda i, j: 2*i + 1 if i == j else 0)\n\n    # test _cholesky_sparse\n    C = m[1:3, :]._cholesky"], "sample_54": ["    def test_avoid_wrapping(self):\n        self.assertEqual(avoid_wrapping(\"Test string with spaces\"), \"Test\\xa0string\\xa0with\\xa0spaces\")\n        self.assertEqual(avoid_wrapping(\"Test string without spaces\"), \"Test\\xa0string\\xa0without\\xa0spaces\")\n        self.assertEqual(avoid_wrapping(\"Single word\"), \"Single\\x20word\")\n", "def test_urlizer(self):\n    tests = (\n        (\n            \"http://\u00f6\u00e4\u00fc.com/\",\n            '<a href=\"http://xn--4ca9at.com/\">http://\u00f6\u00e4\u00fc.com/</a>',\n        ),\n        (\n            \"http://\u00f6\u00e4\u00fc.com/\u00f6\u00e4\u00fc/\",\n            '<a href=\"http://xn--4ca9at.com/%C3%B6%C3%A4%C3%BC/\">http://\u00f6\u00e4\u00fc.com/\u00f6\u00e4\u00fc/</a>',\n        ),\n        (\"www.django.com\", '<a href=\"http://www.django.com\">www.django.com</a>'),\n        (\"django.com\", '<a href=\"http://django.com\">django.com</a>'),\n        (\"test@example.com\", '<a href=\"mailto:test@example.com\">test@example.com</a>'),\n        (\n            \"http://example.com/?q=<>&\",\n            '<a href=\"http://example.com/?q=%3C%3E%26\">http://example.com/?q=&lt;&gt;&amp;</a>',\n        ),\n        (\n            \"http://example.com/?q=<script>alert('XSS')</script>\",\n            '<a href=\"http://example.com/?q=%3Cscript%3Ealert(%27XSS%27)%3C/script%3E\">http://example.com/?q=&lt;script&gt;alert(&#x27;XSS&#x27;)&lt;/script&gt;</a>',\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlizer(value), output)\n", "    def test_urlizer(self):\n        urlizer = Urlizer()\n        self.assertEqual(\n            urlizer(\"Hello world!\", trim_url_limit=10, nofollow=True),\n            \"Hello world!\",\n        )\n        self.assertEqual(\n            urlizer(\"http://example.com\", trim_url_limit=10, nofollow=True),\n            '<a href=\"http://example.com\" rel=\"nofollow\">http://example.com</a>',\n        )\n        self.assertEqual(\n            urlizer(\"http://example.com\", trim_url_limit=5, nofollow=True),\n            '<a href=\"http://example.com\" rel=\"nofollow\">http://e\u2026</a>',\n        )\n        self.assertEqual(\n            urlizer(\"www.example.com\", trim_url_limit=10, nofollow=True),\n            '<a href=\"http://www.example.com\" rel=\"nofollow\">www.example.com</a>',\n        )\n        self.assertEqual(\n            urlizer(\"example@example.com\", trim_url_limit=10, nofollow=True),\n            '<a href=\"mailto:example@example.com\">example@example.com</a>',\n        )\n", "def test_urlizer(self):\n    tests = (\n        (\"Search for (www.test.com)\", 'Search for (<a href=\"http://www.test.com\">www.test.com</a>)'),\n        ('Search for \"www.test.com\"', 'Search for \"<a href=\"http://www.test.com\">www.test.com</a>\"'),\n        (\"Search for 'www.test.com'\", \"Search for '<a href=\\\"http://www.test.com\\\">www.test.com</a>'\"),\n        (\"Search for www.test.com!\", 'Search for <a href=\"http://www.test.com\">www.test.com</a>!'),\n        (\"Search for www.test.com.\", 'Search for <a href=\"http://www.test.com\">www.test.com</a>.'),\n        (\"Search for www.test.com?\", 'Search for <a href=\"http://www.test.com\">www.test.com</a>?'),\n        (\"Search for www.test.com(\", 'Search for <a href=\"http://www.test.com\">www.test.com</a>('),\n        (\"Search for www.test.com)\", 'Search for <a href=\"http://www.test.com\">www.test.com</a>)'),\n        (\"Search for www.test.com[\", 'Search for <a href=\"http://www.test.com\">www.test.com</a>['),\n        (\"Search for www.test.com]\", 'Search for <a href=\"http://www.test.com\">www.test.com</a>]'),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlizer(value), output)\n", "def test_urlize_edge_cases(self):\n    tests = (\n        # Test that it doesn't match too much.\n        (\n            \"not a link: www (no dot)\",\n            \"not a link: www (no dot)\",\n        ),\n        # Test that it matches .co.uk domains.\n        (\n            \"example.co.uk is a valid domain\",\n            'example.co.uk is a valid domain',\n        ),\n        # Test that it doesn't match .co.uk inside another domain.\n        (\n            \"not a link: example.co.uk.com (not a valid domain)\",\n            \"not a link: example.co.uk.com (not a valid domain)\",\n        ),\n        # Test that it doesn't match on subdomains.\n        (\n            \"not a link: subdomain.example.com (has subdomain)\",\n            \"not a link: subdomain.example.com (has subdomain)\",\n        ),\n        # Test that it doesn't match on a TLD without domain.\n        (\n            \"not a link: .com (no domain)\",\n            \"not a link: .com (no domain)\",\n        ),\n        # Test that it doesn't match on email addresses without '@'.\n        (\n            \"not a link: foo.example.com (missing @)\",\n            \"not a link: foo.example.com (missing @)\",\n        ),\n        # Test that it matches email addresses with subdomains.\n        (\n            \"foo@example.co.uk is a valid email address\",\n            '<a href=\"mailto:foo@example.co.uk\">foo@example.co.uk</a> is a valid email address',\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_29": ["    def test_subquery_annotation_on_same_model(self):\n        Employee.objects.create(firstname='John', lastname='Doe', salary=30)\n        Employee.objects.create(firstname='Jane', lastname='Doe', salary=20)\n        qs = Employee.objects.annotate(\n            max_salary=Subquery(\n                Employee.objects.filter(lastname=OuterRef('lastname')).order_by('-salary').values('salary')[:1]\n            )\n        )\n        self.assertEqual(qs.get().max_salary, 30)\n", "    def setUpTestData(cls):\n        cls.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max.manager = Manager.objects.create(name='Manager')\n        cls.max.save()\n        cls.max.manager.manager = cls.max\n        cls.max.manager.save()\n", "    def test_clone(self):\n        q = Query(Company)\n        clone = q.clone()\n        self.assertEqual(q.__dict__, clone.__dict__)\n        self.assertIsNot(q.__dict__, clone.__dict__)\n", "    def setUpTestData(cls):\n        cls.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.company = Company.objects.create(name='Test GmbH', num_employees=32, num_chairs=1, ceo=cls.max)\n", "    def test_ref_resolution(self):\n        # Test that Ref expressions can be resolved to Col expressions.\n        query = Query(Employee)\n        query.select = (Ref('col', Sum('salary')),)\n        query.annotations = {'col': Sum('salary')}\n        query.set_annotation_mask(['col'])\n        query.set_select([Col(query.alias_map[query.base_table].table_name, 'salary')])\n        query.select_related = False\n        query.default_cols = False\n        query.add_ordering('col')\n        self.assertEqual(\n            str(query).splitlines(),\n            ['SELECT SUM(T1.salary) AS col FROM expressions_employee T1 ORDER BY T1.salary ASC']\n        )\n"], "sample_37": ["    def setUp(self):\n        self.relation_name = 'rel_name'\n        self.condition = Q()\n        self.filtered_relation = FilteredRelation(self.relation_name, condition=self.condition)\n", "    def test_resolve_expression(self):\n        q = Q(num_employees__gt=3)\n        clause, joins = Company.objects.all().query._add_q(q)\n        self.assertEqual(clause, ('num_employees__gt', 3))\n        self.assertEqual(joins, [])\n", "    def test_q_resolution(self):\n        q = Q(id__exact=5)\n        self.assertEqual(q.children[0][1], 5)\n", "    def test_q_expression_or(self):\n        # Test Q() with | (or) and ensure the correct number of queries are executed.\n        with self.assertNumQueries(1):\n            qs = Company.objects.filter(Q(num_employees__gt=1000) | Q(num_chairs__gt=10))\n            self.assertEqual(len(qs), 3)\n            list(qs)\n", "    def test_PathInfo(self):\n        from django.db.models.fields.related import ForwardOneToOneDescriptor\n        from django.db.models.fields.related import ForwardManyToOneDescriptor, ReverseOneToOneDescriptor, ReverseOneToOneDescriptor\n        from django.db.models.fields.related import ReverseOneToOneDescriptor\n        from django.test.utils import isolate_apps\n\n        with isolate_apps('expressions'):\n            class Model1(Model):\n                pass\n\n            class Model2(Model):\n                field = IntegerField()\n                model1 = OneToOneField(Model1, on_delete=models.CASCADE, related_name='model2')\n\n            class Model3(Model):\n                field = IntegerField()\n                model1 = OneToOneField(Model1, on_delete=models.CASCADE, related_name='model3', parent_link=True)\n\n            model1 = Model1()\n            model2 = Model2(model1=model1)\n            model3 = Model3(model1=model1)\n\n            self.assertEqual(\n                PathInfo(\n                    from_opts=model1._meta,\n                    to_opts=model2._meta,\n                    target_fields=[model2._meta.get_field('field')],\n                    join_field=model2._meta.get_field('model1'),\n                    m2m=False,\n                    direct=True,\n                    filtered_relation=None\n                ),\n                PathInfo._make([\n                    model1._meta,\n                    model2._meta,\n                    [model2._meta.get_field('field')],\n                    model2._meta.get_field('model1'),\n                    False,\n                    True,\n                    None,\n                ])\n            )\n\n            self.assertEqual(\n                PathInfo(\n                    from_opts=model1._meta,\n                    to_opts=model3._meta,\n                    target_fields=[model3._meta.get_field('field')],\n                    join_field=model3._meta.get_field('model1'),\n                    m2m=False,\n                    direct=True,\n                    filtered_relation=None\n                ),\n                PathInfo._make([\n                    model1._meta,\n                    model3._meta,\n                    [model3._meta.get_field('field')],\n                    model3._meta.get_field('model1'),\n                    False,\n                    True,\n                    None,\n                ])\n            )\n\n            path1 = PathInfo(\n                from_opts=model2._meta,\n                to_opts=model1._meta,\n                target_fields=[model1._meta.get_field('model2')],\n                join_field=model2._meta.get_field('model1'),\n                m2m=False,\n                direct=False,\n                filtered_relation=None\n            )\n\n            path2 = PathInfo(\n                from_opts=model3._meta"], "sample_56": ["    def test_template_tags_no_libraries(self):\n        self.assertEqual(\n            check_for_template_tags_with_the_same_name(None),\n            [],\n        )\n", "    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n", "    def setUpClass(cls):\n        super().setUpClass()\n        cls.empty_libraries_error = Error(\n            E003.msg.format(\n                \"'empty_libraries'\",\n                \"'check_framework.template_test_apps.empty_libraries_app_1.\"\n                \"templatetags.empty_libraries', \"\n                \"'check_framework.template_test_apps.empty_libraries_app_2.\"\n                \"templatetags.empty_libraries'\",\n            ),\n            id=E003.id,\n        )\n", "    def test_template_tags_with_empty_modules(self):\n        self.assertEqual(\n            check_for_template_tags_with_the_same_name(None),\n            [],\n        )\n", "    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_empty_string_library = Error(\n            E003.msg.format(\n                \"''\",\n                \"'check_framework.template_test_apps.same_tags_app_1.templatetags.'\",\n            ),\n            id=E003.id,\n        )\n"], "sample_88": ["def test_ellipsize():\n    assert _ellipsize(\"short\", 10) == \"short\"\n    assert _ellipsize(\"a\" * 10, 10) == \"a\" * 10\n    assert _ellipsize(\"a\" * 100, 10) == \"aaaaa...aaaaa\"\n    assert _ellipsize(\"a\" * 100, 5) == \"a...a\"\n", "def test_saferepr_recursive_objects():\n    class RecursiveObject:\n            self.value = value\n            self.ref = None\n\n            return f\"RecursiveObject(value={self.value})\"\n\n    obj1 = RecursiveObject(1)\n    obj2 = RecursiveObject(2)\n    obj1.ref = obj2\n    obj2.ref = obj1\n\n    assert \"RecursiveObject\" in saferepr(obj1)\n    assert \"RecursiveObject\" in saferepr(obj2)\n\n    # Test that saferepr doesn't go into an infinite recursion\n    assert len(saferepr(obj1)) > 0\n    assert len(saferepr(obj2)) > 0\n", "def test_saferepr_with_recursive_data_structures():\n    \"\"\"Test saferepr() with recursive data structures.\"\"\"\n    class RecursiveList:\n            self.data = data\n            self.nested = [self]\n\n            return f\"RecursiveList({self.data})\"\n\n    recursive_list = RecursiveList([1, 2, 3])\n    assert \"RecursiveList\" in saferepr(recursive_list)\n\n    class RecursiveDict:\n            self.data = data\n            self.nested = {\"key\": self}\n\n            return f\"RecursiveDict({self.data})\"\n\n    recursive_dict = RecursiveDict({\"key\": \"value\"})\n    assert \"RecursiveDict\" in saferepr(recursive_dict)\n\n    class RecursiveTuple:\n            self.data = data\n            self.nested = (self,)\n\n            return f\"RecursiveTuple({self.data})\"\n\n    recursive_tuple = RecursiveTuple((1, 2, 3))\n    assert \"RecursiveTuple\" in saferepr(recursive_tuple)\n", "def test_ellipsis_handling():\n    \"\"\"Test ellipsis handling in saferepr() for long strings.\"\"\"\n    long_string = \"x\" * 250\n    assert saferepr(long_string) == repr(long_string[:10] + \"...\" + long_string[-10:])\n    assert saferepr(long_string, maxsize=50) == repr(long_string[:5] + \"...\" + long_string[-5:])\n", "def test_repr_with_ellipses():\n    class TestObject:\n            self.value = value\n\n            return f\"TestObject({self.value})\"\n\n    obj = TestObject(\"a\" * 500)\n    assert len(saferepr(obj)) < 500\n    assert saferepr(obj).endswith(\"...\")\n\n    obj = TestObject(\"a\" * 240)\n    assert len(saferepr(obj)) <= 240\n    assert \"...\" not in saferepr(obj)\n"], "sample_74": ["def test_colorbar_log_minortick_labels_negative():\n    with rc_context({'_internal.classic_mode': False}):\n        fig, ax = plt.subplots()\n        pcm = ax.imshow([[10000, 50000]], norm=LogNorm(vmin=100, vmax=100000))\n        cb = fig.colorbar(pcm)\n        fig.canvas.draw()\n        lb = [l.get_text() for l in cb.ax.yaxis.get_ticklabels(which='both')]\n        expected = [r'$\\mathdefault{10^{2}}$',\n                    r'$\\mathdefault{2\\times10^{2}}$',\n                    r'$\\mathdefault{3\\times10^{2}}$',\n                    r'$\\mathdefault{4\\times10^{2}}$',\n                    r'$\\mathdefault{5\\times10^{2}}$',\n                    r'$\\mathdefault{6\\times10^{2}}$',\n                    r'$\\mathdefault{7\\times10^{2}}$',\n                    r'$\\mathdefault{8\\times10^{2}}$',\n                    r'$\\mathdefault{9\\times10^{2}}$',\n                    r'$\\mathdefault{10^{3}}$',\n                    r'$\\mathdefault{2\\times10^{3}}$',\n                    r'$\\mathdefault{3\\times10^{3}}$',\n                    r'$\\mathdefault{4\\times10^{3}}$',\n                    r'$\\mathdefault{5\\times10^{3}}$',\n                    r'$\\mathdefault{6\\times10^{3}}$',\n                    r'$\\mathdefault{7\\times10^{3}}$',\n                    r'$\\mathdefault{8\\times10^{3}}$',\n                    r'$\\mathdefault{9\\times10^{3}}$',\n                    r'$\\mathdefault{10^{4}}$',\n                    r'$\\mathdefault{2\\times10^{4}}$',\n                    r'$\\mathdefault{3\\times10^{4}}$',\n                    r'$\\mathdefault{4\\times10^{4}}$',\n                    r'$\\mathdefault{5\\times10^{4}}$']\n        for exp in expected:\n            assert exp in lb\n", "def test_colorbar_edgecolor():\n    \"\"\"\n    Test that the edge color of a colorbar can be changed.\n    \"\"\"\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.arange(100).reshape(10, 10))\n    cb = fig.colorbar(pc)\n    cb.outline.set_edgecolor('red')\n    assert cb.outline.get_edgecolor() == mcolors.to_rgba('red')\n    cb.outline.set_edgecolor('#00ff00')\n    assert cb.outline.get_edgecolor() == mcolors.to_rgba('#00ff00')\n", "def test_colorbar_draw_all():\n    # Check that the draw_all() method works.\n    # This should not be needed by users, but it is used internally.\n    fig, ax = plt.subplots()\n    data = np.arange(1200).reshape(30, 40)\n    levels = [0, 200, 400, 600, 800, 1000, 1200]\n\n    plt.contourf(data, levels=levels)\n    cbar = fig.colorbar(orientation='horizontal', use_gridspec=True)\n    cbar.ax.axis('off')\n    cbar.draw_all()\n    assert len(cbar.ax.texts) == 5\n", "def test_colorbar_add_lines():\n    # test add_lines with different length of hatches\n    fig, ax = plt.subplots()\n    x = np.linspace(-3.0, 4.001)\n    y = np.linspace(-4.0, 3.001)\n    X, Y = np.meshgrid(x, y)\n    Z = X * Y\n    Z = Z[:-1, :-1]\n    pc = ax.pcolormesh(X, Y, Z)\n    cbar = fig.colorbar(pc, ax=ax, extend='both')\n    hatches = ['/','o','+','//', 'x', 'o', '-', '\\\\']\n    levels = np.linspace(-15, 15, 8)\n    cbar.add_lines(levels, hatches, [2])\n", "def test_colorbar_dividers(spacing, extend):\n    fig, ax = plt.subplots()\n    im = ax.pcolormesh(np.arange(100).reshape(10, 10), cmap='RdBu_r')\n    cb = fig.colorbar(im, ax=ax, extend=extend, spacing=spacing)\n    fig.draw_without_rendering()\n    dividers = cb.dividers.get_segments()\n    # number of dividers should be one less than the number of colors\n    assert len(dividers) == 9\n    # the segments should be horizontal (i.e. x-coordinates same)\n    # if the colorbar is vertical\n    assert np.allclose(dividers[:, :, 0], 0.5)\n    # and vertical if the colorbar is horizontal\n    cb.ax.invert_xaxis()\n    fig.draw_without_rendering()\n    dividers = cb.dividers.get_segments()\n    assert np.allclose(dividers[:, :, 1], 0.5)\n"], "sample_111": ["def test_all_points_in_one_cluster(metric_name, y1, y2):\n    metric = SUPERVISED_METRICS[metric_name]\n    score = metric(y1, y2)\n    assert score == pytest.approx(0.0)\n", "def test_1_cluster(metric_name):\n    # Test that metrics return 1.0 when there is only 1 cluster\n    y_true = [0, 0, 0, 0, 0, 0]\n    y_pred = [0, 0, 0, 0, 0, 0]\n    metric = SUPERVISED_METRICS[metric_name]\n    assert metric(y_true, y_pred) == pytest.approx(1.0)\n", "def test_contingency_matrix(sparse):\n    y_true = np.array([0, 0, 1, 1, 0, 0, 1, 1])\n    y_pred = np.array([0, 1, 0, 1, 0, 1, 0, 1])\n    contingency = contingency_matrix(y_true, y_pred, sparse=sparse)\n    if sparse:\n        assert isinstance(contingency, sp.csr_matrix)\n    else:\n        assert isinstance(contingency, np.ndarray)\n    assert contingency.shape == (2, 2)\n    assert np.allclose(contingency.sum(), len(y_true))\n", "def test_input_checking(metric_name):\n    metric = SUPERVISED_METRICS[metric_name]\n    # Test input checking for labels_true and labels_pred\n    y_true = np.array([0, 0, 1, 1])\n    y_pred = np.array([0, 1, 0, 1])\n\n    # test with invalid shape\n    with pytest.raises(ValueError):\n        metric(y_true.reshape(-1, 1), y_pred)\n\n    with pytest.raises(ValueError):\n        metric(y_true, y_pred.reshape(-1, 1))\n\n    # test with different length\n    with pytest.raises(ValueError):\n        metric(y_true, y_pred[:-1])\n\n    with pytest.raises(ValueError):\n        metric(y_true[:-1], y_pred)\n\n    # test with non-1d array\n    with pytest.raises(ValueError):\n        metric(np.array([y_true, y_true]), y_pred)\n\n    with pytest.raises(ValueError):\n        metric(y_true, np.array([y_pred, y_pred]))\n", "def test_contingency_matrix(eps, sparse):\n    labels_true = np.array([0, 0, 1, 1])\n    labels_pred = np.array([0, 1, 0, 1])\n    contingency = contingency_matrix(labels_true, labels_pred, eps, sparse)\n    assert isinstance(contingency, (np.ndarray, sp.csr_matrix))\n    if sparse:\n        assert sp.issparse(contingency)\n    else:\n        assert not sp.issparse(contingency)\n\n    expected_contingency = np.array([[1, 1], [1, 1]])\n    if eps is not None:\n        expected_contingency += eps\n    if sparse:\n        assert_allclose(contingency.toarray(), expected_contingency)\n    else:\n        assert_allclose(contingency, expected_contingency)\n\n"], "sample_47": ["def test_migrate_with_progress_callback(self):\n    \"\"\"\n    Test that the progress callback is called at the correct times during migration.\n    \"\"\"\n    callback_calls = []\n\n        callback_calls.append((action, migration, fake))\n\n    executor = MigrationExecutor(connection, progress_callback=progress_callback)\n    executor.migrate([(\"migrations\", \"0001_initial\")])\n\n    expected_calls = [\n        (\"apply_start\", executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n        (\"apply_success\", executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n    ]\n\n    self.assertEqual(callback_calls, expected_calls)\n", "    def test_replace_migrations(self):\n        \"\"\"\n        Test that replacement migrations work correctly.\n        \"\"\"\n        executor = MigrationExecutor(connection)\n        # Record all replaced migrations as applied\n        recorder = MigrationRecorder(connection)\n        recorder.record_applied(\"migrations\", \"0001_initial\")\n        recorder.record_applied(\"migrations\", \"0002_second\")\n        executor.loader.build_graph()\n        # Migrate to the replacement migration\n        executor.migrate([(\"migrations\", \"0001_squashed_0002\")])\n        # Check that the replacement migration is marked as applied\n        self.assertIn((\"migrations\", \"0001_squashed_0002\"), recorder.applied_migrations())\n        # Check that the replaced migrations are not marked as applied\n        self.assertNotIn((\"migrations\", \"0001_initial\"), recorder.applied_migrations())\n        self.assertNotIn((\"migrations\", \"0002_second\"), recorder.applied_migrations())\n        # Migrate back to the beginning\n        executor.migrate([(\"migrations\", None)])\n        # Check that the replacement migration is not marked as applied\n        self.assertNotIn((\"migrations\", \"0001_squashed_0002\"), recorder.applied_migrations())\n        # Check that the replaced migrations are not marked as applied\n        self.assertNotIn((\"migrations\", \"0001_initial\"), recorder.applied_migrations())\n        self.assertNotIn((\"migrations\", \"0002_second\"), recorder.applied_migrations())\n", "def test_detect_soft_applied_initial_migration(self):\n    \"\"\"\n    Tests the detection of initial migrations being applied when they are the first migration.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Create the tables for the initial migration\n    executor.migrate([(\"migrations\", \"0001_initial\")])\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Check that the migration is detected as applied\n    migration = executor.loader.get_migration(\"migrations\", \"0001_initial\")\n    self.assertTrue(executor.detect_soft_applied(None, migration)[0])\n    # Fake-reverse the migration\n    executor.migrate([(\"migrations\", None)], fake=True)\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Check that the migration is still detected as applied\n    self.assertTrue(executor.detect_soft_applied(None, migration)[0])\n    # Migrate backwards\n    executor.migrate([(\"migrations\", None)])\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Check that the migration is no longer detected as applied\n    self.assertFalse(executor.detect_soft_applied(None, migration)[0])\n", "    def test_migration_plan_reorders_squashed_migration(self, mock_apply_migration, mock_unapply_migration, mock_record_migration):\n        \"\"\"\n        Regression test for #28459 - Squashed migrations are not reordered properly.\n        \"\"\"\n        executor = MigrationExecutor(connection)\n        # Make sure the squashed migration is in the plan\n        plan = executor.migration_plan([(\"migrations\", \"0001_squashed_0002\")])\n        self.assertEqual(len(plan), 1)\n        # Apply the migrations\n        executor.migrate([(\"migrations\", \"0001_squashed_0002\")])\n        # Rebuild the graph to reflect the new DB state\n        executor.loader.build_graph()\n        # Make sure the squashed migration is in the plan\n        plan = executor.migration_plan([(\"migrations\", None)])\n        self.assertEqual(len(plan), 1)\n        # Unapply the migrations\n        executor.migrate([(\"migrations\", None)])\n        # Rebuild the graph to reflect the new DB state\n        executor.loader.build_graph()\n        # Make sure the squashed migration is not in the plan\n        plan = executor.migration_plan([(\"migrations\", \"0001_squashed_0002\")])\n        self.assertEqual(len(plan), 1)\n        # Make sure the apply_migration and unapply_migration were called with the correct migrations\n        mock_apply_migration.assert_called_once_with(executor._create_project_state(with_applied_migrations=True), executor.loader.graph.nodes[\"migrations\", \"0001_squashed_0002\"], fake=False, fake_initial=False)\n        mock_unapply_migration.assert_called_once_with(executor._create_project_state(), executor.loader.graph.nodes[\"migrations\", \"0001_squashed_0002\"], fake=False)\n        # Make sure the record_migration was called with the correct migration\n        mock_record_migration.assert_called_once_with(executor.loader.graph.nodes[\"migrations\", \"0001_squashed_0002\"])\n", "def test_migrate_all_backwards(self):\n    \"\"\"\n    Test for migration all backwards.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    plan = executor.migration_plan([(\"migrations\", \"0002_second\")])\n    executor.migrate(None, plan)\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Migrate all backwards\n    plan = executor.migration_plan([(\"migrations\", None)])\n    executor.migrate(None, plan)\n    # Are the tables gone?\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_book\")\n"], "sample_75": ["def test_imagegrid_cbar_mode_each():\n    imdata = np.arange(100).reshape((10, 10))\n\n    fig = plt.figure(1, (4, 4))\n    grid = ImageGrid(fig, 111, nrows_ncols=(2, 2), axes_pad=(0.5, 0.3),\n                     cbar_mode=\"each\", cbar_location=\"right\", cbar_size=\"15%\",\n                     label_mode=\"all\")\n    for ax, cax in zip(grid, grid.cbar_axes):\n        im = ax.imshow(imdata, interpolation='none')\n        cax.colorbar(im)\n", "def test_grid_set_axes_pad():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 2))\n    axes_pad = (0.1, 0.2)\n    grid.set_axes_pad(axes_pad)\n    assert grid.get_axes_pad() == axes_pad\n\n    grid.set_axes_pad(0.3)\n    assert grid.get_axes_pad() == (0.3, 0.3)\n", "def test_imagegrid_cbar_mode_each(fig_test, fig_ref):\n    imdata = np.arange(100).reshape((10, 10))\n\n    grid_test = ImageGrid(fig_test, (1, 1, 1), nrows_ncols=(2, 2), \n                          axes_pad=(0.5, 0.3), cbar_mode=\"each\", \n                          cbar_location=\"right\", cbar_size=\"15%\")\n    grid_ref = ImageGrid(fig_ref, (1, 1, 1), nrows_ncols=(2, 2), \n                         axes_pad=(0.5, 0.3), cbar_mode=\"each\", \n                         cbar_location=\"right\", cbar_size=\"15%\")\n    \n    for ax, cax in zip(grid_test, grid_test.cbar_axes):\n        im = ax.imshow(imdata, interpolation='none')\n        cax.colorbar(im)\n    \n    for ax, cax in zip(grid_ref, grid_ref.cbar_axes):\n        im = ax.imshow(imdata, interpolation='none')\n        cax.colorbar(im)\n", "def test_image_grid_colorbar_orientation():\n    fig = plt.figure()\n    grid = ImageGrid(fig, 111, nrows_ncols=(1, 1),\n                     cbar_mode=\"single\", cbar_location=\"top\")\n\n    Z = 10000 * np.random.rand(10, 10)\n    im = grid[0].imshow(Z, interpolation=\"nearest\")\n\n    cbar = grid.cbar_axes[0].colorbar(im)\n    assert cbar.orientation == \"horizontal\"\n\n    grid = ImageGrid(fig, 111, nrows_ncols=(1, 1),\n                     cbar_mode=\"single\", cbar_location=\"right\")\n\n    im = grid[0].imshow(Z, interpolation=\"nearest\")\n\n    cbar = grid.cbar_axes[0].colorbar(im)\n    assert cbar.orientation == \"vertical\"\n", "def test_grid_label_mode():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 2), label_mode=\"L\")\n    assert np.all([ax.get_yticks() != [] for ax in grid.axes_column[0][:-1]])\n    assert np.all([ax.get_xticks() != [] for ax in grid.axes_row[-1]])\n    assert np.all([ax.get_xticks() == [] for ax in grid.axes_row[:-1]])\n    assert np.all([ax.get_yticks() == [] for ax in grid.axes_column[1:]])\n\n    grid = Grid(fig, 111, (2, 2), label_mode=\"1\")\n    assert np.all([ax.get_xticks() == [] for ax in grid.axes_all[1:]])\n    assert np.all([ax.get_yticks() == [] for ax in grid.axes_all[1:]])\n\n    grid = Grid(fig, 111, (2, 2), label_mode=\"all\")\n    assert np.all([ax.get_xticks() != [] for ax in grid.axes_all])\n    assert np.all([ax.get_yticks() != [] for ax in grid.axes_all])\n\n    grid = Grid(fig, 111, (2, 2), label_mode=\"keep\")\n    assert np.all([ax.get_xticks() != [] for ax in grid.axes_all])\n    assert np.all([ax.get_yticks() != [] for ax in grid.axes_all])\n"], "sample_147": ["def test_Lambda_kind():\n    x = Symbol('x')\n    assert Lambda(x, x).kind is NumberKind\n    assert Lambda(x, noncomm_x).kind is UndefinedKind\n", "def test_UndefinedFunction_kind():\n    f = Function('f')\n    assert f.kind is UndefinedKind\n    assert f(comm_x).kind is UndefinedKind\n    assert f(noncomm_x).kind is UndefinedKind\n", "def test_Lambda_kind():\n    x = Symbol('x')\n    y = Symbol('y', commutative=False)\n    assert Lambda(x, x).kind is NumberKind\n    assert Lambda(x, y).kind is UndefinedKind\n    assert Lambda((x, y), x*y).kind is UndefinedKind\n    assert Lambda(x, 2*x).kind is NumberKind\n    assert Lambda(x, 2*x*y).kind is UndefinedKind\n", "def test_Lambda_kind():\n    x = Symbol('x')\n    f = Symbol('f')\n    assert Lambda(x, x).kind is NumberKind\n    assert Lambda(x, f(x)).kind is UndefinedKind\n    assert Lambda(x, x**2 + 2*x + 1).kind is NumberKind\n    assert Lambda((x, f(x)), x*f(x)).kind is UndefinedKind\n", "def test_Derivative_kind_extension():\n    A = MatrixSymbol('A', 2,2)\n    B = MatrixSymbol('B', 2,2)\n    assert Derivative(A, comm_x, comm_x).kind is MatrixKind(NumberKind)\n    assert Derivative(A, B, comm_x).kind is MatrixKind(UndefinedKind)\n    assert Derivative(A, noncomm_x, comm_x).kind is MatrixKind(UndefinedKind)\n    assert Derivative(A, B, noncomm_x).kind is MatrixKind(UndefinedKind)\n"], "sample_115": ["def test__wrap_data_with_container():\n    \"\"\"Check _wrap_data_with_container works as expected.\"\"\"\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    original_input = np.asarray([[1, 0, 3], [0, 0, 1]])\n    est = EstimatorWithSetOutput().fit(X)\n\n    # default output\n    config = _get_output_config(\"transform\", est)\n    assert config[\"dense\"] == \"default\"\n    X_wrapped = _wrap_data_with_container(\"transform\", X, original_input, est)\n    assert isinstance(X_wrapped, np.ndarray)\n\n    # pandas output\n    _safe_set_output(est, transform=\"pandas\")\n    config = _get_output_config(\"transform\", est)\n    assert config[\"dense\"] == \"pandas\"\n    X_wrapped = _wrap_data_with_container(\"transform\", X, original_input, est)\n    pd = pytest.importorskip(\"pandas\")\n    assert isinstance(X_wrapped, pd.DataFrame)\n", "def test_set_output_mixin_multiple_inheritance():\n    \"\"\"Check that multiple inheritance does not shadow set_output.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    class Parent(_SetOutputMixin):\n            return X\n\n            return np.asarray([f\"X{i}\" for i in range(X.shape[1])], dtype=object)\n\n    class Child(Parent):\n            super().__init__()\n            self._sklearn_auto_wrap_output_keys = set()\n\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    est = Child()\n    assert hasattr(est, \"set_output\")\n\n    est.set_output(transform=\"pandas\")\n    X_trans_pd = est.transform(X)\n    assert isinstance(X_trans_pd, pd.DataFrame)\n", "def test__wrap_method_output():\n    \"\"\"Check _wrap_method_output works as expected.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    class EstimatorWithSetOutput(_SetOutputMixin):\n            self.n_features_in_ = X.shape[1]\n            return self\n\n            return X\n\n            return np.asarray([f\"X{i}\" for i in range(self.n_features_in_)], dtype=object)\n\n        return X\n\n    est = EstimatorWithSetOutput()\n    est.n_features_in_ = 3\n    wrapped_transform = _wrap_method_output(mock_transform, \"transform\")\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    X_transformed = wrapped_transform(est, X)\n    assert isinstance(X_transformed, pd.DataFrame)\n\n        return X, X\n\n    wrapped_transform_tuple = _wrap_method_output(mock_transform_tuple, \"transform\")\n    X_transformed_tuple = wrapped_transform_tuple(est, X)\n    assert isinstance(X_transformed_tuple[0], pd.DataFrame)\n    assert isinstance(X_transformed_tuple[1], np.ndarray)\n", "def test_wrap_data_with_container():\n    \"\"\"Check _wrap_data_with_container works as expected.\"\"\"\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    X_df = pd.DataFrame(X)\n\n    # Check that dense_config is \"default\" so no wrapping occurs\n    est = EstimatorWithSetOutput()\n    config = _get_output_config(\"transform\", est)\n    assert config[\"dense\"] == \"default\"\n    assert _wrap_data_with_container(\"transform\", X, X, est) is X\n    assert _wrap_data_with_container(\"transform\", X_df, X_df, est) is X_df\n\n    # Check that dense_config is \"pandas\" so wrapping occurs\n    est.set_output(transform=\"pandas\")\n    assert _wrap_data_with_container(\"transform\", X, X, est).equals(\n        pd.DataFrame(X, columns=est.get_feature_names_out())\n    )\n    assert _wrap_data_with_container(\"transform\", X_df, X_df, est).equals(\n        pd.DataFrame(X_df, columns=est.get_feature_names_out())\n    )\n\n    # Check that tuple input is wrapped\n    X_tuple = (X,)\n    X_df_tuple = (X_df,)\n    assert _wrap_data_with_container(\"transform\", X_tuple, X, est) == (\n        _wrap_in_pandas_container(\n            X,\n            columns=est.get_feature_names_out,\n            index=getattr(X, \"index\", None),\n        ),\n    )\n    assert _wrap_data_with_container(\"transform\", X_df_tuple, X_df, est) == (\n        _wrap_in_pandas_container(\n            X_df,\n            columns=est.get_feature_names_out,\n            index=getattr(X_df, \"index\", None),\n        ),\n    )\n\n    # Check that dense_config is not \"default\" or \"pandas\" so raises an error\n    est._sklearn_output_config[\"transform\"] = \"bad\"\n    with pytest.raises(ValueError, match=\"output config must be 'default' or 'pandas'\"):\n        _wrap_data_with_container(\"transform\", X, X, est)\n", "def test__wrap_data_with_container():\n    \"\"\"Check _wrap_data_with_container for wrapped and unwrapped output.\"\"\"\n\n    pd = pytest.importorskip(\"pandas\")\n\n    # Create an estimator with output config set to \"pandas\"\n    est = EstimatorWithSetOutput()\n    est.set_output(transform=\"pandas\")\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    X_trans_pd = est.transform(X)\n\n    assert isinstance(X_trans_pd, pd.DataFrame)\n\n    # Check wrapped output\n    wrapped_output = _wrap_data_with_container(\"transform\", X_trans_pd, X, est)\n    assert isinstance(wrapped_output, pd.DataFrame)\n    assert_array_equal(wrapped_output.columns, X_trans_pd.columns)\n\n    # Create an estimator with output config set to \"default\"\n    est.set_output(transform=\"default\")\n    X_trans_np = est.transform(X)\n\n    assert isinstance(X_trans_np, np.ndarray)\n\n    # Check unwrapped output\n    unwrapped_output = _wrap_data_with_container(\"transform\", X_trans_np, X, est)\n    assert isinstance(unwrapped_output, np.ndarray)\n    assert_array_equal(unwrapped_output, X_trans_np)\n\n    # Check that transform method not being a function does not wrap output\n    class EstimatorWithoutTransform(_SetOutputMixin):\n        pass\n\n    est = EstimatorWithoutTransform()\n    output = _wrap_data_with_container(\"transform\", X_trans_pd, X, est)\n    assert output is X_trans_pd\n\n    # Check that estimator without _sklearn_output_config attribute does not wrap\n    class EstimatorWithoutConfig(_SetOutputMixin):\n            return X\n\n    est = EstimatorWithoutConfig()\n    output = _wrap_data_with_container(\"transform\", X_trans_pd, X, est)\n    assert output is X_trans_pd\n"], "sample_126": ["def test_issue_10271():\n    assert Rational(1, 2) + S.Infinity == S.Infinity\n    assert Rational(1, 2) - S.Infinity == S.NegativeInfinity\n    assert Rational(1, 2) * S.Infinity == S.Infinity\n    assert Rational(1, 2) / S.Infinity == S.Zero\n    assert Rational(1, 2) + S.NegativeInfinity == S.NegativeInfinity\n    assert Rational(1, 2) - S.NegativeInfinity == S.Infinity\n    assert Rational(1, 2) * S.NegativeInfinity == S.NegativeInfinity\n    assert Rational(1, 2) / S.NegativeInfinity == S.Zero\n    assert S.Infinity + Rational(1, 2) == S.Infinity\n    assert S.Infinity - Rational(1, 2) == S.Infinity\n    assert S.Infinity * Rational(1, 2) == S.Infinity\n    assert S.Infinity / Rational(1, 2) == S.Infinity\n    assert S.NegativeInfinity + Rational(1, 2) == S.NegativeInfinity\n    assert S.NegativeInfinity - Rational(1, 2) == S.NegativeInfinity\n    assert S.NegativeInfinity * Rational(1, 2) == S.NegativeInfinity\n    assert S.NegativeInfinity / Rational(1, 2) == S.NegativeInfinity\n", "def test_content_primitive():\n    assert Rational(3, 4).as_content_primitive() == (Rational(3, 4), 1)\n    assert Rational(-3, 4).as_content_primitive() == (Rational(3, 4), -1)\n    assert Integer(3).as_content_primitive() == (3, 1)\n    assert Integer(-3).as_content_primitive() == (3, -1)\n    assert Float(3.4).as_content_primitive() == (1, 3.4)\n    assert Float(-3.4).as_content_primitive() == (3.4, -1)\n    assert pi.as_content_primitive() == (1, pi)\n    assert (2*pi).as_content_primitive() == (1, 2*pi)\n    assert (-2*pi).as_content_primitive() == (2*pi, -1)\n", "def test_issue_13952():\n    assert Rational(1) / Integer(0) == S.ComplexInfinity\n    assert Rational(1) / Rational(0) == S.ComplexInfinity\n    assert Integer(1) / Rational(0) == S.ComplexInfinity\n    assert Float(1.0) / Integer(0) == S.ComplexInfinity\n    assert Float(1.0) / Rational(0) == S.ComplexInfinity\n    assert Rational(1) / Float(0.0) == S.ComplexInfinity\n    assert Integer(1) / Float(0.0) == S.ComplexInfinity\n", "def test_issue_13171():\n    assert Rational('1.1').is_Float is True\n    assert Rational('1.0000000000001').is_Float is True\n    assert Rational('1.0000000000000000000000000001').is_Float is True\n    assert Rational('0.9999999999999999999999999999').is_Float is True\n    assert Rational('1.0').is_Float is True\n    assert Rational('1').is_Float is True\n", "def test_sympify_float_str():\n    assert sympify('1.0') == 1.0\n    assert sympify('1e1') == 10\n    assert sympify('.1') == 0.1\n    assert sympify('-.1') == -0.1\n    assert sympify('-.1e1') == -1.0\n    assert sympify('1e') == '1e'\n    assert sympify('1.2.3') == '1.2.3'\n    assert sympify('1.2a') == '1.2a'\n    assert sympify('1.2e') == '1.2e'\n    assert sympify('e1') == 'e1'\n"], "sample_138": ["def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n\n    real, imag = X.as_real_imag()\n    assert real.blocks[0, 0] == A.as_real_imag()[0]\n    assert real.blocks[0, 1] == B.as_real_imag()[0]\n    assert real.blocks[1, 0] == C.as_real_imag()[0]\n    assert real.blocks[1, 1] == D.as_real_imag()[0]\n    assert imag.blocks[0, 0] == A.as_real_imag()[1]\n    assert imag.blocks[0, 1] == B.as_real_imag()[1]\n    assert imag.blocks[1, 0] == C.as_real_imag()[1]\n    assert imag.blocks[1, 1] == D.as_real_imag()[1]\n\n    X = BlockMatrix([[A + 2*I, B + 2*I], [C + 2*I, D + 2*I]])\n    real, imag = X.as_real_imag()\n    assert real.blocks[0, 0] == A.as_real_imag()[0]\n    assert real.blocks[0, 1] == B.as_real_imag()[0]\n    assert real.blocks[1, 0] == C.as_real_imag()[0]\n    assert real.blocks[1, 1] == D.as_real_imag()[0]\n    assert imag.blocks[0, 0] == A.as_real_imag()[1] + 2\n    assert imag.blocks[0, 1] == B.as_real_imag()[1] + 2\n    assert imag.blocks[1, 0] == C.as_real_imag()[1] + 2\n    assert imag.blocks[1, 1] == D.as_real_imag()[1] + 2\n", "def test_block_collapse_as_real_imag():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n\n    expr = block_collapse(X.as_real_imag()[0] + X.as_real_imag()[1])\n    assert isinstance(expr, BlockMatrix)\n    assert expr.blocks.shape == (2, 2)\n", "def test_as_real_imag():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n\n    real_part, imag_part = X.as_real_imag()\n    assert isinstance(real_part, BlockMatrix)\n    assert isinstance(imag_part, BlockMatrix)\n    assert real_part.blocks == X.blocks\n    assert imag_part.blocks == [[ZeroMatrix(*i.shape) for i in row] for row in X.blocks]\n\n    real_part, imag_part = (A + 3*I).as_real_imag()\n    X = BlockMatrix([[A + 3*I, B], [C, D]])\n    real_part_X, imag_part_X = X.as_real_imag()\n    assert real_part_X.blocks[0, 0] == real_part\n    assert imag_part_X.blocks[0, 0] == imag_part\n", "def test_block_collapse_inverse():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n\n    # Check that the inverse of a 2x2 block matrix is correctly simplified\n    inv_X = X.inverse()\n    assert isinstance(inv_X, Inverse)\n    inv_X_expanded = block_collapse(inv_X)\n    assert inv_X_expanded.blocks.shape == (2, 2)\n\n    # Check that the inverse of a 2x2 block matrix with invertible A is correctly simplified\n    from sympy import assuming, Q\n    with assuming(Q.invertible(A)):\n        inv_X = X.inverse()\n        inv_X_expanded = block_collapse(inv_X)\n        assert inv_X_expanded.blocks[0, 0] == (A - B*D.I*C).I\n        assert inv_X_expanded.blocks[0, 1] == -(A - B*D.I*C).I*B*(D - C*A.I*B).I\n        assert inv_X_expanded.blocks[1, 0] == -(D - C*A.I*B).I*C*A.I\n        assert inv_X_expanded.blocks[1, 1] == (D - C*A.I*B).I\n\n    # Check that the inverse of a 2x2 block matrix with invertible D is correctly simplified\n    with assuming(Q.invertible(D)):\n        inv_X = X.inverse()\n        inv_X_expanded = block_collapse(inv_X)\n        assert inv_X_expanded.blocks[0, 0] == (A - B*D.I*C).I\n        assert inv_X_expanded.blocks[0, 1] == -A.I*B*D.I\n        assert inv_X_expanded.blocks[1, 0] == -(D - C*A.I*B).I*C*A.I\n        assert inv_X_expanded.blocks[1, 1] == (D - C*A.I*B).I\n", "def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n    real_X, imag_X = X.as_real_imag()\n    assert real_X.shape == X.shape\n    assert imag_X.shape == X.shape\n    assert real_X.blocks.shape == X.blocks.shape\n    assert imag_X.blocks.shape == X.blocks.shape\n\n    # Ensure that as_real_imag doesn't break known matrices\n    E = MatrixSymbol('E', n, n)\n    F = MatrixSymbol('F', n, n)\n    Y = BlockDiagMatrix(E, F)\n    real_Y, imag_Y = Y.as_real_imag()\n    assert real_Y.blocks[0, 0] == E\n    assert real_Y.blocks[1, 1] == F\n    assert imag_Y.blocks[0, 0] == ZeroMatrix(n, n)\n    assert imag_Y.blocks[1, 1] == ZeroMatrix(n, n)\n\n    # Ensure that as_real_imag doesn't break normal matrices\n    A = Matrix([[1, 2], [3, 4]])\n    real_A, imag_A = A.as_real_imag()\n    assert real_A == A\n    assert imag_A == ZeroMatrix(2, 2)\n"], "sample_117": ["def test_is_system_TypeVar():\n    T = TypeVar('T')\n    assert is_system_TypeVar(T) is True\n\n    class MyTypeVar(TypeVar):\n        pass\n\n    MT = MyTypeVar('MT')\n    assert is_system_TypeVar(MT) is False\n", "def test_is_system_TypeVar():\n    T = TypeVar('T')\n    T_co = TypeVar('T_co', covariant=True)\n    T_contra = TypeVar('T_contra', contravariant=True)\n    assert is_system_TypeVar(T)\n    assert is_system_TypeVar(T_co)\n    assert is_system_TypeVar(T_contra)\n    assert not is_system_TypeVar(int)\n    assert not is_system_TypeVar(str)\n", "def test_get_type_hints():\n        return True\n\n    assert get_type_hints(func) == {'a': int, 'b': str, 'return': bool}\n\n    class TestClass:\n            pass\n\n    assert get_type_hints(TestClass) == {'a': int, 'b': str, 'return': None}\n\n    class TestClassWithBrokenTypeHints:\n            pass\n\n    assert get_type_hints(TestClassWithBrokenTypeHints) == {}\n\n    class TestClassWithUnresolvableTypeHints:\n            pass\n\n    assert get_type_hints(TestClassWithUnresolvableTypeHints) == {}\n", "def test_get_type_hints():\n        pass\n\n    type_hints = get_type_hints(my_function)\n    assert type_hints == {'a': int, 'b': str, 'c': List[int], 'return': None}\n\n    class MyClass:\n            pass\n\n    type_hints = get_type_hints(MyClass().my_method)\n    assert type_hints == {'a': int, 'b': str, 'c': List[int], 'return': None}\n\n    # Test with broken class\n    class BrokenClass:\n        __annotations__ = {'a': int, 'b': str, 'c': List[int], 'return': None, 'foo': 1}\n\n    type_hints = get_type_hints(BrokenClass())\n    assert type_hints == {'a': int, 'b': str, 'c': List[int], 'return': None}\n\n    # Test with class that does not have __annotations__\n    class EmptyClass:\n        pass\n\n    type_hints = get_type_hints(EmptyClass())\n    assert type_hints == {}\n\n    # Test with function that does not have __annotations__\n        pass\n\n    type_hints = get_type_hints(empty_function)\n    assert type_hints == {}\n", "def test_get_type_hints():\n        pass\n\n    assert get_type_hints(func) == {'a': int, 'b': str, 'return': None}\n\n    class Class:\n            pass\n\n    assert get_type_hints(Class.__init__) == {'a': int, 'b': str, 'return': None}\n\n    # Test case when ForwardRef raises a NameError\n    try:\n        from typing import ForwardRef\n        ref = ForwardRef('NonExistentType')\n        get_type_hints(ref)\n    except NameError:\n        assert True\n    else:\n        assert False\n\n    # Test case when a broken class is encountered\n    class BrokenClass:\n            pass\n\n    BrokenClass.__annotations__ = {'a': int, 'b': str, 'return': None, 'non_existent_arg': int}\n\n    assert get_type_hints(BrokenClass.__init__) == {}\n\n    # Test case when a class with no annotations is encountered\n    class EmptyClass:\n            pass\n\n    EmptyClass.__annotations__ = {}\n\n    assert get_type_hints(EmptyClass.__init__) == {}\n"], "sample_63": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = \"\"\n        self.assertHTMLEqual(\n            widget.render(\"name\", value, {\"id\": \"id_password\"}),\n            '<div id=\"id_password\">'\n            \"<strong>%(label)s</strong>: %(value)s\"\n            \"</div>\" % {\"label\": _(\"No password set.\"), \"value\": \"\"},\n        )\n", "    def test_render_unicode(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = (\n            \"pbkdf2_sha256$100000$\u03b56Pucb1qSFcD$WmCkn9Hqidj48NVe5x0FEM6A9YiOqQcl/83m2Z5u\"\n            \"dm0=\"\n        )\n        self.assertHTMLEqual(\n            widget.render(\"name\", value, {\"id\": \"id_password\"}),\n            '<div id=\"id_password\">'\n            \"    <strong>algorithm</strong>: <bdi>pbkdf2_sha256</bdi>\"\n            \"    <strong>iterations</strong>: <bdi>100000</bdi>\"\n            \"    <strong>salt</strong>: <bdi>\u03b56Pucb******</bdi>\"\n            \"    <strong>hash</strong>: \"\n            \"       <bdi>WmCkn9**************************************</bdi>\"\n            \"</div>\",\n        )\n", "    def test_get_users_case_insensitive(self):\n        user = User.objects.create_user(\n            username=\"testclient\", password=\"password\", email=\"TesT@eXaMpLe.com\"\n        )\n        form = PasswordResetForm({\"email\": \"test@example.com\"})\n        self.assertFalse(form.is_valid())\n        form = PasswordResetForm({\"email\": \"TesT@eXaMpLe.com\"})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(len(form.get_users(form.cleaned_data[\"email\"])), 1)\n", "    def test_render_without_value(self):\n        widget = ReadOnlyPasswordHashWidget()\n        html = widget.render(\"password\", None, {})\n        self.assertHTMLEqual(html, '<div></div>')\n", "    def test_email_case_insensitivity(self):\n        \"\"\"\n        Ensure that the PasswordResetForm is case insensitive when matching emails.\n        \"\"\"\n        user = User.objects.create_user(\"testuser\", \"TeSt@example.com\", \"test\")\n        data = {\"email\": \"tEsT@example.com\"}\n        form = PasswordResetForm(data)\n        self.assertTrue(form.is_valid())\n        form.save()\n        self.assertEqual(len(mail.outbox), 1)\n        self.assertEqual(mail.outbox[0].to, [\"TeSt@example.com\"])\n"], "sample_31": ["def test_shell_no_interface_found(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import python interface.\"):\n        call_command('shell')\n", "    def test_shell_with_all_interfaces_not_installed(self, select):\n        select.return_value = ([], [], [])\n        with self.assertRaisesMessage(CommandError, \"Couldn't import python interface.\"):\n            call_command('shell', interface='python')\n", "def test_shell_with_bpython_not_installed(self, select):\n    select.return_value = ([], [], [])\n    with mock.patch.dict('sys.modules', {'bpython': None}):\n        with self.assertRaisesMessage(CommandError, \"Couldn't import bpython interface.\"):\n            call_command('shell', interface='bpython')\n", "    def test_shell_with_interface_option(self):\n        for interface in self.shells:\n            with self.subTest(interface=interface):\n                with captured_stdout() as stdout:\n                    call_command('shell', interface=interface)\n                self.assertIn(interface, stdout.getvalue())\n", "def test_shell_with_no_interface_installed(self):\n    with self.assertRaisesMessage(CommandError, \"Couldn't import python interface.\"):\n        call_command('shell', interface='python')\n"], "sample_81": ["    def test_fixme_with_pragma(self) -> None:\n        code = \"\"\"a = 1\n                # pylint: disable=fixme\n                # FIXME message\n                \"\"\"\n        with self.assertNoMessages():\n            self.checker.process_tokens(_tokenize_str(code))\n", "    def test_notes_and_notes_rgx(self) -> None:\n        code = \"\"\"a = 1\n                # FIXME message\n                # BUG message\n                \"\"\"\n        with self.assertAddsMessages(\n            MessageTest(msg_id=\"fixme\", line=2, args=\"FIXME message\", col_offset=17),\n            MessageTest(msg_id=\"fixme\", line=3, args=\"BUG message\", col_offset=17),\n        ):\n            self.checker.process_tokens(_tokenize_str(code))\n", "    def test_notes_and_notes_rgx(self) -> None:\n        code = \"\"\"a = 1\n                # TODO message\n                # FIXME message\n                # XXX\n                # XXXX\n                \"\"\"\n        with self.assertAddsMessages(\n            MessageTest(msg_id=\"fixme\", line=2, args=\"TODO message\", col_offset=17),\n            MessageTest(msg_id=\"fixme\", line=3, args=\"FIXME message\", col_offset=17),\n            MessageTest(msg_id=\"fixme\", line=4, args=\"XXX\", col_offset=17),\n        ):\n            self.checker.process_tokens(_tokenize_str(code))\n", "    def test_notes_regex(self) -> None:\n        code = \"\"\"a = 1\n                # custom_tag: message\n                \"\"\"\n        with self.assertNoMessages():\n            self.checker.process_tokens(_tokenize_str(code))\n        \n        set_config(notes_rgx=\"custom_tag:\")\n        with self.assertAddsMessages(\n            MessageTest(msg_id=\"fixme\", line=2, args=\"custom_tag: message\", col_offset=17)\n        ):\n            self.checker.process_tokens(_tokenize_str(code))\n", "def test_encoding_problem(self) -> None:\n    code = b\"# -*- coding: utf-8 -*-\\n\\na = 1\\nb = \\xc3\\xa9\"\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"syntax-error\", line=3, args=\"Cannot decode using encoding 'utf-8', bad encoding\")\n    ):\n        with open(\"test_encoding_problem.py\", \"wb\") as file:\n            file.write(code)\n        self.checker.process_module(self.astroid_module_from_file(\"test_encoding_problem.py\"))\n"], "sample_114": ["def test_ovr_decision_function():\n    n_samples, n_classes = 5, 4\n    predictions = np.random.randint(0, 2, size=(n_samples, n_classes * (n_classes - 1) // 2))\n    confidences = np.random.rand(n_samples, n_classes * (n_classes - 1) // 2)\n\n    decision_function = _ovr_decision_function(predictions, confidences, n_classes)\n\n    assert decision_function.shape == (n_samples, n_classes)\n\n    # Test that the decision function sums to zero for each sample\n    assert_allclose(decision_function.sum(axis=1), np.zeros(n_samples))\n\n    # Test that the decision function is invariant to the order of the classes\n    permuted_predictions = predictions[:, ::-1]\n    permuted_confidences = confidences[:, ::-1]\n    permuted_decision_function = _ovr_decision_function(\n        permuted_predictions, permuted_confidences, n_classes\n    )\n    assert_allclose(permuted_decision_function[:, ::-1], decision_function)\n", "def test_ovr_decision_function():\n    # Test the decision function with OvR\n    predictions = np.array([[0, 1, 0], [1, 0, 0], [0, 0, 1]])\n    confidences = np.array([[0.8, 0.9, 0.7], [0.9, 0.8, 0.6], [0.7, 0.6, 0.8]])\n    n_classes = 3\n    decision_function = _ovr_decision_function(predictions, confidences, n_classes)\n    expected_decision_function = np.array([[0.26666667, -0.46666667, 0.2], \n                                          [-0.46666667, 0.26666667, 0.2], \n                                          [0.2, 0.2, 0.6]])\n    assert_allclose(decision_function, expected_decision_function)\n", "def test_ovr_decision_function():\n    # Define the predictions and confidences\n    predictions = np.array([[0, 1, 1], [1, 1, 0], [1, 0, 1]])\n    confidences = np.array([[0.1, 0.9, 0.5], [0.8, 0.2, 0.3], [0.7, 0.4, 0.6]])\n    n_classes = 3\n\n    # Compute the decision function\n    decision_function = _ovr_decision_function(predictions, confidences, n_classes)\n\n    # Define the expected decision function\n    expected_decision_function = np.array(\n        [[-1.06666667, 0.33333333, 0.73333333], \n         [0.73333333, -1.06666667, 0.33333333], \n         [0.33333333, 0.73333333, -1.06666667]]\n    )\n\n    # Check if the computed decision function is close to the expected decision function\n    assert_allclose(decision_function, expected_decision_function, atol=1e-6)\n", "def test_ovr_decision_function():\n    # Test OvR decision function computation\n    predictions = np.array([[0, 1, 1], [1, 0, 1]])\n    confidences = np.array([[0.5, 0.6, 0.7], [0.4, 0.3, 0.2]])\n    n_classes = 3\n    expected_output = np.array([[0.36666667, -0.13333333, 0.76666667], [-0.1, 0.63333333, -0.53333333]])\n    assert_allclose(_ovr_decision_function(predictions, confidences, n_classes), expected_output)\n\n    # Test OvR decision function with more classes\n    predictions = np.array([[0, 1, 1, 1], [1, 0, 1, 1]])\n    confidences = np.array([[0.5, 0.6, 0.7, 0.8], [0.4, 0.3, 0.2, 0.1]])\n    n_classes = 4\n    expected_output = np.array([[-0.43333333, 0.23333333, 0.46666667, 1.63333333], [0.5, -0.63333333, -0.43333333, 0.56666667]])\n    assert_allclose(_ovr_decision_function(predictions, confidences, n_classes), expected_output)\n\n    # Test OvR decision function with wrong shape of predictions\n    predictions = np.array([[0, 1], [1, 0]])\n    confidences = np.array([[0.5, 0.6], [0.4, 0.3]])\n    n_classes = 4\n    with pytest.raises(ValueError):\n        _ovr_decision_function(predictions, confidences, n_classes)\n\n    # Test OvR decision function with wrong shape of confidences\n    predictions = np.array([[0, 1, 1], [1, 0, 1]])\n    confidences = np.array([[0.5, 0.6], [0.4, 0.3]])\n    n_classes = 3\n    with pytest.raises(ValueError):\n        _ovr_decision_function(predictions, confidences, n_classes)\n", "def test_ovr_decision_function():\n    # Test OvR decision function with binary and multiclass examples\n    predictions_binary = np.array([[0, 1], [1, 0]])\n    confidences_binary = np.array([[0.8, 0.2], [0.4, 0.6]])\n    assert_array_almost_equal(\n        _ovr_decision_function(predictions_binary, confidences_binary, 2),\n        np.array([[0.93333333, -0.46666667], [-0.06666667, 1.03333333]]),\n    )\n\n    predictions_multiclass = np.array([[0, 1, 2], [1, 2, 0]])\n    confidences_multiclass = np.array([[0.8, 0.1, 0.1], [0.1, 0.8, 0.1]])\n    assert_array_almost_equal(\n        _ovr_decision_function(predictions_multiclass, confidences_multiclass, 3),\n        np.array(\n            [\n                [\n                    0.93333333,\n                    -0.06666667,\n                    -0.06666667,\n                ],\n                [-0.06666667, 0.93333333, -0.06666667],\n            ]\n        ),\n    )\n\n    # Test OvR decision function with invalid input\n    predictions_invalid = np.array([[0, 1, 2, 3], [1, 2, 0, 1]])\n    confidences_invalid = np.array([[0.8, 0.1, 0.1, 0.0], [0.1, 0.8, 0.1, 0.0]])\n    with pytest.raises(ValueError):\n        _ovr_decision_function(predictions_invalid, confidences_invalid, 3)\n\n    # Test OvR decision function with different shapes\n    predictions_shape_error = np.array([[0, 1], [1, 2], [1]])\n    confidences_shape_error = np.array([[0.8, 0.2], [0.4, 0.6], [0.5]])\n    with pytest.raises(ValueError):\n        _ovr_decision_function(predictions_shape_error, confidences_shape_error, 2)\n"], "sample_130": ["def test_lambdify_empty_matrix():\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    M = Matrix(0, 0, [])\n    f = lambdify([], M)\n    assert f() == M\n", "def test_lambdify_non_callable_expression():\n    raises(TypeError, lambda: lambdify(x, 1, \"sympy\"))\n    raises(TypeError, lambda: lambdify(x, \"1\", \"sympy\"))\n    raises(TypeError, lambda: lambdify(x, [1, 2], \"sympy\"))\n    raises(TypeError, lambda: lambdify(x, (1, 2), \"sympy\"))\n    raises(TypeError, lambda: lambdify(x, {\"a\": 1}, \"sympy\"))\n", "def test_lambdify_non_list_arg():\n    f = lambdify((x, (y, z)), x + y + z, dummify=True)\n    assert f(1, (2, 3)) == 6\n    assert f(1, (2.0, 3.0)) == 6.0\n", "def test_dummify_nonstr_args():\n    f = implemented_function('f', lambda x: x + 1)\n    expr = f(x)\n    raises(SyntaxError, lambda: lambdify(expr, expr))\n", "def test_non_symbol_args():\n    f = lambdify(x, x**2)\n    raises(TypeError, lambda: f([2]))  # test list argument\n    raises(TypeError, lambda: f({}))  # test dict argument\n    raises(TypeError, lambda: f({1: 2}))  # test dict with integer key\n    raises(TypeError, lambda: f({1.0: 2}))  # test dict with float key\n    raises(TypeError, lambda: f({x: 2}))  # test dict with symbol key\n    raises(TypeError, lambda: f({x**2: 2}))  # test dict with expression key\n    raises(TypeError, lambda: f((1,2)))  # test tuple argument\n    raises(TypeError, lambda: f((1,2,3)))  # test tuple with multiple elements\n    raises(TypeError, lambda: f([1,2,3]))  # test list with multiple elements\n"], "sample_131": ["def test_Sum():\n    assert mcode(Sum(sin(x), (x, 1, 10))) == \"Hold[Sum[Sin[x], {x, 1, 10}]]\"\n    assert mcode(Sum(sin(x)*y**4, (x, 1, 10), (y, 2, 5))) == \\\n        \"Hold[Sum[y^4*Sin[x], {x, 1, 10}, {y, 2, 5}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]]\"\n    assert mcode(Sum(x**2*y**2, (x, 1, 10), (y, 1, 10))) == \\\n        \"Hold[Sum[x^2*y^2, {x, 1, 10}, {y, 1, 10}]]\"\n    assert mcode(Sum(x**2, (x, 1, 10, 2))) == \"Hold[Sum[x^2, {x, 1, 10, 2}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**2, (x, 0, 10))) == \"Hold[Sum[x^2, {x, 0, 10}]]\"\n    assert mcode(Sum(x*y**2, (x, 0, 10), (y, 0, 10))) == \\\n        \"Hold[Sum[x*y^2, {x, 0, 10}, {y, 0, 10}]]\"\n    assert mcode(Sum(x**2, (x, 0, 10), (y, 0, 10))) == \\\n        \"Hold[Sum[x^2, {x, 0, 10}, {y, 0, 10}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]]\"\n    assert mcode(Sum(x**2, (x, 1, 10), (y, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}, {y, 1, 10}]]\"\n    assert mcode(Sum(x**2 + y**2, (x, 1, 10), (y, 1, 10))) == \\\n        \"Hold[Sum[x^2 + y^2, {x, 1, 10}, {y, 1, 10}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]]\"\n    assert mcode(Sum(x, (x, 0, oo))) == \"Hold[Sum[x, {x, 0, Infinity}]]\"\n    assert mcode(Sum(x**y, (x, 1, 10), (y, 1, 10))) == \"Hold[Sum[x^y, {x, 1, 10}, {y, 1, 10}]]\"\n    assert mcode(Sum(x, (x, 1, 10), (y, 1, 10))) == \"Hold[Sum[x, {x, 1, 10}, {y, 1, 10}]]\"\n    assert mcode(Sum(x + y, (x, 1, 10), (y, 1, 10))) == \"Hold[Sum[x + y, {x, 1, 10}, {y, 1, 10}]]\"\n"], "sample_32": ["    def test_function_expression(self):\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.annotate(\n                upper=F('value__k__l').upper(),\n            ).filter(upper='M'),\n            [self.objs[4]],\n        )\n", "    def test_deep_nested_key_transform(self):\n        # Create a deeply nested object\n        nested_obj = {\n            'a': {\n                'b': {\n                    'c': {\n                        'd': {\n                            'e': {\n                                'f': 'g'\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        NullableJSONModel.objects.create(value=nested_obj)\n        # Test deeply nested key transform\n        qs = NullableJSONModel.objects.filter(value__a__b__c__d__e__f='g')\n        self.assertSequenceEqual(qs, [NullableJSONModel.objects.get()])\n        # Test deeply nested key transform with key transform\n        qs = NullableJSONModel.objects.filter(value__a__b__c__d__has_key='e')\n        self.assertSequenceEqual(qs, [NullableJSONModel.objects.get()])\n", "    def setUp(self):\n        self.objs = [\n            NullableJSONModel.objects.create(value={'a': 1, 'b': 2, 'c': 3}),\n            NullableJSONModel.objects.create(value={'a': 2.5, 'b': 3.5, 'c': 4.5}),\n            NullableJSONModel.objects.create(value={'a': '1', 'b': '2', 'c': '3'}),\n        ]\n", "    def setUp(self):\n        self.obj = NullableJSONModel.objects.create(value={'key%with%special%chars': 'value'})\n", "    def test_nested_key_transform_with_subquery(self):\n        subquery = NullableJSONModel.objects.filter(value__d__0='e').values('value__d')\n        qs = NullableJSONModel.objects.annotate(d=Subquery(subquery)).filter(d__1__f='g')\n        self.assertSequenceEqual(qs, [self.objs[4]])\n"], "sample_128": ["def test_Allowed_Flags():\n    assert allowed_flags({'domain': ZZ}, []) == None\n\n    raises(FlagError, lambda: allowed_flags({'domain': ZZ, 'frac': True}, []))\n\n    allowed_flags({'domain': ZZ, 'frac': True}, ['frac'])\n", "def test_Options_init():\n    opt = Options((x, y), {'domain': 'ZZ'})\n\n    assert opt.gens == (x, y)\n    assert opt.domain == ZZ\n\n    opt = Options((x, y), {'domain': 'ZZ', 'order': 'lex'})\n\n    assert opt.gens == (x, y)\n    assert opt.domain == ZZ\n    assert opt.order == lex\n\n    raises(OptionError, lambda: Options((x, y), {'gens': (x, y), 'domain': 'ZZ'}))\n    raises(OptionError, lambda: Options((x, y), {'gens': (x, x), 'domain': 'ZZ'}))\n    raises(GeneratorsError, lambda: Options((x, y), {'gens': (x, z), 'domain': 'ZZ[z]'}))\n    raises(GeneratorsError, lambda: Options((), {'domain': 'EX'}))\n", "def test_Options_init():\n    opt = Options((x, y, z), {'domain': 'ZZ'})\n\n    assert opt.args == {'domain': ZZ}\n    assert opt.options == {'domain': ZZ}\n    assert opt.flags == {}\n\n    opt = Options((x, y, z), {'domain': 'ZZ', 'auto': False})\n\n    assert opt.args == {'domain': ZZ}\n    assert opt.options == {'domain': ZZ}\n    assert opt.flags == {'auto': False}\n\n    raises(OptionError, lambda: Options((x, y, z), {'gens': (x, y, z)}))\n    raises(OptionError, lambda: Options((x, y, z), {'domain': 'abc'}))\n    raises(GeneratorsError, lambda: Options((x, x, y), {'domain': 'ZZ'}))\n\n    raises(FlagError, lambda: Options((x, y, z), {'frac': True}, ['polys']))\n", "def test_Options_init():\n    opt = Options((x, y, z), {'domain': 'ZZ'})\n\n    assert opt['gens'] == (x, y, z)\n    assert opt['domain'] == ZZ\n    assert opt['order'] == lex\n    assert 'auto' not in opt\n\n    opt = Options((x, y, z), {'domain': 'ZZ', 'auto': True})\n\n    assert opt['gens'] == (x, y, z)\n    assert opt['domain'] == ZZ\n    assert opt['order'] == lex\n    assert opt['auto'] == False\n\n    raises(OptionError, lambda: Options((x, y, z), {'gens': (x, y, z)}))\n\n    raises(GeneratorsError, lambda: Options((x, x, y), {'domain': 'ZZ'}))\n\n    raises(GeneratorsError, lambda: Options((x, y, z), {'domain': 'ZZ[x, z]'}))\n\n    raises(GeneratorsError, lambda: Options((), {'domain': 'EX'}))\n", "def test_Options_init():\n    opt = Options((x, y, z), {'domain': 'ZZ'})\n\n    assert opt.gens == (x, y, z)\n    assert opt.domain == ZZ\n\n    raises(OptionError, lambda: Options((x, y, z), {'gens': (x, y, z), 'domain': 'ZZ'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'gens': (x, y, x)}))\n\n    raises(GeneratorsError, lambda: Options((x, y, z), {'gens': (x, y, x)}))\n\n    opt = Options((x, y, z), {'gens': (x, y), 'order': 'lex', 'domain': 'ZZ'})\n\n    assert opt.gens == (x, y)\n    assert opt.domain == ZZ\n    assert opt.order == lex\n\n    opt = Options((x, y, z), {'gens': (x, y), 'order': 'lex'}, strict=False)\n\n    assert opt.gens == (x, y)\n    assert opt.domain == ZZ\n    assert opt.order == lex\n\n    raises(OptionError, lambda: Options((x, y, z), {'gens': (x, y), 'order': 'lex'}, strict=True))\n\n    raises(OptionError, lambda: Options((x, y, z), {'gens': (x, y), 'order': 'lex', 'unknown': 'option'}))\n"], "sample_144": ["def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 1], Q.symmetric(X)) == X[1, 1]\n    assert refine(X[0, 0], Q.symmetric(X)) == X[0, 0]\n", "def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 1], Q.symmetric(X)) == X[1, 1]\n    assert refine(X[0, 2], Q.symmetric(X)) == X[0, 2]\n    assert refine(X[2, 0], Q.symmetric(X)) == X[0, 2]\n", "def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 1], Q.symmetric(X)) == X[1, 1]\n    assert refine(X[0, 1], ~Q.symmetric(X)) == X[0, 1]\n", "def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[0, 0], Q.symmetric(X)) == X[0, 0]\n    assert refine(X[1, 1], Q.symmetric(X)) == X[1, 1]\n    assert refine(X[0, 2], Q.symmetric(X)) == X[0, 2]\n    assert refine(X[2, 0], Q.symmetric(X)) == X[0, 2]\n", "def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[0, 1], ~Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], ~Q.symmetric(X)) == X[1, 0]\n    assert refine(X[0, 0], Q.symmetric(X)) == X[0, 0]\n    assert refine(X[0, 0], ~Q.symmetric(X)) == X[0, 0]\n"], "sample_35": ["    def test_modelmultiplechoicefield(self):\n        # Create choices for the model multiple choice field tests below.\n        ChoiceModel.objects.create(pk=1, name='a')\n        ChoiceModel.objects.create(pk=2, name='b')\n        ChoiceModel.objects.create(pk=3, name='c')\n\n        # ModelMultipleChoiceField\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': '%(value)s IS INVALID CHOICE',\n            'invalid_list': 'NOT A LIST OF VALUES',\n            'invalid_pk_value': '%(pk)s IS NOT A VALID VALUE.',\n        }\n        f = ModelMultipleChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['NOT A LIST OF VALUES'], f.clean, '3')\n        self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, ['4'])\n        self.assertFormErrors(['\"abc\" IS NOT A VALID VALUE.'], f.clean, ['abc'])\n", "    def test_model_to_dict(self):\n        from ..models import Author\n\n        author = Author.objects.create(name='John', email='john@example.com')\n        expected_data = {'name': 'John', 'email': 'john@example.com'}\n        self.assertEqual(model_to_dict(author), expected_data)\n\n        expected_data_fields = {'name': 'John'}\n        self.assertEqual(model_to_dict(author, fields=['name']), expected_data_fields)\n\n        expected_data_exclude = {'email': 'john@example.com'}\n        self.assertEqual(model_to_dict(author, exclude=['name']), expected_data_exclude)\n", "    def test_modelform(self):\n        # Create a ChoiceModel instance for the model form tests below.\n        ChoiceModel.objects.create(pk=1, name='a')\n\n        # ModelForm\n        from .models import ChoiceModel\n        from ..forms import ModelForm\n\n        class ChoiceModelForm(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = ('name',)\n\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'invalid_choice': 'INVALID CHOICE',\n        }\n        form = ChoiceModelForm({}, error_messages=e)\n        self.assertFormErrors(['REQUIRED'], form.is_valid)\n\n        form = ChoiceModelForm({'name': 'a'}, error_messages=e)\n        self.assertTrue(form.is_valid())\n\n        form = ChoiceModelForm({'name': 'b'}, error_messages=e)\n        self.assertFormErrors(['INVALID_CHOICE'], form.is_valid)\n\n        class ChoiceModelForm(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = ('name',)\n\n                raise ValidationError('INVALID FIELD')\n\n        form = ChoiceModelForm({'name': 'a'}, error_messages=e)\n        self.assertFormErrors(['INVALID FIELD'], form.is_valid)\n", "    def test_construct_instance(self):\n        from ..models import Book\n        book = Book(title='Test book', pages=123)\n        form = ModelForm(instance=book)\n        instance = construct_instance(form, book)\n        self.assertEqual(instance.title, 'Test book')\n        self.assertEqual(instance.pages, 123)\n", "    def test_model_form_clean_method(self):\n        from ..models import Author\n\n        class TestForm(ModelForm):\n            class Meta:\n                model = Author\n                fields = ('name', 'age')\n\n        form = TestForm({'name': 'John Doe', 'age': 25})\n        self.assertTrue(form.is_valid())\n\n        # Test form validation\n        form = TestForm({'name': '', 'age': 25})\n        self.assertFalse(form.is_valid())\n        self.assertIn('name', form.errors)\n\n        # Test model instance validation\n        form = TestForm({'name': 'John Doe', 'age': -1})\n        self.assertFalse(form.is_valid())\n        self.assertIn('age', form.errors)\n"], "sample_61": ["    def test_invalid_input(self):\n        with self.assertRaises(TypeError):\n            nformat(None, \".\")\n        with self.assertRaises(TypeError):\n            nformat(\"abc\", \".\")\n        with self.assertRaises(TypeError):\n            nformat(object(), \".\")\n", "    def test_decimal_subclass_formatting(self):\n        ed = EuroDecimal(\"1234.56\")\n        self.assertEqual(nformat(ed, \".\"), \"\u20ac 1234.56\")\n        self.assertEqual(nformat(ed, \".\", decimal_pos=2), \"\u20ac 1234.56\")\n        self.assertEqual(nformat(ed, \".\", decimal_pos=3), \"\u20ac 1234.560\")\n        self.assertEqual(nformat(ed, \".\", grouping=3, thousand_sep=\",\"), \"\u20ac 1,234.56\")\n        self.assertEqual(\n            nformat(ed, \".\", decimal_pos=2, grouping=3, thousand_sep=\",\"), \"\u20ac 1,234.56\"\n        )\n", "def test_format_none(self):\n    self.assertEqual(nformat(None, \".\"), None)\n", "def test_edge_cases(self):\n    # Test None input\n    self.assertEqual(nformat(None, \".\"), mark_safe(None))\n\n    # Test empty string input\n    self.assertEqual(nformat(\"\", \".\"), mark_safe(\"\"))\n\n    # Test very small Decimal numbers\n    self.assertEqual(nformat(Decimal(\"1e-9999\"), \".\"), \"0\")\n\n    # Test very large Decimal numbers\n    self.assertEqual(nformat(Decimal(\"1e9999\"), \".\"), \"9e+9999\")\n\n    # Test Decimal numbers with a lot of decimal places\n    self.assertEqual(nformat(Decimal(\"0.\" + \"1\" * 1000), \".\"), \"0.1\")\n\n    # Test float numbers with a lot of decimal places\n    self.assertEqual(nformat(0.1 + 0.2, \".\", decimal_pos=10), \"0.3000000001\")\n", "def test_edge_cases(self):\n    # Test with None as input\n    self.assertEqual(nformat(None, \".\"), None)\n\n    # Test with an empty string as input\n    self.assertEqual(nformat(\"\", \".\"), \"\")\n\n    # Test with a non-numeric string as input\n    self.assertEqual(nformat(\"abc\", \".\"), \"abc\")\n\n    # Test with a negative number and decimal_pos=0\n    self.assertEqual(nformat(-123.45, \".\", decimal_pos=0), \"-123\")\n\n    # Test with a non-integer grouping value\n    with self.assertRaises(TypeError):\n        nformat(1234, \".\", grouping=2.5, thousand_sep=\",\")\n\n    # Test with a negative grouping value\n    with self.assertRaises(ValueError):\n        nformat(1234, \".\", grouping=-1, thousand_sep=\",\")\n\n    # Test with a non-string decimal_sep value\n    with self.assertRaises(TypeError):\n        nformat(1234, 1)\n\n    # Test with a non-string thousand_sep value\n    with self.assertRaises(TypeError):\n        nformat(1234, \".\", thousand_sep=1)\n\n    # Test with a non-integer decimal_pos value\n    with self.assertRaises(ValueError):\n        nformat(1234, \".\", decimal_pos=\"abc\")\n\n    # Test with a negative decimal_pos value\n    with self.assertRaises(ValueError):\n        nformat(1234, \".\", decimal_pos=-1)\n\n    # Test with a non-boolean force_grouping value\n    with self.assertRaises(TypeError):\n        nformat(1234, \".\", force_grouping=\"abc\")\n\n    # Test with a non-boolean use_l10n value\n    with self.assertRaises(TypeError):\n        nformat(1234, \".\", use_l10n=\"abc\")\n"], "sample_108": ["def test_invalid_gamma_value():\n    # Test that an invalid gamma value raises an error\n    clf = svm.SVC(gamma=-1)\n    with pytest.raises(ValueError, match=\"The gamma value of -1.0 is invalid.\"):\n        clf.fit(X, Y)\n", "def test_base_libsvm_gamma():\n    # Test that BaseLibSVM handles gamma correctly\n    clf = svm.SVC(kernel='linear', gamma='auto')\n    clf.fit(X, Y)\n    assert clf._gamma == 1.0 / X.shape[1]\n\n    clf = svm.SVC(kernel='linear', gamma='scale')\n    clf.fit(X, Y)\n    X_var = np.var(X, axis=0).mean()\n    assert clf._gamma == 1.0 / (X.shape[1] * X_var)\n\n    clf = svm.SVC(kernel='linear', gamma='auto')\n    clf.fit(sparse.csr_matrix(X), Y)\n    X_var = ((sparse.csr_matrix(X).multiply(sparse.csr_matrix(X)).mean() -\n              sparse.csr_matrix(X).mean() ** 2))\n    assert clf._gamma == 1.0 / (X.shape[1] * X_var)\n\n    clf = svm.SVC(kernel='linear', gamma='scale')\n    clf.fit(sparse.csr_matrix(X), Y)\n    X_var = ((sparse.csr_matrix(X).multiply(sparse.csr_matrix(X)).mean() -\n              sparse.csr_matrix(X).mean() ** 2))\n    assert clf._gamma == 1.0 / (X.shape[1] * X_var)\n", "def test_sparse_kernel_matrix():\n    # Test that a sparse kernel matrix passed to a SVC with precomputed\n    # kernel raises an error\n    X = np.random.RandomState(0).randn(10, 3)\n    y = np.random.RandomState(1).randn(10)\n\n    X_sparse = sparse.csr_matrix(rbf_kernel(X))\n    clf = svm.SVC(kernel='precomputed')\n    with pytest.raises(TypeError, match=\"Sparse precomputed kernels are not supported\"):\n        clf.fit(X_sparse, y)\n\n    # But a dense kernel matrix should be fine\n    clf.fit(rbf_kernel(X), y)\n", "def test_sparse_svm():\n    # Test sparse input with sparse libsvm\n    X = np.array([[0, 0, 1, 0],\n                  [1, 0, 0, 0],\n                  [0, 1, 0, 0],\n                  [0, 0, 0, 1]])\n    y = np.array([1, 1, 1, -1])\n\n    for clf in (svm.SVC(kernel='linear'), svm.SVR(kernel='linear'),\n                svm.LinearSVC(), svm.LinearSVR()):\n        clf.fit(X, y)\n        pred = clf.predict(X)\n        assert_array_equal(pred, y)\n\n    # Test sparse input with dense libsvm\n    X_sparse = sparse.csr_matrix(X)\n    y = np.array([1, 1, 1, -1])\n\n    for clf in (svm.SVC(kernel='linear'), svm.SVR(kernel='linear'),\n                svm.LinearSVC(), svm.LinearSVR()):\n        clf.fit(X_sparse, y)\n        pred = clf.predict(X_sparse)\n        assert_array_equal(pred, y)\n", "def test_base_libsvm_intercept_scaling():\n    # Test that intercept_scaling is passed to liblinear\n\n    # We test this by verifying that a linear model with high intercept scaling\n    # will produce different results than one with low intercept scaling.\n\n    X = np.array([[1, 1], [1, 2], [2, 1], [2, 2]])\n    y = np.array([0, 0, 1, 1])\n\n    # high intercept scaling\n    clf_high = svm.LinearSVC(fit_intercept=True, intercept_scaling=1e9,\n                             random_state=42)\n    clf_high.fit(X, y)\n\n    # low intercept scaling\n    clf_low = svm.LinearSVC(fit_intercept=True, intercept_scaling=1e-9,\n                            random_state=42)\n    clf_low.fit(X, y)\n\n    assert clf_high.intercept_ != clf_low.intercept_\n    assert_array_almost_equal(clf_high.predict(X), clf_low.predict(X))\n"], "sample_141": ["def test_convert_to_quantity_simplify():\n    assert convert_to(quantity_simplify(kilo*foot*inch), meter) == 250*meter**2/3\n    assert convert_to(quantity_simplify(foot - 6*inch), meter) == Rational(1, 2)*meter\n    assert convert_to(quantity_simplify(foot + 6*inch), meter) == Rational(3, 2)*meter\n    assert convert_to(quantity_simplify(foot + 12*inch), meter) == 2*meter\n", "def test_quantity_simplify():\n    assert quantity_simplify(kilo*foot*inch) == 250*foot**2/3\n    assert quantity_simplify(foot - 6*inch) == foot/2\n\n    u = Quantity(\"u\", abbrev=\"ikm\")\n    u.set_global_relative_scale_factor(3*kilo, meter)\n    v = Quantity(\"v\", abbrev=\"im\")\n    v.set_global_relative_scale_factor(3, meter)\n\n    assert quantity_simplify(u) == 3000*meter\n    assert quantity_simplify(v) == 3*meter\n    assert quantity_simplify(u + v) == 3003*meter\n    assert quantity_simplify(u * v) == 9000*meter**2\n", "def test_convert_to_quantity_simplify():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    expr = convert_to(u * v, meter)\n    assert quantity_simplify(expr) == 50*meter**2\n\n    expr = convert_to(u / v, meter)\n    assert quantity_simplify(expr) == 2*meter\n\n    expr = convert_to(u ** 2, meter)\n    assert quantity_simplify(expr) == 100*meter**2\n\n    expr = convert_to(v ** 0.5, meter)\n    assert quantity_simplify(expr) == sqrt(meter)\n\n    expr = convert_to(u ** -1, meter)\n    assert quantity_simplify(expr) == 1/(10*meter)\n\n    expr = convert_to(u * v ** -1, meter)\n    assert quantity_simplify(expr) == 2/meter\n", "def test_convert_to_with_non_compatible_dimensions():\n    # Test conversion to a unit with a different dimension\n    assert convert_to(kilogram, joule) == kilogram\n    # Test conversion to a unit with a different dimension system\n    assert convert_to(kilogram, joule, unit_system=\"CGS\") == kilogram\n", "def test_convert_to_issue():\n    km_per_hour = kilometer / hour\n    m_per_s = meter / second\n\n    expr1 = 5 * km_per_hour\n    assert convert_to(expr1, m_per_s) == 5000000 * m_per_s / 3600\n\n    expr2 = 25 * km_per_hour\n    assert convert_to(expr2, m_per_s) == 25000000 * m_per_s / 3600\n\n    # Test that the function handles other units\n    expr3 = 100 * kilogram * meter / second**2\n    assert convert_to(expr3, newton) == 100 * newton\n\n    # Test that the function raises an error when the input expression is not compatible\n    expr4 = 100 * kilogram * meter / second\n    raises(ValueError, lambda: convert_to(expr4, newton))\n"], "sample_142": ["def test_has_variety():\n    assert has_variety([1, 2, 1]) is True\n    assert has_variety([1, 1, 1]) is False\n    assert has_variety([]) is False\n", "def test_least_rotation():\n    assert least_rotation([3, 1, 5, 1, 2]) == 3\n    assert rotate_left([3, 1, 5, 1, 2], least_rotation([3, 1, 5, 1, 2])) == [1, 2, 3, 1, 5]\n    assert rotate_left([1, 2, 3], least_rotation([1, 2, 3])) == [1, 2, 3]\n    assert rotate_left([2, 1, 3], least_rotation([2, 1, 3])) == [1, 2, 3]\n    assert rotate_left([1, 2, 3, 4], least_rotation([1, 2, 3, 4])) == [1, 2, 3, 4]\n    assert rotate_left([2, 1, 3, 4], least_rotation([2, 1, 3, 4])) == [1, 2, 3, 4]\n    assert rotate_left([4, 1, 2, 3], least_rotation([4, 1, 2, 3])) == [1, 2, 3, 4]\n", "def test_ibin():\n    assert ibin(5) == [1, 0, 1]\n    assert ibin(5, bits=8) == [0, 0, 0, 0, 0, 1, 0, 1]\n    assert ibin(5, bits=2) == [1, 0]\n    assert ibin(5, bits='all') == [(0, 0), (0, 1), (1, 0), (1, 1)]\n    assert ibin(5, bits=2, str=True) == '101'\n    assert ibin(5, bits=8, str=True) == '00000101'\n    assert ibin(5, bits='all', str=True) == ['00', '01', '10', '11']\n    raises(ValueError, lambda: ibin(-1))\n    raises(ValueError, lambda: ibin(1, bits=-1))\n    raises(ValueError, lambda: ibin(1, bits=0))\n", "def test_ibin():\n    assert ibin(0) == []\n    assert ibin(0, 2) == [0, 0]\n    assert ibin(1) == [1]\n    assert ibin(1, 1) == [1]\n    assert ibin(1, 2) == [0, 1]\n    assert ibin(2) == [1, 0]\n    assert ibin(2, 2) == [1, 0]\n    assert ibin(2, 3) == [0, 1, 0]\n    assert ibin(2, 3, str=True) == '010'\n    assert ibin(3) == [1, 1]\n    assert ibin(3, 3) == [1, 1]\n    assert ibin(3, 4) == [0, 1, 1]\n    assert ibin(3, 4, str=True) == '011'\n    assert ibin(5, bits='all') == [(0, 0), (0, 1), (1, 0), (1, 1)]\n    assert ibin(5, bits='all', str=True) == ['00', '01', '10', '11']\n    assert list(ibin(1, 3)) == [[1, 0, 0]]\n    assert list(ibin(3, 3)) == [[1, 1, 0], [1, 0, 1], [0, 1, 1]]\n", "def test_ibin():\n    # Test different types of input\n    assert ibin(0, 1, str=True) == '0'\n    assert ibin(1, 1) == [0, 1]\n    assert ibin(3, 2) == [1, 1]\n    assert ibin(3, 3) == [1, 1, 0]\n    assert ibin(1, 2) == [0, 0]\n    assert ibin(2, 4) == [0, 0, 1, 0]\n\n    # Test 'all' option\n    assert list(ibin(1, 'all')) == [(0,), (1,)]\n    assert list(ibin(2, 'all')) == [(0, 0), (0, 1), (1, 0), (1, 1)]\n\n    # Test string output\n    assert ibin(2, 3, str=True) == '010'\n    assert ibin(5, 3, str=True) == '101'\n\n    # Test error handling\n    raises(ValueError, lambda: ibin(-1))\n    raises(ValueError, lambda: ibin(5, -1))\n    raises(ValueError, lambda: ibin(5, 2, str='abc'))\n"], "sample_105": ["def test_transform_voting_regressor():\n    \"\"\"Check transform method of VotingRegressor on toy dataset.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(n_estimators=10, random_state=123)\n    X = np.array([[1, 1], [2, 4], [3, 9], [4, 16], [5, 25]])\n    y = np.array([2, 6, 12, 20, 30])\n\n    ereg1 = VotingRegressor([('lr', reg1), ('rf', reg2)]).fit(X, y)\n    ereg2 = VotingRegressor([('lr', reg1), ('rf', reg2)]).fit(X, y)\n\n    assert_array_almost_equal(ereg1.transform(X), reg1.fit(X, y).predict(X))\n    assert_array_almost_equal(ereg2.transform(X), reg2.fit(X, y).predict(X))\n", "def test_label_encoder_usage():\n    \"\"\"Check usage of LabelEncoder in VotingClassifier\"\"\"\n    clf1 = LogisticRegression(random_state=123, multi_class='ovr')\n    clf2 = RandomForestClassifier(random_state=123)\n    eclf = VotingClassifier(estimators=[\n                ('lr', clf1), ('rf', clf2)],\n                voting='soft')\n    eclf.fit(X, y)\n\n    assert_array_equal(eclf.le_.classes_, eclf.classes_)\n    assert_array_equal(eclf.le_.transform(y), eclf.le_.transform(eclf.predict(X)))\n", "def test_voting_regressor():\n    \"\"\"Check that VotingRegressor returns correct predictions.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(n_estimators=10, random_state=1)\n    X = np.array([[1, 1], [2, 4], [3, 9], [4, 16], [5, 25], [6, 36]])\n    y = np.array([2, 6, 12, 20, 30, 42])\n\n    ereg = VotingRegressor([('lr', reg1), ('rf', reg2)]).fit(X, y)\n    reg1.fit(X, y)\n    reg2.fit(X, y)\n    expected_pred = (reg1.predict(X) + reg2.predict(X)) / 2\n    assert_array_almost_equal(ereg.predict(X), expected_pred, decimal=2)\n\n    ereg = VotingRegressor([('lr', reg1), ('rf', reg2)], weights=[1, 2]).fit(X, y)\n    expected_pred = (reg1.predict(X) + 2 * reg2.predict(X)) / 3\n    assert_array_almost_equal(ereg.predict(X), expected_pred, decimal=2)\n", "def test_voting_regressor_sample_weights():\n    \"\"\"Test VotingRegressor with sample weights\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor()\n    X, y = boston.data, boston.target\n\n    # Test with uniform sample weights\n    ereg1 = VotingRegressor(estimators=[('lr', reg1), ('rf', reg2)])\n    ereg2 = VotingRegressor(estimators=[('lr', reg1), ('rf', reg2)])\n    ereg1.fit(X, y)\n    ereg2.fit(X, y, sample_weight=np.ones(len(y)))\n    assert_array_almost_equal(ereg1.predict(X), ereg2.predict(X))\n\n    # Test with non-uniform sample weights\n    sample_weight = np.random.RandomState(123).uniform(size=(len(y),))\n    ereg1.fit(X, y)\n    ereg2.fit(X, y, sample_weight=sample_weight)\n    assert_array_almost_equal(ereg1.predict(X) != ereg2.predict(X), True)\n", "def test_invalid_input_voting_regressor():\n    \"\"\"Check VotingRegressor raises error on invalid input.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor()\n\n    # Test that all estimators must be a list of (string, estimator) tuples\n    ereg = VotingRegressor(reg1)\n    msg = ('Invalid `estimators` attribute, `estimators` should be'\n           ' a list of (string, estimator) tuples')\n    assert_raise_message(AttributeError, msg, ereg.fit, X_r, y_r)\n\n    # Test that all estimators must be a list of (string, estimator) tuples\n    ereg = VotingRegressor([('r1', reg1)])\n    msg = ('All estimators must be tuples')\n    assert_raise_message(ValueError, msg, ereg.fit, X_r, y_r)\n\n    # Test that all estimators must be instances of BaseEstimator\n    ereg = VotingRegressor([('r1', reg1), ('r2', 'not an estimator')])\n    msg = ('All estimators must be instances of BaseEstimator')\n    assert_raise_message(ValueError, msg, ereg.fit, X_r, y_r)\n\n    # Test that all weights must be positive or zero\n    ereg = VotingRegressor([('r1', reg1), ('r2', reg2)], weights=[1, -1])\n    msg = ('Weights need to be non-negative')\n    assert_raise_message(ValueError, msg, ereg.fit, X_r, y_r)\n"], "sample_53": ["def test_add_custom_fk_with_str_to(self):\n    class StrForeignKey(models.ForeignKey):\n            kwargs[\"to\"] = \"testapp.Author\"\n            super().__init__(*args, **kwargs)\n\n            name, path, args, kwargs = super().deconstruct()\n            del kwargs[\"to\"]\n            return name, path, args, kwargs\n\n    book_str_to = ModelState(\n        \"testapp\",\n        \"Book\",\n        [\n            (\"author\", StrForeignKey(on_delete=models.CASCADE)),\n        ],\n    )\n    changes = self.get_changes(\n        [self.author_empty],\n        [self.author_empty, book_str_to],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Book\")\n", "def test_alter_unique_together_add_m2m_field(self):\n    \"\"\"Tests unique_together detection with adding a ManyToManyField.\"\"\"\n    changes = self.get_changes(\n        [self.author_empty, self.book_foo_together],\n        [self.author_empty, self.book_with_multiple_authors],\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(\n        changes,\n        \"otherapp\",\n        0,\n        [\n            \"AlterUniqueTogether\",\n            \"AddField\",\n        ],\n    )\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        0,\n        name=\"book\",\n        unique_together={(\"author\", \"title\")},\n    )\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        1,\n        model_name=\"book\",\n        name=\"authors\",\n    )\n", "def test_custom_field_unmanaged(self):\n    \"\"\"Custom fields are correctly handled for unmanaged models.\"\"\"\n    class CustomField(models.Field):\n            return \"custom\"\n\n    custom_field_unmanaged = ModelState(\n        \"testapp\",\n        \"Model\",\n        [\n            (\"custom_field\", CustomField()),\n        ],\n        options={\"managed\": False},\n    )\n    changes = self.get_changes([], [custom_field_unmanaged])\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\"])\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, name=\"Model\", fields=[(\"custom_field\", CustomField())]\n    )\n", "def test_order_with_respect_to_inheritance(self):\n    \"\"\"Tests order_with_respect_to in model inheritance.\"\"\"\n    parent = ModelState(\n        \"app\",\n        \"Parent\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n        ],\n        {\n            \"order_with_respect_to\": \"othermodel\",\n        },\n    )\n    child = ModelState(\n        \"app\",\n        \"Child\",\n        [],\n        bases=(\"app.Parent\",),\n    )\n    other_model = ModelState(\n        \"app\",\n        \"OtherModel\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=200)),\n        ],\n    )\n    changes = self.get_changes([], [parent, child, other_model])\n    self.assertNumberMigrations(changes, \"app\", 1)\n    self.assertOperationTypes(changes, \"app\", 0, [\"CreateModel\", \"CreateModel\", \"CreateModel\"])\n    self.assertEqual(\n        changes[\"app\"][0].operations[0].options,\n        {\"order_with_respect_to\": \"othermodel\"},\n    )\n", "    def test_delete_model_with_index_on_m2m_through(self):\n        \"\"\"\n        Removing a model that contains a ManyToManyField with a \"through\" model\n        generates a migration with the indexes of the \"through\" model before\n        the \"through\" model.\n        \"\"\"\n        changes = self.get_changes(\n            [self.author_with_m2m_through, self.publisher, self.contract],\n            [self.author_with_m2m, self.publisher],\n        )\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, \"testapp\", 1)\n        self.assertOperationTypes(\n            changes, \"testapp\", 0, [\"RemoveIndex\", \"RemoveIndex\", \"RemoveField\", \"DeleteModel\"]\n        )\n        self.assertOperationAttributes(\n            changes, \"testapp\", 0, 0, model_name=\"contract\", name=\"contract_publisher_id_32e4\"\n        )\n        self.assertOperationAttributes(\n            changes, \"testapp\", 0, 1, model_name=\"contract\", name=\"contract_author_id_32e4\"\n        )\n        self.assertOperationAttributes(\n            changes, \"testapp\", 0, 2, model_name=\"author\", name=\"publishers\"\n        )\n        self.assertOperationAttributes(changes, \"testapp\", 0, 3, name=\"Contract\")\n"], "sample_137": ["def test_ibin():\n    assert ibin(2) == [1, 0]\n    assert ibin(2, 4) == [0, 0, 1, 0]\n    assert ibin(2, 4)[::-1] == [0, 1, 0, 0]\n    assert ibin(2, bits='all') == [(0, 0), (0, 1), (1, 0), (1, 1)]\n    assert ibin(2, bits=2) == [(0, 0), (0, 1), (1, 0), (1, 1)]\n    assert ibin(123, bits=10, str=True) == '0001111011'\n    assert ibin(123, bits=10, str=True)[::-1] == '1101111000'\n    assert list(ibin(3, 'all', str=True)) == ['000', '001', '010', '011', '100', '101', '110', '111']\n", "def test_ibin():\n    # Test with non-negative integer\n    assert ibin(2) == [1, 0]\n    assert ibin(2, 4) == [0, 0, 1, 0]\n\n    # Test with integer and str=True\n    assert ibin(2, 4, str=True) == '0010'\n\n    # Test with non-integer for bits\n    assert list(ibin(2, 'all')) == [(0, 0), (0, 1), (1, 0), (1, 1)]\n    assert list(ibin(2, 'all', str=True)) == ['00', '01', '10', '11']\n\n    # Test with integer and str=True and bits='all'\n    assert list(ibin(3, 'all', str=True)) == ['000', '001', '010', '011', '100', '101', '110', '111']\n\n    # Test with invalid input\n    raises(ValueError, lambda: ibin(-2))\n    raises(ValueError, lambda: ibin(2, -4))\n    raises(ValueError, lambda: ibin(2, 'invalid'))\n    raises(ValueError, lambda: ibin('invalid'))\n", "def test_ibin():\n    assert ibin(0) == []\n    assert ibin(2) == [1, 0]\n    assert ibin(2, 4) == [0, 0, 1, 0]\n    assert ibin(2, 4)[::-1] == [0, 1, 0, 0]\n\n    assert ibin(2, 'all') == [(0, 0), (0, 1), (1, 0), (1, 1)]\n    assert list(ibin(3, 'all')) == [(0, 0, 0), (0, 0, 1), (0, 1, 0),\n        (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)]\n\n    n = 123\n    bits = 10\n    assert ibin(n, bits, str=True) == '0001111011'\n    assert ibin(n, bits, str=True)[::-1] == '1101111000'\n    assert list(ibin(3, 'all', str=True)) == ['000', '001', '010', '011',\n        '100', '101', '110', '111']\n", "def test_least_rotation():\n        expected = min(least_rotation(i) for i in permutations(s))\n        assert least_rotation(s) == expected\n\n    test_rotation([3, 1, 5, 1, 2])\n    test_rotation([1, 2, 3, 4, 5])\n    test_rotation([5, 4, 3, 2, 1])\n    test_rotation([1, 1, 1, 1, 1])\n    test_rotation([1, 2, 1, 2, 1])\n    test_rotation('aabbc')\n    test_rotation('abcdefgh')\n    test_rotation('zyxwvutsr')\n    test_rotation('aaaaa')\n    test_rotation('ababa')\n    test_rotation('abcde')\n    test_rotation('edcba')\n    test_rotation('dcbae')\n    test_rotation('aabbcc')\n    test_rotation('cbbaac')\n", "def test_reshape_invalid_input():\n    seq = [1, 2, 3, 4, 5]\n    assert reshape(seq, [-1]) == ([1, 2, 3, 4, 5],)\n    assert reshape(seq, [3, 'a']) == ([1, 2, 3], [4, 5])\n    assert reshape(seq, (1, 1, 1, 1, 1)) == ((1,), (2,), (3,), (4,), (5,))\n    assert reshape(seq, [[1, 1, 1, 1, 1]]) == [[[1], [2], [3], [4], [5]]]\n    assert reshape(seq, ((1, 1, 1, 1, 1),)) == (((1,), (2,), (3,), (4,), (5,),)\n\n    # Invalid input\n    raises(ValueError, lambda: reshape(seq, [-1, 1]))\n    raises(ValueError, lambda: reshape(seq, ['a']))\n    raises(ValueError, lambda: reshape(seq, [1, 2, 'a']))\n    raises(ValueError, lambda: reshape(seq, [1, [2, 'a']]))\n    raises(ValueError, lambda: reshape(seq, [[1, 2], [3, 'a']]))\n\n    # Input with different types\n    seq = [1, 2, 3, 4, 5]\n    assert reshape(seq, [2, 'a']) == ([1, 2], ['a'])\n    assert reshape(seq, (2, 'a')) == ((1, 2), ('a',))\n    assert reshape(seq, [[2], 'a']) == [[[1, 2]], ['a']]\n    assert reshape(seq, ((2,), 'a')) == (((1, 2),), ('a',))\n"], "sample_86": ["def test_record_testsuite_property_overwrite(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", \"all good\")\n\n            record_testsuite_property(\"stats\", 10)\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p2_node = properties_node.find_nth_by_tag(\"property\", 1)\n    p2_node.assert_attr(name=\"stats\", value=\"10\")\n", "def test_record_testsuite_property_multiline(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", \"all good\\non multiple lines\")\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p1_node.assert_attr(name=\"stats\", value=\"all good&#10;on multiple lines\")\n", "def test_xunit2_report_attribute(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        junit_family = xunit2\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n            record_xml_attribute(\"foo\", \"<1\");\n    \"\"\"\n    )\n    result, dom = runandparse(testdir, \"-rw\")\n    node = dom.find_first_by_tag(\"testsuite\")\n    tnode = node.find_first_by_tag(\"testcase\")\n    assert \"foo\" not in tnode.attrib\n", "def test_logxml_mangled_path(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    path = testdir.tmpdir.join(\"some/path/with spaces/test.xml\")\n    result = testdir.runpytest(\"--junitxml=%s\" % path)\n    assert result.ret == 0\n    assert path.check()\n", "def test_xunit2_attributes(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        junit_family = xunit2\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n            pytest.xfail(\"reason\")\n            pytest.skip(\"skip reason\")\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    node = dom.find_first_by_tag(\"testsuite\")\n    node.assert_attr(failures=1, skipped=0, tests=1)\n    tnode = node.find_first_by_tag(\"testcase\")\n    tnode.assert_attr(classname=\"test_xunit2_attributes\", name=\"test_xfail\")\n    fnode = tnode.find_first_by_tag(\"skipped\")\n    assert fnode is None\n"], "sample_83": ["def test_colorized_text_reporter(linter):\n    output = StringIO()\n    reporter = ColorizedTextReporter(output)\n    linter.reporter = reporter\n    linter.open()\n    linter.set_current_module(\"my_module\")\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n    linter.add_message(\"line-too-long\", line=2, end_lineno=2, end_col_offset=4, args=(3, 4))\n    result = output.getvalue()\n    assert \"\\033[35m\" in result  # magenta color code\n    assert \"\\033[1m\" in result  # bold style code\n    assert \"\\033[0m\" in result  # reset code\n", "def test_colorized_reporter_color_mapping(linter):\n    output = StringIO()\n    colorized_reporter = ColorizedTextReporter(output)\n    linter.reporter = colorized_reporter\n    linter.open()\n    linter.set_current_module(\"my_module\")\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert out_lines[1].startswith(\"\\033[35m************* Module my_module\\033[0m\")\n    assert out_lines[2].startswith(\"\\033[31;1mmy_module:1:0: C0301: \\033[0m\")\n\n    custom_color_mapping = {\n        \"C\": MessageStyle(\"blue\"),\n    }\n    colorized_reporter = ColorizedTextReporter(output, custom_color_mapping)\n    linter.reporter = colorized_reporter\n    output = StringIO()\n    linter.reporter.out = output\n    linter.open()\n    linter.set_current_module(\"my_module\")\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert out_lines[1].startswith(\"\\033[35m************* Module my_module\\033[0m\")\n    assert out_lines[2].startswith(\"\\033[34mmy_module:1:0: C0301: \\033[0m\")\n", "def test_colorized_output(linter):\n    output = StringIO()\n    linter.reporter = ColorizedTextReporter(output)\n    linter.config.msg_template = \"{msg_id}:{line}: {msg} ({symbol})\"\n    linter.open()\n    linter.set_current_module(\"my_module\")\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n    linter.add_message(\n        \"line-too-long\", line=2, end_lineno=2, end_col_offset=4, args=(3, 4)\n    )\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert out_lines[1] == \"\\033[31mC0301\\033[0m:1: Line too long (1/2) (\\033[31mline-too-long\\033[0m)\"\n    assert out_lines[2] == \"\\033[31mC0301\\033[0m:2: Line too long (3/4) (\\033[31mline-too-long\\033[0m)\"\n\n", "def test_colorized_reporter_deprecated_color_mapping_parameter(linter, recwarn):\n    \"\"\"Test that deprecated color_mapping parameter is handled correctly.\"\"\"\n    output = StringIO()\n    with warnings.catch_warnings(record=True):\n        linter.reporter = ColorizedTextReporter(output, color_mapping={\"I\": (\"green\", \"bold\")})\n    assert len(recwarn) == 1\n    assert \"In pylint 3.0, the ColorizedTextReporter will only accept ColorMappingDict as color_mapping parameter\" in str(\n        recwarn[0].message\n    )\n\n", "def test_colorized_text_reporter_deprecated(linter, recwarn: WarningsRecorder) -> None:\n    \"\"\"Test the deprecation of colorized text reporter's color_mapping parameter\"\"\"\n    color_mapping = {\n        \"I\": (\"green\", (\"bold\",)),\n        \"C\": (\"magenta\", (\"bold\", \"italic\")),\n    }\n    with warnings.catch_warnings(record=True):\n        ColorizedTextReporter(color_mapping=color_mapping)\n    assert len(recwarn) == 1\n    assert isinstance(recwarn[0].message, DeprecationWarning)\n    assert (\n        \"In pylint 3.0, the ColorizedTextReporter will only accept ColorMappingDict as color_mapping parameter\"\n        in str(recwarn[0].message)\n    )\n\n"], "sample_7": ["    def test_setting_timeout_from_environment_variable_invalid(self):\n        with self.assertRaises(ValueError):\n            self.RELOADER_CLS()\n", "    def test_sent_after_apps_ready(self):\n        class FakeApps:\n                self.ready_event = threading.Event()\n\n                self.ready_event.set()\n\n        fake_apps = FakeApps()\n        reloader = autoreload.BaseReloader()\n        sent = []\n\n            sent.append(sender)\n\n        autoreload.autoreload_started.connect(receiver)\n\n        reloader.run(django_main_thread=threading.Thread(target=fake_apps.ready))\n        fake_apps.ready()\n        self.assertEqual(sent, [reloader])\n", "    def setUp(self):\n        self.reloader = autoreload.BaseReloader()\n", "    def test_termios_echo_enabled(self, mocked_isatty, mocked_termios):\n        autoreload.ensure_echo_on()\n        mocked_termios.tcgetattr.assert_called_once_with(sys.stdin)\n        mocked_termios.tcsetattr.assert_called_once_with(sys.stdin, termios.TCSANOW, mocked_termios.tcgetattr.return_value)\n        self.assertEqual(mocked_termios.tcsetattr.call_args[1][2][3] & termios.ECHO, termios.ECHO)\n", "    def test_enable_echo(self, mocked_tcsetattr, mocked_tcgetattr):\n        # Without TTY\n        mocked_tcgetattr.return_value = [1]\n        mocked_tcgetattr.side_effect = termios.error\n        with mock.patch('sys.stdin.isatty', return_value=False):\n            autoreload.ensure_echo_on()\n            mocked_tcgetattr.assert_called_once_with(sys.stdin)\n            mocked_tcsetattr.assert_not_called()\n\n        # With TTY and echo already on\n        mocked_tcgetattr.return_value = [1, 0, 0, termios.ECHO, 0, 0]\n        mocked_tcgetattr.side_effect = None\n        with mock.patch('sys.stdin.isatty', return_value=True):\n            autoreload.ensure_echo_on()\n            mocked_tcgetattr.assert_called_once_with(sys.stdin)\n            mocked_tcsetattr.assert_not_called()\n\n        # With TTY and echo off\n        mocked_tcgetattr.return_value = [1, 0, 0, 0, 0, 0]\n        with mock.patch('sys.stdin.isatty', return_value=True):\n            autoreload.ensure_echo_on()\n            mocked_tcgetattr.assert_called_once_with(sys.stdin)\n            mocked_tcsetattr.assert_called_once_with(sys.stdin, termios.TCSANOW, [1, 0, 0, termios.ECHO, 0, 0])\n"], "sample_22": ["def test_camel_case_to_spaces(self):\n    items = [\n        ('HelloWorld', 'hello world'),\n        ('Hello_World', 'hello_world'),\n        ('helloWorld', 'hello world'),\n        ('hello_World', 'hello_world'),\n        ('hello-world', 'hello-world'),\n        ('hello-world-WORLD', 'hello-world-world'),\n        ('hello_World_World', 'hello_world_world'),\n    ]\n    for value, output in items:\n        self.assertEqual(text.camel_case_to_spaces(value), output)\n        self.assertEqual(text.camel_case_to_spaces(lazystr(value)), output)\n", "def test_format_lazy(self):\n    fmt = format_lazy('Hello, {name}!', name='World')\n    self.assertEqual(str(fmt), 'Hello, World!')\n    fmt_lazy_name = format_lazy('Hello, {name}!', name=lazystr('World'))\n    self.assertEqual(str(fmt_lazy_name), 'Hello, World!')\n    fmt_lazy_format = lazystr('Hello, {name}!')\n    self.assertEqual(format_lazy(fmt_lazy_format, name='World'), 'Hello, World!')\n", "def test_format_lazy(self):\n    lazy_string = lazystr(\"Hello, {}!\")\n    self.assertEqual(_format_lazy(lazy_string, 'world'), 'Hello, world!')\n    lazy_string = gettext_lazy(\"Hello, {}!\")\n    with override('de'):\n        self.assertEqual(_format_lazy(lazy_string, 'world'), 'Hallo, world!')\n    format_lazy_string = format_lazy(lazy_string, 'world')\n    self.assertIsInstance(format_lazy_string, lazystr)\n    self.assertEqual(format_lazy_string, 'Hello, world!')\n", "    def test_camel_case_to_spaces(self):\n        items = [\n            ('helloWorld', 'hello world'),\n            ('hello-world', 'hello-world'),  # Not changed\n            ('hello world', 'hello world'),  # Not changed\n            ('hello_World', 'hello_world'),\n            ('HelloWorld', 'hello world'),\n            ('hello_World', 'hello_world'),\n            ('oneTwoThreeFour', 'one two three four'),\n            ('one_two_three_four', 'one_two_three_four'),  # Not changed\n            ('one-two-three-four', 'one-two-three-four'),  # Not changed\n            ('ONE Two THREE', 'one two three'),\n        ]\n        for value, output in items:\n            self.assertEqual(text.camel_case_to_spaces(value), output)\n            self.assertEqual(text.camel_case_to_spaces(lazystr(value)), output)\n", "def test_camel_case_to_spaces(self):\n    items = [\n        ('helloWorld', 'hello world'),\n        ('hello-world', 'hello-world'),  # hyphens are not replaced with spaces\n        ('helloWorld123', 'hello world123'),\n        ('hello_World', 'hello_World'),  # underscores are not replaced with spaces\n        ('HELLO_WORLD', 'hELLO_WORLD'),  # original casing is kept except first letter\n        ('hello', 'hello'),\n        ('Hello', 'hello'),\n        ('_hello', '_hello'),  # prefix underscore is kept\n        ('hello_', 'hello_'),  # suffix underscore is kept\n    ]\n    for value, output in items:\n        self.assertEqual(text.camel_case_to_spaces(value), output)\n        self.assertEqual(text.camel_case_to_spaces(lazystr(value)), output)\n"], "sample_72": ["def test_constrained_layout_pads():\n    fig = plt.figure(constrained_layout=True)\n    assert fig.get_constrained_layout_pads(relative=False) == (\n        0.04167, 0.04167, 0.02, 0.02)\n    assert fig.get_constrained_layout_pads(relative=True) == (\n        pytest.approx(0.04167 * 100 / fig.dpi),\n        pytest.approx(0.04167 * 100 / fig.dpi),\n        0.02, 0.02)\n", "def test_subplot_mosaic():\n    fig = plt.figure()\n    mosaic = [['a', 'b'],\n              ['c', 'd']]\n    axs = fig.subplot_mosaic(mosaic, sharex='col', sharey='row')\n    assert axs['a'].get_shared_x_axes().has_shared_axes(axs['c'])\n    assert axs['b'].get_shared_x_axes().has_shared_axes(axs['d'])\n    assert axs['a'].get_shared_y_axes().has_shared_axes(axs['b'])\n    assert axs['c'].get_shared_y_axes().has_shared_axes(axs['d'])\n    axs = fig.subplot_mosaic(mosaic, sharex='all', sharey='all')\n    assert axs['a'].get_shared_x_axes().has_shared_axes(axs['c'])\n    assert axs['a'].get_shared_x_axes().has_shared_axes(axs['d'])\n    assert axs['a'].get_shared_y_axes().has_shared_axes(axs['b'])\n    assert axs['a'].get_shared_y_axes().has_shared_axes(axs['c'])\n", "def test_figure_clear():\n    fig, ax = plt.subplots()\n    assert len(fig.axes) == 1\n    assert len(fig.artists) == 0\n    assert len(fig.lines) == 0\n    assert len(fig.patches) == 0\n    assert len(fig.texts) == 0\n    assert len(fig.images) == 0\n    assert len(fig.legends) == 0\n    assert len(fig.subfigs) == 0\n    assert fig.stale == True\n\n    ax.plot([1, 2, 3])\n    fig.text(0.5, 0.5, \"text\")\n    fig.patches.append(plt.Rectangle((0, 0), 1, 1))\n    fig.images.append(plt.imshow([[1]]))\n\n    fig.clear()\n    assert len(fig.axes) == 0\n    assert len(fig.artists) == 0\n    assert len(fig.lines) == 0\n    assert len(fig.patches) == 0\n    assert len(fig.texts) == 0\n    assert len(fig.images) == 0\n    assert len(fig.legends) == 0\n    assert len(fig.subfigs) == 0\n    assert fig.stale == True\n\n    fig.clear(keep_observers=True)\n    assert fig._axobservers.callbacks != {}\n", "def test_figure_mosaic_layout():\n    fig = plt.figure()\n    mosaic = [['A', 'B'], ['C', 'D']]\n    ax_dict = fig.subplot_mosaic(mosaic)\n    assert len(ax_dict) == 4\n    assert set(ax_dict.keys()) == set('ABCD')\n    for ax in ax_dict.values():\n        assert isinstance(ax, mpl.axes._subplots.AxesSubplot)\n    \n    mosaic = [['A', 'B'], ['.', 'D']]\n    with pytest.warns(UserWarning, match=\"Some values are not being used\"):\n        fig.subplot_mosaic(mosaic)\n    \n    mosaic = [['A', 'B'], ['C', 'C']]\n    with pytest.raises(ValueError, match=\"There are duplicate keys\"):\n        fig.subplot_mosaic(mosaic)\n", "def test_constrained_layout_subfigure():\n    fig = plt.figure(constrained_layout=True)\n    sf = fig.add_subfigure(0.4, 0.4)\n    ax = sf.add_subplot()\n    ax.set_title('Subfigure')\n    ax.text(0.5, 0.5, 'Subfigure Axes', ha='center')\n    ax2 = fig.add_subplot()\n    ax2.set_title('Figure Axes')\n    ax2.text(0.5, 0.5, 'Figure Axes', ha='center')\n    fig.canvas.draw()\n\n    # The layout doesn't have to be perfect, just that the figure and\n    # subfigure axes be in the right relative locations\n    assert ax.get_window_extent().p0[0] > ax2.get_window_extent().p0[0]\n    assert ax.get_window_extent().p0[1] < ax2.get_window_extent().p0[1]\n"], "sample_150": ["def test_solve_generic():\n    x0, y0, x1, y1, r = symbols('x0 y0 x1 y1 r')\n\n    f_1 = (x - 1)**2 + (y - 1)**2 - r**2\n    f_2 = (x - 2)**2 + (y - 2)**2 - r**2\n    s = sqrt(2*r**2 - 1)\n    a = (3 - s)/2\n    b = (3 + s)/2\n    assert solve_generic([f_1, f_2], parallel_poly_from_expr([f_1, f_2], x, y)[1]) == [(a, b), (b, a)]\n\n    f_1 = (x - 1)**2 + (y - 2)**2 - r**2\n    f_2 = (x - 1)**2 + (y - 1)**2 - r**2\n\n    assert solve_generic([f_1, f_2], parallel_poly_from_expr([f_1, f_2], x, y)[1]) == \\\n        [(1 - sqrt((2*r - 1)*(2*r + 1))/2, Rational(3, 2)),\n         (1 + sqrt((2*r - 1)*(2*r + 1))/2, Rational(3, 2))]\n\n    query = lambda expr: expr.is_Pow and expr.exp is S.Half\n\n    f_1 = (x - 1 )**2 + (y - 2)**2 - r**2\n    f_2 = (x - x1)**2 + (y - 1)**2 - r**2\n\n    result = solve_generic([f_1, f_2], parallel_poly_from_expr([f_1, f_2], x, y)[1])\n\n    assert len(result) == 2 and all(len(r) == 2 for r in result)\n    assert all(r.count(query) == 1 for r in flatten(result))\n\n    f_1 = (x - x0)**2 + (y - y0)**2 - r**2\n    f_2 = (x - x1)**2 + (y - y1)**2 - r**2\n\n    result = solve_generic([f_1, f_2], parallel_poly_from_expr([f_1,", "def test_solve_generic():\n    x0, x1, x2 = symbols('x0 x1 x2')\n\n    # Test with three variables\n    f_1 = x0**2 + x1 + x2 - 1\n    f_2 = x0 + x1**2 + x2 - 1\n    f_3 = x0 + x1 + x2**2 - 1\n    assert solve_generic([f_1, f_2, f_3], options=(x0, x1, x2)) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0)]\n\n    # Test with two variables\n    f_1 = x0**2 + x1 - 1\n    f_2 = x0 + x1**2 - 1\n    assert solve_generic([f_1, f_2], options=(x0, x1)) == [(0, 1), (1, 0)]\n\n    # Test with one variable\n    f_1 = x0**2 - 1\n    assert solve_generic([f_1], options=(x0,)) == [(1,), (-1,)]\n", "def test_solve_generic():\n    assert solve_generic([x - 1, y - 1], (x, y)) == [(1, 1)]\n\n    assert solve_generic([x*y - 2*y, 2*y**2 - x**2], (x, y)) == \\\n        [(0, 0), (2, -sqrt(2)), (2, sqrt(2))]\n\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n\n    a, b = sqrt(2) - 1, -sqrt(2) - 1\n\n    assert solve_generic([f_1, f_2, f_3], (x, y, z)) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0), (a, a, a), (b, b, b)]\n\n    raises(NotImplementedError, lambda: solve_generic([x**3 - y**3], (x, y)))\n    raises(NotImplementedError, lambda: solve_generic(\n        [z, -2*x*y**2 + x + y**2*z, y**2*(-z - 4) + 2], (x, y, z)))\n    raises(PolynomialError, lambda: solve_generic([1/x], (x,)))\n\n    raises(NotImplementedError, lambda: solve_generic([x-1], (x, y)))\n    raises(NotImplementedError, lambda: solve_generic([y-1], (x, y)))\n\n    assert solve_generic([x**2 + y**2 - 1, y**2 - 1], (x, y)) == \\\n        [(0, -1), (0, 1)]\n\n    assert solve_generic([x - 2*y + 5, 2*x - y - 3], (x, y)) == \\\n        [(11/3, 13/3)]\n\n    assert solve_generic([x**2 + y, x + y*4], (x, y)) == \\\n        [(0, 0), (1/4, -1/16)]\n", "def test_solve_generic():\n    x0, y0, z0 = symbols('x0 y0 z0')\n\n    f_1 = (x - 1)**2 + (y - 2)**2 + (z - 3)**2 - 1\n    f_2 = (x - 2)**2 + (y - 3)**2 + (z - 1)**2 - 1\n    f_3 = (x - 3)**2 + (y - 1)**2 + (z - 2)**2 - 1\n\n    assert solve_generic([f_1, f_2, f_3], None) == [(1, 2, 3)]\n\n    f_1 = (x - x0)**2 + (y - y0)**2 + (z - z0)**2 - 1\n    f_2 = (x - 2)**2 + (y - 3)**2 + (z - 1)**2 - 1\n    f_3 = (x - 3)**2 + (y - 1)**2 + (z - 2)**2 - 1\n\n    result = solve_generic([f_1, f_2, f_3], None)\n\n    assert len(result) == 1 and len(result[0]) == 3\n\n    a, b, c = symbols('a b c')\n    f_1 = x**2 + y**2 + z**2 + a*x + b*y + c*z - 1\n    f_2 = x**2 + y**2 + z**2 - a*x - b*y - c*z - 1\n    f_3 = x**2 + y**2 + z**2 + 2*z - 1\n\n    result = solve_generic([f_1, f_2, f_3], None)\n\n    assert len(result) == 1 and len(result[0]) == 3\n", "def test_solve_poly_system_with_nonlinear_equations():\n    assert solve_poly_system([x**2 + y**2 - 4, x - 2], x, y) == \\\n        [(2, 0), (2, -I*2*sqrt(3)), (2, I*2*sqrt(3))]\n    \n    assert solve_poly_system([x - y, x**3 - y**3 - 1], x, y) == \\\n        [(-1, -1), (S.One, S.One), (S.One/2 + I*sqrt(3)/2, S.One/2 - I*sqrt(3)/2),\n         (S.One/2 - I*sqrt(3)/2, S.One/2 + I*sqrt(3)/2)]\n    \n    assert solve_poly_system([x**2 + y - 3, x + y**2 - 3], x, y) == \\\n        [(S.One, S.One)]\n    \n    raises(PolynomialError, lambda: solve_poly_system([x**2 - 1/x], x))\n"], "sample_40": ["def test_boundfield_get_bound_field(self):\n    class CustomBoundField:\n            self.form = form\n            self.field = field\n            self.name = name\n\n    class CustomField(CharField):\n            return CustomBoundField(form, self, name)\n\n    class SampleForm(Form):\n        name = CustomField()\n\n    f = SampleForm()\n    boundfield = f['name']\n    self.assertIsInstance(boundfield, CustomBoundField)\n    self.assertEqual(boundfield.form, f)\n    self.assertEqual(boundfield.field, f.fields['name'])\n    self.assertEqual(boundfield.name, 'name')\n", "def test_boundfield_widget_type(self):\n    class MyForm(Form):\n        first_name = CharField()\n        birthday = DateField()\n        password = CharField(widget=PasswordInput)\n        multiple_choice = MultipleChoiceField(choices=[('a', 'A'), ('b', 'B')])\n\n    form = MyForm(auto_id=False)\n    self.assertEqual(form['first_name'].widget_type, 'text')\n    self.assertEqual(form['birthday'].widget_type, 'text')\n    self.assertEqual(form['password'].widget_type, 'password')\n    self.assertEqual(form['multiple_choice'].widget_type, 'selectmultiple')\n", "def test_boundfield_iterable_subwidgets(self):\n    class TestForm(Form):\n        field = ChoiceField(\n            choices=[('a', 'A'), ('b', 'B')],\n            widget=CheckboxSelectMultiple,\n        )\n\n    form = TestForm(auto_id=False)\n    field = form['field']\n    self.assertEqual(len(field.subwidgets), 2)\n    self.assertIsInstance(field.subwidgets, list)\n    self.assertIsInstance(field.subwidgets[0], BoundWidget)\n    self.assertIsInstance(field.subwidgets[1], BoundWidget)\n    self.assertEqual(field.subwidgets[0].data['attrs']['id'], None)\n    self.assertEqual(field.subwidgets[1].data['attrs']['id'], None)\n\n    form = TestForm(auto_id='id_%s')\n    field = form['field']\n    self.assertEqual(len(field.subwidgets), 2)\n    self.assertIsInstance(field.subwidgets, list)\n    self.assertIsInstance(field.subwidgets[0], BoundWidget)\n    self.assertIsInstance(field.subwidgets[1], BoundWidget)\n    self.assertEqual(field.subwidgets[0].data['attrs']['id'], 'id_field_0')\n    self.assertEqual(field.subwidgets[1].data['attrs']['id'], 'id_field_1')\n", "    def test_boundfield_css_classes_invalid_choices(self):\n        class ChoicesForm(Form):\n            choices = ChoiceField(choices=[(1, 'Choice 1'), (2, 'Choice 2')])\n\n        form = ChoicesForm({'choices': '3'})\n        boundfield = form['choices']\n        self.assertEqual(boundfield.css_classes(), 'error')\n", "def test_boundfield_subwidget_rendering(self):\n    class SubwidgetForm(Form):\n        choices = MultipleChoiceField(\n            choices=[('a', 'A'), ('b', 'B')],\n            widget=CheckboxSelectMultiple,\n        )\n\n    form = SubwidgetForm(auto_id=False)\n    subwidgets = list(form['choices'])\n    for subwidget in subwidgets:\n        subwidget_data = {'attrs': {'class': 'custom'}}\n        rendered_subwidget = subwidget.tag(subwidget_data)\n        self.assertIn('class=\"custom\"', rendered_subwidget)\n"], "sample_155": ["def test_get_units_non_prefixed():\n    assert meter in SI.get_units_non_prefixed()\n    assert joule in SI.get_units_non_prefixed()\n    assert day in SI.get_units_non_prefixed()\n    assert second in SI.get_units_non_prefixed()\n    assert volt in SI.get_units_non_prefixed()\n    assert ohm in SI.get_units_non_prefixed()\n    assert centimeter not in SI.get_units_non_prefixed()\n    assert kilometer not in SI.get_units_non_prefixed()\n    assert kilogram not in SI.get_units_non_prefixed()\n    assert pebibyte not in SI.get_units_non_prefixed()\n\n    good_grade = Quantity(\"good_grade\")\n    good_grade.set_global_relative_scale_factor(1, meter)\n    assert good_grade in SI.get_units_non_prefixed()\n", "def test_derived_units():\n    system = SI.extend([], derived_units={Dimension(length/time): Quantity(\"speed\")})\n    assert system.derived_units == {Dimension(length/time): Quantity(\"speed\")}\n    assert system.get_quantity_dimension(Quantity(\"speed\")) == length/time\n", "def test_unit_system_properties():\n    assert SI.name == \"SI\"\n    assert SI.descr == \"The International System of Units\"\n    assert SI.dim == 7\n\n    assert SI.is_consistent\n\n    assert SI.get_dimension_system() is not None\n", "def test_derived_units():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n\n    SI.set_quantity_dimension(u, energy/time)\n    SI.set_quantity_dimension(v, energy)\n\n    u.set_global_relative_scale_factor(1, joule/second)\n    v.set_global_relative_scale_factor(1, joule)\n\n    derived_units = {energy/time: u, energy: v}\n    new_SI = SI.extend([], [], derived_units=derived_units)\n\n    assert new_SI.derived_units == derived_units\n    assert new_SI.get_quantity_dimension(u) == energy/time\n    assert new_SI.get_quantity_dimension(v) == energy\n", "def test_derived_units():\n    good_grade = Quantity(\"good_grade\")\n    kilo_good_grade = Quantity(\"kilo_good_grade\")\n    centi_good_grade = Quantity(\"centi_good_grade\")\n\n    kilo_good_grade.set_global_relative_scale_factor(1000, good_grade)\n    centi_good_grade.set_global_relative_scale_factor(S.One/10**5, kilo_good_grade)\n\n    charity_points = Quantity(\"charity_points\")\n    milli_charity_points = Quantity(\"milli_charity_points\")\n    missions = Quantity(\"missions\")\n\n    milli_charity_points.set_global_relative_scale_factor(S.One/1000, charity_points)\n    missions.set_global_relative_scale_factor(251, charity_points)\n\n    us = UnitSystem(\n        base_units=(kilo_good_grade, milli_charity_points),\n        units=(centi_good_grade, missions),\n        name=\"my_unit_system\",\n        derived_units={\n            Dimension(length): meter,\n            Dimension(charity_points/milli_charity_points*missions/kilo_good_grade): charity_points/milli_charity_points*missions/kilo_good_grade,\n        },\n    )\n\n    assert us.get_dimension_system().get_dimensional_dependencies(area) == {length: 2}\n    assert us.get_dimension_system().get_dimensional_dependencies(charity_points/milli_charity_points*missions/kilo_good_grade) == {\n        kilo_good_grade: -1,\n        milli_charity_points: -1,\n        missions: 1,\n    }\n\n    assert us.get_quantity_dimension(kilo_good_grade) == Dimension(kilo_good_grade)\n    assert us.get_quantity_scale_factor(kilo_good_grade) == 1\n\n    assert us.get_quantity_dimension(meter) == Dimension(length)\n    assert us.get_quantity_scale_factor(meter) == 1\n\n    assert us.get_quantity_dimension(charity_points/milli_charity_points*missions/kilo_good_grade) == \\\n           Dimension(charity_points/milli_charity_points*missions/kilo_good_grade)\n    assert us.get_quantity_scale_factor(charity_points/milli_charity_points*missions/kilo_good_grade) == 1\n"], "sample_21": ["    def test_collector_add_dependency(self):\n        collector = Collector(using='default')\n        model = A\n        dependency = R\n\n        # Test adding a dependency\n        collector.add_dependency(model, dependency)\n        self.assertIn(dependency, collector.dependencies[model])\n\n        # Test adding the same dependency multiple times\n        collector.add_dependency(model, dependency)\n        self.assertEqual(len(collector.dependencies[model]), 1)\n\n        # Test adding a dependency with reverse_dependency=True\n        collector.add_dependency(model, dependency, reverse_dependency=True)\n        self.assertIn(model, collector.dependencies[dependency])\n", "    def test_collector_add_dependency_with_reverse_dependency(self):\n        # Test the Collector's add_dependency method with reverse_dependency=True\n        collector = Collector(using='default')\n        model = R\n        dependency = S\n        collector.add_dependency(model, dependency, reverse_dependency=True)\n        self.assertEqual(collector.dependencies[model._meta.concrete_model], {dependency._meta.concrete_model})\n", "    def test_can_fast_delete_with_reverse_one_to_one(self):\n        \"\"\"\n        Test that can_fast_delete() works correctly when a reverse one-to-one\n        relationship is involved.\n        \"\"\"\n        a = A.objects.create()\n        r = R.objects.create(a=a)\n        collector = Collector(using='default')\n        self.assertTrue(collector.can_fast_delete(r))\n        r.delete()\n        self.assertFalse(R.objects.filter(pk=r.pk).exists())\n        self.assertFalse(A.objects.filter(pk=a.pk).exists())\n", "def test_collector_can_fast_delete(self):\n    collector = Collector(using='default')\n    r = R.objects.create()\n    a = A.objects.create(r=r)\n    self.assertTrue(collector.can_fast_delete(a))\n    self.assertFalse(collector.can_fast_delete(r))\n\n    # Test that a model with a signal listener can't be fast deleted.\n        pass\n\n    models.signals.post_delete.connect(listener, sender=A)\n    self.assertFalse(collector.can_fast_delete(a))\n    models.signals.post_delete.disconnect(listener, sender=A)\n\n    # Test that a model with a generic relation can't be fast deleted.\n    a = A.objects.create(r=get_default_r())\n    a.m2m.add(M.objects.create())\n    self.assertFalse(collector.can_fast_delete(a))\n", "def test_add_dependency_reverse_dependency(self):\n    \"\"\"\n    Test that Collector.add_dependency() with reverse_dependency=True\n    correctly sets up the dependencies.\n    \"\"\"\n    collector = Collector(using='default')\n    model1 = R\n    model2 = S\n    collector.add_dependency(model1, model2, reverse_dependency=True)\n    self.assertEqual(collector.dependencies[model2._meta.concrete_model], {model1._meta.concrete_model})\n    self.assertEqual(collector.data, {model2: set(), model1: set()})\n"], "sample_71": ["def test_blacklisted_params():\n    original_value = 'gray'\n    mpl.rcParams[PARAM] = original_value\n    blacklisted_param = 'interactive'\n    with pytest.warns(mpl._api.MatplotlibDeprecationWarning):\n        with style.context({blacklisted_param: True, PARAM: VALUE}):\n            assert mpl.rcParams[PARAM] == VALUE\n            assert mpl.rcParams[blacklisted_param] != True\n    assert mpl.rcParams[PARAM] == original_value\n", "def test_use_invalid_path():\n    with pytest.raises(IOError):\n        style.use('/invalid/path/to/style.mplstyle')\n", "def test_context_after_reset():\n    # Test that the style is applied after resetting settings to their defaults.\n    original_value = 'gray'\n    other_value = 'blue'\n    mpl.rcParams[PARAM] = original_value\n    with temp_style('test', DUMMY_SETTINGS):\n        with style.context('test', after_reset=True):\n            assert mpl.rcParams[PARAM] == VALUE\n        # Check that this value is reset after the exiting the context.\n        assert mpl.rcParams[PARAM] == original_value\n", "def test_use_deprecated_style_name():\n    with pytest.warns(mpl._api.MatplotlibDeprecationWarning):\n        style.use('seaborn-bright')\n    assert mpl.rcParams['axes.prop_cycle'] == mpl.style.library['seaborn-v0_8-bright']['axes.prop_cycle']\n    with pytest.warns(mpl._api.MatplotlibDeprecationWarning):\n        style.use('seaborn')\n    assert mpl.rcParams['axes.prop_cycle'] == mpl.style.library['seaborn-v0_8']['axes.prop_cycle']\n", "def test_use_deprecated_style():\n    original_value = 'gray'\n    mpl.rcParams[PARAM] = original_value\n    with pytest.warns(mpl._api.MatplotlibDeprecationWarning):\n        with style.context('seaborn-bright'):\n            assert mpl.rcParams[PARAM] != VALUE\n    assert mpl.rcParams[PARAM] == original_value\n\n"], "sample_10": ["def test_in_bulk_lots_of_ids_with_field(self):\n    test_range = 2000\n    max_query_params = connection.features.max_query_params\n    expected_num_queries = ceil(test_range / max_query_params) if max_query_params else 1\n    authors = Author.objects.bulk_create([Author() for i in range(test_range - Author.objects.count())])\n    author_slugs = [f\"slug_{author.pk}\" for author in authors]\n    Author.objects.filter(id__in=[author.pk for author in authors]).update(slug=author_slugs)\n    with self.assertNumQueries(expected_num_queries):\n        self.assertEqual(\n            Author.objects.in_bulk([slug for slug in author_slugs], field_name='slug'),\n            {slug: author for slug, author in zip(author_slugs, authors)}\n        )\n", "def test_year_lookups(self):\n    # Create some articles with a date range spanning several years\n    for a in Article.objects.all():\n        a.delete()\n    Article.objects.bulk_create([\n        Article(pub_date=datetime(2005, 1, 1)),\n        Article(pub_date=datetime(2006, 6, 15)),\n        Article(pub_date=datetime(2006, 12, 31)),\n        Article(pub_date=datetime(2007, 1, 1)),\n        Article(pub_date=datetime(2007, 6, 15)),\n        Article(pub_date=datetime(2007, 12, 31)),\n    ])\n\n    # exact year lookup\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year=2006),\n        ['<Article: Article 2>', '<Article: Article 3>']\n    )\n\n    # gt year lookup\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gt=2006),\n        ['<Article: Article 4>', '<Article: Article 5>', '<Article: Article 6>']\n    )\n\n    # gte year lookup\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gte=2006),\n        ['<Article: Article 2>', '<Article: Article 3>', '<Article: Article 4>', '<Article: Article 5>', '<Article: Article 6>']\n    )\n\n    # lt year lookup\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lt=2006),\n        ['<Article: Article 1>']\n    )\n\n    # lte year lookup\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lte=2006),\n        ['<Article: Article 1>', '<Article: Article 2>', '<Article: Article 3>']\n    )\n", "def test_iexact_with_non_ascii(self):\n    \"\"\"\n    __iexact lookup with non-ASCII characters should work properly.\n    \"\"\"\n    a1 = Author.objects.create(name='\\u2660')\n    a2 = Author.objects.create(name='\\u2660')\n    self.assertEqual(Author.objects.filter(name__iexact=a1.name).count(), 2)\n", "def test_isnull_lookup_with_none_rhs(self):\n    season = Season.objects.create(year=2012, nulled_text_field=None)\n    self.assertTrue(Season.objects.filter(pk=season.pk, nulled_text_field__isnull=True))\n    self.assertTrue(Season.objects.filter(pk=season.pk, nulled_text_field__isnull=None))\n", "def test_lookup_transform_chaining(self):\n    # Test that transformations are applied in the correct order when using lookup chaining\n    a = Author.objects.create(name='John Smith', alias='Johx')\n    b = Author.objects.create(name='Rhonda Simpson', alias='sonx')\n    tests = (\n        ('startswith', 'iexact', [a]),\n        ('istartswith', 'iexact', [a]),\n        ('contains', 'iexact', [a, b]),\n        ('icontains', 'iexact', [a, b]),\n        ('endswith', 'iexact', [b]),\n        ('iendswith', 'iexact', [b]),\n    )\n    for lookup1, lookup2, result in tests:\n        with self.subTest(lookup1=lookup1, lookup2=lookup2):\n            authors = Author.objects.filter(**{'name__%s__%s' % (lookup1, lookup2): 'Johx'})\n            self.assertCountEqual(authors, result)\n"], "sample_25": ["def test_mti_inheritance_model_rename(self):\n    Animal = ModelState('app', 'Animal', [\n        (\"id\", models.AutoField(primary_key=True)),\n    ])\n    Dog = ModelState('app', 'Dog', [], bases=('app.Animal',))\n    Cat = ModelState('app', 'Cat', [], bases=('app.Animal',))\n    after = [\n        ModelState('app', 'Dog', [], bases=('app.Animal',)),\n        ModelState('app', 'Puppy', [], bases=('app.Animal',)),\n    ]\n    changes = self.get_changes([Animal, Dog, Cat], after, MigrationQuestioner({\"ask_rename_model\": True}))\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RenameModel', 'DeleteModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, old_name='Cat', new_name='Puppy')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='Dog')\n", "def test_alter_db_table_on_unmanaged_model(self):\n    \"\"\"Tests detection for changing db_table in model's options on unmanaged model.\"\"\"\n    changes = self.get_changes(\n        [self.author_unmanaged_managed, self.author_with_db_table_options],\n        [self.author_unmanaged, self.author_with_db_table_options],\n    )\n    # Right number of migrations?\n    self.assertEqual(len(changes), 0)\n", "def test_add_model_with_field_removed_from_base_model_withFK(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name and a ForeignKey to it.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=200)),\n            ('fk', models.ForeignKey('app.readable', models.CASCADE)),\n        ], bases=('app.readable',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n", "def test_renamed_field_with_altered_unique_together(self):\n    \"\"\"\n    Renamed field is not considered as added field in unique_together.\n    \"\"\"\n    before = [\n        ModelState('app', 'Model', [\n            ('id', models.AutoField(primary_key=True)),\n            ('field1', models.CharField(max_length=200)),\n            ('field2', models.CharField(max_length=200)),\n        ], options={'unique_together': {('field1', 'field2')}}),\n    ]\n    after = [\n        ModelState('app', 'Model', [\n            ('id', models.AutoField(primary_key=True)),\n            ('renamed_field1', models.CharField(max_length=200)),\n            ('field2', models.CharField(max_length=200)),\n        ], options={'unique_together': {('renamed_field1', 'field2')}}),\n    ]\n    changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"app\", 1)\n    self.assertOperationTypes(changes, \"app\", 0, [\"RenameField\", \"AlterUniqueTogether\"])\n    self.assertOperationAttributes(changes, \"app\", 0, 0, model_name=\"model\", old_name=\"field1\", new_name=\"renamed_field1\")\n    self.assertOperationAttributes(changes, \"app\", 0, 1, name=\"model\", unique_together={(\"renamed_field1\", \"field2\")})\n", "def test_alter_model_managers_with_inherited(self):\n    \"\"\"\n    #24267 - AlterModelManagers handles inherited managers.\n    \"\"\"\n    manager = FoodManager('a', 'b')\n    manager_inherited = FoodManager('c', 'd', 1, 2)\n    changes = self.get_changes(\n        [self.author_empty],\n        [\n            ModelState(\n                \"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True))],\n                managers=[(\"food_qs\", FoodQuerySet.as_manager()), (\"food_mgr\", manager)],\n            ),\n            ModelState(\n                \"testapp\", \"Publisher\", [(\"id\", models.AutoField(primary_key=True))],\n                managers=[(\"food_qs\", FoodQuerySet.as_manager()), (\"food_mgr\", manager_inherited)],\n                bases=(\"testapp.author\",),\n            ),\n        ],\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"CreateModel\", \"CreateModel\", \"AlterModelManagers\", \"AlterModelManagers\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"Author\")\n    self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"Publisher\")\n    self.assertEqual([name for name, mgr in changes['testapp'][0].operations[2].managers],\n                     ['food_qs', 'food_mgr'])\n    self.assertEqual(changes['testapp'][0].operations[2].managers[1][1].args, ('a', 'b', 1, 2))\n    self.assertEqual([name for name, mgr in changes['testapp'][0].operations[3].managers],\n                     ['food_qs', 'food_mgr'])\n    self.assertEqual(changes['testapp'][0].operations[3].managers[1][1].args, ('c', 'd', 1, 2))\n"], "sample_9": ["    def test_error_files_are_returned(self):\n        filename = Path('test_module.py')\n        self.assertFileFound(filename)\n", "    def test_echo_enabled(self, mocked_termios):\n        mocked_termios.tcgetattr.return_value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n        with mock.patch('sys.stdin.isatty', return_value=True):\n            autoreload.ensure_echo_on()\n        mocked_termios.tcsetattr.assert_not_called()\n", "    def test_empty_path_list(self):\n        self.assertEqual(autoreload.common_roots(()), ())\n", "    def test_raises_exception_with_context(self):\n        try:\n            raise Exception(2)\n        except Exception as e:\n            try:\n                raise Exception(1) from e\n            except Exception as f:\n                exc_info = sys.exc_info()\n\n        with mock.patch('django.utils.autoreload._exception', exc_info):\n            with self.assertRaises(Exception) as cm:\n                autoreload.raise_last_exception()\n            self.assertEqual(cm.exception.args[0], 1)\n            self.assertEqual(cm.exception.__cause__.args[0], 2)\n\n            self.assertEqual(autoreload._exception, None)\n", "    def test_request_processed_signal_is_connected(self):\n        # Ensure the request_processed signal is connected when WatchmanReloader.tick() is called.\n        with mock.patch('django.core.signals.request_finished.connect') as mocked_connect:\n            self.reloader.tick()\n            self.assertEqual(mocked_connect.call_count, 1)\n            self.assertSequenceEqual(\n                mocked_connect.call_args[0],\n                [self.reloader.request_processed]\n            )\n"], "sample_96": ["def test_ridge_regression_large_alpha():\n    # Test ridge regression for a large alpha value.\n    rng = np.random.RandomState(0)\n    alpha = 1e15\n\n    for solver in (\"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\"):\n        # With more samples than features\n        n_samples, n_features = 6, 5\n        y = rng.randn(n_samples)\n        X = rng.randn(n_samples, n_features)\n\n        ridge = Ridge(alpha=alpha, solver=solver)\n        ridge.fit(X, y)\n\n        # Check that coefficients are very close to zero\n        assert_array_almost_equal(ridge.coef_, np.zeros(n_features), decimal=4)\n\n        # With more features than samples\n        n_samples, n_features = 5, 10\n        y = rng.randn(n_samples)\n        X = rng.randn(n_samples, n_features)\n\n        ridge = Ridge(alpha=alpha, solver=solver)\n        ridge.fit(X, y)\n\n        # Check that coefficients are very close to zero\n        assert_array_almost_equal(ridge.coef_, np.zeros(n_features), decimal=4)\n", "def test_ridge_regression_solvers():\n    # Test different solvers for ridge regression.\n    rng = np.random.RandomState(0)\n\n    for solver in (\"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"):\n        n_samples, n_features = 6, 5\n        y = rng.randn(n_samples)\n        X = rng.randn(n_samples, n_features)\n        alpha = 1.0\n\n        ridge = Ridge(alpha=alpha, solver=solver)\n        ridge.fit(X, y)\n        coef = ridge.coef_\n\n        if solver != \"sag\" and solver != \"saga\":\n            # Closed form of the regularized least square\n            # theta = (X^T X + alpha I)^(-1) * X^T y\n            cf_coef = linalg.solve(X.T.dot(X) + alpha * np.eye(n_features),\n                                   X.T.dot(y))\n            assert_array_almost_equal(coef, cf_coef)\n\n        ridge.fit(X, y)\n        assert_greater(ridge.score(X, y), 0.0)\n", "def test_ridge_solver_change():\n    # Test solver is changed from 'lsqr' to 'sparse_cg' when sample_weight is provided.\n    X = np.array([[1.0, 2.0], [2.0, 3.0]])\n    y = np.array([1.0, 2.0])\n\n    # No sample weights\n    ridge = Ridge(alpha=1.0, solver='lsqr', fit_intercept=False)\n    assert_true(ridge.solver == 'lsqr')\n    ridge.fit(X, y)\n    assert_true(ridge.solver == 'lsqr')\n\n    # With sample weights\n    sample_weight = np.array([1.0, 2.0])\n    ridge = Ridge(alpha=1.0, solver='lsqr', fit_intercept=False)\n    assert_true(ridge.solver == 'lsqr')\n    ridge.fit(X, y, sample_weight=sample_weight)\n    assert_true(ridge.solver == 'sparse_cg')\n", "def test_ridge_solver_cv():\n    # Test that RidgeCV correctly chooses the best solver for the given data\n    rng = np.random.RandomState(0)\n    X, y = make_regression(n_samples=100, n_features=10, random_state=rng)\n    X_sparse = sp.csr_matrix(X)\n    X_dense = X.toarray()\n\n    # Test with default solver\n    ridge_cv = RidgeCV()\n    ridge_cv.fit(X_dense, y)\n    assert ridge_cv.best_estimator_.solver in [\"cholesky\", \"sparse_cg\"]\n    ridge_cv.fit(X_sparse, y)\n    assert ridge_cv.best_estimator_.solver in [\"cholesky\", \"sparse_cg\"]\n\n    # Test with solver='auto'\n    ridge_cv = RidgeCV(solver='auto')\n    ridge_cv.fit(X_dense, y)\n    assert ridge_cv.best_estimator_.solver in [\"cholesky\", \"sparse_cg\"]\n    ridge_cv.fit(X_sparse, y)\n    assert ridge_cv.best_estimator_.solver in [\"cholesky\", \"sparse_cg\"]\n\n    # Test with solver='svd'\n    ridge_cv = RidgeCV(solver='svd')\n    ridge_cv.fit(X_dense, y)\n    assert ridge_cv.best_estimator_.solver == \"svd\"\n    assert_raises(TypeError, ridge_cv.fit, X_sparse, y)\n\n    # Test with solver='cholesky'\n    ridge_cv = RidgeCV(solver='cholesky')\n    ridge_cv.fit(X_dense, y)\n    assert ridge_cv.best_estimator_.solver == \"cholesky\"\n    ridge_cv.fit(X_sparse, y)\n    assert ridge_cv.best_estimator_.solver == \"cholesky\"\n\n    # Test with solver='lsqr'\n    ridge_cv = RidgeCV(solver='lsqr')\n    ridge_cv.fit(X_dense, y)\n    assert ridge_cv.best_estimator_.solver == \"lsqr\"\n    ridge_cv.fit(X_sparse, y)\n    assert ridge_cv.best_estimator_.solver == \"lsqr\"\n\n    # Test with solver='sparse_cg'\n    ridge_cv = RidgeCV(solver='sparse_cg')\n    ridge_cv.fit(X_dense, y)\n    assert ridge_cv.best_estimator_.solver == \"sparse_cg\"\n    ridge_cv.fit(X_sparse, y)\n    assert ridge_cv.best_estimator_.solver == \"sparse_cg\"\n\n    # Test with solver='sag' or 'saga'\n    ridge_cv = RidgeCV(solver='sag')\n    ridge_cv.fit(X_dense, y)\n    assert ridge_cv", "def test_ridge_regression_error():\n    # Test Ridge regression error handling.\n    X, y = make_regression(n_samples=10, n_features=5, random_state=0)\n\n    # Test that Ridge regression raises an error when `alpha` is negative.\n    ridge = Ridge(alpha=-1.0)\n    assert_raise_message(ValueError, \"Regularization strength must be a positive\"\n                             \" float. Got alpha=-1.0\", ridge.fit, X, y)\n\n    # Test that Ridge regression raises an error when `alpha` is a negative array.\n    ridge = Ridge(alpha=[-1.0, 1.0])\n    assert_raise_message(ValueError, \"Regularization strength must be a positive\"\n                             \" float. Got alpha=[-1.  1.]\", ridge.fit, X, y)\n\n    # Test that Ridge regression raises an error when `solver` is not supported.\n    ridge = Ridge(solver='unsupported_solver')\n    assert_raise_message(ValueError, \"Solver unsupported_solver not understood\",\n                        ridge.fit, X, y)\n\n    # Test that Ridge regression raises an error when `fit_intercept` is not a boolean.\n    ridge = Ridge(fit_intercept='not_boolean')\n    assert_raise_message(TypeError, \"fit_intercept must be a boolean\", ridge.fit, X, y)\n\n    # Test that Ridge regression raises an error when `normalize` is not a boolean.\n    ridge = Ridge(normalize='not_boolean')\n    assert_raise_message(TypeError, \"normalize must be a boolean\", ridge.fit, X, y)\n\n    # Test that Ridge regression raises an error when `max_iter` is not an integer.\n    ridge = Ridge(max_iter='not_integer')\n    assert_raise_message(TypeError, \"max_iter should be an integer\", ridge.fit, X, y)\n\n    # Test that Ridge regression raises an error when `tol` is not a float.\n    ridge = Ridge(tol='not_float')\n    assert_raise_message(TypeError, \"tol must be a float\", ridge.fit, X, y)\n\n    # Test that Ridge regression raises an error when `random_state` is not an integer or RandomState instance.\n    ridge = Ridge(random_state='not_integer_or_randomstate')\n    assert_raise_message(TypeError, \"random_state should be an integer or an\"\n                             \" instance of RandomState\", ridge.fit, X, y)\n"], "sample_94": ["def test_getstatementrange_with_trailing_newlines() -> None:\n    source = Source(\n        \"\"\"\\", "def test_getstatementrange_multiline_string() -> None:\n    source = Source(\n        \"\"\"\\\n        s = '''\n            hello\n            world\n            '''\n        \"\"\"\n    )\n    assert len(source) == 4\n    assert source.getstatementrange(0) == (0, 4)\n    assert source.getstatementrange(1) == (0, 4)\n    assert source.getstatementrange(2) == (0, 4)\n    assert source.getstatementrange(3) == (0, 4)\n", "def test_getstatementrange_with_nested_blocks() -> None:\n    source = Source(\n        \"\"\"\\\n        if True:\n            try:\n                if False:\n                    pass\n            finally:\n                pass\n    \"\"\"\n    )\n    assert source.getstatementrange(0) == (0, 6)\n    assert source.getstatementrange(1) == (1, 6)\n    assert source.getstatementrange(2) == (2, 3)\n    assert source.getstatementrange(3) == (3, 4)\n    assert source.getstatementrange(4) == (4, 5)\n    assert source.getstatementrange(5) == (5, 6)\n", "def test_getstatementrange_ast_trailing_newlines() -> None:\n    source = Source(\n        \"\"\"\\", "def test_source_deindent() -> None:\n    source = Source(\n        \"\"\"\n                return 42\n        \"\"\"\n    )\n    deindented = source.deindent()\n    assert deindented.lines == [\"def test_deindent():\", \"    return 42\"]\n"], "sample_0": ["    def test_multilingual_support(self):\n        with translation.override('fr'):\n            beatles = Band.objects.create(name='Les Beatles', style='rock')\n            who = Band.objects.create(name='The Who', style='rock')\n            # With 'band', a ForeignKey.\n            form = AlbumForm(initial={'band': beatles.pk})\n            output = form.as_table()\n            selected_option = '<option value=\"%s\" selected>Les Beatles</option>' % beatles.pk\n            option = '<option value=\"%s\">The Who</option>' % who.pk\n            self.assertIn(selected_option, output)\n            self.assertNotIn(option, output)\n            # With 'featuring', a ManyToManyField.\n            form = AlbumForm(initial={'featuring': [beatles.pk, who.pk]})\n            output = form.as_table()\n            selected_option = '<option value=\"%s\" selected>Les Beatles</option>' % beatles.pk\n            option = '<option value=\"%s\" selected>The Who</option>' % who.pk\n            self.assertIn(selected_option, output)\n            self.assertIn(option, output)\n", "def test_Media_merge(self):\n    media1 = Media(js=['script1.js', 'script2.js'])\n    media2 = Media(js=['script3.js', 'script2.js'])\n    merged_media = media1 + media2\n    self.assertEqual(merged_media._js, ['script1.js', 'script2.js', 'script3.js'])\n    with self.assertWarns(MediaOrderConflictWarning):\n        media1 = Media(js=['script1.js', 'script3.js'])\n        media2 = Media(js=['script3.js', 'script1.js'])\n        merged_media = media1 + media2\n        self.assertEqual(merged_media._js, ['script1.js', 'script3.js'])\n", "def test_render_options_with_empty_label(self):\n    \"\"\"Empty option's label is customizable.\"\"\"\n    beatles = Band.objects.create(name='The Beatles', style='rock')\n    who = Band.objects.create(name='The Who', style='rock')\n    form = NotRequiredBandForm()\n    form.fields['band'].empty_label = 'Select a band'\n    output = form.as_table()\n    self.assertIn('<option value=\"\">Select a band</option>', output)\n", "    def test_value_from_datadict_clearable_file_input(self):\n        form = forms.Form()\n        widget = ClearableFileInput()\n        data = {'file': 'new_file.txt'}\n        files = {'file': 'file_content'}\n        name = 'file'\n        self.assertEqual(widget.value_from_datadict(data, files, name), files[name])\n\n        # Test when checkbox is checked.\n        data[name + '-clear'] = True\n        self.assertEqual(widget.value_from_datadict(data, files, name), False)\n\n        # Test when checkbox is checked and file is uploaded.\n        self.assertEqual(widget.value_from_datadict(data, files, name), FILE_INPUT_CONTRADICTION)\n", "    def test_render_options_with_custom_empty_label(self):\n        class AlbumForm(forms.ModelForm):\n            class Meta:\n                model = Album\n                fields = ['band']\n                widgets = {\n                    'band': AutocompleteSelect(\n                        Album._meta.get_field('band').remote_field,\n                        admin.site,\n                        attrs={'class': 'my-class'},\n                        empty_label='Select band',\n                    ),\n                }\n\n        beatles = Band.objects.create(name='The Beatles', style='rock')\n        who = Band.objects.create(name='The Who', style='rock')\n        form = AlbumForm(initial={'band': beatles.pk})\n        output = form.as_table()\n        selected_option = '<option value=\"%s\" selected>The Beatles</option>' % beatles.pk\n        option = '<option value=\"%s\">The Who</option>' % who.pk\n        custom_empty_option = '<option value=\"\">Select band</option>'\n        self.assertIn(selected_option, output)\n        self.assertIn(option, output)\n        self.assertIn(custom_empty_option, output)\n"], "sample_27": ["def test_make_token_with_timestamp(self):\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    now = datetime.now()\n    timestamp = p0._num_seconds(now)\n    token = p0._make_token_with_timestamp(user, timestamp)\n    self.assertIs(p0.check_token(user, token), True)\n    # Test with a different timestamp.\n    different_timestamp = timestamp + 100\n    different_token = p0._make_token_with_timestamp(user, different_timestamp)\n    self.assertNotEqual(token, different_token)\n    self.assertIs(p0.check_token(user, different_token), True)\n    # Test with a legacy token.\n    legacy_token = p0._make_token_with_timestamp(user, timestamp, legacy=True)\n    self.assertIs(p0.check_token(user, legacy_token), True)\n    # Test with an invalid timestamp.\n    invalid_timestamp = -100\n    invalid_token = p0._make_token_with_timestamp(user, invalid_timestamp)\n    self.assertIs(p0.check_token(user, invalid_token), False)\n", "def test_make_hash_value(self):\n    \"\"\"\n    Test _make_hash_value method of PasswordResetTokenGenerator.\n    \"\"\"\n    user = User.objects.create_user('testuser', 'test@example.com', 'testpw')\n    timestamp = self._num_seconds(datetime.now())\n    last_login = datetime.now()\n    user.last_login = last_login\n    hash_value = self._make_hash_value(user, timestamp)\n    self.assertIn(str(user.pk), hash_value)\n    self.assertIn(user.password, hash_value)\n    self.assertIn(str(last_login.replace(microsecond=0, tzinfo=None)), hash_value)\n    self.assertIn(str(timestamp), hash_value)\n    self.assertIn(user.email, hash_value)\n\n    # Test with user without last_login\n    user.last_login = None\n    hash_value = self._make_hash_value(user, timestamp)\n    self.assertIn(str(user.pk), hash_value)\n    self.assertIn(user.password, hash_value)\n    self.assertIn('', hash_value)\n    self.assertIn(str(timestamp), hash_value)\n    self.assertIn(user.email, hash_value)\n", "    def test_make_token_with_legacy_hashing_algorithm(self):\n        \"\"\"\n        Test that the token is generated correctly when the legacy hashing algorithm is used.\n        \"\"\"\n        user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n        with self.settings(DEFAULT_HASHING_ALGORITHM='sha1'):\n            p0 = PasswordResetTokenGenerator()\n            p0.algorithm = 'sha1'\n            tk0 = p0.make_token(user)\n            self.assertIs(p0.check_token(user, tk0), True)\n\n        with self.settings(DEFAULT_HASHING_ALGORITHM='sha256'):\n            p1 = PasswordResetTokenGenerator()\n            tk1 = p1.make_token(user)\n            self.assertIs(p1.check_token(user, tk0), False)\n            p1.algorithm = 'sha1'\n            tk2 = p1.make_token(user)\n            self.assertIs(p1.check_token(user, tk2), True)\n", "    def test_make_token_with_timestamp(self):\n        \"\"\"\n        Test _make_token_with_timestamp with different inputs.\n        \"\"\"\n        user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n        p0 = PasswordResetTokenGenerator()\n        timestamp = p0._num_seconds(p0._now())\n        token = p0._make_token_with_timestamp(user, timestamp)\n        # Test legacy=False\n        self.assertEqual(len(token), 34)  # 6 digits for timestamp + 28 for hash\n        # Test legacy=True\n        token_legacy = p0._make_token_with_timestamp(user, timestamp, legacy=True)\n        self.assertEqual(len(token_legacy), 34)  # 6 digits for timestamp + 28 for hash\n        # Test different algorithm\n        p0.algorithm = 'sha256'\n        token_sha256 = p0._make_token_with_timestamp(user, timestamp)\n        self.assertEqual(len(token_sha256), 34)  # 6 digits for timestamp + 28 for hash\n        # Test different secret\n        p0.secret = 'new_secret'\n        token_new_secret = p0._make_token_with_timestamp(user, timestamp)\n        self.assertEqual(len(token_new_secret), 34)  # 6 digits for timestamp + 28 for hash\n", "def test_token_with_legacy_hashing_algorithm(self):\n    \"\"\"\n    A valid token created with the legacy hashing algorithm can be checked.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    generator = PasswordResetTokenGenerator()\n    generator.algorithm = 'sha256'\n    token = generator.make_token(user)\n    # Check with the legacy hashing algorithm (sha1)\n    with self.settings(DEFAULT_HASHING_ALGORITHM='sha1'):\n        legacy_generator = PasswordResetTokenGenerator()\n        self.assertIs(legacy_generator.check_token(user, token), True)\n"], "sample_145": ["def test_latex_doubleendedarrow():\n    expr = Eq(x, 2)\n    assert latex(expr) == r\"x = 2\"\n    assert latex(expr, itex=True) == r\"x = 2\"\n\n    expr = Eq(x, 2, relational=False)\n    assert latex(expr) == r\"x \\Leftrightarrow 2\"\n    assert latex(expr, itex=True) == r\"x \\Leftrightarrow 2\"\n", "def test_custom_conjugate():\n    a = symbols('a', real=True)\n    b = symbols('b', real=False)\n\n    assert latex(conjugate(a)) == r\"a\"\n    assert latex(conjugate(b)) == r\"\\overline{b}\"\n    assert latex(conjugate(a + b)) == r\"\\overline{a + b}\"\n    assert latex(conjugate(a + I)) == r\"a - i\"\n    assert latex(conjugate(b + I)) == r\"\\overline{b} - i\"\n    assert latex(conjugate(a + I + b)) == r\"\\overline{a + b} - i\"\n", "def test_latex_PartialDerivative():\n    # issue 12323\n    f, g = symbols('f g', cls=Function)\n    x, y, z = symbols('x y z')\n\n    assert latex(PartialDerivative(f(x, y), x, y)) == r\"\\frac{\\partial^{2}}{\\partial y\\partial x} f{\\left(x, y \\right)}\"\n    assert latex(PartialDerivative(f(x, y, z), x, z)) == r\"\\frac{\\partial^{2}}{\\partial z\\partial x} f{\\left(x, y, z \\right)}\"\n    assert latex(PartialDerivative(f(x, y, z), x, z, 2)) == r\"\\frac{\\partial^{3}}{\\partial z^{2}\\partial x} f{\\left(x, y, z \\right)}\"\n    assert latex(PartialDerivative(f(x, y, z), x, z, 2, y, 3)) == r\"\\frac{\\partial^{6}}{\\partial y^{3}\\partial z^{2}\\partial x} f{\\left(x, y, z \\right)}\"\n    assert latex(PartialDerivative(g(f(x, y), y, z), x, y, z)) == r\"\\frac{\\partial^{3}}{\\partial z\\partial y\\partial x} g{\\left(f{\\left(x, y \\right)}, y, z \\right)}\"\n", "def test_latex_AccumBounds():\n    from sympy import symbols, S\n    a, b, c, d = symbols('a b c d', real=True)\n\n    # issue 18600\n    assert latex(S.EmptySet) == r\"\\emptyset\"\n    assert latex(AccumBounds(a, S.EmptySet)) == r\"\\left\\langle a, \\emptyset\\right\\rangle\"\n    assert latex(AccumBounds(a, S.EmptySet).atoms(AccumBounds)) == r\"\\left\\{ \\left\\langle a, \\emptyset\\right\\rangle \\right\\}\"\n    assert latex(AccumBounds(S.EmptySet, b)) == r\"\\left\\langle \\emptyset, b\\right\\rangle\"\n    assert latex(AccumBounds(S.EmptySet, b).atoms(AccumBounds)) == r\"\\left\\{ \\left\\langle \\emptyset, b\\right\\rangle \\right\\}\"\n    assert latex(AccumBounds(a, b)) == r\"\\left\\langle a, b\\right\\rangle\"\n    assert latex(AccumBounds(a, b).atoms(AccumBounds)) == r\"\\left\\{ \\left\\langle a, b\\right\\rangle \\right\\}\"\n", "def test_differential_geometry():\n    from sympy.diffgeom import Manifold, Patch, CoordSystem, BaseScalarField, \\\n        BaseVectorField, TensorProduct, TensorField, Commutator, LieDerivative, \\\n        CovarDerivativeOp, grad_orthogonal, metric_to_CR_matrix\n    from sympy.diffgeom.rn import R2, R2_p, R2_r, RN, RN_p, RN_r\n    from sympy import symbols, Function, Eq, sin, cos, sqrt\n\n    x, y = symbols('x y', real=True)\n    r, theta = symbols('r theta', real=True)\n\n    # Manifold\n    M = Manifold('M', 2)\n    assert latex(M) == r'\\text{M}'\n\n    # Patch\n    P = Patch('P', M)\n    assert latex(P) == r'\\text{P}_{\\text{M}}'\n\n    # CoordSystem\n    rect = CoordSystem('rect', P, [x, y])\n    assert latex(rect) == r'\\text{rect}^{\\text{P}}_{\\text{M}}'\n\n    polar = CoordSystem('polar', P, [r, theta])\n    assert latex(polar) == r'\\text{polar}^{\\text{P}}_{\\text{M}}'\n\n    # BaseScalarField\n    f = Function('f')\n    f_r = f(R2_r.x, R2_r.y)\n    assert latex(f_r) == r'f{\\left(\\mathbf{x},\\mathbf{y} \\right)}'\n\n    f_p = f(R2_p.r, R2_p.theta)\n    assert latex(f_p) == r'f{\\left(r,\\theta \\right)}'\n\n    f_rect = BaseScalarField(rect, f_r)\n    assert latex(f_rect) == r'f{\\left(\\mathbf{x},\\mathbf{y} \\right)}'\n\n    f_polar = BaseScalarField(polar, f_p)\n    assert latex(f_polar) == r'f{\\left(r,\\theta \\right)}'\n\n    # BaseVectorField\n    v = Function('v')\n    v_r = v(R2_r.x, R2_r.y)\n    assert latex(v_r) == r'v{\\left(\\mathbf{x},\\mathbf{y} \\right)}'\n\n    v_p = v(R2_p.r,"], "sample_1": ["def test_read_write_err_specs(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3]))\n    t1.add_column(Column(name=\"a_err\", data=[0.1, 0.2, 0.3]))\n    t1.add_column(Column(name=\"b\", data=[4, 5, 6]))\n    t1.add_column(Column(name=\"b_perr\", data=[0.1, 0.2, 0.3]))\n    t1.add_column(Column(name=\"b_nerr\", data=[-0.1, -0.2, -0.3]))\n    t1.write(test_file, format=\"ascii.qdp\")\n\n    t2 = Table.read(test_file, format=\"ascii.qdp\", names=[\"a\", \"b\"])\n\n    assert np.allclose(t2[\"a\"], t1[\"a\"])\n    assert np.allclose(t2[\"a_err\"], t1[\"a_err\"])\n    assert np.allclose(t2[\"b\"], t1[\"b\"])\n    assert np.allclose(t2[\"b_perr\"], t1[\"b_perr\"])\n    assert np.allclose(t2[\"b_nerr\"], t1[\"b_nerr\"])\n", "def test_understand_err_col():\n    with pytest.raises(ValueError):\n        _understand_err_col([\"a\", \"a_nerr\"])\n    with pytest.raises(ValueError):\n        _understand_err_col([\"a\", \"a_perr\"])\n    assert _understand_err_col([\"a\", \"a_err\", \"b\", \"b_perr\", \"b_nerr\"]) == ([1], [2])\n", "def test_read_write_table_with_err_specs(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3, 4]))\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0, 1.0], name=\"b\", mask=[False, False, False, True]\n        )\n    )\n    t1.write(test_file, format=\"ascii.qdp\", err_specs={\"terr\": [1]})\n    t2 = Table.read(test_file, format=\"ascii.qdp\", table_id=0, names=[\"a\", \"b\"])\n\n    assert np.allclose(t2[\"a\"], t1[\"a\"])\n    assert np.allclose(t2[\"b\"], t1[\"b\"], equal_nan=True)\n    assert np.allclose(t2[\"a_perr\"], np.zeros(4))\n    assert np.allclose(t2[\"a_nerr\"], np.zeros(4))\n", "def test_read_example_err_specs():\n    example_qdp = \"\"\"\n        ! Initial comment line 1\n        ! Initial comment line 2\n        READ TERR 1\n        READ SERR 3\n        ! Table 0 comment\n        !a a(pos) a(neg) b c ce d\n        53000.5   0.25  -0.5   1  1.5  3.5 2\n        54000.5   1.25  -1.5   2  2.5  4.5 3\n        NO NO NO NO NO\n        ! Table 1 comment\n        !a a(pos) a(neg) b c ce d\n        54000.5   2.25  -2.5   NO  3.5  5.5 5\n        55000.5   3.25  -3.5   4  4.5  6.5 nan\n        \"\"\"\n    dat = ascii.read(example_qdp, format=\"qdp\", table_id=0, names=[\"a\", \"b\", \"c\", \"d\"])\n    t = Table.read(\n        example_qdp, format=\"ascii.qdp\", table_id=0, names=[\"a\", \"b\", \"c\", \"d\"]\n    )\n\n    assert np.allclose(t[\"a\"], [53000.5, 54000.5])\n    assert t[\"a_nerr\"][0] == -0.5\n    assert np.ma.is_masked(t[\"b\"][0])\n    assert np.isnan(t[\"d\"][1])\n\n    for col1, col2 in zip(t.itercols(), dat.itercols()):\n        assert np.allclose(col1, col2, equal_nan=True)\n\n    # Test with incorrect number of data columns\n    with pytest.raises(ValueError):\n        Table.read(example_qdp, format=\"ascii.qdp\", table_id=0, names=[\"a\", \"b\"])\n\n    # Test with incorrect number of error columns\n    with pytest.raises(ValueError):\n        Table.read(example_qdp, format=\"ascii.qdp\", table_id=0, names=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\"])\n", "def test_understand_err_col():\n    colnames = ['a', 'a_err', 'b', 'b_perr', 'b_nerr', 'c']\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [0])\n    assert np.allclose(terr, [1])\n\n    colnames = ['a', 'a_perr', 'a_nerr']\n    with pytest.raises(ValueError) as excinfo:\n        _understand_err_col(colnames)\n    assert \"Missing symmetric\" in str(excinfo.value)\n\n    colnames = ['a', 'a_perr', 'a_nerr', 'b', 'c']\n    with pytest.raises(ValueError) as excinfo:\n        _understand_err_col(colnames)\n    assert \"Missing symmetric\" in str(excinfo.value)\n\n    colnames = ['a', 'b', 'b_err']\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [1])\n    assert np.allclose(terr, [])\n\n    colnames = ['a', 'a_perr', 'b', 'b_nerr']\n    with pytest.raises(ValueError) as excinfo:\n        _understand_err_col(colnames)\n    assert \"Missing negative\" in str(excinfo.value)\n\n    colnames = ['a', 'a_nerr', 'b', 'b_perr']\n    with pytest.raises(ValueError) as excinfo:\n        _understand_err_col(colnames)\n    assert \"Missing positive\" in str(excinfo.value)\n\n    colnames = ['a', 'b', 'c']\n    serr, terr = _understand_err_col(colnames)\n    assert serr == []\n    assert terr == []\n\n    colnames = ['a', 'a_err', 'b_err', 'c', 'd']\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [0, 1])\n    assert np.allclose(terr, [])\n\n    colnames = ['a', 'a_err', 'b', 'b_perr', 'b_nerr', 'c', 'c_err']\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [0, 4])\n    assert np.allclose(terr, [1])\n\n    colnames = ['a', 'a_perr', 'a_nerr', 'b', 'b_err', 'c']\n"], "sample_156": ["def test_parse_mathematica_edge_cases():\n    parser = MathematicaParser()\n\n    # Test parsing of Mathematica expressions with implicit multiplication\n    assert parser.parse(\"2x\") == 2*x\n    assert parser.parse(\"2 x\") == 2*x\n    assert parser.parse(\"x 2\") == 2*x\n    assert parser.parse(\"2.5x\") == 2.5*x\n    assert parser.parse(\"2.5 x\") == 2.5*x\n    assert parser.parse(\"x 2.5\") == 2.5*x\n\n    # Test parsing of Mathematica expressions with implicit multiplication and addition\n    assert parser.parse(\"2x + 3y\") == 2*x + 3*y\n    assert parser.parse(\"2 x + 3 y\") == 2*x + 3*y\n    assert parser.parse(\"x 2 + y 3\") == 2*x + 3*y\n\n    # Test parsing of Mathematica expressions with nested implicit multiplication\n    assert parser.parse(\"2(3x)\") == 6*x\n    assert parser.parse(\"2(3 x)\") == 6*x\n    assert parser.parse(\"(2 3)x\") == 6*x\n    assert parser.parse(\"(2 3) x\") == 6*x\n    assert parser.parse(\"2 (3 x)\") == 6*x\n\n    # Test parsing of Mathematica expressions with implicit multiplication and exponentiation\n    assert parser.parse(\"2x^2\") == 2*x**2\n    assert parser.parse(\"2 x^2\") == 2*x**2\n    assert parser.parse(\"x 2^2\") == 4*x\n    assert parser.parse(\"2.5x^2\") == 2.5*x**2\n    assert parser.parse(\"2.5 x^2\") == 2.5*x**2\n    assert parser.parse(\"x 2.5^2\") == 6.25*x\n\n    # Test parsing of Mathematica expressions with implicit multiplication, addition, and exponentiation\n    assert parser.parse(\"2x^2 + 3y^2\") == 2*x**2 + 3*y**2\n    assert parser.parse(\"2 x^2 + 3 y^2\") == 2*x**2 + 3*y**2\n    assert parser.parse(\"x 2^2 + y 3^2\") == ", "def test_parse_mathematica_functions():\n    # Test parsing of Mathematica functions\n    assert parse_mathematica(\"f[x] := x^2\") == Function(\"f\")(x**2)\n    assert parse_mathematica(\"f[x_, y_] := x + y\") == Function(\"f\")(x + y)\n    assert parse_mathematica(\"f[x_List] := x\") == Function(\"f\")(x)\n\n    # Test parsing of Mathematica functions with conditional expressions\n    assert parse_mathematica(\"f[x_] := x^2 /; x > 0\") == Function(\"f\")(x**2, condition=x > 0)\n\n    # Test parsing of Mathematica functions with PatternTest\n    assert parse_mathematica(\"f[x_?Positive] := x^2\") == Function(\"f\")(x**2, condition=x > 0)\n\n    # Test parsing of Mathematica functions with BlankSequence\n    assert parse_mathematica(\"f[x__] := {x}\") == Function(\"f\")(*x)\n\n    # Test parsing of Mathematica functions with BlankNullSequence\n    assert parse_mathematica(\"f[x___] := {x}\") == Function(\"f\")(*x)\n\n    # Test parsing of Mathematica functions with Optional\n    assert parse_mathematica(\"f[x_:1] := x\") == Function(\"f\")(x, default=1)\n", "def test_parse_mathematica_function():\n    assert parse_mathematica(\"F[x_]:=x^3/;x>0\") == parse_mathematica(\"SetDelayed(F(Pattern(x, Blank())), Condition(x**3, x > 0))\")\n    assert parse_mathematica(\"f[x_]:=f[x-1]/;x>0\") == parse_mathematica(\"SetDelayed(f(Pattern(x, Blank())), Condition(f(x-1), x > 0))\")\n    assert parse_mathematica(\"F[x_?Positive]:=x^3\") == parse_mathematica(\"SetDelayed(F(Pattern(x, Condition(Pattern(x, Blank()), Positive))), x**3)\")\n    assert parse_mathematica(\"f[x_?IntegerQ]:=x^3\") == parse_mathematica(\"SetDelayed(f(Pattern(x, Condition(Pattern(x, Blank()), IntegerQ))), x**3)\")\n    assert parse_mathematica(\"g[x_,y_]:=x+y\") == parse_mathematica(\"SetDelayed(g(Pattern(x, Blank()), Pattern(y, Blank())), x + y)\")\n    assert parse_mathematica(\"h[x_,y_,z_]:=x+y+z\") == parse_mathematica(\"SetDelayed(h(Pattern(x, Blank()), Pattern(y, Blank()), Pattern(z, Blank())), x + y + z)\")\n", "def test_additional_mathematica():\n    d = {\n        \"Max[1, -2, 3, -4, 5]\": \"Max(1, -2, 3, -4, 5)\",\n        \"Min[1, 2, 3, 4]\": \"Min(1, 2, 3, 4)\",\n        \"Mod[17, 5, 7]\": \"Mod(Mod(17, 5), 7)\",\n        \"Pochhammer[x, y, z]\": \"rf(x, y, z)\",\n        \"ExpIntegralEi[5, 3]\": \"Ei(5, 3)\",\n        \"AiryAiPrime[2, 5]\": \"airyaiprime(2, 5)\",\n        \"AiryBiPrime[2, 5]\": \"airybiprime(2, 5)\",\n        \"LogIntegral[5, 2]\": \"li(5, 2)\",\n        \"PrimePi[7, 5]\": \"primepi(7, 5)\",\n        \"Prime[5, 2]\": \"prime(5, 2)\",\n    }\n\n    for e in d:\n        assert parse_mathematica(e) == sympify(d[e])\n", "def test_mathematica_parser_corner_cases():\n    parser = MathematicaParser()\n\n    chain = lambda expr: parser.parse(expr)\n\n    # Test parsing of nested patterns\n    assert chain(\"f[x___, y___]\") == Function('f', ('Pattern', 'x', ('BlankNullSequence',)), ('Pattern', 'y', ('BlankNullSequence',)))\n    assert chain(\"f[x_, y__]\") == Function('f', ('Pattern', 'x', ('Blank',)), ('Pattern', 'y', ('BlankSequence',)))\n    assert chain(\"f[x__, y_].\") == Function('f', ('Pattern', 'x', ('BlankNullSequence',)), ('Optional', ('Pattern', 'y', ('Blank',))))\n\n    # Test parsing of lambda functions with default values\n    assert chain(\"#2&\") == Function('Lambda', ('Slot', '2'))\n    assert chain(\"#n&\") == Function('Lambda', ('Slot', 'n'))\n\n    # Test parsing of strings\n    assert chain('\"Hello, World!\"') == \"_Str('Hello, World!')\"\n\n    # Test parsing of invalid expressions\n    raises(SyntaxError, lambda: chain(\"x__\"))\n    raises(SyntaxError, lambda: chain(\"x_.\"))\n\n    # Test parsing of expressions with multiple newlines\n    assert chain(\"\\n\\nx\\n\\n\") == \"x\"\n\n    # Test parsing of expressions with multiple semicolons\n    assert chain(\"x; y; z\") == (\"CompoundExpression\", \"x\", \"y\", \"z\")\n\n    # Test parsing of expressions with comments\n    assert chain(\"x (* comment *)\") == \"x\"\n    assert chain(\"x (* comment * y *)\") == \"x\"\n    assert chain(\"x (* comment *) y\") == (\"CompoundExpression\", \"x\", \"y\")\n"], "sample_143": ["def test_pretty_ITE_issue_20496():\n    expr = ITE(x, 1, y)\n    ascii_str = \\", "def test_pretty_differential():\n    from sympy.physics import mechanics\n    expr = mechanics.differential(\"dx\")\n    ascii_str = \\", "def test_issue_14329():\n    p = 1/(1+1/(1/sqrt(x) + 1))\n    ucode_str = \\", "def test_pretty_matrix_vector_operation():\n    from sympy import Matrix\n    from sympy.physics.vector import ReferenceFrame, curl, divergence, gradient, dot, cross, Vector, laplacian\n\n    R = ReferenceFrame('R')\n    i, j, k = R.i, R.j, R.k\n    x, y, z = symbols('x y z')\n\n    # Gradient\n    expr = gradient(x**2 + y**2 + z**2)\n    ucode_str = '\u2207(x**2 + y**2 + z**2)'\n    ascii_str = 'del(x**2 + y**2 + z**2)'\n    assert pretty(expr) == ascii_str\n    assert upretty(expr) == ucode_str\n\n    # Divergence\n    expr = divergence(2*i + 3*j + 4*k)\n    ucode_str = '\u2207\u22c5(2\u22c5i_R + 3\u22c5j_R + 4\u22c5k_R)'\n    ascii_str = 'div(2*i_R + 3*j_R + 4*k_R)'\n    assert pretty(expr) == ascii_str\n    assert upretty(expr) == ucode_str\n\n    # Curl\n    expr = curl(2*i + 3*j + 4*k)\n    ucode_str = '\u2207\u00d7(2\u22c5i_R + 3\u22c5j_R + 4\u22c5k_R)'\n    ascii_str = 'curl(2*i_R + 3*j_R + 4*k_R)'\n    assert pretty(expr) == ascii_str\n    assert upretty(expr) == ucode_str\n\n    # Dot\n    expr = dot(2*i + 3*j + 4*k, 5*i + 6*j + 7*k)\n    ucode_str = '(2\u22c5i_R + 3\u22c5j_R + 4\u22c5k_R)\u22c5(5\u22c5i_R + 6\u22c5j_R + 7\u22c5k_R)'\n    ascii_str = '(2*i_R + 3*j_R + 4*k_R) . (5*i_R + 6*j_R + 7*k_R)'\n    assert pretty(expr) == ascii_str\n    assert upretty(expr) == ucode_str\n\n    # Cross\n    expr = cross(2*i + 3*j + ", "def test_pretty_Add_traditional_precedence():\n    a, b = symbols('a b')\n    c = symbols('c', commutative=False)\n    # addition\n    assert pretty(a + b) == 'a + b'\n    assert pretty(b + a) == 'a + b'\n    assert pretty(a + c) == 'a + c'\n    assert pretty(c + a) == 'c + a'\n    assert pretty(c + c) == 'c + c'\n    assert pretty(c + a + b) == 'a + b + c'\n    assert pretty(a + b + c) == 'a + b + c'\n    assert pretty(a + c + b) == 'a + b + c'\n    assert pretty(c + b + a) == 'a + b + c'\n    assert pretty(c + a + b) == 'a + b + c'\n    assert pretty(a + c + c) == 'a + c + c'\n    assert pretty(c + a + c) == 'a + c + c'\n    assert pretty(c + c + a) == 'a + c + c'\n    assert pretty(a + b + c + d) == 'a + b + c + d'\n    assert pretty(c + d + a + b) == 'a + b + c + d'\n    # negation\n    assert pretty(-a) == '-a'\n    assert pretty(-c) == '-c'\n    # subtraction\n    assert pretty(a - b) == 'a - b'\n    assert pretty(b - a) == 'b - a'\n    assert pretty(a - c) == 'a - c'\n    assert pretty(c - a) == 'c - a'\n    assert pretty(c - c) == 'c - c'\n    assert pretty(a - c - b) == 'a - b - c'\n    assert pretty(a - b - c) == 'a - b - c'\n    assert pretty(c - b - a) == 'c - b - a'\n    assert pretty(c - a - b) == 'c - b - a'\n    assert pretty(a - c - c) == 'a - c - c'\n    assert pretty(c - a - c) == 'c - a - c'\n    assert pretty(c - c - a) == 'c - a - c'\n    assert pretty(a - b - c - d) == 'a -"], "sample_106": ["def test_transform_not_fitted():\n    nca = NeighborhoodComponentsAnalysis()\n    assert_raises_message(\n        NotFittedError,\n        \"This NeighborhoodComponentsAnalysis instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.\",\n        nca.transform, iris_data)\n", "def test_transform_shape():\n    \"\"\"Test that the shape of the transformed data is correct\"\"\"\n    X = iris_data\n    y = iris_target\n    n_components = 3\n    nca = NeighborhoodComponentsAnalysis(n_components=n_components,\n                                         max_iter=10)\n    nca.fit(X, y)\n    X_transformed = nca.transform(X)\n    assert_equal(X_transformed.shape, (X.shape[0], n_components))\n", "def test_transform_without_fit():\n    \"\"\"Test that transform raises an error if fit was not called first\"\"\"\n    X = iris_data\n    y = iris_target\n    nca = NeighborhoodComponentsAnalysis()\n    assert_raise_message(ValueError,\n                         \"has not been fitted.\",\n                         nca.transform, X)\n", "def test_transform_call_after_fit():\n    \"\"\"Test that calling transform after fit raises an error if X is not fitted.\"\"\"\n    X = iris_data\n    y = iris_target\n\n    nca = NeighborhoodComponentsAnalysis()\n    assert_raises_message(ValueError,\n                         \"has not been fitted.\",\n                         nca.transform, X)\n", "def test_edge_cases_for_callbacks():\n    X = iris_data\n    y = iris_target\n\n    # Check callback function with too few arguments\n        pass\n\n    nca = NeighborhoodComponentsAnalysis(callback=my_cb)\n    assert_raises(ValueError, nca.fit, X, y)\n\n    # Check callback function with too many arguments\n        pass\n\n    nca = NeighborhoodComponentsAnalysis(callback=my_cb)\n    assert_raises(ValueError, nca.fit, X, y)\n\n    # Check callback function with wrong argument types\n        transformation += 1\n\n    nca = NeighborhoodComponentsAnalysis(callback=my_cb)\n    assert_raises(TypeError, nca.fit, X, y)\n"], "sample_103": ["def test_mutual_info_classif_sparse():\n    # Test that the function correctly handles sparse input.\n    X = csr_matrix(np.array([[0, 0, 0],\n                             [1, 1, 0],\n                             [2, 0, 1],\n                             [2, 0, 1],\n                             [2, 0, 1]]))\n    y = np.array([0, 1, 2, 2, 1])\n\n    # Here X[:, 0] is the most informative feature, and X[:, 1] is weakly\n    # informative.\n    mi = mutual_info_classif(X, y, discrete_features=True)\n    assert_array_equal(np.argsort(-mi.toarray()[0]), np.array([0, 2, 1]))\n", "def test_mutual_info_regression_sparse():\n    # Test mutual_info_regression on sparse data.\n    X = csr_matrix(np.array([\n        [0, 1, 0, 0],\n        [0, 0, 1, 1],\n        [1, 1, 0, 1],\n        [0, 1, 0, 0]\n    ]))\n    y = np.array([0, 1, 0, 1])\n\n    mi = mutual_info_regression(X, y, discrete_features='auto')\n    assert_array_equal(np.argsort(-mi), np.array([1, 3, 0, 2]))\n", "def test_mutual_info_regression_sparse():\n    # Test that sparse input works\n    X = csr_matrix(np.random.rand(100, 3))\n    y = np.random.rand(100)\n    mi_sparse = mutual_info_regression(X, y)\n    mi_dense = mutual_info_regression(X.toarray(), y)\n    assert_array_equal(mi_sparse, mi_dense)\n\n    # Test that sparse input with discrete features works\n    X = csr_matrix(np.random.randint(0, 2, (100, 3)))\n    y = np.random.rand(100)\n    mi_sparse = mutual_info_regression(X, y, discrete_features=True)\n    mi_dense = mutual_info_regression(X.toarray(), y, discrete_features=True)\n    assert_array_equal(mi_sparse, mi_dense)\n", "def test_mutual_info_regression_sparse():\n    # Test for sparse feature matrix\n    X = csr_matrix(np.array([\n        [0, 1, 0, 0],\n        [1, 0, 2, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 1],\n        [0, 1, 0, 0],\n    ]))\n    y = np.array([0, 1, 0, 1, 0])\n\n    mi = mutual_info_regression(X, y)\n    assert_equal(mi.shape, (X.shape[1],))\n\n    # Test for sparse feature matrix with discrete features\n    X = csr_matrix(np.array([\n        [0, 1, 0, 0],\n        [1, 0, 2, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 1],\n        [0, 1, 0, 0],\n    ]))\n    y = np.array([0, 1, 0, 1, 0])\n\n    mi = mutual_info_regression(X, y, discrete_features=[2])\n    assert_equal(mi.shape, (X.shape[1],))\n\n    # Test for sparse feature matrix with continuous features\n    X = csr_matrix(np.array([\n        [0, 1, 0, 0],\n        [1, 0, 2, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 1],\n        [0, 1, 0, 0],\n    ]))\n    y = np.array([0, 1, 0, 1, 0])\n\n    mi = mutual_info_regression(X, y, discrete_features=False)\n    assert_equal(mi.shape, (X.shape[1],))\n", "def test_mutual_info_classif_sparse():\n    # Test that mutual_info_classif handles sparse data correctly.\n    X = csr_matrix(np.array([\n        [0, 1, 0, 1],\n        [1, 0, 1, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0]\n    ]))\n    y = np.array([0, 1, 1, 1])\n\n    mi = mutual_info_classif(X, y, discrete_features=True)\n    assert_array_equal(np.argsort(-mi), np.array([0, 1, 3, 2]))\n\n    # Test that mutual_info_classif raises an error when the input is sparse and\n    # contains continuous features.\n    X = csr_matrix(np.array([\n        [0.5, 1, 0, 1],\n        [1, 0, 1, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0]\n    ]))\n    assert_raises(ValueError, mutual_info_classif, X, y, discrete_features=True)\n"], "sample_113": ["def test_column_transformer_set_output_with_pandas_input_and_dataframe_output():\n    \"\"\"Check column transformer behavior with set_output.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame([[1, 2, 3, 4]], columns=[\"a\", \"b\", \"c\", \"d\"], index=[10])\n    ct = ColumnTransformer(\n        [(\"first\", TransWithNames(), [\"a\", \"c\"]), (\"second\", TransWithNames(), [\"d\"])],\n        remainder=\"passthrough\",\n    )\n    ct.fit(df)\n    X_trans = ct.transform(df)\n    assert isinstance(X_trans, np.ndarray)\n\n    ct.set_output(transform=\"pandas\")\n    df_test = pd.DataFrame([[1, 2, 3, 4]], columns=df.columns, index=[20])\n    X_trans_df = ct.transform(df_test)\n    assert isinstance(X_trans_df, pd.DataFrame)\n\n    feature_names_out = ct.get_feature_names_out()\n    assert_array_equal(X_trans_df.columns, feature_names_out)\n    assert_array_equal(X_trans_df.index, df_test.index)\n", "def test_column_transformer_feature_names_out_unfitted():\n    # Check that `get_feature_names_out` raises an error when the transformer\n    # is not fitted\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame({\"feat0\": [1.0, 2.0, 3.0], \"feat1\": [2.0, 3.0, 4.0]})\n    ct = ColumnTransformer([(\"trans\", TransWithNames(), [\"feat0\"])])\n    msg = \"The `get_feature_names_out` method is only defined after fitting.\"\n    with pytest.raises(NotFittedError, match=msg):\n        ct.get_feature_names_out()\n", "def test_column_transformer_get_params_with_callable():\n    # Test that get_params works correctly with callable transformers.\n    X = np.array([[1, 2, 3], [4, 5, 6]])\n\n        return X * 2\n\n    ct = ColumnTransformer([(\"trans1\", trans_callable, [0])])\n    params = ct.get_params()\n    assert callable(params[\"trans1\"])\n    assert params[\"trans1\"](np.array([1, 2, 3])) == np.array([2, 4, 6])\n", "def test_column_transformer_with_empty_input():\n    # Test that transformers handle empty input data\n    ct = ColumnTransformer([(\"trans\", Trans(), [0])])\n\n    # Test with empty array\n    X = np.array([[]])\n    assert_array_equal(ct.fit_transform(X), np.array([[]]))\n\n    # Test with empty DataFrame\n    pd = pytest.importorskip(\"pandas\")\n    X = pd.DataFrame({\"A\": []})\n    assert_array_equal(ct.fit_transform(X), np.array([[]]))\n\n    # Test with empty list\n    X = [[]]\n    assert_array_equal(ct.fit_transform(X), np.array([[]]))\n", "def test_column_transformer_transformer_weights_invalidation():\n    \"\"\"Test that transformer_weights is validated correctly.\"\"\"\n    scaler = StandardScaler()\n    norm = Normalizer()\n    ct = ColumnTransformer([(\"scaler\", scaler, [0]), (\"norm\", norm, [1])])\n\n    # Test a single invalid key\n    transformer_weights = {\"invalid_key\": 1.0}\n    msg = (\n        \"No valid specification of a list of transformer tags. Did you miss \"\n        \"to specify a prefix? Available transformers are: 'norm', 'scaler'\"\n    )\n    with pytest.raises(ValueError, match=msg):\n        ct.set_params(transformer_weights=transformer_weights)\n\n    # Test multiple invalid keys\n    transformer_weights = {\"invalid_key\": 1.0, \"norm\": 2.0}\n    with pytest.raises(ValueError, match=msg):\n        ct.set_params(transformer_weights=transformer_weights)\n\n    # Test non-string key\n    transformer_weights = {1: 1.0}\n    msg = \"transformer_weights keys must be strings.\"\n    with pytest.raises(ValueError, match=msg):\n        ct.set_params(transformer_weights=transformer_weights)\n"], "sample_97": ["def test_multilabel_binarizer_with_partial_fit():\n    # Test fit_transform and transform with partial_fit\n    mlb = MultiLabelBinarizer()\n    y1 = [[1, 2], [1, 3]]\n    y2 = [[2, 3], [3, 4]]\n    y = y1 + y2\n\n    mlb.fit(y1)\n    assert_array_equal(mlb.classes_, [1, 2, 3])\n    mlb.partial_fit(y2)\n    assert_array_equal(mlb.classes_, [1, 2, 3, 4])\n\n    Y = mlb.transform(y)\n    expected = np.array([[1, 1, 1, 0],\n                         [1, 0, 1, 0],\n                         [0, 1, 1, 0],\n                         [0, 0, 1, 1]])\n    assert_array_equal(Y.toarray(), expected)\n\n    # Test fit_transform with partial_fit\n    mlb = MultiLabelBinarizer()\n    Y = mlb.fit_transform(y1)\n    assert_array_equal(mlb.classes_, [1, 2, 3])\n    mlb.partial_fit(y2)\n    assert_array_equal(mlb.classes_, [1, 2, 3, 4])\n\n    Y = mlb.transform(y)\n    expected = np.array([[1, 1, 1, 0],\n                         [1, 0, 1, 0],\n                         [0, 1, 1, 0],\n                         [0, 0, 1, 1]])\n    assert_array_equal(Y.toarray(), expected)\n", "def test_label_binarize_edge_cases():\n    # Test that y can be a scalar\n    assert_array_equal(label_binarize(1, [0, 1, 2]), [[0, 1, 0]])\n\n    # Test that y can be a numpy scalar\n    assert_array_equal(label_binarize(np.int64(1), [0, 1, 2]), [[0, 1, 0]])\n\n    # Test that y can be a string\n    assert_array_equal(label_binarize('apple', ['banana', 'apple', 'cherry']),\n                       [[0, 1, 0]])\n", "def test_label_encoder_numeric_classes():\n    # Test LabelEncoder's transform and inverse_transform methods with numeric classes\n    le = LabelEncoder()\n    classes = [0.5, 1.2, 2.5]\n    le.classes_ = classes\n    assert_array_equal(le.transform([0.5, 1.2, 1.2, 2.5, 0.5]),\n                       [0, 1, 1, 2, 0])\n    assert_array_equal(le.inverse_transform([0, 1, 1, 2, 0]), classes[0:3])\n    assert_array_equal(le.inverse_transform([0, 1, 1, 2, 0]), [0.5, 1.2, 1.2, 2.5, 0.5])\n    assert_raises(ValueError, le.transform, [0.3])\n    assert_raises(ValueError, le.inverse_transform, [3])\n", "def test_multilabel_binarizer_sparse_input():\n    # Test that sparse matrices are correctly handled in transform\n    # https://github.com/scikit-learn/scikit-learn/issues/19183\n    mlb = MultiLabelBinarizer()\n    y = csr_matrix([[0, 1, 0], [1, 0, 0], [0, 1, 1]])\n    mlb.fit_transform(y)\n    mlb.transform(y)\n\n    # Test that sparse matrices are correctly handled in fit_transform\n    mlb = MultiLabelBinarizer()\n    mlb.fit_transform(y)\n", "def test_inverse_binarize_multiclass():\n    # Test that inverse_binarize_multiclass correctly handles a variety of\n    # inputs, including sparse matrices and arrays with different data types.\n    y = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0]])\n    classes = [1, 2, 3]\n\n    assert_array_equal(_inverse_binarize_multiclass(y, classes), [3, 2, 1])\n\n    y_sparse = csr_matrix(y)\n    assert_array_equal(_inverse_binarize_multiclass(y_sparse, classes), [3, 2, 1])\n\n    y = np.array([[0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0]])\n    assert_array_equal(_inverse_binarize_multiclass(y, classes), [3, 2, 1])\n\n    # Test that it raises an error if there are multiple maximal values\n    y = np.array([[0, 1, 1], [1, 0, 0], [1, 0, 0]])\n    assert_raises(ValueError, _inverse_binarize_multiclass, y, classes)\n"], "sample_26": ["    def test_clone_test_db(self):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        with mock.patch.object(creation, '_clone_test_db') as mocked_clone:\n            creation.clone_test_db('suffix', verbosity=1, autoclobber=False, keepdb=False)\n            mocked_clone.assert_called_once_with('suffix', 1, False)\n", "    def test_create_test_db_with_error(self, mocked_sync_apps, mocked_migrate, *mocked_objects):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = False\n        creation = test_connection.creation_class(test_connection)\n        if connection.vendor == 'oracle':\n            # Don't close connection on Oracle.\n            creation.connection.close = mock.Mock()\n        old_database_name = test_connection.settings_dict['NAME']\n        with mock.patch.object(creation, '_create_test_db', side_effect=Exception('Test error')):\n            with self.assertRaises(SystemExit) as cm:\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n            self.assertEqual(cm.exception.code, 2)\n", "    def test_clone_test_db(self):\n        # clone_test_db() clones the test database.\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        with mock.patch.object(creation, '_clone_test_db'):\n            creation.clone_test_db(suffix='clone', verbosity=0, autoclobber=True, keepdb=False)\n        with mock.patch.object(creation, '_clone_test_db'):\n            creation.clone_test_db(suffix='clone', verbosity=0, autoclobber=True, keepdb=True)\n", "    def test_create_test_db(self, mocked_create_test_db):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            creation.create_test_db(verbosity=0, autoclobber=True, serialize=False, keepdb=False)\n            mocked_create_test_db.assert_called_once()\n            self.assertEqual(test_connection.settings_dict['NAME'], 'test_test.db')\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n", "    def test_clone_test_db(self):\n        # Test that clone_test_db creates a new database with the same data as the original.\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n            # Create some data in the original database.\n            obj = Object.objects.create(name='Original object')\n            # Clone the test database.\n            creation.clone_test_db('clone', verbosity=0, autoclobber=True)\n            # Check that the cloned database has the same data as the original.\n            clone_connection = connections[creation.get_test_db_clone_settings('clone')]\n            clone_obj = Object.objects.using(clone_connection.alias).get(name='Original object')\n            self.assertEqual(obj.name, clone_obj.name)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n                creation.destroy_test_db(creation.get_test_db_clone_settings('clone')['NAME'], verbosity=0)\n"], "sample_50": ["    def test_extra_tags(self):\n        \"\"\"\n        Extra tags are preserved when messages are stored and retrieved.\n        \"\"\"\n        storage = self.get_storage()\n        message = Message(constants.INFO, 'Test message', extra_tags='tag1 tag2')\n        set_cookie_data(storage, [message])\n        retrieved_message = list(storage)[0]\n        self.assertEqual(retrieved_message.message, 'Test message')\n        self.assertEqual(retrieved_message.extra_tags, 'tag1 tag2')\n", "def test_remove_oldest_message(self):\n    \"\"\"\n    If the data exceeds what is allowed in a cookie, and remove_oldest is set\n    to False, the newest messages are removed before saving.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # When storing as a cookie, the cookie has constant overhead of approx\n    # 54 chars, and each message has a constant overhead of about 37 chars\n    # and a variable overhead of zero in the best case. We aim for a message\n    # size which will fit 4 messages into the cookie, but not 5.\n    # See also FallbackTest.test_session_fallback\n    msg_size = int((CookieStorage.max_cookie_size - 54) / 4.5 - 37)\n    first_msg = None\n    # Generate the same (tested) content every time that does not get run\n    # through zlib compression.\n    random.seed(42)\n    for i in range(5):\n        msg = get_random_string(msg_size)\n        storage.add(constants.INFO, msg)\n        if i == 0:\n            first_msg = msg\n    unstored_messages = storage.update(response, remove_oldest=False)\n\n    cookie_storing = self.stored_messages_count(storage, response)\n    self.assertEqual(cookie_storing, 4)\n\n    self.assertEqual(len(unstored_messages), 1)\n    self.assertNotEqual(unstored_messages[0].message, first_msg)\n", "def test_process_messages(self):\n    \"\"\"\n    Verify MessageDecoder.process_messages() correctly handles nested structures.\n    \"\"\"\n    data = [\n        ['__json_message', 0, constants.INFO, 'message'],\n        {\n            'a': ['__json_message', 1, constants.INFO, '<b>Hello Django!</b>'],\n            'b': [\n                ['__json_message', 0, constants.INFO, 'message'],\n                ['__json_message', 1, constants.INFO, '<b>Hello Django!</b>'],\n            ],\n        },\n        ['__json_message', 0, constants.INFO, 'message'],\n    ]\n    processed_data = MessageDecoder().process_messages(data)\n    self.assertEqual(len(processed_data), 3)\n    self.assertIsInstance(processed_data[1]['a'], Message)\n    self.assertIsInstance(processed_data[1]['b'][0], Message)\n    self.assertIsInstance(processed_data[1]['b'][1], Message)\n    self.assertIsInstance(processed_data[1]['a'].message, SafeData)\n    self.assertIsInstance(processed_data[1]['b'][1].message, SafeData)\n    self.assertNotIsInstance(processed_data[0].message, SafeData)\n    self.assertNotIsInstance(processed_data[1]['b'][0].message, SafeData)\n    self.assertNotIsInstance(processed_data[2].message, SafeData)\n", "def test_process_messages(self):\n    \"\"\"\n    Test the MessageDecoder's process_messages method.\n    \"\"\"\n    decoder = MessageDecoder()\n    original_data = {\n        'message': Message(constants.INFO, 'Test message'),\n        'message_list': [\n            Message(constants.INFO, 'message %s') for x in range(5)\n        ] + [{'another-message': Message(constants.ERROR, 'error')}],\n    }\n    encoded_data = json.loads(json.dumps(original_data, cls=MessageEncoder))\n    decoded_data = decoder.process_messages(encoded_data)\n    self.assertEqual(decoded_data, original_data)\n    self.assertIsInstance(decoded_data['message'], Message)\n    self.assertIsInstance(decoded_data['message_list'][0], Message)\n    self.assertIsInstance(decoded_data['message_list'][-1]['another-message'], Message)\n", "    def test_message_encoder_defaults(self):\n        \"\"\"\n        MessageEncoder uses 0/1 instead of False/True to produce more compact json.\n        \"\"\"\n        message = Message(constants.INFO, 'Test message')\n        encoder = MessageEncoder()\n        value = encoder.default(message)\n        self.assertEqual(value, [MessageEncoder.message_key, 0, constants.INFO, 'Test message'])\n"], "sample_90": ["def test_mark_evaluator_istrue_with_nested_conditionals(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        xyz = True\n        xyz2 = False\n\n        @pytest.mark.xyz\n            pass\n\n        @pytest.mark.xyz2\n            pass\n\n        @pytest.mark.eval(\"xyz and xyz2\")\n            pass\n    \"\"\"\n    )\n    rec = testdir.inline_run()\n    rec.assertoutcome(passed=1, failed=1)\n", "def test_mark_evaluator(testdir):\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n            for item in items:\n                if \"test_one\" in item.nodeid:\n                    item.add_marker(pytest.mark.eval(\"1 == 1\"))\n                if \"test_two\" in item.nodeid:\n                    item.add_marker(pytest.mark.eval(\"1 == 2\"))\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n            assert True\n            assert False\n    \"\"\"\n    )\n    reprec = testdir.inline_run(\"-m\", \"eval\")\n    passed, skipped, failed = reprec.countoutcomes()\n    assert passed == 1\n    assert failed == 1\n    assert skipped == 0\n", "def test_mark_evaluator_invalidraise(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.eval(\"1/0\")\n            pass\n    \"\"\"\n    )\n    rec = testdir.inline_run()\n    passed, skipped, failed = rec.listoutcomes()\n    assert len(failed) == 1\n    failed[0].nodeid == \"test_mark_evaluator_invalidraise.py::test_eval\"\n    assert failed[0].longrepr.reprcrash.message.startswith(\"ZeroDivisionError: division by zero\")\n", "def test_mark_evaluator_invalidraise(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.skipif(\"True\")\n            raise Exception(\"Skipped test raised an exception\")\n\n        @pytest.mark.skipif(\"False\")\n            raise Exception(\"Test should not be skipped\")\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"collected 2 items\",\n            \"*Skipped test raised an exception*\",\n            \"*Skipped test should not be skipped*\",\n        ]\n    )\n    assert result.ret == 1\n", "def test_mark_evaluator_istrue(testdir):\n    \"\"\"Test MarkEvaluator._istrue() method\"\"\"\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import os\n        @pytest.mark.skipif(\"os.name != 'nt'\")\n            assert True\n        @pytest.mark.skipif(\"os.name == 'nt'\")\n            assert True\n    \"\"\"\n    )\n    evaluator = MarkEvaluator(item=p, name=\"skipif\")\n    assert evaluator._istrue()\n    assert evaluator.getexplanation() == \"condition: os.name != 'nt'\"\n    assert not evaluator.wasvalid()\n    assert evaluator.invalidraise(ImportError) is None\n    assert not evaluator.invalidraise(FileNotFoundError)\n    evaluator = MarkEvaluator(item=p, name=\"skipif\")\n    assert not evaluator._istrue()\n    assert evaluator.getexplanation() == \"condition: os.name == 'nt'\"\n    assert not evaluator.wasvalid()\n    assert evaluator.invalidraise(ImportError) is None\n    assert not evaluator.invalidraise(FileNotFoundError)\n"], "sample_125": ["def test_mod_inverse_number():\n    raises(ValueError, lambda: mod_inverse(2, 1.5))\n    raises(ValueError, lambda: mod_inverse(2, Rational(3, 2)))\n    raises(ValueError, lambda: mod_inverse(2, oo))\n    raises(ValueError, lambda: mod_inverse(2, S.ComplexInfinity))\n    raises(ValueError, lambda: mod_inverse(2, nan))\n    raises(ValueError, lambda: mod_inverse(2, zoo))\n", "def test_Pow_number_symbol():\n    assert E**pi == E**pi\n    assert E**(pi+1) == E**pi * E\n    assert E**(pi-1) == E**pi / E\n    assert E**(pi-2) == E**pi / E**2\n    assert pi**E == pi**E\n    assert pi**(E+1) == pi**E * pi\n    assert pi**(E-1) == pi**E / pi\n    assert pi**(E-2) == pi**E / pi**2\n", "def test_mpf_norm():\n    assert mpf_norm((0, long(0), 0, 0), 10) == (0, long(0), 0, 0)\n    assert mpf_norm((0, long(0), 1, 0), 10) == (0, long(0), 0, 0)\n    assert mpf_norm((1, long(0), -1, 0), 10) == (0, long(0), 0, 0)\n    assert mpf_norm((1, long(0), 0, 0), 10) == (0, long(0), 0, 0)\n    assert mpf_norm((1, long(0), 1, 0), 10) == (0, long(0), 0, 0)\n    assert mpf_norm((1, long(0), -2, 0), 10) == (0, long(0), 0, 0)\n    assert mpf_norm((0, long(0), 1, 1), 10) == (0, long(0), 0, 0)\n    assert mpf_norm((1, long(1), 1, 1), 10) == (0, long(1), 0, 1)\n    assert mpf_norm((1, long(1), -1, 1), 10) == (0, long(1), 0, 1)\n    assert mpf_norm((0, long(0), -1, -1), 10) == (0, long(0), 0, 0)\n    assert mpf_norm((1, long(0), -1, -1), 10) == (0, long(0), 0, 0)\n    assert mpf_norm((1, long(0), 0, -1), 10) == (0, long(0), 0, 0)\n    assert mpf_norm((1, long(0), 1, -1), 10) == (0, long(0), 0, 0)\n    assert mpf_norm((1, long(0), -2, -1), 10) == (0, long(0), 0, 0)\n    assert mpf_norm((0, long(0), ", "def test_as_coeff_Mul():\n    assert S(3).as_coeff_Mul() == (1, 3)\n    assert S(2.0).as_coeff_Mul() == (1, 2.0)\n    assert S(2/3).as_coeff_Mul() == (1, 2/3)\n    assert S(-2/3).as_coeff_Mul() == (-1, 2/3)\n    assert S(-3/4).as_coeff_Mul() == (-1, 3/4)\n    assert S(-3.4).as_coeff_Mul() == (-1, 3.4)\n    assert S(-3.4).as_coeff_Mul(rational=True) == (S.One, -3.4)\n    assert S(2/3).as_coeff_Mul(rational=True) == (S.One, 2/3)\n    assert S(-2/3).as_coeff_Mul(rational=True) == (-S.One, 2/3)\n    assert S(3).as_coeff_Mul(rational=True) == (S.One, 3)\n    assert S(-3).as_coeff_Mul(rational=True) == (-S.One, 3)\n    assert S(3.0).as_coeff_Mul(rational=True) == (S.One, 3.0)\n    assert S(-3.0).as_coeff_Mul(rational=True) == (-S.One, 3.0)\n", "def test_issue_10215():\n    assert sqrt(-1).conjugate() == -sqrt(-1)\n    assert (-sqrt(-1)).conjugate() == sqrt(-1)\n    assert (sqrt(2) + sqrt(-2)).conjugate() == sqrt(2) - sqrt(-2)\n    assert (sqrt(2) - sqrt(-2)).conjugate() == sqrt(2) + sqrt(-2)\n    assert (sqrt(-2) + sqrt(-2)).conjugate() == -sqrt(-2) - sqrt(-2)\n    assert (sqrt(-2) - sqrt(-2)).conjugate() == -sqrt(-2) + sqrt(-2)\n    assert (-sqrt(2) + sqrt(-2)).conjugate() == -sqrt(2) - sqrt(-2)\n    assert (-sqrt(2) - sqrt(-2)).conjugate() == -sqrt(2) + sqrt(-2)\n    assert sqrt(1).conjugate() == sqrt(1)\n    assert sqrt(0).conjugate() == sqrt(0)\n    assert sqrt(-0).conjugate() == sqrt(-0)\n    assert sqrt(1 + sqrt(-1)).conjugate() == sqrt(1 - sqrt(-1))\n    assert (sqrt(-1) + sqrt(-1)).conjugate() == -sqrt(-1) - sqrt(-1)\n    assert (sqrt(-1) - sqrt(-1)).conjugate() == -sqrt(-1) + sqrt(-1)\n    assert sqrt(2 + sqrt(2)).conjugate() == sqrt(2 + sqrt(2))\n    assert sqrt(-2 - sqrt(2)).conjugate() == sqrt(-2 - sqrt(2))\n"], "sample_129": ["def test_latex_explicit_function():\n    f = Function('f')\n    g = Function('g')\n    assert latex(f(x).diff(x)) == r\"\\frac{d}{d x} f{\\left (x \\right )}\"\n    assert latex(g(x, y).diff(x)) == r\"\\frac{\\partial}{\\partial x} g{\\left (x, y \\right )}\"\n    assert latex(g(x, y).diff(x, x)) == r\"\\frac{\\partial^{2}}{\\partial x^{2}} g{\\left (x, y \\right )}\"\n    assert latex(g(x, y).diff(x, y)) == r\"\\frac{\\partial^{2}}{\\partial y\\partial x} g{\\left (x, y \\right )}\"\n", "def test_latex_MatPow():\n    M = MatrixSymbol('M', 2, 2)\n    assert latex(M**-1) == r\"M^{-1}\"\n    assert latex(M**-1, mode='equation*') == r\"\\begin{equation*}M^{-1}\\end{equation*}\"\n    assert latex(M**-1, mode='equation', itex=True) == r\"$$M^{-1}$$\"\n    assert latex(M**-2) == r\"M^{-2}\"\n    assert latex(M**-2, mode='equation*') == r\"\\begin{equation*}M^{-2}\\end{equation*}\"\n    assert latex(M**-2, mode='equation', itex=True) == r\"$$M^{-2}$$\"\n    assert latex(M**0) == r\"M^{0}\"\n    assert latex(M**0, mode='equation*') == r\"\\begin{equation*}M^{0}\\end{equation*}\"\n    assert latex(M**0, mode='equation', itex=True) == r\"$$M^{0}$$\"\n    assert latex(M**1) == r\"M\"\n    assert latex(M**1, mode='equation*') == r\"\\begin{equation*}M\\end{equation*}\"\n    assert latex(M**1, mode='equation', itex=True) == r\"$$M$$\"\n    assert latex(M**2) == r\"M^{2}\"\n    assert latex(M**2, mode='equation*') == r\"\\begin{equation*}M^{2}\\end{equation*}\"\n    assert latex(M**2, mode='equation', itex=True) == r\"$$M^{2}$$\"\n", "def test_latex_equality():\n    assert latex(Eq(x + 1, 2*x)) == r\"x + 1 = 2 x\"\n    assert latex(Eq(x, y)) == r\"x = y\"\n    assert latex(Eq(x + y, z)) == r\"x + y = z\"\n    assert latex(Eq(x**2, y)) == r\"x^{2} = y\"\n    assert latex(Eq(y, x + 1)) == r\"y = x + 1\"\n    assert latex(Eq(x, x + 1)) == r\"x = x + 1\"\n    assert latex(Eq(x + 1, x)) == r\"x + 1 = x\"\n", "def test_latex_slice():\n    from sympy import MatrixSymbol\n    M = MatrixSymbol('M', 3, 4)\n    assert latex(M[:2, :2]) == r'M\\left[:2, :2\\right]'\n    assert latex(M[1:, 1:]) == r'M\\left[1:, 1:\\right]'\n    assert latex(M[1, :]) == r'M\\left[1, :\\right]'\n    assert latex(M[:, 1]) == r'M\\left[:, 1\\right]'\n    assert latex(M[1:2, :]) == r'M\\left[1:2, :\\right]'\n    assert latex(M[1:2, 1:2]) == r'M\\left[1:2, 1:2\\right]'\n    assert latex(M[1, 1:2]) == r'M\\left[1, 1:2\\right]'\n    assert latex(M[1:2, 1]) == r'M\\left[1:2, 1\\right]'\n", "def test_latex_tensor_expressions():\n    A = CoordSys3D('A')\n\n    assert latex(tensorproduct(A.i, A.j, A.k)) == r\"\\mathbf{\\hat{i}_{A}} \\otimes \\mathbf{\\hat{j}_{A}} \\otimes \\mathbf{\\hat{k}_{A}}\"\n    assert latex(tensorproduct(A.i, tensorproduct(A.j, A.k))) == r\"\\mathbf{\\hat{i}_{A}} \\otimes \\mathbf{\\hat{j}_{A}} \\otimes \\mathbf{\\hat{k}_{A}}\"\n    assert latex(tensorproduct(A.i, tensorproduct(tensorproduct(A.j, A.k), A.i))) == r\"\\mathbf{\\hat{i}_{A}} \\otimes \\mathbf{\\hat{j}_{A}} \\otimes \\mathbf{\\hat{k}_{A}} \\otimes \\mathbf{\\hat{i}_{A}}\"\n    assert latex(tensorproduct(A.i, A.j, tensorproduct(A.k, A.i))) == r\"\\mathbf{\\hat{i}_{A}} \\otimes \\mathbf{\\hat{j}_{A}} \\otimes \\mathbf{\\hat{k}_{A}} \\otimes \\mathbf{\\hat{i}_{A}}\"\n    assert latex(tensorproduct(tensorproduct(A.i, A.i), A.j, A.k)) == r\"\\mathbf{\\hat{i}_{A}} \\otimes \\mathbf{\\hat{i}_{A}} \\otimes \\mathbf{\\hat{j}_{A}} \\otimes \\mathbf{\\hat{k}_{A}}\"\n    assert latex(tensorproduct(A.i, tensorproduct(A.i, A.i), A.j, A.k)) == r\"\\mathbf{\\hat{i}_{A}} \\otimes \\mathbf{\\hat{i}_{A}} \\otimes \\mathbf{\\hat{i}_{A}} \\otimes \\mathbf{\\hat{j}_{A}} \\otimes \\mathbf{\\hat{k}_{A}}\"\n    assert latex(tensorproduct(tensorproduct(tensorproduct(A.i, A.i), A.i), A.j, A.k)) == r\"\\mathbf{\\hat{i}_{A}} \\otimes \\mathbf{\\hat{i}_{A}} \\otimes \\mathbf{\\hat{i}_{A}} \\otimes \\mathbf{\\hat{j}_{A}} \\otimes \\mathbf{\\hat{k}_{A}}\"\n"], "sample_70": ["def test_legend_edgecolor():\n    # Smoke test for PolyCollection legend handler with 'face' edgecolor.\n    fig, ax = plt.subplots()\n    ax.fill_between([0, 1, 2], [1, 2, 3], [2, 3, 4],\n                    facecolor='r', edgecolor='face', label='Fill')\n    ax.legend(edgecolor='blue')\n    assert ax.get_legend().get_frame().get_edgecolor() == 'blue'\n", "def test_legend_title():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [3, 4], label='line')\n    leg = ax.legend(title='My Legend')\n    assert leg.get_title().get_text() == 'My Legend'\n    assert leg.get_title().get_visible()\n\n    # test that setting title to None removes the title\n    leg.set_title(None)\n    assert leg.get_title().get_text() == ''\n    assert not leg.get_title().get_visible()\n", "def test_legend_draggable_loc_update():\n    # test that the legend loc is updated when dragging\n    fig, ax = plt.subplots()\n    ax.plot(range(10), label='shabnams')\n    leg = ax.legend(draggable=True)\n    assert leg.get_draggable()\n    leg._draggable.finalize_offset()\n    assert leg.get_loc() != (0, 0)\n", "def test_legend_alignment_negative_labelspacing():\n    # test that negative labelspacing doesn't break alignment\n    fig, ax = plt.subplots()\n    ax.plot(range(10), label='test')\n    ax.legend(title=\"Aardvark\", labelspacing=-1)\n    ax.legend(title=\"Aardvark\", labelspacing=-1, alignment='left')\n    ax.legend(title=\"Aardvark\", labelspacing=-1, alignment='right')\n", "def test_legend_set_frame_on():\n    # test that setting frame_on via kwarg and method works correctly\n    fig, ax = plt.subplots()\n    x = np.linspace(0, 1, 11)\n    ln1, = ax.plot(x, x, label='x')\n    ln2, = ax.plot(x, 2*x, label='2x')\n    leg = ax.legend(handles=[ln1, ln2])\n    assert leg.get_frame_on()\n    leg.set_frame_on(False)\n    assert not leg.get_frame_on()\n    leg.set_frame_on(True)\n    assert leg.get_frame_on()\n"], "sample_3": ["def test_coord_matrix_mapping():\n    c = _coord_matrix(map1, 'left', 4)\n    assert_allclose(np.array([[1, 0], [0, 1], [1, 0], [0, 1]]), c)\n    c = _coord_matrix(map1, 'right', 4)\n    assert_allclose(np.array([[0, 0], [0, 0], [1, 0], [0, 1]]), c)\n    c = _coord_matrix(map2, 'left', 3)\n    assert_allclose(np.array([[1, 0], [1, 0], [0, 1]]), c)\n    c = _coord_matrix(map2, 'right', 3)\n    assert_allclose(np.array([[0, 0], [0, 0], [1, 1]]), c)\n", "def test_coord_matrix_mapping():\n    c = _coord_matrix(map1, 'left', 4)\n    assert_allclose(np.array([[1, 0], [0, 1], [1, 0], [0, 1]]), c)\n    c = _coord_matrix(map1, 'right', 4)\n    assert_allclose(np.array([[0, 1], [1, 0], [0, 1], [1, 0]]), c)\n    c = _coord_matrix(map2, 'left', 3)\n    assert_allclose(np.array([[1, 0], [1, 0], [0, 1]]), c)\n    c = _coord_matrix(map2, 'right', 3)\n    assert_allclose(np.array([[0, 1], [0, 1], [1, 0]]), c)\n", "def test_separable_mapping():\n    mapping = Mapping((1, 0, 1, 0), name='mapping')\n    result = is_separable(mapping)\n    assert_allclose(result, np.array([True, True]))\n\n    result = separability_matrix(mapping)\n    assert_allclose(result, np.array([[False, True], [True, False]]))\n\n    mapping = Mapping((1, 1, 1, 0), name='mapping')\n    with pytest.raises(ModelDefinitionError, match=r\"Unsupported operands for arithmetic operator: .*\"):\n        separability_matrix(mapping)\n", "def test_separable_mapping_model():\n    map_model = Mapping((0, 1), name='map_model')\n    sep = is_separable(map_model)\n    assert_allclose(sep, np.array([True, True]))\n\n    sep_matrix = separability_matrix(map_model)\n    expected_sep_matrix = np.array([[True, False], [False, True]])\n    assert_allclose(sep_matrix, expected_sep_matrix)\n\n", "def test_separable_inputs1():\n    \"\"\"\n    Test separability with inputs of size 1.\n    \"\"\"\n    # Test is_separable\n    model = sh1 & sh2\n    result = is_separable(model)\n    assert_allclose(result, np.array([True, True]))\n\n    # Test separability_matrix\n    result = separability_matrix(model)\n    assert_allclose(result, np.array([[True, False], [False, True]]))\n\n"], "sample_157": ["def test_tensor_product_anticommutator():\n    assert TP(AntiCommutator(A, B), C).doit().expand(tensorproduct=True) == \\\n        TP(A*B, C) + TP(B*A, C)\n    assert AntiCommutator(TP(A, B), TP(B, C)).doit() == \\\n        TP(A, B)*TP(B, C) + TP(B, C)*TP(A, B)\n", "def test_tensor_product_trace():\n    assert Tr(TP(A, B)).doit() == Tr(A)*Tr(B)\n    assert Tr(TP(A, B), indices=[0]).doit() == Tr(A)*B\n    assert Tr(TP(A, B), indices=[1]).doit() == A*Tr(B)\n", "def test_tensor_product_simp_anticommutator():\n    assert tensor_product_simp(AntiCommutator(TP(A, B), TP(B, C))) == \\\n        AntiCommutator(TP(A*B, B*C), TP(B*C, B*C))\n", "def test_tensor_product_trace():\n    assert Tr(TensorProduct(A, B)) == Tr(A)*Tr(B)\n    assert Tr(TensorProduct(mat1, mat2)) == Tr(mat1)*Tr(mat2)\n    assert Tr(TensorProduct(A, B), (0,)) == Tr(A)*B\n    assert Tr(TensorProduct(A, B), (1,)) == A*Tr(B)\n", "def test_tensor_product_simp_trace():\n    assert Tr(tensor_product_simp(TP(A, B)*TP(C, D))) == Tr(A*C)*Tr(B*D)\n    assert Tr(tensor_product_simp(TP(A, B)**x)) == Tr(A**x)*Tr(B**x)\n    assert Tr(tensor_product_simp(x*(TP(A, B)**2)*TP(C,D))) == x*Tr(A**2*C)*Tr(B**2*D)\n    assert Tr(tensor_product_simp(TP(A,B)-TP(C,D)**x)) == Tr(A*B)-Tr(C**x*D**x)\n    assert Tr(tensor_product_simp(TP(A, B)*TP(C, D)), indices=[0]) == Tr(A*C)\n"], "sample_139": ["def test_periodic_argument_exp_polar():\n    from sympy import pi, periodic_argument, exp_polar\n    assert periodic_argument(exp_polar(5*pi*I), 2*pi) == pi\n    assert periodic_argument(exp_polar(5*pi*I), 3*pi) == -pi\n    assert periodic_argument(exp_polar(5*pi*I), pi) == 0\n    assert periodic_argument(exp_polar(7*pi*I), 2*pi) == pi\n    assert periodic_argument(exp_polar(7*pi*I), 3*pi) == -2*pi\n    assert periodic_argument(exp_polar(7*pi*I), pi) == 0\n", "def test_polar_lift():\n    x = Symbol('x')\n    p = Symbol('p', positive=True)\n    n = Symbol('n', negative=True)\n    assert polar_lift(4) == 4\n    assert polar_lift(4*p) == 4*p\n    assert polar_lift(4*n) == 4*polar_lift(n)\n    assert polar_lift(-4) == 4*polar_lift(-1)\n    assert polar_lift(-4*p) == -4*p\n    assert polar_lift(-4*n) == -4*n\n    assert polar_lift(n) == polar_lift(-1)*n\n    assert polar_lift(x) == polar_lift(x)\n    assert polar_lift(0) == 0\n    assert polar_lift(I) == exp_polar(-I*pi/2)\n    assert polar_lift(-I) == exp_polar(I*pi/2)\n    assert polar_lift(I*p) == exp_polar(-I*pi/2)*p\n    assert polar_lift(-I*p) == exp_polar(I*pi/2)*p\n", "def test_polar_lift():\n    from sympy import exp_polar, polar_lift, I, pi\n    x = Symbol('x')\n    p = Symbol('p', positive=True)\n    n = Symbol('n', negative=True)\n    \n    assert polar_lift(4) == 4 * exp_polar(0)\n    assert polar_lift(-4) == 4 * exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(I + 2) == polar_lift(2 + I)\n    assert polar_lift(4*x) == 4 * polar_lift(x)\n    assert polar_lift(4*p) == 4 * p\n\n    assert polar_lift(n * exp_polar(3 * pi * I)) == n * exp_polar(pi * I)\n\n    assert polar_lift(x).as_real_imag() == (re(x), im(x))\n\n    assert polar_lift(p).is_positive is True\n    assert polar_lift(n).is_positive is False\n    assert polar_lift(x).is_positive is None\n\n    assert polar_lift(p).is_negative is False\n    assert polar_lift(n).is_negative is True\n    assert polar_lift(x).is_negative is None\n", "def test_unpolarify_explicit_lift():\n    from sympy import unpolarify, polar_lift, exp_polar, oo, pi, sqrt, Symbol\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z', polar=True)\n    assert unpolarify(polar_lift(x), exponents_only=True) == polar_lift(x)\n    assert unpolarify(polar_lift(x), exponents_only=False) == x\n    assert unpolarify(polar_lift(exp_polar(y)), exponents_only=True) == exp_polar(y)\n    assert unpolarify(polar_lift(exp_polar(y)), exponents_only=False) == exp(y)\n    assert unpolarify(polar_lift(sqrt(x)), exponents_only=True) == polar_lift(sqrt(x))\n    assert unpolarify(polar_lift(sqrt(x)), exponents_only=False) == sqrt(x)\n    assert unpolarify(sqrt(polar_lift(x)), exponents_only=True) == sqrt(polar_lift(x))\n    assert unpolarify(sqrt(polar_lift(x)), exponents_only=False) == sqrt(x)\n    assert unpolarify(polar_lift(x)**2, exponents_only=True) == polar_lift(x)**2\n    assert unpolarify(polar_lift(x)**2, exponents_only=False) == x**2\n    assert unpolarify(polar_lift(exp_polar(y*pi/2)), exponents_only=True) == exp_polar(y*pi/2)\n    assert unpolarify(polar_lift(exp_polar(y*pi/2)), exponents_only=False) == I**y\n", "def test_periodic_argument_simplification():\n    from sympy import periodic_argument, oo, pi, symbols\n    x = symbols('x')\n    y = symbols('y', real=True)\n\n    assert periodic_argument(oo*x, 2*pi) is None\n    assert periodic_argument(-oo*x, 2*pi) is None\n\n    assert periodic_argument(x, oo).is_zero is None\n    assert periodic_argument(y, oo) == 0\n\n    assert periodic_argument(oo, 2*pi) is None\n    assert periodic_argument(-oo, 2*pi) is None\n    assert periodic_argument(oo*I, 2*pi) == periodic_argument(oo, 2*pi)\n    assert periodic_argument(-oo*I, 2*pi) == periodic_argument(-oo, 2*pi)\n\n    assert periodic_argument(pi, pi) == 0\n    assert periodic_argument(pi, 2*pi) == pi\n    assert periodic_argument(2*pi, pi) == pi\n    assert periodic_argument(3*pi, 2*pi) == pi\n    assert periodic_argument(-pi, pi) == pi\n    assert periodic_argument(-pi, 2*pi) == -pi\n    assert periodic_argument(-2*pi, pi) == pi\n    assert periodic_argument(-3*pi, 2*pi) == -pi\n"], "sample_95": ["    def test_module_level_skip(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            pytest.skip(\"skip_module_level\")\n\n                assert True\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            [\"*Using pytest.skip outside of a test will skip the entire module*\"]\n        )\n", "def test_xfail_strict_with_nested_marks(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(strict=True)\n        @pytest.mark.skipif(\"True\")\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-rxs\")\n    result.stdout.fnmatch_lines([\"*SKIP*condition: True*\", \"*1 skipped*\"])\n", "def test_function_definition_prune_dependency_tree(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.fixture\n            return 42\n\n        @pytest.mark.parametrize(\"x\", [1, 2], indirect=True)\n            assert x in [1, 2]\n            assert my_fixture == 42\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-v\")\n    result.stdout.fnmatch_lines([\"*= 2 passed in *\"])\n", "    def test_collect_function_definitions(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n                pass\n                pass\n        \"\"\"\n        )\n        result = pytester.runpytest(\"--collect-only\")\n        result.stdout.fnmatch_lines(\n            [\n                \"*test_collect_function_definitions.py::test_foo*\",\n                \"*test_collect_function_definitions.py::test_bar*\",\n            ]\n        )\n", "    def test_parametrize_function_scopes(self, pytester: Pytester) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n                return 1\n            @pytest.mark.parametrize(\"a\", [1, 2, 3])\n                assert my_fixture == 1\n        \"\"\"\n        )\n        result = pytester.runpytest(p)\n        result.stdout.fnmatch_lines([\"*3 passed*\"])\n        result = pytester.runpytest(p, \"--setup-show\")\n        result.stdout.fnmatch_lines(\n            [\n                \"SETUP    F my_fixture[scope: function]\",\n                \"CALL     test_func[1-1-my_fixture0] (fixtures used: my_fixture).\",\n                \"TEARDOWN F my_fixture[scope: function]\",\n                \"SETUP    F my_fixture[scope: function]\",\n                \"CALL     test_func[1-2-my_fixture1] (fixtures used: my_fixture).\",\n                \"TEARDOWN F my_fixture[scope: function]\",\n                \"SETUP    F my_fixture[scope: function]\",\n                \"CALL     test_func[1-3-my_fixture2] (fixtures used: my_fixture).\",\n                \"TEARDOWN F my_fixture[scope: function]\",\n            ]\n        )\n"], "sample_44": ["def test_modelchoicefield_with_limit_choices_to(self):\n    # limit_choices_to is a callable\n    f = forms.ModelChoiceField(Category.objects.all(), limit_choices_to=lambda: {'name': 'Entertainment'})\n    self.assertEqual(len(f.choices), 2)\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c1.pk, 'Entertainment'),\n    ])\n\n    # limit_choices_to is a dict\n    f = forms.ModelChoiceField(Category.objects.all(), limit_choices_to={'name': 'Entertainment'})\n    self.assertEqual(len(f.choices), 2)\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c1.pk, 'Entertainment'),\n    ])\n\n    # limit_choices_to is None\n    f = forms.ModelChoiceField(Category.objects.all(), limit_choices_to=None)\n    self.assertEqual(len(f.choices), 4)\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c1.pk, 'Entertainment'),\n        (self.c2.pk, 'A test'),\n        (self.c3.pk, 'Third'),\n    ])\n\n    # limit_choices_to is an invalid value\n    with self.assertRaises(TypeError):\n        forms.ModelChoiceField(Category.objects.all(), limit_choices_to='invalid')\n", "def test_model_multiple_choice_field(self):\n    f = forms.ModelMultipleChoiceField(Category.objects.all())\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c1.pk, 'Entertainment'),\n        (self.c2.pk, 'A test'),\n        (self.c3.pk, 'Third'),\n    ])\n    with self.assertRaises(ValidationError):\n        f.clean('')\n    with self.assertRaises(ValidationError):\n        f.clean(None)\n    with self.assertRaises(ValidationError):\n        f.clean(0)\n\n    self.assertEqual(list(f.clean([self.c2.pk, self.c3.pk]), [self.c2, self.c3])\n\n    # Invalid types that require TypeError to be caught.\n    with self.assertRaises(ValidationError):\n        f.clean([['fail']])\n    with self.assertRaises(ValidationError):\n        f.clean([{'foo': 'bar'}])\n\n    # Invalid choices.\n    msg = \"['Select a valid choice. 100 is not one of the available choices.']\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        f.clean([self.c2.pk, 100])\n\n    # Add a Category object *after* the ModelMultipleChoiceField has already been\n    # instantiated. This proves clean() checks the database during clean()\n    # rather than caching it at instantiation time.\n    c4 = Category.objects.create(name='Fourth', slug='4th', url='4th')\n    self.assertEqual(list(f.clean([c4.pk, self.c2.pk]), [c4, self.c2])\n\n    # Delete a Category object *after* the ModelMultipleChoiceField has already been\n    # instantiated. This proves clean() checks the database during clean()\n    # rather than caching it at instantiation time.\n    Category.objects.get(url='4th').delete()\n    msg = \"['Select a valid choice. %d is not one of the available choices.']\" % c4.pk\n    with self.assertRaisesMessage(ValidationError, msg):\n        f.clean([c4.pk, self.c2.pk])\n", "def test_model_multiple_choice_field_with_to_field_name(self):\n    f = forms.ModelMultipleChoiceField(Category.objects.all(), to_field_name='slug')\n    self.assertEqual(f.clean([self.c1.slug, self.c2.slug]), [self.c1, self.c2])\n    self.assertEqual(f.clean([self.c1, self.c2]), [self.c1, self.c2])\n    with self.assertRaises(ValidationError):\n        f.clean(['not-a-slug', 'invalid'])\n\n    f = forms.ModelMultipleChoiceField(Category.objects.all(), to_field_name='slug', empty_label='--')\n    self.assertEqual(f.clean([]), [])\n", "def test_has_changed(self):\n    class CustomModelChoiceValue:\n            self.value = value\n\n            return str(self.value)\n\n    field = forms.ModelChoiceField(Category.objects.all())\n    self.assertIs(field.has_changed(CustomModelChoiceValue(1), 2), True)\n    self.assertIs(field.has_changed(1, 1), False)\n    self.assertIs(field.has_changed(None, None), False)\n    self.assertIs(field.has_changed(CustomModelChoiceValue(1), CustomModelChoiceValue(1)), False)\n    self.assertIs(field.has_changed('1', '1'), True)  # Different types, so has changed.\n", "def test_model_multiple_choice_field(self):\n    f = forms.ModelMultipleChoiceField(Category.objects.all())\n    self.assertEqual(list(f.choices), [\n        (self.c1.pk, 'Entertainment'),\n        (self.c2.pk, 'A test'),\n        (self.c3.pk, 'Third'),\n    ])\n\n    self.assertEqual(f.clean([self.c2.id]).count(), 1)\n    self.assertEqual(f.clean([self.c2.id])[0].name, 'A test')\n    self.assertEqual(f.clean([self.c2.id, self.c3.id]).count(), 2)\n    self.assertEqual(f.clean([self.c2.id, self.c3.id])[0].name, 'A test')\n    self.assertEqual(f.clean([self.c2.id, self.c3.id])[1].name, 'Third')\n\n    with self.assertRaises(ValidationError):\n        f.clean([self.c2.id, self.c2.id])\n\n    with self.assertRaises(ValidationError):\n        f.clean([self.c2.id, 100])\n\n    with self.assertRaises(ValidationError):\n        f.clean([self.c2.id, 'invalid'])\n\n    with self.assertRaises(ValidationError):\n        f.clean(['invalid'])\n\n    with self.assertRaises(ValidationError):\n        f.clean([self.c2.id, None])\n\n    with self.assertRaises(ValidationError):\n        f.clean([self.c2.id, ''])\n\n    f = forms.ModelMultipleChoiceField(Category.objects.all(), required=False)\n    self.assertEqual(f.clean([]), [])\n\n    f = forms.ModelMultipleChoiceField(Category.objects.all(), required=True)\n    with self.assertRaises(ValidationError):\n        f.clean([])\n\n    with self.assertRaises(ValidationError):\n        f.clean([self.c2.id, None])\n\n    f = forms.ModelMultipleChoiceField(Category.objects.all(), required=False, empty_value='invalid')\n    with self.assertRaises(ValidationError):\n        f.clean('invalid')\n"], "sample_76": ["def test_insufficient_unique_points(self, df):\n    \"\"\"Test that the function handles cases with insufficient unique x points.\"\"\"\n    df[\"x\"] = np.repeat(0, len(df))\n    groupby = GroupBy([\"group\"])\n    res = PolyFit(order=1, gridsize=100)(df, groupby, \"x\", {})\n\n    assert res.columns.to_list() == [\"x\", \"y\", \"group\"]\n    assert res[\"x\"].empty\n    assert res[\"y\"].empty\n", "    def test_two_groupers(self, df):\n\n        groupby = GroupBy([\"group\", \"color\"])\n        gridsize = 50\n        res = PolyFit(gridsize=gridsize)(df, groupby, \"x\", {})\n\n        assert res.columns.to_list() == [\"x\", \"y\", \"group\", \"color\"]\n\n        ngroups = df[\"group\"].nunique() * df[\"color\"].nunique()\n        assert_array_equal(res.index, np.arange(ngroups * gridsize))\n\n        for _, part in res.groupby([\"group\", \"color\"]):\n            grid = np.linspace(part[\"x\"].min(), part[\"x\"].max(), gridsize)\n            assert_array_equal(part[\"x\"], grid)\n            assert part[\"y\"].diff().diff().dropna().abs().gt(0).all()\n", "def test_too_few_unique_x(self, df):\n\n    groupby = GroupBy([\"group\"])\n    df_unique_x = df.groupby(\"group\").apply(lambda x: x.nsmallest(2, \"x\")).reset_index(drop=True)\n    res = PolyFit(order=1, gridsize=100)(df_unique_x, groupby, \"x\", {})\n\n    assert_array_equal(res.columns, [\"x\", \"y\"])\n\n    assert_frame_equal(res, pd.DataFrame(columns=[\"x\", \"y\"]))\n", "def test_low_x_unique(self, df):\n\n    # Reduce the number of unique x values\n    df[\"x\"] = np.round(df[\"x\"], 2)\n    \n    groupby = GroupBy([\"group\"])\n    gridsize = 50\n    res = PolyFit(gridsize=gridsize)(df, groupby, \"x\", {})\n\n    assert res.columns.to_list() == [\"x\", \"y\", \"group\"]\n    assert res[\"x\"].empty\n    assert res[\"y\"].empty\n", "def test_too_few_unique_x(self, df):\n\n    df_few_x = df.drop_duplicates(subset=\"x\")\n\n    groupby = GroupBy([\"group\"])\n    with pytest.warns(UserWarning, match=\"not enough unique x\"):\n        res = PolyFit()(df_few_x, groupby, \"x\", {})\n\n    assert res.columns.to_list() == [\"x\", \"y\", \"group\"]\n    assert res.empty\n"], "sample_24": ["def test_update_error_dict(self):\n    error_dict = {\n        'field1': ['error1', 'error2'],\n        'field2': ['error3'],\n    }\n    exception = ValidationError(error_dict)\n    updated_error_dict = {}\n    exception.update_error_dict(updated_error_dict)\n    self.assertEqual(updated_error_dict, error_dict)\n\n    updated_error_dict = {'field3': ['error4']}\n    exception.update_error_dict(updated_error_dict)\n    self.assertEqual(updated_error_dict, {\n        'field1': ['error1', 'error2'],\n        'field2': ['error3'],\n        'field3': ['error4'],\n    })\n\n    exception = ValidationError('error')\n    updated_error_dict = {}\n    exception.update_error_dict(updated_error_dict)\n    self.assertEqual(updated_error_dict, {NON_FIELD_ERRORS: ['error']})\n\n    exception = ValidationError([\n        ValidationError('error1'),\n        ValidationError('error2'),\n    ])\n    updated_error_dict = {}\n    exception.update_error_dict(updated_error_dict)\n    self.assertEqual(updated_error_dict, {NON_FIELD_ERRORS: ['error1', 'error2']})\n\n    exception = ValidationError({\n        'field1': ValidationError('error1'),\n        'field2': ValidationError('error2'),\n    })\n    updated_error_dict = {}\n    exception.update_error_dict(updated_error_dict)\n    self.assertEqual(updated_error_dict, {\n        'field1': ['error1'],\n        'field2': ['error2'],\n    })\n", "def test_update_error_dict(self):\n    error_dict = {}\n    exception = ValidationError(error_dict)\n    error_dict['field1'] = ['error1']\n    exception.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['error1'], NON_FIELD_ERRORS: []})\n\n    error_dict = {}\n    exception = ValidationError('message')\n    exception.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {NON_FIELD_ERRORS: ['message']})\n\n    error_dict = {}\n    exception = ValidationError({\n        'field1': ValidationError('error1'),\n        'field2': ValidationError('error2'),\n    })\n    exception.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['error1'], 'field2': ['error2']})\n\n    error_dict = {}\n    exception = ValidationError([\n        ValidationError({'field1': 'error1'}),\n        ValidationError({'field2': 'error2'}),\n    ])\n    exception.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['error1'], 'field2': ['error2']})\n", "    def test_update_error_dict(self):\n        error_dict = {}\n        validation_error = ValidationError({'field1': 'message'})\n        validation_error.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {NON_FIELD_ERRORS: ['message']})\n\n        error_dict = {}\n        validation_error = ValidationError({'field1': ['message1', 'message2']})\n        validation_error.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {NON_FIELD_ERRORS: ['message1', 'message2']})\n\n        error_dict = {'field1': ['message1']}\n        validation_error = ValidationError({'field2': 'message2'})\n        validation_error.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {'field1': ['message1'], NON_FIELD_ERRORS: ['message2']})\n\n        error_dict = {'field1': ['message1']}\n        validation_error = ValidationError({'field2': ['message2', 'message3']})\n        validation_error.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {'field1': ['message1'], NON_FIELD_ERRORS: ['message2', 'message3']})\n\n        error_dict = {'field1': ['message1']}\n        validation_error = ValidationError('message2')\n        validation_error.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {'field1': ['message1'], NON_FIELD_ERRORS: ['message2']})\n\n        error_dict = {'field1': ['message1']}\n        validation_error = ValidationError([\n            ValidationError('message2'),\n            ValidationError('message3'),\n        ])\n        validation_error.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {'field1': ['message1'], NON_FIELD_ERRORS: ['message2', 'message3']})\n", "def test_update_error_dict(self):\n    error_dict = {\n        'field1': ['error1', 'error2'],\n        'field2': ['error3'],\n    }\n    validation_error = ValidationError(error_dict)\n    new_error_dict = {}\n\n    validation_error.update_error_dict(new_error_dict)\n\n    expected_error_dict = {\n        NON_FIELD_ERRORS: ['error1', 'error2', 'error3'],\n    }\n    self.assertEqual(new_error_dict, expected_error_dict)\n\n    error_dict = {\n        'field1': ['error1', 'error2'],\n        'field2': ['error3'],\n    }\n    validation_error = ValidationError(error_dict)\n    new_error_dict = {\n        'field3': ['error4'],\n    }\n\n    validation_error.update_error_dict(new_error_dict)\n\n    expected_error_dict = {\n        'field3': ['error4'],\n        NON_FIELD_ERRORS: ['error1', 'error2', 'error3'],\n    }\n    self.assertEqual(new_error_dict, expected_error_dict)\n", "def test_init(self):\n    # Test with message\n    error = ValidationError('message')\n    self.assertEqual(error.message, 'message')\n    self.assertIsNone(error.code)\n    self.assertIsNone(error.params)\n    self.assertEqual(error.error_list, [error])\n\n    # Test with code\n    error = ValidationError('message', code='my_code')\n    self.assertEqual(error.message, 'message')\n    self.assertEqual(error.code, 'my_code')\n    self.assertIsNone(error.params)\n    self.assertEqual(error.error_list, [error])\n\n    # Test with params\n    error = ValidationError('message', params={'param1': 'value1'})\n    self.assertEqual(error.message, 'message')\n    self.assertIsNone(error.code)\n    self.assertEqual(error.params, {'param1': 'value1'})\n    self.assertEqual(error.error_list, [error])\n\n    # Test with code and params\n    error = ValidationError('message', code='my_code', params={'param1': 'value1'})\n    self.assertEqual(error.message, 'message')\n    self.assertEqual(error.code, 'my_code')\n    self.assertEqual(error.params, {'param1': 'value1'})\n    self.assertEqual(error.error_list, [error])\n\n    # Test with ValidationError instance as message\n    error1 = ValidationError('message')\n    error = ValidationError(error1)\n    self.assertEqual(error.message, 'message')\n    self.assertIsNone(error.code)\n    self.assertIsNone(error.params)\n    self.assertEqual(error.error_list, [error])\n\n    # Test with ValidationError instance as message with code and params\n    error1 = ValidationError('message', code='my_code', params={'param1': 'value1'})\n    error = ValidationError(error1)\n    self.assertEqual(error.message, 'message')\n    self.assertEqual(error.code, 'my_code')\n    self.assertEqual(error.params, {'param1': 'value1'})\n    self.assertEqual(error.error_list, [error])\n\n    # Test with dictionary as message\n    error_dict = {'field1': 'message'}\n    error = ValidationError(error_dict)\n    self.assertEqual(error.error_dict, {'field1': ValidationError('message')})\n\n    # Test with list as message\n    error_list = ['message1', 'message2']\n    error = ValidationError(error_list)\n    self.assertEqual(len(error.error_list), 2)\n    self.assertIsInstance(error.error_list[0], ValidationError)\n    self.assertIsInstance(error.error_list[1], ValidationError)\n\n    # Test with nested ValidationError instance as message\n    error1 = ValidationError({'field1': 'message'})\n    error = ValidationError"], "sample_36": ["def test_clone(self):\n    fr = FilteredRelation('relation_name', condition=Q(x=1))\n    fr.alias = 'alias'\n    fr.path = ['path']\n    clone = fr.clone()\n    self.assertEqual(clone.relation_name, fr.relation_name)\n    self.assertEqual(clone.alias, fr.alias)\n    self.assertEqual(clone.condition, fr.condition)\n    self.assertEqual(clone.path, fr.path)\n    self.assertIsNot(clone.path, fr.path)\n", "def test_invert(self):\n    q = Q(price__gt=F('discounted_price'))\n    not_q = ~q\n    self.assertEqual(not_q.connector, 'AND')\n    self.assertEqual(len(not_q.children), 1)\n    self.assertEqual(not_q.negated, True)\n\n    path, args, kwargs = not_q.deconstruct()\n    self.assertEqual(args, ())\n    self.assertEqual(kwargs, {\n        'price__gt': F('discounted_price'),\n        '_negated': True,\n    })\n\n    q2 = ~not_q\n    self.assertEqual(q, q2)\n", "    def test_combine_and_empty_negated(self):\n        q = Q(x=1)\n        self.assertEqual(q & ~Q(), q)\n        self.assertEqual(~Q() & q, q)\n        self.assertEqual(~Q() & ~q, ~q)\n        self.assertEqual(q & ~Q(), q)\n        self.assertEqual(~Q() & q, q)\n", "def test_resolve_expression(self):\n    q = Q(price__gt=F('discounted_price'))\n    resolved_expression = q.resolve_expression()\n    self.assertIsInstance(resolved_expression, tuple)\n    self.assertEqual(len(resolved_expression), 2)\n", "def test_resolve_expression(self):\n    from django.db.models import Model\n    from django.db import models\n    from django.db.models.fields.related import ForwardOneToOneDescriptor, ReverseOneToOneDescriptor\n    from django.db.models.fields.related import ForwardManyToOneDescriptor, ReverseOneToOneDescriptor, ReverseOneToOneDescriptor\n\n    class Author(Model):\n        name = models.CharField(max_length=50)\n\n    class Book(Model):\n        author = models.ForeignKey(Author, on_delete=models.CASCADE)\n\n    q = Q(author__name='John')\n    q.resolve_expression(query=Book.objects)\n\n    q = Q(author__name__in=['John', 'Doe'])\n    q.resolve_expression(query=Book.objects)\n\n    q = Q(author__name='John') & Q(author__name='Doe')\n    q.resolve_expression(query=Book.objects)\n\n    q = Q(author__name='John') | Q(author__name='Doe')\n    q.resolve_expression(query=Book.objects)\n\n    # Testing resolve_expression raises NotImplementedError for FilteredRelation\n    with self.assertRaises(NotImplementedError):\n        fr = FilteredRelation('author')\n        fr.resolve_expression(query=Book.objects)\n"], "sample_67": ["def test_register_serializer(self):\n    Serializer.register(Money, ComplexSerializer)\n    string, imports = MigrationWriter.serialize(Money(\"1.3\"))\n    self.assertEqual(string, \"complex(Decimal('1.3'))\")\n    self.assertEqual(imports, {\"from decimal import Decimal\"})\n    Serializer.unregister(Money)\n    self.assertSerializedResultEqual(\n        Money(\"1.3\"),\n        (\"migrations.test_writer.Money('1.3')\", {\"import migrations.test_writer\"}),\n    )\n", "    def test_register_serializer(self):\n        class ComplexSerializer(BaseSerializer):\n                return \"complex(%r)\" % self.value, {}\n\n        Serializer.register(type, ComplexSerializer)\n        self.assertSerializedResultEqual(\n            type,\n            (\"complex(<class 'type'>)\", set()),\n        )\n        Serializer.unregister(type)\n        self.assertSerializedResultEqual(\n            type,\n            (\"models.Model\", {\"from django.db import models\"}),\n        )\n", "    def test_serialize_uuid_in_path(self):\n        uuid_a = uuid.UUID(\"5c859437-d061-4847-b3f7-e6b78852f8c8\")\n        path = pathlib.PurePosixPath(f\"/path/to/{uuid_a}\")\n        expected = (\n            f\"pathlib.PurePosixPath('/path/to/{uuid_a}')\",\n            {\"import pathlib\", \"import uuid\"},\n        )\n        self.assertSerializedResultEqual(path, expected)\n", "def test_serialize_timezone(self):\n    self.assertSerializedResultEqual(\n        datetime.timezone.utc,\n        (\"datetime.timezone.utc\", {\"import datetime\"}),\n    )\n    self.assertSerializedResultEqual(\n        get_default_timezone(),\n        (\"datetime.timezone.utc\", {\"import datetime\"}),\n    )\n    self.assertSerializedResultEqual(\n        get_fixed_timezone(0),\n        (\"datetime.timezone.utc\", {\"import datetime\"}),\n    )\n    self.assertSerializedResultEqual(\n        get_fixed_timezone(180),\n        (\"datetime.timezone(datetime.timedelta(seconds=180))\", {\"import datetime\"}),\n    )\n    self.assertSerializedResultEqual(\n        zoneinfo.ZoneInfo(\"Europe/Paris\"),\n        (\n            \"datetime.datetime(2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc)\",\n            {\"import datetime\"},\n        ),\n    )\n    self.assertSerializedResultEqual(\n        datetime.datetime(\n            2012, 1, 1, 2, 1, tzinfo=zoneinfo.ZoneInfo(\"Europe/Paris\")\n        ),\n        (\n            \"datetime.datetime(2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc)\",\n            {\"import datetime\"},\n        ),\n    )\n    tz = datetime.timezone(datetime.timedelta(hours=5))\n    self.assertSerializedResultEqual(\n        datetime.datetime(2012, 1, 1, 2, 1, tzinfo=tz),\n        (\n            \"datetime.datetime(2012, 1, 1, 2, 1, tzinfo=datetime.timezone(datetime.timedelta(seconds=18000)))\",\n            {\"import datetime\"},\n        ),\n    )\n", "    def test_register_serializer(self):\n        @deconstructible\n        class ComplexModel:\n            pass\n\n        @deconstructible\n        class ComplexModel2(ComplexModel):\n            pass\n\n        class ComplexModel3(ComplexModel):\n            pass\n\n        Serializer.register(ComplexModel, ComplexSerializer)\n        Serializer.register(ComplexModel2, ComplexSerializer)\n\n        # Successful serialization\n        self.assertSerializedResultEqual(\n            ComplexModel(),\n            (\"complex(migrations.test_writer.ComplexModel())\", {\"import migrations.test_writer\"}),\n        )\n        self.assertSerializedResultEqual(\n            ComplexModel2(),\n            (\"complex(migrations.test_writer.ComplexModel2())\", {\"import migrations.test_writer\"}),\n        )\n\n        # Unsuccessful serialization due to lack of deconstruct method\n        with self.assertRaisesMessage(\n            ValueError,\n            \"Cannot serialize: ComplexModel3()\\\\nThere are some values Django cannot serialize into migration files.\"\n            \"\\\\nFor more, see https://docs.djangoproject.com/en/%s/topics/migrations/#migration-serializing\"\n            % get_version(),\n        ):\n            self.serialize_round_trip(ComplexModel3())\n\n        # Successful deserialization\n        result = self.serialize_round_trip(ComplexModel())\n        self.assertEqual(type(result), ComplexModel)\n\n        # Unregistration of serializer\n        Serializer.unregister(ComplexModel)\n        self.assertNotIn(ComplexModel, Serializer._registry)\n\n        # Unsuccessful serialization due to lack of serializer\n        with self.assertRaisesMessage(\n            ValueError,\n            \"Cannot serialize: ComplexModel()\\\\nThere are some values Django cannot serialize into migration files.\"\n            \"\\\\nFor more, see https://docs.djangoproject.com/en/%s/topics/migrations/#migration-serializing\"\n            % get_version(),\n        ):\n            self.serialize_round_trip(ComplexModel())\n"], "sample_5": ["def test_cannot_defer_constraint_checks_reverse(self):\n    u = User.objects.create(\n        avatar=Avatar.objects.create()\n    )\n    # Attach a signal to make sure we will not do fast_deletes.\n    calls = []\n\n        calls.append('')\n    models.signals.post_delete.connect(noop, sender=Avatar)\n\n    # 1 query to find the users for the avatar.\n    # 1 query to null out user.avatar, because we can't defer the constraint\n    # 1 query to delete the user\n    # 1 query to delete the avatar\n    self.assertNumQueries(4, u.delete)\n    self.assertFalse(User.objects.exists())\n    self.assertFalse(Avatar.objects.exists())\n    self.assertEqual(len(calls), 1)\n    models.signals.post_delete.disconnect(noop, sender=Avatar)\n", "    def test_protected_error_creation(self):\n        try:\n            raise ProtectedError(\"Test message\", [1, 2, 3])\n        except ProtectedError as e:\n            self.assertEqual(str(e), \"Test message\")\n            self.assertEqual(e.protected_objects, [1, 2, 3])\n", "    def test_fast_delete_with_on_delete_set_null(self):\n        a = Avatar.objects.create(desc='a')\n        u = User.objects.create(avatar=a)\n        # One query to fast-delete the user\n        # One query to null out the user's avatar field\n        self.assertNumQueries(2, a.delete)\n        self.assertFalse(Avatar.objects.exists())\n        self.assertIsNone(User.objects.get(pk=u.pk).avatar_id)\n", "    def test_add_field_update(self):\n        collector = Collector(using='default')\n        field = A._meta.get_field('setvalue')\n        objs = [A.objects.create()]\n        collector.add_field_update(field, 1, objs)\n        self.assertEqual(collector.field_updates[A][field, 1], {objs[0]})\n", "    def test_can_fast_delete_with_multi_table_inheritance(self):\n        \"\"\"Regression test for #29759: Multi-table inheritance with\n        related objects should not prevent fast deletion.\"\"\"\n        p = Parent.objects.create()\n        c = Child.objects.create(parent_ptr=p)\n        c.save()\n        self.assertNumQueries(1, p.delete)\n"], "sample_98": ["def test_check_X_y():\n    # Test check_X_y function\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([0, 0, 1])\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    # Test check_X_y function with sparse X\n    X_sparse = sp.csr_matrix(X)\n    X_checked, y_checked = check_X_y(X_sparse, y)\n    assert_array_equal(X_checked.toarray(), X)\n\n    # Test check_X_y function with multi-output y\n    y_multi = np.array([[0, 1], [0, 1], [1, 0]])\n    X_checked, y_checked = check_X_y(X, y_multi, multi_output=True)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y_multi)\n\n    # Test check_X_y function with non-numeric y\n    y_non_numeric = np.array(['a', 'b', 'c'])\n    assert_raises(ValueError, check_X_y, X, y_non_numeric)\n\n    # Test check_X_y function with inconsistent length\n    y_inconsistent = np.array([0, 0])\n    assert_raises(ValueError, check_X_y, X, y_inconsistent)\n", "def test_check_array_min_features_warning():\n    # Test that a warning is raised when ensuring a minimum number of features\n    X = np.ones((10, 0))\n    y = np.ones(10)\n    msg = \"0 feature(s) (shape=(10, 0)) while a minimum of 1 is required.\"\n    assert_warns_message(ValueError, msg, check_X_y, X, y,\n                         ensure_min_features=1, estimator='SomeEstimator')\n", "def test_check_X_y_force_all_finite():\n    # test that y can have np.inf with force_all_finite=False\n    X = np.array([0, 0, 1])\n    y = np.array([0, np.inf, 1])\n    X_checked, y_checked = check_X_y(X, y, force_all_finite=False)\n    assert_array_equal(X, X_checked)\n    assert_array_equal(y, y_checked)\n\n    # test that y can have np.nan with force_all_finite='allow-nan'\n    X = np.array([0, 0, 1])\n    y = np.array([0, np.nan, 1])\n    X_checked, y_checked = check_X_y(X, y, force_all_finite='allow-nan')\n    assert_array_equal(X, X_checked)\n    assert_array_equal(y, y_checked)\n\n    # test that y cannot have np.nan with force_all_finite=False\n    X = np.array([0, 0, 1])\n    y = np.array([0, np.nan, 1])\n    with pytest.raises(ValueError):\n        check_X_y(X, y, force_all_finite=False)\n\n    # test that y cannot have np.inf with force_all_finite='allow-nan'\n    X = np.array([0, 0, 1])\n    y = np.array([0, np.inf, 1])\n    with pytest.raises(ValueError):\n        check_X_y(X, y, force_all_finite='allow-nan')\n", "def test_check_X_y_deprecation_warning_on_accept_sparse_none():\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_csr = sp.csr_matrix(X)\n    y_csr = sp.csr_matrix(y[:, np.newaxis])\n\n    with pytest.warns(DeprecationWarning):\n        check_X_y(X_csr, y_csr, accept_sparse=None)\n\n    assert_warns(DeprecationWarning, check_X_y, X_csr, y_csr, accept_sparse=None)\n\n    with pytest.warns(DeprecationWarning):\n        check_X_y(X, y, accept_sparse=None)\n\n    assert_warns(DeprecationWarning, check_X_y, X, y, accept_sparse=None)\n", "def test_check_X_y_input_validation():\n    # Test input validation in check_X_y\n    X = np.arange(5).reshape(5, 1)\n    y = np.arange(5)\n\n    # Check that X and y have same number of samples\n    X_1 = np.arange(10).reshape(10, 1)\n    assert_raises_regex(ValueError, 'Found input variables with inconsistent '\n                        'numbers of samples: \\\\[5, 10\\\\]', check_X_y, X, X_1)\n\n    # Check that X is 2D and y is 1D\n    X_2 = np.arange(5)\n    assert_raises_regex(ValueError, 'Expected 2D array, got 1D array instead',\n                        check_X_y, X_2, y)\n\n    X_3 = np.arange(5).reshape(5, 1, 1)\n    assert_raises_regex(ValueError, 'Found array with 3 feature\\\\(s\\\\) \\\\(shape='\n                        '\\\\(5, 1, 1\\\\)\\\\) while a\\\\ minimum of 1 is required',\n                        check_X_y, X_3, y)\n\n    y_2 = np.arange(5).reshape(5, 1)\n    assert_raises_regex(ValueError, 'bad input shape \\\\(5, 1\\\\)', check_X_y, X, y_2)\n\n    # Check that X and y are not empty\n    X_4 = np.empty((0, 1))\n    y_3 = np.empty((0,))\n    assert_raises_regex(ValueError, 'Found array with 0 feature\\\\(s\\\\) '\n                        '\\\\(shape=\\\\(0, 0\\\\)\\\\) while a minimum of 1 is required',\n                        check_X_y, X_4, y_3)\n\n    # Check that multi-output is correctly handled\n    y_4 = np.arange(10).reshape(5, 2)\n    check_X_y(X, y_4, multi_output=True)\n\n    # Check that check_X_y raises an error when X contains NaN or infinity\n    X_5 = np.array([[1, 2], [np.nan, 3], [4, 5]])\n    assert_raises_regex(ValueError, 'Input contains NaN, infinity or a value '\n                        'too large for dtype\\\\(\\\\'float64'\\\\).', check_X_y, X_5, y)\n\n    # Check that check"], "sample_120": ["def test_adjoint():\n    A = MatrixSymbol('A', n, m)\n    i, j = symbols('i j')\n    assert A.adjoint().shape == (m, n)\n    assert A.adjoint()[i, j] == A[j, i].conjugate()\n    assert (A.adjoint().adjoint()).shape == A.shape\n    assert (A.adjoint().adjoint())[i, j] == A[i, j]\n", "def test_MatrixElement_subs():\n    A = MatrixSymbol('A', 2, 2)\n    expr = A[0, 1] + 2*A[1, 0]\n    assert expr.subs(A, MatrixSymbol('B', 2, 2)) == expr.subs(A, MatrixSymbol('B', 2, 2))\n    raises(ShapeError, lambda: expr.subs(A, MatrixSymbol('B', 3, 3)))\n    assert expr.subs({A[0, 1]: 1, A[1, 0]: 2}) == 1 + 2*2\n", "def test_matrixelement_subs():\n    n, m = symbols('n m')\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', n, m)\n    a = A[1, 2]\n    b = B[1, 2]\n    c = C[1, 2]\n    assert a.subs(A, B) == b\n    assert a.subs(A, C) == c\n    assert a.subs(A, A) == a\n    assert a.subs(B, C) == a\n    assert a.subs(B, A) == a\n    assert a.subs(C, A) == a\n    assert a.subs(C, B) == a\n", "def test_MatrixSymbol_matrix_element_slicing():\n    A = MatrixSymbol('A', 3, 4)\n    assert A[:, :] == A\n    assert A[:, 1] == MatrixSlice(A, slice(None), 1)\n    assert A[1, :] == MatrixSlice(A, 1, slice(None))\n    assert A[1:2, 1:3] == MatrixSlice(A, slice(1, 2), slice(1, 3))\n\n    with raises(IndexError):\n        A[:, 5]\n\n    with raises(IndexError):\n        A[3, :]\n", "def test_matrix_symbol_slicing():\n    A = MatrixSymbol('A', 4, 4)\n    B = A[1:3, 1:3]\n    assert B.shape == (2, 2)\n    assert B[0, 0] == A[1, 1]\n    assert B[1, 1] == A[2, 2]\n    assert B[0, 1] == A[1, 2]\n    assert B[1, 0] == A[2, 1]\n    raises(IndexError, lambda: A[:, 5])\n    raises(IndexError, lambda: A[5, :])\n    raises(IndexError, lambda: A[5:7, 5:7])\n    raises(IndexError, lambda: A[-1:7, 5:7])\n    raises(IndexError, lambda: A[5:7, -1:7])\n    raises(IndexError, lambda: A[n:7, 5:7])\n    raises(IndexError, lambda: A[5:7, n:7])\n    raises(TypeError, lambda: A[n, m])\n"], "sample_104": ["def test_large_n_max_elements_to_show():\n    n_max_elements_to_show = 1000\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=n_max_elements_to_show\n    )\n\n    # Test large vocabulary\n    vocabulary = {i: i for i in range(n_max_elements_to_show)}\n    vectorizer = CountVectorizer(vocabulary=vocabulary)\n\n    expected = r\"\"\"", "def test_large_input():\n    # Test the handling of large input data\n    n_max_elements_to_show = 10\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=n_max_elements_to_show\n    )\n\n    # Large vocabulary\n    vocabulary = {i: i for i in range(n_max_elements_to_show * 10)}\n    vectorizer = CountVectorizer(vocabulary=vocabulary)\n    expected = r\"\"\"", "def test_empty_list_dict():\n    # Test rendering of empty list and dict\n    pp = _EstimatorPrettyPrinter(compact=True, indent=1, indent_at_name=True)\n    empty_list_estimator = CountVectorizer(vocabulary={})\n    empty_dict_estimator = GridSearchCV(SVC(), param_grid={})\n    expected_list = r\"\"\"", "def test_non_default_init_params():\n    # Test that non-default init params are correctly rendered\n    class CustomEstimator(BaseEstimator):\n            self.a = a\n            self.b = b\n            self.c = c\n\n    estimator = CustomEstimator(a=2, b='world', c=[1, 2, 3])\n    expected = \"\"\"", "def test_key_val_tuple_repr():\n    # Test that KeyValTuple and KeyValTupleParam are correctly rendered\n    kvt = KeyValTuple(('key', 'value'))\n    kvtp = KeyValTupleParam(('param', 'value'))\n    pp = _EstimatorPrettyPrinter(compact=True, indent=1, indent_at_name=True)\n\n    expected = \"(key, value)\"\n    assert pp.pformat(kvt) == expected\n\n    expected = \"param=value\"\n    assert pp.pformat(kvtp) == expected\n\n    # Now with long repr\n    kvt = KeyValTuple(('key', 'value' * 100))\n    kvtp = KeyValTupleParam(('param', 'value' * 100))\n    pp = _EstimatorPrettyPrinter(compact=True, indent=1, indent_at_name=True)\n\n    expected = \"(key, valuevaluevalue...)\"\n    assert pp.pformat(kvt) == expected\n\n    expected = \"param=valuevaluevalue...\"\n    assert pp.pformat(kvtp) == expected\n"], "sample_87": ["    def test_ignored_virtualenvs_via_conftest(self, testdir, fname):\n        bindir = \"Scripts\" if sys.platform.startswith(\"win\") else \"bin\"\n        testdir.tmpdir.ensure(\"virtual\", bindir, fname)\n        testfile = testdir.tmpdir.ensure(\"virtual\", \"test_invenv.py\")\n        testfile.write(\"def test_hello(): pass\")\n        testdir.makeconftest(\n            \"\"\"\n                return path.dirname.basename == \"virtual\"\n        \"\"\"\n        )\n        # by default, ignore tests inside a virtualenv\n        result = testdir.runpytest()\n        result.stdout.no_fnmatch_line(\"*test_invenv*\")\n        # allow test collection if user insists\n        result = testdir.runpytest(\"--collect-in-virtualenv\")\n        assert \"test_invenv\" in result.stdout.str()\n        # allow test collection if user directly passes in the directory\n        result = testdir.runpytest(\"virtual\")\n        assert \"test_invenv\" in result.stdout.str()\n", "    def test_collect_init_tests_with_confcutdir(self, testdir):\n        \"\"\"Check that we collect files from __init__.py files when they patch the 'python_files' (#3773)\n           and --confcutdir is specified.\n        \"\"\"\n        p = testdir.copy_example(\"collect/collect_init_tests\")\n        result = testdir.runpytest(\"--confcutdir=.\", \"--collect-only\", p)\n        result.stdout.fnmatch_lines(\n            [\n                \"collected 2 items\",\n                \"<Package */tests>\",\n                \"  <Module __init__.py>\",\n                \"    <Function test_init>\",\n                \"  <Module test_foo.py>\",\n                \"    <Function test_foo>\",\n            ]\n        )\n        result = testdir.runpytest(\"--confcutdir=.\", \"--collect-only\", \"./tests\")\n        result.stdout.fnmatch_lines(\n            [\n                \"collected 2 items\",\n                \"<Package */tests>\",\n                \"  <Module __init__.py>\",\n                \"    <Function test_init>\",\n                \"  <Module test_foo.py>\",\n                \"    <Function test_foo>\",\n            ]\n        )\n        # Ignores duplicates with \".\" and pkginit (#4310).\n        result = testdir.runpytest(\"--confcutdir=.\", \"--collect-only\", \"./tests\", \".\")\n        result.stdout.fnmatch_lines(\n            [\n                \"collected 2 items\",\n                \"<Package */tests>\",\n                \"  <Module __init__.py>\",\n                \"    <Function test_init>\",\n                \"  <Module test_foo.py>\",\n                \"    <Function test_foo>\",\n            ]\n        )\n        # Same as before, but different order.\n        result = testdir.runpytest(\"--confcutdir=.\", \"--collect-only\", \".\", \"tests\")\n        result.stdout.fnmatch_lines(\n            [\n                \"collected 2 items\",\n                \"<Package */tests>\",\n                \"  <Module __init__.py>\",\n                \"    <Function test_init>\",\n                \"  <Module test_foo.py>\",\n                \"    <Function test_foo>\",\n            ]\n        )\n        result = testdir.runpytest(\"--confcutdir=.\", \"--collect-only\", \"./tests/test_foo.py\")\n        result.stdout.fnmatch_lines(\n            [\"<Package */tests>\", \"  <Module test_foo.py>\", \"    <Function test_foo>\"]\n        )\n        result.stdout.no_fnmatch_line(\"*test_init*\")\n        result = testdir", "def test_collect_with_global_conftest_and_nested_conftest(testdir):\n    \"\"\"Test that nested conftests are taken into account when collecting tests.\"\"\"\n    sub = testdir.mkpydir(\"sub\")\n    sub.ensure(\"conftest.py\").write(\n        \"\"\"\n        import pytest\n        @pytest.fixture\n            return \"subfixture\"\n    \"\"\"\n    )\n    sub.ensure(\"test_sub.py\").write(\n        \"\"\"\n            assert myfixture == \"subfixture\"\n    \"\"\"\n    )\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n        @pytest.fixture\n            return \"globalfixture\"\n    \"\"\"\n    )\n    result = testdir.runpytest(sub)\n    result.stdout.fnmatch_lines([\"*1 passed in*\"])\n    assert result.ret == 0\n", "def test_conftest_on_dir_with_space(testdir):\n    \"\"\"Ensure conftest.py is loaded from directory with space in its name (#5029).\"\"\"\n    dir_with_space = testdir.mkdir(\"dir with space\")\n    dir_with_space.join(\"conftest.py\").write(\n        textwrap.dedent(\n            \"\"\"\n        import pytest\n            parser.addoption(\"--foo\", action=\"store_true\", default=False)\n    \"\"\"\n        )\n    )\n    test_file = dir_with_space.join(\"test_foo.py\")\n    test_file.write(\n        textwrap.dedent(\n            \"\"\"\n            assert True\n    \"\"\"\n        )\n    )\n    result = testdir.runpytest(str(dir_with_space), \"--foo\")\n    result.stdout.fnmatch_lines([\"*1 passed in*\"])\n    assert result.ret == 0\n", "    def test_custom_conftest_module_collection(self, testdir):\n        sub1 = testdir.mkpydir(\"sub1\")\n        sub2 = testdir.mkpydir(\"sub2\")\n\n        # conftest.py in sub1 should not be collected\n        sub1.join(\"conftest.py\").write(\"\")\n\n        # custom conftest module in sub1 should be collected\n        sub1.join(\"myconftest.py\").write(\n            \"\"\"\n            import pytest\n                if path.ext == \".abc\":\n                    return MyFile(path, parent)\n\n            class MyFile(pytest.File):\n                    return [MyItem(name=\"check\", parent=self)]\n\n            class MyItem(pytest.Item):\n                    pass\n        \"\"\"\n        )\n\n        # conftest.py in sub2 should be collected\n        sub2.join(\"conftest.py\").write(\n            \"\"\"\n            import pytest\n                if path.ext == \".abc\":\n                    return MyFile(path, parent)\n\n            class MyFile(pytest.File):\n                    return [MyItem(name=\"check\", parent=self)]\n\n            class MyItem(pytest.Item):\n                    pass\n        \"\"\"\n        )\n\n        testdir.makefile(\".abc\", \"\")\n\n        result = testdir.runpytest(\"--collect-only\")\n        result.stdout.fnmatch_lines(\n            [\n                \"*sub1/myconftest.py::check*\",\n                \"*sub2/conftest.py::check*\",\n            ]\n        )\n"], "sample_78": ["def test_flaskgroup_app_context_with_error(runner):\n        return Flask(\"flaskgroup\")\n\n    @click.group(cls=FlaskGroup, create_app=create_app)\n        pass\n\n    @cli.command()\n        click.echo(current_app.name)\n        raise ValueError(\"Test error\")\n\n    result = runner.invoke(cli, [\"test\"])\n    assert result.exit_code == 1\n    assert result.output == \"flaskgroup\\n\"\n    assert \"ValueError: Test error\" in result.stderr\n", "def test_appgroup_command_with_app_context(runner):\n    app = Flask(__name__)\n\n    @app.cli.command()\n        assert current_app._get_current_object() is app\n        click.echo(\"success\")\n\n    cli = FlaskGroup(create_app=lambda: app)\n    result = runner.invoke(cli, [\"test\"])\n    assert result.exit_code == 0\n    assert result.output == \"success\\n\"\n", "def test_locate_app_with_submodules(test_apps):\n    class Module:\n        class sub:\n            app = Flask(\"appname\")\n\n    assert locate_app(\"Module\", \"sub:app\").name == \"appname\"\n", "def test_flaskgroup_load_dotenv(runner, monkeypatch):\n        return Flask(\"flaskgroup\")\n\n    @click.group(cls=FlaskGroup, create_app=create_app, load_dotenv=True)\n        pass\n\n    @cli.command()\n        click.echo(os.environ.get(\"FOO\"))\n\n    # Create a .flaskenv file in the current directory\n    with open(\".flaskenv\", \"w\") as f:\n        f.write(\"FOO=bar\")\n\n    result = runner.invoke(cli, [\"test\"])\n    assert result.exit_code == 0\n    assert result.output == \"bar\\n\"\n\n    # Create a .env file in the current directory\n    with open(\".env\", \"w\") as f:\n        f.write(\"FOO=baz\")\n\n    result = runner.invoke(cli, [\"test\"])\n    assert result.exit_code == 0\n    assert result.output == \"baz\\n\"\n\n    # Remove the .env and .flaskenv files\n    os.remove(\".env\")\n    os.remove(\".flaskenv\")\n\n    # Test with an env file path\n    cli = click.Group(cls=FlaskGroup, create_app=create_app, load_dotenv=True)\n    cli.add_command(test)\n    with open(\"test.env\", \"w\") as f:\n        f.write(\"FOO=qux\")\n\n    result = runner.invoke(cli, [\"test\", \"--env-file\", \"test.env\"])\n    assert result.exit_code == 0\n    assert result.output == \"qux\\n\"\n    os.remove(\"test.env\")\n", "def test_load_dotenv_from_env_file_option(monkeypatch, runner):\n    for item in (\"FOO\", \"BAR\", \"EGGS\"):\n        monkeypatch._setitem.append((os.environ, item, notset))\n\n    result = runner.invoke(FlaskGroup(), [\"--env-file\", test_path / \".flaskenv\"])\n    assert result.exit_code == 0\n    assert \"FOO\" in os.environ\n    assert \"BAR\" in os.environ\n    assert \"EGGS\" not in os.environ\n\n"], "sample_92": ["def test_xfail_imperative_with_reason(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n            pytest.xfail(\"hello\")\n    \"\"\"\n    )\n    result = testdir.runpytest(p, \"-rx\")\n    result.stdout.fnmatch_lines([\"*XFAIL*test_this*\", \"*reason: hello*\"])\n", "def test_xfail_with_invalid_boolean(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        class InvalidBool:\n                raise TypeError(\"INVALID\")\n\n        @pytest.mark.xfail(InvalidBool(), reason=\"xxx\")\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rx\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_xfail_with_invalid_boolean*\",\n            \"*XFAIL*Error evaluating 'xfail' condition as a boolean*\",\n            \"*INVALID*\",\n            \"*1 xfailed*\",\n        ]\n    )\n", "def test_xfail_with_invalid_raises(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(raises=\"Invalid\")\n            raise TypeError()\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\"*ERROR*test_raises*\", \"*Error evaluating 'xfail' raises parameter: Invalid*\"]\n    )\n", "def test_xfail_with_invalid_reason_type(testdir):\n    \"\"\"Verify that xfail with a reason that is not a string raises an error.\"\"\"\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(reason=123)\n            assert 0\n    \"\"\"\n    )\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_xfail_marks(item)\n    assert excinfo.value.msg is not None\n    assert \"xfail reason must be a string\" in excinfo.value.msg\n", "    def test_xfail_dynamic_skip(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n                pytest.xfail(\"Expected failure\")\n                pytest.skip(\"Dynamic skip\")\n                assert False\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rsx\")\n        result.stdout.fnmatch_lines([\"*XFAIL*Expected failure*\", \"*1 xfailed*\"])\n"], "sample_107": ["def test_logistic_regression_zero_features():\n    # Test that the logistic regression can handle zero features\n    X, y = make_classification(n_samples=20, n_features=0, random_state=0)\n\n    for solver in ['lbfgs', 'liblinear', 'sag', 'saga']:\n        clf = LogisticRegression(random_state=0, solver=solver)\n        clf.fit(X, y)\n        assert_array_equal(clf.coef_, np.array([]))\n        assert_array_equal(clf.intercept_, np.log(y.mean()/(1-y.mean())))\n", "def test_logistic_regression_sparsify():\n    X, y = make_classification(random_state=0)\n\n    # Check sparsify works with dense input\n    clf = LogisticRegression(random_state=0)\n    clf.fit(X, y)\n    clf.sparsify()\n    assert sp.issparse(clf.coef_)\n    assert sp.issparse(clf.intercept_)\n\n    # Check sparsify works with sparse input\n    clf = LogisticRegression(random_state=0)\n    clf.fit(sp.csr_matrix(X), y)\n    clf.sparsify()\n    assert sp.issparse(clf.coef_)\n    assert sp.issparse(clf.intercept_)\n\n    # Check densify works with dense input\n    clf = LogisticRegression(random_state=0)\n    clf.fit(X, y)\n    clf.densify()\n    assert not sp.issparse(clf.coef_)\n    assert not sp.issparse(clf.intercept_)\n\n    # Check densify works with sparse input\n    clf = LogisticRegression(random_state=0)\n    clf.fit(sp.csr_matrix(X), y)\n    clf.densify()\n    assert not sp.issparse(clf.coef_)\n    assert not sp.issparse(clf.intercept_)\n", "def test_logistic_regression_sparse_input(solver):\n    # Test that logistic regression can handle sparse input correctly.\n    n_samples, n_features = 100, 10\n    X = sp.csr_matrix(np.random.rand(n_samples, n_features))\n    y = np.random.randint(0, 2, n_samples)\n\n    for sparse in [True, False]:\n        if sparse:\n            X_test = X\n        else:\n            X_test = X.toarray()\n\n        clf = LogisticRegression(solver=solver)\n        clf.fit(X_test, y)\n\n        assert clf.predict(X_test).shape == (n_samples,)\n        assert clf.predict_proba(X_test).shape == (n_samples, 2)\n        assert clf.score(X_test, y) <= 1.0\n", "def test_sample_weight_non_negative(LR):\n    # Check that a non-negative sample_weight array is passed to the fit method\n    X, y = make_classification(n_samples=50, n_features=20, random_state=0)\n    sample_weight = np.array([-1, 0, 1])\n    msg = \"Sample weights must be non-negative.\"\n    assert_raise_message(ValueError, msg, LR().fit, X[:3], y[:3],\n                         sample_weight)\n", "def test_logistic_regression_path_refit():\n    # Test that logistic_regression_path with refit=True works correctly\n    X, y = make_classification(n_samples=200, n_features=5, random_state=0,\n                               n_informative=3, n_redundant=0, n_classes=3)\n    params = {'C': 1.0, 'fit_intercept': True, 'penalty': 'l2',\n              'solver': 'saga', 'random_state': 0, 'multi_class': 'multinomial',\n              'max_iter': 1000, 'tol': 1e-5, 'class_weight': None}\n    Cs = [1.0]\n    # refit=True should give same results as the LogisticRegression object\n    coefs, _, _ = _logistic_regression_path(X, y, Cs=Cs, refit=True,\n                                            **params)\n    lr = LogisticRegression(**params)\n    lr.fit(X, y)\n    assert_array_almost_equal(coefs[0], lr.coef_)\n\n    # refit=False should give the same results as taking the average of the\n    # coefs obtained after fitting across the folds.\n    coefs, _, _ = _logistic_regression_path(X, y, Cs=Cs, refit=False,\n                                            **params)\n    cv = StratifiedKFold(5, random_state=0)\n    coefs_list = []\n    for train, _ in cv.split(X, y):\n        w0 = np.mean(coefs_list, axis=0) if coefs_list else np.zeros_like(coefs)\n        _, coefs_, _ = _logistic_regression_path(X[train], y[train], Cs=Cs,\n                                                 refit=True, w0=w0, **params)\n        coefs_list.append(coefs_[0])\n    avg_coefs = np.mean(coefs_list, axis=0)\n    assert_array_almost_equal(coefs[0], avg_coefs)\n"], "sample_45": ["    def test_sync_and_async_middleware(self):\n        @sync_and_async_middleware\n            pass\n        self.assertTrue(middleware_func.sync_capable)\n        self.assertTrue(middleware_func.async_capable)\n", "    def test_sync_and_async_middleware(self):\n        @sync_and_async_middleware\n            pass\n        self.assertTrue(middleware.sync_capable)\n        self.assertTrue(middleware.async_capable)\n", "    def test_sync_only_middleware(self):\n        @sync_only_middleware\n                return view_func(request, *args, **kwargs)\n            return _wrapped_view\n\n        self.assertTrue(middleware.sync_capable)\n        self.assertFalse(middleware.async_capable)\n", "    def test_make_middleware_decorator(self):\n        class Middleware:\n                self.get_response = get_response\n\n                return self.get_response(request)\n\n        decorator = make_middleware_decorator(Middleware)\n        view = lambda request: HttpResponse('OK')\n        decorated_view = decorator(view)\n\n        self.assertEqual(decorated_view(HttpRequest()).content, b'OK')\n", "    def test_decorator_from_middleware(self):\n        class TestMiddleware:\n                self.get_response = get_response\n\n                return self.get_response(request)\n\n                request.middleware_applied = True\n                return None\n\n                response.middleware_applied = True\n                return response\n\n            return HttpResponse()\n\n        decorated_view = decorator_from_middleware(TestMiddleware)(view)\n\n        request = HttpRequest()\n        response = decorated_view(request)\n\n        self.assertTrue(hasattr(request, 'middleware_applied'))\n        self.assertTrue(hasattr(response, 'middleware_applied'))\n"], "sample_100": ["def test_ordinal_encoder_unsorted_categories():\n    X = np.array([['a', 'b']], dtype=object).T\n\n    enc = OrdinalEncoder(categories=[['b', 'a', 'c']])\n    exp = np.array([[0.], [1.]])\n    assert_array_equal(enc.fit(X).transform(X), exp)\n    assert_array_equal(enc.fit_transform(X), exp)\n    assert enc.categories_[0].tolist() == ['b', 'a', 'c']\n    assert np.issubdtype(enc.categories_[0].dtype, np.object_)\n\n    # unsorted passed categories still raise for numerical values\n    X = np.array([[1, 2]]).T\n    enc = OrdinalEncoder(categories=[[2, 1, 3]])\n    msg = 'Unsorted categories are not supported'\n    with pytest.raises(ValueError, match=msg):\n        enc.fit_transform(X)\n", "def test_ordinal_encoder_handle_unknown():\n    X = np.array([['a', 'b', 'c'], ['b', 'a', 'd']])\n\n    enc = OrdinalEncoder(handle_unknown='error')\n    assert_raises(ValueError, enc.fit_transform, X)\n\n    enc = OrdinalEncoder(handle_unknown='use_encoded_value')\n    with pytest.raises(ValueError, match=\"handle_unknown should be\"):\n        enc.fit(X)\n\n    enc = OrdinalEncoder(handle_unknown='ignore')\n    with pytest.raises(ValueError, match=\"handle_unknown should be\"):\n        enc.fit(X)\n", "def test_ordinal_encoder_specified_categories_with_handle_unknown(X):\n    cats = [['a', 'b', 'c']]\n    enc = OrdinalEncoder(categories=cats, handle_unknown='use_encoded_value')\n    with pytest.raises(NotImplementedError, match=\"Using 'use_encoded_value' is not supported\"):\n        enc.fit_transform(X)\n", "def test_ordinal_encoder_unknown():\n    X = np.array([['a', 'b'], ['c', 'd']])\n\n    enc = OrdinalEncoder(handle_unknown='error')\n    with pytest.raises(ValueError, match=\"Found unknown categories\"):\n        enc.fit_transform(X)\n\n    enc = OrdinalEncoder(handle_unknown='ignore')\n    X2 = np.array([['e', 'f']])\n\n    with pytest.warns_message(UserWarning, \"Found unknown categories\"):\n        X2_tr = enc.fit_transform(X).transform(X2)\n    assert_array_equal(X2_tr, np.array([[0], [0]]))\n", "def test_ordinal_encoder_inverse_with_dtype():\n    # test inverse_transform with different dtypes\n    X = [['abc', 2, 55], ['def', 1, 55]]\n    exp = np.array(X, dtype='object')\n\n    for dtype in ['int32', 'int64', 'float32', 'float64']:\n        enc = OrdinalEncoder(dtype=dtype)\n        X_tr = enc.fit_transform(X)\n        assert_array_equal(enc.inverse_transform(X_tr), exp)\n\n    # test inverse_transform with pandas dataframe\n    pd = pytest.importorskip('pandas')\n    X_df = pd.DataFrame({'A': ['a', 'b'], 'B': [1, 2]})\n    exp = X_df.values\n\n    for dtype in ['int32', 'int64', 'float32', 'float64']:\n        enc = OrdinalEncoder(dtype=dtype)\n        X_tr = enc.fit_transform(X_df)\n        assert_array_equal(enc.inverse_transform(X_tr), exp)\n"], "sample_77": ["    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n", "    def test_set_view_interval(self):\n        axis = PseudoAxis(\"scale\")\n        axis.set_view_interval(0, 10)\n        assert axis.get_view_interval() == (0, 10)\n", "    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n", "    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n", "    def x(self):\n        return pd.Series([1, 2, 3], name=\"x\", dtype=float)\n"], "sample_68": ["    def test_update_conflicts_on_conflict_do_nothing(self):\n        UpsertConflict.objects.bulk_create(\n            [\n                UpsertConflict(number=1, rank=1, name=\"John\"),\n                UpsertConflict(number=2, rank=2, name=\"Mary\"),\n                UpsertConflict(number=3, rank=3, name=\"Hannah\"),\n            ]\n        )\n        self.assertEqual(UpsertConflict.objects.count(), 3)\n\n        conflicting_objects = [\n            UpsertConflict(number=1, rank=4, name=\"Steve\"),\n            UpsertConflict(number=2, rank=2, name=\"Olivia\"),\n            UpsertConflict(number=3, rank=1, name=\"Hannah\"),\n        ]\n        results = UpsertConflict.objects.bulk_create(\n            conflicting_objects,\n            update_conflicts=True,\n            update_fields=[],\n            unique_fields=[\"number\"],\n        )\n        self.assertEqual(len(results), len(conflicting_objects))\n        if connection.features.can_return_rows_from_bulk_insert:\n            for instance in results:\n                self.assertIsNotNone(instance.pk)\n        self.assertEqual(UpsertConflict.objects.count(), 3)\n        self.assertCountEqual(\n            UpsertConflict.objects.values(\"number\", \"rank\", \"name\"),\n            [\n                {\"number\": 1, \"rank\": 1, \"name\": \"John\"},\n                {\"number\": 2, \"rank\": 2, \"name\": \"Mary\"},\n                {\"number\": 3, \"rank\": 3, \"name\": \"Hannah\"},\n            ],\n        )\n\n        results = UpsertConflict.objects.bulk_create(\n            conflicting_objects + [UpsertConflict(number=4, rank=4, name=\"Mark\")],\n            update_conflicts=True,\n            update_fields=[],\n            unique_fields=[\"number\"],\n        )\n        self.assertEqual(len(results), 4)\n        if connection.features.can_return_rows_from_bulk_insert:\n            for instance in results:\n                self.assertIsNotNone(instance.pk)\n        self.assertEqual(UpsertConflict.objects.count(), 4)\n        self.assertCountEqual(\n            UpsertConflict.objects.values(\"number\", \"rank\", \"name\"),\n            [\n                {\"number\": 1, \"rank\": 1, \"name\": \"John\"},\n                {\"number\": 2, \"rank\": 2, \"name\": \"Mary\"},\n                {\"number\": 3, \"rank\": 3, \"name\": \"Hannah\"},\n                {\"number\": 4, \"rank\": 4, \"name\": \"Mark\"},\n", "def test_bulk_create_deferred(self):\n    class DeferredFieldsModel(Country):\n        class Meta:\n            proxy = True\n\n            super().__init__(*args, **kwargs)\n            self.defer(\"name\")\n\n    DeferredFieldsModel.objects.bulk_create(\n        [\n            DeferredFieldsModel(name=\"United States of America\", iso_two_letter=\"US\"),\n            DeferredFieldsModel(name=\"The Netherlands\", iso_two_letter=\"NL\"),\n        ]\n    )\n    self.assertEqual(DeferredFieldsModel.objects.count(), 2)\n", "def test_update_conflicts_update_fields_order(self):\n    \"\"\"Test update conflicts with update fields in a different order.\"\"\"\n    UpsertConflict.objects.bulk_create(\n        [\n            UpsertConflict(number=1, rank=1, name=\"John\"),\n            UpsertConflict(number=2, rank=2, name=\"Mary\"),\n            UpsertConflict(number=3, rank=3, name=\"Hannah\"),\n        ]\n    )\n    self.assertEqual(UpsertConflict.objects.count(), 3)\n\n    conflicting_objects = [\n        UpsertConflict(number=1, rank=4, name=\"Steve\"),\n        UpsertConflict(number=2, rank=2, name=\"Olivia\"),\n        UpsertConflict(number=3, rank=1, name=\"Hannah\"),\n    ]\n    results = UpsertConflict.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        update_fields=[\"rank\", \"name\"],\n        unique_fields=[\"number\"],\n    )\n    self.assertEqual(len(results), len(conflicting_objects))\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(UpsertConflict.objects.count(), 3)\n    self.assertCountEqual(\n        UpsertConflict.objects.values(\"number\", \"rank\", \"name\"),\n        [\n            {\"number\": 1, \"rank\": 4, \"name\": \"Steve\"},\n            {\"number\": 2, \"rank\": 2, \"name\": \"Olivia\"},\n            {\"number\": 3, \"rank\": 1, \"name\": \"Hannah\"},\n        ],\n    )\n\n    results = UpsertConflict.objects.bulk_create(\n        conflicting_objects + [UpsertConflict(number=4, rank=4, name=\"Mark\")],\n        update_conflicts=True,\n        update_fields=[\"name\", \"rank\"],\n        unique_fields=[\"number\"],\n    )\n    self.assertEqual(len(results), 4)\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(UpsertConflict.objects.count(), 4)\n    self.assertCountEqual(\n        UpsertConflict.objects.values(\"number\", \"rank\", \"name\"),\n        [\n            {\"number\": 1, \"rank\": 4, \"name\": \"Steve\"},\n            {\"number\": 2, \"rank\": 2, \"name\": \"Olivia\"},\n            {\"number\": 3, \"rank\": 1, \"name\": \"Hannah\"},\n", "    def test_bulk_create_transaction(self):\n        data = [\n            Country(name=\"United States of America\", iso_two_letter=\"US\"),\n            Country(name=\"The Netherlands\", iso_two_letter=\"NL\"),\n            Country(name=\"Germany\", iso_two_letter=\"DE\"),\n            Country(name=\"Czech Republic\", iso_two_letter=\"CZ\"),\n        ]\n        with transaction.atomic():\n            Country.objects.bulk_create(data)\n\n        self.assertEqual(Country.objects.count(), 4)\n\n        # Test that bulk_create doesn't commit the transaction if it fails.\n        with self.assertRaises(IntegrityError):\n            with transaction.atomic():\n                Country.objects.bulk_create(data)\n\n        self.assertEqual(Country.objects.count(), 4)\n", "def test_bulk_create_default_kwargs(self):\n    \"\"\"\n    Ensure that bulk_create() populates fields with their default values.\n    \"\"\"\n    FieldsWithDbColumns.objects.bulk_create([FieldsWithDbColumns()])\n    obj = FieldsWithDbColumns.objects.get()\n    self.assertEqual(obj.default_char_field, \"default\")\n    self.assertEqual(obj.default_text_field, \"default\")\n    self.assertEqual(obj.default_integer_field, 42)\n    self.assertEqual(obj.default_boolean_field, True)\n    self.assertEqual(obj.default_date_field, datetime.date(2022, 1, 1))\n    self.assertEqual(obj.default_datetime_field, datetime.datetime(2022, 1, 1, 12, 0, 0))\n"], "sample_14": ["def test_register_serializer(self):\n    Serializer.register(DeconstructibleInstances, ComplexSerializer)\n    try:\n        string = MigrationWriter.serialize(DeconstructibleInstances())[0]\n        self.assertEqual(string, \"complex(migrations.test_writer.DeconstructibleInstances())\")\n    finally:\n        Serializer.unregister(DeconstructibleInstances)\n", "def test_register_serializer(self):\n    Serializer.register(DeconstructibleInstances, ComplexSerializer)\n    try:\n        string, imports = MigrationWriter.serialize(DeconstructibleInstances())\n        self.assertEqual(string, \"complex(migrations.test_writer.DeconstructibleInstances())\")\n        self.assertEqual(imports, set())\n    finally:\n        Serializer.unregister(DeconstructibleInstances)\n", "def test_serialize_functools_partial_with_kwargs(self):\n    value = functools.partial(datetime.timedelta, seconds=1, minutes=2)\n    result = self.serialize_round_trip(value)\n    self.assertEqual(result.func, value.func)\n    self.assertEqual(result.args, value.args)\n    self.assertEqual(result.keywords, value.keywords)\n", "def test_serialize_function_type_with_nested_class(self):\n    class OuterClass:\n        class InnerClass:\n                return 42\n\n    instance = OuterClass()\n    method = instance.InnerClass().method\n\n    with self.assertRaisesMessage(ValueError, 'Could not find function method in migrations.test_writer'):\n        self.serialize_round_trip(method)\n", "def test_serialize_functools_partial_with_nested_functions(self):\n        return arg * 2\n\n        return func(arg)\n\n    partial = functools.partial(outer, inner, 2)\n    result = self.serialize_round_trip(partial)\n    self.assertEqual(result.func, outer)\n    self.assertEqual(result.args, (inner,))\n    self.assertEqual(result.keywords, {'arg': 2})\n"], "sample_57": ["def test_formset_get_context(self):\n    formset = self.make_choiceformset()\n    context = formset.get_context()\n    self.assertIn(\"formset\", context)\n    self.assertEqual(context[\"formset\"], formset)\n", "    def test_formset_absolute_max_zero(self):\n        \"\"\"\n        If absolute_max is 0 then no form is rendered at all, regardless of extra,\n        unless initial data is present.\n        \"\"\"\n        AbsoluteMaxFavoriteDrinkFormSet = formset_factory(\n            FavoriteDrinkForm, absolute_max=0\n        )\n        formset = AbsoluteMaxFavoriteDrinkFormSet()\n        self.assertEqual(formset.forms, [])\n\n        # initial trumps absolute_max\n        initial = [{\"name\": \"Fernet and Coke\"}]\n        formset = AbsoluteMaxFavoriteDrinkFormSet(initial=initial)\n        self.assertHTMLEqual(\n            \"\\n\".join(str(form) for form in formset.forms),\n            \"\"\"\n            <div><label for=\"id_form-0-name\">Name:</label>\n            <input id=\"id_form-0-name\" name=\"form-0-name\" type=\"text\"\n                value=\"Fernet and Coke\"></div>\n            \"\"\",\n        )\n", "def test_management_form_invalid_data_min_num_max_num(self):\n    data = {\n        \"form-TOTAL_FORMS\": \"2\",\n        \"form-INITIAL_FORMS\": \"1\",\n        \"form-MIN_NUM_FORMS\": \"a\",\n        \"form-MAX_NUM_FORMS\": \"b\",\n    }\n    formset = ArticleFormSet(data)\n    self.assertIs(formset.is_valid(), False)\n    self.assertEqual(\n        formset.non_form_errors(),\n        [\n            \"ManagementForm data is missing or has been tampered with. \"\n            \"Missing fields: form-MIN_NUM_FORMS, form-MAX_NUM_FORMS. \"\n            \"You may need to file a bug report if the issue persists.\"\n        ],\n    )\n    self.assertEqual(formset.errors, [])\n    self.assertHTMLEqual(\n        str(formset),\n        '<ul class=\"errorlist nonfield\">'\n        \"<li>(Hidden field MIN_NUM_FORMS) Enter a whole number.</li>\"\n        \"<li>(Hidden field MAX_NUM_FORMS) Enter a whole number.</li>\"\n        \"</ul>\"\n        \"<div>\"\n        '<input type=\"hidden\" name=\"form-TOTAL_FORMS\" value=\"2\" id=\"id_form-TOTAL_FORMS\">'\n        '<input type=\"hidden\" name=\"form-INITIAL_FORMS\" value=\"1\" '\n        'id=\"id_form-INITIAL_FORMS\">'\n        '<input type=\"hidden\" name=\"form-MIN_NUM_FORMS\" value=\"a\" '\n        'id=\"id_form-MIN_NUM_FORMS\">'\n        '<input type=\"hidden\" name=\"form-MAX_NUM_FORMS\" value=\"b\" '\n        'id=\"id_form-MAX_NUM_FORMS\">'\n        \"</div>\\n\",\n    )\n", "def test_management_form_has_absolute_max_validation(self):\n    \"\"\"\n    The management form has absolute_max validation.\n    \"\"\"\n    formset = ChoiceFormSet(\n        data={\"choices-TOTAL_FORMS\": 2001, \"choices-INITIAL_FORMS\": \"0\"},\n        prefix=\"choices\",\n    )\n    self.assertFalse(formset.management_form.is_valid())\n    self.assertEqual(\n        str(formset.management_form.errors),\n        '<ul class=\"errorlist nonfield\">'\n        \"<li>(Hidden field TOTAL_FORMS) Ensure this value is less than or equal to 1000.</li>\"\n        \"</ul>\",\n    )\n", "def test_add_fields(self):\n    class MyFormset(BaseFormSet):\n            form.fields[\"my_field\"] = CharField()\n\n    class MyForm(Form):\n        pass\n\n    MyFormset = formset_factory(MyForm, formset=MyFormset)\n    formset = MyFormset()\n    self.assertIn(\"my_field\", formset.forms[0].fields)\n\n    class MyFormset2(BaseFormSet):\n            if index is None:\n                raise Exception(\"Index should be None for the empty form\")\n            form.fields[\"my_field\"] = CharField()\n\n    MyFormset2 = formset_factory(MyForm, formset=MyFormset2)\n    formset = MyFormset2()\n    self.assertIn(\"my_field\", formset.forms[0].fields)\n    self.assertIn(\"my_field\", formset.empty_form.fields)\n\n    class MyFormset3(BaseFormSet):\n            if index is not None:\n                raise Exception(\"Index should not be None for non-empty forms\")\n            form.fields[\"my_field\"] = CharField()\n\n    with self.assertRaises(Exception):\n        MyFormset3 = formset_factory(MyForm, formset=MyFormset3)\n        MyFormset3()\n\n    class MyFormset4(BaseFormSet):\n            form.fields[\"my_field\"] = CharField(initial=\"initial\")\n\n    MyFormset4 = formset_factory(MyForm, formset=MyFormset4)\n    formset = MyFormset4()\n    self.assertEqual(formset.forms[0].fields[\"my_field\"].initial, \"initial\")\n    self.assertEqual(formset.empty_form.fields[\"my_field\"].initial, \"initial\")\n"], "sample_151": ["def test_orthogonal_direction():\n    p1 = Point(0, 1, 0, 0)\n    p2 = Point(1, 0, 0, 0)\n    p3 = Point(0, 0, 0, 1)\n\n    assert p1.orthogonal_direction == p2\n    assert p2.orthogonal_direction == p3\n    assert p3.orthogonal_direction == p1\n\n    p4 = Point(0, 1, 0)\n    p5 = Point(0, 0, 1)\n    p6 = Point(1, 0, 0)\n\n    assert p4.orthogonal_direction == p5\n    assert p5.orthogonal_direction == p6\n    assert p6.orthogonal_direction == p4\n", "def test_affine_rank():\n    p1 = Point(0, 0)\n    p2 = Point(1, 1)\n    p3 = Point(2, 2)\n    p4 = Point(0, 1)\n    assert Point.affine_rank(p1, p2, p3) == 1\n    assert Point.affine_rank(p1, p2, p4) == 2\n    assert Point.affine_rank() == -1\n    assert Point.affine_rank(p1) == 0\n    assert Point.affine_rank(p1, p1) == 0\n    assert Point.affine_rank(p1, p2) == 1\n\n    p5 = Point(1, 2, 3)\n    p6 = Point(2, 3, 4)\n    p7 = Point(3, 4, 5)\n    p8 = Point(1, 2, 4)\n    assert Point.affine_rank(p5, p6, p7) == 1\n    assert Point.affine_rank(p5, p6, p8) == 2\n    assert Point.affine_rank(p5, p6, p7, p8) == 2\n\n    p9 = Point(0, 0, 0, 0)\n    p10 = Point(1, 0, 0, 0)\n    p11 = Point(0, 1, 0, 0)\n    p12 = Point(0, 0, 1, 0)\n    p13 = Point(1, 1, 1, 0)\n    assert Point.affine_rank(p9, p10, p11, p12) == 3\n    assert Point.affine_rank(p9, p10, p11, p13) == 3\n", "def test_canberra_distance():\n    p1 = Point(0, 0)\n    p2 = Point(1, 0)\n    p3 = Point(0, 1)\n    p4 = Point(0, 0, 0)\n\n    assert Point.canberra_distance(p1, p2) == 1\n    assert Point.canberra_distance(p1, p3) == 1\n    assert Point.canberra_distance(p2, p3) == 2\n\n    raises(ValueError, lambda: Point.canberra_distance(p4, p4))\n    assert Point.canberra_distance(p1, p4) == 1\n", "def test_issue_23300():\n    # Used to give an error\n    p = Point(1, 2)\n    assert p.transform(rotate(pi/2, (2, 2))) == Point(3, -1)\n    assert p.transform(scale(3, 2, (2, 2))) == Point(4, 4)\n    assert p.transform(translate(2, 2)) == Point(3, 4)\n\n    # Test affine_rank for zero points\n    assert Point.affine_rank(Point(0, 0), Point(0, 0)) == 0\n    assert Point.affine_rank(Point(0, 0, 0), Point(0, 0, 0)) == 0\n", "def test_affine_rank():\n    p1 = Point(1, 1)\n    p2 = Point(1, 2)\n    p3 = Point(1, 3)\n    p4 = Point(2, 4)\n    assert Point.affine_rank() == -1\n    assert Point.affine_rank(p1) == 0\n    assert Point.affine_rank(p1, p2) == 1\n    assert Point.affine_rank(p1, p2, p3) == 1\n    assert Point.affine_rank(p1, p2, p4) == 2\n    assert Point.affine_rank(p1, p2, p3, p4) == 2\n    assert Point.affine_rank(p1, p2, p3, p4, p4) == 2\n    assert Point.affine_rank(p1, p1, p1, p1) == 0\n    assert Point.affine_rank(p1, p2, p3, p4, p1, p2, p3, p4) == 2\n    assert Point.affine_rank(p1, p2, p3, p4, p1, p2, p3, p4, p1, p2, p3, p4) == 2\n    raises(TypeError, lambda: Point.affine_rank(p1, Line(p1, p2)))\n    raises(TypeError, lambda: Point.affine_rank(p1, 1))\n    raises(ValueError, lambda: Point.affine_rank(p1, p2, p3, p4, p4, p1, p2, p3, p4, p1, p2, p3, p4, p1, p2, p3, p4))\n"], "sample_43": ["def test_process_request_invalid_app_label(self):\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': 'nonexistent', 'model_name': Answer._meta.model_name, 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n", "def test_process_request_empty_term(self):\n    request = self.factory.get(self.url, {'term': '', **self.opts})\n    request.user = self.superuser\n    response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n    self.assertEqual(response.status_code, 200)\n    data = json.loads(response.content.decode('utf-8'))\n    self.assertEqual(data, {\n        'results': [{'id': str(o.pk), 'text': o.question} for o in Question.objects.all()],\n        'pagination': {'more': True},\n    })\n", "def test_process_request_validation(self):\n    # Test invalid app_label\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': 'nonexistent', 'model_name': Answer._meta.model_name, 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n\n    # Test invalid model_name\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': Answer._meta.app_label, 'model_name': 'nonexistent', 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n\n    # Test invalid field_name\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': Answer._meta.app_label, 'model_name': Answer._meta.model_name, 'field_name': 'nonexistent'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n", "    def test_process_request_invalid_admin_site(self):\n        request = self.factory.get(self.url, {'term': 'is', **self.opts})\n        request.user = self.superuser\n        with self.assertRaises(PermissionDenied):\n            AutocompleteJsonView.as_view(admin_site=None)(request)\n", "def test_to_field_resolution_with_mti_field_name_not_pk(self):\n    \"\"\"\n    to_field resolution should correctly resolve for target models using MTI and\n    field_name not being the primary key.\n    \"\"\"\n    tests = [\n        (Employee, WorkHour, 'employee'),\n        (Manager, Bonus, 'recipient'),\n    ]\n    for Target, Remote, related_name in tests:\n        with self.subTest(target_model=Target, remote_model=Remote, related_name=related_name):\n            o = Target.objects.create(name=\"Frida Kahlo\", gender=2, code=\"painter\", alive=False)\n            opts = {\n                'app_label': Remote._meta.app_label,\n                'model_name': Remote._meta.model_name,\n                'field_name': related_name,\n            }\n            request = self.factory.get(self.url, {'term': 'frida', **opts})\n            request.user = self.superuser\n            response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n            self.assertEqual(response.status_code, 200)\n            data = json.loads(response.content.decode('utf-8'))\n            self.assertEqual(data, {\n                'results': [{'id': str(o.pk), 'text': o.name}],\n                'pagination': {'more': False},\n            })\n"], "sample_38": ["    def test_autocomplete_attribute(self):\n        field = UsernameField()\n        self.assertEqual(field.widget_attrs(None)['autocomplete'], 'username')\n", "    def test_normalize_username(self):\n        field = UsernameField()\n        ohm_username = 'test\u2126'  # U+2126 OHM SIGN\n        self.assertEqual(field.to_python(ohm_username), 'test\u03a9')  # U+03A9 GREEK CAPITAL LETTER OMEGA\n", "    def test_to_python(self):\n        field = UsernameField()\n        self.assertEqual(field.to_python('test'), 'test')\n", "    def test_render_without_hash_value(self):\n        # Rendering the widget with a value that doesn't start with a hash prefix\n        # mustn't raise an exception.\n        widget = ReadOnlyPasswordHashWidget()\n        html = widget.render('name', 'test', {})\n        self.assertIn(_(\"No password set.\"), html)\n", "    def test_custom_model_with_custom_username_field(self):\n        \"\"\"\n        Test custom model with custom username field.\n        \"\"\"\n        class CustomUserCreationForm(UserCreationForm):\n            class Meta(UserCreationForm.Meta):\n                model = CustomUser\n                fields = ('username',)\n\n        data = {\n            'username': 'testclient',\n            'password1': 'testclient',\n            'password2': 'testclient',\n        }\n        form = CustomUserCreationForm(data)\n        self.assertTrue(form.is_valid())\n"], "sample_79": ["def test_concat_data_vars_list():\n    data = Dataset({\"foo\": (\"x\", np.random.randn(10))})\n    split_data = [data.isel(x=slice(5)), data.isel(x=slice(5, None))]\n    actual = concat(split_data, dim=\"x\", data_vars=[\"foo\"])\n    assert_identical(data, actual)\n\n    with raises_regex(ValueError, \"some variables in data_vars are not data\"):\n        concat(split_data, dim=\"x\", data_vars=[\"not_found\"])\n", "def test_concat_positions():\n    # Test the positions argument\n    data = create_test_data()\n    split_data = [data.isel(dim1=slice(3)), data.isel(dim1=slice(3, None))]\n    positions = [0, 1]\n    actual = concat(split_data, \"dim1\", positions=positions)\n    assert_identical(data, actual)\n\n    positions = [1, 0]\n    actual = concat(split_data, \"dim1\", positions=positions)\n    assert_identical(data, actual)\n\n    with raises_regex(ValueError, \"lengths do not match\"):\n        concat(split_data, \"dim1\", positions=[0, 1, 2])\n\n    with raises_regex(ValueError, \"not integer arrays\"):\n        concat(split_data, \"dim1\", positions=[0.5, 1.0])\n", "def test_concat_positions_kwarg(self):\n    # GH401\n    data = Dataset({\"a\": (\"x\", [1, 2, 3, 4, 5])}, {\"x\": [0, 1, 2, 3, 4]})\n    objs = [data.isel(x=slice(2)), data.isel(x=slice(2, None))]\n    actual = concat(objs, \"x\", positions=[np.array([0, 1]), np.array([2, 3, 4])])\n    expected = data\n    assert_identical(actual, expected)\n\n    with raises_regex(ValueError, \"must have the same length\"):\n        concat(objs, \"x\", positions=[np.array([0, 1]), np.array([2, 3, 4, 5])])\n\n    with raises_regex(ValueError, \"must be integer arrays\"):\n        concat(objs, \"x\", positions=[[0, 1], [2, 3, 4]])\n\n    with raises_regex(ValueError, \"must be 1-dimensional\"):\n        concat(objs, \"x\", positions=[np.array([[0, 1], [2, 3]]), np.array([2, 3, 4])])\n", "def test_concat_positions_kwarg():\n    # test that positions is respected for both DataArray and Dataset\n    data = create_test_data()\n    split_data = [data.isel(dim1=slice(5)), data.isel(dim1=slice(5, None))]\n\n    positions = [np.array([1, 2, 3, 4, 5]), np.array([0, 2, 3, 4, 5])]\n    expected = Dataset(\n        {\n            \"a\": ([\"dim1\", \"dim2\", \"dim3\", \"dim4\"], np.random.randn(10, 3, 4, 4)),\n            \"b\": ([\"dim1\", \"dim2\"], np.random.randn(10, 3)),\n            \"c\": ([\"dim2\", \"dim3\", \"dim4\"], np.random.randn(3, 4, 4)),\n        },\n        {\"dim1\": [1, 2, 3, 4, 5, 0, 2, 3, 4, 5]},\n    )\n    actual = concat(split_data, dim=\"dim1\", positions=positions)\n    assert_identical(expected, actual)\n\n    # test that positions is respected for DataArray\n    foo = DataArray(np.random.randn(10, 3, 4), dims=[\"dim1\", \"dim2\", \"dim3\"])\n    split_foo = [foo.isel(dim1=slice(5)), foo.isel(dim1=slice(5, None))]\n    expected = DataArray(\n        np.random.randn(10, 3, 4),\n        dims=[\"dim1\", \"dim2\", \"dim3\"],\n        coords={\"dim1\": [1, 2, 3, 4, 5, 0, 2, 3, 4, 5]},\n    )\n    actual = concat(split_foo, dim=\"dim1\", positions=positions)\n    assert_identical(expected, actual)\n\n    # test that positions raises an error when it is not the same length\n    # as the number of objects to concatenate\n    with raises_regex(ValueError, \"positions must be the same length\"):\n        concat(split_data, dim=\"dim1\", positions=[np.array([1, 2, 3])])\n\n    # test that positions raises an error when it is not a list of arrays\n    with raises_regex(ValueError, \"positions must be a list", "def test_concat_unlabeled_dimensions(self, data):\n    # Test that unlabeled dimensions are not included in the result\n    dim = \"dim1\"\n    datasets = [g for _, g in data.groupby(dim, squeeze=False)]\n    for dim_order in [\"first\", \"last\"]:\n        if dim_order == \"first\":\n            result = concat(datasets, dim, coords=\"all\")\n            expected = data\n        else:\n            result = concat(datasets[::-1], dim, coords=\"all\")\n            expected = data.isel(dim1=data.dims[dim] - 1 - np.arange(data.dims[dim]))\n        assert_identical(result, expected)\n\n    # unlabeled dimension\n    datasets = [g for _, g in data.groupby(dim, squeeze=True)]\n    result = concat(datasets, dim, coords=\"all\")\n    expected = data\n    assert_identical(result, expected)\n\n    # unlabeled dimension with different coordinates\n    data1, data2 = [data.isel(dim1=slice(3)), data.isel(dim1=slice(3, None))]\n    data2.coords[\"extra\"] = (\"extra_dim\", np.arange(3))\n    datasets = [data1, data2]\n    with pytest.raises(ValueError):\n        concat(datasets, dim, coords=\"all\")\n\n    # unlabeled dimension with different coordinates, same names\n    data1, data2 = [data.isel(dim1=slice(3)), data.isel(dim1=slice(3, None))]\n    data2.coords[\"extra_dim\"] = (\"extra_dim\", np.arange(3))\n    datasets = [data1, data2]\n    with pytest.raises(ValueError):\n        concat(datasets, dim, coords=\"all\")\n"], "sample_135": ["def test_copy():\n    b22 = b21.copy()\n    assert b21 == b22\n    assert b21 is not b22\n", "def test_class_key():\n    assert b1.class_key() == (5, 0, 'Basic')\n    assert Atom().class_key() == (2, 0, 'Atom')\n    assert Basic.fromiter([1, 2, 3]).class_key() == (5, 0, 'Basic')\n", "def test_fromiter():\n    x, y, z = symbols('x y z')\n    assert Basic.fromiter([x, y, z]) == Basic(x, y, z)\n    assert Basic.fromiter((x, y, z)) == Basic(x, y, z)\n    assert Basic.fromiter([]) == Basic()\n    assert Basic.fromiter(()) == Basic()\n    raises(TypeError, lambda: Basic.fromiter(\"hello\"))\n", "def test_xreplace_with_frozen_set():\n    s = frozenset([1, 2])\n    t = frozenset([1, 3])\n    assert Basic(s).xreplace({s: t}) == Basic(t)\n    assert Basic(s).xreplace({t: s}) == Basic(s)\n", "def test_replace():\n    x = symbols('x')\n    y = symbols('y')\n\n    # Check replacement with a string pattern\n    assert (x + y).replace('x', 'y') == y + y\n    assert (x + y).replace('x', y) == y + y\n    assert (x + y).replace('x', x) == x + y\n\n    # Check replacement with a Wild pattern\n    p = Wild('p')\n    assert (x + y).replace(p, 2*y) == 2*y + 2*y\n    assert (x + y).replace(x + p, 2*y) == 2*y\n\n    # Check replacement with a function pattern\n    assert (x + y).replace(lambda z: z.is_Mul, lambda z: 2*z) == 2*(x + y)\n\n    # Check that the replacement is not done when the pattern has no match\n    assert (x + y).replace(sin(x), cos(x)) == x + y\n\n    # Check that the replacement is not done when the pattern is not found\n    assert (x + y).replace(sin(x) + z, cos(x) + z) == x + y\n\n    # Check replacement with a dictionary\n    assert (x + y).replace({x: y}) == y + y\n\n    # Check replacement with an ordered dictionary\n    from collections import OrderedDict\n    assert (x + y).replace(OrderedDict({x: y})) == y + y\n\n    # Check replacement with a ChainMap\n    from collections import ChainMap\n    assert (x + y).replace(ChainMap({x: y})) == y + y\n"], "sample_159": ["def test_prefix_latex_repr():\n    m = PREFIXES['m']\n    mu = PREFIXES['mu']\n\n    assert m._latex(None) == r'\\text{m}'\n    assert mu._latex(None) == r\"\\mu\"\n", "def test_prefix_latex():\n    assert kilo._latex(None) == r'\\text{k}'\n    assert micro._latex(None) == r'\\mu'\n\n", "def test_prefix_properties():\n    p = Prefix('yotta', 'Y', 24)\n    assert p.name == 'yotta'\n    assert p.abbrev == 'Y'\n    assert p.scale_factor == 1000000000000000000000000\n    assert str(p) == 'Y'\n    assert repr(p) == \"Prefix('yotta', 'Y', 24)\"\n\n    assert p._latex(None) == r'\\text{Y}'\n\n    p = Prefix('micro', 'mu', -6, latex_repr=r\"\\mu\")\n    assert p._latex(None) == r\"\\mu\"\n", "def test_prefix_latex():\n    assert str(Prefix._latex(PREFIXES['micro'], None)) == r'\\text{\\mu}'\n    assert str(Prefix._latex(PREFIXES['kilo'], None)) == r'\\text{k}'\n\n", "def test_prefix_division_with_other_prefixes():\n    m = PREFIXES['m']\n    k = PREFIXES['k']\n    M = PREFIXES['M']\n    c = PREFIXES['c']\n\n    assert m / k is M\n    assert k / m is c\n    assert M / m is k\n    assert M / k is S.One\n    assert c / m is S.One / 100\n    assert c / k is m\n    assert c / c is S.One\n    assert m / c is k\n    assert k / c is M\n    assert M / c is S(1000) / 100\n"], "sample_30": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n", "    def test_model_admin_inheritance(self):\n        class ParentAdmin(ModelAdmin):\n            list_display = ['name']\n            list_filter = ['name']\n            search_fields = ['name']\n\n        class ChildAdmin(ParentAdmin):\n            list_display = ['name', 'age']\n\n        class GrandChildAdmin(ChildAdmin):\n            list_filter = ['name', 'age']\n\n        modeladmin = GrandChildAdmin(Person, admin_site)\n        self.assertEqual(modeladmin.list_display, ['name', 'age'])\n        self.assertEqual(modeladmin.list_filter, ['name', 'age'])\n        self.assertEqual(modeladmin.search_fields, ['name'])\n", "    def setUp(self):\n        self.superuser = User.objects.create_superuser(username='super', email='super@example.com', password='secret')\n", "    def test_field_lookups(self):\n        # Setup\n        holder = Holder.objects.create(dummy=42)\n        inner = Inner.objects.create(dummy=42, holder=holder)\n        holder2 = Holder.objects.create(dummy=13)\n        Inner.objects.create(dummy=13, holder=holder2)\n\n        # Test\n        modeladmin = ModelAdmin(Inner, admin_site)\n        modeladmin.lookup_allowed('dummy', '42')\n\n        with self.assertRaises(IncorrectLookupParameters):\n            modeladmin.lookup_allowed('dummy__gt', '13')\n\n        with self.assertRaises(IncorrectLookupParameters):\n            modeladmin.lookup_allowed('holder__dummy__gt', '42')\n", "    def setUp(self):\n        self.client.force_login(self.superuser)\n"], "sample_154": ["def test_tensorflow_heaviside():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n\n    x = symbols('x')\n    f = lambdify(x, Heaviside(x), modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        x_val = tensorflow.constant(0.0)\n        assert f(x_val).eval(session=s) == 0.5\n        x_val = tensorflow.constant(-1.0)\n        assert f(x_val).eval(session=s) == 0\n        x_val = tensorflow.constant(1.0)\n        assert f(x_val).eval(session=s) == 1\n", "def test_lambdify_modules_with_duplicates():\n    f = lambdify(x, x**2, modules=[\"math\", \"sympy\"])\n    assert f(1) == 1\n    f = lambdify(x, x**2, modules=[\"sympy\", \"math\"])\n    assert f(1) == 1\n    f = lambdify(x, x**2, modules=[\"math\", \"math\"])\n    assert f(1) == 1\n", "def test_issue_21045():\n    expr = lambdify(x, x + 1j, 'math')\n    assert expr(-1) == -1 + 1j\n    assert expr(1) == 1 + 1j\n    assert expr(-2) == -2 + 1j\n    assert expr(2) == 2 + 1j\n    assert expr(2.5) == 2.5 + 1j\n", "def test_issue_15100():\n    if not tensorflow:\n        skip(\"tensorflow not installed\")\n\n    # See https://github.com/tensorflow/tensorflow/issues/37136\n    f = lambdify(x, Min(x, 1 + x, x**2), modules=\"tensorflow\")\n    with tensorflow.compat.v1.Session() as s:\n        assert f(tensorflow.constant(1.0)).eval(session=s) == 1.0\n", "def test_issue_18444():\n    if not tensorflow:\n        skip(\"TensorFlow not installed.\")\n\n    f = lambdify(x, x**2 + 1, modules=\"tensorflow\")\n    result = f(tensorflow.constant(0.5))\n    assert tensorflow.math.is_tensor(result)\n    assert result.dtype == tensorflow.float32\n    assert result.shape == []\n    assert result.numpy() == 1.25\n\n    result = f(tensorflow.constant(0.5, dtype=tensorflow.float64))\n    assert tensorflow.math.is_tensor(result)\n    assert result.dtype == tensorflow.float64\n    assert result.shape == []\n    assert result.numpy() == 1.25\n\n    result = f(tensorflow.constant([0.5], dtype=tensorflow.float32))\n    assert tensorflow.math.is_tensor(result)\n    assert result.dtype == tensorflow.float32\n    assert result.shape == [1]\n    assert tensorflow.math.reduce_all(result == [1.25])\n"], "sample_18": ["    def test_foreign_object_to_unique_fields(self):\n        class Person(models.Model):\n            # Note that both fields are unique together.\n            country_id = models.IntegerField()\n            city_id = models.IntegerField()\n\n            class Meta:\n                unique_together = (('country_id', 'city_id'),)\n\n        class MMembership(models.Model):\n            person_country_id = models.IntegerField()\n            person_city_id = models.IntegerField()\n\n            person = models.ForeignObject(\n                Person,\n                on_delete=models.SET_NULL,\n                from_fields=['person_country_id', 'person_city_id'],\n                to_fields=['country_id', 'city_id'],\n            )\n\n        field = MMembership._meta.get_field('person')\n        self.assertEqual(field.check(from_model=MMembership), [])\n", "    def test_foreign_object_with_unique_fields(self):\n        class Person(models.Model):\n            country_id = models.PositiveIntegerField(unique=True)\n            city_id = models.PositiveIntegerField(unique=True)\n\n        class Membership(models.Model):\n            person_country_id = models.PositiveIntegerField()\n            person_city_id = models.PositiveIntegerField()\n            person = models.ForeignObject(\n                Person,\n                on_delete=models.CASCADE,\n                from_fields=('person_country_id', 'person_city_id'),\n                to_fields=('country_id', 'city_id'),\n            )\n\n        field = Membership._meta.get_field('person')\n        self.assertEqual(field.check(from_model=Membership), [])\n", "    def test_referencing_to_swapped_model_using_string(self):\n        class SwappableModel(models.Model):\n            class Meta:\n                swappable = 'TEST_SWAPPABLE_MODEL'\n\n        class ReplacementModel(models.Model):\n            pass\n\n        class Model(models.Model):\n            fk = models.ForeignKey('SwappableModel', models.CASCADE)\n\n        with override_settings(TEST_SWAPPED_MODEL='invalid_models_tests.ReplacementModel'):\n            self.assertEqual(Model.check(), [\n                Error(\n                    \"Field defines a relation with the model 'invalid_models_tests.SwappableModel', \"\n                    \"which has been swapped out.\",\n                    hint=\"Update the relation to point at 'settings.TEST_SWAPPED_MODEL'.\",\n                    obj=Model._meta.get_field('fk'),\n                    id='fields.E301',\n                ),\n            ])\n", "    def test_limit_choices_to_callable(self):\n            return {'name': 'Test name'}\n\n        class Model(models.Model):\n            name = models.CharField(max_length=20)\n            m2m = models.ManyToManyField('self', limit_choices_to=limit_choices_to)\n\n        field = Model._meta.get_field('m2m')\n        self.assertEqual(field.check(from_model=Model), [])\n", "    def test_through_model_with_abstract_parent(self):\n        \"\"\"\n        Refs #29539. Ensure that a ManyToManyField with a through model\n        that inherits from an abstract model doesn't raise an exception.\n        \"\"\"\n        class AbstractModel(models.Model):\n            class Meta:\n                abstract = True\n\n        class ThroughModel(AbstractModel):\n            from_model = models.ForeignKey('FromModel', models.CASCADE)\n            to_model = models.ForeignKey('ToModel', models.CASCADE)\n\n        class FromModel(models.Model):\n            to_models = models.ManyToManyField('ToModel', through='ThroughModel')\n\n        class ToModel(models.Model):\n            pass\n\n        self.assertEqual(FromModel.check(), [])\n"], "sample_58": ["def test_default_database(self):\n    \"\"\"Tests connecting to the default 'postgres' database.\"\"\"\n    self.assertEqual(\n        self.settings_to_cmd_args_env(\n            {\n                \"USER\": \"someuser\",\n                \"PASSWORD\": \"somepassword\",\n                \"HOST\": \"somehost\",\n                \"PORT\": \"444\",\n            }\n        ),\n        (\n            [\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"postgres\"],\n            {\"PGPASSWORD\": \"somepassword\"},\n        ),\n    )\n", "    def test_sigint_handler_restore(self):\n        \"\"\"The original SIGINT handler is restored after running the shell.\"\"\"\n\n        original_handler = signal.getsignal(signal.SIGINT)\n\n            pass\n\n        with mock.patch(\"subprocess.run\", _mock_subprocess_run):\n            DatabaseClient().runshell([])\n            handler = signal.getsignal(signal.SIGINT)\n            self.assertEqual(handler, original_handler)\n", "def test_default_database(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env({}),\n        ([\"psql\"], None),\n    )\n\n    self.assertEqual(\n        self.settings_to_cmd_args_env({\"HOST\": \"somehost\"}),\n        ([\"psql\", \"-h\", \"somehost\"], None),\n    )\n\n    self.assertEqual(\n        self.settings_to_cmd_args_env({\"PORT\": \"444\"}),\n        ([\"psql\", \"-p\", \"444\"], None),\n    )\n\n    self.assertEqual(\n        self.settings_to_cmd_args_env({\"HOST\": \"somehost\", \"PORT\": \"444\"}),\n        ([\"psql\", \"-h\", \"somehost\", \"-p\", \"444\"], None),\n    )\n", "    def test_sigint_handler_restoration(self):\n        \"\"\"The original SIGINT handler is restored after running the shell.\"\"\"\n\n            handler = signal.getsignal(signal.SIGINT)\n            self.assertNotEqual(handler, signal.SIG_IGN)\n\n        with mock.patch.object(subprocess, \"run\", side_effect=_mock_subprocess_run):\n            DatabaseClient().runshell([])\n        handler = signal.getsignal(signal.SIGINT)\n        self.assertEqual(handler, signal.SIG_DFL)\n", "    def test_sigint_handler_restore(self):\n        \"\"\"SIGINT handler is restored after running psql.\"\"\"\n        original_handler = signal.getsignal(signal.SIGINT)\n        with mock.patch(\"django.db.backends.postgresql.client.subprocess\") as mock_subprocess:\n            mock_subprocess.run.return_value = None\n            DatabaseClient().runshell([])\n        self.assertEqual(signal.getsignal(signal.SIGINT), original_handler)\n"], "sample_73": ["def test_offsetimage():\n    fig, ax = plt.subplots()\n\n    im = OffsetImage(np.random.rand(10, 10), zoom=3, interpolation='nearest')\n    ab = AnnotationBbox(im, (.5, .5), xycoords='data', boxcoords=\"axes fraction\")\n    ax.add_artist(ab)\n\n    fig.canvas.draw()\n    assert ab.get_children()[0].get_data().shape == (10, 10)\n    assert ab.get_children()[0].get_zoom() == 3\n    assert ab.get_children()[0].get_offset() == (0, 0)\n", "def test_auxtransformbox():\n    # create a plot\n    # put an AuxTransformBox at the center of the axes\n    # give the AuxTransformBox a gray background\n    fig, ax = plt.subplots()\n    size = 100\n    aux_transform = mtransforms.Affine2D().rotate_deg(45)\n    aux_box = AuxTransformBox(aux_transform)\n    bg = mpatches.Rectangle((0, 0), size, size,\n                            facecolor='#CCCCCC',\n                            edgecolor='None',\n                            linewidth=0)\n    aux_box.add_artist(bg)\n    aux_box.set_offset((0.5, 0.5))\n    ax.add_artist(aux_box)\n    ax.set_xlim((0, 1))\n    ax.set_ylim((0, 1))\n    fig.canvas.draw()\n    # check the AuxTransformBox is rotated\n    bb = aux_box.get_window_extent(fig.canvas.get_renderer())\n    assert_allclose(bb.width, bb.height, atol=5)\n", "def test_offsetbox_anchor_alignment():\n    # Test alignment of AnchoredOffsetbox at different anchor points\n    fig, ax = plt.subplots()\n\n    # Define anchor points and expected coordinates\n    anchors = {\n        'upper right': (1, 1),\n        'upper left': (0, 1),\n        'lower left': (0, 0),\n        'lower right': (1, 0),\n        'right': (1, 0.5),\n        'center left': (0, 0.5),\n        'center right': (1, 0.5),\n        'lower center': (0.5, 0),\n        'upper center': (0.5, 1),\n        'center': (0.5, 0.5),\n    }\n\n    for loc, coord in anchors.items():\n        da = DrawingArea(10, 10)\n        anchored_box = AnchoredOffsetbox(loc, child=da)\n        ax.add_artist(anchored_box)\n        ax.set_xlim(0, 1)\n        ax.set_ylim(0, 1)\n        fig.canvas.draw()\n        renderer = fig.canvas.get_renderer()\n        bbox = anchored_box.get_window_extent(renderer)\n        assert_allclose(bbox.center, coord, atol=1)\n", "def test_offsetimage_draw():\n    fig, ax = plt.subplots()\n\n    # Create an image with 3 pixels of height and 4 pixels of width\n    im = np.random.rand(3, 4)\n\n    # Create an OffsetImage with the image and add it to the axes\n    oi = OffsetImage(im)\n    ab = AnnotationBbox(oi, (0.5, 0.5), xybox=(0.5, 0.5), xycoords='axes fraction', boxcoords='axes fraction')\n    ax.add_artist(ab)\n\n    # Draw the figure\n    fig.canvas.draw()\n\n    # Check if the image is drawn correctly\n    assert oi.image.get_window_extent() is not None\n", "def test_annotationbbox_arrowprops():\n    # Test the arrowprops are properly updated when the arrowprops\n    # dictionary is not provided at instantiation but later updated.\n    da = DrawingArea(20, 20, 0, 0, clip=True)\n    ab = AnnotationBbox(da, [.5, .5], xybox=(-0.2, 0.5), xycoords='data',\n                        boxcoords=\"axes fraction\", box_alignment=(0., .5),\n                        arrowprops=None)\n    ab.arrowprops = {\"arrowstyle\": \"->\"}\n    assert ab.arrow_patch.get_arrowstyle() == \"->\"\n"], "sample_121": ["def test_properties():\n    p = Permutation([1, 0, 2, 3])\n    assert p.is_Empty is False\n    assert p.is_Singleton is False\n    assert p.is_Identity is False\n\n    q = Permutation([0, 1, 2, 3])\n    assert q.is_Empty is False\n    assert q.is_Singleton is False\n    assert q.is_Identity is True\n\n    r = Permutation([0])\n    assert r.is_Empty is False\n    assert r.is_Singleton is True\n    assert r.is_Identity is True\n\n    s = Permutation([])\n    assert s.is_Empty is True\n    assert s.is_Singleton is False\n    assert s.is_Identity is True\n", "def test_rmul_with_af():\n    a = Permutation([0, 2, 1])\n    b = Permutation([2, 1, 0])\n    c = Permutation([0, 1, 2])\n    assert Permutation.rmul_with_af(a, b) == a*b\n    assert Permutation.rmul_with_af(a, b, c) == a*b*c\n    raises(TypeError, lambda: Permutation.rmul_with_af(a, list(b)))\n", "def test_af_parity():\n    # Test _af_parity on permutations with different parity\n    assert _af_parity([0, 1, 2]) == 0\n    assert _af_parity([2, 1, 0]) == 1\n    # Test _af_parity on permutations with different sizes\n    assert _af_parity([0, 1, 2, 3]) == 0\n    assert _af_parity([3, 2, 1, 0]) == 1\n    assert _af_parity([0, 1, 2, 3, 4]) == 0\n    assert _af_parity([4, 3, 2, 1, 0]) == 1\n    # Test _af_parity on permutations with singletons\n    assert _af_parity([0, 1, 2, 3, 4, 5]) == 0\n    assert _af_parity([5, 4, 3, 2, 1, 0]) == 1\n    # Test _af_parity on permutations with repeated elements\n    raises(ValueError, lambda: _af_parity([0, 1, 1, 2, 3]))\n", "def test_edge_cases():\n    # Test edge cases for Permutation methods\n    p = Permutation([0])\n    assert p.rank() == 0\n    assert p.order() == 1\n    assert p.length() == 0\n    assert p.size == 1\n    assert p.cycles == 1\n    assert p.cardinality == 1\n    assert p.inversions() == 0\n    assert p.signature() == 1\n    assert p.max() == 0\n    assert p.min() == 0\n    assert p.ascents() == []\n    assert p.descents() == []\n    assert p.runs() == [[0]]\n    assert p.index() == 0\n    assert p.get_precedence_distance(p) == 0\n    assert p.get_adjacency_distance(p) == 0\n    assert p.get_positional_distance(p) == 0\n    assert p.cycle_structure == {1: 1}\n\n    p = Permutation([])\n    assert p.rank() == 0\n    assert p.order() == 1\n    assert p.length() == 0\n    assert p.size == 0\n    assert p.cycles == 0\n    assert p.cardinality == 1\n    assert p.inversions() == 0\n    assert p.signature() == 1\n    assert p.max() == -1\n    assert p.min() == -1\n    assert p.ascents() == []\n    assert p.descents() == []\n    assert p.runs() == []\n    assert p.index() == 0\n    raises(ValueError, lambda: p.get_precedence_distance(p))\n    raises(ValueError, lambda: p.get_adjacency_distance(p))\n    raises(ValueError, lambda: p.get_positional_distance(p))\n    assert p.cycle_structure == {}\n\n    # Test edge cases for Cycle methods\n    c = Cycle()\n    assert c.list() == []\n    assert c.size == 0\n    raises(ValueError, lambda: c.list(0))\n    raises(ValueError, lambda: c.list(-2))\n\n    c = Cycle(1, 2)\n    assert c.list() == [0, 2, 1]\n    assert c.list(4) == [0, 2, 1, 3]\n    assert c.list(-1) == [0, 2, 1]\n    assert c.size == 3\n", "def test_power():\n    p = Permutation([2, 3, 1, 0])\n    assert p**4 == Permutation([0, 1, 2, 3])\n    assert p**(-4) == Permutation([0, 1, 2, 3])\n    assert p**(-3) == Permutation([1, 0, 3, 2])\n    assert p**(4 + 1) == Permutation([3, 1, 0, 2])\n    p = Permutation([0, 1, 2, 3])\n    assert p**-1 == Permutation([0, 1, 2, 3])\n    raises(TypeError, lambda: p**'s')\n    raises(TypeError, lambda: p**a)\n\n    p = Permutation([2, 3, 0, 1])\n    assert p.order() == 4\n    assert p**p.order() == Permutation([0, 1, 2, 3])\n    assert p**(p.order() + 1) == p\n    assert p**(p.order() + 2) == Permutation([2, 0, 1, 3])\n"], "sample_158": ["def test_get_units_non_prefixed():\n    assert set(SI.get_units_non_prefixed()) == {meter, second, ampere, kelvin, mole, candela, gram, kilogram}\n", "def test_Quantity_units_non_prefixed():\n    units = SI.get_units_non_prefixed()\n    assert len(units) > 0\n    assert meter in units\n    assert joule in units\n    assert day not in units\n    assert second not in units\n    assert volt in units\n    assert ohm in units\n    assert centimeter not in units\n    assert kilometer not in units\n    assert kilogram not in units\n    assert pebibyte not in units\n", "def test_UnitSystem():\n    # Test the UnitSystem class\n    si = UnitSystem.get_default_unit_system()\n    assert str(si) == \"SI\"\n    assert si.name == \"SI\"\n    assert si.descr == \"International System of Units\"\n    assert len(si._base_units) == 7\n    assert si.dim == 7\n    assert si.is_consistent\n\n    # Test the extend method\n    si_extended = si.extend((Dimension(length/time),), name=\"SI Extended\")\n    assert str(si_extended) == \"SI Extended\"\n    assert si_extended.name == \"SI Extended\"\n    assert len(si_extended._base_units) == 8\n    assert si_extended.dim == 8\n    assert si_extended.is_consistent\n\n    # Test the get_dimension_system method\n    assert si.get_dimension_system().name == \"SI\"\n\n    # Test the get_quantity_dimension method\n    assert si.get_quantity_dimension(meter) == length\n\n    # Test the get_quantity_scale_factor method\n    assert si.get_quantity_scale_factor(meter) == 1\n\n    # Test the get_unit_system method\n    assert UnitSystem.get_unit_system(\"SI\") == si\n\n    # Test the get_units_non_prefixed method\n    assert meter in si.get_units_non_prefixed()\n\n    # Test the get_dimensional_expr method\n    assert si.get_dimensional_expr(meter) == length.name\n\n    # Test the _collect_factor_and_dimension method\n    assert si._collect_factor_and_dimension(meter) == (1, length)\n\n    # Test the derived_units property\n    assert len(si.derived_units) > 0\n", "def test_unit_system():\n    us = UnitSystem(base_units=[length, time], dimension_system=SI.get_dimension_system())\n    assert us.dim == 2\n    assert us.is_consistent\n\n    us = UnitSystem(base_units=[length, time, energy], dimension_system=SI.get_dimension_system())\n    assert us.dim == 3\n    assert not us.is_consistent\n\n    us = UnitSystem(base_units=[length, time], units=[meter, second])\n    assert us._units == (meter, second)\n\n    us = UnitSystem(base_units=[length, time], derived_units={area: meter**2})\n    assert us.derived_units == {area: meter**2}\n\n    us = UnitSystem(base_units=[length, time], name=\"Custom System\", descr=\"A custom unit system\")\n    assert str(us) == \"Custom System\"\n    assert repr(us) == '<UnitSystem: (length, time)>'\n\n    us2 = us.extend(base=[energy], units=[joule], name=\"Custom System Extended\", description=\"An extension of the custom unit system\")\n    assert us2._base_units == (length, time, energy)\n    assert us2._units == (meter, second, joule)\n    assert us2.name == \"Custom System Extended\"\n    assert us2.descr == \"An extension of the custom unit system\"\n", "def test_unit_system_extension():\n    base_units = [meter, second]\n    units = [joule]\n    name = \"SI\"\n    descr = \"The International System of Units\"\n    dimension_system = None\n    derived_units = {energy: joule}\n\n    si = UnitSystem(base_units, units, name, descr, dimension_system, derived_units)\n\n    extended_units = [volt]\n    extended_name = \"SI-extended\"\n    extended_description = \"An extension of the SI system\"\n\n    extended_si = si.extend(base=extended_units, name=extended_name, description=extended_description)\n\n    assert extended_si.name == extended_name\n    assert extended_si.descr == extended_description\n    assert len(extended_si._base_units) == len(si._base_units) + len(extended_units)\n    assert extended_si._derived_units == derived_units\n\n    assert extended_si.get_dimension_system() == si.get_dimension_system()\n\n    assert extended_si.get_quantity_dimension(meter) == si.get_quantity_dimension(meter)\n    assert extended_si.get_quantity_dimension(volt) is not None\n\n    assert extended_si.get_quantity_scale_factor(meter) == si.get_quantity_scale_factor(meter)\n    assert extended_si.get_quantity_scale_factor(volt) is not None\n"], "sample_59": ["def test_management_form_prefix_with_custom_prefix(self):\n    \"\"\"The management form's prefix is updated when the formset prefix is updated.\"\"\"\n    formset = ChoiceFormSet(prefix=\"my_choices\")\n    self.assertEqual(formset.management_form.prefix, \"my_choices\")\n    formset.prefix = \"another_prefix\"\n    self.assertEqual(formset.management_form.prefix, \"another_prefix\")\n", "def test_formset_absolute_max_with_initial_and_extra(self):\n    LimitedFavoriteDrinkFormSet = formset_factory(\n        FavoriteDrinkForm, extra=1, max_num=2, initial=[{\"name\": \"Gin Tonic\"}]\n    )\n    formset = LimitedFavoriteDrinkFormSet()\n    self.assertHTMLEqual(\n        \"\\n\".join(str(form) for form in formset.forms),\n        \"\"\"\n        <div><label for=\"id_form-0-name\">Name:</label>\n        <input type=\"text\" name=\"form-0-name\" value=\"Gin Tonic\" id=\"id_form-0-name\">\n        </div>\n        <div><label for=\"id_form-1-name\">Name:</label>\n        <input type=\"text\" name=\"form-1-name\" id=\"id_form-1-name\"></div>\"\"\",\n    )\n\n    LimitedFavoriteDrinkFormSet = formset_factory(\n        FavoriteDrinkForm, extra=5, max_num=2, initial=[{\"name\": \"Gin Tonic\"}]\n    )\n    formset = LimitedFavoriteDrinkFormSet()\n    self.assertHTMLEqual(\n        \"\\n\".join(str(form) for form in formset.forms),\n        \"\"\"\n        <div><label for=\"id_form-0-name\">Name:</label>\n        <input type=\"text\" name=\"form-0-name\" value=\"Gin Tonic\" id=\"id_form-0-name\">\n        </div>\n        <div><label for=\"id_form-1-name\">Name:</label>\n        <input type=\"text\" name=\"form-1-name\" id=\"id_form-1-name\"></div>\"\"\",\n    )\n\n    LimitedFavoriteDrinkFormSet = formset_factory(\n        FavoriteDrinkForm, extra=5, max_num=3, initial=[{\"name\": \"Gin Tonic\"}]\n    )\n    formset = LimitedFavoriteDrinkFormSet()\n    self.assertHTMLEqual(\n        \"\\n\".join(str(form) for form in formset.forms),\n        \"\"\"\n        <div><label for=\"id_form-0-name\">Name:</label>\n        <input type=\"text\" name=\"form-0-name\" value=\"Gin Tonic\" id=\"id_form-0-name\">\n        </div>\n        <div><label for=\"id_form-1-name\">Name:</label>\n        <input type=\"text\" name=\"form-1-name\" id=\"id_form-1-name\"></div", "def test_formset_with_min_num_and_absolute_max(self):\n    \"\"\"\n    Test that absolute_max takes precedence over min_num if min_num > absolute_max\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, min_num=2, absolute_max=1)\n    formset = ChoiceFormSet()\n    self.assertEqual(formset.total_form_count(), 1)\n", "def test_formset_deletion_flag_with_custom_delete_widget(self):\n    \"\"\"A custom deletion widget works with the deletion flag.\"\"\"\n    class DeleteWidget(CheckboxInput):\n            return super().render(name, value, {\"class\": \"delete-checkbox\"}, renderer)\n\n    class DeletionFormSet(BaseFormSet):\n        deletion_widget = DeleteWidget\n\n    ChoiceFormSet = formset_factory(Choice, formset=DeletionFormSet, can_delete=True)\n    initial = [{\"choice\": \"Calexico\", \"votes\": 100}]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix=\"choices\")\n    self.assertHTMLEqual(\n        \"\\n\".join(form.as_ul() for form in formset.forms),\n        '<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"choices-0-votes\" value=\"100\"></li>'\n        '<li>Delete: <input class=\"delete-checkbox\" type=\"checkbox\" '\n        'name=\"choices-0-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"choices-1-choice\"></li>'\n        '<li>Votes: <input type=\"number\" name=\"choices-1-votes\"></li>'\n        '<li>Delete: <input class=\"delete-checkbox\" type=\"checkbox\" '\n        'name=\"choices-1-DELETE\"></li>',\n    )\n", "def test_formset_media(self):\n    \"\"\"Formset's media is the combination of media from each form.\"\"\"\n    class MediaForm(Form):\n        class Media:\n            js = (\"some-file.js\",)\n\n    class OtherMediaForm(Form):\n        class Media:\n            css = {\"all\": (\"some-file.css\",)}\n\n    class NoMediaForm(Form):\n        pass\n\n    formset = formset_factory([MediaForm, OtherMediaForm, NoMediaForm])\n    self.assertEqual(formset.media._js, [\"some-file.js\"])\n    self.assertEqual(formset.media._css[\"all\"], [\"some-file.css\"])\n    self.assertEqual(formset.media._jsssi, set())\n    self.assertEqual(formset.media._csss, set())\n    self.assertEqual(formset.media._css, {\"all\": [\"some-file.css\"]})\n"], "sample_60": ["def test_register_serializer(self):\n    Serializer.register(type(None), ComplexSerializer)\n    self.assertSerializedResultEqual(\n        None, (\"complex(None)\", set())\n    )\n    Serializer.unregister(type(None))\n", "def test_register_serializer(self):\n    Serializer.register(type(None), ComplexSerializer)\n    self.assertSerializedResultEqual(None, (\"complex(None)\", set()))\n    Serializer.unregister(type(None))\n", "def test_serialize_settings_reference(self):\n    string, imports = serializer_factory(SettingsReference(settings.AUTH_USER_MODEL, \"AUTH_USER_MODEL\")).serialize()\n    self.assertEqual(string, \"settings.AUTH_USER_MODEL\")\n    self.assertEqual(imports, {\"from django.conf import settings\"})\n\n    string, imports = serializer_factory(SettingsReference(\"someapp.model\", \"AUTH_USER_MODEL\")).serialize()\n    self.assertEqual(string, \"settings.AUTH_USER_MODEL\")\n    self.assertEqual(imports, {\"from django.conf import settings\"})\n\n    string, imports = serializer_factory(SettingsReference(\"someapp.model\", \"NOT_SETTING\")).serialize()\n    self.assertEqual(string, \"settings.NOT_SETTING\")\n    self.assertEqual(imports, {\"from django.conf import settings\"})\n\n    string, imports = serializer_factory(SettingsReference(\"someapp.model\", \"AUTH_USER_MODEL\", \"path.to.setting\")).serialize()\n    self.assertEqual(string, \"settings.NOT_SETTING\")\n    self.assertEqual(imports, {\"from django.conf import settings\"})\n", "    def test_serialize_settings_reference(self):\n        \"\"\"\n        Tests serialization of settings reference.\n        \"\"\"\n        with self.settings(AUTH_USER_MODEL='testapp.User'):\n            setting = SettingsReference('AUTH_USER_MODEL', 'AUTH_USER_MODEL')\n            self.assertSerializedEqual(setting)\n            self.assertSerializedResultEqual(\n                setting,\n                (\"settings.AUTH_USER_MODEL\", {\"from django.conf import settings\"}),\n            )\n\n            # Test setting that doesn't exist\n            setting = SettingsReference('NON_EXISTENT_SETTING', 'NON_EXISTENT_SETTING')\n            with self.assertRaisesMessage(\n                AttributeError, \"Invalid setting: 'NON_EXISTENT_SETTING'\"\n            ):\n                self.assertSerializedEqual(setting)\n", "    def test_register_serializer(self):\n        # Test registering a serializer for a custom type\n        @deconstructible\n        class Complex:\n            pass\n\n            return self.value.x, set()\n\n        Serializer.register(Complex, ComplexSerializer)\n        string, imports = MigrationWriter.serialize(Complex())\n        self.assertEqual(string, \"complex(migrations.test_writer.Complex())\")\n        self.assertIn(\"import migrations.test_writer\", imports)\n\n        # Test unregistering a serializer\n        Serializer.unregister(Complex)\n        with self.assertRaises(ValueError):\n            MigrationWriter.serialize(Complex())\n\n        # Test registering a serializer for a type that already has a serializer\n        Serializer.register(list, ComplexSerializer)\n        string, imports = MigrationWriter.serialize([1, 2, 3])\n        self.assertEqual(string, \"complex([1, 2, 3])\")\n        self.assertEqual(imports, set())\n"], "sample_102": ["def test_compute_score_samples():\n    \"\"\"Test _compute_score_samples and _compute_chunked_score_samples consistency\"\"\"\n    X_train = [[1, 1], [1, 2], [2, 1]]\n    clf = IsolationForest(contamination=0.1).fit(X_train)\n    X_test = [[2., 2.]]\n    chunk_size = len(X_test)\n    assert_array_almost_equal(clf._compute_score_samples(X_test, True),\n                              clf._compute_chunked_score_samples(X_test))\n    with patch(\n        \"sklearn.ensemble.iforest.get_chunk_n_rows\",\n        side_effect=Mock(**{\"return_value\": chunk_size}),\n    ):\n        assert_array_almost_equal(clf._compute_score_samples(X_test, True),\n                                  clf._compute_chunked_score_samples(X_test))\n", "def test_iforest_max_depth():\n    \"\"\"Test that max_depth is correctly calculated when max_samples is less than n_samples\"\"\"\n    rng = check_random_state(0)\n    X_train = rng.randn(100, 2)\n    X_test = rng.randn(10, 2)\n\n    # Test with max_samples as an integer\n    clf = IsolationForest(n_estimators=10, max_samples=50, random_state=rng).fit(X_train)\n    for est in clf.estimators_:\n        assert_equal(est.max_depth, int(np.ceil(np.log2(50))))\n\n    # Test with max_samples as a float\n    clf = IsolationForest(n_estimators=10, max_samples=0.5, random_state=rng).fit(X_train)\n    for est in clf.estimators_:\n        assert_equal(est.max_depth, int(np.ceil(np.log2(50))))\n\n    # Test with max_samples as 'auto'\n    clf = IsolationForest(n_estimators=10, max_samples='auto', random_state=rng).fit(X_train)\n    for est in clf.estimators_:\n        assert_equal(est.max_depth, int(np.ceil(np.log2(256))))\n\n    # Test predict method\n    clf.predict(X_test)\n", "def test_iforest_subsampled_features_constant():\n    # It tests non-regression for #5732 which failed at predict.\n    rng = check_random_state(0)\n    X_train, X_test, y_train, y_test = train_test_split(boston.data[:50],\n                                                        boston.target[:50],\n                                                        random_state=rng)\n    clf = IsolationForest(max_features=1)\n    clf.fit(X_train, y_train)\n    clf.predict(X_test)\n\n    # Test when subsample_features=False (n_features < max_features)\n    X_train, X_test, y_train, y_test = train_test_split(boston.data[:50, :2],\n                                                        boston.target[:50],\n                                                        random_state=rng)\n    clf = IsolationForest(max_features=10)\n    clf.fit(X_train, y_train)\n    clf.predict(X_test)\n", "def test_iforest_fit_predict_n_jobs():\n    \"\"\"Test that IsolationForest works with multiple n_jobs for fit and predict.\"\"\"\n    X_train = [[1, 1], [1, 2], [2, 1]]\n    X_test = [[2., 2.]]\n\n    clf = IsolationForest(n_estimators=5, random_state=0)\n    clf.fit(X_train)\n\n    for n_jobs in [None, 1, 2, 3, -1]:\n        clf.set_params(n_jobs=n_jobs)\n        decision_func = clf.decision_function(X_test)\n        assert_array_almost_equal(clf.decision_function(X_test), decision_func)\n", "def test_iforest_parallel_computing(n_estimators, n_jobs):\n    \"\"\"Check parallel computing for IsolationForest\"\"\"\n    X = iris.data\n    y = iris.target\n\n    # Check parallel computing with and without pre_dispatch\n    for pre_dispatch in ['2*n_jobs', 'all']:\n        with patch.dict('os.environ', {'JOBLIB_DISPATCH_VERSION': '0.16'}):\n            with patch('sklearn.utils.parallel_backend', return_value=None) as mock_backend:\n                clf = IsolationForest(n_estimators=n_estimators, n_jobs=n_jobs, random_state=0)\n                clf.fit(X)\n                clf.predict(X)\n\n                assert mock_backend.called_once\n                mock_backend.assert_called_once_with('multiprocessing',\n                                                    n_jobs=n_jobs,\n                                                    pre_dispatch=pre_dispatch)\n\n"], "sample_109": ["def test_kfold_repr(CVSplitter):\n    splitter = CVSplitter(n_splits=2, shuffle=True, random_state=42)\n    assert repr(splitter) == (f\"{CVSplitter.__name__}(n_splits=2, \"\n                              \"random_state=42, shuffle=True)\")\n", "def test_time_series_split_long_data():\n    X = np.zeros((600, 1))\n    tscv = TimeSeriesSplit(n_splits=4)\n    splits = list(tscv.split(X))\n    assert len(splits) == 4\n    assert_array_equal(splits[0], (np.arange(150), np.arange(150, 300)))\n    assert_array_equal(splits[1], (np.arange(200), np.arange(300, 400)))\n    assert_array_equal(splits[2], (np.arange(250), np.arange(400, 500)))\n    assert_array_equal(splits[3], (np.arange(300), np.arange(500, 600)))\n", "def test_group_shuffle_split_groups_input_types():\n    X = y = np.ones(10)\n    g = np.array([1, 1, 1, 1, 2, 2, 2, 3, 3, 3])\n    groups_list = g.tolist()\n    groups_df = MockDataFrame(g)\n\n    n_splits = 5\n    test_size = 1. / 3\n    train_size = 2. / 3\n\n    cv1 = GroupShuffleSplit(n_splits, test_size, train_size, random_state=0)\n    cv2 = GroupShuffleSplit(n_splits, test_size, train_size, random_state=0)\n    cv3 = GroupShuffleSplit(n_splits, test_size, train_size, random_state=0)\n\n    # check that groups types does not affect the result\n    np.testing.assert_equal(list(cv1.split(X, y, g)), list(cv2.split(X, y, groups_list)))\n    np.testing.assert_equal(list(cv2.split(X, y, groups_list)), list(cv3.split(X, y, groups_df)))\n", "def test_leave_p_out():\n    # Check that LeavePOut works as expected\n    p = 2\n    X = np.arange(6)\n    loo = LeavePOut(p)\n    expected_combinations = np.array(list(combinations(range(6), p)))\n    splits = np.array(list(loo.split(X)))\n\n    # Check if the combinations are returned\n    assert np.all(np.sort(splits) == np.sort(expected_combinations))\n\n    # Check that all samples are present in a test set\n    test_indices = np.concatenate(splits[:, 1, :])\n    assert np.all(np.unique(test_indices) == np.arange(len(X)))\n\n    # Check that all combinations are present\n    assert len(splits) == comb(len(X), p)\n\n    # Check that the combinations are unique\n    assert len(np.unique(splits, axis=0)) == len(splits)\n", "def test_leave_one_p_group_out_combinations():\n    # test combinations is correct, and _approximate_mode\n    X = np.array([1, 2, 3, 4])\n    y = np.array([0, 0, 1, 1])\n    groups = np.array([1, 1, 1, 2])\n\n    # case 1: n_groups < p\n    cv = LeavePGroupsOut(n_groups=2)\n    # for groups with one sample, this should raise\n    with pytest.raises(ValueError):\n        list(cv.split(X, y, groups))\n\n    # case 2: n_groups > p\n    # make sure groups with only one sample don't cause problems\n    groups = np.array([1, 1, 2, 3])\n    cv = LeavePGroupsOut(n_groups=2)\n    assert len(list(cv.split(X, y, groups))) == 6\n\n    # case 3: n_groups = p\n    cv = LeavePGroupsOut(n_groups=1)\n    assert len(list(cv.split(X, y, groups))) == 2\n"], "sample_110": ["def test_affinity_propagation_damping():\n    # Test AffinityPropagation with different damping values\n    af = AffinityPropagation(affinity=\"euclidean\", damping=0.9)\n    labels = af.fit_predict(X)\n    assert np.unique(labels).size > 1\n\n    af = AffinityPropagation(affinity=\"euclidean\", damping=0.51)\n    labels = af.fit_predict(X)\n    assert np.unique(labels).size > 1\n\n    with pytest.raises(ValueError):\n        AffinityPropagation(affinity=\"euclidean\", damping=0.4)\n\n    with pytest.raises(ValueError):\n        AffinityPropagation(affinity=\"euclidean\", damping=1)\n", "def test_affinity_propagation_empty_input():\n    # Test empty input\n    af = AffinityPropagation(affinity=\"euclidean\")\n    with pytest.raises(ValueError):\n        af.fit(np.empty((0, 2)))\n\n    # Test input with a single row\n    with pytest.raises(ValueError):\n        af.fit(np.array([[1, 2]]))\n", "def test_affinity_propagation_unequal_preferences():\n    # Test Affinity Propagation with different preferences for each sample\n    X = np.array([[0, 0], [1, 1], [-2, -2]])\n    S = -euclidean_distances(X, squared=True)\n    preference = np.array([-1, 0, 1])\n\n    cluster_center_indices, labels = affinity_propagation(S, preference=preference)\n    assert len(cluster_center_indices) > 0\n    assert len(labels) > 0\n\n    af = AffinityPropagation(preference=preference, affinity=\"precomputed\")\n    labels_precomputed = af.fit(S).labels_\n\n    af = AffinityPropagation(preference=preference, verbose=True)\n    labels = af.fit(X).labels_\n\n    assert_array_equal(labels, labels_precomputed)\n\n    cluster_centers_indices = af.cluster_centers_indices_\n\n    assert np.unique(labels).size > 0\n    assert len(cluster_centers_indices) > 0\n", "def test_affinity_propagation_inputs():\n    # Test AffinityPropagation with invalid inputs\n    af = AffinityPropagation(affinity=\"euclidean\")\n\n    # Test with non-numeric input\n    X = np.array([[1, 2], ['a', 'b']])\n    with pytest.raises(ValueError):\n        af.fit(X)\n\n    # Test with non-square similarity matrix\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    af = AffinityPropagation(affinity=\"precomputed\")\n    with pytest.raises(ValueError):\n        af.fit(X)\n\n    # Test with non-numeric similarity matrix\n    X = np.array([[1, 2], [3, 'a']])\n    af = AffinityPropagation(affinity=\"precomputed\")\n    with pytest.raises(ValueError):\n        af.fit(X)\n\n    # Test with preference as a 2D array\n    X = np.array([[1, 2], [3, 4]])\n    af = AffinityPropagation(affinity=\"precomputed\")\n    with pytest.raises(ValueError):\n        af.fit(X, preference=np.array([[1, 2], [3, 4]]))\n", "def test_affinity_propagation_predict_equal_similarities():\n    # Test AffinityPropagation.predict with equal similarities\n    X = np.array([[-1, 1], [1, -1]])\n    S = -euclidean_distances(X, squared=True)\n    af = assert_no_warnings(AffinityPropagation, affinity=\"precomputed\")\n    af.fit(S)\n\n    # When all samples have equal similarities, assignment of labels depends\n    # on preference.\n    to_predict = np.array([[0, 0], [2, 2]])\n    y = af.predict(to_predict)\n\n    # The result may vary depending on the preference, so just check\n    # that all predictions are valid labels.\n    assert_array_equal(y, np.array([0, 0]))  # or np.array([1, 1])\n"], "sample_39": ["    def test_language_prefix(self):\n        self.assertEqual(LocalePrefixPattern().language_prefix, '')\n", "    def test_init(self):\n        pattern = RegexPattern(r'^test/$', name='test')\n        self.assertEqual(pattern.regex.pattern, r'^test/$')\n        self.assertEqual(pattern.name, 'test')\n", "    def test_check_pattern_name(self):\n        # Test that pattern names can't contain colons\n        pattern = RegexPattern(r'^test/$', name='test:pattern')\n        url_pattern = URLPattern(pattern, empty_view)\n        with self.assertRaisesMessage(Warning, \"Your URL pattern 'test:pattern' has a name including a ':'. Remove the colon, to avoid ambiguous namespace references.\"):\n            url_pattern.check()\n", "    def test_regex_pattern_with_trailing_slash(self):\n        # Test that the trailing slash is included in the pattern when present\n        pattern = RegexPattern(r'^hello/world/$', name='hello')\n        self.assertEqual(pattern.regex.pattern, r'^hello/world/$')\n", "    def test_name_collision(self):\n        \"\"\"\n        Two URLPatterns with the same name can be registered. This is intentional\n        and used in some third-party packages.\n        \"\"\"\n        url_patterns = [\n            path('test/', lambda request: None, name='test'),\n            path('test2/', lambda request: None, name='test'),\n        ]\n        with self.assertRaisesMessage(\n            NoReverseMatch, \"Reverse for 'test' with no arguments not found. 2 pattern(s) tried:\"\n        ):\n            reverse('test')\n"]}, "raw_scored_generations": {"sample_3": [false, false, false, true, true], "sample_2": [false, false, false, false, false], "sample_1": [false, false, false, false, false], "sample_0": [true, true, true, false, false], "sample_6": [true, true, true, true, true], "sample_4": [false, false, false, false, false], "sample_5": [false, false, false, false, false], "sample_7": [false, false, false, false, false], "sample_9": [false, false, false, false, false], "sample_8": [false, false, false, false, false], "sample_10": [true, true, true, true, true], "sample_11": [true, true, false, true, false], "sample_13": [false, false, false, false, false], "sample_12": [true, true, true, true, true], "sample_14": [true, true, true, false, false], "sample_15": [true, true, true, true, true], "sample_16": [false, false, false, true, false], "sample_17": [false, false, false, false, false], "sample_18": [true, true, false, false, true], "sample_19": [false, false, false, true, true], "sample_21": [true, false, false, false, true], "sample_20": [false, true, false, false, true], "sample_23": [true, true, true, true, true], "sample_22": [true, true, true, false, true], "sample_24": [true, true, false, true, true], "sample_25": [true, true, true, true, true], "sample_28": [false, false, false, false, false], "sample_26": [true, false, false, false, false], "sample_27": [true, true, false, false, true], "sample_29": [false, false, false, false, false], "sample_31": [true, false, true, false, true], "sample_30": [false, true, false, true, false], "sample_32": [false, false, false, false, false], "sample_33": [false, false, false, false, false], "sample_34": [false, false, false, false, false], "sample_35": [false, false, false, false, false], "sample_36": [true, true, true, true, true], "sample_37": [false, false, true, false, false], "sample_39": [false, true, false, true, false], "sample_38": [false, false, false, false, false], "sample_40": [false, true, true, false, true], "sample_42": [false, true, true, false, false], "sample_41": [false, true, true, false, true], "sample_43": [true, true, true, true, true], "sample_45": [false, false, false, false, false], "sample_44": [true, false, true, false, true], "sample_46": [false, false, false, false, false], "sample_48": [true, true, false, true, false], "sample_47": [false, false, true, false, true], "sample_50": [true, true, true, true, true], "sample_49": [true, true, false, false, true], "sample_51": [true, true, true, true, true], "sample_52": [false, true, true, false, true], "sample_53": [false, true, false, true, false], "sample_55": [true, false, false, true, false], "sample_54": [false, true, false, true, true], "sample_56": [true, false, false, true, false], "sample_58": [true, false, true, false, false], "sample_57": [true, false, true, true, true], "sample_60": [true, true, true, false, false], "sample_59": [true, false, true, false, true], "sample_61": [false, false, true, true, true], "sample_63": [false, false, false, false, false], "sample_62": [false, false, false, false, false], "sample_64": [true, true, true, false, true], "sample_66": [true, true, true, true, false], "sample_65": [false, false, false, false, false], "sample_68": [false, true, false, false, true], "sample_67": [true, false, false, true, false], "sample_69": [false, false, true, false, false], "sample_70": [false, true, false, false, true], "sample_71": [false, true, true, true, true], "sample_72": [false, false, false, false, false], "sample_73": [false, false, false, true, false], "sample_74": [false, true, false, false, false], "sample_75": [false, false, false, true, false], "sample_76": [false, false, false, false, false], "sample_77": [false, false, false, false, false], "sample_78": [false, false, false, false, false], "sample_79": [true, false, false, false, false], "sample_80": [false, false, false, false, false], "sample_82": [false, false, false, false, false], "sample_81": [false, false, true, false, false], "sample_83": [false, false, false, false, false], "sample_84": [false, true, true, false, true], "sample_85": [false, false, false, false, false], "sample_86": [false, false, false, false, false], "sample_87": [true, false, false, false, false], "sample_88": [false, false, false, false, false], "sample_89": [false, false, false, false, false], "sample_90": [false, false, false, false, false], "sample_91": [false, false, false, true, false], "sample_92": [false, false, false, false, true], "sample_93": [false, false, false, false, false], "sample_95": [true, false, false, false, true], "sample_94": [false, true, false, false, false], "sample_96": [true, false, false, false, false], "sample_97": [false, false, false, false, false], "sample_98": [false, false, false, false, false], "sample_99": [false, false, true, false, false], "sample_100": [false, false, false, false, true], "sample_101": [true, false, true, false, true], "sample_102": [false, false, false, true, false], "sample_103": [false, false, false, false, false], "sample_104": [false, false, false, false, false], "sample_105": [false, false, true, false, false], "sample_107": [false, false, false, false, false], "sample_106": [false, true, false, false, false], "sample_108": [false, false, false, false, false], "sample_109": [false, false, true, false, false], "sample_110": [false, false, true, false, false], "sample_111": [false, false, false, false, false], "sample_112": [true, true, false, true, false], "sample_113": [true, false, false, false, false], "sample_114": [false, false, false, false, false], "sample_115": [false, false, false, false, false], "sample_116": [false, false, false, false, false], "sample_117": [false, false, false, false, false], "sample_118": [false, false, false, false, false], "sample_119": [true, false, true, true, false], "sample_120": [true, false, true, false, false], "sample_121": [true, false, false, false, false], "sample_122": [true, false, true, true, false], "sample_123": [true, false, true, false, false], "sample_124": [true, false, false, true, false], "sample_125": [false, false, false, false, false], "sample_126": [true, false, false, false, false], "sample_127": [false, false, false, true, false], "sample_128": [false, false, false, false, false], "sample_129": [false, false, false, false, false], "sample_130": [true, false, true, false, true], "sample_131": [true, false, true, true, true], "sample_132": [false, false, false, false, false], "sample_133": [false, false, false, false, false], "sample_134": [true, true, false, false, true], "sample_135": [true, true, false, false, false], "sample_136": [false, false, false, true, false], "sample_137": [false, false, false, false, false], "sample_138": [false, false, false, false, false], "sample_139": [false, false, false, false, false], "sample_140": [true, true, true, false, false], "sample_142": [false, false, false, false, false], "sample_141": [false, false, false, false, false], "sample_143": [false, false, false, false, false], "sample_144": [true, true, true, true, true], "sample_145": [false, false, false, false, false], "sample_146": [false, false, false, false, true], "sample_147": [false, false, false, false, false], "sample_148": [false, false, false, false, false], "sample_149": [false, true, false, false, false], "sample_150": [false, false, false, false, false], "sample_151": [false, true, false, false, false], "sample_152": [false, false, true, true, false], "sample_153": [true, false, false, false, false], "sample_154": [true, true, true, true, true], "sample_155": [false, false, false, false, false], "sample_156": [false, false, false, false, false], "sample_157": [false, false, false, false, false], "sample_158": [false, false, false, false, false], "sample_159": [true, false, false, false, false]}}